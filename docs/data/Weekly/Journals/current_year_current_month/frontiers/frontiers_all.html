<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>frontiers</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="fcomp">FCOMP - 7</h2>
<ul>
<li><details>
<summary>
(2025). Enhancing medical image segmentation via complementary CNN-transformer fusion and boundary perception. <em>FCOMP</em>, <em>7</em>, 1677905. (<a href='https://doi.org/10.3389/fcomp.2025.1677905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionVision Transformers (ViTs) show promise for image recognition but struggle with medical image segmentation due to a lack of inductive biases for local structures and an inability to adapt to diverse modalities like CT, endoscopy, and dermatology. Effectively combining multi-scale features from CNNs and ViTs remains a critical, unsolved challenge.MethodsWe propose a Pyramid Feature Fusion Network (PFF-Net) that integrates hierarchical features from pre-trained CNN and Transformer backbones. Its dual-branch architecture includes: (1) a region-aware branch for global-to-local contextual understanding via pyramid fusion, and (2) a boundary-aware branch that employs orthogonal Sobel operators and low-level features to generate precise, semantic boundaries. These boundary predictions are iteratively fed back to enhance the region branch, creating a mutually reinforcing loop between segmenting anatomical regions and delineating their boundaries.ResultsPFF-Net achieved state-of-the-art performance across three clinical segmentation tasks. On polyp segmentation, PFF-Net attained a Dice score of 91.87%, surpassing the TransUNet baseline (86.96%) by 5.6% and reducing the HD95 metric from 22.25 to 11.68 (a 47.5% reduction). For spleen CT segmentation, it reached a Dice score of 95.33%, outperforming ESFPNet-S (94.92%) by 4.3% while reducing the HD95 from 6.99 to 3.35 (a 52.1% reduction). In skin lesion segmentation, our model achieved a Dice score of 90.29%, which represents a 7.3% improvement over the ESFPNet-S baseline (89.64%).DiscussionThe results validate the effectiveness of our pyramid fusion strategy and dual-branch design in bridging the domain gap between natural and medical images. The framework demonstrates strong generalization on small-scale datasets, proving its robustness and potential for accurate segmentation across highly heterogeneous medical imaging modalities.},
  archive      = {J_FCOMP},
  author       = {Liu, Xiaowei and Tian, Juanxiu and Huang, Shangrong and Shen, Wei},
  doi          = {10.3389/fcomp.2025.1677905},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1677905},
  shortjournal = {Front. Comput. Sci.},
  title        = {Enhancing medical image segmentation via complementary CNN-transformer fusion and boundary perception},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Market malicious bidding user detection based on multi-agent reinforcement learning. <em>FCOMP</em>, <em>7</em>, 1670238. (<a href='https://doi.org/10.3389/fcomp.2025.1670238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of e-commerce and online auction markets, malicious bidding activities have severely disrupted market order. Traditional detection methods face limitations due to their inability to effectively address the covert nature, dynamic characteristics, and massive data volumes associated with such behaviors. To address this challenge, this paper proposes a detection method for users engaging in malicious bidding based on Multi-Agent Reinforcement Learning (MARL). This approach first models target users as specialized agents, then integrates their historical bidding data, and finally learns optimal strategies through competitive games with adversarial agents. Additionally, this paper designs a dynamic adjustment mechanism for the maliciousness coefficient to simulate user behavior changes, enabling precise assessment of malicious intent. Compared to existing fraud detection approaches based on reinforcement learning, the fundamental innovation lies not merely in applying MARL technology, but in introducing the novel “dynamic maliciousness coefficient” mechanism. This mechanism achieves dynamic and precise maliciousness assessment through mathematical modeling and real-time iteration, addressing the shortcomings of traditional MARL models in capturing user behavioral heterogeneity. Experimental results demonstrate that this method exhibits higher detection accuracy and adaptability in complex dynamic market environments. It effectively captures bidder interaction relationships, significantly enhancing the detection of malicious behavior.},
  archive      = {J_FCOMP},
  author       = {Wang, Peng and Wang, Yimeng and Zhang, Yilin and Lan, Yin and Huang, Ziyang and Tang, Di and Liang, Yu},
  doi          = {10.3389/fcomp.2025.1670238},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1670238},
  shortjournal = {Front. Comput. Sci.},
  title        = {Market malicious bidding user detection based on multi-agent reinforcement learning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep one-class classifier for network anomaly detection using autoencoders and one-class support vector machines. <em>FCOMP</em>, <em>7</em>, 1646679. (<a href='https://doi.org/10.3389/fcomp.2025.1646679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe integration of deep learning models into Network Intrusion Detection Systems (NIDS) has shown promising advancements in distinguishing normal network traffic from cyber-attacks due to their capability to learn complex non-linear patterns. These approaches typically rely on both benign and malicious network traffic during training. However, in many organizations, collecting malicious traffic is challenging due to privacy restrictions, high costs of manual labeling, and requirement for advanced security expertise.MethodsIn this study, we introduce a deep one-class classification model that is trained exclusively on flow-based benign network traffic data, with the goal of identifying attacks during inference. The proposed anomaly detection model consists of two steps, a One-Class Support Vector Machine (OC-SVM) and a deep AutoEncoder (AE). While autoencoders have shown great potential in anomaly detection, their effectiveness can be undermined by spurious network activity located on the boundaries of their discriminating capabilities, thus failing to identify malicious behavior. Our model leverages the topological structure of the OC-SVM to generate decision scores for each traffic flow, which are subsequently incorporated into an autoencoder as part of the input feature space.ResultsThis approach enhances the ability of the autoencoder to detect incidents that deviate from normal patterns. Furthermore, we propose a heuristic method for tuning the trade-off parameter of the OC-SVM, based only on one-class data, achieving comparable performance to grid-based methods that require both benign and malicious labeled data. Experimental results on a benchmark network intrusion data set, the UNSW-NB15, suggest that OCSVM-AE performs well on unseen attacks and is more effective than traditional and deep-learning based one-class classifiers.DiscussionThe method makes no specific assumptions about the data distribution, making it broadly applicable and suitable as a complementary tool to signature-based intrusion detection systems.},
  archive      = {J_FCOMP},
  author       = {Bountzis, Polyzois and Kavallieros, Dimitris and Tsikrika, Theodora and Vrochidis, Stefanos and Kompatsiaris, Ioannis},
  doi          = {10.3389/fcomp.2025.1646679},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1646679},
  shortjournal = {Front. Comput. Sci.},
  title        = {A deep one-class classifier for network anomaly detection using autoencoders and one-class support vector machines},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discomfort detection during automated driving using temporal transformers. <em>FCOMP</em>, <em>7</em>, 1639505. (<a href='https://doi.org/10.3389/fcomp.2025.1639505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionWith the recent breakthroughs in driving automation and the development of smart vehicles, human-technology interaction issues, such as detecting comfort levels in automated driving, have been gaining increasing attention. Given the evidence of discomfort levels being an evolving psychological state in time, the tracking of discomfort levels for passengers of an automated vehicle can be considered a time-varying phenomenon.MethodsWe assessed a passenger's discomfort level in a smart, automated vehicle using physiological, environmental, and vehicle automation features from different sensors. Our approach is to dynamically predict discomfort levels using time-dependent models, particularly the Temporal Fusion Transformer (TFT), an advanced attention-based deep learning architecture providing an interpretable explanation of temporal dynamics as well as high-performance forecasting over multiple horizons. The models are trained and evaluated using a dataset of 100 participants of a simulated automated driving experiment, during which they signaled their level of discomfort using a manual device. Two TFT models, TFT-full and TFT-restricted, are investigated depending on which physiological, environmental, and vehicle automation signals are used as inputs. The results are compared with the auto-regressive model DeepAR. Different window sizes are used to analyze the impact of the window size on the model's performance.ResultsAmong the tested models, TFT-restricted with a window size of 300-time steps (about 5 s) demonstrates the best performance in predicting discomfort levels on our data, with a mean absolute error (MAE) of 0.037 and a root mean square error (RMSE) of 0.131.DiscussionIn our study, TFT-restricted outperformed TFT-full and the autoregressive model DeepAR in discomfort prediction, delivering superior results for all metrics. Finally, our study shows that the TFT can capture temporal dependencies in the data and help us interpret the model for detecting discomfort, which is essential for analyzing and improving people's acceptance of automated vehicles.},
  archive      = {J_FCOMP},
  author       = {Assarzadeh, Maha and Hartwich, Franziska and Vitay, Julien and Bocklisch, Franziska and Hamker, Fred H.},
  doi          = {10.3389/fcomp.2025.1639505},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1639505},
  shortjournal = {Front. Comput. Sci.},
  title        = {Discomfort detection during automated driving using temporal transformers},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the role of instructor gestures during virtual lectures. <em>FCOMP</em>, <em>7</em>, 1615791. (<a href='https://doi.org/10.3389/fcomp.2025.1615791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this study was to establish the importance of instructor gestures in online lectures. Social information processing theory explains that virtual communication can be just as effective as face-to-face communication if communicators understand how to adapt their communication to the virtual channel. This study seeks to better understand the roles of camera distance and gestures in adapting lectures to virtual classrooms. An experiment examined the impact of student gender, camera distance from the instructor, and gesture use on instructor credibility, as measured by caring, competence, and trustworthiness. The results indicate that while camera distance did not impact students’ perceptions of instructor competence, the absence of gestures did impact how trustworthy and caring male students perceived the instructor to be. In the absence of gestures, male students perceived the instructor to be less caring and trustworthy. This indicates that instructors should make efforts to speak with gestures in virtual lectures, especially for male students, just as they do in the traditional classroom.},
  archive      = {J_FCOMP},
  author       = {Kelly, Stephanie and Kim, Jihyun and Chaudhary, Pankaj},
  doi          = {10.3389/fcomp.2025.1615791},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1615791},
  shortjournal = {Front. Comput. Sci.},
  title        = {Understanding the role of instructor gestures during virtual lectures},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Component features based enhanced phishing website detection system using EfficientNet, FH-BERT, and SELU-CRNN methods. <em>FCOMP</em>, <em>7</em>, 1582206. (<a href='https://doi.org/10.3389/fcomp.2025.1582206'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionPhishing is a type of cybercrime used by hackers to steal sensitive user information, making it essential to detect phishing attacks on websites. Many prevailing works have utilized Uniform Resource Locator (URL) links and Document Object Model (DOM) tree structures for Phishing Website Detection (PWD). However, since phishing websites imitate legitimate websites, these approaches often produce inaccurate detection results.MethodsTo enhance detection efficiency, we propose a PWD system that focuses on important website features and components. The process begins with collecting URL links from phishing website datasets, followed by the generation of Hypertext Markup Language (HTML) formats. A DOM tree structure is then constructed from the HTML, and components are extracted along with Natural Language Processing (NLP) features, credentials, URL, DOM tree similarity, and component features. The DOM-tree components are converted into score values using Feature Hasher-Bidirectional Encoder Representations from Transformers (FH-BERT). These score values are fused with component features, and significant features are selected using an Entropy-based Chameleon Swarm Algorithm (ECSA).ResultsThe final classification is performed by Scaled Exponential Linear Unit Convolutional Recurrent Neural Network (SELU-CRNN). Simulation results demonstrate that the proposed technique improves PWD performance, achieving higher accuracy (98.42%) and reduced training time (63,003 ms) compared to prevailing methods.DiscussionBy integrating component, semantic, and structural features, the proposed model enhances both robustness and efficiency, making it an effective solution for phishing website detection.},
  archive      = {J_FCOMP},
  author       = {Murhej, Mahmoud and Nallasivan, G.},
  doi          = {10.3389/fcomp.2025.1582206},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1582206},
  shortjournal = {Front. Comput. Sci.},
  title        = {Component features based enhanced phishing website detection system using EfficientNet, FH-BERT, and SELU-CRNN methods},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling the dynamics of misinformation spread: A multi-scenario analysis incorporating user awareness and generative AI impact. <em>FCOMP</em>, <em>7</em>, 1570085. (<a href='https://doi.org/10.3389/fcomp.2025.1570085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of misinformation on social media threatens public trust, public health, and democratic processes. We propose three models that analyze fake news propagation and evaluate intervention strategies. Grounded in epidemiological dynamics, the models include: (1) a baseline Awareness Spread Model (ASM), (2) an Extended Model with fact-checking (EM), and (3) a Generative AI-Influenced Spread model (GIFS). Each incorporates user behavior, platform-specific dynamics, and cognitive biases such as confirmation bias and emotional contagion. We simulate six distinct scenarios: (1) Accurate Content Environment, (2) Peer Network Dynamics, (3) Emotional Engagement, (4) Belief Alignment, (5) Source Trust, and (6) Platform Intervention. All models converge to a single, stable equilibrium. Sensitivity analysis across key parameters confirms model robustness and generalizability. In the ASM, forwarding rates were lowest in scenarios 1, 4, and 6 (1.47%, 3.41%, 2.95%) and significantly higher in 2, 3, and 5 (19.67%, 56.52%, 29.47%). The EM showed that fact-checking reduced spread to as low as 0.73%, with scenario-based variation from 1.16 to 17.47%. The GIFS model revealed that generative AI amplified spread by 5.7%–37.8%, depending on context. ASM highlights the importance of awareness; EM demonstrates the effectiveness of fact-checking mechanisms; GIFS underscores the amplifying impact of generative AI tools. Early intervention, coupled with targeted platform moderation (scenarios 1, 4, 6), consistently yields the lowest misinformation spread, while emotionally resonant content (scenario 3) consistently drives the highest propagation.},
  archive      = {J_FCOMP},
  author       = {Jain, Kurunandan and Achuthan, Krishnashree},
  doi          = {10.3389/fcomp.2025.1570085},
  journal      = {Frontiers in Computer Science},
  month        = {10},
  pages        = {1570085},
  shortjournal = {Front. Comput. Sci.},
  title        = {Modeling the dynamics of misinformation spread: A multi-scenario analysis incorporating user awareness and generative AI impact},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="fcteg">FCTEG - 1</h2>
<ul>
<li><details>
<summary>
(2025). Conflict-based model predictive control for multi-agent path finding experimentally validated on a magnetic planar drive system. <em>FCTEG</em>, <em>6</em>, 1645918. (<a href='https://doi.org/10.3389/fcteg.2025.1645918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis work presents an approach to collision avoidance in multi-agent systems (MAS) by integrating Conflict-Based Search (CBS) with Model Predictive Control (MPC), referred to as Conflict-Based Model Predictive Control (CB-MPC).MethodsThe proposed method leverages the conflict-avoidance strengths of CBS to generate collision-free paths, which are then refined into dynamic reference trajectories using a minimum jerk trajectory optimizer and then used inside a MPC to follow the trajectories and to avoid collisions. This integration ensures real-time trajectory execution, preventing collisions and adapting to online changes. The approach is evaluated using a magnetic planar drive system for realistic multi-agent scenarios, demonstrating enhanced real-time responsiveness and adaptability. The focus is on the development of a motion planning algorithm and its validation in dynamic environments, which are becoming increasingly relevant in modern adaptive production sites.ResultsOn the MAS demonstrator with four active agents, ten different scenarios were created with varying degrees of complexity in terms of route planning. In addition, external disturbances that hinder the execution of the paths were simulated. All calculation and solution times were recorded and discussed. The result show that all scenarios could be successfully solved and executed., and the CB-MPC is therefore suitable for motion planning on the presented MAS demonstrator.DiscussionThe results show, that the CB-MPC is suitable for motion planning on the presented MAS demonstrator. The greatest limitation of the approach lies in scalability with regard to increasing the number of agents.},
  archive      = {J_FCTEG},
  author       = {Janning, Kai and Housin, Abdalsalam and Schulte, Christopher and Erkens, Frederik and Frenken, Luca and Herbst, Laura and Nießing, Bastian and Schmitt, Robert H.},
  doi          = {10.3389/fcteg.2025.1645918},
  journal      = {Frontiers in Control Engineering},
  month        = {7},
  pages        = {1645918},
  shortjournal = {Front. Control Eng.},
  title        = {Conflict-based model predictive control for multi-agent path finding experimentally validated on a magnetic planar drive system},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="fdata">FDATA - 1</h2>
<ul>
<li><details>
<summary>
(2025). Editorial: Navigating the nexus of big data, AI, and public health: Transformations, triumphs, and trials in multiple sclerosis care access. <em>FDATA</em>, <em>8</em>, 1682151. (<a href='https://doi.org/10.3389/fdata.2025.1682151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {[Joshi] provides a critical examination of how big data and AI technologies can both advance and hinder gender equality in healthcare access and treatment. This perspective article addresses one of the most pressing ethical challenges in contemporary healthcare technology: bias is a big challenge when implementing AI systems in medical settings, particularly relevant for conditions like Multiple Sclerosis, where gender disparities in diagnosis and treatment access are well-documented.The contribution by [Joshi] highlights three critical categories where machine learning can facilitate accessible, affordable, personalized, and evidence-based healthcare for women, while simultaneously addressing the algorithmic bias that threatens to undermine these advances. This work exemplifies the critical need for intersectional approaches to healthcare AI development that consider both the transformative potential and the ethical implications of these technologies in specialized treatment contexts such as neurological care.[Chen et al.] contribute valuable insights into the practical challenges of leveraging social media data for public health research and healthcare accessibility analysis. Social media has profoundly changed our modes of self-expression, communication, and participation in public discourse, generating volumes of conversations and content that cover every aspect of our social lives. Their research addresses the critical gap between the theoretical potential of social media analytics and the practical hurdles researchers face in accessing and utilizing these data sources for understanding patient experiences and healthcare navigation challenges.The work by [Chen et al.] is particularly relevant for understanding patient perspectives on healthcare accessibility, treatment barriers, and health-seeking behaviors-essential components for developing comprehensive models of healthcare access, such as those needed for MS treatment planning as an example of the United Arab Emirates. Social media platforms provide unprecedented access to real-time patient sentiment, treatment experiences, and geographic variation in healthcare access that can inform policy and practice improvements.The fourth contribution explores advanced techniques in knowledge-based recommendation systems, with direct relevance to clinical decision support and personalized treatment recommendations for complex conditions like Multiple Sclerosis. This research demonstrates how sophisticated recommendation algorithms can be applied to support clinical decisionmaking in specialized care contexts, patient education about treatment options, and healthcare resource allocation-all critical components for ensuring equitable access to Disease-Modifying Therapies.The integration of knowledge-based systems with machine learning approaches represents a significant advancement in creating transparent, including clinically interpretable, explainable AI tools for specialized healthcare settings. This work addresses the crucial challenge of AI interpretability in neurological care contexts, where understanding the rationale behind treatment recommendations is essential for both clinical acceptance and patient adherence to complex therapeutic regimens.When handling private health information, strong protections are needed to prevent breaches and unauthorized use. Across all four articles, several critical themes emerge that are directly applicable to addressing geographic and socioeconomic disparities in specialized healthcare access, particularly relevant for conditions requiring ongoing Disease-Modifying Therapy.The methodological approaches demonstrated across these studies provide frameworks for mapping healthcare accessibility patterns.[Santos et al.]'s geographic analysis of educational access barriers during the pandemic offers direct parallels to understanding how distance, infrastructure, and socioeconomic factors create barriers to specialized medical care in diverse geographic regions, including accessibility heatmaps or location allocation models, which are used in health system planning to reduce spatial inequality Algorithmic Bias and Treatment Equity: [Joshi]'s examination of gender bias in healthcare AI systems highlights challenges that extend to all aspects of specialized care delivery. The research demonstrates how historical inequities in healthcare access can be embedded in algorithmic systems used for treatment allocation, facility planning, diverse training data and patient risk stratification-directly relevant to ensuring equitable DMT access across different populations.The integration of quantitative analytics with qualitative patient experience data, demonstrated by [Santos et al.] and supported by [Chen et al.]'s social media analysis framework, provides essential methodological guidance for comprehensive healthcare accessibility studies that combine geospatial analysis with patient journey mapping.The research presented in this collection moves beyond theoretical accessibility models to address practical implementation challenges in healthcare delivery. [Chen et al.]'s analysis of data collection hurdles provides essential guidance for researchers conducting patient experience studies, while [Santos et al.]'s socioeconomic analysis offers actionable insights for policymakers addressing geographic healthcare disparities.These studies demonstrate that successful implementation of equitable healthcare access requires not only advanced analytical capabilities but also careful attention to privacy protection, stakeholder engagement, and systematic approaches to addressing the social determinants that influence treatment access and adherence patterns.Policymakers can use Big Data to subsequently review the social factors, among others, behind these health disparities. The collective insights from these four articles point toward several critical areas for future research in healthcare accessibility, with direct applications to specialized treatment access challenges.The development of comprehensive accessibility indices that integrate geographic, socioeconomic, and system-level factors becomes increasingly crucial for conditions requiring complex, ongoing treatment regimens. The methodological frameworks demonstrated in this collection provide essential building blocks for creating predictive models that can identify patients at risk of treatment discontinuation and guide targeted intervention strategies.Furthermore, the research highlights the importance of real-time monitoring systems that can track accessibility patterns and identify emerging barriers to care. The integration of social media analytics, demonstrated by [Chen et al.], with geospatial analysis approaches offers promising directions for developing systems that monitor healthcare accessibility in real time.},
  archive      = {J_FDATA},
  author       = {Moonesar, Immanuel Azaad and Kumar, M. V. Manoj and Alsayegh, Khulood and Abu-Agla, Ayat and Thomas, Likewin},
  doi          = {10.3389/fdata.2025.1682151},
  journal      = {Frontiers in Big Data},
  month        = {10},
  pages        = {1682151},
  shortjournal = {Front. Big Data},
  title        = {Editorial: Navigating the nexus of big data, AI, and public health: Transformations, triumphs, and trials in multiple sclerosis care access},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="frai">FRAI - 6</h2>
<ul>
<li><details>
<summary>
(2025). Editorial: Methodology for emotion-aware education based on artificial intelligence. <em>FRAI</em>, <em>8</em>, 1704389. (<a href='https://doi.org/10.3389/frai.2025.1704389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, advances in Artificial Intelligence (AI) have opened up unprecedented horizons in educational research. The ability to recognize, interpret and respond to students' emotions presents education with a crucial challenge: to design methodologies that integrate the affective dimension as a fundamental part of the learning process. With this objective in mind, the research topic "Methodology for Emotion-Aware Education Based on Artificial Intelligence" was born. Its purpose was to bring together work that explores theoretical approaches, technological applications and empirical evidence on Educational AI linked to emotions, bridging affective computing, pedagogy, and human–computer interaction to foster more responsive and ethical emotion-aware learning environments. This research topic offers a pluralistic overview, both in terms of methods and contexts, which allows for reflection on the advances and challenges that arise when introducing AI systems capable of detecting and responding to emotional states in the educational field. The contributions range from the analysis of the social impact of scientific production to the application of deep learning models, the integration of pedagogical beliefs in the adoption of generative technologies, and the design of innovative sentiment analysis models. They also highlight ethical, methodological, and practical challenges in the field. In particular, Ni and Ni (2024) presents ECO-SAM, an innovative sentiment analysis model that combines self-attention techniques with pre-trained neural networks to improve emotion classification in texts with notable increases in accuracy. Its educational relevance lies in the potential of text analysis systems to interpret interactions on learning platforms, forums, and student social networks. The study also opens possibilities for transferring these techniques to the analysis of written work in school environments, enriching formative assessment and identifying emotional patterns in students' academic and personal writing. From another perspective, Govea et al. (2024) apply deep reinforcement learning models in hybrid learning environments, developing a system capable of detecting emotions in real time by integrating convolutional and recurrent networks. Using data from 500 students collected through cameras, microphones and biometric sensors, the authors show significant improvements in emotional detection accuracy and learning personalization. This work invites us to rethink hybrid environments as spaces where AI supports cognition and, at the same time, responds to the emotional dimension. However, it also highlights the urgent need to establish regulatory and pedagogical frameworks, so that the pursuit of efficiency does not compromise the privacy and emotional well-being of students. Cabero-Almenara et al. (2024) focuses on a decisive aspect: teacher acceptance of AI in higher education. The study, involving 425 university professors, uses the UTAUT2 model to analyze how pedagogical beliefs shape willingness to integrate generative AI tools. The results show that teachers with a constructivist orientation are more willing to incorporate these technologies than those with transmissive approaches. This emphasizes that the adoption of AI does not depend solely on technical availability, but also on the pedagogical concepts that guide teaching practice. This conclusion highlights the need for professional training programs that address the diversity of beliefs and contexts. In this sense, we see that the future of AI in education will not be played out solely in laboratories, but also in the ability of institutions to support their teachers in processes of pedagogical reflection and continuous professional development. Zhou et al. (2024) provide a novel approach by applying Item Response Theory (IRT) from a student state-aware perspective. Their SAD-IRT model incorporates parameters derived from facial expression analysis using advanced deep learning techniques, which allows for the estimation of item ability and difficulty, as well as an additional parameter linked to the cognitive-affective state of the students. The study demonstrates that this approach improves predictive capacity compared to traditional IRT models and even allows responses to be anticipated before they occur. Beyond its technical value, the article proposes a paradigm shift in educational assessment: considering students' emotions and states as part of the measurement, moving towards more personalized, sensitive and useful assessment systems to guide teaching and learning. Finally, Roda-Segarra et al. (2024) offers a pioneering study that goes beyond traditional bibliometric indicators, by examining more than 6,000 social impact records across 243 publications. They reveal that research on AI and emotions in education has a considerable impact on social media and scientific repositories, although academic impact and social visibility do not always align. This finding prompts reflection on how research reaches communities, and how social networks shape knowledge circulation. In addition, the study opens the door to reflection on the role of scientific communication in building trust around the use of AI in education, an essential aspect for building a balanced dialogue between innovation, society and schools. As we can see, the articles gathered in this research topic show that AI-mediated emotion-aware education is not a distant goal, but a field in full swing. From a social perspective, research still faces the challenge of extending its impact beyond the academic sphere and ensuring a true transfer to educational communities. From a pedagogical perspective, it is clear that teachers' beliefs influence the adoption of AI, which requires the design of training processes that are sensitive to this diversity. Finally, from a technological perspective, advanced models of deep learning and sentiment analysis open up unprecedented possibilities for creating adaptive environments capable of addressing both student performance and emotional well-being. The research published in this research topic shows that the combination of pedagogy, AI and emotion-awareness can transform the way we conceive of teaching and learning in the 21st century. The path ahead is not without ethical and practical challenges. Issues such as privacy, transparency, and fairness in personalization processes must be non-negotiable principles when using AI in an educational context. The results presented here show that this is possible, but at the same time, they reveal that there is still a long way to go in terms of academic research.},
  archive      = {J_FRAI},
  author       = {Roig-Vila, Rosabel and Cazorla, Miguel and Lallé, Sébastien},
  doi          = {10.3389/frai.2025.1704389},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1704389},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Methodology for emotion-aware education based on artificial intelligence},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phase-specific kidney graft failure prediction with machine learning model. <em>FRAI</em>, <em>8</em>, 1682639. (<a href='https://doi.org/10.3389/frai.2025.1682639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundAccurate prediction of kidney graft failure at different phases post-transplantation is critical for timely intervention and long-term allograft preservation. Traditional survival models offer limited capacity for dynamic, time-specific risk estimation. Machine learning (ML) approaches, with their ability to model complex patterns, present a promising alternative.MethodsThis study developed and dynamically evaluated phase-specific ML models to predict kidney graft failure across five post-transplant intervals: 0–3 months, 3–9 months, 9–15 months, 15–39 months, and 39–72 months. Clinically relevant retrospective data from deceased donor kidney transplant recipients were used for training and internal validation, with performance further confirmed on a blinded external validation cohort. Predictive performance was assessed using ROC AUC, F1 score, and G-mean.ResultsThe ML models demonstrated varying performance across time intervals. Short-term predictions in the 0–3 month and 3–9 month intervals yielded moderate accuracy (ROC AUC = 0.73 ± 0.07 and 0.72 ± 0.04, respectively). The highest predictive accuracy observed in mid-term or the 9–15-month window (ROC AUC = 0.92 ± 0.02; F1 score = 0.85 ± 0.03), followed by the 15–39-month period (ROC AUC = 0.84 ± 0.04; F1 score = 0.76 ± 0.04). Long-term prediction from 39 to 72 months was more challenging (ROC AUC = 0.70 ± 0.07; F1 score = 0.65 ± 0.06).ConclusionPhase-specific ML models offer robust predictive performance for kidney graft failure, particularly in mid-term periods, supporting their integration into dynamic post-transplant surveillance strategies. These models can aid clinicians in identifying high-risk patients and tailoring follow-up protocols to optimize long-term transplant outcomes.},
  archive      = {J_FRAI},
  author       = {Salybekov, Amankeldi A. and Wolfien, Markus and Yerkos, Ainur and Buribayev, Zholdas and Hidaka, Sumi and Kobayashi, Shuzo},
  doi          = {10.3389/frai.2025.1682639},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1682639},
  shortjournal = {Front. Artif. Intell.},
  title        = {Phase-specific kidney graft failure prediction with machine learning model},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Big data in financial risk management: Evidence, advances, and open questions: A systematic review. <em>FRAI</em>, <em>8</em>, 1658375. (<a href='https://doi.org/10.3389/frai.2025.1658375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe intersection of big data analytics and financial risk management has spurred significant methodological innovation and organizational change. Despite growing research activity, the literature remains fragmented, with notable gaps in comparative effectiveness, cross-sectoral applicability, and the use of non-traditional data sources.MethodsFollowing the PRISMA 2020 protocol, a systematic review was conducted on 21 peer-reviewed studies published between 2016 and June 2025. The review evaluated the methodological diversity and effectiveness of machine learning and hybrid approaches in financial risk management.ResultsThe analysis mapped the relative strengths and limitations of neural networks, ensemble learning, fuzzy logic, and hybrid optimization across credit, fraud, systemic, and operational risk. Advanced machine learning techniques consistently demonstrated strong predictive accuracy, yet real-world deployment remained geographically concentrated, primarily in Chinese and European banking and fintech sectors. Applications involving alternative and unstructured data, such as IoT signals and behavioral analytics, were largely experimental and faced both technical and governance challenges.Discussion/conclusionThe findings underscore the scarcity of systematic benchmarking across risk types and organizational contexts, as well as the limited attention to explainability in current implementations. This review identifies an urgent need for comparative, cross-jurisdictional studies, stronger field validation, and open science practices to bridge the gap between technical advances and their operational impact in big data–enabled financial risk management.},
  archive      = {J_FRAI},
  author       = {Theodorakopoulos, Leonidas and Theodoropoulou, Alexandra and Bakalis, Aristeidis},
  doi          = {10.3389/frai.2025.1658375},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1658375},
  shortjournal = {Front. Artif. Intell.},
  title        = {Big data in financial risk management: Evidence, advances, and open questions: A systematic review},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chimera: A block-based neural architecture search framework for event-based object detection. <em>FRAI</em>, <em>8</em>, 1644889. (<a href='https://doi.org/10.3389/frai.2025.1644889'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event-based cameras are sensors inspired by the human eye, offering advantages such as high-speed robustness and low power consumption. Established deep learning techniques have proven effective in processing event data, but there remains a significant space of possibilities that could be further explored to maximize the potential of such combinations. In this context, Chimera is a Block-Based Neural Architecture Search (NAS) framework specifically designed for Event-Based Object Detection, aiming to systematically adapt RGB-domain processing methods to the event domain. The Chimera design space is constructed from various macroblocks, including attention blocks, convolutions, State Space Models, and MLP-mixer-based architectures, providing a valuable trade-off between local and global processing capabilities, as well as varying levels of complexity. Results on Prophesee's GEN1 dataset demonstrated state-of-the-art mean Average Precision (mAP) while reducing the number of parameters by 1.6 × and achieving a 2.1 × speed-up. The project is available at: https://github.com/silvada95/Chimera.},
  archive      = {J_FRAI},
  author       = {Silva, Diego A. and Elsheikh, Ahmed and Smagulova, Kamilya and Fouda, Mohammed E. and Eltawil, Ahmed M.},
  doi          = {10.3389/frai.2025.1644889},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1644889},
  shortjournal = {Front. Artif. Intell.},
  title        = {Chimera: A block-based neural architecture search framework for event-based object detection},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The perceived impact of artificial intelligence on academic learning. <em>FRAI</em>, <em>8</em>, 1611183. (<a href='https://doi.org/10.3389/frai.2025.1611183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative artificial intelligence, such as ChatGPT, is transforming higher education by enabling personalized learning, while raising ethical challenges. This study explores how technical university students perceive and leverage ChatGPT in academic tasks, focusing on motivation, learning outcomes, and ethical awareness. Using the Technology Acceptance Model and Self-Determination Theory, the research surveyed 84 students from a technical university via a 5-point Likert-scale questionnaire. Six salient dimensions of student engagement with ChatGPT emerged: perceived usefulness for problem solving, learning retention and skill acquisition, structured interaction with familiar content, consultation on unfamiliar topics, preference for conciseness, and confidence in the accuracy of AI responses. Students who perceived ChatGPT as a valuable resource for addressing academic problems reported enhanced motivation and competence, and frequent structured interaction was linked to the practice of verifying uncertain information, indicating the emergence of AI literacy. However, extensive reliance was correlated with dependence and limited citation practices, revealing risks to academic integrity. By examining ChatGPT’s role in STEM education, this study substantiates the relevance of AI literacy training and institutional policies to ensure responsible use. The findings offer practical insights for educators to integrate AI tools effectively while fostering critical thinking and academic integrity in technology-driven learning environments.},
  archive      = {J_FRAI},
  author       = {Dogaru, Mariana and Pisică, Olivia and Popa, Cosmin-Ștefan and Răgman, Andrei-Adrian and Tololoi, Ilinca-Roxana},
  doi          = {10.3389/frai.2025.1611183},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1611183},
  shortjournal = {Front. Artif. Intell.},
  title        = {The perceived impact of artificial intelligence on academic learning},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heart rates, facial expressions and self-reports: A multimodal longitudinal approach of learners' emotions in the foreign language classroom. <em>FRAI</em>, <em>8</em>, 1604110. (<a href='https://doi.org/10.3389/frai.2025.1604110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotions in educational settings are often studied through self-reports or lab experiments, limiting insights into their real-world dynamics. This study examines learner emotions in authentic foreign language classrooms using a multimodal longitudinal approach. Over 16 consecutive sessions, we collected heart rate (HR) signals, emotional facial expressions (EFE), classroom observations, and self-reports on enjoyment, anxiety, and boredom to capture both physiological and self-perceived emotional responses. Rather than aggregating data across students, we focused on individualized emotional patterns to understand variations in emotional experiences. Each dataset included extensive video recordings, continuous HR monitoring, detailed observational notes, and post-session questionnaires, providing a high-resolution picture of emotional dynamics. Using unsupervised clustering techniques, we identified key emotional episodes—peaks and drops in physiological arousal (heart rate variation) and facial expression—relative to individual emotional baselines. These moments were cross-referenced with classroom observations and self-reports for validation. Findings highlight moments of positive emotional contagion during peer interactions, emphasizing the social dimension of language learning. This multimodal approach captures the interplay of physiological, behavioral, and subjective responses, offering a scalable method for studying classroom emotions. Methodologically, it demonstrates how multimodal analytics can uncover transient emotional states in real-world settings, while practically informing adaptive teaching strategies, such as leveraging peer interactions to enhance engagement or reduce anxiety. By integrating physiological, behavioral, and subjective data, this study provides a comprehensive framework for understanding the affective dimensions of learning.},
  archive      = {J_FRAI},
  author       = {Guedat-Bittighoffer, Delphine and Moufidi, Abderrazzaq and Dewaele, Jean-Marc and Rousseau, David and Voyneau, Hugo and Rasti, Pejman},
  doi          = {10.3389/frai.2025.1604110},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1604110},
  shortjournal = {Front. Artif. Intell.},
  title        = {Heart rates, facial expressions and self-reports: A multimodal longitudinal approach of learners' emotions in the foreign language classroom},
  volume       = {8},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="frobt">FROBT - 2</h2>
<ul>
<li><details>
<summary>
(2025). Designing socially assistive robots for clinical practice: Insights from an asynchronous remote community of speech-language pathologists. <em>FROBT</em>, <em>12</em>, 1646880. (<a href='https://doi.org/10.3389/frobt.2025.1646880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionSocially Assistive Robots (SARs) hold promise for augmenting speech-language therapy by addressing high caseloads and enhancing child engagement. However, many implementations remain misaligned with clinician practices and overlook expressive strategies central to speech-language pathology.MethodsWe conducted a 4-week Asynchronous Remote Community (ARC) study with thirteen licensed speech-language pathologists (SLPs). Participants engaged in weekly activities and asynchronous discussions, contributing reflective insights on emotional expression, domain-specific needs, and potential roles for SARs. The ARC format supported distributed, flexible engagement and facilitated iterative co-design through longitudinal peer dialogue. Data were analyzed using thematic analysis to identify emerging patterns.ResultsAnalysis revealed five clinician-driven design considerations for SARs: (1) the need for expressive and multi-modal communication; (2) customization of behaviors to accommodate sensory and developmental profiles; (3) adaptability of roles across therapy contexts; (4) ethical concerns surrounding overuse and fears of clinician replacement; and (5) opportunities for data tracking and personalization.DiscussionFindings highlight clinician-informed design implications that can guide the development of socially intelligent, adaptable, and ethically grounded SARs. The ARC approach proved a viable co-design framework, enabling deeper reflection and peer-driven requirements than traditional short-term methods. This work bridges the gap between robotic capabilities and clinical expectations, underscoring the importance of embedding clinician expertise in SAR design to foster meaningful integration into speech-language interventions.},
  archive      = {J_FROBT},
  author       = {Oliva, Denielle and Olszewski, Abbie and Sadeghi, Shekoufeh and Dantu, Karthik and Feil-Seifer, David},
  doi          = {10.3389/frobt.2025.1646880},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1646880},
  shortjournal = {Front. Robot. AI},
  title        = {Designing socially assistive robots for clinical practice: Insights from an asynchronous remote community of speech-language pathologists},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An approach for unsupervised interaction clustering in human–robot co-work using spatiotemporal graph convolutional networks. <em>FROBT</em>, <em>12</em>, 1545712. (<a href='https://doi.org/10.3389/frobt.2025.1545712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an approach to cluster interaction forms in industrial human–robot co-work using spatiotemporal graph convolutional networks (STGCNs). Humans will increasingly work with robots in the future, whereas previously, humans worked side by side, hand in hand, or alone. The growing frequency of robotic and human–robot co-working applications and the requirement to increase flexibility affect the variety and variability of interactions between humans and robots, which can be observed at production workplaces. In this paper, we investigate the variety and variability of human–robot interactions in industrial co-work scenarios where full automation is impractical. To address the challenges of interaction modeling and clustering, we present an approach that utilizes STGCNs for interaction clustering. Data were collected from 12 realistic human–robot co-work scenarios using a high-accuracy tracking system. The approach identified 10 distinct interaction forms, revealing more granular interaction patterns than established taxonomies. These results support continuous, data-driven analysis of human–robot behavior and contribute to the development of more flexible, human-centered systems that are aligned with Industry 5.0.},
  archive      = {J_FROBT},
  author       = {Heuermann, Aaron and Ghrairi, Zied and Zitnikov, Anton and Al Noman, Abdullah and Thoben, Klaus-Dieter},
  doi          = {10.3389/frobt.2025.1545712},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1545712},
  shortjournal = {Front. Robot. AI},
  title        = {An approach for unsupervised interaction clustering in human–robot co-work using spatiotemporal graph convolutional networks},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
