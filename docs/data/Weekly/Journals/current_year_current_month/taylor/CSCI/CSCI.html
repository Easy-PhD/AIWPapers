<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CSCI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="csci">CSCI - 34</h2>
<ul>
<li><details>
<summary>
(2025). Hybrid CNN XGBoost intrusion detection approach tuned by modified sine cosine algorithm towards better cloud security. <em>CSCI</em>, <em>37</em>(1), Article: 2549581. (<a href='https://doi.org/10.1080/09540091.2025.2549581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing (CC) delivers processing power and data storage on demand. It is one of the most significant computer science technologies, contributing to healthcare, industry, and the Internet of Things. One of CC's biggest security concerns are intrusion detection and separating harmful from legitimate communication, similar to computer networks. Although a wide range of intrusion detection systems is available today, they often suffer from misclassification issues, where the system can fail to recognize an attack as a threat or to mark normal traffic as malicious. This research proposes classifying network traffic using a convolutional neural network and extreme gradient boosting model. Additionally, a modified sine cosine algorithm is used to tune model hyperparameters for optimal performance. The presented framework was tested on major real-world TON IoT intrusion detection datasets. The proposed optimizer is compared to many recent metaheuristics in a matched experimental setting. The simulation results show that the suggested technique is superior to other methods for both datasets, with the best-performing optimized models achieving an accuracy of 96.667 on Windows 10 and 98.6731 on Windows 7 simulation.},
  archive      = {J_CSCI},
  author       = {Nikola Savanovic and Aleksandra Bozovic and Milos Antonijevic and Goran Kvascev and Bosko Nikolic and K. Venkatachalam and Nebojsa Bacanin and Miodrag Zivkovic},
  doi          = {10.1080/09540091.2025.2549581},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2549581},
  shortjournal = {Connect. Sci.},
  title        = {Hybrid CNN XGBoost intrusion detection approach tuned by modified sine cosine algorithm towards better cloud security},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A homotopy-CNN framework for continuous deformation in low-light image enhancement. <em>CSCI</em>, <em>37</em>(1), Article: 2546911. (<a href='https://doi.org/10.1080/09540091.2025.2546911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a homotopy-guided image enhancement framework for Low-Light Image Enhancement (LLIE), where a low-light image is progressively transformed into a well-lit version using a parametric deformation model. The enhancement pipeline incorporates a convolutional neural network that predicts structure-aware filtering parameters, which are applied via a 12-directional convolution kernel fusion, followed by adaptive gamma, contrast, and saturation refinements. Instead of relying solely on reference-free or black-box learning, the model leverages perceptual quality metrics such as SSIM and PSNR during training to optimise enhancement along the homotopy path. Notably, we explore the modulation of brightness across the range b ∈ [ − 2.0 , 2.0 ] , observing that b ≤ 0 yields outputs closer to ground-truth references, while b ≥ 0 enhances perceptual vividness. Experiments on the LOL dataset show that the method produces superior visual quality and strong quantitative performance, all while remaining efficient on standard CPUs without the need for GPU acceleration.},
  archive      = {J_CSCI},
  author       = {S. Shivam Kumar Jha and N. Mohana},
  doi          = {10.1080/09540091.2025.2546911},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2546911},
  shortjournal = {Connect. Sci.},
  title        = {A homotopy-CNN framework for continuous deformation in low-light image enhancement},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-constraints active learning assisted deep-ensemble spatio-textural feature learning model for violence detection in surveillance dataset. <em>CSCI</em>, <em>37</em>(1), Article: 2544539. (<a href='https://doi.org/10.1080/09540091.2025.2544539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Vi-mCALNET, a multi-constraint active learning-assisted deep-ensemble spatio-textural feature learning model for violence detection in surveillance videos. Unlike traditional approaches, Vi-mCALNET integrates active learning-driven frame selection with deep ensemble learning to enhance classification accuracy while reducing computational complexity. Traditional deep learning vision models for violent crime detection face limitations including inability to use contextual details, long-term dependency issues, gradient vanishing, and accuracy degradation. Vi-mCALNET addresses these challenges through a comprehensive approach. The model employs GLCM, ResNet101, and DenseNet121 for feature extraction, followed by a heterogeneous ensemble classifier comprising SVM, DT, k-NN, NB, and RF. Extracted features are fused into a composite feature vector, processed through PCA and z-score normalization to prevent local minima, convergence issues, and overfitting.The heterogeneous ensemble classifier uses maximum voting to classify videos as violent or non-violent. Vi-mCALNET achieved superior performance with 99.51% accuracy, 99.32% precision, 99.36% recall, and 0.994 F-measure on publicly available datasets.Ablation studies and statistical significance analysis confirmed Vi-mCALNET's robust performance with lower variance, making it suitable for real-time, scalable surveillance applications while reducing annotation costs and computational demands.},
  archive      = {J_CSCI},
  author       = {Duba Sriveni and Loganathan R},
  doi          = {10.1080/09540091.2025.2544539},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2544539},
  shortjournal = {Connect. Sci.},
  title        = {Multi-constraints active learning assisted deep-ensemble spatio-textural feature learning model for violence detection in surveillance dataset},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An experimental evaluation of deep learning-based models for acne severity classification in humans. <em>CSCI</em>, <em>37</em>(1), Article: 2533867. (<a href='https://doi.org/10.1080/09540091.2025.2533867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the context of acne severity, this paper presents a novel comparison between three convolutional neural network models: SqueezeNet, CenterNet and VGG-16 for the evaluation of acne severity on a custom-annotated dataset through Hayashi Grading Criterion. Unlike previous works, which mainly focus on single-model performance, this paper systematically presents the classification abilities of these three distinct architectures. The models were compared against real labels by the predictions for every group of images used in training that have been graded 0 through 3 in terms of acne severity. According to the results, CenterNet has the highest accuracy of 79.45%, followed by VGG-16 with 78.08% and then SqueezeNet having 76.71%. These findings add to the literature on AI models in acne classification and suggest that CenterNet is the most accurate model which can be incorporated into clinical practice for the management of acne vulgaris. The ACNE04 dataset contains both local lesion number and global acne severity have been utilised to assess the effectiveness of acne classification of the listed deep learning models.},
  archive      = {J_CSCI},
  author       = {Ayesha Shaik and Jincy Jis Kanichai and Aleena Bosco Kurumthottam and Vidul Garg and Balasundaram Ananthakrishnan},
  doi          = {10.1080/09540091.2025.2533867},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2533867},
  shortjournal = {Connect. Sci.},
  title        = {An experimental evaluation of deep learning-based models for acne severity classification in humans},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel architecture for efficient pedestrian detection in autonomous vehicles. <em>CSCI</em>, <em>37</em>(1), Article: 2529261. (<a href='https://doi.org/10.1080/09540091.2025.2529261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public safety and intelligent surveillance systems rely heavily on accurate pedestrian detection to ensure effective monitoring and response. However, real-world challenges such as complex backgrounds, occlusions, and small target sizes significantly impact detection performance. To address these issues, this study proposes YOLO-SPD, an optimised YOLOv8-based architecture specifically designed for pedestrian detection. The model enhances multi-scale feature fusion by integrating a Bi-directional Feature Pyramid Network (BiFPN) in the neck structure, reducing computational complexity while preserving fine-grained details. Additionally, the Coordinate Attention (CA) mechanism is embedded within the Spatial Pyramid Pooling Fast (SPPF) module to improve localisation by effectively capturing both local and global spatial dependencies. Furthermore, pedestrian-specific bounding box regression is refined using the Complete Intersection over Union (CIoU) loss function, ensuring precise localisation and better edge positioning. The proposed approach is evaluated on the Caltech Pedestrian and KITTI datasets. Extensive experiments demonstrate its effectiveness, achieving 97.85% precision on the KITTI dataset and 96.18% precision on the Caltech Pedestrian dataset. These results highlight the robustness and reliability of YOLO-SPD in detecting pedestrians across diverse environments, making it a promising solution for real-time autonomous driving and intelligent surveillance applications.},
  archive      = {J_CSCI},
  author       = {Wajdi Farhat and Olfa Ben Rhaiem and Hassene Faiedh and Chokri Souani},
  doi          = {10.1080/09540091.2025.2529261},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2529261},
  shortjournal = {Connect. Sci.},
  title        = {A novel architecture for efficient pedestrian detection in autonomous vehicles},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SMARDY: The CORE of zero-trust FAIR marketplace for research data. <em>CSCI</em>, <em>37</em>(1), Article: 2523965. (<a href='https://doi.org/10.1080/09540091.2025.2523965'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supporting discovery through good and open management of existing datasets is the core of progress in data-rich research environments. Open Data and FAIR (Findable, Accessible, Interoperable, and Reusable) principles drive the exploitation of current results to a better and more trustworthy scientific era, but the wide adoption in Science is hindered by concerns regarding the proper handling of sensitive or extra-valuable copyrighted datasets. We present Smardy, our proposal for extending Open Data Repositories for research datasets with components meant to protect data sovereignty and trust in transfer. Our implementation of a cross-platform is the core of a FAIR Dataset Marketplace, which allows the authors to trade their datasets with the unconditional security of a Zero-Trust environment, and helps them to protect their IP over data using undisputable, Blockchain-based proofs of their authorship. The depicted aspects include application-code design, functional schemes, fingerprinting, and encryption steps for properly handling datasets and generating authorship proofs.},
  archive      = {J_CSCI},
  author       = {Cosmin-Andrei Ioniţe and Ion-Dorinel Filip and Alba González–Cebrián and Ciprian Dobre},
  doi          = {10.1080/09540091.2025.2523965},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2523965},
  shortjournal = {Connect. Sci.},
  title        = {SMARDY: The CORE of zero-trust FAIR marketplace for research data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differential privacy in statistical queries for synthetic trajectories generated by generative adversarial networks. <em>CSCI</em>, <em>37</em>(1), Article: 2523964. (<a href='https://doi.org/10.1080/09540091.2025.2523964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread adoption of smartphones and the rapid advancement of information and communication technologies, the use of Location-Based Services (LBS) has significantly increased across various domains. Consequently, the collection and utilisation of user trajectory data are also growing rapidly. While such data can provide valuable insights for personalised services and other analyses, it inherently contains sensitive location information, posing serious privacy risks if used without proper anonymization. Previous studies have attempted to mitigate privacy concerns by applying Differential Privacy (DP) to prefix tree structures for statistical analysis. However, these approaches often suffer from diminished data utility due to the excessive noise required by DP mechanisms. To address this issue, we propose a two-stage trajectory privacy framework. In the first stage, we employ a Category Auxiliary Classifier-Generative Adversarial Network (CAC-GAN) to generate synthetic trajectory data that preserves the statistical characteristics of the original data, thereby providing primary privacy protection. In the second stage, we apply a prefix tree-based DP algorithm to the synthetic data, offering enhanced privacy during statistical analysis and query processing. Experimental results demonstrate that the proposed CAC-GAN method achieves approximately 53% improvement in both data utility and anonymity compared to existing methods. Furthermore, relative error analysis across various ϵ values confirms that our two-stage protection scheme maintains superior statistical accuracy. This study presents a novel methodology that effectively balances trajectory data privacy and utility.},
  archive      = {J_CSCI},
  author       = {Jihwan Shin and Yeji Song and Minsoo Jang and Jinhyun Ahn and Taewhi Lee and Dong-Hyuk Im},
  doi          = {10.1080/09540091.2025.2523964},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2523964},
  shortjournal = {Connect. Sci.},
  title        = {Differential privacy in statistical queries for synthetic trajectories generated by generative adversarial networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReinforceAdapt: Multi-objective approach for environmental adaptation method. <em>CSCI</em>, <em>37</em>(1), Article: 2523960. (<a href='https://doi.org/10.1080/09540091.2025.2523960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization (MOO) underpins numerous real-world applications requiring the simultaneous optimization of conflicting objectives. Evolutionary Algorithms (EAs), particularly Multi-Objective Evolutionary Algorithms (MOEAs), have demonstrated exceptional capabilities in approximating Pareto-optimal solutions. However, their reliance on static operator configurations often results in suboptimal performance in dynamic and high-dimensional search spaces. To address this limitation, we propose a novel framework that integrates Deep Reinforcement Learning (DRL) with MOEAs, enabling adaptive and context-aware operator selection. Our methodology formulates operators as actions and solution states within a reinforcement learning paradigm. By leveraging Q -learning, the framework dynamically evaluates and selects operators that balances exploration and exploitation to optimise convergence and diversity. The implementation incorporates modular optimization, adaptive credit assignment, and decomposition-based subproblem partitioning which ensures scalability across diverse problem domains. Experimental evaluations on benchmark suites reveal that the proposed DRL-MOEA framework achieves superior performance, significantly improving Inverted Generational Distance (IGD) metrics while enhancing Pareto front diversity compared to state-of-the-art approaches. The results shows the framework's robustness and adaptability, establishing it as a powerful tool for addressing the challenges of multi-objective optimization in complex and dynamic environments.},
  archive      = {J_CSCI},
  author       = {Ravi Prakash and Brajesh Kumar Umrao and Ranvijay},
  doi          = {10.1080/09540091.2025.2523960},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2523960},
  shortjournal = {Connect. Sci.},
  title        = {ReinforceAdapt: Multi-objective approach for environmental adaptation method},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection and classification of enhanced periapical lesion images with YOLO algorithms. <em>CSCI</em>, <em>37</em>(1), Article: 2522706. (<a href='https://doi.org/10.1080/09540091.2025.2522706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence has become a reliable technology in clinical decision support systems with the solutions it offers in the dental field. This success also indicates a significant potential in detecting five different types of lesions on the tooth root through radiographic images. Because the periapical X-ray-taking process may vary depending on the individual's physical, psychological, and mental conditions. Also, environmental parameters may negatively affect the image acquisition process. It is possible to tolerate these disadvantageous situations with artificial intelligence-based algorithms and image processing approaches. In this study, it was planned to in-depth analysis of the periapical lesion data types in the original dataset called Periapical X-rays provided from the Kaggle public database. For this, the original adaptive image processing approach developed by integrating the ABC optimisation algorithm was applied to the dataset for five different lesion types. Then, the enhanced images enriched with the data augmentation approach were trained with YOLOv7, YOLOv8, YOLOv9 and YOLOv10 algorithms. As a result of the training, the enhanced images compared to the original images reached 96% F Criterion thanks to the network architecture of YOLOv8 algorithm. This shows that the YOLOv8 network architecture in enhanced lesion images is more successful.},
  archive      = {J_CSCI},
  author       = {Fatma Akalin and Tuğçenur Yildiz},
  doi          = {10.1080/09540091.2025.2522706},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2522706},
  shortjournal = {Connect. Sci.},
  title        = {Detection and classification of enhanced periapical lesion images with YOLO algorithms},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An NLP-driven e-learning platform with LLMs and graph databases for personalised guidance. <em>CSCI</em>, <em>37</em>(1), Article: 2518991. (<a href='https://doi.org/10.1080/09540091.2025.2518991'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information is ubiquitously available at our fingertips, transforming the way we learn, work and engage with the world around us. The challenge is not just accessing data but discerning its relevance and utility. This constant flow of information demands selective attention and strategic thinking about how we integrate new findings for professional growth. In this context, we propose an e-learning platform that recommends career paths based on user-uploaded PDFs. Our solution extracts keywords with Natural Language Processing (NLP). Using OpenAI, we enable interaction with the PDF files, allowing the user to ask questions and receive summaries. Then, we generate embeddings and index them with Facebook AI Similarity Search (FAISS). Next, we use a dataset of job listings and, with BERT, skills and technologies are extracted. An interconnected graph using a graph database system (Neo4j) based on these skills and technologies is built. Keywords from the uploaded documents are analyzed and matched to skills, leading to job recommendations or guidance on additional skills needed to secure employment. Mean Reciprocal Rank (MRR) is calculated to compare the results of different job recommendation systems.},
  archive      = {J_CSCI},
  author       = {Gabriela Dobriţa and Simona-Vasilica Oprea and Adela Bâra},
  doi          = {10.1080/09540091.2025.2518991},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2518991},
  shortjournal = {Connect. Sci.},
  title        = {An NLP-driven e-learning platform with LLMs and graph databases for personalised guidance},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSLWNet: A dual-stream lightweight deep learning network for the detection of epileptic seizures using EEG signals. <em>CSCI</em>, <em>37</em>(1), Article: 2518985. (<a href='https://doi.org/10.1080/09540091.2025.2518985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is one of the most prevalent neurological disorders, and the accurate detection of epileptic seizures is challenging. Therefore, a dual-stream deep learning network is proposed in this research to extract the deep features by utilising the scalograms and time-series EEG signals. In this, first, the convolutional neural network (CNN) extracts the spatial dimensional features from the scalogram images, and then the squeeze and excitation (SE) technique enhances the relevant informative features by adjusting the channel weights. Correspondingly, the gated recurrent unit (GRU) extracts the temporal characteristics from the time-series EEG signal, and then for assigning more weights to the significant features the confined attention (CA) mechanism is included. Next, the extracted features are fused to form a deep feature set for the accurate detection of seizures using the support vector machine (SVM) classifier. Further, to improve the seizure detection rate, the regression at the end of variational mode extraction techniques (VME) is employed in the preprocessing stage. In addition, the performance of the proposed dual-stream lightweight seizure network (DSLWNet) is evaluated using the CHB-MIT and Bonn datasets. The experimental outcomes show the superiority of the proposed work in seizure detection by achieving an accuracy of 98.67% and 99.5%, respectively.},
  archive      = {J_CSCI},
  author       = {Bommala Silpa and Malaya Kumar Hota},
  doi          = {10.1080/09540091.2025.2518985},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2518985},
  shortjournal = {Connect. Sci.},
  title        = {DSLWNet: A dual-stream lightweight deep learning network for the detection of epileptic seizures using EEG signals},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LPIF-based image enhancement and hybrid ensemble models for brain tumor detection. <em>CSCI</em>, <em>37</em>(1), Article: 2518983. (<a href='https://doi.org/10.1080/09540091.2025.2518983'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors represent one of the most critical neurological disorders where early and accurate diagnosis significantly impacts treatment outcomes. This paper presents a comprehensive deep learning framework for automated brain tumor classification using MRI scans, validated across both binary (DS1) and multi-class (DS2) datasets. Our approach introduces three key innovations: (1) a novel Local Pixel Inhomogeneity Factor (LPIF) based preprocessing pipeline that enhances tumor visibility while suppressing noise through adaptive local intensity processing, (2) AugmentFusion – a hybrid data augmentation strategy combining CLAHE with geometric transformations and noise injection to improve model generalisation, and (3) a hybrid ensemble model integrating DenseNet121 and VGG16 through majority voting, optimised using Adaptive Lookahead-AdamW with Cyclic Learning (ALACL). Extensive experiments demonstrate state-of-the-art performance, with our ensemble achieving 99.46% accuracy (AUC: 0.995, F1-score: 0.992) on the DS1 dataset (normal vs. tumor classification) and 98.63% accuracy (AUC: 0.986, F1-score: 0.99) on the more challenging DS2 dataset (multi-class tumor classification). These results significantly outperform existing approaches including transformer-based methods (98.6% accuracy) and 3D CNN architectures (98.4% accuracy). The framework maintains robust performance across all evaluation metrics while demonstrating computational efficiency suitable for clinical deployment. Our solution provides radiologists with a reliable decision support tool that combines high diagnostic accuracy with interpretability, potentially improving early detection and treatment planning for brain tumor patients.},
  archive      = {J_CSCI},
  author       = {Prabhat Kumar Sahu},
  doi          = {10.1080/09540091.2025.2518983},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2518983},
  shortjournal = {Connect. Sci.},
  title        = {LPIF-based image enhancement and hybrid ensemble models for brain tumor detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PSPNet EPO-SEB: A novel attention-enhanced hybrid model for accurate histopathological image segmentation. <em>CSCI</em>, <em>37</em>(1), Article: 2508357. (<a href='https://doi.org/10.1080/09540091.2025.2508357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise histopathological image segmentation is vital for accurate diagnosis and treatment planning. This manuscript proposes a hybrid framework, PSPNet EPO-SEB, combining PSPNet with an emperor penguin optimizer and an attention-enhanced module for improved segmentation performance. The model was rigorously evaluated on two prominent datasets, BACH and Camelyon17, encompassing high-resolution and whole-slide histopathological images, respectively. Experimental results demonstrate that PSPNet EPO-SEB outperforms conventional segmentation models, achieving dice coefficients (DC) of 0.9237 and 0.9186, and intersection over union (IoU) values of 0.8629 and 0.8622 on the BACH and Camelyon17 datasets, respectively. These metrics surpass those of competing models such as U-Net, V-Net, PA-Net, FANet18, Mask R-CNN, R2UNet, with PSPNet EPO-SEB showing enhanced boundary accuracy, True positive rates (TPR) above 0.93, and minimized false positive rates (FPR) at 0.1211 on BACH and 0.1108 on Camelyon17. Furthermore, the proposed model maintains low average error rates (AER) and achieves boundary precision with Hausdorff distances (HD) as low as 12.68 on BACH and 13.04 on Camelyon17, underscoring its accuracy in delineating complex tissue structures. Despite a slight increase in computational time due to optimization and attention mechanisms, the enhanced segmentation precision and boundary adherence make PSPNet EPO-SEB a highly effective solution for complex histopathological image analysis.},
  archive      = {J_CSCI},
  author       = {Prem Purusottam Jena and Debahuti Mishra and Kaberi Das and Sashikala Mishra and Mandakini Priyadarshani Behera},
  doi          = {10.1080/09540091.2025.2508357},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2508357},
  shortjournal = {Connect. Sci.},
  title        = {PSPNet EPO-SEB: A novel attention-enhanced hybrid model for accurate histopathological image segmentation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QIR: A novel quaternion-based image representation for reversible image steganography. <em>CSCI</em>, <em>37</em>(1), Article: 2507830. (<a href='https://doi.org/10.1080/09540091.2025.2507830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image steganography involves concealing data within a digital image. Reversible steganography is considered as the complete restoration of the original image after the embedded secret data have been extracted. In this research work, a novel quaternion-based image representation technique is proposed for effective representation of images for processing it in quantum computational units. The proposed model is evaluated by implementing the representation of images for reversible image steganography where the images that are represented should be decrypted without loss. The images that were used in this study involve three different sizes 256 × 256 , 512 × 512 , 1024 × 1024 . Here the numerical results of the proposed work shows that the average PSNR value of the original image to the stego image is 44 dB and the average PSNR value to the original image and quantum decrypted image using quaternion function is 74 dB approximately which is 40% greater than the previous quantum representation and the SSIM and MSE values obtained are 95% similar to the previous works. The importance of our contribution is the stego image which is represented using 3-D quaternion rotation undergoes a decryption using LSB–MSB technique which then recovers the original secret and cover image with minimum loss. This shows that the stego image is not affected by the proposed quantum representation.},
  archive      = {J_CSCI},
  author       = {R. Deepika and Kalaipriyan Thirugnanasambandam and K. Muthunagai},
  doi          = {10.1080/09540091.2025.2507830},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507830},
  shortjournal = {Connect. Sci.},
  title        = {QIR: A novel quaternion-based image representation for reversible image steganography},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative linguistic analysis framework of human-written vs. machine-generated text. <em>CSCI</em>, <em>37</em>(1), Article: 2507183. (<a href='https://doi.org/10.1080/09540091.2025.2507183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Writing content with the assistance of artificial intelligence has increased in popularity and influenced every domain, yet the challenge of understanding the differences between machine-generated and human-authored writing remains. To address this issue, our research aims to propose a detailed framework for deciphering the characteristics of machine-written language by identifying distinct linguistic features, analyzing stylistic differences, evaluating sentiment consistency, and validating the performance of selected generative models in replicating human writing across different types of writing. Using free resources from Hugging Face, we selected three models: GPT-Neo 1.3B, Qwen2.5-1.5B-Instruct, and BloomZ-560M, and employed them without fine-tuning in a Google Colab environment using a consistent prompt. These models were used to generate introductions for corresponding human-authored texts. We compared the extracted features of 2,121 texts, using visualisation methods such as histograms, boxplots and Q-Q plots, alongside the Shapiro–Wilk test and the non-parametric Kruskal – Wallis test and Dunn’s post-hoc test. Our findings highlight both the advancements of open-source text-generating models and the persistent gaps in replicating the depth and richness of human writing, providing and contributing to the knowledge about artificial intelligence and its progress in the generative field, supporting the validation of open-source text-generative models through statistical comparisons.},
  archive      = {J_CSCI},
  author       = {Lia Cornelia Culda and Raluca Andreea Nerişanu and Marian Pompiliu Cristescu and Dumitru Alexandru Mara and Adela Bâra and Simona-Vasilica Oprea},
  doi          = {10.1080/09540091.2025.2507183},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507183},
  shortjournal = {Connect. Sci.},
  title        = {Comparative linguistic analysis framework of human-written vs. machine-generated text},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage deep learning based method for diabetic retinopathy classification. <em>CSCI</em>, <em>37</em>(1), Article: 2507182. (<a href='https://doi.org/10.1080/09540091.2025.2507182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is a major cause of blindness, but current classification models suffer from low interpretability and difficulty in adjustment. To address these issues, a two-stage deep learning method for DR classification has been proposed, featuring lesion-sliced detection and DR classification stages. In the lesion-sliced detection stage, an improved neural process model extracts information from fundus images by fusing lesion details from various image locations, significantly enhancing accuracy. In the DR classification stage, an enhanced deep forest model was used to identify critical features influencing DR grades, boosting the credibility of the grading outcomes. Tests on the IDRiD and E-ophtha datasets demonstrated superior performance and generalisation ability of the lesion-sliced detection model compared to mainstream neural networks. Meanwhile, experiments on the Kaggle dataset confirmed that the deep forest-based DR classification model outperformed both traditional forest models and residual networks, marking its first application in DR classification. This approach achieves high accuracy and reliability, with improvements in both detection efficiency and generalisation.},
  archive      = {J_CSCI},
  author       = {Chen Zhang and Shaoqi Dong and Ziyun Song and Liming Liu and Jiaxu Ning and Bin Zhang and Changsheng Zhang},
  doi          = {10.1080/09540091.2025.2507182},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507182},
  shortjournal = {Connect. Sci.},
  title        = {A two-stage deep learning based method for diabetic retinopathy classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EXING-IoT conceptual framework for explainability integration in next generation-IoT. <em>CSCI</em>, <em>37</em>(1), Article: 2507180. (<a href='https://doi.org/10.1080/09540091.2025.2507180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) paradigm is evolving and the Next-Generation IoT (NG-IoT) ecosystem will incorporate distributed ledger and blockchain technology, AI-adapted components, and intelligent edge solutions that take advantage of edge computing, Artificial Intelligence (AI), networks, and communications. In addition to the low integration of eXplainable Artificial Intelligence (XAI) in the IoT or NG-IoT contexts, the explainability of these systems is rarely evaluated. Due to these limitations, we thoroughly examined the current state of XAI integration with IoT services. We propose a new conceptual framework called eXING-IoT (eXplainability Integrated in the Next Generation IoT) for better NG-IoT systems' explainability integration and evaluation. This includes a list of qualities that future NG-IoT environments should have, thus paving the way for the advancement of NG-IoT beyond the state of the art.},
  archive      = {J_CSCI},
  author       = {Alexandra Vultureanu-Albişi and Costin Bădică and Mirjana Ivanović},
  doi          = {10.1080/09540091.2025.2507180},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507180},
  shortjournal = {Connect. Sci.},
  title        = {EXING-IoT conceptual framework for explainability integration in next generation-IoT},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensuring unbiasedness: Foundational insights into integrating GSTARIMA and DNN models for rainfall prediction. <em>CSCI</em>, <em>37</em>(1), Article: 2507179. (<a href='https://doi.org/10.1080/09540091.2025.2507179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The GSTARIMA (Generalied Space–Time Autoregressive Integrated Moving Average) model is commonly used to analyse time series and spatial data with temporal and spatial dependencies. This paper focuses on estimating the autoregressive and moving average parameters of the GSTARIMA model using Maximum Likelihood Estimation (MLE). We theoretically demonstrate the unbiasedness of these estimates, proving that the expected values of the estimates match the true parameters. Empirical experiments further verify this property, both before and after applying Deep Neural Network (DNN) interventions to correct model errors. The results show that the parameter estimates remain unbiased, and error properties (zero mean and constant variance) are preserved even after DNN processing. This study highlights the robustness of MLE in providing unbiased estimates within the GSTARIMA framework, even when integrated with machine learning techniques.},
  archive      = {J_CSCI},
  author       = {Devi Munandar and Budi Nurani Ruchjana and Atje Setiawan Abdullah and Hilman Ferdinandus Pardede},
  doi          = {10.1080/09540091.2025.2507179},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2507179},
  shortjournal = {Connect. Sci.},
  title        = {Ensuring unbiasedness: Foundational insights into integrating GSTARIMA and DNN models for rainfall prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning computer vision system for estimating sheep age using teeth images. <em>CSCI</em>, <em>37</em>(1), Article: 2506456. (<a href='https://doi.org/10.1080/09540091.2025.2506456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the use of deep learning neural networks and transfer learning to estimate the age of sheep from their dental images. This is an important aspect of agriculture for meat quality, animal welfare, breeding, and health management. Using cutting-edge techniques, MobileNet, ResNet50, and ResNet102, we compare two deep learning approaches: fine-tuning and feature extraction using the pre-trained version of these models as part of our investigation. We collected 540 images of sheep from nearby farms, concentrating on three age groups: young, middle-aged, and elderly, for the purpose of our study. With an interesting recognition accuracy of 96.9%, the experimental results demonstrate that ResNet102 is the best performer both when fine-tuned and when employing its deep features that are retrieved from its pre-trained version. These findings highlight how cutting-edge machine learning techniques have the potential to completely transform long-standing methods in the sheep sector and pave the way for developing a novel mobile application that improves economic outcomes and cultural conformity concerning sheep age recognition.},
  archive      = {J_CSCI},
  author       = {Ahmad B. Hassanat and Mohammad A. Al-Sarayreh and Ahmad S. Tarawneh and Mohammad A. Abbadi and Khalid Almohammadi and Mansoor Alghamdi and Maha Alamri and Abdulkareem Alzahrani and Ghada A. Altarawneh},
  doi          = {10.1080/09540091.2025.2506456},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2506456},
  shortjournal = {Connect. Sci.},
  title        = {Deep learning computer vision system for estimating sheep age using teeth images},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual data security in healthcare and cloud applications using a novel 2D-HCFCM, polynomial chains and NLDSR. <em>CSCI</em>, <em>37</em>(1), Article: 2491340. (<a href='https://doi.org/10.1080/09540091.2025.2491340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past two decades, numerous encryption schemes leveraging chaotic systems have been developed to ensure data integrity in healthcare and cloud environments. In this paper, we first assess the performance of a two-dimensional Higher Complexity Folium Chaotic Map (2D-HCFCM) and then introduce a robust encryption algorithm for 8-bit and 24-bit images. The algorithm constructs polynomials of 0 ≤ d ≤ 7 with 2D-HCFCM, followed by polynomial chaining and 8-bit conditional logical operation ( CL O 8 bit ), driven by ζ ( υ ) = ( ⌊ csin ⁡ ( x 2 + y 2 ) ⌋ + x y ) mod 2 to introduce additional dynamic control. Furthermore, the Nested Layered with Diagonal Swapping and Relocation (NLDSR) technique introduces nonlinearity and resistance to chosen plaintext attacks. In summary, the algorithm offers an encryption key of 800 bits and demonstrates satisfactory security performance, with a χ 2 of 236.0598, an NBCR of 49.7%, and an NPCR value of 99.6389, with optimal computational efficiency. The security analysis confirms that the algorithm is effective in preserving the integrity of visual data.},
  archive      = {J_CSCI},
  author       = {Sajid Khan and Hao Peng and Abdul Haseeb and Sardar Usman},
  doi          = {10.1080/09540091.2025.2491340},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2491340},
  shortjournal = {Connect. Sci.},
  title        = {Visual data security in healthcare and cloud applications using a novel 2D-HCFCM, polynomial chains and NLDSR},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel classification of meditation techniques via optimised chi-squared 1D-CNN method based on complexity, continuity and connectivity features. <em>CSCI</em>, <em>37</em>(1), Article: 2467387. (<a href='https://doi.org/10.1080/09540091.2025.2467387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate world of human–computer interaction deeply explores how people gain knowledge and blend technology into daily life. Electroencephalography (EEG) is one of several methods for measuring brain activity, it is non-invasive, portable, inexpensive and time-sensitive. Research shows a strong link between meditation and changes in EEG patterns, spanning various techniques. With machine learning playing a major role, EEG datasets have made comprehensive study possible. This paper investigates the efficacy of 1D-CNN (One-Dimensional Convolutional Neural Network) classification, using complexity, continuity and connectivity features. It remarkably outperforms and achieves 60% training accuracy, showcasing model robustness in meditation classification. This novel methodology enables to differentiates neural oscillations in type of meditator and control. Prior research used power spectrum density, entropy, and connectivity for meditation distinctions. EEG data from practitioners of Himalayan Yoga (HYT), Isha Shoonya (SYN) and Vipassana (VIP) as well as untrained controls (CTR) are examined in this research. Employing chi-square, CNN and hyperparameter models, outcomes reveal distinctive cognitive aspects among meditation styles, allowing effective differentiation.},
  archive      = {J_CSCI},
  author       = {Abhishek Jain and Rohit Raja and Manoj Kumar and Pawan Kumar Verma},
  doi          = {10.1080/09540091.2025.2467387},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2467387},
  shortjournal = {Connect. Sci.},
  title        = {A novel classification of meditation techniques via optimised chi-squared 1D-CNN method based on complexity, continuity and connectivity features},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel CNN architecture for image restoration with implicit frequency selection. <em>CSCI</em>, <em>37</em>(1), Article: 2465448. (<a href='https://doi.org/10.1080/09540091.2025.2465448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration aims to recover clear images from degraded ones, with deep neural networks becoming the dominant approach. While earlier methods focused on spatial-domain information, recent models have explored frequency-domain data to improve performance. However, explicit frequency-domain processing introduces significant computational overhead. To address this, we propose the Implicit Frequency Selective Image Restoration Network (IFSR-Net), which implicitly captures frequency information without explicit transformations, achieving high performance with reduced computational cost. Our analysis indicates that the main spectral variations between the clear and degraded images are centred on the high-frequency components in the feature maps; the convolution operator tends to amplify the amplitude and variance of these components. Building on this observation, we designed an Implicit Frequency Selection Module (IFSM) to enrich high-frequency components and an Implicit Frequency Selection Attention (IFSA) mechanism to emphasize and integrate beneficial frequency features. We integrated and optimized design elements from existing image restoration models to further refine the overall architecture of IFSR-Net. Extensive experiments across seven datasets and three tasks demonstrate the effectiveness of our approach. Ablation studies confirm the validity of our design choices, offering insights for future research in image restoration.},
  archive      = {J_CSCI},
  author       = {Jiaxing Hu and Zhibo Wang},
  doi          = {10.1080/09540091.2025.2465448},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2465448},
  shortjournal = {Connect. Sci.},
  title        = {A novel CNN architecture for image restoration with implicit frequency selection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Password region attribute classification based on multi-granularity cascade fusion. <em>CSCI</em>, <em>37</em>(1), Article: 2461092. (<a href='https://doi.org/10.1080/09540091.2025.2461092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The composition of the password is markedly disparate contingent on the configuration strategy and the individual user's predilections. The objective of this paper is to mine the region attribute information behind the password text through text classification. In contrast to the traditional text classification approach, the classification of password region attribution represents a distinct challenge namely ultra-short text classification. The issue of password regional attribute classification is particularly tricky due to its inherent lexical polysemy, the scarcity of text features, the lack of context and the difficulty in explicitly identifying semantics. To address the aforementioned issues, we propose a multi-granularity cascade fusion approach for password region attribution classification. Firstly, the model employs series of segmentation techniques to split password into multi-dimensional fine-grained subword representations. Subsequently, multiple segmented representations of the same password are fed into a localised feature encoder to mine the private local features. Finally, a multi-level cascade fusion method is designed to integrate different granularity of password features into a unified representation to classification. Our approach can effectively addresses the limitations of scarce information and the challenge of integrating multiple representations for password text. Experiments on a large amount of real password data demonstrate that, our model can converge rapidly and achieve an accuracy of 88.18%, a precision of 88.31%, a recall of 87.73%, and an F1-score of 88.02%, significantly outperforming traditional models.},
  archive      = {J_CSCI},
  author       = {Wei Yu and Cheng Liu and Lvlin Ni and Yu Shi and Qingbing Ji},
  doi          = {10.1080/09540091.2025.2461092},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2461092},
  shortjournal = {Connect. Sci.},
  title        = {Password region attribute classification based on multi-granularity cascade fusion},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved data labelling method for news headlines classification in cloud environment. <em>CSCI</em>, <em>37</em>(1), Article: 2461088. (<a href='https://doi.org/10.1080/09540091.2025.2461088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In several domains, such as computer vision, natural language processing, and speech recognition, automatic data labelling is a critical task. Automatic data labelling is the process of utilising machine learning techniques to automatically label substantial amounts of data. Two largest news datasets like, the Kaggle dataset and the AG News dataset are used as benchmark for the performance analysis of the proposed algorithms. A novel four-dimensional matrix-based input representation that depicts the intra – and inter-word associations is used to obtain the feature vectors. Density-Based Spatial Clustering of Applications with Noise (DBSCAN) helps to remove the outliers which improves the overall accuracy of Convolutional Neural Networks (CNN). The proposed approach also reduces the dependency on human annotators. The DBSCAN algorithm is utilised o automatically cluster similar data points, thereby reducing the need for manual labelling. These clusters are then fed into a CNN with a rethinking mechanism, which allows the network to revise its initial predictions based on additional context. This integration of clustering and deep learning techniques aims to improve the accuracy and efficiency. The cloud computing method is used to achieve high-throughput news headlines classification in order to achieve accurate and efficient data labelling.},
  archive      = {J_CSCI},
  author       = {A. Sherly Alphonse and S. Abinaya and Nirvik Verma},
  doi          = {10.1080/09540091.2025.2461088},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2461088},
  shortjournal = {Connect. Sci.},
  title        = {Improved data labelling method for news headlines classification in cloud environment},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Software defect prediction using wrapper-based dynamic arithmetic optimization for feature selection. <em>CSCI</em>, <em>37</em>(1), Article: 2461080. (<a href='https://doi.org/10.1080/09540091.2025.2461080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Defect Prediction (SDP) empowers the creators to diagnose and unscramble defects in the introductory legs of the software evolution process to reduce the effort and cost invested in creating high-quality software. Feature Selection (FS) is critical to pinpoint the most pertinent features for defect prediction. This paper intends to employ a peculiar wrapper-based FS mode, dubbed DAOAFS, rooted on the dynamic arithmetic optimization algorithm (DAOA). Subsequently, this work evaluates the competence of the proposed FS mode using ten benchmark NASA datasets on four supervised learning classifiers, namely NB, DT, SVM, and KNN using accuracy and error curve as the standard performance measure metrics. This paper also correlates the proposed FS mode's conduct with existing FS techniques based on widely utilized meta-heuristic approaches such as GA, PSO, DE, ACO, FA, and SWO. This work employed Friedman and Holm test to ratify the proposed FS mode's statistical connotation. The investigatory outcomes supported the assertion that the recommended DAOAFS mode was effective in enhancing the efficacy of the defect forecasting model by achieving the highest mean accuracy of 94.76%. The findings also revealed that the proposed approach established its supremacy over the other studied FS techniques with bettered veracity in most instances.},
  archive      = {J_CSCI},
  author       = {Kunal Anand and Ajay Kumar Jena and Himansu Das and S. S. Askar and Mohamed Abouhawwash},
  doi          = {10.1080/09540091.2025.2461080},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2461080},
  shortjournal = {Connect. Sci.},
  title        = {Software defect prediction using wrapper-based dynamic arithmetic optimization for feature selection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative adversarial deep learning model for producing location-based synthetic trajectory data. <em>CSCI</em>, <em>37</em>(1), Article: 2458502. (<a href='https://doi.org/10.1080/09540091.2025.2458502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of location-based services has triggered the acquisition and analysis of various types of individual trajectory recordings. However, the sensitive nature of such kind of data inevitably leads to privacy constraints and regulations on its use and sharing. This paper addresses the problem in a distinctive perspective. Instead of blurring or modifying original trajectory samples, we aim to generate a completely synthetic dataset, whose samples are singularly different from the original ones, but whose collective sets share similar global characteristics and performances. We propose a generative deep learning solution for location-based trajectory formats, with the goal of producing realistic synthetic location sequences: the process relies on a generative adversarial network (GAN) framework, involving long short-term memory (LSTM) recurrent layers to capture trajectory characteristics, and neural embeddings to model mobility relations between places. We leverage multiple metrics to assess the realistic character of synthetic data and their similarity with the original source; moreover, we evaluate downstream performance differences with regard to the next place prediction problem. Tested on a real-world large-scale dataset of long-distance trips, and compared with baselines and traditional geomasking techniques, our approach presents better characteristics, providing novel insights into GeoAI solutions for human mobility analysis.},
  archive      = {J_CSCI},
  author       = {Alessandro Crivellari and Yuhui Shi},
  doi          = {10.1080/09540091.2025.2458502},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2458502},
  shortjournal = {Connect. Sci.},
  title        = {Generative adversarial deep learning model for producing location-based synthetic trajectory data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental learning based two-level multimodal data fusion model for alzheimer disease prediction on different data modalities. <em>CSCI</em>, <em>37</em>(1), Article: 2458501. (<a href='https://doi.org/10.1080/09540091.2025.2458501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer's disease (AD) is a complex neurodegenerative condition that affects millions of people worldwide, necessitating early and accurate diagnosis for optimal patient care. This study presents a novel Two-Level Multimodal Data Fusion Integrated Incremental Learner Ensemble Classifier (TMDFILE) for Alzheimer's detection. This method integrates temporal, spatial, spectral, audio, and text data modalities, utilising a gating mechanism to optimise the contribution of each modality. Incremental learning is employed to adjust evolving data patterns and, enhance long-term performance. The proposed TMDFILE was evaluated across five diverse datasets: achieving an accuracy of 94.5%, precision of 93.5%, recall of 95.1%, and F-measure of 94.1% on the ADNI dataset; an accuracy of 94.9%, with precision, recall, and F-measure values of 94.5%, 94.1%, and 94.3%, respectively, on the OASIS dataset; an accuracy of 93.5%, precision of 95.1%, and recall of 94.1% on the EEG Emotion Recognition dataset; an accuracy of 94.5%, precision of 93.5%, and recall of 95.1% on the Aberystwyth Dementia dataset, providing reliable classifications that contribute to early cognitive decline detection; and showed robust performance with an accuracy of 94.5%, precision of 93.5%, and recall of 95.1% on the BRATS dataset, relevant to brain imaging analysis for Alzheimer's detection. TMDFILE consistently outperformed traditional classifiers, including Support Vector Machines, Random Forest, and Convolutional Neural Networks, achieving an average precision of 93.5%, recall of 95.1%, F-measure of 94.1%, and accuracy of 94.5%. These findings underscore TMDFILE's effectiveness in diagnostic accuracy and reliability, establishing it as a promising tool for Alzheimer's disease detection across clinical and research applications.},
  archive      = {J_CSCI},
  author       = {M. Leela and K. Helenprabha},
  doi          = {10.1080/09540091.2025.2458501},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2458501},
  shortjournal = {Connect. Sci.},
  title        = {Incremental learning based two-level multimodal data fusion model for alzheimer disease prediction on different data modalities},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep learning model for stock market prediction using a sentiment analysis system from authoritative financial website’s data. <em>CSCI</em>, <em>37</em>(1), Article: 2455070. (<a href='https://doi.org/10.1080/09540091.2025.2455070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of deep learning, specifically time series neural networks, in predicting stock market trends has emerged as a significant use case in financial analysis. However, the complex interrelationships and instability of the stock market have made the timely and accurate prediction of its behaviour as a confronting endeavour. To address this difficulty, in this research work a stock market index prediction model called SenT-In, which combines the with a sentiment awareness model. A sentiment awareness model using Convolutional Neural Networks (CNN) and Gated Recurrent Unit (GRU) is proposed to calculate the sentiment index of a large volume of news articles collected from reputable financial websites. In addition, a sentiment attention method is developed to combine stock data and news sentiment index as the input for training and predicting using the SenT-In network, which is both simple and efficient. The proposed model is evaluated in four different stock market datasets which include FSTE, SSE, Nifty 50 and S&P 500. On comparing the results with conventional deep learning algorithms such as GRU, LSTM, CNN and SVM, proposed SenT-In outperforms existing methods in accuracy with 9%, F1-Score with 7%, AUC-ROC curve with 13% and PR-AUC curve with 9% efficiency (on average).},
  archive      = {J_CSCI},
  author       = {Jitendra Kumar Chauhan and Tanveer Ahmed and Amit Sinha},
  doi          = {10.1080/09540091.2025.2455070},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2455070},
  shortjournal = {Connect. Sci.},
  title        = {A novel deep learning model for stock market prediction using a sentiment analysis system from authoritative financial website’s data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classification of heart sound signals with whisper model. <em>CSCI</em>, <em>37</em>(1), Article: 2449943. (<a href='https://doi.org/10.1080/09540091.2025.2449943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart sounds, or phonocardiograms (PCG), are important for diagnosing cardiovascular conditions, providing a non-invasive means to assess heart function through auscultation. Accurate classification of PCG signals can facilitate early detection of cardiac abnormalities, significantly improving patient outcomes. However, the complexity and variability of heart sound recordings present significant challenges for traditional classification methods, necessitating advanced approaches that can effectively handle the nuances of cardiac acoustics. This paper introduces a novel transfer learning approach that adapts OpenAI's Whisper model, originally designed for robust speech recognition, to the task of heart sound classification. In particular, we employ Whisper's encoder architecture to effectively capture acoustic features that generalize to cardiac auscultation, making it a promising candidate for PCG analysis. To tailor the model for this specialized task, we implement a modified encoder architecture optimized for heart sound characteristics. We process the input to the model using a Log-Mel spectrogram pipeline specifically designed to highlight the unique acoustic properties of PCG signals. Experimental results demonstrate that the adapted Whisper model achieves state-of-the-art performance, surpassing existing methods in both accuracy and robustness.},
  archive      = {J_CSCI},
  author       = {Maryam Alotaibi and Yakoub Bazi and Mohamad Mahmoud Al Rahhal and Nassim Ammour and Mansour Zuair},
  doi          = {10.1080/09540091.2025.2449943},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2449943},
  shortjournal = {Connect. Sci.},
  title        = {Classification of heart sound signals with whisper model},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimising source code vulnerability detection using deep learning and deep graph network. <em>CSCI</em>, <em>37</em>(1), Article: 2447373. (<a href='https://doi.org/10.1080/09540091.2024.2447373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the effectiveness of vulnerability detection in software developed using C and C++ programming languages, our study introduces a novel correlation calculation method for analyzing and evaluating Code Property Graphs (CPG). The intelligent computation method proposed in this study comprises three key stages. In the first stage, we present a method for extracting features from the CPG source code. To accomplish this, we integrate three distinct data exploration methods: employing Graph Convolutional Neural (GCN) to extract node features from CPG, utilizing Convolutional Neural Network (CNN) to extract edge features from CPG, and finally employing the Doc2vec natural language processing algorithm to extract source code from CPG nodes. The second stage involves proposing a method for synthesizing CPG source code features. Building on the features acquired in the first stage, our paper introduces a synthesis and construction method to generate feature vectors for the source code. The final stage, stage three, executes the detection of source code vulnerabilities. The experimental results demonstrate that our proposed model in this study achieves higher efficiency compared to other studies, with an improvement ranging from 3% to 4%.},
  archive      = {J_CSCI},
  author       = {Cho Do Xuan and Tran Thi Luong and Ma Cong Thanh},
  doi          = {10.1080/09540091.2024.2447373},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2447373},
  shortjournal = {Connect. Sci.},
  title        = {Optimising source code vulnerability detection using deep learning and deep graph network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selecting hybrids of metaheuristics for resource-constraint project scheduling problems with discounted cashflows. <em>CSCI</em>, <em>37</em>(1), Article: 2447365. (<a href='https://doi.org/10.1080/09540091.2024.2447365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving resource-constrained project scheduling problems with discounted cash flows (RCPSP-DC) is a critical challenge for project and finance managers, as efficient resource allocation can significantly impact a company’s financial success. While prior research addresses this NP-hard problem, most approaches depend on hybrid metaheuristics requiring expertise in hybridisation and lack systematic methods for architecture selection, often relying on a single criterion with trial-and-error parameter tuning. In this paper, we propose a novel collaborative parallel hybridisation framework that integrates Thompson sampling and multicriteria decision analysis (MCDA) to holistically evaluate and identify the best hybrid architecture from a diverse set of options. Unlike conventional approaches, our method employs onboard Taguchi design of experiments (DOE) for structured and efficient parameter tuning. Additionally, Thompson sampling, applied in the form of Bayesian learning, mitigates the stochastic nature of metaheuristics through multiple experiments. This framework was used to select the best architecture from 57 hybrid combinations of six metaheuristics for solving RCPSP-DC. Extensive experiments using standard datasets demonstrate that the proposed framework achieves statistically significant performance improvements, selecting a hybrid architecture that outperforms state-of-the-art methods. The selected architecture’s competitiveness is validated through a Z-test of proportions, underscoring its effectiveness in solving RCPSP-DC problems.},
  archive      = {J_CSCI},
  author       = {Tshewang Phuntsho and Tad Gonsalves},
  doi          = {10.1080/09540091.2024.2447365},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2447365},
  shortjournal = {Connect. Sci.},
  title        = {Selecting hybrids of metaheuristics for resource-constraint project scheduling problems with discounted cashflows},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human body contour extraction method based on human skeleton key point guidance. <em>CSCI</em>, <em>37</em>(1), Article: 2445805. (<a href='https://doi.org/10.1080/09540091.2024.2445805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By extracting human contours from 2D images captured by the camera and then obtaining human size data, the cost of garment custom measurement can be effectively reduced and the efficiency of custom measurement can be improved. The extraction of human contours plays an important role in the collection of online human size data. We propose a method to extract human contours by fusing the prior information of human skeleton key points into the salience target detection network. Specifically, the skeleton key point information extracted based on OpenPose is fused into the encoder-decoder network for rough detection of the human body target, and the residual refinement network is used to fine-adjust the human body matting, so as to achieve accurate human contour extraction. In this paper, the accuracy and superiority of the algorithm are verified in the public data set P3M-10K of human body matting and applied to the 2D body measurement WeChat applet on mobile phone and computer website.},
  archive      = {J_CSCI},
  author       = {Zhongwei Hua and Yong Ren and Yulu Wang and Zhuriyao Jin},
  doi          = {10.1080/09540091.2024.2445805},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2445805},
  shortjournal = {Connect. Sci.},
  title        = {Human body contour extraction method based on human skeleton key point guidance},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards enhanced assessment question classification: A study using machine learning, deep learning, and generative AI. <em>CSCI</em>, <em>37</em>(1), Article: 2445249. (<a href='https://doi.org/10.1080/09540091.2024.2445249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to benchmark the performance of machine learning (ML), deep learning (DL), and generative AI (GenAI) models in categorising assessment questions based on Bloom’s Taxonomy. Previous studies have lacked comprehensive investigations into the performance of these approaches. Further, the GenAI remains unexplored, offering a promising avenue for groundbreaking explorations. Therefore, we explore the effectiveness of various ML models by incorporating domain-specific term weighting and utilising word embeddings. The study also analyses the performance of Recurrent Neural Networks (RNNs) and Convolutional Neural Network (CNN) with and without bidirectional connections, as well as an approach that combines RNNs and CNN. Furthermore, we evaluate several transformer-based models by fine-tuning them alongside GenAI models text-davinci-003, gpt-3.5-turbo, PaLM2, and Gemini Pro in zero-shot classification settings. The results demonstrate that ML models outperformed DL models, achieving a best accuracy of 0.871 and F1 score of 0.872. Additionally, domain-specific term weighting is found to be superior to word embeddings. Furthermore, most ML and DL models performed better than GenAI models, with GenAI models achieving a best accuracy of 0.618 and a best F1 score of 0.627. Therefore, the outcome suggests considering the ML models with domain-specific term weighting as benchmark models in future research.},
  archive      = {J_CSCI},
  author       = {Mohammed Osman Gani and Ramesh Kumar Ayyasamy and Saadat M. Alhashmi and Khondaker Sajid Alam and Anbuselvan Sangodiah and Khondaker Khaleduzzman and Chinnasamy Ponnusamy},
  doi          = {10.1080/09540091.2024.2445249},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2445249},
  shortjournal = {Connect. Sci.},
  title        = {Towards enhanced assessment question classification: A study using machine learning, deep learning, and generative AI},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating robustness dynamics of shallow machine learning techniques: Beyond basic natural variations in image classification. <em>CSCI</em>, <em>37</em>(1), Article: 2435654. (<a href='https://doi.org/10.1080/09540091.2024.2435654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the widespread adoption of deep learning models, shallow machine learning (SML) algorithms are still used for image classification due to simplicity, interpretability and efficiency. This study aims to bridge this gap by investigating the robustness dynamics of SML techniques under more complex scenarios, such as adversarial perturbations and geometric transformation. Five popular classification algorithms, including k-nearest neighbour and support vector machines, were employed to build classification models. Methodology involves investigating the robustness of proposed  methods, first, on original and corrupted data by utilising benchmark datasets across several image domains. To strengthen the investigation, the models were trained using a new low-rank representation (LRR) strategy. This hybrid model simultaneously addresses two key limitations in classical LRR models: overcoming the sequential learning process and effectively capturing both local and global data structures. By introducing a dual regularisation mechanism, it integrates a k-nearest neighbour graph to preserve local consistency, while a global low-rank constraint ensures coherent data representation. Experimental results reveal significant drops in accuracy of most SML methods, especially under adversarial attacks and geometric transformations, but LRR approach mitigates these effects to a notable extent, boosting performance across data variations. The results also show that the proposed  method outperforms state-of-the-art LRR techniques in most experiments.},
  archive      = {J_CSCI},
  author       = {Mengtong Li},
  doi          = {10.1080/09540091.2024.2435654},
  journal      = {Connection Science},
  month        = {12},
  number       = {1},
  pages        = {Article: 2435654},
  shortjournal = {Connect. Sci.},
  title        = {Investigating robustness dynamics of shallow machine learning techniques: Beyond basic natural variations in image classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
