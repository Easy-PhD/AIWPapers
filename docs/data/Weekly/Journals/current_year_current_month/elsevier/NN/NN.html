<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NN</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="nn">NN - 91</h2>
<ul>
<li><details>
<summary>
(2026). A continual test-time domain adaptation method for online machinery fault diagnosis under dynamic operating conditions. <em>NN</em>, <em>194</em>, 108192. (<a href='https://doi.org/10.1016/j.neunet.2025.108192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical industrial scenarios, monitoring data is collected in a streaming fashion under dynamic changes in operating conditions of mechanical systems, with continual covariate shift and label shift occurring in the collected data. Traditional transfer learning-based fault diagnosis methods typically involve pre-collecting substantial monitoring data for offline training and testing under static conditions. These approaches cannot adjust the model in real-time to continuous data shifts caused by dynamically changing conditions, resulting in a lack of adaptability and generalization. To overcome this practical challenge, a continual test-time domain adaptation (CTDA) approach with a teacher-student framework is developed for online machinery fault diagnosis under dynamic operating conditions in this study. Firstly, a class-balanced sampling mechanism is proposed to eliminate the impact of continual condition label shift by enforcing the model to learn from a uniform label distribution. Secondly, a joint positive-negative learning strategy is employed to guide model optimization and reduce the interference from pseudo-label noise. Lastly, the continual covariate shift is mitigated by performing the knowledge alignment between the teacher and student models. Comprehensive experiments on four rotating machinery datasets demonstrate that the proposed method improves average diagnosis accuracy by 3.78% in handling dynamic industrial streaming data compared to existing fault diagnosis methods.},
  archive      = {J_NN},
  author       = {Jinghui Tian and Yue Yu and Hamid Reza Karimi and Fei Gao and Jing Lin},
  doi          = {10.1016/j.neunet.2025.108192},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108192},
  shortjournal = {Neural Netw.},
  title        = {A continual test-time domain adaptation method for online machinery fault diagnosis under dynamic operating conditions},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WaveNet-SF: A hybrid network for retinal disease detection based on wavelet transform in spatial-frequency domain. <em>NN</em>, <em>194</em>, 108189. (<a href='https://doi.org/10.1016/j.neunet.2025.108189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal diseases are a leading cause of vision impairment and blindness, with timely diagnosis being critical for effective treatment. Optical Coherence Tomography (OCT) has become a standard imaging modality for retinal disease diagnosis, but OCT images often suffer from issues such as speckle noise, complex lesion shapes, and varying lesion sizes, making interpretation challenging. In this paper, we propose a novel model, WaveNet-SF, to enhance retinal disease detection by integrating the spatial-domain and frequency-domain learning. The framework utilizes wavelet transforms to decompose OCT images into low- and high-frequency components, enabling the model to extract both global structural features and fine-grained details. To improve lesion detection, we introduce a Multi-Scale Wavelet Spatial Attention (MSW-SA) module, which enhances the model's focus on regions of interest at multiple scales. Additionally, a High-Frequency Feature Compensation (HFFC) block is incorporated to recover edge information lost during wavelet decomposition, suppress noise, and preserve fine details crucial for lesion detection. Our approach achieves state-of-the-art (SOTA) classification accuracies of 97.82 % and 99.58 % on the OCT-C8 and OCT2017 datasets, respectively, surpassing existing methods. These results demonstrate the efficacy of WaveNet-SF in addressing the challenges of OCT image analysis and its potential as a powerful tool for retinal disease diagnosis.},
  archive      = {J_NN},
  author       = {Jilan Cheng and Guoli Long and Zeyu Zhang and Zhenjia Qi and Hanyu Wang and Libin Lu and Shuihua Wang and Yudong Zhang and Jin Hong},
  doi          = {10.1016/j.neunet.2025.108189},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108189},
  shortjournal = {Neural Netw.},
  title        = {WaveNet-SF: A hybrid network for retinal disease detection based on wavelet transform in spatial-frequency domain},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CEVG-RTNet: A real-time architecture for robust forest fire smoke detection in complex environments. <em>NN</em>, <em>194</em>, 108187. (<a href='https://doi.org/10.1016/j.neunet.2025.108187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forest fire smoke detection is crucial for early warning and emergency management, especially under complex environmental conditions such as low contrast, high transparency, background interference, low illumination, occlusion, and overlapping smoke sources. These factors significantly hinder detection accuracy in real-world scenarios. To address these challenges, we propose CEVG-RTNet, a real-time forest fire smoke detection architecture designed to enhance robustness under such complex conditions. CEVG-RTNet incorporates several novel components. The Spatial-Channel Priori Perceptual Convolution (SCPP-Conv) module improves the model's ability to localize smoke and perceive its morphology, even in low-contrast and high-transparency environments. The Hierarchical Residual Feature Alignment (HRFA) module addresses the challenge of multi-scale feature extraction by aligning local and large-scale smoke features through a residual-guided alignment strategy and multi-layer perceptron (MLP)-based aggregation. To further refine dynamic smoke detection, the Dynamic Recursive Feature Enhancement (DRFE) module applies recursive channel adaptive enhancement and cross-channel attention strategies. Additionally, Polygonal-Intersection over Union (PolyIoU) Loss, a novel loss function, is introduced to handle the morphological complexity of smoke regions. The architecture leverages a graph sparse attention mechanism to enhance accuracy without excessive computational cost. Experimental results demonstrate the effectiveness of CEVG-RTNet, with the variant CEVG-RTNet-n achieving 89.1% precision, 82.9% recall, mAP@0.5 of 89%, and mAP@0.5:0.95 of 58.9%. The model operates with 3.04M parameters, 6.6G FLOPs, and 99.42 FPS, showcasing its strong generalization, anti-interference capabilities, and suitability for complex forest fire smoke detection. The source code is available at: https://github.com/CNNanmuzi/CEVG-RTNet .},
  archive      = {J_NN},
  author       = {Jun Wang and Chunman Yan},
  doi          = {10.1016/j.neunet.2025.108187},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108187},
  shortjournal = {Neural Netw.},
  title        = {CEVG-RTNet: A real-time architecture for robust forest fire smoke detection in complex environments},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Synchronization of reaction-diffusion delayed inertial memristive neural networks via adaptive pinning control. <em>NN</em>, <em>194</em>, 108183. (<a href='https://doi.org/10.1016/j.neunet.2025.108183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The synchronization control problem of delayed inertial memristive neural networks (DIMNNs) with reaction-diffusion terms is addressed. First, by differential inclusions and a reduced-order approach to analyze the DIMNNs. Second, an adaptive pinning control method is introduced to achieve synchronization of drive-and-response systems. By applying inequality technology and Green’s Formula, a criterion is obtained to ensure the synchronization of DIMNNs with reaction-diffusion terms. Furthermore, the proposed control scheme requires fewer controlled nodes compared to the full-state feedback method, exhibits robustness against parameter uncertainties, and automatically adapts to varying network conditions. Finally, a numerical example is presented to confirm the theoretical results and demonstrate the effectiveness of the proposed approach.},
  archive      = {J_NN},
  author       = {Jiemei Zhao and Fenglin Wang},
  doi          = {10.1016/j.neunet.2025.108183},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108183},
  shortjournal = {Neural Netw.},
  title        = {Synchronization of reaction-diffusion delayed inertial memristive neural networks via adaptive pinning control},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-level teacher assistant-based knowledge distillation framework with dynamic feedback for motor imagery EEG decoding. <em>NN</em>, <em>194</em>, 108180. (<a href='https://doi.org/10.1016/j.neunet.2025.108180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has shown promise in motor imagery-based electroencephalogram (MI-EEG) decoding, a critical task in non-invasive brain-computer interfaces (BCIs). In response to the computational complexity of deep learning models to be deployed in practical BCI applications, knowledge distillation (KD) has emerged as a solution for model compression. However, vanilla KD methods struggle to effectively extract and transfer the abundant multi-level knowledge from MI-EEG signals under high compression ratios. This study proposes a novel knowledge distillation framework termed Motor Imagery Knowledge Distillation (MIKD), which compresses deep learning models for MI classification tasks while maintaining high performance. The MIKD framework consists of two key modules: (1) a multi-level teacher assistant knowledge distillation (ML-TAKD) module designed to extract and transfer local representations and global dependencies of MI-EEG signals from the complex teacher network to the much smaller student network, and (2) a dynamic feedback module that allows the teacher assistant to adjust its teaching strategy based on the student's learning progress. Extensive experiments on three public EEG datasets demonstrate that the MIKD framework achieves state-of-the-art performance. The proposed framework improves the baseline student model's accuracy by 6.61 %, 1.91 %, and 3.29 % on the three datasets, while reducing the model size by nearly 90 %.},
  archive      = {J_NN},
  author       = {Jinzhou Wu and Baoping Tang and Yi Wang and Cheng Li and Qichao Yang},
  doi          = {10.1016/j.neunet.2025.108180},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108180},
  shortjournal = {Neural Netw.},
  title        = {A multi-level teacher assistant-based knowledge distillation framework with dynamic feedback for motor imagery EEG decoding},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view spectral clustering algorithm based on bipartite graph and multi-feature similarity fusion. <em>NN</em>, <em>194</em>, 108177. (<a href='https://doi.org/10.1016/j.neunet.2025.108177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering remains a challenging task due to the heterogeneity and inconsistency across multiple views. Most esisting multi-view spectral clustering methods adopt a two-stage approch–constructing fused spectral embeddings matrix followed by k-means clustering–which often leads to information loss and suboptimal performance. Moreover, current graph and feature fusion strategies struggle to address view-specific discrepancies and label misalignment, while their high computational complexity hinders scalability to large datasets. To overcome these limitations, we propose a unified Multi-view Spectral Clustering algorithm based on Bipartite Graph and Multi-feature Similarity Fusion (BG-MFS). The proposed framework jointly integrates bipartite graph construction, multi-feature similarity fusion, and discrete clustering within a single optimization model, enabling mutual reinforcement among components. Furthermore, an entropy-based weighting mechanism is introduced to adaptively assess the contribution of each view. Extensive experiments demonstrate that BG-MFS consistently outperforms state-of-the-art methods in both clustering accuracy and computational efficiency.},
  archive      = {J_NN},
  author       = {Shunyong Li and Kun Liu and Mengjiao Zheng and Liang Bai},
  doi          = {10.1016/j.neunet.2025.108177},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108177},
  shortjournal = {Neural Netw.},
  title        = {Multi-view spectral clustering algorithm based on bipartite graph and multi-feature similarity fusion},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FTA2C: Achieving superior trade-off between accuracy and robustness in adversarial training. <em>NN</em>, <em>194</em>, 108176. (<a href='https://doi.org/10.1016/j.neunet.2025.108176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks are notoriously vulnerable to adversarial perturbations, largely due to the presence of non-robust features that destabilize model performance. Traditional Adversarial Training (AT) methods on feature space typically operate on one part of features individually, resulting in the loss of useful information in them, and improve robustness at the expense of accuracy, making it difficult to optimize the inherent trade-off between the two. To address this challenge, we propose a novel plug-in method termed Feature Transformation Alignment and Compression (FTA2C). FTA2C comprises three key components. First, a compression network constrains the perturbation space to reduce the vulnerability of non-robust features. Second, a feature transformation network enhances the expressiveness of robust features. Third, an alignment mechanism enforces consistency between adversarial and natural samples in the robust feature space. The above mechanism achieves co-processing of the two parts of the feature. Additionally, we propose the Defense Efficiency Metric (DEM) to evaluate defense methods. DEM quantifies the trade-off between maintaining natural accuracy and enhancing adversarial robustness, offering a unified and interpretable standard for comparing defense strategies. Extensive experiments conducted on four benchmark datasets demonstrate that FTA2C significantly improvements robustness under the high-level accuracy, resulting in superior trade-off performance. Our code is available at https://github.com/HymanGao31/FTA2C .},
  archive      = {J_NN},
  author       = {Zhenghan Gao and Chengming Liu and Yucheng Shi and Xin Guo and Jing Xu and Hong Zhang and Lei Shi},
  doi          = {10.1016/j.neunet.2025.108176},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108176},
  shortjournal = {Neural Netw.},
  title        = {FTA2C: Achieving superior trade-off between accuracy and robustness in adversarial training},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Anchor point segmentation based multi-view clustering. <em>NN</em>, <em>194</em>, 108175. (<a href='https://doi.org/10.1016/j.neunet.2025.108175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing bipartite graph based methods commonly learn a consistent anchor graph across multiple views utilizing various optimization techniques to determine clustering assignments, maintaining linear complexity w.r.t. the number of samples. Owing to their efficiency and effectiveness, these approaches have attracted significant attention. However, the inherent geometric relationship in which anchors and the raw data share common centroids remains under-explored, leaving room for potential improvements in algorithm efficiency. This relationship enables the use of anchors to efficiently learn clustering centroids. In this paper, we propose a novel multi-view clustering approach termed anchor point segmentation based multi-view clustering (APS-MVC). Specifically, we group the raw data by first assigning each data point to an anchor point, then to a centroid. This process is modeled as a two-step transition within a Markov chain, where the optimal centroids and the soft partition of anchors are learned simultaneously by encoding the graph structure information of the anchor points. Furthermore, the proposed APS-MVC effectively tackles the out-of-sample issue. The resultant optimization problem is solved efficiently, exhibiting square complexity w.r.t. the number of anchors. Experimental results on six benchmark datasets validate the effectiveness of the proposed method. The source code is available at: https://github.com/Wenhua-Dong/APS-MVC .},
  archive      = {J_NN},
  author       = {Wenhua Dong and Xiao-Jun Wu and Bo Fan},
  doi          = {10.1016/j.neunet.2025.108175},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108175},
  shortjournal = {Neural Netw.},
  title        = {Anchor point segmentation based multi-view clustering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-speed olfactory perception with adaptive load balancing based on a laser array reservoir computing architecture. <em>NN</em>, <em>194</em>, 108173. (<a href='https://doi.org/10.1016/j.neunet.2025.108173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the front-end information acquisition module of intelligent olfactory systems, the inherent cross-sensitivity of gas sensors presents a significant technical challenge. While sensor-array-based architectures have been established as an effective solution to address this limitation, the requirements for real-time detection in gas identification and concentration quantification have introduced a new challenge: the intrinsic multi-channel information processing demands of array systems lead to a dramatic increase in computational complexity. In this work, we propose a photonic reservoir computing (RC) method for high-speed mixed gases olfactory perception, by leveraging the nonlinear mapping properties of semiconductor lasers and the inherent high-speed parallelism and low-energy characteristics of optical computing. A dimensional segmentation mechanism for multidimensional signals based on semiconductor laser arrays has been developed. By constructing a parallel PRC architecture, this mechanism enables distributed processing of multidimensional signals from gas sensor arrays, achieving adaptive matching between the number of activated lasers in the array and the internal feature dimensions required for computational load balancing. Numerical results indicate that the proposed system achieves high accuracy in gas classification tasks and concentration prediction performance comparable to current mainstream algorithms. This confirms the significant advantages of laser-array-based reservoirs in processing multivariable sensor data. The results provide a theoretical foundation for the development of physical RC systems oriented toward low-power rapid detection of mixed gases. With integration and miniaturization of photonic technologies, it is promising to build miniaturized brain-inspired computing systems with rapid inference capability and dynamic adaptability, thus contributing to the advancement of electronic nose technology.},
  archive      = {J_NN},
  author       = {Guizheng Guan and Bin Liu},
  doi          = {10.1016/j.neunet.2025.108173},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108173},
  shortjournal = {Neural Netw.},
  title        = {High-speed olfactory perception with adaptive load balancing based on a laser array reservoir computing architecture},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Output-based sampled-data control of signed networks via parametric lyapunov equations approach. <em>NN</em>, <em>194</em>, 108169. (<a href='https://doi.org/10.1016/j.neunet.2025.108169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is dedicated to demonstrating the influence of leaders on followers in signed networks with antagonistic interactions, where leaders have their own dynamics and interact with other leaders in a strongly connected closed subgraph (SCCC). An output-based distributed sampled-data protocol is designed to comprehensively analyze and assess the impact exerted by leaders on followers, where a heterogeneous sampled-data state observer associated with each agent is developed. The sampled-data control gain is then explicitly calculated via the solutions of parametric Lyapunov equations, enabling more flexible sampling intervals than classical Lyapunov equations. It is demonstrated that leaders in the structurally balanced SCCCs will reach bipartite consensus, and all followers eventually fall within a region that is precisely delineated by the states of these leaders and their corresponding opposite states. For structurally unbalanced graphs, leaders in unbalanced SCCCs reach neutrality, while follower states depend only on leaders in balanced SCCCs. The validity of the theoretical results is verified through simulation tests.},
  archive      = {J_NN},
  author       = {Wenbing Zhang and Abuzar Hussein Mohammed Atitalla and Luyang Yu and Tingwen Huang},
  doi          = {10.1016/j.neunet.2025.108169},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108169},
  shortjournal = {Neural Netw.},
  title        = {Output-based sampled-data control of signed networks via parametric lyapunov equations approach},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EEG-CLIP: A transformer-based framework for EEG-guided image generation. <em>NN</em>, <em>194</em>, 108167. (<a href='https://doi.org/10.1016/j.neunet.2025.108167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decoding visual perception from neural signals represents a fundamental step toward advanced brain-computer interfaces (BCIs), where functional magnetic resonance imaging (fMRI) has shown promising results despite practical constraints in deployment and costs. Electroencephalography (EEG), with its superior temporal resolution, portability, and cost-effectiveness, emerges as a promising alternative for real-time brain-computer interface (BCI) applications. While existing EEG-based approaches have advanced neural decoding capabilities, they remain constrained by inadequate architectural designs, limited reconstruction fidelity, and inconsistent evaluation protocols. To address these challenges, we present EEG-CLIP, a novel Transformer-based framework that systematically addresses each limitation: (1) We introduce a specialized EEG-ViT encoder that adeptly captures the spatial and temporal characteristics of EEG signals to augment model capacity, along with a Diffusion Prior Transformer architecture to approximate the image feature distribution. (2) We employ a dual-stage reconstruction pipeline that integrates class contrastive learning and pretrained diffusion models to enhance visual reconstruction quality. (3) We establish comprehensive evaluation protocols across multiple datasets. Our framework operates through two stages: first projecting EEG signals into CLIP image space via class contrastive learning and refining them into image priors, then reconstructing perceived images through a pretrained conditional diffusion model. Comprehensive empirical analysis, including temporal window sensitivity studies and regional brain activation visualization, demonstrates the framework’s robustness. We demonstrate through ablations that EEG-CLIP’s performance improvements over previous methods result from specialized architecture for EEG encoding and improved training techniques. Quantitative and qualitative evaluations on ThingsEEG and Brain2Image datasets establish EEG-CLIP’s state-of-the-art performance in both classification and reconstruction tasks, advancing neural signal-based visual decoding capabilities.},
  archive      = {J_NN},
  author       = {Xuhao Cao and Peiliang Gong and Liying Zhang and Daoqiang Zhang},
  doi          = {10.1016/j.neunet.2025.108167},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108167},
  shortjournal = {Neural Netw.},
  title        = {EEG-CLIP: A transformer-based framework for EEG-guided image generation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Necessary and sufficient knowledge enhanced collaborative logical reasoning in LLMs. <em>NN</em>, <em>194</em>, 108164. (<a href='https://doi.org/10.1016/j.neunet.2025.108164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) learn massive knowledge through pre-training, and they have demonstrated strong reasoning capabilities by leveraging the knowledge. However, LLMs often make mistakes due to the failure of using necessary and sufficient knowledge. The inadequate utilization of sufficient knowledge will lead to the incorrect conclusions due to the lack of important evidence. Unnecessary knowledge may mislead the LLMs into generating false reasoning paths. To tackle the above challenges, we propose a collaborative logical reasoning framework called CLR. We first utilize deductive reasoning based on evidence retrieval to generate reasoning paths. Next, we use abductive reasoning based on knowledge attribution to identify the necessary conditions. Then we use necessary conditions to verify the correctness of reasoning paths and obtain reliable reasoning paths. Finally, we conduct reliable inductive reasoning to obtain the final reasoning conclusion. Therefore, CLR achieves the collaboration of multiple logical reasoning paradigms. Extensive experiments demonstrate that CLR outperforms a series of baselines on multiple datasets. It also performs well in error identification and self-correction. Our work contributes to remedy the inherent limitations of the logical reasoning paradigms in LLMs and lays the foundation for modeling human cognitive thinking.},
  archive      = {J_NN},
  author       = {Peng Wang and Xiao Ding and Kai Xiong and Bing Qin and Ting Liu},
  doi          = {10.1016/j.neunet.2025.108164},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108164},
  shortjournal = {Neural Netw.},
  title        = {Necessary and sufficient knowledge enhanced collaborative logical reasoning in LLMs},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Linear convergence of proximal gradient method for linear sparse SVM. <em>NN</em>, <em>194</em>, 108162. (<a href='https://doi.org/10.1016/j.neunet.2025.108162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the hinge loss function being non-strongly-convex and non-strongly smooth, we establish the linear rate of convergence for sparse linear support vector machines (SVM) up to its statistical accuracy. The algorithm we use is the proximal gradient method for composite functions, applied to a sequence of regularization parameters to compute the approximate solution path on a grid. Unlike works on loss functions that are strongly convex and strongly smooth, here we do not have linear convergence to the exact solution, but we can demonstrate linear convergence to the population truth up to the statistical error (in particular, we simultaneously consider numerical convergence and statistical convergence). For any regularization parameter in the chosen decreasing sequence, we show that the estimator is in a small neighborhood of the exact solution after O ( log s * ) iterations, where s * is the sparsity of the true coefficient in the model, and a total number of O ( log n ) stages (i.e., using a sequence of regularization parameters of length O ( log n ) ) are required to achieve the near-oracle statistical rate, with n the sample size.},
  archive      = {J_NN},
  author       = {Xiaoqi Jiao and Heng Lian and Jiamin Liu and Yingying Zhang},
  doi          = {10.1016/j.neunet.2025.108162},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108162},
  shortjournal = {Neural Netw.},
  title        = {Linear convergence of proximal gradient method for linear sparse SVM},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fine-tuning large language models in federated learning with fairness-aware prompt selection. <em>NN</em>, <em>194</em>, 108160. (<a href='https://doi.org/10.1016/j.neunet.2025.108160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) require domain-specific fine-tuning for real-world deployment, yet face critical barriers of data privacy and computational constraints. Federated learning (FL) provides an indispensable solution by enabling collaborative tuning across distributed private data sources while preserving confidentiality. However, existing FL-LLM methods suffer from non-IID degradation, communication overhead, and fairness issues. To address these challenges, this paper proposes FedPSF-LLM, a novel FL framework integrating three core innovations: (1) the Prompt Selection Module (PSM) adaptively selects high-impact prompt parameters to reduce transmission costs; (2) the Dynamic Weighting Module (DWM) adjusts aggregation weights based on client contribution and data disparity; (3) the Attention-Based Bias Mitigation (ABM) corrects aggregation bias via alignment-aware reweighting. Extensive experiments on 10 NLP tasks and 4 LLMs demonstrate that FedPSF-LLM improves fairness while maintaining strong overall performance. Compared to state-of-the-art methods, it reduces accuracy variance by 52.1 %, improves worst-client accuracy by 8.6 %, and narrows small-large client performance gaps by 74.4 %, while maintaining 76.8 % global accuracy. These results demonstrate superiority over 8 baselines in both fairness metrics and communication efficiency, establishing a new paradigm for privacy-preserving and fairness-guaranteed LLM deployment in federated systems.},
  archive      = {J_NN},
  author       = {Yalan Jiang and Zhongliang Li and Bin Song},
  doi          = {10.1016/j.neunet.2025.108160},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108160},
  shortjournal = {Neural Netw.},
  title        = {Fine-tuning large language models in federated learning with fairness-aware prompt selection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Small sphere and large margin support tensor machines for imbalanced tensor data classification. <em>NN</em>, <em>194</em>, 108158. (<a href='https://doi.org/10.1016/j.neunet.2025.108158'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The small sphere and large margin approach (SSLM) is a representative learning algorithm for handling imbalanced data classification problems. However, it is only effective for the vector data, and not suitable for the tensor data. How to build a novel model for the imbalanced tensor data is a challenge. In this paper, a small sphere and large margin support tensor machine (SSLMSTM) is proposed by taking full advantage of the structural information of tensor data. Its basic idea is to construct two concentric hyperspheres, whose centers are represented by a rank-1 tensor. The small hypersphere captures as many normal training samples (positive samples) as possible, while most outliers (negative samples) are pushed out of the large hypersphere. It can obtained great performance by increasing the margin of two hyperspheres. Furthermore, we extend SSLMSTM to a higher rank R case, named HR-SSLMSTM. Above two models can be solved by CANDECOMP/PARAFAC decomposition and alternating iteration method. Experiments on multiple datasets are conducted to verify the validity of our proposed SSLMSTM and HR-SSLMSTM.},
  archive      = {J_NN},
  author       = {Hexuan Liu and Xiao Li and Yitian Xu},
  doi          = {10.1016/j.neunet.2025.108158},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108158},
  shortjournal = {Neural Netw.},
  title        = {Small sphere and large margin support tensor machines for imbalanced tensor data classification},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Consistency-regularized graph neural networks for molecular property prediction. <em>NN</em>, <em>194</em>, 108157. (<a href='https://doi.org/10.1016/j.neunet.2025.108157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although graph neural networks (GNNs) have proven powerful in molecular property prediction tasks, they tend to underperform when trained on small datasets. Conventional data augmentation strategies are generally ineffective in this context, as simply perturbing molecular graphs can unintentionally alter their intrinsic properties. In this study, we propose a consistency-regularized graph neural network (CRGNN) method to better utilize molecular graph augmentation during training. We apply molecular graph augmentation to obtain strongly and weakly-augmented views for each molecular graph. By incorporating a consistency regularization loss into the learning objective, the GNN is encouraged to learn representations such that the strongly-augmented views of a molecular graph are mapped close to a weakly-augmented view of the same graph. In doing so, molecular graph augmentation can contribute to improving the prediction performance of the GNN while mitigating its negative effects. Through experimental evaluation on various molecular benchmark datasets, we demonstrate that the proposed method outperforms existing methods that leverage molecular graph augmentation, especially when the training dataset is smaller.},
  archive      = {J_NN},
  author       = {Jongmin Han and Seokho Kang},
  doi          = {10.1016/j.neunet.2025.108157},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108157},
  shortjournal = {Neural Netw.},
  title        = {Consistency-regularized graph neural networks for molecular property prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LLM-led vision-spectral fusion: A zero-shot approach to temporal fruit image classification. <em>NN</em>, <em>194</em>, 108155. (<a href='https://doi.org/10.1016/j.neunet.2025.108155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A zero-shot multimodal framework for temporal image classification is proposed, targeting automated fruit quality assessment. The approach leverages large language models for expert-level semantic description generation, which guides zero-shot object detection and segmentation through GLIP and SAM models. Visual features and spectral data are fused to capture both external appearance and internal biochemical properties of fruits. Experiments on the newly constructed Avocado Freshness Temporal-Spectral dataset—comprising daily synchronized images and spectral measurements across the full spoilage lifecycle—demonstrate reductions in mean squared error by up to 33 % and mean absolute error by up to 17 % compared to established baselines. These results validate the effectiveness and generalizability of the framework for temporal image analysis in smart agriculture and food quality monitoring.},
  archive      = {J_NN},
  author       = {Huyu Wu and Bowen Jia and Xue–Ming Yuan},
  doi          = {10.1016/j.neunet.2025.108155},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108155},
  shortjournal = {Neural Netw.},
  title        = {LLM-led vision-spectral fusion: A zero-shot approach to temporal fruit image classification},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cascading size-dependent deep propagation (CADP): Addressing over-smoothing in graph few-shot dermatology classification. <em>NN</em>, <em>194</em>, 108154. (<a href='https://doi.org/10.1016/j.neunet.2025.108154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs play a critical role in capturing complex data relationships, particularly in few-shot learning tasks. However, one of the major challenges in graph-based models, such as Graph Neural Networks (GNNs), is the issue of over-smoothing, which diminishes the discriminative power of node representations. This problem arises when GNNs aggregate information from too large a neighborhood, leading to homogenization of node features. To overcome this limitation, we propose Cascading Size-Dependent Deep Propagation (CADP) , a novel approach designed to mitigate over-smoothing in graph-based few-shot learning, with a particular focus on improving skin disease classification. The model constructs the graph by employing a convolutional neural network (CNN) to extract feature representations from a small set of support and query images, where the nodes represent the extracted features, and the edges reflect the similarity between them. To improve feature representation and prevent over-smoothing, the model decouples the feature propagation process from the neural network to avoid repeated nonlinear transformations that lead to over-smoothing, enabling deeper information flow while preserving discriminative features. Then the initial support labels are integrated with the early prediction labels of query images, which are generated by a Multi-Layer Perceptron (MLP). Furthermore, this aggregated data is optimized through deep label propagation, which leverages the underlying graph structure to enhance classification accuracy. The propagation depths are controlled by the hyperparameters K 1 and K 2 , which are determined based on graph size, to regulate how extensively features and labels are propagated. We evaluate our approach on three dermatology datasets: ISIC 2018, Derm7pt, and SD-198, achieving 78.3 %, 79.29 %, and 91.92 % accuracy, respectively, in the 2-way 5-shot setting. CADP outperforms existing methods on all datasets, demonstrating its effectiveness in skin disease classification.},
  archive      = {J_NN},
  author       = {Abdulrahman Noman and Zou Beiji and Chengzhang Zhu and Mohammed Al-Habib and Ahmed Alasri},
  doi          = {10.1016/j.neunet.2025.108154},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108154},
  shortjournal = {Neural Netw.},
  title        = {Cascading size-dependent deep propagation (CADP): Addressing over-smoothing in graph few-shot dermatology classification},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Progressive multi-branch video style transfer network via confidence reweighted projection. <em>NN</em>, <em>194</em>, 108153. (<a href='https://doi.org/10.1016/j.neunet.2025.108153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving temporal consistency in video content poses a significant challenge for high-quality video styling. Unfortunately, current video style transfer techniques often amplify the differences between frames in the input video, leading to unsmooth transitions between the stylized video frames. This can lead to visual flickering and discontinuities over time. Besides, the lack of style consistency between video frames or between different modes can make the overall style of the video appear fragmented or unnatural. To address these issues, this paper introduces an innovative real-time, end-to-end model for video style transfer,named as Progressive Multi-Branch Video Style Transfer Network (PMBNet). The primary focus is on introducing a Multi-layer Branch Semantic Transformation Structure (MBSTS), which comprises a multi-scale feature extraction layer featuring a multi-parallel progressive sub-modules (MPP), as well as a multi-level feature fusion layer that includes multiple channel spatial attention sub-modules (CSA). Among them, the MPP sub-modules use progressively dilated convolutions to enlarge the receptive field and mitigate grid artifacts, enabling the model to capture temporal and spatial dependencies, improving temporal consistency and reducing flickering between frames. The CSA sub-modules fuse content and style features across branches, ensuring multi-scale extraction and consistent style application, which resolves style fragmentation and ensures smooth transitions and consistency across frames and video modes. Additionally, a confidence reweighted calculation is employed to choose a dominant pattern from several potential options, ensuring consistency in modal content structure and preserving perceptual quality. Comprehensive evaluation demonstrates that PMBNet surpasses the performance of current state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Kunbo Han and Hongyan Yin and Junpeng Tan and Chongzhi Gao and Chunmei Qing},
  doi          = {10.1016/j.neunet.2025.108153},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108153},
  shortjournal = {Neural Netw.},
  title        = {Progressive multi-branch video style transfer network via confidence reweighted projection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial-spectral multi-order gated aggregation network with bidirectional interactive fusion for hyperspectral image classification. <em>NN</em>, <em>194</em>, 108152. (<a href='https://doi.org/10.1016/j.neunet.2025.108152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, convolutional neural networks (CNNs) have made significant strides in hyperspectral image classification (HSIC) tasks by contextualizing the convolutional kernels as global as possible. However, as the kernel sizes increase, encoding multi-order feature interactions becomes less efficient. Furthermore, self-attention mechanisms and convolutional operations can only handle global and local features independently, resulting in overly complex or simplified interactions. To overcome these limitations, in this work, we propose a novel HSIC framework called the Spatial-Spectral Multi-order Gated Aggregation Network with Bidirectional Interaction Fusion (SS-MoGAN). The proposed SS-MoGAN method integrates simple yet powerful convolutions and gated aggregations into a compact module, facilitating efficient feature extraction and adaptive contextual processing. Specifically, the spatial aggregation (SpaAg) and spectral aggregation (SpeAg) blocks guide the model to explicitly capture the interactions between low- and high-order features within the spatial and spectral dimensions. The bidirectional interaction fusion (BIF) blocks further integrate structural information through a bidirectional cross-attention mechanism, enhancing the representation of fine-grained details. Extensive experiments on three hyperspectral benchmark datasets demonstrate that the proposed SS-MoGAN method outperforms other state-of-the-art methods in HSIC applications. The source code for this work is available at https://github.com/szq0816/SS-MoGAN_HSIC .},
  archive      = {J_NN},
  author       = {Mingzhu Tai and Zhenqiu Shu and Songze Tang and Zhengtao Yu},
  doi          = {10.1016/j.neunet.2025.108152},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108152},
  shortjournal = {Neural Netw.},
  title        = {Spatial-spectral multi-order gated aggregation network with bidirectional interactive fusion for hyperspectral image classification},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep adaptive fusion network with multimodal neuroimaging information for MDD diagnosis: An open data study. <em>NN</em>, <em>194</em>, 108151. (<a href='https://doi.org/10.1016/j.neunet.2025.108151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuroimaging offers powerful evidence for the automated diagnosis of major depressive disorder (MDD). However, discrepancies across imaging modalities hinder the exploration of cross-modal interactions and the effective integration of complementary features. To address this challenge, we propose a supervised Deep Adaptive Fusion Network (DAFN) that fully leverages the complementarity of multimodal neuroimaging information for the diagnosis of MDD. Specifically, high- and low-frequency features are extracted from the images using a customized convolutional neural network and multi-head self-attention encoders, respectively. A modality weight adaptation module dynamically adjusts the contribution of each modality during training, while a progressive information reinforcement training strategy reinforces multimodal fusion features. Finally, the performance of the DAFN is evaluated on both the open-access dataset and the recruited dataset. The results demonstrate that DAFN achieves competitive performance in multimodal neuroimaging fusion for the diagnosis of MDD. The source code is available at: https://github.com/TTLi1996/DAFN .},
  archive      = {J_NN},
  author       = {Tongtong Li and Kai Li and Ziyang Zhao and Qi Sun and Xinyan Zhang and Zhijun Yao and Jiansong Zhou and Bin Hu},
  doi          = {10.1016/j.neunet.2025.108151},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108151},
  shortjournal = {Neural Netw.},
  title        = {Deep adaptive fusion network with multimodal neuroimaging information for MDD diagnosis: An open data study},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MSA-LR: Enhancing multi-scale temporal dynamics in multivariate time series forecasting with low-rank self-attention. <em>NN</em>, <em>194</em>, 108150. (<a href='https://doi.org/10.1016/j.neunet.2025.108150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately forecasting multivariate time series requires effectively capturing intricate temporal dependencies across diverse scales. Existing deep learning models, while promising, often fall short in this regard. Recurrent architectures like LSTMs struggle with long-range dependencies crucial for multi-scale modeling, while standard Transformers, despite employing attention mechanisms, fail to explicitly differentiate the importance of distinct periodicities, treating all time steps within a fixed window with similar relevance. This limitation hinders their ability to leverage the rich hierarchical structure of real-world time series, particularly in long-term forecasting scenarios. This paper introduces MSA-LR (Multi-Scale Self-Attention with Low-Rank Approximation), a novel architecture explicitly designed to capture multi-scale temporal dynamics. MSA-LR leverages a learnable scale weight matrix and low-rank approximations to directly model the influence of different temporal granularities (e.g., hourly, daily, weekly). This approach not only allows for fine-grained control over multi-scale interactions but also significantly reduces computational complexity compared to standard self-attention, enabling efficient processing of long time series. Empirical evaluations on diverse datasets, including electricity load, traffic flow, and air quality, demonstrate that MSA-LR achieves competitive performance compared to state-of-the-art methods, exhibiting notable improvements in long-term forecasting accuracy. Further analysis reveals MSA-LR's ability to discern and leverage periodic patterns at various resolutions, confirming its effectiveness in capturing the rich multi-scale temporal structure of real-world time series data.},
  archive      = {J_NN},
  author       = {Jie Sun and Zhilin Sun and Zhongshan Chen and Mengyang Dong and Xiaozheng Wang and Changwei Chen and Hao Zheng and Xiangjun Zhao},
  doi          = {10.1016/j.neunet.2025.108150},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108150},
  shortjournal = {Neural Netw.},
  title        = {MSA-LR: Enhancing multi-scale temporal dynamics in multivariate time series forecasting with low-rank self-attention},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-head prediction and reconstruction with coarse-to-fine masks for visual reinforcement learning. <em>NN</em>, <em>194</em>, 108149. (<a href='https://doi.org/10.1016/j.neunet.2025.108149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In situations of limited experience and high-dimensional input data, effective representation learning plays a vital role in enabling visual reinforcement learning (RL) to excel in diverse tasks. To better leverage the agent’s sampled trajectory during the training process, we introduce the DPRM approach, which involves a D ual-head P rediction and R econstruction task with coarse-to-fine M asks in RL. The DPRM method tackles these challenges through integration of coarse-to-fine masks with a dual-head prediction-reconstruction (DHPR) architecture, complemented by a coordinate-based spatial coding strategy (CSCS). The CSCS enhances the spatial information of the observation state, facilitating the capture of motion changes between continuous context states. Furthermore, the coarse-to-fine masks gradually refine, guiding the following DHPR model to learn essential features and semantics more effectively. Built on a transformer architecture, DHPR introduces a novel triplet input token comprising two consecutive actions paired with an observation state. This design facilitates bidirectional prediction of past and future states from temporal extremities while efficiently reconstructing masked latent features throughout state sequences. Experimental results on both multiple continuous control (DeepMind Control Suite benchmarks) and discrete control (Atari) tasks demonstrate that the DPRM algorithm significantly enhances performance, leading to higher reward accumulation and faster convergence. Code is available at here .},
  archive      = {J_NN},
  author       = {Yun Zhou and Yuqiang Wu and Qiaoyun Wu and Chunyu Tan and Shu Zhan and Richang Hong},
  doi          = {10.1016/j.neunet.2025.108149},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108149},
  shortjournal = {Neural Netw.},
  title        = {Dual-head prediction and reconstruction with coarse-to-fine masks for visual reinforcement learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PepHarmony: A multi-view contrastive learning framework for integrated sequence and structure-based peptide representation. <em>NN</em>, <em>194</em>, 108148. (<a href='https://doi.org/10.1016/j.neunet.2025.108148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide representation task. PepHarmony innovatively combines sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank and AlphaFold DB to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The training strategies and the pre-trained PepHarmony model serve as helpful contributions to peptide representations, and offer valuable insights for future applications in peptide drug discovery and peptide engineering.},
  archive      = {J_NN},
  author       = {Ruochi Zhang and Haoran Wu and Chang Liu and Huaping Li and Yuqian Wu and Kewei Li and Yifan Wang and Yifan Deng and Jiahui Chen and Fengfeng Zhou and Xin Gao},
  doi          = {10.1016/j.neunet.2025.108148},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108148},
  shortjournal = {Neural Netw.},
  title        = {PepHarmony: A multi-view contrastive learning framework for integrated sequence and structure-based peptide representation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Lena-TRNN: Exploring energy flow for time series prediction. <em>NN</em>, <em>194</em>, 108147. (<a href='https://doi.org/10.1016/j.neunet.2025.108147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on exploring the inherent energy flow for time series prediction in this paper, i.e., we consider the inherent energy of time series data as a sequence measuring properties such as fluctuations, oscillations, and trends. Distinctive with main-stream methods that adopt complex architecture to capture the presentative data relation, this brand-new perspective allows us to better differentiate the underlying distribution of the time-series data. Concretely, we design a novel decoder-free architecture, L atent- en ergy- a ware Transformer Recurrent Neural Network (Lena-TRNN), for multivariate time series forecasting and imputation. The new network tends to assign low energy scores to the samples belonging to the in-distribution dataset, and high energy scores otherwise, which is in accordance with the law of natural change. Predicted samples can be readily obtained by iterating gradient-based optimization along the direction of energy minimization to explicitly learn the inherent energy flow. With the energy optimization modelling, our proposed method exhibits superior performance to many other competitive methods and attains state-of-the-art performance in many benchmark time series forecasting and imputation tasks. The code is available at https://github.com/PengleiGao/Lena-TRNN .},
  archive      = {J_NN},
  author       = {Penglei Gao and Rui Zhang and Xi Yang and Zhuang Qian and Kaizhu Huang},
  doi          = {10.1016/j.neunet.2025.108147},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108147},
  shortjournal = {Neural Netw.},
  title        = {Lena-TRNN: Exploring energy flow for time series prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforcement learning with formation energy feedback for material diffusion models. <em>NN</em>, <em>194</em>, 108146. (<a href='https://doi.org/10.1016/j.neunet.2025.108146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models are emerging as foundation tools for the discovery of new materials with remarkable efficiency. Existing works introduce physical constraints during the generation process of diffusion models to improve the quality of the generated crystals. However, it is difficult to accurately capture the distribution of stable crystal material structures, given the complex periodic crystal structure and the limited available crystal material data, even with the incorporation of symmetries and other domain-specific knowledge. Thus, these models still struggle to achieve a high success rate in producing stable crystal materials. To further improve the stability of generative crystal materials, we propose a novel fine-tuning framework RLFEF. We formulate the material diffusion process as a Markov Decision Process with formation energy serving as rewards. Moreover, we prove that optimizing the expected return in reinforcement learning is equivalent to applying policy gradient updates to a diffusion model. Additionally, we prove that the fine-tuned model adheres to the unique symmetry of crystal materials. Extensive experiments are conducted on three real-world datasets. The results show that our model achieves state-of-the-art performance on most tasks related to property optimization, ab initio generation, crystal structure prediction, and material generation.},
  archive      = {J_NN},
  author       = {Jiao Huang and Qianli Xing and Jinglong Ji and Bo Yang},
  doi          = {10.1016/j.neunet.2025.108146},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108146},
  shortjournal = {Neural Netw.},
  title        = {Reinforcement learning with formation energy feedback for material diffusion models},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hölder network for improved adversarial robustness. <em>NN</em>, <em>194</em>, 108145. (<a href='https://doi.org/10.1016/j.neunet.2025.108145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A small Lipschitz constant can help improve robustness and generalization by restricting the sensitivity of the model to input perturbations. However, overly aggressive constraints may also limit the network’s ability to approximate complex functions. In this paper, we propose the Hölder network, a novel architecture utilizing α -rectified power units ( α -RePU). This framework generalizes Lipschitz-constrained networks by enforcing α -Hölder continuity. We theoretically prove that α -RePU networks are universal approximators of Hölder continuous functions, thereby offering greater flexibility than models with hard Lipschitz constraints. Empirical results show that the Hölder network achieves comparable accuracy and superior adversarial robustness against a wide range of attacks (e.g., PGD and l ∞ ) on both image classification and tabular data benchmarks.},
  archive      = {J_NN},
  author       = {Dazhi Zhao and Haiyan Li and Qin Luo and Wenguang Hu},
  doi          = {10.1016/j.neunet.2025.108145},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108145},
  shortjournal = {Neural Netw.},
  title        = {Hölder network for improved adversarial robustness},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A one-layer recurrent neural network for robust linear programming subject to l∞ norm uncertainty. <em>NN</em>, <em>194</em>, 108144. (<a href='https://doi.org/10.1016/j.neunet.2025.108144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust optimization problems subject to norm uncertainty appear in numerous applications in various fields such as engineering, logistics, and finance. Despite its importance, robust optimization algorithms face significant computational challenges for solving high-dimensional problems, limiting their practical use. This paper presents a neurodynamic approach to mitigate these challenges by transforming the robust linear programming to a non-smooth convex optimization through parameter elimination. A one-layer projection neural network with proven stability and convergence is proposed to solve the non-smooth optimization problem. The effectiveness of this approach is validated based on simulations of numerical examples and applications in reactor design and wastewater treatment.},
  archive      = {J_NN},
  author       = {Jin Hu and Keying Zhou and Jun Wang},
  doi          = {10.1016/j.neunet.2025.108144},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108144},
  shortjournal = {Neural Netw.},
  title        = {A one-layer recurrent neural network for robust linear programming subject to l∞ norm uncertainty},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Implicit graph neural networks with flexible propagation operators. <em>NN</em>, <em>194</em>, 108143. (<a href='https://doi.org/10.1016/j.neunet.2025.108143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the capability to capture high-order information of nodes and reduce memory consumption, implicit graph neural networks have become an explored hotspot in recent years. However, these implicit graph neural networks are limited by the static topology, which makes it difficult to handle heterophilic graph-structured data. Furthermore, the existing methods inspired by optimization problem are limited by the explicit structure of graph neural networks, which makes it difficult to set an appropriate number of network layers to solve optimization problems. To address these issues, we propose an implicit graph neural network with flexible propagation operators in this paper. From the optimization objective function, we derive an implicit message passing formula with flexible propagation operators. Compared to the static operator, the proposed method that joints the dynamic semantic and topology of data is more applicable to heterophilic graphs. Moreover, the proposed model performs a fixed-point iterative process for the optimization of the objective function, which implicitly adjusts the number of network layers without requiring sufficient prior knowledge. Extensive experiment results demonstrate the superiority of the proposed model.},
  archive      = {J_NN},
  author       = {Yueyang Pi and Yang Huang and Yongquan Shi and Fuhai Chen and Shiping Wang},
  doi          = {10.1016/j.neunet.2025.108143},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108143},
  shortjournal = {Neural Netw.},
  title        = {Implicit graph neural networks with flexible propagation operators},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards out-of-distribution detection using gradient vectors. <em>NN</em>, <em>194</em>, 108142. (<a href='https://doi.org/10.1016/j.neunet.2025.108142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying Deep Learning algorithms in the real world requires some care that is generally not considered in the training procedure. In real-world scenarios, where the input data cannot be controlled, it is important for a model to identify when a sample does not belong to any known class. This is accomplished using out-of-distribution (OOD) detection, a technique designed to distinguish unknown samples from those that belong to the in-distribution classes. These methods mainly rely on output or intermediate features to calculate OOD scores, but the gradient space is still under-explored for this task. In this work, we propose a new family of methods using gradient features, named GradVec, using the gradient space as input representation for different OOD detection methods. The main idea is that the model gradient presents, in a more informative way, the knowledge that a sample belongs to a known class, being able to distinguish it from other unknown ones. GradVec methods do not change the model training procedure and no additional data is needed to adjust the OOD detector, and it can be used on any pre-trained model. Our approach presents superior results in different scenarios for OOD detection in image classification and text classification, reducing FPR95 up to 26.67 % and 21.29 %, respectively.},
  archive      = {J_NN},
  author       = {Thiago Carvalho and Marley Vellasco and José Franco Amaral},
  doi          = {10.1016/j.neunet.2025.108142},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108142},
  shortjournal = {Neural Netw.},
  title        = {Towards out-of-distribution detection using gradient vectors},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph-patchformer: Patch interaction transformer with adaptive graph learning for multivariate time series forecasting. <em>NN</em>, <em>194</em>, 108140. (<a href='https://doi.org/10.1016/j.neunet.2025.108140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series (MTS) forecasting plays a pivotal role in the digitalization and intelligent development of modern society, while previous MTS forecasting methods based on deep learning often rely on capturing intra-series dependencies for modeling, neglecting the structural information within MTS and failing to consider inter-series local dynamic dependencies. Although some approaches utilize multi-scale representation learning to capture inter-series dynamic dependencies at different time scales, they still require additional multi-scale feature fusion modules to output the multi-scale representation of final forecasting results. In this paper, we propose a novel deep learning framework called Graph-Patchformer, which leverages structural encodings to reflect the structural information within MTS while capturing intra-series dependencies and inter-series local dynamic dependencies using the Patch Interaction Blocks we proposed. Specifically, Graph-Patchformer embeds structural encodings into MTS to reflect the inter-series relationships and temporal variations within the MTS. The embedded data is subsequently fed into the Patch Interaction Blocks through a patching operation. Within the Patch Interaction Blocks, the multi-head self-attention mechanism and adaptive graph learning module are employed to capture intra-series dependencies and inter-series local dynamic dependencies. In this way, Graph-Patchformer not only facilitates interactions between different patches within a single series but also enables cross-time-window interactions between patches of different series. The experimental results show that the Graph-Patchformer outperforms the state-of-the-art approaches and exhitits significant forecasting performance compared to several state-of-the-art methods across various real-world benchmark datasets. The code will be available at this repository: https://github.com/houchunyiPhd/Graph-Patchformer/tree/main},
  archive      = {J_NN},
  author       = {Chunyi Hou and Yongchuan Yu and Jinquan Ji and Siyao Zhang and Xumeng Shen and Jianzhuo Yan},
  doi          = {10.1016/j.neunet.2025.108140},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108140},
  shortjournal = {Neural Netw.},
  title        = {Graph-patchformer: Patch interaction transformer with adaptive graph learning for multivariate time series forecasting},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LLM-augmented entity alignment: An unsupervised and training-free framework. <em>NN</em>, <em>194</em>, 108139. (<a href='https://doi.org/10.1016/j.neunet.2025.108139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment (EA) is a fundamental task in knowledge graph (KG) integration, aiming to identify equivalent entities across different KGs for a unified and comprehensive representation. Recent advances have explored pre-trained language models (PLMs) to enhance the semantic understanding of entities, achieving notable improvements. However, existing methods face two major limitations. First, they rely heavily on human-annotated labels for training, leading to high computational costs and poor scalability. Second, some approaches use large language models (LLMs) to predict alignments in a multi-choice question format, but LLM outputs may deviate from expected formats, and predefined options may exclude correct matches, leading to suboptimal performance. To address these issues, we propose LEA, an LLM-augmented entity alignment framework that eliminates the need for labeled data and enhances robustness by mitigating information heterogeneity at both embedding and semantic levels. LEA first introduces an entity textualization module that transforms structural and textual information into a unified format, ensuring consistency and improving entity representations. It then leverages LLMs to enrich entity descriptions, enhancing semantic distinctiveness. Finally, these enriched descriptions are encoded into a shared embedding space, enabling efficient alignment through text retrieval techniques. To balance performance and computational cost, we further propose a selective augmentation strategy that prioritizes the most ambiguous entities for refinement. Experimental results on both homogeneous and heterogeneous KGs demonstrate that LEA outperforms existing models trained on 30 % labeled data, achieving a 30 % absolute improvement in Hit@1 score. As LLMs and text embedding models advance, LEA is expected to further enhance EA performance, providing a scalable and robust paradigm for practical applications. The code and dataset can be found at https://github.com/Longmeix/LEA .},
  archive      = {J_NN},
  author       = {Meixiu Long and Jiahai Wang and Junxiao Ma and Jianpeng Zhou and Siyuan Chen},
  doi          = {10.1016/j.neunet.2025.108139},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108139},
  shortjournal = {Neural Netw.},
  title        = {LLM-augmented entity alignment: An unsupervised and training-free framework},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Image restoration driven by dual-scale prior. <em>NN</em>, <em>194</em>, 108138. (<a href='https://doi.org/10.1016/j.neunet.2025.108138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of advanced imaging technologies, the demand for high quality images in various fields has increased. However, image degradation due to noise, data loss, and other factors persistently hinder image quality. Image restoration (IR) is a critical task in computer vision, aiming to recover original images from degraded observations. Traditional non-learning prior based methods offer flexibility and interpretability but often yield sub-optimal results due to limited representational capacity. In contrast, learning prior based counterparts produce superior performance but suffer from over-fitting and poor generalization to unseen degradations. In this paper, we introduce a novel dual-scale prior (DSP) model that integrates the flexibility strength of non-learning prior with the representation power of learning-based prior. Specifically, the DSP model employs a group-scale physical prior, leveraging non-local self-similarity (NSS) for jointly sparse and low-rank approximation. And an image-scale bias-free deep denoising prior for capturing external characteristics. These dual-scale priors complement each other by effectively preserving edges and removing noise, demonstrating robustness across various types of degradation. We then present DSPIR, an effective IR method by incorporating DSP into existing maximum a posteriori (MAP) principle. DSPIR is solved by alternating minimization and alternating direction method of multipliers. Extensive evaluations on both synthetic and real data demonstrate that DSPIR achieves better performance in image denoising and inpainting compared to state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Weimin Yuan and Cai Meng and Xiangzhi Bai},
  doi          = {10.1016/j.neunet.2025.108138},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108138},
  shortjournal = {Neural Netw.},
  title        = {Image restoration driven by dual-scale prior},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph neural networks for fMRI functional brain networks: A survey. <em>NN</em>, <em>194</em>, 108137. (<a href='https://doi.org/10.1016/j.neunet.2025.108137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of neuroimaging technologies, the development of deep learning-based models for the analysis of mental disorders has become an emerging consensus. Graphs, as a data and relationship representative, can abstract complex brain data, enabling us to systematically and precisely reveal key issues related to brain structure and function with the support of neuroimaging techniques. Graph neural networks (GNNs) provide new tools and methods for brain network analysis, allowing for a deeper exploration of the relationships between functional regions of the brain and potential functional patterns. Therefore, GNN-based methods for brain network analysis are gaining increasing attention. However, there is currently a lack of a comprehensive summary of the latest research approaches in this field from the perspective of computer science. This survey covers functional brain network analysis methods from different dimensions. In addition, for each method, we discuss the corresponding open challenges and unmet needs to identify the limitations and future directions of these methods in brain network research. Finally, to facilitate researchers in selecting and applying appropriate brain network datasets for experimentation and validation, we summarize the characteristics and sources of various brain network analysis datasets.},
  archive      = {J_NN},
  author       = {Jingye Tang and Tianqing Zhu and Wanlei Zhou and Wei Zhao},
  doi          = {10.1016/j.neunet.2025.108137},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108137},
  shortjournal = {Neural Netw.},
  title        = {Graph neural networks for fMRI functional brain networks: A survey},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WideTopo: Improving foresight neural network pruning through training dynamics preservation and wide topologies exploration. <em>NN</em>, <em>194</em>, 108136. (<a href='https://doi.org/10.1016/j.neunet.2025.108136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foresight neural network pruning methods have garnered significant attention due to their potential to save computational resources. Recent advancements in this field are predominantly categorized into saliency score-based and graph theory-based methods. The former assesses the sensitivity of pruning parameter connections concerning specific metrics, while the latter aims to identify sub-networks characterized by sparse yet highly connected graph structures. However, recent research suggests that relying exclusively on saliency scores may result in deep but narrow sub-networks, while graph theory-based methods may be unsuitable for neural networks requiring pre-trained parameters for initialization, particularly in transfer learning scenarios. We hypothesize that preserving the training dynamics of sub-networks during pruning, along with exploring network structures with wide topology, can facilitate the identification of structurally stable sub-networks with improved post-training performance. Motivated by this, we propose WideTopo, which integrates Neural Tangent Kernel (NTK) theory with Implicit Target Alignment (ITA) in neural networks to capture the training dynamics of sub-networks. Furthermore, it employs a density-aware saliency score decay strategy and a repeated mask restoration strategy to retain more effective nodes, thereby sustaining the width of each layer within the sub-networks. We conducted extensive validations using CNN-based and ViT-based models on representative image classification and semantic segmentation datasets under both random and pre-trained initialization settings. The effectiveness and applicability of our method have been validated on diverse network architectures at various model density rates, showing competitive post-training performance compared with other existing baselines. Our code is publicly available at https://github.com/Memoristor/WideTopo .},
  archive      = {J_NN},
  author       = {Changjian Deng and Jian Cheng and Yanzhou Su and Zeyu An and Zhiguo Yang and Ziying Xia and Yijie Zhang and Shiguang Wang},
  doi          = {10.1016/j.neunet.2025.108136},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108136},
  shortjournal = {Neural Netw.},
  title        = {WideTopo: Improving foresight neural network pruning through training dynamics preservation and wide topologies exploration},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DePoint: Improving rotation robustness of 3D point cloud analysis via decreasing entropy. <em>NN</em>, <em>194</em>, 108135. (<a href='https://doi.org/10.1016/j.neunet.2025.108135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world scenarios, achieving rotation robustness in point cloud analysis is crucial due to the unpredictable orientations of 3D objects. While recent advancements in rotation robustness typically rely on auxiliary modules to align rotated objects, precisely aligning object orientations remains challenging given the vast space of possible rotations. In this work, we investigate the impact of rotation on point clouds, revealing that random rotations significantly increase the joint entropy of point clouds and semantic labels—a key factor leading to degraded model performance on rotated datasets. To address this issue, we introduce DePoint, a simple yet effective rotation enhancement method that decreases entropy by aligning the spatial distribution of rotated point cloud representations with semantic information. Specifically, a Siamese point cloud encoder processes differently oriented views of an object with a shared task head, ensuring semantic consistency in the learned representations. A minimal auxiliary classifier enforces linear separability into these representations. Notably, DePoint can be seamlessly integrated into existing point cloud models without introducing additional parameters during inference. Experimental results demonstrate that DePoint significantly enhances the rotation robustness of various point cloud models in 3D object classification and segmentation.},
  archive      = {J_NN},
  author       = {Lu Shi and Gaoyun An and Yigang Cen and Yansen Huang and Fei Gan},
  doi          = {10.1016/j.neunet.2025.108135},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108135},
  shortjournal = {Neural Netw.},
  title        = {DePoint: Improving rotation robustness of 3D point cloud analysis via decreasing entropy},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AAC-GS: Attention-aware adaptive codebook for gaussian splatting compression. <em>NN</em>, <em>194</em>, 108134. (<a href='https://doi.org/10.1016/j.neunet.2025.108134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Radiance Fields (NeRF) have demonstrated remarkable performance in the field of novel view synthesis (NVS). However, their high computational cost limits practical applicability. The 3D Gaussian Splatting (3DGS) method offers a significant improvement in rendering efficiency, enabling real-time rendering through its explicit representations. Nevertheless, its substantial storage requirements pose challenges for complex scenes and resource-constrained devices. Existing methods aim to achieve storage compression through redundant point pruning, spherical harmonics adjustment, and vector quantization. However, point pruning methods often compromise geometric details in complex structures, while vector quantization approaches fail to capture feature relationships effectively, resulting in texture degradation and geometric boundary blurring. Although anchor point representations partially address storage concerns, their sparse representation limits compression efficiency. These limitations become particularly evident in scenes with intricate textures and complex lighting conditions. To ensure optimal compression ratios while maintaining high fidelity in Gaussian scenarios, this paper proposes an Attention-Aware Adaptive Codebook Gaussian Splatting (AAC-GS) method for efficient storage compression. The approach dynamically adjusts the size of the codebook to optimize storage efficiency and incorporates an attention mechanism to capture feature contextual relationships, thereby enhancing reconstruction quality. Additionally, a Generative Adversarial Network (GAN) is employed to mitigate quantization losses, achieving a balance between compression rate and visual fidelity. Experimental results demonstrate that AAC-GS achieves an average compression ratio of approximately 40× while maintaining high reconstruction quality, showcasing its potential for multi-scene applications.},
  archive      = {J_NN},
  author       = {Fang Wan and Jianhang Zhang and Tianyu Li and Guangbo Lei and Li Xu and Zhiwei Ye},
  doi          = {10.1016/j.neunet.2025.108134},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108134},
  shortjournal = {Neural Netw.},
  title        = {AAC-GS: Attention-aware adaptive codebook for gaussian splatting compression},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive knowledge selection in dialogue systems: Accommodating diverse knowledge types, requirements, and generation models. <em>NN</em>, <em>194</em>, 108133. (<a href='https://doi.org/10.1016/j.neunet.2025.108133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective knowledge-grounded dialogue systems rely heavily on accurate knowledge selection. This paper begins with an innovative new perspective that categorizes research on knowledge selection based on when knowledge is selected in relation to response generation: pre-, joint-, and post-selection. Among these, pre-selection is of great interest nowadays because they endeavor to provide sufficiently relevant knowledge inputs for downstream response generation models in advance. This reduces the burden of learning, adjusting, and interpreting for the subsequent response generation models, particularly for Large Language Models. Current knowledge pre-selection methods, however, still face three significant challenges: how to cope with different types of knowledge, adapt to the various knowledge requirements in different dialogue contexts, and adapt to different generation models. To resolve the above challenges, we propose ASK, an adaptive knowledge pre-selection method. It unifies various types of knowledge, scores their relevance and contribution to generating desired responses, and adapts the knowledge pool size to ensure the optimal amount is available for generation models. ASK is enhanced by leveraging rewards for selecting appropriate knowledge in both quality and quantity, through a reinforcement learning framework. We perform exhaustive experiments on two benchmarks (WoW and OpenDialKG) and get the following conclusions: 1) ASK has excellent knowledge selection capabilities on diverse knowledge types and requirements. 2) ASK significantly enhances the performance of various downstream generation models, including ChatGPT and GPT-4o. 3) The lightweight improvement of ASK saves 40 % of the computational consumption. Code is available at https://github.com/AnonymousCode32213/ASK .},
  archive      = {J_NN},
  author       = {Yao Zhang and Lang Qin and Zhongtian Bao and Hongru Liang and Jun Wang and Zhenglu Yang and Zhe Sun and Andrzej Cichocki},
  doi          = {10.1016/j.neunet.2025.108133},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108133},
  shortjournal = {Neural Netw.},
  title        = {Adaptive knowledge selection in dialogue systems: Accommodating diverse knowledge types, requirements, and generation models},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Metacognition for unknown situations and environments (MUSE). <em>NN</em>, <em>194</em>, 108131. (<a href='https://doi.org/10.1016/j.neunet.2025.108131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metacognition, defined as the awareness and regulation of one’s cognitive processes, is central to human adaptability in unknown situations. In contrast, current autonomous agents often struggle in novel environments due to their limited capacity for adaptation. We hypothesize that metacognition is a critical missing ingredient in autonomous agents for the cognitive flexibility needed to tackle unfamiliar challenges. Given the broad scope of metacognitive abilities, we focus on competence awareness and strategy selection. To this end, we propose the Metacognition for Unknown Situations and Environments (MUSE) framework to integrate metacognitive processes of self-assessment and self-regulation into autonomous agents. We present two implementations of MUSE: one based on world modeling and another leveraging large language models (LLMs). Our system continually learns to assess its competence on a given task and uses this self-assessment to guide iterative cycles of strategy selection. MUSE agents demonstrate high competence awareness and significant improvements in self-regulation for solving novel, out-of-distribution tasks more effectively compared to model-based reinforcement learning and purely prompt-based LLM agent approaches. This work highlights the promise of approaches inspired by cognitive and neural systems in enabling autonomous agents to adapt to new environments while mitigating the heavy reliance on extensive training data and large models for the current models.},
  archive      = {J_NN},
  author       = {Rodolfo Valiente and Praveen K. Pilly},
  doi          = {10.1016/j.neunet.2025.108131},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108131},
  shortjournal = {Neural Netw.},
  title        = {Metacognition for unknown situations and environments (MUSE)},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed-time learning-based optimal tracking control for robotic systems with prescribed performance constraints. <em>NN</em>, <em>194</em>, 108130. (<a href='https://doi.org/10.1016/j.neunet.2025.108130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a fixed-time learning-based dynamic event-triggered control framework to address the optimal tracking control problem in robotic systems with the prescribed performance constraints. In many practical scenarios, the states of robotic systems are often subject to performance constraints imposed by structural characteristics and task requirements. To address this issue, prescribed performance control (PPC) theory is employed to ensure performance state constraints and construct an unconstrained tracking error system. Subsequently, a critic-only adaptive dynamic programming (ADP) control framework is designed to approximate the optimal control law for the transformed unconstrained system. Furthermore, in the design of critic neural network (NN), a novel fixed-time convergence (FTC) weight update law based on concurrent learning (CL) techniques is proposed, which guarantees the fixed-time convergence of weight estimation error under relaxed persistent excitation (PE) condition. Throughout the controller design, a dynamic event-triggered mechanism is adopted to reduce the number of sampling instances and computational resources. Meanwhile, the stability of the closed-loop system under this mechanism is rigorously proven. Finally, the effectiveness of the proposed method is demonstrated through simulation results and comparative analysis.},
  archive      = {J_NN},
  author       = {Zhinan Peng and Xingyu Zhang and Zhuo Xia and Lin Hao and Linpu He and Hong Cheng},
  doi          = {10.1016/j.neunet.2025.108130},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108130},
  shortjournal = {Neural Netw.},
  title        = {Fixed-time learning-based optimal tracking control for robotic systems with prescribed performance constraints},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CSTSINR: Improving temporal continuity via convolutional structured implicit neural representations for time series anomaly detection. <em>NN</em>, <em>194</em>, 108129. (<a href='https://doi.org/10.1016/j.neunet.2025.108129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection plays a crucial role in identifying significant deviations from expected behavior. Implicit Neural Representation (INR) has been explored for time series modeling due to its ability to learn continuous functions. The inherent spectral bias of INRs, which prioritizes low-frequency signal fitting, further enables the detection of high-frequency anomalies. However, current INR-based approaches demonstrate limited capability in representing complex temporal patterns, particularly when the normal data itself contains significant high-frequency components. To address these challenges, we propose CSTSINR, a novel anomaly detection model that integrates the structured feature map and convolutional mechanisms with the INR continuous function. By leveraging a structured feature map and convolutional layers, CSTSINR addresses the limitations of directive prediction of all parameters and point-wise query processing, providing improved modeling of temporal continuity and enhanced anomaly detection. Our extensive experiments demonstrate that CSTSINR outperforms existing state-of-the-art methods across ten benchmark datasets, highlighting its superior ability to detect anomalies, particularly in high-frequency or complex time series data.},
  archive      = {J_NN},
  author       = {Ke Liu and Mengxuan Li and Jiajun Bu and Hongwei Wang and Haishuai Wang},
  doi          = {10.1016/j.neunet.2025.108129},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108129},
  shortjournal = {Neural Netw.},
  title        = {CSTSINR: Improving temporal continuity via convolutional structured implicit neural representations for time series anomaly detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MDSFD-net: Alzheimer’s disease diagnosis with missing modality via disentanglement learning and feature distillation. <em>NN</em>, <em>194</em>, 108128. (<a href='https://doi.org/10.1016/j.neunet.2025.108128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal analysis can provide complementary information and significantly aid in the early diagnosis and intervention of Alzheimer’s Disease (AD). However, the issue of missing modalities presents a major challenge, as most methods that rely on complete multi-modal data become infeasible. The most advanced approaches to addressing missing modalities typically use generative models, but these often neglect the importance of modality-specific features, leading to biased predictions and poor performance. Inspired by this limitation, we propose a Modality Disentanglement and Specific Features Distillation Network (MDSFD-Net) for AD diagnosis with missing modality, which consists of a disentanglement-based imputation module (DI module) and a specific features distillation module (SFD module). In the DI module, we introduce a novel spatial-channel modality disentanglement learning scheme that is first used to disentangle modality-specific features, along with a shared constrain objective to learn modality-shared features, which are used for imputing missing modality features. To address the specific features of the missing modality, the SFD module is designed to transfer the specific features from complete modality in the teacher network to the incomplete modality in the student network. A regularized knowledge distillation (R-KD) mechanism is incorporated to mitigate the impact of incorrect predictions from the teacher network. By leveraging modality-shared features imputation and modality-specific features distillation, our model can effectively learn sufficient information for classification even if some modalities are missing. Extensive experiments on ADNI dataset demonstrate the superiority of our proposed MDSFD-Net over state-of-the-art methods in missing modality situations.},
  archive      = {J_NN},
  author       = {Nana Jia and Zhiao Zhang and Tong Jia},
  doi          = {10.1016/j.neunet.2025.108128},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108128},
  shortjournal = {Neural Netw.},
  title        = {MDSFD-net: Alzheimer’s disease diagnosis with missing modality via disentanglement learning and feature distillation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spiking neural networks for EEG signal analysis: From theory to practice. <em>NN</em>, <em>194</em>, 108127. (<a href='https://doi.org/10.1016/j.neunet.2025.108127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate and efficient information processing of the human brain, driven by spiking neural interactions, has led to the development of spiking neural networks (SNNs) as a cutting-edge neural network paradigm. Unlike traditional artificial neural networks (ANNs) that use continuous values, SNNs emulate the brain’s spiking mechanisms, offering enhanced temporal information processing and computational efficiency. This review addresses the critical gap between theoretical advancements and practical applications of SNNs in EEG signal analysis. We provide a comprehensive examination of recent SNN methodologies and their application to EEG signals, highlighting their potential benefits over conventional deep learning approaches. The review encompasses foundational knowledge of SNNs, detailed implementation strategies for EEG analysis, and challenges inherent to SNN-based methods. Practical guidance is provided through step-by-step instructions and accessible code available on GitHub, aimed at facilitating researchers’ adoption of these techniques. Additionally, we explore emerging trends and future research directions, emphasizing the potential of SNNs to advance brain-computer interfaces and neurofeedback systems. This paper serves as a valuable resource for bridging the gap between theoretical developments in SNNs and their practical implementation in EEG signal analysis.},
  archive      = {J_NN},
  author       = {Siqi Cai and Zheyuan Lin and Xiaoli Liu and Wenjie Wei and Shuai Wang and Malu Zhang and Tanja Schultz and Haizhou Li},
  doi          = {10.1016/j.neunet.2025.108127},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108127},
  shortjournal = {Neural Netw.},
  title        = {Spiking neural networks for EEG signal analysis: From theory to practice},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Energy-based diffusion generator for efficient sampling of boltzmann distributions. <em>NN</em>, <em>194</em>, 108126. (<a href='https://doi.org/10.1016/j.neunet.2025.108126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sampling from Boltzmann distributions, particularly those tied to high dimensional and complex energy functions, poses a significant challenge in many fields. In this work, we present the Energy-Based Diffusion Generator (EDG), a novel approach that integrates ideas from variational autoencoders and diffusion models. EDG uses a decoder to generate Boltzmann-distributed samples from simple latent variables, and a diffusion-based encoder to estimate the Kullback-Leibler divergence to the target distribution. Notably, EDG is simulation-free, eliminating the need to solve ordinary or stochastic differential equations during training. Furthermore, by removing constraints such as bijectivity in the decoder, EDG allows for flexible network design. Through empirical evaluation, we demonstrate the superior performance of EDG across a variety of sampling tasks with complex target distributions, outperforming existing methods.},
  archive      = {J_NN},
  author       = {Yan Wang and Ling Guo and Hao Wu and Tao Zhou},
  doi          = {10.1016/j.neunet.2025.108126},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108126},
  shortjournal = {Neural Netw.},
  title        = {Energy-based diffusion generator for efficient sampling of boltzmann distributions},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TGSL: Trade-off graph structure learning via multifaceted graph information bottleneck. <em>NN</em>, <em>194</em>, 108125. (<a href='https://doi.org/10.1016/j.neunet.2025.108125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are prominent for their effectiveness in processing graph-structured data for semi-supervised node classification tasks. Most existing GNNs perform message passing directly based on the observed graph structure. However, in real-world scenarios, the observed structure is often suboptimal due to multiple factors, significantly degrading the performance of GNNs. To address this challenge, we first conduct an empirical analysis showing that different graph structures significantly impact empirical risk and classification performance. Motivated by our observations, we propose a novel method named T rade-off G raph S tructure L earning (TGSL), guided by the multifaceted Graph Information Bottleneck (GIB) principle based on Mutual Information (MI). The key idea behind TGSL is to learn a minimal sufficient graph structure that minimizes empirical risk while maintaining performance. Specifically, we introduce global feature augmentation to capture the structural roles of nodes, and global structure augmentation to uncover global relationships between nodes. The augmented graphs are then processed by structure estimators with different parameters for refinement and redefinition, respectively. Additionally, we innovatively leverage multifaceted GIB as the optimization objective by maximizing the MI between the labels and the representation derived from the final structure, while constraining the MI between this representation and that based on the redefined structures. This trade-off helps avoid capturing irrelevant information from the redefined structures and enhances the final representation for node classification. We conduct extensive experiments across a range of datasets under clean and attacked conditions. The results demonstrate the outstanding performance and robustness of TGSL over state-of-the-art baselines.},
  archive      = {J_NN},
  author       = {Shuangjie Li and Baoming Zhang and Jianqing Song and Gaoli Ruan and Chongjun Wang and Junyuan Xie},
  doi          = {10.1016/j.neunet.2025.108125},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108125},
  shortjournal = {Neural Netw.},
  title        = {TGSL: Trade-off graph structure learning via multifaceted graph information bottleneck},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improving few-shot relation classification with multi-scale hierarchical prototype learning. <em>NN</em>, <em>194</em>, 108124. (<a href='https://doi.org/10.1016/j.neunet.2025.108124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot relation classification aims to distinguish different relation classes from extremely limited annotated data. Most existing methods primarily use prototype networks to construct a prototypical representation, classifying the instance by comparing its similarity to each prototype. Despite achieving promising results, the prototypes derived solely from limited support instances are often inaccurate due to constraints in feature extraction capabilities. Moreover, they ignore the different hierarchical levels of relational information, which can provide more effective guidance for classification. In this paper, we propose a novel m ulti-sc a le hie r arch i cal pr o totype (Mario) learning method that captures relational interaction information at three levels: inter-set, inter-class and intra-class, enhancing the model’s understanding of global semantic information and helping it distinguish subtle differences between classes. Additionally, we incorporate relational descriptive information to reduce the impact of textual expression diversity, enabling the model to emulate the human cognitive process in understanding variation. Extensive experiments conduct on the FewRel dataset demonstrate the effectiveness of our proposed model. In particular, it achieves accuracy rates of 92.52 %/95.33 %/85.46 %/91.33 % under four common few-shot settings. Notably, in the critical 5-way and 10-way 1-shot settings, it outperforms the strongest baseline by 2.87 % and 4.29 %.},
  archive      = {J_NN},
  author       = {Haijia Bi and Lu Liu and Hai Cui and Shengyue Liu and Ridong Han and Jiayu Han and Tao Peng},
  doi          = {10.1016/j.neunet.2025.108124},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108124},
  shortjournal = {Neural Netw.},
  title        = {Improving few-shot relation classification with multi-scale hierarchical prototype learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Planning forward: Deep incremental hashing by gradually defrosting bits. <em>NN</em>, <em>194</em>, 108123. (<a href='https://doi.org/10.1016/j.neunet.2025.108123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep incremental hashing can generate hash codes incrementally for new classes, while keeping the existing ones unchanged. Existing methods typically allocate fixed code lengths to all classes, causing the entire Hamming space occupied by existing classes, thus failing to prepare models for future extensions. This significantly limits the ability to effectively accommodate new classes. Beyond that, it is inefficient in computation and storage to use all bits for encoding a few classes in the early sessions. This paper presents B it D efrosting Deep I ncremental H ashing (BDIH) to tackle these problems. Our key insight is to map the classes into a small subspace by freezing most hash bits during the first session, which reserves adequate space for future classes. This allows subsequent sessions to map new classes into progressively expanding subspaces by defrosting a portion of the frozen bits. Specifically, we propose a bit-defrosting code learning framework, which includes a bit-defrosting center generation part and a center-based bit-defrosting code learning part. The former part generates hash centers as learning objectives in expanding subspaces while the latter part learns globally discriminative hash codes with the guidance of hash centers and preserves the backward compatibility between the updated model and previously stored codes. As a result, our method achieves comparable performance on old classes using fewer bits while reserving more space for new ones. Extensive experiments demonstrate that BDIH outperforms existing methods regarding retrieval accuracy and storage efficiency in long-sequence incremental learning scenarios.},
  archive      = {J_NN},
  author       = {Qinghang Su and Dayan Wu and Chenming Wu and Bo Li and Weiping Wang},
  doi          = {10.1016/j.neunet.2025.108123},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108123},
  shortjournal = {Neural Netw.},
  title        = {Planning forward: Deep incremental hashing by gradually defrosting bits},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Contrastive learning unlocks geometric insights for dataset pruning. <em>NN</em>, <em>194</em>, 108122. (<a href='https://doi.org/10.1016/j.neunet.2025.108122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dataset pruning aims at selecting a subset of the data so that the model trained on the subset performs comparably to the one trained on the full dataset. In the era of big data, unsupervised pruning of the dataset can alleviate the issue of the expensive labeling process from the beginning. Existing methods sort and select instances by well-designed importance metrics, while the unsupervised ones commonly regard representation learning as a black box employed to get embeddings, with its properties remaining insufficiently explored for dataset pruning. In this study, we revisit self-supervised Contrastive Learning by observing the learned embedding manifold, introducing Curvature Estimation to characterize the geometrical properties of the manifold. The statistical results reveal that the embedding distribution of instances on manifold surfaces is not uniform. Based on this observation, we propose an unsupervised dataset pruning strategy by performing downsampling in geometric areas with high instance density, namely KITTY sampling. Extensive experiments demonstrate that our proposed methods have achieved leading performances on CV dataset pruning compared to the baselines. Code is available at https://github.com/Frostland12138/KITTY .},
  archive      = {J_NN},
  author       = {Hongjia Xu and Sheng Zhou and Zhuonan Zheng and Ning Ma and Jiawei Chen and Jiajun Bu},
  doi          = {10.1016/j.neunet.2025.108122},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108122},
  shortjournal = {Neural Netw.},
  title        = {Contrastive learning unlocks geometric insights for dataset pruning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tacit mechanism: Bridging pre-training of individuality to multi-agent adversarial coordination. <em>NN</em>, <em>194</em>, 108121. (<a href='https://doi.org/10.1016/j.neunet.2025.108121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the multi-agent adversarial coordination problem, current multi-agent reinforcement learning (MARL) algorithms primarily depend on team-based rewards to update agent policies. However, they do not fully exploit the spatial relationships and their variant trends, thereby limiting overall performance. Inspired by human tactics, we propose the concept of tacit behavior to enhance the efficiency of multi-agent reinforcement learning through the refinement of the learning process. This paper introduces a novel two-phase framework to learn P re-trained T acit B ehavior for efficient multi-agent adversarial C oordination ( PTBC ). The framework consists of a tacit pre-training phase and a centralized adversarial training phase. For pre-training the tacit behaviors, we develop a pattern mechanism and a tacit mechanism to integrate spatial relationships among agents, which dynamically guide agents’ actions to gain spatial advantages for coordination. In the subsequent centralized adversarial training phase, we utilize the pre-trained network to enhance the formation of advantageous spatial positioning, achieving more efficient learning performance. Our experimental results in the predator-prey and StarCraft Multi-Agent Challenge (SMAC) environments demonstrate the effectiveness of our method through comparisons with several algorithms exhibiting distinct strengths. Additionally, by visualizing the agents’ performance in adversarial tasks, we validate that incorporating inter-agent relationships enables agents with pre-trained tacit behavior to achieve more advantageous coordination. Extensive ablation studies demonstrate the critical role of tacit guidance and the general applicability of the PTBC framework.},
  archive      = {J_NN},
  author       = {Shiqing Yao and Jiajun Chai and Haixin Yu and Yongzhe Chang and Tiantian Zhang and Yuanheng Zhu and Xueqian Wang},
  doi          = {10.1016/j.neunet.2025.108121},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108121},
  shortjournal = {Neural Netw.},
  title        = {Tacit mechanism: Bridging pre-training of individuality to multi-agent adversarial coordination},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Offline-to-online reinforcement learning with efficient unconstrained fine-tuning. <em>NN</em>, <em>194</em>, 108120. (<a href='https://doi.org/10.1016/j.neunet.2025.108120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning provides the capability to learn a policy only from pre-collected datasets, but its performance is often limited by the quality of the offline dataset and the coverage of the state-action space. Offline-to-online reinforcement learning is promising to address these limitations and achieve high sample efficiency by integrating the advantages of both offline and online learning paradigms. However, existing methods typically struggle to adapt to online learning and improve the performance of pre-trained policies due to the distributional shift and conservative training. To address these issues, we propose an efficient unconstrained fine-tuning framework that removes conservative constraints on the policy during fine-tuning, allowing thorough exploration of state-action pairs not covered by the offline data. This framework leverages three key techniques: dynamics representation learning, layer normalization, and increasing the update frequency of the value network to improve sample efficiency and mitigate value function estimation bias caused by the distributional shift. Dynamics representation learning accelerates fine-tuning by capturing meaningful features, layer normalization bounds Q -value to suppress catastrophic value function divergence, and increasing the update frequency of the value network enhances the sample efficiency and reduces value function estimation bias. Extensive experiments on the D4RL benchmark demonstrate that our algorithm outperforms state-of-the-art offline-to-online reinforcement learning algorithms across various tasks with minimal online interactions.},
  archive      = {J_NN},
  author       = {Jun Zheng and Runda Jia and Shaoning Liu and Ranmeng Lin and Dakuo He and Fuli Wang},
  doi          = {10.1016/j.neunet.2025.108120},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108120},
  shortjournal = {Neural Netw.},
  title        = {Offline-to-online reinforcement learning with efficient unconstrained fine-tuning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AutoSGRL: Automated framework construction for self-supervised graph representation learning. <em>NN</em>, <em>194</em>, 108119. (<a href='https://doi.org/10.1016/j.neunet.2025.108119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated machine learning (AutoML) is a promising solution for building a machine learning framework without human assistance and has attracted significant attention throughout the computational intelligence research community. Although there has been an emerging interest in graph neural architecture search, current research focuses on the specific design of semi-supervised or supervised graph neural networks. Motivated by this, we propose a novel method that enables the automatic construction of flexible self-supervised graph representation learning frameworks for the first time as far as we know, referred to as AutoSGRL. Based on existing self-supervised graph contrastive learning methods, AutoSGRL establishes a framework search space for self-supervised graph representation learning, which encompasses data augmentation strategies and proxy tasks for constructing graph contrastive learning frameworks, and the hyperparameters required for model training. Then, we implement an automatic search engine based on genetic algorithms, which constructs multiple self-supervised graph representation learning frameworks as the initial population. By simulating the process of biological evolution including selection, crossover, and mutation, the search engine iteratively evolves the population to identify high-performed frameworks and optimal hyperparameters. Empirical studies demonstrate that our AutoSGRL achieves comparative or even better performance than state-of-the-art manual-designed self-supervised graph representation learning methods and semi-supervised graph neural architecture search methods.},
  archive      = {J_NN},
  author       = {Yu Xie and Yu Chang and Ming Li and A.K. Qin and Xialei Zhang},
  doi          = {10.1016/j.neunet.2025.108119},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108119},
  shortjournal = {Neural Netw.},
  title        = {AutoSGRL: Automated framework construction for self-supervised graph representation learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation. <em>NN</em>, <em>194</em>, 108118. (<a href='https://doi.org/10.1016/j.neunet.2025.108118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vascular morphology plays a crucial role in diagnosing diseases such as diabetes, glaucoma, and hypertension, making accurate segmentation of retinal vessels essential for early intervention. Traditional segmentation methods assume that training and testing data share similar distributions, which can lead to poor performance on unseen domains due to domain shifts caused by variations in imaging devices and patient demographics. This paper presents a novel approach, DGSSA, for retinal vessel image segmentation that enhances model generalization by combining structural and stylistic augmentation strategies. We utilize a space colonization algorithm to generate diverse vascular-like structures that closely mimic actual retinal vessels, which are then used to generate pseudo-retinal images with an improved Pix2Pix model, allowing the segmentation model to learn a broader range of structure distributions. Additionally, we utilize PixMix to apply random photometric augmentations and introduce uncertainty perturbations, enriching the stylistic diversity of fundus images and further improving the model’s robustness and generalization across varying imaging conditions. Our framework, which employs a DeepLabv3+ model with a MobileNetV2 backbone as its segmentation network, has been rigorously evaluated on four challenging datasets—DRIVE, CHASEDB1, HRF, and STARE—achieving Dice Similarity Coefficient (DSC) of 78.45%, 78.62%, 72.66% and 82.17%, respectively, with an average DSC of 77.98%. These results demonstrate that our method surpasses existing approaches, validating its effectiveness and highlighting its potential for clinical application in automated retinal vessel analysis.},
  archive      = {J_NN},
  author       = {Bo Liu and Yudong Zhang and Shuihua Wang and Siyue Li and Jin Hong},
  doi          = {10.1016/j.neunet.2025.108118},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108118},
  shortjournal = {Neural Netw.},
  title        = {DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ToBaFu: Topology-based fusion model for classification of two-dimensional cancer images. <em>NN</em>, <em>194</em>, 108117. (<a href='https://doi.org/10.1016/j.neunet.2025.108117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical images play a pivotal role in disease diagnosis. Numerous studies on cancer image analysis focus on end-to-end deep neural networks, neglecting the analysis of global topological features in images. In cancer diagnosis, pathological images frequently display structures like holes or loops that are absent in healthy images, highlighting the benefits of topological analysis of images. In our study, we employ persistent homology (PH) to extract topological features from two-dimensional cancer images. Then, we propose a topology-based model (Topo) for image classification by implementing a shallow neural module following the feature extraction. More importantly, we integrate the Topo model with an end-to-end enhanced ResNet architecture to develop a novel topology-based fusion model (ToBaFu), aimed at enhancing diagnostic performance and model robustness. The proposed ToBaFu model achieves remarkable performance across three cancer image datasets: 99.98 % accuracy and F1-score on the LC-25000 lung and colon cancer histopathological dataset, 99.60 % accuracy and F1-score on the CRC-5000 colorectal cancer histological dataset, and 99.80 % accuracy with 99.83 % F1-score on the BUS-250 breast ultrasound dataset.},
  archive      = {J_NN},
  author       = {Yuqing Xing and Haodong Chen and Quan Zheng},
  doi          = {10.1016/j.neunet.2025.108117},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108117},
  shortjournal = {Neural Netw.},
  title        = {ToBaFu: Topology-based fusion model for classification of two-dimensional cancer images},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution. <em>NN</em>, <em>194</em>, 108116. (<a href='https://doi.org/10.1016/j.neunet.2025.108116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data distribution discrepancy across datasets is one of the major obstacles hindering the improvement of the accuracy of cross-domain adaptive detection of medical images. To address this challenge, we propose a novel lightweight cross-modal adaptive detection module named LCA-Med (LCaM). The proposed module boasts a lightweight structure and a minimalistic parameter count, thereby facilitating its integration into the anterior segment of a diverse array of foundational and downstream networks. It is adept at serving as a feature preprocessor, proficiently extracting pertinent information regrading pathologies from a array of images (image modality) produced through varied medical imaging techniques, all guided by the input of prompts (text modality). We also propose a novel cross-modal medical image adaptive detection method, LCA-Med CNX (LCaM-CNX), and a novel cross-domain adaptive detection training paradigm that incorporates generated dataset groups, an attention module, and a meta-heuristic algorithm. Experimental results on six medical image datasets compared with ten state-of-the-art methods demonstrate that the LCaM-CNX trained following the proposed paradigm achieves the best performance on five datasets and competitive performance on the other dataset. Notably, our method outperforms the state-of-the-art methods more when the data distribution is more imbalanced.},
  archive      = {J_NN},
  author       = {Xiang Li and Long Lan and Husam Lahza and Shaowu Yang and Shuihua Wang and Yong Liang and Hudan Pan and Wenjing Yang and Hengzhu Liu and Yudong Zhang},
  doi          = {10.1016/j.neunet.2025.108116},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108116},
  shortjournal = {Neural Netw.},
  title        = {LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Counterfactual causal inference for robust visual question answering. <em>NN</em>, <em>194</em>, 108115. (<a href='https://doi.org/10.1016/j.neunet.2025.108115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) systems have seen remarkable progress with the incorporation of multimodal data. However, their performance is still hampered by biases ingrained in language and vision modalities, frequently resulting in subpar generalization. In this study, we introduce a novel counterfactual causal framework (CC-VQA). This framework utilizes Counterfactual Sample Synthesis (CSS) and causal inference to tackle cross-modality biases. Our approach innovatively employs a strategy based on causal graphs, which effectively disentangles spurious correlations in multimodal data. This ensures a balanced and precise multimodal reasoning process, enabling the model to make more accurate and unbiased decisions. Moreover, we propose a contrastive loss mechanism. By contrasting the embeddings of positive and negative samples, this mechanism significantly enhances the robustness of VQA models. Additionally, we develop a robust training strategy that improves both the visual-explainable and question-sensitive capabilities of these models. Our experimental evaluations on benchmark datasets, such as VQA-CP v2 and VQA v2, demonstrate substantial improvements in bias mitigation and overall accuracy. The proposed CC-VQA framework outperforms state-of-the-art methods, highlighting its effectiveness in enhancing the performance of VQA systems.},
  archive      = {J_NN},
  author       = {Wei Li and Zhixin Li and Fuyun Deng and Kun Zeng and Canlong Zhang},
  doi          = {10.1016/j.neunet.2025.108115},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108115},
  shortjournal = {Neural Netw.},
  title        = {Counterfactual causal inference for robust visual question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A domain-specific cross-lingual semantic alignment learning model for low-resource languages. <em>NN</em>, <em>194</em>, 108114. (<a href='https://doi.org/10.1016/j.neunet.2025.108114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-lingual semantic alignment models facilitate the sharing and utilization of multilingual domain-specific data (e.g., medical, legal), offering cost-effective solutions for improving low-resource language tasks. However, existing methods are challenged by parallel data scarcity, semantic space heterogeneity, morphological complexity, and weak robustness-particularly for agglutinative languages. Therefore, this paper proposes CLWKD, a cross-lingual mapping and knowledge distillation framework. CLWKD leverages domain-specific pretrained models from high-resource languages as teachers and integrates multi-granularity alignment matrices with limited parallel data to guide cross-lingual knowledge transfer. CLWKD jointly learns multi-granularity semantic alignment mapping matrices at the token, word, and sentence levels from general-domain data. It eases domain data scarcity and helps bridge structural gaps caused by morphological and syntactic differences. To alleviate data sparsity and out-of-vocabulary issues in agglutinative languages, multilingual embedding sharing and morphological segmentation strategies are introduced. To improve the stability of unsupervised mapping training, generator pretraining is introduced and further combined with high-confidence word and sentence pairs to optimize the mapping matrix.To preserve alignment with fewer parameters, a parameter recycling and embedding bottleneck design is adopted. Experiments across the medical, legal, and educational domains on Mongolian-Chinese and Korean-Chinese language pairs demonstrate the effectiveness of CLWKD in three cross-lingual tasks.},
  archive      = {J_NN},
  author       = {Yurong Wang and Min Lin and Qitu Hu and Shuangcheng Bai and Yanling Li and Longjie Bao},
  doi          = {10.1016/j.neunet.2025.108114},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108114},
  shortjournal = {Neural Netw.},
  title        = {A domain-specific cross-lingual semantic alignment learning model for low-resource languages},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inference of hidden common driver dynamics by anisotropic self-organizing neural networks. <em>NN</em>, <em>194</em>, 108113. (<a href='https://doi.org/10.1016/j.neunet.2025.108113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the Anisotropic Self-Organizing Map (ASOM), a novel neural network-based approach for inferring hidden common drivers in nonlinear dynamical systems from observed time series. Grounded in topological theorems, our method integrates time-delay embedding, intrinsic dimension estimation, and a new anisotropic training scheme for Kohonen’s self-organizing map, enabling the precise decomposition of attractor manifolds into autonomous and shared components of the dynamics. We validated ASOM through simulations involving chaotic maps, where two driven systems were influenced by a hidden nonlinear driver. The inferred time series showed a strong correlation with the actual hidden common driver, unlike the observed systems. We further compared our reconstruction performance against several established methods for identifying shared features in time series, including PCA, kernel PCA, ICA, dynamical component analysis, canonical correlation analysis, deep canonical correlation analysis, traditional self-organizing map, and recent recurrence-based approaches. Our results demonstrate ASOM’s superior accuracy and robustness in recovering latent dynamics, providing a powerful tool for unsupervised learning of hidden causal structures in complex systems.},
  archive      = {J_NN},
  author       = {Zsigmond Benkő and Marcell Stippinger and Attila Bencze and Fülöp Bazsó and András Telcs and Zoltán Somogyvári},
  doi          = {10.1016/j.neunet.2025.108113},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108113},
  shortjournal = {Neural Netw.},
  title        = {Inference of hidden common driver dynamics by anisotropic self-organizing neural networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the theoretical expressive power of graph transformers for solving graph problems. <em>NN</em>, <em>194</em>, 108112. (<a href='https://doi.org/10.1016/j.neunet.2025.108112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Transformers have become the dominant neural architecture in the fields of natural language processing and computer vision. The generalization of Transformers to graphs, so-called Graph Transformers, have recently emerged as a promising alternative to the successful message passing Graph Neural Networks (MPNNs). While the expressive power of MPNNs has been intensively studied in the past years, that of Graph Transformers is still underexplored. Existing results mostly rely on the employed structural/positional encodings and not on the pure architecture itself. However, gaining an understanding of the strengths and limitations of Graph Transformers would be very useful both for the scientific community and the practitioners. In this paper, we derive a connection between Graph Transformers and the Congested clique , a popular model in distributed computing. This connection allows us to translate theoretical results for different graph problems from the latter to the former. We show that under certain conditions, Graph Transformers with depth 2 are Turing universal. We also show that there exist Graph Transformers that can solve problems which cannot be solved by MPNNs. We empirically investigate whether Graph Transformers and MPNNs with depth 2 can solve graph problems on some molecular datasets. Our results demonstrate that Graph Transformers can generally address the underlying tasks, while MPNNs are incapable of learning any information about the graph.},
  archive      = {J_NN},
  author       = {Giannis Nikolentzos and Dimitrios Kelesis and Michalis Vazirgiannis},
  doi          = {10.1016/j.neunet.2025.108112},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108112},
  shortjournal = {Neural Netw.},
  title        = {On the theoretical expressive power of graph transformers for solving graph problems},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A biologically plausible model of astrocyte-neuron networks in random and hub-driven connectivity. <em>NN</em>, <em>194</em>, 108111. (<a href='https://doi.org/10.1016/j.neunet.2025.108111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research studies in brain neural networks are highlighting the involvement of glial cells, in particular astrocytes, in synaptic modulation, memory formation, and neural synchronization, a role that has often been overlooked. Thus, theoretical models have begun incorporating astrocytes to better understand their functional impact. Additionally, the structural organization of neuron-neuron, astrocyte-neuron and astrocyte-astrocyte connections plays a crucial role in network dynamics. Starting from a recently published astrocyte-neuron network model with neuron-neuron random connectivity, we provide an extensive evaluation of this same model, focusing on astrocytic dynamics, neuron-astrocyte connectivity, and spatial distribution of inhibitory neurons. We propose refinements to the model with the aim of improving the biological plausibility of the above described characteristics of the model. To assess the interplay between astrocytes and network topology, we compare four configurations: neural networks with and without astrocytes, each under random and hub-driven connectivity. Simulations are conducted using the Brian2 simulator, providing insights into how astrocytes and structural heterogeneity jointly influence neural dynamics. Our findings contribute to a deeper understanding of neuron-glia interactions and the impact of network topology on astrocyte-neuron network dynamics. In particular, while finding an expected decrease of neural firing activity due to astrocyte calcium dynamics, we also found that hub-driven topology trigger a much higher firing rate with respect to the random topology, even having this last one a much higher number of neuron-neuron connections.},
  archive      = {J_NN},
  author       = {Giulia Salzano and Paolo Paradisi and Enrico Cataldo},
  doi          = {10.1016/j.neunet.2025.108111},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108111},
  shortjournal = {Neural Netw.},
  title        = {A biologically plausible model of astrocyte-neuron networks in random and hub-driven connectivity},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders. <em>NN</em>, <em>194</em>, 108110. (<a href='https://doi.org/10.1016/j.neunet.2025.108110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodevelopmental disorders exhibit highly similar behavioral characteristics in clinical assessments, heavily relying on subjective behavioral reports, leading to insufficient understanding of the neurobiological mechanisms behind inter-patient heterogeneity and symptom overlap between diseases. To address this issue, this study proposes a graph neural network framework that integrates neuroimaging data, focusing on three key problems: Firstly, enhance the nonlinear features in brain neural activity by introducing the Neurodynamics Rössler system. Transform raw static neural signals into simulated signals with nonlinear, temporal, and dynamic features, thereby more accurately reflecting the process of brain neural activity. Secondly, improve feature discrimination by integrating the spatial adjacency characteristics of local brain regions with the topological structure information of the global brain network to highlight key features. Thirdly, improve noise resistance and generalization ability. Introducing adaptive controllers and cross-site adversarial learning mechanisms, the interference of heterogeneous noise is effectively reduced. This study conducted experimental validation on data from neurodevelopmental disorders such as ADHD and ASD. The results indicate that this framework not only has advantages in classification accuracy but also possesses good interpretability, making it a promising tool for imaging biomarker research and auxiliary diagnosis.},
  archive      = {J_NN},
  author       = {Qiulei Han and Hongbiao Ye and Miaoshui Bai and Lili Wang and Yan Sun and Ze Song and Jian Zhao and Lijuan Shi and Zhejun Kuang},
  doi          = {10.1016/j.neunet.2025.108110},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108110},
  shortjournal = {Neural Netw.},
  title        = {MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). State-flipped control design for the stabilization of probabilistic boolean control networks. <em>NN</em>, <em>194</em>, 108109. (<a href='https://doi.org/10.1016/j.neunet.2025.108109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stabilization is a fundamental issue in modern control theory. In the past decades, significant efforts have been invested in deriving necessary and sufficient conditions for verifying the global stabilization of probabilistic Boolean control networks (PBCNs). However, systematic methods and general criteria for exploring the local stabilization and determining the domain of attraction of PBCNs are still lacking in the existing literature. Motivated by this research gap, this paper investigates the local state feedback stabilization of PBCNs, including local finite-time state feedback stabilization with probability one (FTSFS) and local state feedback stabilization in distribution (SFSD). Firstly, a sequence of reachable sets with probability one is constructed, based on which, the largest domain of attraction is derived for the FTSFS of PBCNs by designing the state feedback controllers. Secondly, by constructing a sequence of reachable sets with positive probability, the largest domain of attraction is determined for the SFSD of PBCNs. Finally, when the largest domain of attraction is not the whole state space, the state-flipped control is designed to achieve the global FTSFS or SFSD of PBCNs via the largest domain of attraction.},
  archive      = {J_NN},
  author       = {Xinrong Yang and Haitao Li},
  doi          = {10.1016/j.neunet.2025.108109},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108109},
  shortjournal = {Neural Netw.},
  title        = {State-flipped control design for the stabilization of probabilistic boolean control networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stability of large-scale probabilistic boolean networks via network aggregation. <em>NN</em>, <em>194</em>, 108108. (<a href='https://doi.org/10.1016/j.neunet.2025.108108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale probabilistic Boolean networks (LSPBNs) are a modeling tool used to simulate and analyze the dynamics of complex systems with uncertainty. However, due to its high computational complexity, previous research methods cannot be directly applied to study such systems. Inspired by network aggregation, this paper conducts network aggregation on LSPBNs to investigate its global stability with probability 1. It is worth mentioning that the stability conclusion proposed in this article holds for any form of network aggregation. First, the entire network is partitioned and the algebraic expressions for each subnetwork are given through the semi-tensor product of matrices. And then, a set of iterative formulas is constructed to describe and reflect the input-output coordination relationship among the subnetworks, and based on which, a sufficient condition for the global stability of LSPBNs is derived, greatly reducing computational complexity. The feasibilities of the proposed method and results are verified through examples.},
  archive      = {J_NN},
  author       = {Wen Liu and Shihua Fu and Jianjun Wang and Renato De Leone and Jianwei Xia},
  doi          = {10.1016/j.neunet.2025.108108},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108108},
  shortjournal = {Neural Netw.},
  title        = {Stability of large-scale probabilistic boolean networks via network aggregation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPC: Self-supervised point cloud completion. <em>NN</em>, <em>194</em>, 108107. (<a href='https://doi.org/10.1016/j.neunet.2025.108107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape incompleteness is a common issue in point clouds acquired by depth sensors. Point cloud completion aims to restore partial point clouds to their complete form. However, most existing point cloud completion methods rely on complete point clouds or multi-view information of the same object during training, which is not practical for real-world scenarios with high information acquisition costs. To overcome the above limitation, a self-supervised point cloud completion (SPC) method is proposed, which uses the training set consisting of only a single partial point cloud for each object. Specifically, an autoencoder-like network architecture that includes a two-step strategy is developed. First, a compression-reconstruction strategy is proposed to enable the network to learn the representation of complete point clouds from existing knowledge. Then, considering the potential problem of overfitting in self-supervised training, a global enhancement strategy is further designed to maintain the positional coherence of predicted points. Comprehensive experiments are conducted on the ScanNet, MatterPort3D, KITTI, and ShapeNet datasets. On real-world datasets, the unidirectional Chamfer distance (UCD) and the unidirectional Hausdorff distance (UHD) of the method are reduced by an average of 2.3 and 2.4, respectively, compared to the state-of-the-art method. In addition to its excellent completion capabilities, the proposed method has a positive impact on downstream tasks. In point cloud classification, applying the proposed method improves classification accuracy by an average of 14 %. Extensive experimental results demonstrate that the proposed SPC has a high practical value.},
  archive      = {J_NN},
  author       = {Jie Song and Xing Wu and Junfeng Yao and Qi Zhang and Chenhao Shang and Quan Qian and Jun Song},
  doi          = {10.1016/j.neunet.2025.108107},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108107},
  shortjournal = {Neural Netw.},
  title        = {SPC: Self-supervised point cloud completion},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition. <em>NN</em>, <em>194</em>, 108106. (<a href='https://doi.org/10.1016/j.neunet.2025.108106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Named Entity Recognition (MNER) integrates complementary information from both text and images to identify named entities within text. However, existing methods face three key issues: imbalanced handling of modality noise, the cascading effect of semantic mismatch, and information loss resulting from the lack of text dominance. To address these issues, this paper proposes a M ulti-stage I nteraction N etwork I nspired by G ene E diting for MNER (MINIGE-MNER). The core innovations of this method include: A gene knockout module based on the variational information bottleneck, which removes inferior genes (modality noise) from the text, raw image, and generated image features. This approach retains the superior genes, achieving balanced filtering of modality noise. A determination of gene recombination sites module that maximizes the mutual information between superior genes across modalities, reducing the spatial distance between them and ensuring precise, fine-grained semantic alignment. This helps to prevent the cascading effect of semantic mismatch. A text-guided gene recombination module that implements a “text-dominant, vision-supplementary” cross-modal fusion paradigm. This module dynamically filters out visual noise unrelated to the text while avoiding excessive reliance on visual information that could obscure the unique contextual information of the text, effectively mitigating information loss. Experimental results show that MINIGE-MNER achieves F1 scores of 76.45 % and 88.67 % on the Twitter-2015 and Twitter-2017 datasets, respectively, outperforming existing state-of-the-art methods by 0.83 % and 0.42 %. In addition, this paper presents comprehensive experiments that demonstrate the superiority of MINIGE-MNER and the effectiveness of its individual modules.},
  archive      = {J_NN},
  author       = {Bo Kong and Shengquan Liu and Liruizhi Jia and Yi Liang and Dongfang Han and Xu Zhang},
  doi          = {10.1016/j.neunet.2025.108106},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108106},
  shortjournal = {Neural Netw.},
  title        = {MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deceiving question-answering models: A hybrid word-level adversarial approach. <em>NN</em>, <em>194</em>, 108105. (<a href='https://doi.org/10.1016/j.neunet.2025.108105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning underpins most of the currently advanced natural language processing (NLP) tasks such as textual classification, neural machine translation (NMT), abstractive summarization and question-answering (QA). However, the robustness of the models, particularly QA models, against adversarial attacks is a critical concern that remains insufficiently explored. This paper introduces QA-Attack (Question Answering Attack), a novel word-level adversarial strategy that fools QA models. Our attention-based attack exploits the customized attention mechanism and deletion ranking strategy to identify and target specific words within contextual passages. It creates deceptive inputs by carefully choosing and substituting synonyms, preserving grammatical integrity while misleading the model to produce incorrect responses. Our approach demonstrates versatility across various question types, particularly when dealing with extensive long textual inputs. Extensive experiments on multiple benchmark datasets demonstrate that QA-Attack successfully deceives baseline QA models and surpasses existing adversarial techniques regarding success rate, semantics changes, BLEU score, fluency and grammar error rate.},
  archive      = {J_NN},
  author       = {Jiyao Li and Mingze Ni and Yongshun Gong and Wei Liu},
  doi          = {10.1016/j.neunet.2025.108105},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108105},
  shortjournal = {Neural Netw.},
  title        = {Deceiving question-answering models: A hybrid word-level adversarial approach},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified gradient regularization method for heterogeneous graph neural networks. <em>NN</em>, <em>194</em>, 108104. (<a href='https://doi.org/10.1016/j.neunet.2025.108104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Graph Neural Networks (HGNNs) are advanced deep learning methods widely applied for learning representations of heterogeneous graphs. However, they face challenges such as over-smoothing and non-robustness. Existing methods can mitigate these issues by applying gradient regularization to one of the three information dimensions: node, edge, or propagation message. However, these methods have problems such as unstable training, difficulty in parameter convergence, and inadequate utilization of heterogeneous information. We propose a novel gradient regularization method called Grug, which iteratively applies regularization to the gradients derived from both node type and message matrix during the message-passing process. A detailed theoretical analysis demonstrates its advantages in Stability and Diversity. Notably, Grug potentially exceeds the theoretical upper bounds set by DropMessage. In addition, Grug offers a unified gradient regularization framework that integrates the existing dropping and adversarial training methods, and provides theoretical guidance for their further optimization in different data and tasks. We validate Grug through extensive experiments on six public datasets, showing significant improvements in performance and effectiveness.},
  archive      = {J_NN},
  author       = {Xiao Yang and Xuejiao Zhao and Zhiqi Shen},
  doi          = {10.1016/j.neunet.2025.108104},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108104},
  shortjournal = {Neural Netw.},
  title        = {A unified gradient regularization method for heterogeneous graph neural networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-level graph contrastive learning for community value prediction. <em>NN</em>, <em>194</em>, 108103. (<a href='https://doi.org/10.1016/j.neunet.2025.108103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community Value Prediction (CVP) is an important emerging task in the field of social commerce, which aims to predict the community values. However, due to the complex structure of communities and individuals, previous graph machine learning methods have struggled to adequately address this task. This study endeavors to bridge this gap by introducing a cross-level graph contrastive learning method called Cross-level Community Contrastive Learning (CCCL) to handle such subgraph-level tasks. Specifically, we generate two views that describe different levels of social connections, the augmented node-level graph and the community-level graph that is produced by graph coarsening. Subsequently, CCCL captures the mutual information between the two views through a cross-view contrastive loss. The learned embeddings utilize community and node information at various levels, making them capable of handling subgraph-level regression problems. To the best of our knowledge, CCCL is the first graph contrastive learning method that addresses the CVP problem. We theoretically show that CCCL maximizes a lower bound of the mutual information shared between node-view and community-view representations. Experimental results demonstrate that our proposed approach is highly effective for the CVP task, outperforming both end-to-end and self-supervised baselines. Furthermore, our model also exhibits robust resistance to edge perturbation attacks.},
  archive      = {J_NN},
  author       = {Wenjie Yang and Shengzhong Zhang and Zengfeng Huang},
  doi          = {10.1016/j.neunet.2025.108103},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108103},
  shortjournal = {Neural Netw.},
  title        = {Cross-level graph contrastive learning for community value prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training. <em>NN</em>, <em>194</em>, 108102. (<a href='https://doi.org/10.1016/j.neunet.2025.108102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation, which aims to provide accurate descriptions of both normal and abnormal regions, has been attracting growing research attention. Recently, despite considerable progress, data-driven deep-learning based models still face challenges in capturing and describing the abnormalities, due to the data bias problem. To address this problem, we propose to generate radiology reports via the Visual-Semantic Ambivalence-Aware Network (VSANet) and the Focal Self-Critical Sequence Training (FSCST). In detail, our VSANet follows the encoder-decoder framework. In the encoder part, we first deploy a multi-grained abnormality extractor and a visual extractor to capture both semantic and visual features from given images, and then introduce a Parameter Shared Dual-way Encoder (PSDwE) to delve into the inter- and intra-relationships among these features. In the decoder part, we propose the Visual-Semantic Ambivalence-Aware (VSA) module to generate the abnormality-aware visual features to mitigate the data bias problem. In implementation, our VSA introduces three sub-modules: Dual-way Attention (DwA), introduced to generate both the word-related visual and semantic features; Dual-way Attention on Attention (DwAoA), designed to mitigate redundant information; Score-based Feature Fusion (SFF), constructed to fuse the visual and semantic features in an ambivalence way. We further introduce the FSCST to enhance the overall performance of our VSANet by allocating more attention toward difficult samples. Experimental results demonstrate that our proposal achieves superior performance on various evaluation metrics. Source code have released at https://github.com/SKD-HPC/VSANet .},
  archive      = {J_NN},
  author       = {Xiulong Yi and You Fu and Enxu Bi and Jianguo Liang and Hao Zhang and Jianzhi Yu and Qianqian Li and Rong Hua and Rui Wang},
  doi          = {10.1016/j.neunet.2025.108102},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108102},
  shortjournal = {Neural Netw.},
  title        = {Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discriminative representation learning via attention-enhanced contrastive learning for short text clustering. <em>NN</em>, <em>194</em>, 108101. (<a href='https://doi.org/10.1016/j.neunet.2025.108101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has gained significant attention in short text clustering, yet it has an inherent drawback of mistakenly identifying samples from the same category as negatives and separating them in the feature space (i.e., the false negative separation problem). To generate discriminative representations for short text clustering, we propose a novel clustering method, called Discriminative Representation learning via A ttention- E nhanced C ontrastive L earning for Short Text Clustering ( AECL ). The AECL consists of two modules which are the contrastive learning module and the pseudo-label assisting module. Both modules utilize a sample-level attention mechanism to extract similarities between samples, based on which cross-sample features are aggregated to form a consistent representation for each sample. The contrastive learning module explores the similarity relationships and the consistent representations to form positive samples, effectively addressing the false negative separation issue, and the pseudo-label assisting module utilizes the consistent representations to produce reliable supervision information to assist the clustering task. Experimental results demonstrate that AECL outperforms state-of-the-art methods. The code is available at https://github.com/YZH0905/AECL-STC .},
  archive      = {J_NN},
  author       = {Zhihao Yao and Bo Li and Yufei Liao},
  doi          = {10.1016/j.neunet.2025.108101},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108101},
  shortjournal = {Neural Netw.},
  title        = {Discriminative representation learning via attention-enhanced contrastive learning for short text clustering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects. <em>NN</em>, <em>194</em>, 108100. (<a href='https://doi.org/10.1016/j.neunet.2025.108100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the fixed-time synchronization (FXTS) and prescribed-time synchronization (PSTS) problems of state-dependent switching neural networks (SDSNNs) with stochastic disturbances and impulsive effects. By leveraging the average impulsive interval, comparison principle, and interval matrix methodology, this study advances a novel analytical framework. Departing from conventional approaches, we reformulate stochastic disturbed and impulsive SDSNNs as interval-parameter systems through rigorous interval matrix transformation. Consequently, we derive some sufficient conditions in the form of linear matrix inequalities (LMIs) to ensure the realization of FXTS and PSTS. Since impulsive effects can potentially compromise synchronization stability, careful controller design becomes critical. To address this challenge, we develop a unified proportional integral (PI) control framework. Through proper adjustment of its control parameters, this framework enables the system to achieve both FXTS and PSTS. Moreover, by reasonably configuring the relationship between the impulsive intensity and the prescribed time, the synchronization performance can be balanced. Finally, we demonstrate the effectiveness of the theoretical results through two examples.},
  archive      = {J_NN},
  author       = {Guici Chen and Houxuan Zhang and Shiping Wen and Junhao Hu and Leimin Wang},
  doi          = {10.1016/j.neunet.2025.108100},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108100},
  shortjournal = {Neural Netw.},
  title        = {Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories. <em>NN</em>, <em>194</em>, 108099. (<a href='https://doi.org/10.1016/j.neunet.2025.108099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of long-tail visual recognition, the imbalance in data distribution leads to a significant performance gap between head and tail classes. Improving the tail-class performance and alleviating the decline in head class are two critical questions. Although many methods have proposed solutions for the former, most of them fall short in the latter. Introducing additional knowledge is a novel view to address the problem, however, how to attain useful knowledge and further transfer the knowledge to the target model is the core. This paper proposes a novel method called Expert Knowledge Distillation for Specific Categories (EKDSC). Firstly, we propose a kind of well-trained teacher model ensuring each expert concentrates on its specialized field while being less affected by other interference. Furthermore, the teacher model including three categories of experts: head, mid, and tail classes, is utilized to distill their specialized knowledge to the student model. Experimental results demonstrate that EKDSC effectively improves the accuracy of tail classes, and mitigates the common decreases of head classes’ performance. Our proposed method achieves a high accuracy, exceeding the current state-of-the-art (SOTA) by 1–5 % on benchmark datasets including the small-scale CIFAR-10 LT and CIFAR-100 LT. Furthermore, it demonstrates outstanding performance on large-scale datasets such as ImageNet-LT, iNaturalist 2018, and Places-LT.},
  archive      = {J_NN},
  author       = {Yaping Bai and Jinghua Li and Dehui Kong and Suqiao Yang and Baocai Yin},
  doi          = {10.1016/j.neunet.2025.108099},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108099},
  shortjournal = {Neural Netw.},
  title        = {EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations. <em>NN</em>, <em>194</em>, 108098. (<a href='https://doi.org/10.1016/j.neunet.2025.108098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal imitation learning enables the agent to learn demonstrations of multiple modes at the same time. However, as expert demonstrations in practice tend to have incomplete labels for behavior modes, most methods are inefficient. To address this issue, an approach capable of imitation learning from incompletely labeled expert demonstrations, referred to as Weakly Supervised Multi-modal Imitation Learning (WSMIL), is proposed. WSMIL incorporates weakly supervised learning into multi-modal imitation learning by adding a behavior mode classifier to the adversarial network, thus forming adversaries among three players (generator, classifier and discriminator). Both labeled and unlabeled data are fully utilized in this adversarial process where fake state-action-label pairs generated by the generator and the classifier try to deceive the discriminator that tries to identify them and limited labeled expert demonstrations. Additionally, in order to ensure the data distribution of classifier and generator individually to converge to the expert’s real distribution, three extra losses are employed, where simulated annealing behavioral cloning is also added to the generator network to improve the generalization of policy. Experiments show that WSMIL accurately distinguishes modes with incomplete modal labels in demonstrations, learns close to the expert standard for each mode, and is more stable than other multi-modal methods.},
  archive      = {J_NN},
  author       = {Sijia Gu and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108098},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108098},
  shortjournal = {Neural Netw.},
  title        = {Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection. <em>NN</em>, <em>194</em>, 108097. (<a href='https://doi.org/10.1016/j.neunet.2025.108097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightweight salient object detection (SOD) is widely used in various downstream applications due to its low resource requirements and fast inference speed. The use of hybrid encoders offers the potential to achieve a better balance between efficiency and accuracy for SOD task. However, the aggregation of features from convolutional neural networks (CNNs) and transformers remains challenging, and most existing lightweight SOD models rarely explore the efficient aggregation of cross-architecture features derived from hybrid encoders. In this paper, we propose a hybrid aggregation strategy network (HASNet) that balances accuracy and efficiency for lightweight SOD by grouping and aggregating features to leverage salient information across different architectures. Specifically, the features obtained after hybrid encoder processing are divided into convolutional and transformer features for shallow and deep aggregation respectively. Deep aggregation uses the global inverted residual block (GIRB) to facilitate the transfer of salient information encoded within transformer features across various levels. Meanwhile, shallow aggregation uses the lightweight inverted residual block (LIRB) to efficiently integrate the spatial information inherent in convolutional features. The GIRB incorporates an efficient global operation to extract channel semantic information from the high-dimensional transformer features. The LIRB fuses low-level features by efficiently exploiting the spatial information in features at extremely low computational cost. Comprehensive experiments conducted across five datasets demonstrate that our HASNet significantly outperform existing methods in a thorough evaluation encompassing parameter sizes, inference speed, and accuracy. The source code will be publicly available at https://github.com/LitterMa-820/HASNet .},
  archive      = {J_NN},
  author       = {Jianhua Ma and Mingfeng Jiang and Xian Fang and Jiatong Chen and Yaming Wang and Guang Yang},
  doi          = {10.1016/j.neunet.2025.108097},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108097},
  shortjournal = {Neural Netw.},
  title        = {Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing image restoration through learning context-rich and detail-accurate features. <em>NN</em>, <em>194</em>, 108096. (<a href='https://doi.org/10.1016/j.neunet.2025.108096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration aims to recover high-quality images from their degraded counterparts, necessitating a delicate balance between preserving spatial details and capturing contextual information. Although some methods attempt to address this trade-off, they tend to focus primarily on spatial features while overlooking the importance of understanding frequency variations. Moreover, these approaches commonly utilize skip connections–implemented via addition or concatenation–to fuse encoder and decoder features for improved restoration. However, since encoder features may still carry degradation artifacts, such direct fusion strategies risk introducing implicit noise, ultimately hindering restoration performance. In this paper, we present a multi-scale design that optimally balances these competing objectives, seamlessly integrating spatial and frequency domain knowledge to selectively recover the most informative information. Specifically, we develop a hybrid scale frequency selection block (HSFSBlock), which not only captures multi-scale information from the spatial domain, but also selects the most informative components for image restoration in the frequency domain. Furthermore, to mitigate the inherent noise introduced by skip connections employing only addition or concatenation, we introduce a skip connection attention mechanism (SCAM) to selectively determines the information that should propagate through skip connections. The resulting tightly interlinked architecture, named as LCDNet. Extensive experiments conducted across diverse image restoration tasks showcase that our model attains performance levels that are either superior or comparable to those of state-of-the-art algorithms. The code and the pre-trained models are released at https://github.com/Tombs98/LCDNet .},
  archive      = {J_NN},
  author       = {Hu Gao and Xiaoning Lei and Depeng Dang},
  doi          = {10.1016/j.neunet.2025.108096},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108096},
  shortjournal = {Neural Netw.},
  title        = {Enhancing image restoration through learning context-rich and detail-accurate features},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation. <em>NN</em>, <em>194</em>, 108095. (<a href='https://doi.org/10.1016/j.neunet.2025.108095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter-efficient fine-tuning (PEFT) has emerged as a critical paradigm for adapting large pre-trained models to downstream tasks, offering a balance between computational efficiency and model performance. Among these methods, Low-Rank Adaptation (LoRA) has gained significant popularity due to its efficiency; it freezes the pre-trained weights and decomposes the incremental matrices into two trainable low-rank matrices. However, a critical limitation of LoRA lies in its uniform rank assignment across all layers, which fails to account for the heterogeneous importance of different layers in contributing to task performance, potentially resulting in suboptimal adaptation. To address this limitation, we propose Layer-wise Adaptive Low-Rank Adaptation (La-LoRA), a novel approach that dynamically allocates rank to each layer based on Dynamic Contribution-Driven Parameter Budget (DCDPB) and Truncated Norm Weighted Dynamic Rank Allocation (TNW-DRA) during training. By treating each layer as an independent unit and progressively adjusting its rank allocation, La-LoRA ensures optimal model performance while maintaining computational efficiency and adapting to the complexity of diverse tasks. We conducted extensive experiments across multiple tasks and models to evaluate the effectiveness of La-LoRA. The results demonstrate that La-LoRA consistently outperforms existing benchmarks, validating its effectiveness in diverse scenarios.},
  archive      = {J_NN},
  author       = {Jiancheng Gu and Jiabin Yuan and Jiyuan Cai and Xianfa Zhou and Lili Fan},
  doi          = {10.1016/j.neunet.2025.108095},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108095},
  shortjournal = {Neural Netw.},
  title        = {La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-level dynamic heterogeneous graph network for video question answering. <em>NN</em>, <em>194</em>, 108094. (<a href='https://doi.org/10.1016/j.neunet.2025.108094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Video Question Answering (VideoQA) has garnered considerable research interest as a pivotal task within the realm of vision-language understanding. However, existing Video Question Answering datasets often lack sufficient entity and event information. Thus, the Vision Language Models (VLMs) struggle to complete intricate grounding and reasoning among multi-modal entities or events and heavily rely on language short-cut or irrelevant visual context. To address these challenges, we make improvements from both data and model perspectives. In terms of VideoQA data, we focus on supplementing the missing specific entities and events with the proposed event and entity augmentation strategies. Based on the augmented data, we propose a Dual-Level Dynamic Heterogeneous Graph Network (DDHG) for Video Question Answering. DDHG incorporates transformer layers to capture the dynamic temporal-spatial changes of visual entities. Then, DDHG establishes multi-modal semantic grounding ability between vision and text with entity-level and event-level heterogeneous graphs. Finally, the Dual-level Cross-modal Interaction Module integrates the dual-level features to predict correct answers. Our method not only significantly outperforms existing VideoQA models on two complex event-based benchmark datasets (Causal-VidQA and NExT-QA) but also demonstrates superior event content prediction ability over several state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Zefan Zhang and Yanhui Li and Weiqi Zhang and Tian Bai},
  doi          = {10.1016/j.neunet.2025.108094},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108094},
  shortjournal = {Neural Netw.},
  title        = {Dual-level dynamic heterogeneous graph network for video question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction. <em>NN</em>, <em>194</em>, 108093. (<a href='https://doi.org/10.1016/j.neunet.2025.108093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug–target interaction (DTI) prediction plays a crucial role in drug discovery and repurposing by efficiently and accurately identifying potential therapeutic targets. Existing methods face challenges in capturing high-order semantic relationships in heterogeneous graphs and effectively integrating multi-meta-path information while also suffering from low computational efficiency. To address these challenges, a pre-computation-style hierarchical meta-path learning framework named HMT-DTI is proposed. HMT-DTI can effectively capture rich semantic information about drugs and targets while ensuring high computational efficiency. Specifically, during the pre-collection stage, HMT-DTI employs a Transformer-based message passing mechanism to evaluate neighbors’ importance and adaptively collect meta-path information. The incorporation of even-relation propagation reduces redundant iterations and improves efficiency. During training, HMT-DTI adopts a hierarchical knowledge extraction strategy to evaluate the importance of multi-hop neighbors and different meta-path patterns, capturing fine-grained semantic representations of drugs and targets. HMT-DTI is evaluated on three heterogeneous biological datasets and compared with several state-of-the-art methods. The results demonstrate the superiority of HMT-DTI in DTI prediction.},
  archive      = {J_NN},
  author       = {Dianlei Gao and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108093},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108093},
  shortjournal = {Neural Netw.},
  title        = {HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On training networks of monostable multivibrator timer neurons. <em>NN</em>, <em>194</em>, 108092. (<a href='https://doi.org/10.1016/j.neunet.2025.108092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important bottleneck in present-day neuromorphic hardware is its reliance on synaptic addition, which limits the achievable degree of parallelization and thus processing throughput. We present a network of monostable multivibrator timers, whose synaptic inputs are simply OR-ed together, thus mitigating the synaptic addition bottleneck. Monostable multivibrators are simple timers which are easily implemented using counters in digital hardware and can be interpreted as non biologically-inspired spiking neurons. We show how fully binarized event-driven recurrent networks of monostable multivibrators can be trained to solve classification tasks. Our training algorithm resolves temporally overlapping input events. We demonstrate our approach on the MNIST handwritten digits, Google Soli radar gestures, IBM DVS128 gestures and Yin-Yang classification tasks. The estimated energy consumption for the MNIST handwritten digits task, excluding the final linear readout layer, is 855pJ per inference for a test accuracy of 98.61 % for a reconfigurable network of 500 units, when mapped to the TSMC HPC+ 28 nm process.},
  archive      = {J_NN},
  author       = {Lars Keuninckx and Matthias Hartmann and Paul Detterer and Ali Safa and Wout Mommen and Ilja Ocket},
  doi          = {10.1016/j.neunet.2025.108092},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108092},
  shortjournal = {Neural Netw.},
  title        = {On training networks of monostable multivibrator timer neurons},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis. <em>NN</em>, <em>194</em>, 108091. (<a href='https://doi.org/10.1016/j.neunet.2025.108091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal neuroimaging techniques are widely employed for the accurate diagnosis of Alzheimer’s Disease (AD). Existing fusion methods typically focus on capturing semantic correlations between modalities through feature-level interactions. However, they fail to suppress redundant cross-modal information, resulting in sub-optimal multi-modal representation. Moreover, these methods ignore subject-specific differences in modality contributions. To address these challenges, we propose a novel Multi-modal Orthogonal Fusion Network via cross-layer guidance (MOFNet) to effectively fuse multi-modal information for AD diagnosis. We first design a Cross-layer Guidance Interaction module (CGI), leveraging high-level features to guide the learning of low-level features, thereby enhancing the fine-grained representations on disease-relevant regions. Then, we introduce a Multi-modal Orthogonal Compensation module (MOC) to realize bidirectional interaction between modalities. MOC encourages each modality to compensate for its limitations by learning orthogonal components from other modalities. Finally, a Feature Enhancement Fusion module (FEF) is developed to adaptively fuse multi-modal features based on the contributions of different modalities. Extensive experiments on the ADNI dataset demonstrate that MOFNet achieves superior performance in AD classification tasks.},
  archive      = {J_NN},
  author       = {Yumiao Zhao and Bo Jiang and Yuan Chen and Ye Luo and Jin Tang},
  doi          = {10.1016/j.neunet.2025.108091},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108091},
  shortjournal = {Neural Netw.},
  title        = {Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ClickAttention: Click region similarity guided interactive segmentation. <em>NN</em>, <em>194</em>, 108090. (<a href='https://doi.org/10.1016/j.neunet.2025.108090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive segmentation algorithms based on click points have attracted significant attention from researchers in recent years. However, most existing methods rely on sparse click maps as model inputs to segment specific target objects. These clicks primarily affect local regions, limiting the model’s ability to focus on the entire target object and often resulting in a higher number of required clicks. Additionally, many current algorithms struggle to balance performance and efficiency effectively. To address these challenges, we propose a click attention algorithm that expands the influence of positive clicks by leveraging the similarity between positively-clicked regions and the entire input. We further introduce a discriminative affinity loss to reduce attention coupling between positive and negative click regions, minimizing accuracy degradation caused by mutual interference. On the DAVIS dataset, our method achieves a 2 % performance gain (NoC@90) over the state-of-the-art SimpleClick-ViT-L, while using only 15.6 % of its parameters. Extensive experiments demonstrate that our approach outperforms existing methods and achieves state-of-the-art performance with fewer parameters. Data and code are published.},
  archive      = {J_NN},
  author       = {Long Xu and Yongquan Chen and Shanghong Li and Junkang Chen and Ziyuan Tang},
  doi          = {10.1016/j.neunet.2025.108090},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108090},
  shortjournal = {Neural Netw.},
  title        = {ClickAttention: Click region similarity guided interactive segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A vision-language model for multitask classification of memes. <em>NN</em>, <em>194</em>, 108089. (<a href='https://doi.org/10.1016/j.neunet.2025.108089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of social media and online memes has led to an increasing demand for automated systems that can analyse and classify multimodal data, particularly in online forums. Memes blend text and graphics to express complicated ideas, sometimes containing emotions, satire, or inappropriate material. Memes often represent cultural prejudices such as objectification, sexism, and bigotry, making it difficult for artificial intelligence to classify these components. Our solution is the vision-language model ViT-BERT CAMT (cross-attention multitask), which is intended for multitask meme categorization. Our model uses a linear self-attentive fusion mechanism to combine vision transformer (ViT) features for image analysis and bidirectional encoder representations from transformers (BERT) for text interpretation. In this way, we can see how text and images relate to space and meaning. We tested the ViT-BERT CAMT on two difficult datasets: the SemEval 2020 Memotion dataset, which contains a multilabel classification of sentiment, sarcasm, and offensiveness in memes, and the MIMIC dataset, which focuses on detecting sexism, objectification, and prejudice. The findings show that the ViT-BERT CAMT achieves good accuracy on both datasets and outperforms many current baselines in multitask settings. These results highlight the importance of combined image-text modelling for correctly deciphering nuanced meanings in memes, particularly when spotting abusive and discriminatory content. By improving multimodal categorization algorithms, this study helps better monitor and comprehend online conversation.},
  archive      = {J_NN},
  author       = {Md. Mithun Hossain and Md. Shakil Hossain and M.F. Mridha and Nilanjan Dey},
  doi          = {10.1016/j.neunet.2025.108089},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108089},
  shortjournal = {Neural Netw.},
  title        = {A vision-language model for multitask classification of memes},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view learning meets state-space model: A dynamical system perspective. <em>NN</em>, <em>194</em>, 108088. (<a href='https://doi.org/10.1016/j.neunet.2025.108088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning exploits the complementary nature of multiple modalities to enhance performance across diverse tasks. While deep learning has significantly advanced these fields by enabling sophisticated modeling of intra-view and cross-view interactions, many existing approaches still rely on heuristic architectures and lack a principled framework to capture the dynamic evolution of feature representations. This limitation hampers interpretability and theoretical understanding. To address these challenges, this paper introduces the Multi-view State-Space Model (MvSSM), which formulates multi-view representation learning as a continuous-time dynamical system inspired by control theory. In this framework, view-specific features are treated as external inputs, and a shared latent representation evolves as the internal system state, driven by learnable dynamics. This formulation unifies feature integration and label prediction within a single interpretable model, enabling theoretical analysis of system stability and representational transitions. Two variants, MvSSM-Lap and MvSSM-iLap, are further developed using Laplace and inverse Laplace transformations to derive system dynamics representations. These solutions exhibit structural similarities to graph convolution operations in deep networks, supporting efficient feature propagation and theoretical interpretability. Experiments on benchmark datasets such as IAPR-TC12, and ESP demonstrate the effectiveness of the proposed method, achieving up to 4.31 % improvement in accuracy and 4.27 % in F1-score over existing state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Weibin Chen and Ying Zou and Zhiyong Xu and Li Xu and Shiping Wang},
  doi          = {10.1016/j.neunet.2025.108088},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108088},
  shortjournal = {Neural Netw.},
  title        = {Multi-view learning meets state-space model: A dynamical system perspective},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph convolutional network with adaptive grouping aggregation strategy. <em>NN</em>, <em>194</em>, 108086. (<a href='https://doi.org/10.1016/j.neunet.2025.108086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of graph convolutional networks (GCNs) with naive aggregation functions on nodes has reached the bottleneck, rendering a gap between practice and theoretical expressity. Some learning-based aggregation strategies have been proposed to improve the performance. However, few of them focus on how these strategies affect the expressity and evaluate their performance in an equal experimental setting. In this paper, we point out that the generated features lack discrimination because naive aggregation functions cannot retain sufficient node information, largely leading to the performance gap. Accordingly, a novel Adaptive Grouping Aggregation (AGA) strategy is proposed to remedy this drawback. Inspired by the label histogram in the Weisfeiler-Lehman (WL) Test, this strategy assigns each node to a unique group to retain more node information, which is proven to have a strictly more powerful expressity. In this work setting, the nodes are grouped according to a modified Student’s t-Distribution between node features and a set of learnable group labels, where the Gumbel Softmax is employed to implement this strategy in an end-to-end trainable pipeline. As a result, such a design can generate more discriminative features and offer a plug-in module in most architectures. Extensive experiments have been conducted on several benchmarks to compare our method with other aggregation strategies. The proposed method improves the performance in all control groups of all benchmarks and achieves the best result in most cases. Additional ablation studies and comparisons with state-of-the-art methods on the large-scale benchmark also indicate the superiority of our method.},
  archive      = {J_NN},
  author       = {Ruixiang Wang and Chunxia Zhang and Chunhong Pan},
  doi          = {10.1016/j.neunet.2025.108086},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108086},
  shortjournal = {Neural Netw.},
  title        = {Graph convolutional network with adaptive grouping aggregation strategy},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-driven optimization of collaborative multi-agent via case learning and curiosity. <em>NN</em>, <em>194</em>, 108083. (<a href='https://doi.org/10.1016/j.neunet.2025.108083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Deep Reinforcement Learning(MADRL) faces significant challenges in exploration-exploitation trade-off during training, particularly when learning collaborative behaviors through continuous environment interactions. Current exploration methods generally rely on unbiased randomized policy, which makes the policy optimization process lack of goal-directed, resulting in a large number of low signal-to-noise ratio transitions collected in the experience replay buffer, which seriously affects the learning efficiency and policy convergence stability of MADRL. To address the above research challenges, We propose the Case-Enhanced Random Network Distillation Exploration for Centralized Training and Decentralized Execution(CERE-CTDE) paradigm. Our innovation lies in the novel integration of Random Network Distillation(RND) and Case-Based Reasoning(CBR): RND provides intrinsic motivation to enhance exploration and overcome sparse rewards, while CBR enables goal-directed exploitation by leveraging historical case to guide agent action selection. This dual mechanism creates a dynamic equilibrium between exploring novel policy and exploiting proven case, effectively preventing premature convergence. We incorporate the CERE into two categories of MADRL methods based on the CTDE paradigm. The performance of us is assessed and validated with 2 methods focused on exploration using 13 confrontation scenarios in the StarCraft Multi-Agent Challenge(SMAC). The experimental results demonstrate: a 17.97 % statistically significant improvement in win rate on complex battlefields compared to baseline performance in simple scenarios; effective enhancement of policy exploration-exploitation and mitigation of partial sparse reward problems through intrinsic motivation and CBR-guided action sampling; and superior capability in escaping local optima while maintaining learning efficiency. The framework’s robustness is further validated by its consistent performance across different SMAC scenarios with varying difficulty levels.},
  archive      = {J_NN},
  author       = {Ruizhu Chen and Rong Fei and Junhuai Li and Aimin Li and Yalin Miao and Lili Wu and Zhiming Chen},
  doi          = {10.1016/j.neunet.2025.108083},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108083},
  shortjournal = {Neural Netw.},
  title        = {Dual-driven optimization of collaborative multi-agent via case learning and curiosity},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive behavior with stable synapses. <em>NN</em>, <em>194</em>, 108082. (<a href='https://doi.org/10.1016/j.neunet.2025.108082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral changes in animals and humans, triggered by errors or verbal instructions, can occur extremely rapidly. While learning theories typically attribute improvements in performance to synaptic plasticity, recent findings suggest that such fast adaptations may instead result from dynamic reconfiguration of the networks involved without changes to synaptic weights. Recently, similar capabilities have been observed in transformers, foundational architecture in machine learning widely used in applications such as natural language and image processing. Transformers are capable of in-context learning, the ability to adapt and acquire new information dynamically within the context of the task or environment they are currently engaged in, without changing their parameters. We argue that this property may stem from gain modulation–a feature widely observed in biological networks, such as pyramidal neurons through input segregation and dendritic amplification. We propose a constructive approach to induce in-context learning in an architecture composed of recurrent networks with gain modulation, demonstrating abilities inaccessible to standard networks. In particular, we show that, such architecture can dynamically implement standard gradient-based by encoding weight changes in the activity of another network. We argue that, while these algorithms are traditionally associated with synaptic plasticity, their reliance on non-local terms suggests that they may be more naturally realized in the brain at the level of neural circuits. We demonstrate that we can extend our approach to temporal tasks and reinforcement learning. We further validate our approach in a MuJoCo ant navigation task, showcasing a neuromorphic control paradigm via real-time network reconfiguration.},
  archive      = {J_NN},
  author       = {Cristiano Capone and Luca Falorsi},
  doi          = {10.1016/j.neunet.2025.108082},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108082},
  shortjournal = {Neural Netw.},
  title        = {Adaptive behavior with stable synapses},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Disentangled self-supervised video camouflaged object detection and salient object detection. <em>NN</em>, <em>194</em>, 108077. (<a href='https://doi.org/10.1016/j.neunet.2025.108077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video tasks play an important role in multimedia fields. In various video tasks, such as video camouflaged/salient object detection (VCOD/VSOD), motion and context information are two important aspects. Despite the fact that many existing works have already achieved promising results in VCOD and VSOD tasks, they still have limitations when it comes to leveraging motion and context information. In this paper, we propose a new disentangled perspective to treat motion and context information in VCOD and VSOD tasks. Our proposed model can respectively utilize context and motion information in ContextNet and MotionNet, without conflicting with each other as there can be biases between these two types of information in certain circumstances. Moreover, we further explore how to apply disentangled perspective in the self-supervised manner, which can reduce annotation costs. Specifically, we first design a self-supervised adaptive frame routing mechanism to determine whether each video frame belongs to ContextNet or MotionNet. Then we design a cross-supervision for ContextNet and MotionNet to train these two segmentation networks in self-supervised mechanism. In experiments, our proposed self-supervised disentangled model consistently outperforms state-of-the-art unsupervised methods on VCOD and VSOD datasets.},
  archive      = {J_NN},
  author       = {Haoke Xiao and Lv Tang and Bo Li and Zhiming Luo and Shaozi Li},
  doi          = {10.1016/j.neunet.2025.108077},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108077},
  shortjournal = {Neural Netw.},
  title        = {Disentangled self-supervised video camouflaged object detection and salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Design, analysis and verification of noise-tolerant and overshoot-free recurrent neural network. <em>NN</em>, <em>194</em>, 108075. (<a href='https://doi.org/10.1016/j.neunet.2025.108075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A kind of recurrent neural network (RNN) specialized in solving time-varying problems has wide applications in various fields, where the RNN with integral terms (RNN-IT) as a state-of-art method plays an important role in rejecting noise. However, the RNN-IT always experiences overshoot phenomenon when suppressing noise, which greatly affects the convergence time. In order to overcome the above disadvantage of the RNN-IT, this paper proposes a noise-tolerant and overshoot-free recurrent neural network (NORNN) by designing a time-varying additional term, which can flexibly compensate errors and avoid accumulation, thereby resisting noise and eliminating overshoot. Furthermore, the convergence time of the NORNN is obviously improved, which means that the NORNN can effectively and quickly address time-varying problems even when the noise disturbed. Two theorems and a corollary analyze the convergence, noise-tolerance, and overshoot-free properties of the proposed NORNN. Meanwhile, simulation experiments on solving the time-varying matrix inversion problem and the trajectory tracking of the RPRR manipulator also verify its excellent performance.},
  archive      = {J_NN},
  author       = {Lei Jia and Tiandong Zheng and Yujie Wu and Yiwei Li},
  doi          = {10.1016/j.neunet.2025.108075},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108075},
  shortjournal = {Neural Netw.},
  title        = {Design, analysis and verification of noise-tolerant and overshoot-free recurrent neural network},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WPDA: Frequency-based backdoor attack with wavelet packet decomposition. <em>NN</em>, <em>194</em>, 108074. (<a href='https://doi.org/10.1016/j.neunet.2025.108074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores backdoor attack, which is an emerging security threat against deep neural networks (DNNs). The adversary aims to inject a backdoor into the model by manipulating a portion of training samples, such that the backdoor could be activated by a particular trigger to make a target prediction at inference. Currently, existing backdoor attacks often require moderate or high poisoning ratios to achieve the desired attack performance, but making them susceptible to some advanced backdoor defenses ( e . g . , poisoned sample detection). One possible solution to this dilemma is enhancing the attack performance at low poisoning ratios, which has been rarely studied due to its high challenge. To achieve this goal, we propose an innovative frequency-based backdoor attack via wavelet packet decomposition (WPD), which could finely decompose the original image into multiple sub-spectrograms with semantic information. It facilitates us to accurately identify the most critical frequency regions to effectively insert the trigger into the victim image, such that the trigger information could be sufficiently learned to form the backdoor. The proposed attack stands out for its exceptional effectiveness, stealthiness, and resistance at an extremely low poisoning ratio. Notably, it achieves the 98.12 % attack success rate on CIFAR-10 with an extremely low poisoning ratio of 0.004 % ( i.e. , only 2 poisoned samples among 50,000 training samples), and bypasses several advanced backdoor defenses. Besides, we provide more extensive experiments to demonstrate the efficacy of the proposed method, as well as in-depth analyses to explain its underlying mechanism.},
  archive      = {J_NN},
  author       = {Zhengyao Song and Yongqiang Li and Danni Yuan and Li Liu and Shaokui Wei and Baoyuan Wu},
  doi          = {10.1016/j.neunet.2025.108074},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108074},
  shortjournal = {Neural Netw.},
  title        = {WPDA: Frequency-based backdoor attack with wavelet packet decomposition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts. <em>NN</em>, <em>194</em>, 108064. (<a href='https://doi.org/10.1016/j.neunet.2025.108064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are gaining popularity for processing graph data. In real-world scenarios, graph data within the same dataset can vary significantly in scale. This variability leads to depth-sensitivity, where the optimal depth of GNN layers depends on the scale of the graph data. Empirically, fewer layers are sufficient for message passing in smaller graphs, while larger graphs typically require deeper networks to capture long-range dependencies and global features. However, existing methods generally use a fixed number of GNN layers to generate representations for all graphs, overlooking the depth-sensitivity issue in graph data. To address this challenge, we propose the depth adaptive mixture of expert (DA-MoE) method, which incorporates two main improvements to GNN backbone: 1) DA-MoE employs different GNN layers, each considered an expert with its own parameters. Such a design allows the model to flexibly aggregate information at different scales, effectively addressing the depth-sensitivity issue in graph data. 2) DA-MoE utilizes GNN to capture the structural information instead of the linear projections in the gating network. Thus, the gating network enables the model to capture complex patterns and dependencies within the data. By leveraging these improvements, each expert in DA-MoE specifically learns distinct graph patterns at different scales. Furthermore, comprehensive experiments on the TU dataset and open graph benchmark (OGB) have shown that DA-MoE consistently surpasses existing baselines on various tasks, including graph, node, and link-level analyses. The code are available at https://github.com/Celin-Yao/DA-MoE .},
  archive      = {J_NN},
  author       = {Zelin Yao and Mukun Chen and Chuang Liu and Xianke Meng and Yibing Zhan and Jia Wu and Shirui Pan and Huiting Xu and Wenbin Hu},
  doi          = {10.1016/j.neunet.2025.108064},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108064},
  shortjournal = {Neural Netw.},
  title        = {DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic graph representation learning with disentangled information bottleneck. <em>NN</em>, <em>194</em>, 108056. (<a href='https://doi.org/10.1016/j.neunet.2025.108056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph representation learning recently garnered enormous research attention. Despite the notable successes of existing methods, they usually characterize dynamic graphs as a perceptual whole and learn dynamic graph representations within an entangled feature space, which overlook different temporal dependencies inherent in the data. Specifically, the evolution of dynamic graphs is usually decided by a dichotomy in properties: time-invariant properties and time-varying properties. Existing holistic works fail to distinguish these temporal properties and may suffer suboptimal performance in downstream tasks. To tackle this problem, we propose to learn macro-disentangled dynamic graph representations based on the Information Bottleneck theory, leading to a novel dynamic graph representation learning method, Disentangled Dynamic Graph Information Bottleneck (DDGIB). Our DDGIB explicitly embeds the dynamic graphs into a time-invariant representation space and a time-varying representation space. The time-invariant representation space encapsulates stable properties across the temporal span of dynamic graphs, whereas the time-varying representation space encapsulates time-fluctuating properties. The macro disentanglement on the temporal dependencies facilitates the representations’ performance on downstream tasks. Furthermore, we theoretically prove the sufficiency and macro disentanglement of DDGIB. The sufficiency demonstrates that DDGIB can achieve sufficient representations for any possible downstream tasks, while the macro disentanglement certifies that DDGIB can embed the different temporal properties into their corresponding temporal representation space. Extensive experimental results on various datasets and downstream tasks demonstrate the superiority of our method.},
  archive      = {J_NN},
  author       = {Jihong Wang and Yuxin Bai and Chunqiang Zhu and Hao Qian and Ziqi Liu and Minnan Luo},
  doi          = {10.1016/j.neunet.2025.108056},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108056},
  shortjournal = {Neural Netw.},
  title        = {Dynamic graph representation learning with disentangled information bottleneck},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning. <em>NN</em>, <em>194</em>, 108023. (<a href='https://doi.org/10.1016/j.neunet.2025.108023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral diversity emerges as a crucial factor for achieving effective collaboration in Multi-Agent Reinforcement Learning (MARL). Current methods often use partial parameter sharing, such as sharing the same representation layer, to balance behavioral diversity and algorithmic scalability. However, this approach ignores that different agents need different decision knowledge, causing training conflicts and knowledge redundancy. To solve these, we propose Tailoring Knowledge for Empowered Cooperative Actions in Multi-Agent Reinforcement Learning (TKCA). Specially, we employ a set of Knowledge Encoders to encode different environment types of knowledge and utilize a Knowledge Selector network to assist each agent in decision-making by selecting the corresponding knowledge. We evaluated TKCA in challenging StarCraftII micromanagement games and Google Research Football games, and the results demonstrate the superior performance of TKCA.},
  archive      = {J_NN},
  author       = {Hu Fu and Yihua Tan and Hao Chen and Pengyi Li},
  doi          = {10.1016/j.neunet.2025.108023},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108023},
  shortjournal = {Neural Netw.},
  title        = {Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
