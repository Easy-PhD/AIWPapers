<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ESWA</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eswa">ESWA - 279</h2>
<ul>
<li><details>
<summary>
(2026). Modeling trust in human–Robot collaborative construction: An improved cloud bayesian network. <em>ESWA</em>, <em>298</em>, 129928. (<a href='https://doi.org/10.1016/j.eswa.2025.129928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust developed by workers towards robotic systems is critical to the successful implementation of human-robot collaboration (HRC) in construction, directly influencing operational efficiency and safety outcomes. To accurately evaluate trust risks within HRC scenarios, this study proposes an integrated method combining an improved Cloud Model (CM) with Bayesian Networks (BNs) for dynamic trust risk analysis. Initially, key factors influencing trust risks in HRC were identified through literature review and expert elicitation. The improved CM was then employed to capture inherent uncertainties and fuzziness in trust state definitions, facilitating the discretization of continuous expert evaluations into appropriate risk states. Subsequently, the BN was developed to perform forward reasoning, sensitivity analysis, and backward diagnosis, enabling proactive trust risk prediction, critical factor identification, and targeted interventions. The primary contributions of this research include: (a) identifying 11 trust factors from human, organizational, and robotic perspectives, offering a comprehensive basis for analyzing HRC trust risk in construction; (b) employing an optimized cloud entropy approach to accurately capture fuzziness and randomness in expert evaluations, thereby producing robust prior probabilities; and (c) developing a hybrid CBN framework to assess HRC trust risk in construction, demonstrating superior performance in risk perception, analysis, and control. Overall, this study provides valuable insights into safer and more effective HRC through dynamic evaluation of trust risk.},
  archive      = {J_ESWA},
  author       = {Lei Wang and Mingyu Zhang and Heng Li and Yinong Hu and Jie Ma and Waleed Umer and Xin Fang},
  doi          = {10.1016/j.eswa.2025.129928},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129928},
  shortjournal = {Expert Syst. Appl.},
  title        = {Modeling trust in human–Robot collaborative construction: An improved cloud bayesian network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A machine learning-based medical device recall initiator prediction framework: From supply chain risk management and resilience view. <em>ESWA</em>, <em>298</em>, 129922. (<a href='https://doi.org/10.1016/j.eswa.2025.129922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persistent quality problems with medical devices and the associated recall present potential health risks to users, bringing extra costs and disturbances to the supply chain. Classical medical device recall strategy neglects the significance of the failure detection process in the premarket phase, increasing the medical device recall risks. This research first established the theoretical foundation for the medical device recall reasons detection problem by reconstructing the medical device recall strategy from the supply chain risk and resilience view and reinforced the importance of failure detection and quality inspection work in the premarket stage. Moreover, existing medical device failure reason prediction research was limited in practicality and scalability. To address this problem, we developed a machine learning-based medical device recall initiator prediction system framework to conduct proactive failure detection based on the industrial case. By redesigning in dataset, clustering method and input feature selection, an accuracy rate of 88.85% is achieved, which indicates the potential of the proposed framework in assisting manufacturers with asset predictive failure detection for reducing recall. A comparative analysis of prediction performance between our framework and the most similar research that utilized the same prediction algorithms was presented. The comparison results showed that our distinctive design in the dataset, clustering method, and key input features chosen are valid and efficient. Before redesigning the prediction algorithms that require higher technical investment, our elaborate research design in selecting the dataset, cluster method, and key input features can be the antecedents of better prediction performance for manufacturers. The proposed predictive framework obtains higher accuracy, scalability, practicality, with accessibility.},
  archive      = {J_ESWA},
  author       = {Yang Hu and Davy Monticolo and Pezhman Ghadimi},
  doi          = {10.1016/j.eswa.2025.129922},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129922},
  shortjournal = {Expert Syst. Appl.},
  title        = {A machine learning-based medical device recall initiator prediction framework: From supply chain risk management and resilience view},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A computational learning pipeline for glaucoma progression detection based on the prediction of visual field changes from fundus photographs. <em>ESWA</em>, <em>298</em>, 129907. (<a href='https://doi.org/10.1016/j.eswa.2025.129907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of glaucoma progression is crucial to managing patients, permitting individualized care plans and treatment. It is a challenging task requiring the assessment of structural changes to the optic nerve head and functional changes based on visual field testing. Artificial intelligence, especially deep learning techniques, has shown promising results in many applications, including glaucoma diagnosis. This paper proposes a two-stage computational learning pipeline for detecting glaucoma progression using only fundus photographs. In the first stage, a deep learning model takes a time series of fundus photographs as input and outputs a vector of predictions where each element represents the overall rate of change in visual field (VF) sensitivity values for a sector (region) of the optic nerve head (ONH). We implemented two deep learning models—ResNet50 and InceptionResNetV2—for this stage. In the second stage, a binary classifier (weighted logistic regression) takes the predicted vector as input to detect progression. We also propose a novel method for constructing annotated datasets from temporal sequences of clinical fundus photographs and corresponding VF data suitable for machine learning. Each dataset element comprises a temporal sequence of photographs together with a vector-valued label. The label is derived by computing the pointwise linear regression of VF sensitivity values at each VF test location, mapping these locations to eight ONH sectors, and assigning the overall rate of change in each sector to one of the elements of the vector. We used a retrospective clinical dataset with 82 patients collected at multiple timepoints over five years in our experiments. The InceptionResNetV2-based implementation yielded the best performance, achieving detection accuracies of 97.28 ± 1.10 % for unseen test data (i.e., each dataset element is unseen but originates from the same set of patients appearing in the training dataset), and 87.50 ± 0.70 % for test data from unseen patients (training and testing patients are entirely different). The testing throughput was 11.60 ms per patient. These results demonstrate the efficacy of the proposed method for detecting glaucoma progression from fundus photographs.},
  archive      = {J_ESWA},
  author       = {Md.Reduanul Haque and Andrew Mehnert and William Huxley Morgan and Graham Mann and Ferdous Sohel},
  doi          = {10.1016/j.eswa.2025.129907},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129907},
  shortjournal = {Expert Syst. Appl.},
  title        = {A computational learning pipeline for glaucoma progression detection based on the prediction of visual field changes from fundus photographs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Operator learning-based springback behavior prediction for complex-shaped tube free-bending forming. <em>ESWA</em>, <em>298</em>, 129899. (<a href='https://doi.org/10.1016/j.eswa.2025.129899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Free-bending (FB) technology enables the efficient processing of spatially complex-shaped tubes. Springback causes variations in curvature and torsion of the tube axis during the FB process. The mapping relationship of bent tube curvature and torsion from ideal to actual values can be abstracted as nonlinear physical operators. This paper first proposes a novel six-axis FB processing method that can control geometric features of tube transition segments. Then, an operator learning-based springback behavior prediction (OL-SBP) framework is presented, which includes an OL module and an SBP module. A feature-information-enhanced deep operator network (FIE-DeepONet) is integrated into the first module to learn tube springback operators. The curvature and torsion predicted by the OL module are then fed into the SBP module to calculate the overall shape of the springback axis. This paper also introduces a set of similarity evaluation indicators that are independent of the curve’s spatial attitude. Planar and spatial bent tubes are selected as case studies. Results show that the framework yields more accurate predictions compared to the analytical model. The framework also exhibits excellent generalization performance. Once FIE-DeepONet has learned the springback operators, it can accurately predict the springback curvature and torsion, even for tube shapes not present during training.},
  archive      = {J_ESWA},
  author       = {Yongzhe Xiang and Zili Wang and Shuyou Zhang and Le Wang and Caicheng Wang and Yaochen Lin and Jianrong Tan},
  doi          = {10.1016/j.eswa.2025.129899},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129899},
  shortjournal = {Expert Syst. Appl.},
  title        = {Operator learning-based springback behavior prediction for complex-shaped tube free-bending forming},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exact reliability of cold chain networks with multi-state travel time and transport capacity. <em>ESWA</em>, <em>298</em>, 129892. (<a href='https://doi.org/10.1016/j.eswa.2025.129892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post-pandemic lifestyle changes have increased reliance on e-commerce, boosting the logistics sector. One of the most highly regarded industries is cold chain logistics, especially for vaccines and refrigerated foods. In cold chain networks, transport routes have varying capacities based on customer orders, and travel times fluctuate due to traffic and weather. Thus, this study focuses on evaluating network reliability, i.e., the probability to meet given demands within the specified time threshold, of cold chain networks considering the two multi-state factors: travel time and transport capacity. To account for practical situations, a multi-state cold chain network (MCCN) is constructed with retailers, third-party logistics companies, and suppliers as nodes, and transportation routes as arcs. The concept of minimal path is used to determine the transport flow that complies with the time threshold and to determine the transport capacity vectors that satisfy the demands. An algorithm is proposed to resolve different characteristics of time thresholds and demand requirements for efficient assessment. Network reliability is successfully calculated, as shown in the case and sensitivity analysis. This allows managers to grasp the performance of MCCN and make informed decisions based on the achieved network reliability.},
  archive      = {J_ESWA},
  author       = {Thi-Phuong Nguyen and Chin-Lung Huang and Louis Cheng-Lu Yeng and Yi-Kuei Lin},
  doi          = {10.1016/j.eswa.2025.129892},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129892},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exact reliability of cold chain networks with multi-state travel time and transport capacity},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An RL-NSGA-DP algorithm for optimization of robot placement and trajectory allocation in mobile robotic grinding of wind turbine blades. <em>ESWA</em>, <em>298</em>, 129876. (<a href='https://doi.org/10.1016/j.eswa.2025.129876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robot machining, offering a more flexible and reconfigurable approach compared to fixed-base robots, has therefore become a promising solution for efficiently machining large and complex wind turbine blades. In this context, determining proper machining placements and allocating machining trajectories are two pivotal factors in the mobile robotic automation grinding of wind turbine blades, directly affecting machining efficiency and quality. However, the highly nonlinear performance distribution of the robot in the task space, combined with the complexity of the machining surface, presents significant challenges. To address these challenges, this paper presents a general optimization model of this problem with the objectives of completion time and robot manipulability, considering singularity avoidance and collision avoidance. Based on this model, an improved non-dominated sorting genetic algorithm integrated with reinforcement learning and dual population co-evolution (RL-NSGA-DP) is developed. In RL-NSGA-DP, each solution is coded using a novel two-layer metavariable encoding scheme, and a tailored dominated-recessive crossover operator is designed. Moreover, a dual-population collaborative search strategy employing different operators and an adaptive switching environmental selection mechanism based on reinforcement learning are implemented to ensure the convergence and maintain population diversity. Comparative experiments on test instances and a practical case study demonstrate that RL-NSGA-DP outperforms five well-known multi-objective evolutionary algorithms, and effectively addresses robot placement and trajectory allocation problem in mobile robotic machining systems.},
  archive      = {J_ESWA},
  author       = {Yi Hua and Xuewu Wang},
  doi          = {10.1016/j.eswa.2025.129876},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129876},
  shortjournal = {Expert Syst. Appl.},
  title        = {An RL-NSGA-DP algorithm for optimization of robot placement and trajectory allocation in mobile robotic grinding of wind turbine blades},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RAFN: A risk-aware feature network for identifying risk factors in supply chain finance. <em>ESWA</em>, <em>298</em>, 129874. (<a href='https://doi.org/10.1016/j.eswa.2025.129874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As supply chain finance businesses expand, traditional risk assessment systems, which rely heavily on manual processes and static rule-based frameworks, are increasingly unable to keep up with the complexity and dynamism of modern risk patterns. This often leads to delayed responses and inefficiencies in risk management. To address key challenges such as difficulties in integrating heterogeneous data, low detection rates for hidden risks, and limited ability to capture dynamic risk patterns, this paper introduces a novel Risk-Aware Feature Network (RAFN) driven by an adaptive attention mechanism. The RAFN model is designed with a dual-channel architecture to process numerical and categorical data separately, employs gated linear units to dynamically merge heterogeneous data streams, and incorporates a multi-head attention mechanism with dynamic coefficients to focus on risk-sensitive features adaptively. Experiments conducted on both public and proprietary datasets show that RAFN outperforms mainstream algorithms, achieving a 1.73%-5.81% improvement in accuracy, recall, and F1-score, while maintaining a strong balance between specificity and recall. Furthermore, this study proposes a closed-loop risk management framework based on RAFN, which integrates “smart contract triggering, off-chain model evaluation, and on-chain consensus validation.” This approach offers an efficient technical solution to break down data silos and enhance the precision of risk identification in supply chain finance, paving the way for more effective and reliable risk control systems.},
  archive      = {J_ESWA},
  author       = {Yang Zhang and Yating Zhao and Wenjuan Lian and Bin Jia},
  doi          = {10.1016/j.eswa.2025.129874},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129874},
  shortjournal = {Expert Syst. Appl.},
  title        = {RAFN: A risk-aware feature network for identifying risk factors in supply chain finance},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Novel design and speed-adaptive control of a cable-driven parallel elastic hip exoskeleton for compliant locomotion assistance. <em>ESWA</em>, <em>298</em>, 129871. (<a href='https://doi.org/10.1016/j.eswa.2025.129871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic hip exoskeletons hold enormous potential to enhance human locomotion. However, the rigid structures and predefined control laws limit their compliance and adaptability during dynamic human-robot interactions. Here, a novel parallel elastic hip exoskeleton is developed for human locomotion assistance. The exoskeleton utilizes a remote cable actuation system to improve compliance and incorporates a parallel elastic mechanism at the hip wearable components to enhance actuator energy efficiency by generating a compensatory torque. For exoskeleton control, a speed-adaptive torque control strategy is implemented to modulate the assistance torque in real time, based on the user’s gait phase and hip movement frequency estimated by adaptive oscillators. The system was tested on seven healthy subjects, and preliminary results indicate that the parallel elastic element achieves a 40.2 % reduction in peak motor torque through energy conversion. The controller exhibits excellent torque tracking performance and effectively extracts human gait features across walking speeds with hip frequency correlation ( R 2 = 0.89). Furthermore, the hip exoskeleton significantly reduced users’ peak hip moments and muscle activity while preserving natural kinematics. The parallel elastic hip exoskeleton demonstrates strong adaptive assistive capabilities and is expected to enhance locomotion in real-world applications.},
  archive      = {J_ESWA},
  author       = {Jing Zhang and Aibin Zhu and Bingsheng Bao and Xinyu Wu and Chunli Zheng and Meng Li and Jing Wang and Yu Zhang and Xue Wu and Xiao Li},
  doi          = {10.1016/j.eswa.2025.129871},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129871},
  shortjournal = {Expert Syst. Appl.},
  title        = {Novel design and speed-adaptive control of a cable-driven parallel elastic hip exoskeleton for compliant locomotion assistance},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Short-term high-speed rail passenger flow forecasting integrated extended empirical mode decomposition with multivariate and bidirectional support vector machine. <em>ESWA</em>, <em>298</em>, 129870. (<a href='https://doi.org/10.1016/j.eswa.2025.129870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-speed rail (HSR) short-term passenger flow forecasting is of great significance for dynamically adjusting operation plans and optimizing transportation resource allocation. For this reason, this paper proposes an innovative complete ensemble empirical mode decomposition with adaptive noise integrated with multivariate and bidirectional support vector machine (CEEMDAN-MBSVM) method with four key steps. First, we analyze the correlations between multiple origin–destination (OD) passenger flows and select strongly correlated ODs incorporated with their opposite OD for joint bidirectional forecasting. Second, we decompose the original passenger flow time series by using period division technique of CEEMDAN, which yield multiple intrinsic mode functions (IMFs) and a residual trend term (RES). Then we apply MBSVM to predict the IMFs of each OD and use trend extrapolation to forecast the RES. Finally, we reconstruct the predicted IMFs and RES to obtain the final bidirectional HSR OD daily passenger flows. Subsequently, we conduct a comprehensive validation exercise and significance testing, using real data from Beijing-Shanghai HSR Line, against seven prediction methods. In particular, for five selected ODs, benchmarking against EEMD-MSVM method, the best performer among the six existing models, our model reduces the minimum mean absolute percentage error (MAPE) by 1.30 % to 4.97 % and benchmarking against ARIMA model, the worst performer among the six existing models, our model reduces the MAPE by 11.57 % to 22.72 %. This research has clearly demonstrated the value of leveraging bidirectional OD data on improving short-term passenger flow forecasting.},
  archive      = {J_ESWA},
  author       = {Xueyi Guan and Michael Z.F. Li and Jin Qin and Chengna Wang},
  doi          = {10.1016/j.eswa.2025.129870},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129870},
  shortjournal = {Expert Syst. Appl.},
  title        = {Short-term high-speed rail passenger flow forecasting integrated extended empirical mode decomposition with multivariate and bidirectional support vector machine},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Frequency-decomposed attention joint optimization network for image compressive sensing. <em>ESWA</em>, <em>298</em>, 129866. (<a href='https://doi.org/10.1016/j.eswa.2025.129866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network approaches for image compressive sensing (ICS) have garnered significant attention due to their high efficiency and fidelity in image reconstruction. Reconstructing complex image textures from highly compressed measurements has been a longstanding goal of ICS, yet existing methods often struggle to varying degrees with the restoration of low-frequency (LF) textures and high-frequency (HF) details, which potentially limits the quality of the reconstructed image. In this paper, we propose a Frequency-decomposed Attention Joint Optimization Network (FAJO-Net) for ICS, which is capable of enhancing the attention to LF and HF components of images. Specifically, we introduce a frequency-decomposed sparse prior and coupling fidelity constraints, and incorporate a tri-optimization network framework for full, low, and high-frequency (FLH) features, where each component is optimized using an optimization-unfolded multi-scale network (OM-Net), inclusive of Principal Component Augmented Gradient Descent Module (PCAGDM) and U-shaped Proximal Mapping Module (UPMM). The PCAGDM optimizes the FLH features efficiently by supplementing the optimization of the minimum dimension principal component augmented features while optimizing the principal component features. The UPMM is able to perform multi-scale proximal mapping for all FLH features. Finally, we design a Frequency-decomposed Interaction Attention Module (FIAM) to enhance the fusion of FLH features, particularly the HF and LF components related to the full-frequency features, while reducing the impact of unnecessary features introduced by frequency decomposition. Extensive experiments demonstrate that our proposed FAJO-Net surpasses the state-of-the-art ICS networks in terms of image fidelity and visual effect, and validates that the proposed FAJO-Net framework can help enhance the image reconstruction capabilities of the vast majority of existing ICS networks, further unlocking the potential for high-fidelity restoration in ICS. Code is available at https://github.com/giant-pandada/FAJO-Net .},
  archive      = {J_ESWA},
  author       = {Zhifu Tian and Tao Hu and Di Wu and Shu Wang and Tingli Li and Ming Zhang},
  doi          = {10.1016/j.eswa.2025.129866},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129866},
  shortjournal = {Expert Syst. Appl.},
  title        = {Frequency-decomposed attention joint optimization network for image compressive sensing},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Identification of critical nodes by fusing propagation probabilities and entropy in binary networks. <em>ESWA</em>, <em>298</em>, 129861. (<a href='https://doi.org/10.1016/j.eswa.2025.129861'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identification of critical nodes is crucial for effectively allocating resources and prioritizing tasks in complex networks, which significantly enhances the stability and the efficiency of networks in real-world environments. Generally, existing studies primarily focus on extracting multiple different influential factors from network topology, but they have to face accuracy limitations due to high computational complexity, overlapping influence ranges, and information loss. Inspired by information entropy, in this paper, we explore to identify critical node in complex networks from the perspective of inter-node propagation probabilities. We introduce an innovative critical node ranking algorithm, named MNIE (Mixed Node Information Entropy). MNIE initially segments the node influence within the network topology by distinguishing between global and local effects so as to integrate a more comprehensive topological features set. Then, we refine the connection probability calculation and integrate the features derived from the network structural topology with the probabilities of information transmission (infection rates) among the nodes. Experimental results on 9 real-world networks and 4 synthetic datasets indicate that MNIE enhances the identification of critical nodes and accomplishes better than state-of-the-art methods on monotonicity and accuracy.},
  archive      = {J_ESWA},
  author       = {Lintao Zhang and Jianing Zhang and Rong Yan and Guoqin Yu},
  doi          = {10.1016/j.eswa.2025.129861},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129861},
  shortjournal = {Expert Syst. Appl.},
  title        = {Identification of critical nodes by fusing propagation probabilities and entropy in binary networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive energy management for battery swapping stations using HMDE-PSO: Optimizing charge-discharge control against cyber-physical attacks. <em>ESWA</em>, <em>298</em>, 129860. (<a href='https://doi.org/10.1016/j.eswa.2025.129860'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Battery Swapping Stations (BSSs) are emerging as critical components in smart power systems, offering rapid energy refueling, grid load balancing, and improved battery lifecycle management for electric vehicles (EVs). However, the economic operation and cyber-physical security of BSSs remain underexplored, particularly in microgrids that integrate distributed generation (DG) and face increasing vulnerability to cyber-attacks. This paper presents a novel, adaptive energy management framework that optimally schedules the charge and discharge cycles of BSSs under uncertain EV user behavior and potential cyber-physical disruptions. A key innovation lies in modeling two types of cyber-attacks—power disruption and control hijacking—and embedding their technical and economic impacts directly into the optimization process. To solve this multi-objective problem, a Hybrid multi-objective Differential Evolution–Particle Swarm Optimization (HMDE-PSO) algorithm is proposed, which efficiently balances cost minimization, system reliability, and resilience. The framework is validated using the IEEE 69-bus distribution system, demonstrating substantial improvements: over 40% reduction in power losses, enhanced voltage stability, and lower operational costs compared to conventional methods. This work distinguishes itself by integrating cyber-defense considerations with real-time energy scheduling, providing a comprehensive and resilient solution for future BSS-integrated microgrids.},
  archive      = {J_ESWA},
  author       = {Mehdi Ahmadi Jirdehi and Hamdi Abdi and Hazhir Dousti},
  doi          = {10.1016/j.eswa.2025.129860},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129860},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive energy management for battery swapping stations using HMDE-PSO: Optimizing charge-discharge control against cyber-physical attacks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-enhanced 3D residual networks for knee abnormality classification. <em>ESWA</em>, <em>298</em>, 129858. (<a href='https://doi.org/10.1016/j.eswa.2025.129858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of deep learning technologies, particularly through Convolutional Neural Networks (CNNs), has substantially enriched medical image analysis. This study focuses on improving knee MRI diagnostics by comparing 2D and 3D CNN architectures using the MRNet and SKM-TEA datasets. Initially, modified 2D CNNs, such as ResNet50, were applied for plane-specific and integrated multi-plane analyses. Plane-specific models captured detailed anatomical features, while integrated approaches synthesized information across multiple planes, improving diagnostic capability but lacking full volumetric data utilization. To address these limitations, a novel 3D CNN architecture enhanced with residual attention blocks was developed, leveraging volumetric MRI data. These blocks integrate spatial attention and Squeeze-and-Excitation (SE) mechanisms, optimizing feature focus for accurate diagnostics. This approach improved both model precision and interpretability, which are crucial for clinical applications. Experimental evaluation on the MRNet dataset demonstrated that the proposed 3D CNN outperformed 2D models, achieving 83.58 % accuracy for abnormalities. On the SKM-TEA dataset, the model classified Meniscal Tear (71.36 %), Ligament Tear (79.84 %), Cartilage Lesion (84.28 %), and Effusion (76.74 %), demonstrating robustness in complex pathology detection. Gradient-weighted Class Activation Mapping (Grad-CAM) further enhanced interpretability by highlighting critical diagnostic regions. These findings emphasize the effectiveness of attention-guided 3D CNNs in knee abnormality classification. Future work will explore broader applications in medical imaging, refining the model’s generalizability across diverse clinical datasets.},
  archive      = {J_ESWA},
  author       = {Mohamad M.A. Ashames and Semih Ergin and Omer N. Gerek and H. Serhan Yavuz},
  doi          = {10.1016/j.eswa.2025.129858},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129858},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attention-enhanced 3D residual networks for knee abnormality classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SmartScope: Smart contract vulnerability detection via heterogeneous graph embedding with local semantic enhancement. <em>ESWA</em>, <em>298</em>, 129857. (<a href='https://doi.org/10.1016/j.eswa.2025.129857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart contracts are integral to blockchain ecosystems, yet their security remains a critical concern due to the prevalence of exploitable vulnerabilities. Existing conventional and deep learning-based vulnerability detection methods often struggle to capture the fine-grained semantics and heterogeneous structural dependencies essential for accurate analysis. We propose and implement SmartScope , a novel technique for smart contract vulnerability detection that leverages heterogeneous graph embedding with local semantic enhancement. Specifically, SmartScope constructs a semantically rich contract graph that depicts control-flow, data-flow, and fallback relations among critical code elements. To guide the graph learning process, we empirically assign various importance coefficients to vulnerability-relevant subgraphs, thereby enhancing the detection model’s focus on semantically critical regions. The heterogeneous graph transformer is then employed to generate context-aware node representations, which are then passed to an MLP-based detector for vulnerability classification. To the best of our knowledge, this is the first method that structurally encodes domain knowledge into the heterogeneous graph learning for achieving effective smart contract analysis. Experimental results demonstrate that SmartScope outperforms 10 representative conventional and deep learning-based baselines on over 5K smart contracts. The evaluation spans multiple vulnerability types, including reentrancy, timestamp dependence, and infinite loops, highlighting the effectiveness and robustness of our work.},
  archive      = {J_ESWA},
  author       = {Zhaoyi Meng and Zexin Zhang and Wansen Wang and Jie Cui and Hong Zhong},
  doi          = {10.1016/j.eswa.2025.129857},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129857},
  shortjournal = {Expert Syst. Appl.},
  title        = {SmartScope: Smart contract vulnerability detection via heterogeneous graph embedding with local semantic enhancement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Short-term air quality prediction using a multi-scale attention fusion model with 3DIGAT-CBAM-BiLSTM based on spatio-temporal correlation. <em>ESWA</em>, <em>298</em>, 129856. (<a href='https://doi.org/10.1016/j.eswa.2025.129856'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air Quality Index (AQI) prediction is crucial for environmental management and public health. However, most existing studies focus on single site modeling, neglecting the complex spatial correlations of meteorological factors and air pollutants. Therefore, a multi-scale spatio-temporal prediction model, 3DIGAT-CBAM-BiLSTM, is proposed to fully capture the spatio-temporal evolution characteristics of AQI. To reduce the interference of redundant information, the Maximum Information Coefficient and Dynamic Time Series Trend Correlation Method are employed to select the neighboring sites and influencing factors that are highly correlated with the AQI of the target site. The original air quality data is decomposed and reconstructed into high-frequency, low-frequency, and trend-term subsequences using Multivariate Variational Mode Decomposition and Sample Entropy to enhance prediction accuracy. To forecast the three-dimensional spatial tensors of these reconstructed subsequences based on time steps, monitoring sites, and influencing factors, we propose the 3DIGAT-CBAM-BiLSTM model. The spatial dependencies between sites are effectively captured by the Improved Graph Attention Network, which constructs a graph adjacency matrix based on MIC and geographic distance. Meanwhile, the Convolutional Block Attention Mechanism enhances the focus on important sites and features by combining channel and spatial attention. Furthermore, the Bidirectional Long Short-Term Memory network extracts global temporal patterns. The experimental results on the Beijing dataset show that the proposed model achieves a relative reduction of 8.53 % in RMSE and 5.83 % in MAE compared with the optimal baseline model, demonstrating clear performance improvements and offering a novel approach for modeling complex spatio-temporal data.},
  archive      = {J_ESWA},
  author       = {Liangqiong Zhu and Liren Chen and Huayou Chen},
  doi          = {10.1016/j.eswa.2025.129856},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129856},
  shortjournal = {Expert Syst. Appl.},
  title        = {Short-term air quality prediction using a multi-scale attention fusion model with 3DIGAT-CBAM-BiLSTM based on spatio-temporal correlation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EEG-based emotion identification from nerve conduction mechanisms: A gustatory-emotion coupling model combined with multiblock attention module. <em>ESWA</em>, <em>298</em>, 129855. (<a href='https://doi.org/10.1016/j.eswa.2025.129855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG)-based emotion identification enables accurate emotional interaction in brain-computer fusion by decoding brain signals, thereby enhancing the intelligence of human-computer collaboration. Data augmentation (DA) techniques offer a promising solution to the challenge of data scarcity in emotion identification. However, traditional DA methods often overlook the physiological mechanisms underlying EEG data, limiting their effectiveness and constraining the performance of emotion classification. To address this, a DA model based on human nerve conduction mechanisms (NCMs), named the gustatory-emotion coupling model and multiblock attention module (GECM-MBAM), is proposed to improve the performance of emotion identification. First, the 1/ f characteristics and synchronization of brain responses are reproduced in the GECM output when stimulated by EEG. The bionic performance of the model in EEG processing is validated, demonstrating brain-like perception of EEG signals via the GECM. Second, the MBAM is designed based on the characteristics of the GECM output, facilitating data augmentation of emotion-related EEG. Comparative experiments demonstrate that GECM-MBAM remarkably outperforms multiple existing DA models in recognition accuracy ( p < 0.05), confirming its effectiveness and superiority in EEG data augmentation. Finally, when compared with state-of-the-art algorithms and in ablation studies, GECM-MBAM demonstrates superior performance in emotion recognition. Specifically, GECM-MBAM attains accuracies of 96.91 % and 94.52 %, recalls of 96.23 % and 93.86 %, and kappa coefficients of 95.45 % and 94.29 % on the SEED and SEED-IV datasets, respectively. In conclusion, the performance of emotion identification is improved using the GECM-MBAM, offering a novel bionic processing approach for affective computing.},
  archive      = {J_ESWA},
  author       = {Wenbo Zheng and Yong Peng and Ancai Zhang and Quan Yuan},
  doi          = {10.1016/j.eswa.2025.129855},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129855},
  shortjournal = {Expert Syst. Appl.},
  title        = {EEG-based emotion identification from nerve conduction mechanisms: A gustatory-emotion coupling model combined with multiblock attention module},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CoSemiGNN: Blockchain fraud detection with dynamic graph neural networks based on co-association of semi-supervised. <em>ESWA</em>, <em>298</em>, 129853. (<a href='https://doi.org/10.1016/j.eswa.2025.129853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of blockchain technology, the increasing number of cyber frauds has caused huge economic losses, prompting more and more researchers to focus on how to effectively detect criminal activities in the blockchain transaction environment. Currently, graph neural network (GNN)-based methods have made significant progress in the field of blockchain illegal transaction detection due to their advantages in extracting graph structure features. However, existing illegal transaction pattern detection methods usually rely on historical labeled data. In the blockchain transaction environment, transaction data changes over time, and it is often difficult to obtain transaction labels. As a result, the performance of these methods is often unsatisfactory when faced with newly distributed transaction data. To address this challenge, this paper proposes a dynamic graph neural network based on co-association of semi-supervised (CoSemiGNN) for more efficiently identifying illegal transactions in blockchain environments under conditions of dynamically changing transaction data. The model combines semi-supervised learning with a dynamic graph neural network, enabling it to effectively identify novel illegal transaction patterns from unlabeled data and adapt to the evolving blockchain network environment. Specifically, CoSemiGNN captures features of novel transactions by integrating semi supervised learning results. It utilizes co-occurrence relations of edges and co-occurrence feature aggregation of nodes to skillfully integrate semi-supervised methods into feature extraction of transaction graphs, enabling the model to extract novel illegal transaction patterns from unlabeled data. In addition, the model utilizes self attention recurrent neural networks (RNNs) to capture temporal information in transactions, ensuring the dynamics of CoSemiGNN. Finally, we theoretically analyze the model, and experiments on a real Bitcoin transaction dataset demonstrate that CoSemiGNN outperforms existing methods by as much as 30 % in terms of F1 scores for detecting illegal transactions when the transaction data undergoes distributional migration. This research compensates the problem that existing methods ignore the distributional changes of blockchain transaction data, and provides a new perspective and an effective solution for blockchain illegal transaction detection.},
  archive      = {J_ESWA},
  author       = {Yulong Wang and Qingxiao Zheng and Xuedong Li and Lingfeng Wang and Ling Lin},
  doi          = {10.1016/j.eswa.2025.129853},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129853},
  shortjournal = {Expert Syst. Appl.},
  title        = {CoSemiGNN: Blockchain fraud detection with dynamic graph neural networks based on co-association of semi-supervised},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LLM-based exploration and analysis of real-time and historical blockchain data. <em>ESWA</em>, <em>298</em>, 129851. (<a href='https://doi.org/10.1016/j.eswa.2025.129851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has revolutionized digital transactions and decentralized applications through its transparent and immutable ledger system, with platforms like Ethereum processing millions of transactions daily. However, as blockchain networks grow, traditional blockchain explorers show limitations when providing intuitive access to this vast data landscape, particularly when handling complex analytical queries, interpreting transaction patterns, and serving users without technical expertise. In this paper, we address these limitations by proposing an intelligent blockchain explorer that combines a Large Language Model (LLM)-powered agent for real-time blockchain interactions with a schema-aware SQL agent for historical data analysis. For real-time interactions, a dedicated blockchain agent connects to live networks through external APIs and specialized tools to process queries about current transactions and network states. When analyzing historical data patterns, we use an approach in which a Retrieval-Augmented Generation (RAG) system enhances the SQL agent’s understanding of the blockchain database schema and structure. This SQL agent subsequently translates natural language queries into SQL commands for efficient data retrieval from our periodically synchronized blockchain database. A query processor, powered by an LLM, intelligently routes user queries between these components based on temporal and contextual requirements, which enables both immediate blockchain state analysis and complex historical data querying. We evaluate our system on diverse blockchain queries, including complex analytical scenarios and multi-step operations. The experimental results demonstrate the effectiveness of our schema-aware SQL agent in accurate query translation and the overall system’s capability in handling both real-time and historical blockchain data exploration tasks.},
  archive      = {J_ESWA},
  author       = {S. Gebreab and A. Musamih and K. Salah and R. Jayaraman},
  doi          = {10.1016/j.eswa.2025.129851},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129851},
  shortjournal = {Expert Syst. Appl.},
  title        = {LLM-based exploration and analysis of real-time and historical blockchain data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RL-DFN: A reinforcement learning-driven dual-view feature fusion network for aspect-based sentiment analysis in online public opinion. <em>ESWA</em>, <em>298</em>, 129850. (<a href='https://doi.org/10.1016/j.eswa.2025.129850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis of online public opinion plays a vital role in understanding emotional dynamics on social media. However, most existing approaches focus on overall sentiment within text, often neglecting fine-grained sentiment information. This limitation restricts the depth of insights obtainable for public opinion monitoring. Aspect-based sentiment analysis (ABSA) addresses this issue by identifying sentiment toward specific aspects. Despite its advantages, current ABSA methods struggle to effectively integrate syntactic and sequential features, leading to incomplete contextual understanding. Additionally, noisy dependency trees introduce irrelevant syntactic features, which mislead sentiment classification and degrade accuracy. To address these challenges, we propose RL-DFN, a reinforcement learning-driven dual-view feature fusion network that enhances the robustness of ABSA models. RL-DFN consists of a dual-view feature fusion network and an actor-critic reinforcement learning module. The dual-view feature fusion network employs a graph attention network (GAT) to extract syntactic features and a transformer to capture sequential features. These complementary features are then fused through a bilinear affine transformation (Biaffine) module which captures fine-grained and bidirectional correlations between syntactic and sequential representations, enabling more expressive cross-view interactions. Simultaneously, an actor-critic reinforcement learning module dynamically refines the dependency tree representations by identifying key dependency types and filtering out noise, ensuring the reliability of syntactic features used in fusion. Extensive experiments on five widely used benchmark datasets demonstrate that RL-DFN significantly outperforms existing models, validating the effectiveness of our approach.},
  archive      = {J_ESWA},
  author       = {Ziheng Li and Kui Zhao},
  doi          = {10.1016/j.eswa.2025.129850},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129850},
  shortjournal = {Expert Syst. Appl.},
  title        = {RL-DFN: A reinforcement learning-driven dual-view feature fusion network for aspect-based sentiment analysis in online public opinion},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Truck scheduling optimization at a cold chain cross-docking terminal considering uncertainties and the door-mixed service mode. <em>ESWA</em>, <em>298</em>, 129849. (<a href='https://doi.org/10.1016/j.eswa.2025.129849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing global demand for perishable agricultural products necessitates advancements in cold chain logistics. Cross-docking, known for its efficiency, is particularly well-suited for the transfer and distribution of such goods. However, truck scheduling at cold chain cross-dock terminals (CDTs) presents unique challenges, including product perishability, stringent time windows, and temperature-controlled environments. This work investigates a truck scheduling problem within a cold chain CDT, explicitly addressing uncertainties in refrigerated product damage (affecting supply) and repackaging times. A two-stage stochastic programming model is developed to capture these uncertainties. To solve this model, a scenario reduction approach employing K-means++ and K-medoids clustering is used, followed by Sample Average Approximation. Small-scale instances are solved optimally using CPLEX. For larger instances, a novel hybrid heuristic algorithm, combining the global search capabilities of Genetic Algorithms with the local search capabilities of Adaptive Large Neighborhood Search and Simulated Annealing, is proposed. Numerical experiments demonstrate the effectiveness of this algorithm, and sensitivity analysis provides valuable managerial insights.},
  archive      = {J_ESWA},
  author       = {Feifeng Zheng and Yuzhi Yi and Ming Liu and Huaxin Qiu},
  doi          = {10.1016/j.eswa.2025.129849},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129849},
  shortjournal = {Expert Syst. Appl.},
  title        = {Truck scheduling optimization at a cold chain cross-docking terminal considering uncertainties and the door-mixed service mode},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage hybrid heuristic approach combining genetic algorithm and variable neighborhood descent for the clustered electric vehicle routing problem. <em>ESWA</em>, <em>298</em>, 129848. (<a href='https://doi.org/10.1016/j.eswa.2025.129848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a new variant of the Electric Vehicle Routing Problem (EVRP), termed the Clustered Electric Vehicle Routing Problem (CluEVRP). In CluEVRP, all customers are pre-divided into clusters, and each charging station is either located within a cluster or independent of any cluster. Each electric vehicle must complete service for all customers within the current cluster before proceeding to the next cluster or returning to the depot. Electric vehicles can charge at any available charging station while serving a cluster, but incur a penalty cost upon entering each cluster. The objective is to minimize the total logistics cost, comprising vehicle startup costs, cluster entry penalty costs, and energy consumption costs. To solve CluEVRP, a two-stage hybrid heuristic combining a Genetic Algorithm (GA) and Variable Neighborhood Descent (VND) is proposed (HGA-VND), where GA ensures population diversity and VND enhances local search capability. To evaluate the algorithm’s performance, 75 test instances are adapted from classic Clustered Vehicle Routing Problem (CluVRP) dataset, incorporating electric vehicle characteristics. Computational results demonstrate that HGA-VND consistently obtains high-quality solutions within reasonable time for both CluVRP and CluEVRP instances, exhibiting good performance. Furthermore, sensitivity analysis indicates that moderately increasing vehicle capacity, optimizing battery configuration, and adopting lightweight designs can significantly reduce total operating costs. This study extends traditional EVRP research by introducing clustered customer distribution, enriching solutions for routing problems in practical logistics networks, particularly for “milk run” models in industrial parks, and providing significant managerial insights.},
  archive      = {J_ESWA},
  author       = {Yuheng Jin and Xiaoguang Bao and Zhaocai Wang},
  doi          = {10.1016/j.eswa.2025.129848},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129848},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-stage hybrid heuristic approach combining genetic algorithm and variable neighborhood descent for the clustered electric vehicle routing problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Group-guided prompt learning for vision-language models. <em>ESWA</em>, <em>298</em>, 129846. (<a href='https://doi.org/10.1016/j.eswa.2025.129846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt learning has become one of the mainstream approaches for enabling Vision-Language Models (VLMs) to effectively adapt to downstream tasks. Recent approaches enhanced the generalization of models by integrating prior knowledge from large language models (LLMs). However, these approaches overlook the potential value of group knowledge derived from semantic correlations across different classes, which may limit the performance of the model in the face of complex downstream tasks. To overcome this challenge, we propose Group-guided Prompt Learning (GGPL) , which integrates group knowledge into the original text prompts through LLMs. Specifically, GGPL uses LLMs to group all classes and integrates the group knowledge into the original text prompts to construct the final text prompts. Furthermore, we introduce a novel Group Knowledge Alignment (GKA) module, which aligns the learnable prompt features with the pre-trained features that contain group knowledge, preventing the learnable prompt features from feature shift during the training process and thus reducing overfitting. Experimental results across 11 public datasets demonstrate that the proposed GGPL method achieves significant improvement on various prompt learning approaches, while numerous ablation experiments also demonstrate the effectiveness of the each component of our GGPL method.},
  archive      = {J_ESWA},
  author       = {Yufei Zheng and Shengsheng Wang and Yansheng Gao},
  doi          = {10.1016/j.eswa.2025.129846},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129846},
  shortjournal = {Expert Syst. Appl.},
  title        = {Group-guided prompt learning for vision-language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MTMP: Multimodal targeted molecule generation model with protein features. <em>ESWA</em>, <em>298</em>, 129845. (<a href='https://doi.org/10.1016/j.eswa.2025.129845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular generation is a fundamental task in computational chemistry and drug discovery, aiming to design molecular structures with specific properties through algorithmic approaches. Traditional molecular generation models predominantly rely on SMILES representations or molecular topological graphs, limiting their ability to comprehensively capture molecular characteristics. To address this limitation, we propose MTMP, a generative model that bridges molecular structure and sequence. It uses a graph neural network to encode topological features and a GRU decoder to generate SMILES strings. This integration enhances the joint modeling of chemical properties and structure. Furthermore, MTMP incorporates a pre-trained language model trained on large-scale protein sequence data to extract target protein features, enabling a direct and more precise encoding of protein-specific information. This facilitates the generation of molecules with enhanced binding affinity to specific protein targets. To further improve molecular design efficacy, the model was pre-trained on the ZINC molecular database and subsequently fine-tuned via transfer learning using a curated dataset of ligand molecules with known activity against specific target proteins. Experimental evaluations demonstrate that MTMP achieves competitive performance compared to state-of-the-art molecular generation methods. The model produces structurally valid and diverse molecules with favorable physicochemical properties and strong drug-likeness. Notably, it generates novel compounds with high docking scores against target proteins, underscoring its potential for de novo drug design and targeted molecular discovery.},
  archive      = {J_ESWA},
  author       = {Dingming Liang and Runfu Yu and Xiaofeng Wang and Kaiyu Dong and Yunjing Zhang and Huicong Liang and Ximing Xu and Tao Song and Shuang Wang},
  doi          = {10.1016/j.eswa.2025.129845},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129845},
  shortjournal = {Expert Syst. Appl.},
  title        = {MTMP: Multimodal targeted molecule generation model with protein features},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing mixture-of-experts model with prior knowledge for infrared and visible image fusion in complex degraded environments. <em>ESWA</em>, <em>298</em>, 129844. (<a href='https://doi.org/10.1016/j.eswa.2025.129844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion aims to generate a composite image that simultaneously preserves thermal radiation information from infrared images and the rich texture details of visible images. However, existing studies have overlooked the adverse effects of scene degradation in visible images on the fusion process, leading to suboptimal fusion outcomes. To address the challenges posed by scene degradation in image fusion tasks, this paper proposes an image fusion network with degradation correction capability named the Enhancing Mixture-of-Experts model with Prior knowledge for infrared and visible image fusion (EMPFusion), which pioneers the automated execution of multiple degradation restoration tasks during the fusion process. First, we develop a diffusion model for degradation removal to generate high-quality pseudo-labels of visible images, thereby providing supervisory signals for training the fusion network. Second, to overcome the significant challenges in feature extraction caused by complex and diverse degradation scenarios, we design a Degradation removal backbone based on Prior knowledge and the Mixture-of-Experts (DPM) module. This architecture removes degradation with low loss and moderate computational overhead by integrating domain-specific prior knowledge and the Mixture-of-Experts framework. Furthermore, to mitigate semantic loss under extreme environmental conditions, we propose a Semantic Deconstruction and Segmentation (SDS) module based on image-text foundation models, enhancing semantic consistency throughout the fusion process. Extensive experiments demonstrate that EMPFusion excels in infrared-visible fusion tasks within complex degraded scenes. Across the LLVIP, M3FD, RoadScene, and MSRS datasets, EMPFusion achieves state-of-the-art (SOTA) performance on multiple evaluation metrics, showcasing exceptional degradation robustness and visual-semantic information preservation capabilities. By unifying adaptive degradation correction with fusion, this research addresses fusion distortion caused by degraded multimodal data in harsh environments, significantly enhancing applicability and robustness in downstream tasks such as autonomous driving and security monitoring.},
  archive      = {J_ESWA},
  author       = {Gang Li and Chengrun Jiang and Jiachen Li and Jin Wan and Mingle Zhou and Delong Han},
  doi          = {10.1016/j.eswa.2025.129844},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129844},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing mixture-of-experts model with prior knowledge for infrared and visible image fusion in complex degraded environments},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-scenario building change detection in remote sensing images using CNN-mamba hybrid network and consistency enhancement learning. <em>ESWA</em>, <em>298</em>, 129843. (<a href='https://doi.org/10.1016/j.eswa.2025.129843'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-scenario building change detection (BCD) plays a crucial role in scientific decision-making for urban development, natural disasters, and war scenarios. Nevertheless, current research confronts several challenges: (1) In deep learning (DL) methods, convolutional neural networks (CNN) fail to capture global information, and transformer has high computational overhead. (2) The clear distinction and collaborative suppression of scene-level and data-level pseudo-changes remain unresolved. (3) Multi-scenario BCD remains under-explored. To address these challenges, this study proposes a dual pseudo-change suppression framework for multi-scenario BCD. The framework includes the novel C 2 Mamba DL model (CNN collaborates with Mamba) and the consistency enhancement learning strategy (CELS). Among them, the C 2 Mamba merges the local feature extraction capability of CNN with the efficient global modeling capability of Mamba. It further integrates the proposed progressive context information aggregation module (PCIA) and the multi-scale differential feature enhancement module (MDFE). These two modules enable the model to effectively distinguish building changes among various ground targets, thereby suppressing the scene-level pseudo-changes. The CELS first performs data augmentation on the post-temporal images, including weather (clouds, rain, and overcast) and sensor differences. Subsequently, a novel difference-focused loss function is designed to ensure the accurate alignment of the change features between the original and enhanced image pairs, thereby suppressing the data-level pseudo-changes. In experiments, the BCD performance of urban development, natural disasters, and war scenarios is evaluated using WHU-CD, xBD, and WraBCD datasets, respectively. Compared to the second-best methods, the proposed method achieves F1-score improvements of 1.36%, 2.69%, and 1.65%, and IoU improvements of 2.49%, 3.21%, and 2.32%, respectively. Additionally, numerous ablation experiments are conducted to validate the validity of the proposed method. And the robustness of the proposed method is verified through zero-shot generalization and few-shot testing.},
  archive      = {J_ESWA},
  author       = {Wei Li and Guorui Ma and Haiming Zhang and Peng Chen and Di Wang and Rong Chen},
  doi          = {10.1016/j.eswa.2025.129843},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129843},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-scenario building change detection in remote sensing images using CNN-mamba hybrid network and consistency enhancement learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Software defect prediction based on graph code semantics. <em>ESWA</em>, <em>298</em>, 129842. (<a href='https://doi.org/10.1016/j.eswa.2025.129842'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As software systems become larger and more complicated, researchers are focusing more on how to effectively determine whether a program is flawed. Convolutional neural networks (CNNs) have been employed by several researchers in recent years to extract latent semantic information based on Abstract Syntax Trees (AST). However, the small granularity of code information in AST makes it easy to focus on local information and difficult to capture global semantic information. Further, ASTs lack control flow and data flow edges to fully utilize the code’s contextual semantic information. In this paper, we obtain the Control Flow Graph (CFG) and Program Dependence Graph (PDG) of a program through the improved TinyPDG. The Continuous Bag-of-Words (CBOW) model is utilized to train the corpus of CFG and PDG. Additionally, an improved PNIAT layer that combines multi-head attention and BiLSTM is employed to obtain method-level semantic feature vectors. Subsequently, methods based on weighted summation and linear fully connected are respectively proposed to aggregate method-level semantic feature vectors into file-level semantic feature vectors. The joint features are then constructed in combination with the hand-labeled features. Finally, after balancing the data using the SMOTETomek method, 11 machine learning models are used as classifiers for defect prediction. The experimental findings demonstrate that, compared to current software defect prediction techniques, the PDG using a weighted summation-based approach in the QDA model (W-PDG-QDA) presented in this research is the best, and improves AUC, F1, and accuracy scores by 0.723 % -21.72 %, 5.18 % -55.25 % and 1.99 % -25.16 %.},
  archive      = {J_ESWA},
  author       = {Hongwei Tao and Tao Wang and Zhenhao Geng and Xiaoxu Niu and Qiaoling Cao},
  doi          = {10.1016/j.eswa.2025.129842},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129842},
  shortjournal = {Expert Syst. Appl.},
  title        = {Software defect prediction based on graph code semantics},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel grey possibility clustering method based on inverse perspective and its applications. <em>ESWA</em>, <em>298</em>, 129837. (<a href='https://doi.org/10.1016/j.eswa.2025.129837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The center-point mixed possibility functions (CMPFs), which are determined by the decision makers qualitatively, are the most important element to obtain the effective clustering results in a grey clustering model. However, different decision makers provide different CMPFs which may lead to inconsistent or contradictory clustering results. In response to this problem, this article proposes an inverse grey possibility clustering model which can determine the CMPFs based on the part of the given final results. This novel matrix-based method can derive all of the required CMPFs which satisfy the partially known clustering results. More specifically, four theorems are put forward to analyze the four different cases, which are single index single object (SISO), single index multiple objects (SIMO), multiple indices single object (MISO) and multiple indices multiple objects (MIMO), respectively, to derive the required CMPFs of a given clustering result using algebraic expressions. For the purpose of developing the matrix representations for the MISO and MIMO situations, a new unified expression of the CMPFs to replace their existing segmented function expression is proposed. Finally, in order to demonstrate how it can be used in practice, the proposed method is applied for evaluating the effects of the reduction of pollution and carbon emissions and determining aerospace equipment component suppliers with different types of data. Compared to the forward GPC models, the proposed IGPC model has higher accuracy.},
  archive      = {J_ESWA},
  author       = {Junjie Wang and Xun Li and Yaoguo Dang and Zhongju Shang and Li Ye and Sifeng Liu},
  doi          = {10.1016/j.eswa.2025.129837},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129837},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel grey possibility clustering method based on inverse perspective and its applications},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Balancing semantic and structural decoding for fMRI-to-image reconstruction. <em>ESWA</em>, <em>298</em>, 129836. (<a href='https://doi.org/10.1016/j.eswa.2025.129836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing visual images from fMRI signals is an enticing task that opens new horizons in understanding the intricate workings of human cognition. Most existing methods benefit from the diffusion model to decode high-level semantic information from fMRI signals, achieving promising semantic reconstruction. However, such a solution ignores low-level structure information, e.g. , object location and color, leading to an uncompleted visual reconstruction. In this work, we present a novel fMRI-to-image approach to reconstruct high-quality images by balancing semantic and structural decoding in the diffusion model. Specifically, we first utilize the CLIP model and an MLP module to extract sufficient semantic information and structural details, respectively. Then we design a S emantic and S tructural A wareness B alanced module ( SSAB ) to predict the weight of structural information for the current denoising step, thus generating high-quality images by gradually integrating semantic and structural information during image reconstruction. Experimental results demonstrate that the proposed SSAB model is effective with only a few extra parameters, it achieves state-of-the-art performance in comprehensively evaluating both semantic and structural metrics. All code is available on https://github.com/Venchy-he/SSAB .},
  archive      = {J_ESWA},
  author       = {Wanqi He and Jin Wang and Hui Li and Hanyang Chi and Bingfeng Zhang},
  doi          = {10.1016/j.eswa.2025.129836},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129836},
  shortjournal = {Expert Syst. Appl.},
  title        = {Balancing semantic and structural decoding for fMRI-to-image reconstruction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cohen’s class bilinear distributions and convolutional neural networks applied to broken rotor bar diagnosis. <em>ESWA</em>, <em>298</em>, 129835. (<a href='https://doi.org/10.1016/j.eswa.2025.129835'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-frequency (t-f) signal processing techniques are particularly advantageous for induction motor (IM) fault diagnosis under dynamic and variable industrial operating conditions. Broken rotor bar (BRB) faults remain among the most challenging to detect because of their proximity to the fundamental frequency and significantly lower amplitude in comparison. Additionally, traditional approaches often result in false positives or negatives in scenarios involving load variation, power quality issues, and inverter-fed operations. To address these issues, this work proposes a comprehensive and objective methodology to evaluate eight Cohen-Class Bilinear Distributions (CCBD) to diagnose BRB. CCBDs offer high-resolution t-f representations, a crucial advantage for fault identification. However, their use is limited by cross-terms, nonlinear artifacts inherent to bilinear processing. To overcome this limitation, convolutional neural networks (CNNs) are applied to automatically classify t-f images and identify the CCBD methods that effectively minimize the cross-terms while preserving fault signature harmonics. This strategy also avoids subjective and time-consuming visual inspections. In addition, this work proposes a novel CNN architecture with an attention module (CNN-Attention), designed to enhance performance in this context. The evaluation considers challenging conditions, including 1) line-fed and 2) inverter-fed operation, 3) voltage unbalance, and 4) load oscillations, applied to a 2 HP, 60 Hz motor. Generalization capability is validated with data collected from a different laboratory, using an independent 1 HP, 50 Hz motor and five different inverter models. Experimental results show that combining CNN-Attention with CCBDs enables highly accurate and fast classification, achieving approximately 96% accuracy even when trained and tested on distinct laboratory datasets, demonstrating the effectiveness and adaptability of the proposed method.},
  archive      = {J_ESWA},
  author       = {Avyner L.O. Vitor and Alessandro Goedtel and Wesley A. Souza and Marcelo F. Castoldi and Daniel Morinigo-Sotelo and Oscar Duque-Perez},
  doi          = {10.1016/j.eswa.2025.129835},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129835},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cohen’s class bilinear distributions and convolutional neural networks applied to broken rotor bar diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A data-driven spatio-temporal driving risk field mechanism for path planning. <em>ESWA</em>, <em>298</em>, 129834. (<a href='https://doi.org/10.1016/j.eswa.2025.129834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Characterizing the future risk posed by surrounding human-driven vehicles is crucial for enhancing the safety of autonomous vehicles. Existing risk field methods build spatiotemporal risk fields using mathematical models with fixed parameters, making them struggle to capture dynamic human driving behaviors such as frequent acceleration, deceleration or lane changes, and are prone to overlooking rare but critical sudden events, which leads to unstable risk assessments in complex long-term scenarios. To address the aforementioned issues, a data-driven spatio-temporal risk field framework is proposed, which builds on a Bidirectional Deep Ultra-Gated Recurrent Unit (BDUGRU) to capture the high-dimensional spatio-temporal features of nearby vehicles and precisely predict vehicle distribution patterns over extended horizons. The introduced approach manages to yield a more accurate risk field and significantly improves long-term risk assessment in complex traffic environments. Furthermore, to validate the model’s practicality in engineering, we integrated Rapidly-exploring Random Tree with spatiotemporal data-driven risk field (SRF-RRT) and conducted path-planning simulations for autonomous vehicles using real-world traffic data. The results demonstrate that the proposed model excels in both prediction accuracy and reliability, and effectively reduces the measurement error based on collision time (TTC), offering strong applicability and providing a novel theoretical foundation and technological route for path planning in intelligent connected vehicles (ICVs).},
  archive      = {J_ESWA},
  author       = {Zhuoer Wang and Baohan Shi and Jianping Zhang and Xiaowen Zhu and Jian Zhou and Bingrong Xu and Bijun Li},
  doi          = {10.1016/j.eswa.2025.129834},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129834},
  shortjournal = {Expert Syst. Appl.},
  title        = {A data-driven spatio-temporal driving risk field mechanism for path planning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated pothole detection and volume assessment using PointPSSN and smartphone LiDAR point clouds. <em>ESWA</em>, <em>298</em>, 129833. (<a href='https://doi.org/10.1016/j.eswa.2025.129833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid detection and assessment of potholes are critical for ensuring road traffic safety. However, point cloud-based techniques relying on surveying vehicles or drones are often expensive and may be limited by roadside obstruction or narrow roadways. This study proposes a novel approach for assessing road potholes using point cloud data collected by smartphone LiDAR. The method integrates the Point Pothole-Specialized Segmentation Network (PointPSSN), a lightweight point cloud segmentation model designed to achieve high accuracy with low parameter complexity and rapid inference, together with scale-adjustable voxelization for assessment. The PointPSSN model incorporates a Geometric Feature Encoder module to capture the geometric attributes of potholes by extracting local geometric features. Neighbor Finder module identifies and aggregates neighboring points that provide more significant information. Experiments were conducted using a smartphone LiDAR device within a 7.28 km 2 area of Wuchang District, Wuhan, China, encompassing diverse road conditions. A dataset of 1040 potholes was constructed for model training and evaluation. The results demonstrate that the PointPSSN model achieves a segmentation accuracy of 97.336 %, precision of 91.322 %, recall of 79.888 %, an F1-score of 85.223 %, and an intersection-over-union (IoU) of 74.251 %. Notably, the accuracy, F1-score, and IoU surpass the performance of state-of-the-art models by 0.233 %, 1.336 %, and 2.006 %, respectively. In terms of efficiency, PointPSSN requires only one-seventh of the FLOPs and one-fifteenth of the parameters of state-of-the-art models, while achieving an 18.37 % faster inference speed. Furthermore, the average relative errors in depth and volume assessment using voxelization methods are 9.08 % and 9.04 %, respectively.},
  archive      = {J_ESWA},
  author       = {Tingrui Zhang and Xuequan Zhang and Zichuan Yang and Yumin Chen and Li Song and Weichen Zhang},
  doi          = {10.1016/j.eswa.2025.129833},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129833},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated pothole detection and volume assessment using PointPSSN and smartphone LiDAR point clouds},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PAD: Popularity-aware debiasing for high-value item recommendation. <em>ESWA</em>, <em>298</em>, 129830. (<a href='https://doi.org/10.1016/j.eswa.2025.129830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems play a crucial role in our daily lives. However, in the context of high-value item recommendation, they face significant challenges. Due to the high price of these items, user purchase histories are often extremely sparse, making it difficult for recommender systems to accurately capture user preferences. Consequently, they tend to over-rely on popularity information. Moreover, the high-value item market exhibits a pronounced imbalanced distribution, where most user interactions focus on popular items. As a result, traditional recommender systems tend to prioritize these items while rarely recommending less popular ones, leading to low recommendation coverage. To address this challenge, we propose a P opularity- A ware D ebiasing (PAD) model, which improves recommendation coverage in high-value item scenarios without compromising accuracy. First, we employ soft prompts to guide a pre-trained language model (PLM) in enriching user representations. By incorporating semantic knowledge from the PLM, our model captures more comprehensive user preferences, ensuring recommendation accuracy while mitigating the model’s dependence on popularity signals. Building upon this, we apply popularity-aware debiasing to reduce overfitting and enhance coverage. PAD prevents the recommendation model from indiscriminately recommending the most popular items to all users, encouraging it to explore a wider range of items in its recommendations. Experiments conducted on industrial and public datasets demonstrate that our method mitigates popularity bias, significantly improving item recommendation coverage while maintaining accuracy.},
  archive      = {J_ESWA},
  author       = {Yuchen Zheng and Dongming Zhao and Xiangrui Cai and Yanlong Wen and Xiaojie Yuan},
  doi          = {10.1016/j.eswa.2025.129830},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129830},
  shortjournal = {Expert Syst. Appl.},
  title        = {PAD: Popularity-aware debiasing for high-value item recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HWA-net: Hierarchical window aggregate network for cross-resolution remote sensing change detection. <em>ESWA</em>, <em>298</em>, 129829. (<a href='https://doi.org/10.1016/j.eswa.2025.129829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-resolution remote sensing change detection (CD) is a critical task in various applications, including urban monitoring, environmental changes, and disaster management, where images captured at different times often possess varying spatial resolutions. Current methods typically address this by resampling low-resolution (LR) images to high-resolution (HR) formats, but such image-level strategies lead to significant artifacts and misalignment in the change map. These imperfections not only reduce detection accuracy but also lead to misleading or false change identifications, resulting in incorrect or incomplete conclusions in time-sensitive applications, such as land-use change detection or disaster monitoring. To address these challenges, we propose the Hierarchical Window Aggregate Network(HWA-Net), a novel framework that directly operates on cross-resolution image pairs without preprocessing, aiming to accurately aggregate cross-resolution representations for robust CD. HWA-Net initially employed window-based feature extraction to produce scale-independent representations, subsequently transferring these features to layered decoding. This process effectively enhances detection accuracy across diverse resolutions. Our approach establishes new state-of-the-art results on three synthesized datasets and one real-world cross-resolution change detection dataset.},
  archive      = {J_ESWA},
  author       = {Hualin Yang and Boran Ren and Zhijun Yang and Jing Xiong and Xiying Li and Calvin Yu-Chian Chen},
  doi          = {10.1016/j.eswa.2025.129829},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129829},
  shortjournal = {Expert Syst. Appl.},
  title        = {HWA-net: Hierarchical window aggregate network for cross-resolution remote sensing change detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Photovoltaic cluster power ultra-short-term cross-seasonal prediction integrating multi-channel information probabilistic diffusion generation and improved offset loss strategy. <em>ESWA</em>, <em>298</em>, 129826. (<a href='https://doi.org/10.1016/j.eswa.2025.129826'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate photovoltaic (PV) power prediction under complex meteorological conditions remains challenging, particularly given the pronounced seasonal variations that obscure generation patterns. This study presents a novel ultra-short-term prediction framework integrating meteorological volatility analysis with seasonal characteristic modeling. We developed a specialized multi-channel Gram angular summation field (MGASF) transformation matrix to holistically capture meteorological fluctuations, subsequently leveraging denoising diffusion probabilistic model (DDPM) for strategic augmentation of under-represented weather scenarios to enhance similar-day identification. Our hybrid architecture combines multi-channel vision Transformer (VIT) with bidirectional long and short-term memory (BILSTM) networks to synergistically analyze temporal dependencies and spatial patterns in PV similarity recognition. Furthermore, we engineered a seasonal-adaptive prediction system through an improved variable-weight Smooth L1 loss function, establishing an optimized seasonal alignment mechanism that achieves high-precision prediction across varying meteorological conditions with minimal computational overhead. Through rigorous validation using operational data from a utility-scale photovoltaic cluster in Western Inner Mongolia, the proposed method achieved consistent accuracy improvements: 3.02 % reduction in N RMSE , 1.65 % decrease in N MAE , and 2.19 % enhancement in R 2 compared to baseline approaches in PV cluster. These statistically significant enhancements demonstrate our framework’s capability to mitigate seasonal impacts while maintaining prediction reliability in complex meteorological environments.},
  archive      = {J_ESWA},
  author       = {Mao Yang and Yue Jiang and Yunfeng Guo and Jianfeng Che and Wei He and Kang Wu},
  doi          = {10.1016/j.eswa.2025.129826},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129826},
  shortjournal = {Expert Syst. Appl.},
  title        = {Photovoltaic cluster power ultra-short-term cross-seasonal prediction integrating multi-channel information probabilistic diffusion generation and improved offset loss strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards large-scale multi-objective feature selection: A two-stage evolutionary algorithm guided by dual feature weightings. <em>ESWA</em>, <em>298</em>, 129823. (<a href='https://doi.org/10.1016/j.eswa.2025.129823'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature Selection (FS) is a critical task in high-dimensional data processing, aiming to identify the most discriminative subset of features to improve model performance and reduce computational complexity. In recent years, multi-objective evolutionary algorithms have been widely applied to FS problems due to their ability to simultaneously optimize multiple objectives (i.e., classification accuracy and subset size for an FS problem). However, when dealing with large-scale multi-objective FS problems, existing algorithms often suffer from the vast search space and limited search capability, which makes them prone to local optima. To address these challenges, this paper proposes a two-stage evolutionary algorithm guided by dual feature weightings, named TSEA/DFW. In the first stage, an evolutionary search is performed under the guidance of the filter-based feature weighting strategy. The key features are then identified based on the population distribution and optimal solutions, thereby shrinking the search space. In the second stage, a refined search is conducted in the shrunken feature space to boost search efficiency and solution quality. To this end, a novel weighting strategy named Pareto-based hierarchical feature weighting is proposed, which captures the variation in feature performance across different non-dominated levels, reinforces the contribution of high-quality solutions, and preserves useful information from suboptimal solutions. Additionally, a novel offspring reproduction procedure guided by stage-specific feature weights is designed to further enhance search capability. Experimental results on 13 real-world datasets show that the proposed TSEA/DFW performs best on 10 datasets in terms of HV metric and on 11 datasets in terms of IGD, demonstrating the significant superiority of TSEA/DFW over seven state-of-the-art feature selection methods. The performance improvements stem from the two-stage evolutionary framework guided by dual feature weighting, which enables the early identification of important features, thereby effectively reducing the search space and enhancing search efficiency. In addition, further analysis demonstrates that the proposed TSEA/DFW has strong generality across diverse classifiers, and the developed two-stage evolutionary framework in TSEA/DFW is a general powerful framework that can integrate any mainstream FS algorithm into its second stage, exhibiting robust applicability and scalability.},
  archive      = {J_ESWA},
  author       = {Gaohui Li and Zefeng Chen and Yuren Zhou and Zhengxin Huang and Xiaoyun Xia},
  doi          = {10.1016/j.eswa.2025.129823},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129823},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards large-scale multi-objective feature selection: A two-stage evolutionary algorithm guided by dual feature weightings},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-temporal ensemble for few-shot action recognition. <em>ESWA</em>, <em>298</em>, 129821. (<a href='https://doi.org/10.1016/j.eswa.2025.129821'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-Shot Action Recognition (FSAR) aims to recognize novel action classes with only a few labeled samples. Due to the scarcity of labeled data, FSAR models suffer from high variance and low confidence. To address this issue, this paper first introduces ensemble learning into the field of FSAR, leveraging the diversity among multiple temporal action representations to generate base models. Specifically, we propose a Multi-Temporal Ensemble (MTE) method for FSAR. By combining sub-sequences of video frames of various lengths (i.e., tuples), MTE creates multiple sets of action representations and generates base models based on these representations. All base models share a single embedding network to learn frame-level features. The proposed method adaptively captures temporal relations with different lengths and speeds while avoiding the computational cost of training multiple deep neural networks. Furthermore, we introduce a Short-term Temporal Modeling Module (STMM) that uses self-attention to highlight frames with high variation, enhancing short-term temporal representation at the frame level. The proposed method has been validated on four benchmark datasets. Extensive experimental results demonstrate that MTE outperforms 26 state-of-the-art FSAR methods. The source code is available at https://github.com/CharmainCahill/MTE.git .},
  archive      = {J_ESWA},
  author       = {Zhen Jiang and Jianlong Sun and Haodong Liu and Haizhen Guan},
  doi          = {10.1016/j.eswa.2025.129821},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129821},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-temporal ensemble for few-shot action recognition},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MSIDiff:Multi-stage interaction-aware diffusion model for protein-specific 3D molecule generation. <em>ESWA</em>, <em>298</em>, 129820. (<a href='https://doi.org/10.1016/j.eswa.2025.129820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structure-based drug design (SBDD) focuses on developing 3D ligand molecules that bind with high affinity to specific protein targets, which requires the accurate capture of the complex interactions between proteins and ligands. Although existing diffusion models have demonstrated potential in molecular generation tasks, they typically consider only a single stage of the generation process. This limitation prevents them from integrating the multi-stage protein-ligand interaction information from both forward and reverse processes, which may negatively impact the binding affinity of the generated molecules. To address this problem, MSIDiff ( M ulti- S tage I nteraction-Aware Diff usion Model), a multi-stage interaction-aware diffusion model for protein-specific molecule generation, is proposed. MSIDiff leverages the pre-trained model MSINet to extract authentic protein-ligand interaction information during the initial diffusion stage and incorporates this information into the reverse process to ensure that the generated molecules accurately interact with target proteins. Through a scoring mechanism, MSIDiff filters key nodes to extract crucial protein-ligand interaction data and employs a GRU-based cross-layer interaction update module to recursively integrate information across different denoising stages, facilitating effective cross-layer information transmission. Experimental results on the CrossDocked2020 dataset show that MSIDiff can generate molecules with more realistic 3D structures and higher binding affinity to protein targets, achieving an Avg. Vina Score of up to -6.36, while maintaining appropriate molecular properties.Our code and data are available at: https://github.com/zhangyaoxiang/MSIDiff .},
  archive      = {J_ESWA},
  author       = {Yaoxiang Zhang and Junteng Ma and Ze Zhang and Zhaoyang Dong and Shuang Wang},
  doi          = {10.1016/j.eswa.2025.129820},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129820},
  shortjournal = {Expert Syst. Appl.},
  title        = {MSIDiff:Multi-stage interaction-aware diffusion model for protein-specific 3D molecule generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OSATG-GPT: Instruction-tuning large language models with open-source atomic tasks in github. <em>ESWA</em>, <em>298</em>, 129819. (<a href='https://doi.org/10.1016/j.eswa.2025.129819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Across numerous application scenarios in Natural Language Processing (NLP), Large Language Models (LLMs) have demonstrated exceptional capabilities in text comprehension and generation. These models exhibit significant potential across various interdisciplinary fields. However, their effectiveness is somewhat constrained by the unique characteristics of the open-source ecosystem. Developing an LLM with generalization capabilities across datasets and tasks, specifically tailored for the open-source ecosystem, is an urgent research need. To address this challenge, this paper introduces open-source atomic tasks, which are defined as intermediate tasks essential for solving complex objectives. These tasks are designed through strategies such as simplification, reversal, decomposition, and composition, enabling models to gradually acquire domain knowledge and understand task interdependencies. By integrating public resources with open-source atomic tasks, we construct OSE-Instruct–an instruction dataset for the open-source ecosystem. We first unify open-source atomic tasks within an instruction-tuning paradigm that reflects real-world developer behavior, and develop OSATG-GPT at various parameter scales by fine-tuning the BLOOMZ backbone model on OSE-Instruct. This enables the model to learn fine-grained developer actions and the underlying task dependencies. Extensive experiments validate the effectiveness of OSATG-GPT compared to other advanced LLMs with larger parameter scales, and highlight its advantages over GPT-4 in specific and complex open-source collaboration tasks.},
  archive      = {J_ESWA},
  author       = {Fanyu Han and Li Ma and Fenglin Bi and Yantong Wang and Mingdong You and Wei Wang and Jiaheng Peng and Xiaoya Xia},
  doi          = {10.1016/j.eswa.2025.129819},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129819},
  shortjournal = {Expert Syst. Appl.},
  title        = {OSATG-GPT: Instruction-tuning large language models with open-source atomic tasks in github},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploiting knowledge graph communities to fine-tune large language models. <em>ESWA</em>, <em>298</em>, 129816. (<a href='https://doi.org/10.1016/j.eswa.2025.129816'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the introduction of GPT-2, Large Language Models (LLMs) have proven to be able to handle various tasks with impressive performance. However, they sometimes generate incorrect output or even hallucinations. To overcome this problem, many researchers have investigated the possibility of integrating external factual knowledge, such as that encoded in Knowledge Graphs (KGs), into LLMs. Although there are many approaches in the existing literature that integrate KGs and LLMs in different ways, few of them use KGs to fine-tune LLMs, and none of them systematically use KG substructures. In this paper, we propose CoFine (Community-Based Fine-Tuner), an approach to fine-tune an LLM using the communities of a KG. CoFine works as follows: it first divides the KG into communities, each of which contains a homogeneous portion of the knowledge expressed by the KG. It then uses these communities to fine-tune the LLM. This way of proceeding allows LLM fine-tuning to focus on specific homogeneous information contained in the KG expressed by each community. CoFine allows the LLM to achieve a very high accuracy in knowledge completion tasks. This is evidenced by comparisons between CoFine and a baseline LLM fine-tuning approach, which showed that our approach achieves better results for all metrics considered with several KG.},
  archive      = {J_ESWA},
  author       = {Alessia Amelio and Christopher Buratti and Michele Marchetti and Davide Traini and Domenico Ursino and Luca Virgili},
  doi          = {10.1016/j.eswa.2025.129816},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129816},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploiting knowledge graph communities to fine-tune large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-scale fusion graph convolutional networks. <em>ESWA</em>, <em>298</em>, 129815. (<a href='https://doi.org/10.1016/j.eswa.2025.129815'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph analysis methods, as important tools for mining complex information, have made remarkable progress driven by graph neural networks (GNNs). However, existing approaches still face challenges in handling complex topological structures and multi-dimensional node features, making it difficult to fully capture deep-level feature and structural information. When analyzing attribute networks, a key challenge is how to effectively integrate node attribute features with graph topological structure information. To address this issue, this paper proposes a multi-scale fusion graph convolutional network (MSF-GCN) method. This method combines shallow and deep convolution strategies while adaptively fusing information across three parallel channels — the original topological structure, a feature-derived graph, and a deep-combination channel that captures shared depth information between them. An autoencoder is employed to reconstruct the adjacency matrix, enhancing the representation capability of the network. Additionally, an attention mechanism is introduced to dynamically assign weights to attribute and structural features at different scales, optimizing node representation. Experimental results demonstrate that, in node classification tasks across multiple benchmark datasets, MSF-GCN achieves outstanding performance, strongly validating the effectiveness and robustness of the proposed method.},
  archive      = {J_ESWA},
  author       = {Zhi Kong and Jie Ren and Lifu Wang and Ge Guo},
  doi          = {10.1016/j.eswa.2025.129815},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129815},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-scale fusion graph convolutional networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient deep template matching and in-plane pose estimation method via template-aware dynamic convolution. <em>ESWA</em>, <em>298</em>, 129813. (<a href='https://doi.org/10.1016/j.eswa.2025.129813'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial inspection and component alignment tasks, template matching requires efficient estimation of a target’s position and geometric state (rotation and scaling) under complex backgrounds to support precise downstream operations. Traditional methods rely on exhaustive enumeration of angles and scales, leading to low efficiency under compound transformations. Meanwhile, most deep learning-based approaches only estimate similarity scores without explicitly modeling geometric pose, making them inadequate for real-world deployment. To overcome these limitations, we propose a lightweight end-to-end framework that reformulates template matching as joint localization and geometric regression, outputting the center coordinates, rotation angle, and independent horizontal and vertical scales. A Template-Aware Dynamic Convolution Module (TDCM) dynamically injects template features at inference to guide generalizable matching. The compact network integrates depthwise separable convolutions and pixel shuffle for efficient matching. To enable geometric-annotation-free training, we introduce a rotation-shear-based augmentation strategy with structure-aware pseudo labels. A lightweight refinement module further improves angle and scale precision via local optimization. Experiments show our 3.07M model achieves high precision and ∼ 14 ms inference under compound transformations. It also demonstrates strong robustness in small-template and multi-object scenarios, making it highly suitable for deployment in real-time industrial applications. The code is available at: https://github.com/ZhouJ6610/PoseMatch-TDCM .},
  archive      = {J_ESWA},
  author       = {Ke Jia and Ji Zhou and Hanxin Li and Zhigan Zhou and Haojie Chu and Xiaojie Li},
  doi          = {10.1016/j.eswa.2025.129813},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129813},
  shortjournal = {Expert Syst. Appl.},
  title        = {An efficient deep template matching and in-plane pose estimation method via template-aware dynamic convolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GraphShield: Advanced dynamic graph-based malware detection using graph neural networks. <em>ESWA</em>, <em>298</em>, 129812. (<a href='https://doi.org/10.1016/j.eswa.2025.129812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising complexity of modern malware-such as polymorphic, fileless, and sandbox-aware variants-has severely diminished the reliability of conventional detection techniques. Models based on sequential data frequently miss intricate behavioral patterns and long-range dependencies, resulting in poor accuracy and limited adaptability to new threats. This paper introduces GraphShield, a graph-centric behavioral detection framework that identifies malware with high precision by analyzing dynamic API call sequences. GraphShield converts raw API calls into temporal graphs, applies semantic vectorization, and leverages attention mechanisms to extract both localized activity and extended behavioral correlations, directly addressing the weaknesses of earlier systems. We design and assess multiple Graph Neural Network (GNN) variants, including Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), Graph Isomorphism Networks (GINs), and Transformer-based architectures combining convolutional, recurrent, and autoencoding layers. These models capture structural and temporal traits of execution traces using both classification-only and combined classification-reconstruction strategies. To enhance transparency, we incorporate GNN interpretation tools that isolate key API call subgraphs and critical decision pathways, making detection outcomes explainable for analysts. GraphShield is trained on 300,000 balanced instances and tested on a separate 200,000-sample holdout set, achieving over 58 % improvement in accuracy over advanced sequence-driven deep learning models while maintaining a false positive rate under 1 %. Key features include BERT-based API call grouping for reducing dimensionality and a Markov-inspired graph stabilization method for managing graphs of variable length. Our top models attain a 99.5 % F1-score on the test set. GraphShield aligns recent graph learning techniques with operational cybersecurity needs, delivering accurate detection and clear, interpretable results.},
  archive      = {J_ESWA},
  author       = {Eslam Amer and Shaker El-Sappagh and Tamer Abuhamad and Bander Ali Saleh Al-Rimy and Alaa Mohasseb},
  doi          = {10.1016/j.eswa.2025.129812},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129812},
  shortjournal = {Expert Syst. Appl.},
  title        = {GraphShield: Advanced dynamic graph-based malware detection using graph neural networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LFRSCNet: Skin defect detection based on lightweight flexible residual separable convolutional network. <em>ESWA</em>, <em>298</em>, 129811. (<a href='https://doi.org/10.1016/j.eswa.2025.129811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aircraft skin is prone to surface damage, such as cracks and dents, during long-term service or manufacturing processes. These defects not only threaten structural integrity but may also pose potential safety hazards. The industrial sector continually explores more efficient and precise detection methods to address this issue. Therefore, this paper proposes a skin defect detection method based on a lightweight and flexible residual separation convolutional network to improve detection accuracy and efficiency. Therefore, this paper proposes a skin defect detection method based on a lightweight flexible residual separable convolution network to improve detection accuracy and efficiency. First, a lightweight flexible residual separable convolution module (LFRCM) is designed, which effectively integrates multi-modal features by combining multi-scale receptive fields with an adaptive channel attention mechanism; at the same time, a lightweight backbone network based on PP-LCNet is constructed, employing a collaborative optimization strategy of depthwise separable convolutions and the h-swish activation function to significantly enhance inference speed while maintaining detection accuracy; finally, the MPDIoU metric criterion is introduced, which effectively improves target localization accuracy by implementing a center point offset penalty mechanism. Experiments on the self-built professional dataset SD-DET and the public dataset GC10-DET show that the model achieves mAP@0.5 of 99.5% and 86.2%, respectively, demonstrating significant advantages over mainstream detection models. Systematic ablation experiments confirm the synergistic effect of various innovative modules. Finally, verification experiments are conducted on the AIRCRAFT skin defect dataset, achieving an mAP@0.5 of 30.7%. Quantitative analysis and comparative experiments verify that LFRSCNet can achieve detection accuracy breakthroughs while maintaining low parameter counts and computational costs. Its balanced accuracy-efficiency characteristics provide an efficient and reliable solution for surface defect detection in industrial scenarios.},
  archive      = {J_ESWA},
  author       = {Zhenyu Lu and Jue Wang and Jiteng Zhu and Yuwen Sun},
  doi          = {10.1016/j.eswa.2025.129811},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129811},
  shortjournal = {Expert Syst. Appl.},
  title        = {LFRSCNet: Skin defect detection based on lightweight flexible residual separable convolutional network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The knowledge-driven adaptive late acceptance iterative hill-climbing heuristics for the bus and ADR collaborative delivery problem. <em>ESWA</em>, <em>298</em>, 129810. (<a href='https://doi.org/10.1016/j.eswa.2025.129810'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban-rural bus transit services encounter a dilemma between the necessity for enhanced services and the challenge of low profitability due to scant travel demand. Combining freight transportation with passenger services can enhance the efficiency and profitability of buses in both urban and rural areas, while also reducing environmental impacts. A case in point is the integration of freight deliveries into rural bus networks in China. Concurrently, with the advancement of autonomous delivery robot (ADR) technology, there is a growing deployment of ADRs for last-mile delivery purposes. In this paper, we have studied a new collaborative passenger and freight transportation problem involving buses and ADRs, namely, the bus and ADR collaborative delivery problem (BACDP). In this scenario, a bus route transports several ADRs, which carry multiple parcels, to distribution regions for door-to-door delivery, each ADR boards a bus to reach the sub-region and then boards another bus to return to the distribution center. We have proposed a mathematical model for BACDP, which can be decomposed into a master problem and a sub-problem. and the condition that the optimal solution to the master problem is also the optimal solution to the original problem has been proved. To tackle the BACDP effectively, we designed a novel three-stage iterative method, guided by adaptive late acceptance hill-climbing heuristics (ALAHH). Specifically, at the first stage, the k-means++ and Hamiltonian graph-guided algorithms are used to cluster customers; at the second stage, the variable neighborhood search plans the ADRs’ routes; at the third stage, we utilize the solver to address subproblems, and the evaluation and invocation mechanism is proposed to achieve the efficient utilization of solvers. Extensive experiments have been conducted on synthetic instances of varying scales to investigate the efficiency of ALAHH. The experimental results demonstrate that the objective values and the computation time are significantly lower than those of SA and LAHC, and our algorithm has achieved the best solutions for 16 problems to date. Additionally, the impacts of two key parameters and mechanisms have been analyzed, and further validation of the robustness of the algorithm parameters and the effectiveness of the mechanisms.},
  archive      = {J_ESWA},
  author       = {Lijun Pan and Changshi Liu and Yifan Zhang and Shun Li},
  doi          = {10.1016/j.eswa.2025.129810},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129810},
  shortjournal = {Expert Syst. Appl.},
  title        = {The knowledge-driven adaptive late acceptance iterative hill-climbing heuristics for the bus and ADR collaborative delivery problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Simultaneous multi-objective path planning with cumulative hazardous dosage constraint for mobile detection robots in complex environments. <em>ESWA</em>, <em>298</em>, 129808. (<a href='https://doi.org/10.1016/j.eswa.2025.129808'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning for a mobile robot operating in complex hazardous environments often requires simultaneous optimization of multiple objectives, such as minimal path length, low energy consumption, and safe passing under cumulative hazard dosage (CHD) constraint. Available methods, involving deterministic algorithms and meta -heuristic algorithms, have drawbacks in solving this problem to meet these simultaneous requirements. A flexible jump point search strategy (FlexJPS) is proposed to address the problem. In the scheme, jump points are divided into two categories, dominant waypoints (DWPs) and linkage jump points (LJPs). Each DWP is flexibly assigned to one limited zone and all the limited zones are distributed in a spaced form in the grid-based environment. The LJPs are generated in a limited short range by the modified jump point search rule. The DWPs followed by LJPs are evaluated by a designed multi-operator differential evolution algorithm to achieve the optimal solution meeting the safe passing constraint. Various experiments are carried out to validate the performance of the proposed scheme with comparisons to feasible famous counterparts. Statistical results and achieved planning success rates from the experiments under stringent CHD constraint indicate superior performance of the proposed method. It is concluded that the proposed method contributes a high-efficacy multi-objective path planning method for a mobile robot operating in complex environments with CHD constraint.},
  archive      = {J_ESWA},
  author       = {Xiankun Lin and Xiaoting Peng and Linsen Liang},
  doi          = {10.1016/j.eswa.2025.129808},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129808},
  shortjournal = {Expert Syst. Appl.},
  title        = {Simultaneous multi-objective path planning with cumulative hazardous dosage constraint for mobile detection robots in complex environments},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-domain feature-based epileptic seizure prediction method using EEG source estimation and graph theory. <em>ESWA</em>, <em>298</em>, 129807. (<a href='https://doi.org/10.1016/j.eswa.2025.129807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a disorder caused by abnormal discharges of cerebral neurons, affecting 50 million people worldwide. Most existing research on seizure prediction remains at the scalp level. To explore and harness the potential of information flow among cortical regions as well as the intrinsic brain networks and functional mechanisms for seizure prediction, this study proposes a novel multi-domain feature fusion seizure prediction framework based on Electroencephalography (EEG) source estimation and graph theory. Specifically, dSPM source estimation and singular value decomposition (SVD) are first applied to extract 44 subcortical regions defined by the “HCPMMP1_combined” atlas. Brain networks are then constructed using coherence (COH) and phase lag index (PLI), from which specific network topological features based on graph theory are calculated. These features are further extended to higher-order brain networks to enhance connectivity modeling. We also build a multi-domain feature hybrid (MFH) prediction model that adopts a multi-branch structure. One branch employs hypergraph convolution attention along with time–frequency node features derived from continuous wavelet transform (CWT) to capture high-order spatial correlations; another branch inputs the temporal signals from cortical brain regions and combines the hybrid Mamba2-Transformer expert (HMT) model with a frequency-domain dot-product channel attention network (FDCA). By fusing these branches, the model demonstrates satisfactory results across multiple age-groups in the epilepsy EEG dataset of Gansu Province Central Hospital, as well as in the CHB − MIT dataset. This framework highlights the potential of integrating source estimation, hypergraph analysis, and multi-domain feature learning for personalized seizure prediction.},
  archive      = {J_ESWA},
  author       = {Bingyang Ji and Wenwen Chang and Guanghui Yan and Dandan Li and Rong Yin and Xuan Liu and Yaxuan Wei},
  doi          = {10.1016/j.eswa.2025.129807},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129807},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-domain feature-based epileptic seizure prediction method using EEG source estimation and graph theory},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-hop commonsense knowledge injection framework for zero-shot commonsense question answering. <em>ESWA</em>, <em>298</em>, 129806. (<a href='https://doi.org/10.1016/j.eswa.2025.129806'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot commonsense question answering (QA) task is to evaluate the general reasoning ability of the language model without training on the specific datasets. The existing zero-shot framework transforms triples within the commonsense knowledge graphs (KGs) into QA-format samples, serving as a pre-training data source to integrate commonsense knowledge into the language model. However, this approach still faces the following challenges: 1) The model trained from synthetic QA generated from triples lacks the multi-hop commonsense knowledge required for handling complex QA problems. 2) Ambiguity caused by confusing commonsense knowledge within synthetic QA, making it challenging for models to discern semantically similar entities. To address the above problem, we propose a novel M ulti-hop C ommonsense K nowledge I njection Framework (MCKI). Specifically, we draw inspiration from human complex reasoning thinking and further propose a synthetic multi-hop commonsense QA generation method. Meanwhile, we introduce negative samples with high confusion in synthetic QA, and then use contrastive learning to improve the model’s ability to distinguish similar commonsense knowledge. Extensive experiments on five commonsense question answering benchmarks demonstrate that our framework achieves state-of-the-art performance, surpassing existing methods, including large language models like GPT3.5 and ChatGPT.},
  archive      = {J_ESWA},
  author       = {Xin Guan and Jiuxin Cao and Biwei Cao and Qingqing Gao and Bo Liu},
  doi          = {10.1016/j.eswa.2025.129806},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129806},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-hop commonsense knowledge injection framework for zero-shot commonsense question answering},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CR-GAC: Cross-modal recombination via graph-attention collaborative optimization for multimodal sentiment analysis. <em>ESWA</em>, <em>298</em>, 129805. (<a href='https://doi.org/10.1016/j.eswa.2025.129805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis integrates linguistic, audio, and visual modalities for predicting human emotional states. However, current algorithms encounter three challenges: limitations in adjacency matrix modeling, noise interference and modality imbalances in cross-modal attention, and inefficient cross-modal feature alignment. To address these, we propose the C ross-modal R ecombination via G raph- A ttention C ollaborative Optimization (CR-GAC) by unifying graph and sequence learning in a collaborative framework. Specifically, we first design the modality-adaptive M ultimodal G raph C onstruction (MGC) to tackle the first challenge. For the linguistic modality, a local sparse graph based on a K-Nearest Neighbors-Radial Basis Function kernel is designed to preserve fine-grained semantics; for the audio and visual modalities, a low-rank representation method combined with nuclear norm regularization is designed to capture latent cross-sample structures via singular value decomposition, while suppressing noise interference. Modalities that have been processed are then input into graph attention networks to achieve higher-order feature aggregation. Next, we construct the L anguage-guided H ierarchical C ross-modal I nteraction (LHCI) to tackle the second challenge, which leverages bidirectional cross-modal attention and multi-level Transformer blocks to hierarchically enhance feature representations. Subsequently, the H igh-level M ultimodal F eature C ontainer (HMFC) iteratively accumulates multi-grained semantics, providing a high-level feature pool for fusion. Finally, the dynamic matching-based H igh-level F eature R ecombination (HFR) is designed to tackle the third challenge, which uses the linguistic feature as an anchor to achieve semantically controllable explicit alignment and flexible implicit alignment by matching the most relevant features. Experimental results show our model achieves state-of-the-art performance on CMU-MOSI and CMU-MOSEI datasets, and demonstrates generalization capability on CH-SIMS dataset.},
  archive      = {J_ESWA},
  author       = {Haoran Chen and Jiapeng Liu and Zuhe Li and Yushan Pan and Hongwei Tao and Huaiguang Wu and Yunyang Wang and Chenguang Yang},
  doi          = {10.1016/j.eswa.2025.129805},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129805},
  shortjournal = {Expert Syst. Appl.},
  title        = {CR-GAC: Cross-modal recombination via graph-attention collaborative optimization for multimodal sentiment analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sustainable time-dependent intermodal hub-and-spoke logistic network considering hub failure: A mathematical model and a hybrid artificial bee colony algorithm. <em>ESWA</em>, <em>298</em>, 129804. (<a href='https://doi.org/10.1016/j.eswa.2025.129804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the design of a sustainable hub-and-spoke logistics network that integrates intermodal transportation between the hubs, hub failures, time dependency, and environmental parameters. Accordingly, we propose a novel mixed-integer linear programming (MILP) model and a hybrid artificial bee colony-based algorithm (HABCb) to minimize transportation costs and emissions in robust network configurations. The model is the first to simultaneously integrate intermodality, sustainability metrics, and hub disruption scenarios within a single framework. Computational experiments using real-life data from Turkey demonstrate that the proposed HABCb approach outperforms both genetic algorithm (GA) and artificial bee colony (ABC) algorithm. On medium-sized problem sets, it achieves average cost reductions of 7% compared to GA and 10% compared to ABC algorithm, while on large-sized problems the reductions are 10% and 15%, respectively. Furthermore, the HABCb approach provides faster convergence and higher-quality solutions for larger problem sizes. The findings highlight the practical and theoretical insights of incorporating sustainability, intermodality, and robustness into hub-and-spoke network design.},
  archive      = {J_ESWA},
  author       = {Burcu Tokbay Erkek and Salih Himmetoğlu and Yılmaz Delice and Emel Kızılkaya Aydoğan},
  doi          = {10.1016/j.eswa.2025.129804},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129804},
  shortjournal = {Expert Syst. Appl.},
  title        = {Sustainable time-dependent intermodal hub-and-spoke logistic network considering hub failure: A mathematical model and a hybrid artificial bee colony algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A belief rule-based system for online and centralized collaborative performance assessment of networked physical systems subject to nonideal channels. <em>ESWA</em>, <em>298</em>, 129803. (<a href='https://doi.org/10.1016/j.eswa.2025.129803'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networked physical systems (NPSs) are widely applied in modern engineering practices characterized by intensive domain knowledge and imperfect observational data. Meanwhile, collaborative performance assessment provides strong support for them to operate safely and stably over a long period of time. For a specific NPS and its corresponding online and centralized collaborative performance assessment system, the existence of interference and noise in the real-world channel that is rather nonideal inevitably obstructs the smooth progress of the assessment. To this end, in this paper, a symbolic systematic solution is proposed resorting to an improved version of the belief rule base with continuous inputs (BRB-CI). First, the extrapolation module is enhanced by integrating a matched filtering-based link. Second, the existing robustness analysis for systems based on the fundamental belief rule base is extended to systems based on the BRB-CI. Third, the optimization module is ameliorated by designing a multimetric-balanced pattern of the grey wolf optimizer with interpretability reinforcement. Ultimately, by choosing an instance of NPSs in the field of aerospace with continuous time dynamics, pertinent empirical studies are carried out to substantiate the good engineering practicability of our proposal. Note that this paper is the first piece inquiring into belief rule-based systems such a class of expert systems for online and centralized cooperative performance assessment of NPSs with continuous time dynamics such an application, with considerable attention paid to the nonideality of real-world channels.},
  archive      = {J_ESWA},
  author       = {Haoran Zhang and Lining Xing and Jian Wu and Ruohan Yang and Zhichao Feng},
  doi          = {10.1016/j.eswa.2025.129803},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129803},
  shortjournal = {Expert Syst. Appl.},
  title        = {A belief rule-based system for online and centralized collaborative performance assessment of networked physical systems subject to nonideal channels},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). E2D-GS: Event-enhanced deblurring gaussian splatting. <em>ESWA</em>, <em>298</em>, 129802. (<a href='https://doi.org/10.1016/j.eswa.2025.129802'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, implicit neural representations and explicit 3D Gaussian Splatting(3DGS) have demonstrated substantial advancements in the domain of novel view synthesis. Nevertheless, the efficacy of these approaches is predominantly contingent upon the availability of well-defined, clear imagery and precise camera pose information. Consequently, they exhibit a pronounced susceptibility to motion blur, which impedes the rendering of sharp images. Event cameras, which measure intensity changes with microsecond temporal precision, possess an inherent robustness to motion-induced blur. This characteristic offers new avenues for 3D reconstruction in challenging scenarios characterized by high-speed motion or low-light conditions. This paper introduces E2D-GS, a novel algorithm for deblurring and reconstruction based on event cameras and 3D Gaussian Splatting. To enhance reconstruction accuracy, our proposed framework leverages event streams to physically model the formation process of motion blur. This is achieved by optimizing the discrepancy between synthesized data and the observed blurry images, while simultaneously recovering the camera’s motion trajectory. Additionally, to enhance robustness in real-world scenarios, this paper proposes a differential consistency module. This module effectively mitigates noise within the event data and regularizes the optimization of Gaussian parameters, thereby improving reconstruction quality under non-ideal conditions. Comprehensive experimental evaluations on both simulated and real-world benchmarks validate the proposed method’s capability to reconstruct latent sharp imagery via the learned 3DGS representations, and further demonstrate its capacity for stable reconstruction under adverse scenarios. The results show that our approach surpasses the performance of previous works.},
  archive      = {J_ESWA},
  author       = {Lifeng Lin and Shuangjie Yuan and Lu Yang},
  doi          = {10.1016/j.eswa.2025.129802},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129802},
  shortjournal = {Expert Syst. Appl.},
  title        = {E2D-GS: Event-enhanced deblurring gaussian splatting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive gated universal information extraction for chinese legal texts. <em>ESWA</em>, <em>298</em>, 129801. (<a href='https://doi.org/10.1016/j.eswa.2025.129801'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing knowledge graphs in legal domains requires simultaneous extraction of entities and relations. To reduce repeated modeling in traditional approaches, we adopt the Universal Information Extraction (UIE) model as a foundation and propose an enhanced variant named Adaptive Gated Universal Information Extraction (AGUIE). This study develops a new decoder based on the Adaptive Focusing Gated Attention Unit (AFGAU). This unit enhances the standard Gated Attention Unit (GAU) by integrating two key components—learnable dynamic convolution and reset/update gating mechanisms. Moreover, the study employs a cross-pointer structure as the output layer to better identify information boundaries. To support this study, we construct a domain specific dataset for extracting key information from legal judgment documents. Systematic comparative analysis and ablation studies demonstrate that AGUIE achieves significant performance gains over baseline UIE, with an F1 score of 85.56% on our legal judgment documents dataset. Additionally, we evaluate the model’s generalization on public datasets such as ACE04, ACE05, and CoNLL04, covering both entity recognition and relation extraction tasks. Experimental results indicate that AGUIE demonstrates competitive results with recent studies on ACE04-Ent and CoNLL04, outperforms them on the ACE05 dataset, achieving F1 scores of 87.19% on ACE05-Ent and 79.29% on ACE05-Rel. In conclusion, AGUIE is a reliable and effective solution for universal information extraction in both legal and general domains.},
  archive      = {J_ESWA},
  author       = {Yabo Liu and Yatong Zhou and Kuo-Ping Lin},
  doi          = {10.1016/j.eswa.2025.129801},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129801},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive gated universal information extraction for chinese legal texts},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid graph and LLM approach for measuring scientific novelty via knowledge recombination and propagation. <em>ESWA</em>, <em>298</em>, 129794. (<a href='https://doi.org/10.1016/j.eswa.2025.129794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific novelty constitutes a fundamental catalyst for both disciplinary innovation and interdisciplinary progress. Nevertheless, prevailing approaches to novelty assessment predominantly emphasize a single analytical dimension–either the semantic content of the focal paper or its cited references. Content-based methodologies frequently fail to incorporate the foundational knowledge cited by the target publication, whereas reference-based strategies tend to disregard the intrinsic conceptual contributions of the focal work itself. To address this limitation, the present study introduces a hybrid graph and large language model approach to jointly capture and integrate knowledge embedded in both the focal paper and its cited literature. The proposed method, which integrates knowledge recombination and propagation, is structured into four primary stages. First, prompt-based extraction techniques using general LLMs are applied to extract knowledge. Second, a Reference Knowledge Combination Network (RKCN) is constructed to model the knowledge referenced by the focal paper. Third, the RKCN is initialized with representations generated by SciDeBERTa(CS), and a graph attention network is employed to propagate knowledge across the network. Finally, the novelty of the focal paper is quantified by aggregating the novelty scores of all internal knowledge combinations based on the propagated representations. Experimental evaluation in the domain of artificial intelligence (AI) demonstrates that the proposed method significantly outperforms existing baseline approaches in quantifying scientific novelty. Additional ablation studies further validate the contribution of the knowledge propagation module. A case study illustrates the interpretability of our approach, and a cross-field validation in Biomedical Engineering (BME) domain highlights its robustness and cross-domain generalizability. A multi-dimensional comparative analysis between award-winning and non-award papers further reveals that the former generally incorporate a larger volume of knowledge and exhibit greater diversity in knowledge combinations. Moreover, while both groups encompass knowledge combinations spanning a wide range of novelty, award-winning papers display a stronger concentration at higher novelty levels, in contrast to the more uniform distribution observed in non-award papers. Data, code, and more detailed results are publicly available at: https://github.com/haihua0913/graphLLM4ScientificNovelty .},
  archive      = {J_ESWA},
  author       = {Zhongyi Wang and Zeren Wang and Guangzhao Zhang and Jiangping Chen and Markus Luczak-Roesch and Haihua Chen},
  doi          = {10.1016/j.eswa.2025.129794},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129794},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid graph and LLM approach for measuring scientific novelty via knowledge recombination and propagation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph-based approaches for rumor detection in social networks: A systematic review. <em>ESWA</em>, <em>298</em>, 129786. (<a href='https://doi.org/10.1016/j.eswa.2025.129786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increased public anxiety and fear, disrupted decision-making, social instability, and other significant societal challenges are the results of the rapid spread of rumors on social media platforms. The unique characteristics of these platforms contribute to the rapid spread of both verified and unverified information. These pressing issues highlight the need to develop advanced technologies for early detection and prevention of rumors. This paper presents a systematic review of graph-based approaches for rumor detection in social networks, analyzing 53 studies published between 2018 and 2025. The selected studies are comprehensively reviewed with a focus on graph models and the integration of propagation structure, social, temporal, and content features, which enhances detection accuracy. This review critically evaluates the effectiveness of various methods, highlighting their strengths, limitations, and key challenges. The key contributions of this paper include: (i) an in-depth analysis of current graph-based rumor detection approaches (ii) a categorization of graph models and feature extraction strategies, (iii) the identification of major challenges and research gaps, and (iv) recommendations for future research to develop scalable, robust, and accurate early rumor detection systems. The findings of this study provide valuable insights for researchers aiming to advance the state-of-the-art in fighting misinformation on social networks.},
  archive      = {J_ESWA},
  author       = {Fatima Al-Thulaia and Seyyed Alireza Hashemi Golpayegani},
  doi          = {10.1016/j.eswa.2025.129786},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129786},
  shortjournal = {Expert Syst. Appl.},
  title        = {Graph-based approaches for rumor detection in social networks: A systematic review},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatiotemporal online fuzzy modeling with knowledge-driven differential evolution automatic clustering for distributed parameter systems. <em>ESWA</em>, <em>298</em>, 129785. (<a href='https://doi.org/10.1016/j.eswa.2025.129785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed parameter systems are prevalent in various industrial processes and attract significant attention. However, these systems exhibit complex spatiotemporal coupling characteristics, and effectively determining the fuzzy rules of the antecedent set is crucial for improving modeling performance. Traditional clustering methods typically rely on empirical heuristics and are unable to adapt to dynamic system characteristics under changing environments. In high-dimensional and nonlinear scenarios, the number of fuzzy rule combinations grows exponentially, significantly increasing computational complexity. Therefore, an online spatiotemporal three-dimensional fuzzy modeling method based on knowledge-driven differential evolution automatic clustering and extreme learning machine (3D-OSADE-ELM) is proposed for the complex nonlinear distributed parameter system. First, an automatic clustering mechanism based on differential evolution and extreme learning machine initializes the fuzzy rules within the three-dimensional fuzzy system. Subsequently, a knowledge-driven archiving mechanism dynamically updates the fuzzy rules of the antecedent set during the online incremental learning phase. Finally, the spatial basis function is obtained by learning the output weight of the online extreme learning machine. The validation experiments conducted on the rapid thermal chemical vapor deposition reactor system and the nonisothermal packed-bed system demonstrate the effectiveness and superiority of the proposed method.},
  archive      = {J_ESWA},
  author       = {Gang Zhou and Xianxia Zhang and Bing Wang},
  doi          = {10.1016/j.eswa.2025.129785},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129785},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spatiotemporal online fuzzy modeling with knowledge-driven differential evolution automatic clustering for distributed parameter systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CG-TRAN: A novel multi-label retinal disease classification model with partially known pathologies. <em>ESWA</em>, <em>298</em>, 129784. (<a href='https://doi.org/10.1016/j.eswa.2025.129784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection of retinal diseases is vital to preventing partial or permanent blindness. However, the diagnostic process is often impeded by the complexity of interrelated lesions and the challenge of incomplete or missing pathology labels, which require specialized expertise in ophthalmic diagnosis. To address these limitations, we propose CG-Tran, a novel multi-label classification model that leverages partially known pathology information to diagnose retinal diseases. This approach integrates a pathology graph neural network with graph-based feature extraction to handle partially known pathologies, enabling more accurate multi-label classification of retinal diseases. To model the intricate interrelationships among ocular diseases, CG-Tran employs BERT-GNN to learn label interactions and construct a comprehensive fundus pathology graph. Additionally, an enhanced attention mechanism incorporates known pathology label features, bridging the gap between incomplete pathology information and fundus image data. These innovations collectively empower the model to overcome the challenges of missing or incomplete pathology labels. The model’s performance is rigorously evaluated on the Multilabel Retinal Disease (MuReD) dataset. Results demonstrate that CG-Tran significantly improves diagnostic accuracy, especially as more pathology labels become available. Under conditions with 0% and 75% partially known labels, CG-Tran achieves mean average precision (mAP) scores of 69.9% and 72.1%, respectively—outperforming the baseline model by 1.0% and 1.9%. This innovative architecture excels in multi-label classification tasks, particularly in recognizing and distinguishing complex and interrelated retinal lesions with partially known pathology. It offers a promising solution for early detection and accurate diagnosis of retinal diseases, addressing critical limitations in existing diagnostic methods.},
  archive      = {J_ESWA},
  author       = {Jia Sheng Yang and Zihao Ning and Xu Xiao and Rui Zhong and Chenbo Xia and Ya Ding},
  doi          = {10.1016/j.eswa.2025.129784},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129784},
  shortjournal = {Expert Syst. Appl.},
  title        = {CG-TRAN: A novel multi-label retinal disease classification model with partially known pathologies},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time-balanced MSE for machinery imbalanced degradation trend prediction. <em>ESWA</em>, <em>298</em>, 129783. (<a href='https://doi.org/10.1016/j.eswa.2025.129783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate degradation trend prediction (DTP) is crucial for optimizing equipment operation and maintenance. With the rapid development of artificial intelligence, many data-driven methods have been applied to machinery degradation trend prediction. In practice, most machineries are in the early stages of degradation, with only a few reaching the final stages, leading to a temporal imbalanced data distribution. Current research on imbalanced distributions mainly focuses on classification tasks. However, DTP involves multiple time-dependent continuous targets, making classification-based methods unsuitable. To address this issue, the degradation trend prediction task is reformulated as a multi-task problem and a novel time-balanced Mean Square Error (TBMSE) loss function is proposed. In each prediction task, the Gaussian Mixture Model (GMM) is used to fit the training label distribution. Additionally, the cumulative information noise for each prediction task is modeled using GMM, and an end-to-end network structure is designed to learn the GMM parameters. Experiments are conducted on the IMS bearing dataset and the turboprop engine dataset, demonstrating that the TBMSE loss effectively mitigates the issue of temporal imbalanced distribution in degradation trend prediction.},
  archive      = {J_ESWA},
  author       = {Yu-Qiang Wang and Yong-Ping Zhao and Tian-Ding Zhang and Yu-Wei Wang},
  doi          = {10.1016/j.eswa.2025.129783},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129783},
  shortjournal = {Expert Syst. Appl.},
  title        = {Time-balanced MSE for machinery imbalanced degradation trend prediction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Differentiable histogram-guided unsupervised retinex enhancement for paired low-light images. <em>ESWA</em>, <em>298</em>, 129782. (<a href='https://doi.org/10.1016/j.eswa.2025.129782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing low-light image enhancement (LIE) methods rely on expensive paired low-light and normal-light datasets, while unsupervised approaches depend on handcrafted priors to design networks or select similar normal-light images as pseudo-references, limiting their generalization and robustness. To address these challenges, we propose a novel differentiable histogram-guided unsupervised Retinex enhancement (DHURE) method, which leverages the distribution of illumination histograms in real-world scenarios to achieve high-fidelity color preservation and refined brightness distribution across diverse extremely low-light images. DHURE avoids reliance on scene-specific features and effectively captures both fine-grained details and overall brightness information. Specifically, our method consists of two key components: 1) The lightweight architecture of DHURE is composed of Retinex decomposition and illumination enhancement. We perform Retinex decomposition on paired low-light images (PRD) and design the Illumination Histogram-guided Enhancement (IHE) module. Both modules employ lightweight architectures. 2) To fully exploit the adaptive priors inherent in paired low-light images, we introduce a self-supervised reflectance map loss that aligns with the Retinex basis loss. Based on the illumination distribution of real-world normal-light images, we define two unsupervised illumination histogram losses, enabling more generalized and robust enhancement. Extensive and diverse experiments demonstrate that our method achieves competitive performance compared to existing unsupervised LIE approaches, showing superior results on most evaluation metrics. The source code is available at https://github.com/yoonyin/DHURE-main .},
  archive      = {J_ESWA},
  author       = {Liyuan Yin and Pingping Liu and Tongshun Zhang and Hongwei Zhao and Qiuzhan Zhou},
  doi          = {10.1016/j.eswa.2025.129782},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129782},
  shortjournal = {Expert Syst. Appl.},
  title        = {Differentiable histogram-guided unsupervised retinex enhancement for paired low-light images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SUNRISE: Multi-agent reinforcement learning via neighbors’ observations under fully noisy environments. <em>ESWA</em>, <em>298</em>, 129781. (<a href='https://doi.org/10.1016/j.eswa.2025.129781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning (MARL) methodologies have achieved notable advancements across diverse domains. Despite these successes, the susceptibility of neural networks to perturbed data and the ubiquity of external attacks in real-world settings, such as sensor noise, pose challenges for MARL approaches. The pivotal issue revolves around the effective transfer of policies learned in idealized simulation environments to the complexities inherent in real-world scenarios. More precisely, when agents are unable to obtain any accurate observations of the external environment throughout the entire policy learning process, the MARL methods cannot learn effective policies. In addressing this issue, we propose a methodology wherein noisy observations from neighboring agents are utilized, with an agent’s own noisy observations serving as surrogate ground truth. This approach facilitates the learning of effective policies by MARL methods in environments characterized by pervasive noise. We design a denoising representation network to filter out the principal state information from environment data characterized by noise to mitigate the adverse effects of noise on the process of policy learning. Then, we integrate the denoising representation network with classic MARL methodologies to learn effective policies within environments characterized by pervasive noise. A series of exhaustive experimental results demonstrate the efficacy of our approach in attenuating the impact of external attacks on the optimization parameters of neural networks during the policy-learning process. Moreover, our methodology exhibits compatibility with classic MARL methods, allowing for the learning of effective policies.},
  archive      = {J_ESWA},
  author       = {Kaiyu Wang and Bohao Qu and Menglin Zhang and Xianchang Wang and Ximing Li},
  doi          = {10.1016/j.eswa.2025.129781},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129781},
  shortjournal = {Expert Syst. Appl.},
  title        = {SUNRISE: Multi-agent reinforcement learning via neighbors’ observations under fully noisy environments},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RSUTrajRec: Multi-granularity trajectory recovery based on roadside units sensing. <em>ESWA</em>, <em>298</em>, 129780. (<a href='https://doi.org/10.1016/j.eswa.2025.129780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle mobility trajectories, especially fine-grained trajectories, provide valuable insights for understanding urban dynamics and play a crucial role in intelligent transportation systems and urban planning. Obtaining fine-grained vehicle trajectories can be realized by trajectory recovery, but traditional efforts suffer from defects such as poor privacy protection and low recovery accuracy. To address these issues, we propose a new scenario of trajectory recovery based on roadside unit (RSU) sensing. However, this scenario introduces a significant challenge: recovering high-precision trajectories from the incomplete and unevenly distributed sensing data. To tackle this, we design RSUTrajRec , a multi-granularity trajectory recovery framework that comprises a graph neural network-based module for road information prediction, a Transformer-based module for multi-granularity recovery, and an RSU deployment planning module. Extensive real-world dataset evaluations reveal that RSUTrajRec has a significant advantage in recovering missing vehicle trajectories outside the RSU coverage area. In addition, evaluations also verify that the performance of the trajectory recovery task can be effectively improved by optimizing the RSU deployment plan.},
  archive      = {J_ESWA},
  author       = {Xianjing Wu and Xutao Chu and Jianyu Wang and Shengjie Zhao},
  doi          = {10.1016/j.eswa.2025.129780},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129780},
  shortjournal = {Expert Syst. Appl.},
  title        = {RSUTrajRec: Multi-granularity trajectory recovery based on roadside units sensing},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Technology foresight in china’s industrial robotics with MLWS-TF: A machine learning and weak signal-based system. <em>ESWA</em>, <em>298</em>, 129779. (<a href='https://doi.org/10.1016/j.eswa.2025.129779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technology foresight analyses technological trends and potential impacts to provide strategic guidance. However, existing methods either rely on experts to discover emerging directions leading to subjective bias or adopt machine learning to predict without explanation. We propose a Machine Learning and Weak Signal-based Technology Forecasting System (MLWS-TF), which is entirely data-driven to enhance the objectivity of technology foresight and can interpret emerging directions through weak signals. The system adopts a two-phase machine learning model (2P-ML), the first phase identifies papers related to the robotics field, while the second further classifies them into fine-grained research directions. Keywords are extracted from the papers using a Word2Vec-based approach, and a three-dimensional signal classification method (DVI) is developed to quantify the foresight value of keywords across the Diffusion, Visibility, and Impact dimensions, identifying weak signals for technology forecasting. Experiments evaluate various machine learning algorithms, and XGBoost outperforms in constructing the 2P-ML classifier. The model achieved over 90% accuracy, demonstrating its effectiveness in identifying the theme of scientific documents based on textual features. For each research theme, the DVI provides a more comprehensive assessment of signal strength to detect weak signals. Finally, MLWS-TF analyses the growth potential of themes and successfully identifies critical development directions. Our approach offers a novel automated technology foresight system, which completely avoids the subjectivity and dependence on expert judgment that characterize traditional technology foresight approaches, and extends weak signal theory by introducing the Impact dimension to evaluate signal strength.},
  archive      = {J_ESWA},
  author       = {Ruihan Wang and Yuhao Zhu},
  doi          = {10.1016/j.eswa.2025.129779},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129779},
  shortjournal = {Expert Syst. Appl.},
  title        = {Technology foresight in china’s industrial robotics with MLWS-TF: A machine learning and weak signal-based system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generating realistic pruning solutions for automated grape vine pruning using graph neural networks. <em>ESWA</em>, <em>298</em>, 129778. (<a href='https://doi.org/10.1016/j.eswa.2025.129778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our prior work we showed that graph neural networks (GNNs) can be trained to generate pruning solutions that could direct robotic pruning robots to perform automated cane pruning of wine grape vines. That study introduced the feasibility of the technology but also showed that there were many open questions and issues with the research results that needed to be addressed. In this study we address some of these questions. For example, we answer the question of how would a model like this perform on real vine architectures compared with pruning solutions from real experienced pruners. Our most notable contributions include moving away from a per-cane classification model that attempts to define a single perfect pruning solution, to a model that ranks multiple good solutions and picks the best one. We addressed a key limitation of the previous training data by moving away from synthetic vine architectures to realistic ones recorded from real vines and using pruning solutions collected by expert pruners as our ground-truth. Our primary goal was to show that learning by example using a GNN-based model was a viable approach to automated pruning, even when compared with experienced pruners. We showed robust performance from our model by training on a dataset of 90 pruning solutions generated by expert pruners in the 2022 season, and testing our performance on 117 pruning solutions from an independent set of pruners from the 2021 season. The model was able to correctly score all the pruning solutions from the 2021 dataset as good to very good and none of the expert solutions were classified as poor .},
  archive      = {J_ESWA},
  author       = {Jaco Fourie and Jeffrey Hsiao and Oliver Batchelor and Kevin Langbroek and Henry Williams and Richard Green and Armin Werner},
  doi          = {10.1016/j.eswa.2025.129778},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129778},
  shortjournal = {Expert Syst. Appl.},
  title        = {Generating realistic pruning solutions for automated grape vine pruning using graph neural networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Disruption-responsive berth allocation and quay crane scheduling with inter-terminal collaboration. <em>ESWA</em>, <em>298</em>, 129776. (<a href='https://doi.org/10.1016/j.eswa.2025.129776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Container terminal operations frequently encounter disruptions, including delays, extended handling times, and unscheduled vessel arrivals, all of which necessitate intelligent rescheduling strategies to maintain operational efficiency. This study investigates the integrated problem of disruption-responsive berth allocation and quay crane (QC) scheduling, explicitly considering vessel gathering status and incorporating inter-terminal shifting (ITS) and reassignment to terminals different from its originally designated one (RT) as adaptive response strategies to mitigate these disruptions. A rescheduling model is developed to minimize associated costs. To efficiently solve large-scale problems, an adaptive large neighborhood search (ALNS)-based heuristic is proposed. The effectiveness of the proposed scheme is validated through comparative experiments involving three alternative schemes, highlighting its superior performance. Furthermore, algorithm comparison experiments are conducted to verify the robustness of parameter settings. Computational results demonstrate that the proposed model and algorithm achieve high efficiency and solution quality. Additionally, sensitivity analysis reveals that neglecting vessel gathering status leads to substantial cost increases, particularly in large-scale operations. The integration of ITS and RT proves to be an effective strategy for mitigating disruptions, enhancing scheduling flexibility, and improving operational performance.},
  archive      = {J_ESWA},
  author       = {Hongxing Zheng and Zhaoyang Wang and Lingxiao Wu},
  doi          = {10.1016/j.eswa.2025.129776},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129776},
  shortjournal = {Expert Syst. Appl.},
  title        = {Disruption-responsive berth allocation and quay crane scheduling with inter-terminal collaboration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mining spatiotemporal dominant co-location patterns. <em>ESWA</em>, <em>298</em>, 129775. (<a href='https://doi.org/10.1016/j.eswa.2025.129775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial co-location pattern mining is an important branch of spatial data mining, which can identify spatial features that prevalently occur in proximity. Based on spatial co-location patterns, the research of dominant relationships mining within co-location patterns further considers the influence relationship among features. However, relying solely on spatial data to analyze the positions and distribution of features for mining dominant relationships is insufficient and may lead to incorrect patterns. To address this limitation, this paper introduces the temporal factor into the research of dominant relationships mining and proposes the spatiotemporal dominant co-location pattern mining (STDCPM). At first, we define the concepts of spatiotemporal dominant relationship from both temporal and spatial dimensions, and then propose the spatiotemporal dominant participation index to assess the prevalence of spatiotemporal dominant co-location patterns. Furthermore, we design two algorithms, the spatiotemporal dominant co-location pattern mining algorithm with level-by-level search and its improved version, i.e., the spatiotemporal dominant co-location pattern mining approach based on dual pruning and refining set (STDCPM-DPR), to ensure efficient mining in spatiotemporal datasets. The time complexity, correctness, and completeness of proposed algorithms are discussed. Extensive experiments on real-world datasets demonstrate the effectiveness of STDCPM and the efficiency of STDCPM-DPR algorithm.},
  archive      = {J_ESWA},
  author       = {Jiangchuan Mei and Peizhong Yang and Hongmei Chen and Lizhen Wang},
  doi          = {10.1016/j.eswa.2025.129775},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129775},
  shortjournal = {Expert Syst. Appl.},
  title        = {Mining spatiotemporal dominant co-location patterns},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-scale content adaptive network for three-dimensional multi-object tracking and fish activity quantification. <em>ESWA</em>, <em>298</em>, 129774. (<a href='https://doi.org/10.1016/j.eswa.2025.129774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tracking and quantifying fish activity are vital for evaluating their health status and adaptability to the environment. However, most current research on fish tracking and activity quantification suffers from the limitation of being two-dimensional, losing crucial vertical or horizontal information. To facilitate tracking and quantitative analysis of fish activity in three-dimensional (3D) space, a cross-scale content-adaptive network-based 3D multi-object tracking method for fish is proposed, through which fish movements are quantified accordingly. Firstly, a cross-scale content-adaptive fusion network is proposed to accurately determine the fish positions from top-down and side views, thereby mitigating the issue of scale variation across different perspectives. Secondly, a hierarchical tracking method is implemented to obtain the 3D trajectories of the fish, addressing the challenge of cross-view identity matching. Finally, activity parameters in 3D space, including the activity quantity and trajectory length for individual fish, as well as the dispersion and cohesion for the fish group, are calculated. The proposed method was validated, achieving a Multi-Object Tracking Accuracy (MOTA) of 97.68% and an Identification F1 Score (IDF1) of 97.93%. For activity quantification, the Mean Absolute Error (MAE) was found to be 0.088 (unit weight·(cm/s) 2 ), and the Root Mean Square Error (RMSE) was 0.1064 (unit weight·(cm/s) 2 ). These results affirm the method’s adaption of fish features across scales for 3D tracking and activity analysis. With its efficient performance, our method presents as an instrument for activities such as fish behavior monitoring, selective breeding, and environmental assessment.},
  archive      = {J_ESWA},
  author       = {Yiran Liu and Dingshuo Liu and Mingrui Kong and Beibei Li and Qingling Duan},
  doi          = {10.1016/j.eswa.2025.129774},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129774},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-scale content adaptive network for three-dimensional multi-object tracking and fish activity quantification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive multimodal semantic knowledge enhanced framework for sarcasm detection. <em>ESWA</em>, <em>298</em>, 129773. (<a href='https://doi.org/10.1016/j.eswa.2025.129773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sarcasm detection (MSD) has become an important research topic for understanding sentiments on social media, while various recent MSD approaches extract high-level semantic knowledge from images to improve performance. However, some key semantic information, such as emotions expressed in images, is still neglected, limiting reliable sentiment understanding. To address this issue, we propose an adaptive multimodal semantic knowledge enhanced framework for sarcasm detection. We first design an adaptive processing pipeline to extract emotion-aware visual semantics as an auxiliary modality to enhance multimodal feature representations. Enabled by two attention mechanisms, bidirectional cross-modal attention and graph attention, interactions between modalities are analysed to improve MSD performance. Extensive experiments are conducted on two public multimodal sarcasm detection datasets, MMSD and MMSD 2.0, comprising approximately 19,000 tweet samples. Our proposed approach achieves consistent improvements in both sarcasm detection accuracy and F1-score compared to strong baseline models such as DIP and KnowleNet. Built upon a ViT-based architecture, the fine-tuned model offers competitive performance with lower computational overhead, highlighting its potential for practical deployment.},
  archive      = {J_ESWA},
  author       = {Jing Dong and Yu Sui and Qiang Zhang and Hui Fang and Gerald Schaefer and Rui Liu and Pengfei Yi and Xiaoyong Fang},
  doi          = {10.1016/j.eswa.2025.129773},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129773},
  shortjournal = {Expert Syst. Appl.},
  title        = {An adaptive multimodal semantic knowledge enhanced framework for sarcasm detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FoRKER: Focused reasoner with knowledge editing and self-reflection. <em>ESWA</em>, <em>298</em>, 129771. (<a href='https://doi.org/10.1016/j.eswa.2025.129771'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop question answering (MHQA) is a complex question answering (QA) benchmark that requires agents to integrate information from diverse sources and utilize cross-referencing reasoning to answer intricate questions. Existing MHQA-handling frameworks typically employ a retrieve-read paradigm. However, these efforts rooted in the retrieve-read paradigm are still constrained by: 1) unstable document retrieval performance , 2) weak knowledge refinement capabilities , and 3) the absence of a reflection mechanism for error awareness . To address these limitations, we propose FoRKER ( Fo cused R easoner with K nowledge E diting and Self- R eflection), which is a plug-and-play framework. Specifically, we develop a novel progressive focusing mechanism to pinpoint highly relevant document resources and introduce knowledge editing techniques to further eliminate noise interference within textual information. Additionally, we design a novel prompting method, named Chain-of-Evidence (CoE), which is designed to augment the reasoning capabilities of FoRKER . Notably, the integration of Self-Reflection technology further endows FoRKER with the ability to learn and improve from its mistakes. Extensive experiments on widely-used datasets demonstrate that FoRKER achieves new state-of-the-art results in information retrieval and reading comprehension, while also exhibiting effective generalization. Exhilaratingly, on the MusiqueQA dataset, FoRKER demonstrates a 20 % improvement in Answering scores compared to the advanced competitors.},
  archive      = {J_ESWA},
  author       = {Chunbai Zhang and Haoyang Li and Chao Wang and Yang Zhou and Yan Peng},
  doi          = {10.1016/j.eswa.2025.129771},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129771},
  shortjournal = {Expert Syst. Appl.},
  title        = {FoRKER: Focused reasoner with knowledge editing and self-reflection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel fuzzy clustering approach with transition matrix for explainable evaluation of social media-based digital literacy interventions. <em>ESWA</em>, <em>298</em>, 129769. (<a href='https://doi.org/10.1016/j.eswa.2025.129769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the effectiveness of digital literacy interventions often relies on raw score comparisons or hard classifications, which may obscure nuanced changes in conceptual understanding and provide limited interpretability. Traditional approaches fail to capture the probabilistic and fuzzy nature of learning progression and do not support transparent analysis of how learners transition across conceptual clusters over time. This study proposes an explainable evaluation framework that integrates fuzzy clustering with a fuzzy transition matrix to model the redistribution of aggregated membership values between pretest and posttest conceptual clusters. The framework applies Fuzzy C-Means (FCM) to derive soft cluster memberships and constructs a transition matrix that represents probabilistic learning progression in a linguistically interpretable form. Unlike conventional methods, this approach enables the analysis of gradual transitions across levels of proficiency rather than binary outcomes. The model was applied to real-world educational data from control and experimental classes, the latter of which received a social media-based instructional intervention. Results indicate that the control class exhibited downward or stagnant patterns, particularly among high-performing learners, while the experimental class showed more coherent upward cluster transitions among low- and moderate-level learners. By enabling interpretable modeling of pre–post cluster transition patterns, the proposed framework contributes to the advancement of explainable machine learning in education. It also highlights the potential of social computing platforms to foster scalable, data-driven digital literacy development.},
  archive      = {J_ESWA},
  author       = {Rustam and Diana Noor Anggraini and Koredianto Usman and Loveleen Gaur},
  doi          = {10.1016/j.eswa.2025.129769},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129769},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel fuzzy clustering approach with transition matrix for explainable evaluation of social media-based digital literacy interventions},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic graph structure correction with nonadjacent correlations for multivariate time series forecasting. <em>ESWA</em>, <em>298</em>, 129768. (<a href='https://doi.org/10.1016/j.eswa.2025.129768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively modeling the relations between variables in multivariate time series is of utmost importance for accomplishing accurate predictions. In real-world scenarios, in addition to sequential correlations, the evolution of relations between variables also exhibits nonadjacent correlations at different scales. However, existing methods primarily focus on constructing dynamic graph structures at each time step using temporal features extracted by continuous temporal models, which cannot capture above latent dependencies. In this study, we introduce the Dynamic Graph Structure Correction (DGC) model, leveraging a multi-scale framework with dilated convolution. To take full advantage of nonadjacent correlations in the evolution of relations between variables, we adaptively select history-related graph structures to correct initial graph structure constructed by Gate Recurrent Units. In addition, we design a time-decay-based attention mechanism to address the influence of time intervals between history-related and current time steps. Finally, the evolved graph structures are fed into graph neural networks to handle the multi-scale and complex structural relations. Our proposed model achieves superior performance compared to state-of-the-art methods in multivariate time series forecasting, as evidenced by the evaluation results on four widely used benchmark datasets.},
  archive      = {J_ESWA},
  author       = {Dandan He and Yueyang Wang and Chaoli Lou and Gang Tan and Qingyu Xiong and Guodong Sa},
  doi          = {10.1016/j.eswa.2025.129768},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129768},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic graph structure correction with nonadjacent correlations for multivariate time series forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimized homomorphic linear computation in privacy-preserving CNN inference. <em>ESWA</em>, <em>298</em>, 129767. (<a href='https://doi.org/10.1016/j.eswa.2025.129767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning as a Service (MLaaS) provides robust solutions for deploying deep learning inference in cloud environments. However, it also raises serious privacy concerns regarding user data and proprietary model parameters. Numerous hybrid cryptographic protocols that integrate homomorphic encryption (HE) and garbled circuits (GC) have been proposed to enable secure inference with low latency. In these protocols, the homomorphic evaluation of linear operations remains the primary performance bottleneck and warrants further optimization. In this work, we propose novel optimizations for HE-based linear computations within the hybrid cryptographic framework for secure neural network inference. Specifically, we devise two efficient strategies for homomorphic matrix-vector multiplication and convolution. For matrix-vector multiplication, we introduce a grouped diagonal extraction technique that encodes the weight matrix more compactly and enables configurable ciphertext rotation reuse, while for homomorphic convolution, we present a group-wise combine-and-merge evaluation method. Both methods significantly reduce the number of required ciphertext rotations. Our approach achieves up to a 3.9 × speedup in matrix-vector multiplication and a 2.9 × improvement in convolution over state-of-the-art (SOTA) solutions. The HE-GC hybrid secure convolutional neural networks (CNN) inference framework incorporating these enhancements yields speedups of 2.5 × on widely used ResNets deep learning architectures.},
  archive      = {J_ESWA},
  author       = {Chenglong Li and Xirong Ma and Xiuhao Wang and Fanyu Kong and Yunting Tao and Chunpeng Ge},
  doi          = {10.1016/j.eswa.2025.129767},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129767},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimized homomorphic linear computation in privacy-preserving CNN inference},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding. <em>ESWA</em>, <em>298</em>, 129766. (<a href='https://doi.org/10.1016/j.eswa.2025.129766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reversible data hiding in encrypted images (RDHEI) is a promising technique for multimedia cloud computing that enables the embedding of secret data into encrypted images while preserving confidentiality. However, the existing RDHEI algorithms fail to meet the high-security requirements of distributed storage systems in the cloud. Although, secret sharing based RDHEI (SS-RDHEI) may solve this problem, the current methods have weakness such as insufficient embedding capacity and unsatisfactory balance between image security and redundancy. To enhance the algorithm’s ability to carry information, this paper proposes a SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding. Firstly, pixel-difference preservation based modulation (PDPM) ensures secure encryption by modifying all pixels except for a reference block, minimizing damage; moreover, an improved block-level pixel predictor enhances carrier redundancy. Secondly, auxiliary data free coding (ADFC) marks prediction errors directly in the binary sequence of the original pixel without auxiliary information while maintaining accuracy, and reduces the impact of different textures on embedding performance byselecting optimal parameters for each share image. Finally, by combining PDPM with secret sharing, it achieves independent embedding for multiple data hiders while ensuring fair information embedding. Experimental results demonstrate that the proposed algorithm outperforms existing state-of-the-art schemes in terms of information-carrying capability.},
  archive      = {J_ESWA},
  author       = {Zhihua Gan and Zongwei Tang and Yalin Song and Gongyao Cao and Xiuli Chai and Yushu Zhang},
  doi          = {10.1016/j.eswa.2025.129766},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129766},
  shortjournal = {Expert Syst. Appl.},
  title        = {SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved convolutional neural networks for the bullwhip effect in supply chains. <em>ESWA</em>, <em>298</em>, 129764. (<a href='https://doi.org/10.1016/j.eswa.2025.129764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bullwhip Effect (BWE) introduces significant challenges to production systems by amplifying demand and order oscillations. One of the most effective methods for predicting and modeling complex systems is Convolutional Neural Networks (CNNs). However, certain phenomena, such as the BWE in supply chains (SC), are difficult to predict and identify directly. The primary challenge for Machine Learning (ML) algorithms in this context lies in the training phase: the raw demand and order data are fed into the network, yet the desired training outcome is the oscillatory behavior of these data from the perspective of the BWE. Consequently, conventional max pooling, average pooling operators, kernels, and weighted linear combinations of data are insufficient for capturing this type of learning. To address this issue, in this paper, a novel structure containing new pooling operators and kernels of CNNs is proposed to tailor the unique characteristics of the BWE. Specifically: a ) Considering the temporal propagation nature of the BWE, new filters and pooling operators were designed to enable CNNs to predict the BWE accurately. b ) A tensor structure was also proposed for the time signal of demand as inputs of the CNNs to facilitate the analysis of all factors influencing the occurrence of the BWE. c ) To capture the magnitude of the BWE among features, a novel combination of filters and pooling operators was proposed, enabling the CNNs to account for hidden but yet significant feature effects during training. The benefits of the proposed approach lie in its versatility, and it can be applied to train CNNs to model structured fluctuations like the BWE in various dynamic systems.},
  archive      = {J_ESWA},
  author       = {Sajjad Aslani Khiavi and Farzad Hashemzadeh},
  doi          = {10.1016/j.eswa.2025.129764},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129764},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improved convolutional neural networks for the bullwhip effect in supply chains},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid risk assessment method combining CatBoost and FAHP-grid search optimized risk matrix for container ship accident. <em>ESWA</em>, <em>298</em>, 129763. (<a href='https://doi.org/10.1016/j.eswa.2025.129763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a dominant mode of maritime transportation with unique risk characteristics, container shipping requires accurate and applicable risk assessment. However, conventional risk matrices oversimplify complex interactions, while pure data-driven models lack operational utility. To address this, a hybrid method for container ship risk assessment is proposed. This method integrates CatBoost-based predictive method, FAHP-grid search optimized risk matrix, and GIS-supported risk mapping. A comprehensive study of maritime casualties and piracy accidents is conducted, utilizing historical incident data sets collected from the Global Integrated Shipping Information System (GISIS). The global maritime accident risk of container ships is then evaluated and mapped. The sensitivity analysis confirms the robustness of the method under varying linguistic distance parameters, while expert weights have a moderate impact on the assessment results. Finally, the effectiveness of the proposed method is validated through comparative analyses on predictive performance, risk discrimination capability, and risk assessment accuracy. CatBoost algorithm outperforms XGBoost, LightGBM, and Random Forest algorithms in predictive metrics. The designed risk matrix shows strong discriminatory ability for container ship risk levels. In historical accident data validation, the proposed method also achieves higher accuracy than combinations involving XGBoost, LightGBM, or Random Forest with the designed risk matrix.},
  archive      = {J_ESWA},
  author       = {Yuqing Xiao and Shilian Han and Xinwang Liu},
  doi          = {10.1016/j.eswa.2025.129763},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129763},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid risk assessment method combining CatBoost and FAHP-grid search optimized risk matrix for container ship accident},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quadrotor navigation considering attitude: A deep reinforcement learning method using tangent path rewards. <em>ESWA</em>, <em>298</em>, 129762. (<a href='https://doi.org/10.1016/j.eswa.2025.129762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous navigation of quadrotors is a fundamental prerequisite for numerous applications. This work proposes a novel deep reinforcement learning (DRL) framework that explicitly addresses quadrotor attitude dynamics during autonomous navigation, a critical yet underexplored challenge in existing learning-based UAV navigation studies. In the proposed method, high-level velocity commands will be generated by a deep neural network policy and translated by a low-level control algorithm to achieve precise control of both positions and rotations of quadrotors. A specialized network structure is designed to effectively extract environmental obstacle features and quadrotor sequence features to improve navigation performance. In addition, a novel tangent path reward (TPR) calculation method is developed to adequately utilize the known contours and positions of obstacles during the training phase. Experimental results demonstrate that the proposed method enables quadrotors to autonomously navigate complex virtual obstacle environments with superior efficiency compared with other algorithms. Furthermore, the feasibility and adaptability of the proposed method are validated through simulations by varying obstacle density and map size, as well as replicating real-world obstacle distributions.},
  archive      = {J_ESWA},
  author       = {Qizhang Luo and Yuqi Li and Jiaheng Zeng and Guohua Wu and Yalin Wang},
  doi          = {10.1016/j.eswa.2025.129762},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129762},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quadrotor navigation considering attitude: A deep reinforcement learning method using tangent path rewards},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dynamic tri-stage framework with neural network-assisted search for constrained multi-objective optimization. <em>ESWA</em>, <em>298</em>, 129761. (<a href='https://doi.org/10.1016/j.eswa.2025.129761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems involve the optimization of multiple objective functions and the satisfaction of different constraints, which poses a challenge for algorithms to achieve a good balance between convergence and diversity. However, indiscriminately enhancing diversity can hinder convergence, while solely focusing on convergence may impair the exploration of the objective space, especially when the current stage is not well-defined. To address this issue, we propose a three-stage multi-task framework for constrained multi-objective optimization with dynamically switchable stages. This framework introduces two auxiliary tasks: one that operates during the exploration and transition stages to accelerate convergence towards the boundary of the infeasible regions and assist the population in crossing it, and another that operates in the final convergence stage to guide the population towards the constrained Pareto front. Moreover, a stage detection method is proposed, which evaluates the current stage to determine the appropriate evolutionary direction for the population, thus enabling dynamic stage transitions. In addition, a neural network-assisted search operator is designed for the auxiliary task during the transition stage, which learns the optimal offspring generation process. This operator enhances the ability of the auxiliary population to cross the infeasible regions. Finally, the performance of the proposed algorithm is superior and competitive on three test suites and six real-world engineering problems compared to seven state-of-the-art algorithms.},
  archive      = {J_ESWA},
  author       = {Qianlong Dang and Xinkang Hong and Xianpeng Sun},
  doi          = {10.1016/j.eswa.2025.129761},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129761},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dynamic tri-stage framework with neural network-assisted search for constrained multi-objective optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A physics-informed neural network surrogate model and many-objective optimization algorithm for coupled multi-energy systems in smart grids. <em>ESWA</em>, <em>298</em>, 129760. (<a href='https://doi.org/10.1016/j.eswa.2025.129760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scope of smart grids is progressively extending toward Integrated Energy Systems (IES) that couple electricity with gas, heating, and cooling. Due to the unsteady-state physical characteristics inherent in the transmission of gas, heat, and cooling resources, IES scheduling must not only balance multiple typical objectives but also account for the dynamic coupling of heterogeneous physical domains. To address these challenges, this paper formulates a Many-objective Optimization Model for Coupled Multi-Energy Flows (MaOCMFM) with partial differential equations (PDEs) in IES, which captures the dynamic physical behaviors of electricity, gas, heat, and cooling subsystems. Building upon this model, we propose a Probabilistic Contributing Many-objective Evolutionary Algorithm enhanced by a Physics-Informed Neural Network surrogate model (PC-MaOEA-PINN). Cubic B-spline functions are employed to achieve a continuous representation of the decision variables, while multi-physics constraints are embedded into the loss function of the surrogate model. This design enables efficient approximation of the objective function with a limited number of samples and facilitates focused exploration in critical evolutionary regions, thereby accelerating population convergence. The effectiveness of the proposed model and algorithm is validated on 9 typical scheduling days across four simulated IES scenarios.},
  archive      = {J_ESWA},
  author       = {Jingbo Zhang and Xingjuan Cai and Zhihua Cui and Jinjun Chen},
  doi          = {10.1016/j.eswa.2025.129760},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129760},
  shortjournal = {Expert Syst. Appl.},
  title        = {A physics-informed neural network surrogate model and many-objective optimization algorithm for coupled multi-energy systems in smart grids},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An emergency scheduling method based on AutoML for space maneuver objective tracking. <em>ESWA</em>, <em>298</em>, 129759. (<a href='https://doi.org/10.1016/j.eswa.2025.129759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of large-scale constellations has led to a dramatic increase in the number of Resident Space Objectives (RSOs), significantly intensifying the complexity of Space Situational Awareness (SSA). Furthermore, the maneuver behaviors of non-cooperative RSOs pose potential threats to space safety, making the real-time monitoring of their post-maneuver orbital becomes more critical. In particular, the maneuvering characteristics of large-scale constellation satellites impose more stringent demands on the timeliness and adaptability of existing scheduling algorithms for observation resources. To address the emergency scheduling demands of heterogeneous ground-based observation resources, this paper proposes an Emergency Task Three-phase Scheduling Framework (ETTSF) based on Automated Machine Learning (AutoML) and auction algorithm. The framework collaboratively optimizes resource allocation through three phases: resource matching, task scheduling, and rescheduling. First, AutoML combined with an auction algorithm predicts and assigns emergency tasks to the most appropriate resources, reducing solution space complexity, simultaneously, the auction algorithm’s corrected results are fed back to AutoML for model fine-tuning. Second, a heuristic algorithm with dynamic neighborhood structures efficiently inserts emergency tasks into the routine observation plan. Finally, affected routine tasks are rescheduled to minimize the operational impact. Simulation results demonstrate that compared to baselines-Real-Time Dynamic Scheduling (RTDS) and Improved Adaptive Large Neighborhood Search (IALNS)-ETTSF achieves a 2.82% improvement in Completion Rate of Emergency RSOs (CRER) and a 27.83% reduction in Impact Rate (IR) on routine tasks. Ablation experiments further validate the effectiveness of the resource matching and rescheduling phases.},
  archive      = {J_ESWA},
  author       = {Xi Long and Jinrun Chen and Leping Yang and Huan Huang},
  doi          = {10.1016/j.eswa.2025.129759},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129759},
  shortjournal = {Expert Syst. Appl.},
  title        = {An emergency scheduling method based on AutoML for space maneuver objective tracking},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploiting point-language models with dual-prompts for 3D anomaly detection. <em>ESWA</em>, <em>298</em>, 129758. (<a href='https://doi.org/10.1016/j.eswa.2025.129758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection (AD) in 3D point clouds is crucial in a wide range of industrial applications, especially in various forms of precision manufacturing. Considering the industrial demand for reliable 3D AD, several methods have been developed. However, most of these approaches typically require training separate models for each category, which is memory-intensive and lacks flexibility. In this paper, we propose a novel P oint- L anguage model with dual-prompts for 3D AN omaly d E tection (PLANE). The approach leverages multi-modal prompts to extend the strong generalization capabilities of pre-trained Point-Language Models (PLMs) to the domain of 3D point cloud AD, achieving impressive detection performance across multiple categories using a single model. Specifically, we propose a dual-prompt learning method, incorporating both text and point cloud prompts. The method utilizes a dynamic prompt creator module (DPCM) to produce instance-specific dynamic prompts, which are then integrated with class-specific static prompts for each modality, effectively driving the PLMs. Additionally, based on the characteristics of point cloud data, we propose a pseudo 3D anomaly generation method (Ano3D) to improve the model’s detection capabilities in the unsupervised setting. Experimental results demonstrate that the proposed method, which is under the multi-class-one-model paradigm, achieves a +8.7 %/+7.0 % gain on anomaly detection and localization performance as compared to the state-of-the-art one-class-one-model methods for the Anomaly-ShapeNet dataset, and obtains +4.3 %/+0.3 % gain for the Real3D-AD dataset. Code will be available upon publication.},
  archive      = {J_ESWA},
  author       = {Jiaxiang Wang and Haote Xu and Xiaolu Chen and Haodi Xu and Yue Huang and Xinghao Ding and Xiaotong Tu},
  doi          = {10.1016/j.eswa.2025.129758},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129758},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploiting point-language models with dual-prompts for 3D anomaly detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Path-aware routing system for multimodal vigilance estimation: A structured fusion perspective. <em>ESWA</em>, <em>298</em>, 129757. (<a href='https://doi.org/10.1016/j.eswa.2025.129757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver vigilance is a critical cognitive factor in ensuring the safety of intelligent driving systems. With advances in physiological and behavioral sensing technologies, multimodal data have become an essential source for modeling drivers’ cognitive states. However, vigilance, as an implicit cognitive state, is difficult to model accurately using a single modality. Efficient fusion of multiple modalities and structured information interaction remains a core challenge in this task. Existing approaches often rely on strategies such as feature concatenation and attention mechanisms, which lack explicit structural constraints. As a result, heterogeneous modality features are fused in an uncontrolled and entangled manner, making the interaction process opaque and difficult to interpret. To address these issues, we propose the Path-Aware Routing System (PARS), which formulates multimodal fusion as a feature routing task. In PARS, intra-modal enhancement and cross-modal interaction are abstracted into independent semantic channels, and a confidence-aware mechanism is introduced to enable dynamically weighted fusion. PARS explicitly constructs a path space, allowing features to be selectively routed and integrated along semantical pathways, thereby enhancing the model’s discriminative power and robustness. We conduct extensive experiments on a public dataset and a self-constructed driving simulation dataset. The results demonstrate that PARS significantly outperforms existing multimodal fusion methods in the task of driver vigilance estimation, achieving superior performance in terms of accuracy, interpretability, and generalization. These findings highlight the broad potential of PARS in intelligent driving applications. Our code and models are available at: https://github.com/SunYu-Gavin/PARS .},
  archive      = {J_ESWA},
  author       = {Yu Sun and Shiwu Li and Yiming Bie and Linhong Wang and Tongtong Jin and Mengzhu Guo and Zhifa Yang},
  doi          = {10.1016/j.eswa.2025.129757},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129757},
  shortjournal = {Expert Syst. Appl.},
  title        = {Path-aware routing system for multimodal vigilance estimation: A structured fusion perspective},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Homophone-aware offensive language detection via semantic-phonetic collaboration. <em>ESWA</em>, <em>298</em>, 129756. (<a href='https://doi.org/10.1016/j.eswa.2025.129756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing use of implicit and obfuscated expressions poses significant challenges to offensive language detection in Chinese online platforms. In particular, users often exploit homophone substitutions to bypass keyword-based moderation, making traditional detection systems inadequate. This study addresses the problem of detecting offensive content masked through homophonic substitutions, which retain aggressive intent while altering character representations. Existing methods fall into two main categories: (1) semantic-only models, which struggle with phonetic manipulations due to their reliance on text features alone, and (2) auxiliary-enhanced models, which incorporate phonetic or syntactic signals but lack deep integration between modalities. To overcome these limitations, we propose a lightweight dual-branch model that separately encodes textual semantics and pinyin phonetics under a multi-view learning framework. A Dual-Branch Interactive Training strategy is introduced to enable dynamic cross-modal alignment via contrastive objectives, allowing each modality to mutually refine the other and enhance robustness to adversarial inputs. We conduct experiments on two benchmark datasets, COLD and SWSR, both of which are augmented with varying levels of homophone noise to simulate real-world evasion strategies. The proposed model outperforms all baseline models, achieving an average F1-score improvement of 6.3 % under high-noise conditions, while reducing inference latency and memory usage by more than 60 %, demonstrating both effectiveness and efficiency for real-time deployment. We will release the source code for further use by the community https://github.com/hjhhlc/DBIT .},
  archive      = {J_ESWA},
  author       = {Jiahao Hu and Shanliang Pan},
  doi          = {10.1016/j.eswa.2025.129756},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129756},
  shortjournal = {Expert Syst. Appl.},
  title        = {Homophone-aware offensive language detection via semantic-phonetic collaboration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing traffic signal control through model-based reinforcement learning and policy reuse. <em>ESWA</em>, <em>298</em>, 129755. (<a href='https://doi.org/10.1016/j.eswa.2025.129755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning (MARL) has shown significant potential in traffic signal control (TSC). However, current MARL-based methods often suffer from insufficient generalization due to the fixed traffic patterns and conditions of the road network used during training. This limitation results in poor adaptability to new traffic scenarios, leading to high retraining costs and complex deployment. To address this challenge, we propose two algorithms: PLight and PRLight. PLight employs a model-based reinforcement learning approach, pretraining control policies, and environment models using predefined source-domain traffic scenarios. The environmental model predicts state transitions, facilitating the comparison of environmental characteristics. PRLight further enhances adaptability by adaptively selecting pre-trained PLight agents based on the similarity between the source and target domains to accelerate the learning process in the target domain. We evaluated the algorithms through two transfer settings: (1) adaptability to different traffic scenarios within the same road network, and (2) generalization across different road networks. The results show that PRLight significantly reduces the adaptation time compared to learning from scratch in new TSC scenarios, achieving optimal performance using similarities between available and target scenarios.},
  archive      = {J_ESWA},
  author       = {Yihong Li and Chengwei Zhang and Furui Zhan and Wanting Liu and Kailing Zhou and Longji Zheng},
  doi          = {10.1016/j.eswa.2025.129755},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129755},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing traffic signal control through model-based reinforcement learning and policy reuse},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated transfer learning for anomaly detection in HPC systems: First real-world validation on a tier-0 supercomputer. <em>ESWA</em>, <em>298</em>, 129754. (<a href='https://doi.org/10.1016/j.eswa.2025.129754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-Performance Computing (HPC) systems increasingly require intelligent, scalable anomaly detection to ensure operational reliability. However, conventional centralized approaches often struggle with data privacy constraints, poor generalization across heterogeneous nodes, and limited scalability. This study presents the first real-world application of federated transfer learning (FTL) for anomaly detection in a production-grade Tier-0 supercomputer. By combining federated learning with transfer learning, the proposed framework enables decentralized model training and personalized adaptation to unseen nodes, without accessing raw data. We validate the approach using two large-scale telemetry datasets collected from 100 nodes of the Marconi100 supercomputer, evaluating its effectiveness across supervised, semi-supervised, and unsupervised learning paradigms. Results show that FTL consistently improves anomaly detection performance on nodes that did not participate in federated training, with F1-score gains reaching up to 0.50. These improvements demonstrate the framework’s ability to generalize across non-identically distributed data and maintain detection accuracy under real-world conditions. This work establishes FTL as a scalable, privacy-preserving solution for fault detection in HPC environments. Its practical deployment on production hardware confirms its readiness for real-time monitoring applications in large-scale, heterogeneous computing systems.},
  archive      = {J_ESWA},
  author       = {Emmen Farooq and Michela Milano and Andrea Borghesi},
  doi          = {10.1016/j.eswa.2025.129754},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129754},
  shortjournal = {Expert Syst. Appl.},
  title        = {Federated transfer learning for anomaly detection in HPC systems: First real-world validation on a tier-0 supercomputer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Security script arrangement based on enhanced BERT for cooperative defense in networked control systems. <em>ESWA</em>, <em>298</em>, 129753. (<a href='https://doi.org/10.1016/j.eswa.2025.129753'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the mutual collaboration and in-depth integration among multiple defense technologies through information sharing, the cooperative defense in networked control systems has emerged as a feasible solution to counter increasingly diversified cyber threats under the unique security characteristics and requirements of industrial environments. However, one of the chief challenges is how to automatically and intelligently develop effective cooperative working strategies when an attack occurs. Leveraging the advantages of large-scale AI (Artificial Intelligence) models, this paper defines a new concept named “security script”, and proposes a security script arrangement approach based on enhanced BERT to achieve fine-grained cooperative defense in networked control systems. Furthermore, this approach introduces intrusion detection and industrial firewall as two practical examples, and can automatically arrange effective security scripts to enable the dynamic interaction of two defense technologies. Additionally, to improve efficiency, the encoder structure adjusting and AdamW optimizing are further presented to enhance the traditional BERT. Experimental results clearly demonstrate that: for one thing, these two optimization ways can make greater achievements in reducing unnecessary time consumption and enhancing accuracy of security script arrangement; for another, compared with other typical BERT and large-scale AI models, the proposed approach can exhibit more favorable performance advantages in achieving cooperative defense based on security script arrangement. In particular, through its successful application and verification in one real-world manufacturing control system, our approach may bring a potential opportunity or direction for further research and improvement of AI-based cooperative defense.},
  archive      = {J_ESWA},
  author       = {Ming Wan and Xueqing Liu and Shengbao An and Aiping Tan and Xi Jin and Chuan Sheng},
  doi          = {10.1016/j.eswa.2025.129753},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129753},
  shortjournal = {Expert Syst. Appl.},
  title        = {Security script arrangement based on enhanced BERT for cooperative defense in networked control systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ScSCDT: Self-contrastive neural network with deep topology mining for scRNA-seq data clustering. <em>ESWA</em>, <em>298</em>, 129751. (<a href='https://doi.org/10.1016/j.eswa.2025.129751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in single-cell sequencing technologies have enabled researchers to better identify cells based on gene-level information. Cell clustering is a key task in single-cell analysis and plays an important role in distinguishing cell types. However, due to the high dimensionality and sparsity of scRNA-seq data, single-cell clustering remains a major challenge. Although many methods based on deep learning and machine learning have been developed for single-cell clustering, they often fail to capture the deep topological structure between cells, which limits clustering precision. In addition, most existing clustering approaches cannot effectively construct suitable sample pairs to optimize clustering models. To address these issues, we propose a topology-aware deep contrastive clustering model for single-cell data, named scSCDT. First, scSCDT employs a ZINB-based autoencoder to simultaneously learn cell embeddings and topological information, effectively handling the challenges posed by the high-dimensional and sparse nature of the data. Then, we introduce a dual clustering-guided loss to supervise the clustering task, combining a probabilistic soft assignment strategy and a hard pseudo-labeling strategy for optimization. Finally, based on the topological structure in the low-dimensional embedding space, we construct negative pairs within a single view and design a self-contrastive learning method to further improve clustering performance. We conduct extensive experiments on ten real scRNA-seq datasets and evaluate performance using four clustering metrics. The results indicate that scSCDT achieves strong clustering performance across multiple datasets, thereby facilitating more accurate cell type identification in single-cell transcriptomic analysis.},
  archive      = {J_ESWA},
  author       = {Zhongyang Zhou and Bin Tang and Feiyu Chen and Wei Wang and Shangshang Zhao and Nanjun Yu},
  doi          = {10.1016/j.eswa.2025.129751},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129751},
  shortjournal = {Expert Syst. Appl.},
  title        = {ScSCDT: Self-contrastive neural network with deep topology mining for scRNA-seq data clustering},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Visual mamba-CNN for scribble-based segmentation in weakly supervised learning for photoacoustic tomography. <em>ESWA</em>, <em>298</em>, 129749. (<a href='https://doi.org/10.1016/j.eswa.2025.129749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoacoustic (PA) imaging is a powerful non-invasive medical imaging technique that combines the high contrast of optical imaging with the deep tissue penetration of ultrasound, offering both structural and functional insights into tissues and organs. Organ-level analysis of photoacoustic tomography (PAT) images enables quantification of specific morphological and functional parameters, making accurate organ segmentation a critical step in PA image-based analysis. However, the limited availability of large-scale annotated datasets remains a major challenge. To address this, we employ cross-modality data augmentation by generating synthetic PA images from MRI scans. To further reduce manual annotation efforts, we propose a weakly supervised learning (WSL) framework that leverages scribble annotations. Since many deep learning models struggle to capture global context from sparse labels, we introduce a novel architecture that combines traditional convolutional neural networks (CNNs) with Visual Mamba, integrating both local and global feature extraction capabilities. This hybrid design improves segmentation performance in weakly supervised settings. We validate our method on a simulated PA abdominal dataset and real in vivo mouse abdominal PAT data, demonstrating notable improvements in segmentation accuracy and robustness.},
  archive      = {J_ESWA},
  author       = {Meng Zhou and Ziyin Ren and Qinlin Tan and Xin Du and Hengrong Lan and Fei Gao and Raymond Kai-Yu Tong},
  doi          = {10.1016/j.eswa.2025.129749},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129749},
  shortjournal = {Expert Syst. Appl.},
  title        = {Visual mamba-CNN for scribble-based segmentation in weakly supervised learning for photoacoustic tomography},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 3D modeling from a single sketch with multifaceted semantic understanding. <em>ESWA</em>, <em>298</em>, 129748. (<a href='https://doi.org/10.1016/j.eswa.2025.129748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of 3D shape generation from a single sketch. Prior works rely on directly extracted visual features of sketches as guidance for the generation process. However, the sparse visual cues and abstract nature of sketches, which are inherited in the guiding features, lead to semantic ambiguity and geometry incompleteness in the generated shapes, compromising accuracy. To address this, we propose MSU-3D, a diffusion-based framework for sketch-to-3D generation, leveraging Multifaceted Semantic Understanding to explicitly analyze the construction information of sketches from multiple facets before providing fine-grained guidance over 3D shape generation. Specifically, we decompose sketches through three interpretative facets (semantics, depth, and normal), introducing reasoning of three representations to capture 3D features from distinct perspectives: local components, basic 3D geometry, and 3D surface details. One step further, we propose a multifaceted perception module. It aggregates multifaceted feature representations and leverages local component features as a two-pronged guiding representation to jointly guide the perception of basic shapes and surface details. To ensure fine-grained control, the hierarchical perception strategy adaptively injects varying granularity of perception features at different stages of the 3D generation. Extensive experiments and comparisons with state-of-the-art methods on various complex posture datasets validate the effectiveness of our framework in mitigating semantic ambiguity and geometry incompleteness in 3D generation.},
  archive      = {J_ESWA},
  author       = {Yuxiao Zhang and Jin Wang and Yang Zhou and Senyun Jia and Zhi Zheng and Dongliang Zhang and Guodong Lu},
  doi          = {10.1016/j.eswa.2025.129748},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129748},
  shortjournal = {Expert Syst. Appl.},
  title        = {3D modeling from a single sketch with multifaceted semantic understanding},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Continuous learning approach to synergize shimmering image enhancement and de-fogging with small sample. <em>ESWA</em>, <em>298</em>, 129747. (<a href='https://doi.org/10.1016/j.eswa.2025.129747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shimmering Image Enhancement and Defogging (SIED) are two important aspects of image recovery. However, most methods are often fail to consider image context information, overexposure of image and the intrinsic correlation between SIED without enough sample. Furthermore, current methods may lead to the amplification of external color interference during image recovery, and can’t fine-tune the model with new samples. Firstly, we propose an Adjustable Multiscale Attention Codec Network (AMACNet) architecture. AMACNet includes variable restorative coder decoder and group channel attention to fuse multi-level contextual and channel information of images, respectively. These components are designed as plug-and-play modules. Secondly, a Continuous Learning with Small Sample (CLS) training method is presented. It utilizes few samples based on a front-and-back stage receding structure. The method synergizes the tasks of SIED, allowing the network to perform both tasks without incresing the number of parameters. It also enables the network to adapt to new tasks with a small number of unpaired samples. Finally, a color adjustment module for image post-processing is designed. The post-processing method is used to balance the impact of color illumination on the inherent color of materials. Extensive experiments demonstrate that training AMACNet by CLS allow the final image recovery results to exceed the GT in terms of ENIQA, FES, PIQE, and other unparameterized metrics.},
  archive      = {J_ESWA},
  author       = {Fenglin Yao and Zhengxiang Liu},
  doi          = {10.1016/j.eswa.2025.129747},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129747},
  shortjournal = {Expert Syst. Appl.},
  title        = {Continuous learning approach to synergize shimmering image enhancement and de-fogging with small sample},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning domain-invariant representation for generalizable iris segmentation. <em>ESWA</em>, <em>298</em>, 129746. (<a href='https://doi.org/10.1016/j.eswa.2025.129746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain iris segmentation (CDIS) seeks to transfer knowledge from a labeled source dataset to an unlabeled target dataset. Existing CNN-based iris segmentation methods commonly assume that training and application stages share the same data distribution and modality setting, thus their performance may decline substantially on open-domain iris datasets unseen before. Furthermore, the process of annotating pixel-wise labels is labor-intensive and time-consuming, resulting in limited applicability of these methods in realistic scenarios. Therefore, we propose a generic domain adaptation iris segmentation framework ( DAIrisSeg ), which can be flexibly incorporated into existing methods. First, a domain-sensitive feature whitening strategy is proposed to effectively mitigate the domain-specific styles while preserving the domain-invariant content, thereby improving the model’s generalizability to unknown domain distribution. We then utilize the prototype estimation and the context-similarity learning adapter to produce reliable segmentation labels. In addition, DAIrisSeg incorporates prior constraints of the iris to further refine the segmentation results. Extensive experiments on three iris datasets demonstrate that the proposed method has shown consistent improvements over state-of-the-art (SOTA) methods.},
  archive      = {J_ESWA},
  author       = {Dawei Lin and Meng Yuan and Ying Chen and Xiaodong Zhu and Yuanning Liu},
  doi          = {10.1016/j.eswa.2025.129746},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129746},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning domain-invariant representation for generalizable iris segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cycle-CFM: An unsupervised framework for robust multimodal anomaly detection in industrial settings. <em>ESWA</em>, <em>298</em>, 129745. (<a href='https://doi.org/10.1016/j.eswa.2025.129745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial multimodal anomaly detection is confronted with three pivotal challenges: cross-modal feature drift, noise sensitivity, and modality imbalance. To address these issues, we propose Cycle-Consistent Cross-Modal Feature Mapping (Cycle-CFM), an unsupervised framework that integrates cycle-consistent cross-modal mapping with channel-attention-guided adaptive loss weighting. Cycle-CFM establishes bidirectional feature alignment between RGB and 3D modalities via reversible cycle mappings, yielding consistent representations robust to vibration and depth noise. To further mitigate dynamic interferences such as illumination variations, we introduce a joint optimization strategy that combines cross-consistency and cycle-consistency losses. Experimental results on our self-constructed SteelDefect-3D-AD dataset demonstrate that Cycle-CFM achieves an AUPRO@1 % of 0.371, outperforming state-of-the-art methods by 17–45 %. It also attains a pixel-level AUROC (P-AUROC) of 0.991 and an image-level AUROC (I-AUROC) of 0.998. On the public MVTec 3D-AD benchmark, Cycle-CFM reaches a mean P-AUROC of 0.960 and improves accuracy by 37.5 % for elongated anomalies. With a runtime of 11.03 FPS and 469.52 MB of parameters, the model highlights both its effectiveness and deployability for real-time industrial inspection.},
  archive      = {J_ESWA},
  author       = {Yikang Shi and Xin Zhan and Yaqian Li and Zhongqiang Wu and Wenming Zhang and Haibin Li},
  doi          = {10.1016/j.eswa.2025.129745},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129745},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cycle-CFM: An unsupervised framework for robust multimodal anomaly detection in industrial settings},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable transfer learning approach to predict carbon emission intensity of coal-fired power plants with multi-source monitoring data. <em>ESWA</em>, <em>298</em>, 129743. (<a href='https://doi.org/10.1016/j.eswa.2025.129743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon mitigation policies and emission trading systems have heightened the need to monitor and predict the carbon emission intensity (CEI) of coal-fired power plants. Leveraging big data and machine learning (ML) technologies, this study trains predictive models of CEI using operational parameters, load rate, and coal-quality data from three Chinese power plants. The performance of Random Forest (RF), eXtreme Gradient Boosting (XGBoost), Support Vector Machine (SVM), and Artificial Neural Network (ANN) was evaluated, and the challenge of limited data in individual plants was mitigated through instance-based transfer learning (ITL) and graft learning (GL) technologies. The results indicate that while traditional ML models struggle with poor data quality and limited samples, transfer learning between different plants will improve predictive accuracy substantially, and GL delivers the greatest gains. Among the most influential features, air supply temperature and load rate critically impact CEI and therefore should be carefully managed to achieve emission reductions. Nevertheless, the effectiveness of transfer learning depends on source data quality and model choice, and the proposed operational strategies require further validation before practical adoption. Our findings offer a robust framework for enhancing the predictive accuracy of plant CEI under data-scarce conditions and inform effective strategies for promoting a low-carbon transition in the energy sector.},
  archive      = {J_ESWA},
  author       = {Xiaodong Jin and Lingzhen Zhang and Fangyi Li and Wu Xie and Dawei Ma and Yan Wu},
  doi          = {10.1016/j.eswa.2025.129743},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129743},
  shortjournal = {Expert Syst. Appl.},
  title        = {An explainable transfer learning approach to predict carbon emission intensity of coal-fired power plants with multi-source monitoring data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Uncertainty-guided denoising bi-classifier adversarial domain adaptation network for cross-domain fault diagnosis. <em>ESWA</em>, <em>298</em>, 129742. (<a href='https://doi.org/10.1016/j.eswa.2025.129742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent fault diagnosis is crucial for ensuring the safety and reliability of modern industrial systems. However, the performance of deep learning models often significantly degrades due to the domain shift between training and testing data. Domain Adaptation (DA) methods, particularly bi-classifier adversarial networks, have proven effective in transferring knowledge from a labeled source domain to an unlabeled target domain. However, existing approaches often pay insufficient attention to target sample prediction accuracy, resulting in reduced feature discriminability and generalization. Additionally, due to the absence of labeled target data, most approaches rely on pseudo-labels, which are often noisy and unreliable, especially in the early stages of training. To address these issues, this paper proposes a novel uncertainty-guided denoising bi-classifier adversarial domain adaptation network (UGDBAN) for cross-domain fault diagnosis. Specifically, a feature generator based on Transformer layers is designed to capture long-range dependencies and local features. To mitigate the impact of noisy pseudo-labels, an uncertainty-based denoising pseudo-labeling mechanism is introduced to enhance the discriminability of features by redefining pseudo-labels and dynamically selecting high-confidence samples as clean samples. Building upon this denoised pseudo-label set, a Dirichlet uncertainty estimation-based class prototype alignment strategy is proposed to align domain features at the class level by selecting low-uncertainty samples representative of each class as prototypes. Extensive experiments demonstrate the effectiveness of UGDBAN, and comparative results with mainstream methods highlight its superiority.},
  archive      = {J_ESWA},
  author       = {Zheng Li and Lei Geng and Yanbei Liu and Feng Rong and Ming Ma and Jun Tong and Zhitao Xiao},
  doi          = {10.1016/j.eswa.2025.129742},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129742},
  shortjournal = {Expert Syst. Appl.},
  title        = {Uncertainty-guided denoising bi-classifier adversarial domain adaptation network for cross-domain fault diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Partially view-aligned clustering via data recoupling and elastic bi-consistency learning. <em>ESWA</em>, <em>298</em>, 129741. (<a href='https://doi.org/10.1016/j.eswa.2025.129741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern multi-view data often suffer from partial view alignment issues, yet most existing multi-view clustering (MVC) methods assume that the data are fully aligned, which is rarely the case in real-world scenarios. This misalignment leads to False Negative Pairs (FNPs), disrupting the learning process. While some methods address partial alignment, they often neglect intra-view consistency and multi-scale inter-view relationships, limiting their ability to capture both global and local structural dependencies. Additionally, the prevalent use of Mean Squared Error (MSE) as a reconstruction loss is suboptimal for discrete data, potentially causing severe performance degradation. To overcome these limitations, we propose Partially View-aligned Clustering via Data Recoupling and Elastic Bi-consistency Learning (PVC-DREBL). Our method integrates two key components: (1) a Data Recouple Module, which realigns the data to mitigate the effects of FNPs while leveraging an exponential contrastive loss to enhance learning stability and prevent overfitting; (2) an Elastic Bi-consistency Learning Module, designed to reconstruct diverse data types robustly while enforcing intra-view and multi-scale inter-view consistency. Extensive experiments on six benchmark datasets demonstrate that PVC-DREBL significantly outperforms existing methods, highlighting its effectiveness in handling partially view-aligned clustering tasks.},
  archive      = {J_ESWA},
  author       = {Wenzhe Liu and Jiongcheng Zhu and Jingbo Tan and Huibing Wang and Yong Zhang},
  doi          = {10.1016/j.eswa.2025.129741},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129741},
  shortjournal = {Expert Syst. Appl.},
  title        = {Partially view-aligned clustering via data recoupling and elastic bi-consistency learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-based CNN for lithological identification from logging curves: A case study in the qaidam basin, china. <em>ESWA</em>, <em>298</em>, 129740. (<a href='https://doi.org/10.1016/j.eswa.2025.129740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subsurface lithological distribution is essential for extrapolating geological information from core to block or basin scales. Given the limited availability of core data, there is a critical need to develop a reliable method for establishing robust correlations between logging curves and lithologies in cores, thereby maximizing the value of large historical logging data. Here, we propose a novel attention-based convolutional neural network (ATT-CNN), which employs a 1D-CNN to transform six types of logging curves into high-dimensional feature space at each depth, and applies an attention mechanism to the 1D-CNN outputs along both the depth and feature dimensions. The architecture is designed to mimic human perceptual processing for lithology identification, leveraging curve combination, thresholding, and local pattern recognition within this enriched and high-dimensional feature representation. In addtion, the study employs wavelet-based preprocessing on logging curves to eliminate the impact of compaction-induced data drift on model generalization—an issue rarely considered in prior studies. The result showes that: ① The proposed ATT-CNN model demonstrates superior performance over benchmark models—the bidirectional gated recurrent unit (BiGRU) and an ensemble of machine learning models (En-ML)—across all evaluation metrics; ②Wavelet-based preprocessing enhances the generalization capability of both ATT-CNN and BiGRU, yielding higher metric scores and improved predictions, particularly in shallow-depth intervals; ③ For blind wells, the ATT-CNN outperforms BiGRU and En-ML in both accuracy and its ability to capture lithological variations even from low-amplitude curve deviations. The integration of ATT-CNN with wavelet-based preprocessing demonstrates significant potential for accurately characterizing subsurface lithological distribution, then provides critical support for key petroleum geology workflows, including provenance analysis, sedimentary facies mapping, and reservoir property prediction.},
  archive      = {J_ESWA},
  author       = {Jianguo Yin and Shuai Zhang and Zhixiong Wu and Shouji Pang and Rui Wang},
  doi          = {10.1016/j.eswa.2025.129740},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129740},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attention-based CNN for lithological identification from logging curves: A case study in the qaidam basin, china},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Clustering-based brain functional segmentation via deep collapsed nonparametric von mises-fisher mixture models. <em>ESWA</em>, <em>298</em>, 129739. (<a href='https://doi.org/10.1016/j.eswa.2025.129739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a clustering-based framework for the analysis of functional magnetic resonance imaging (fMRI) data, with a particular focus on brain segmentation into functional sub-regions. The proposed approach comprises two key modules: representation learning and brain functional segmentation. To extract meaningful latent representations from high-dimensional fMRI signals while preserving temporal dependencies, we introduce the Spherical Variational Recurrent Autoencoder (SVRAE), a deep generative model built upon the Variational Autoencoder (VAE) architecture. Unlike conventional VAEs that assume a Gaussian prior, SVRAE employs the von Mises-Fisher (vMF) distribution to model latent variables on a unit hypersphere, which is more suitable for L 2 -normalized data. To further enhance temporal modeling, we replace standard fully connected layers with Long Short-Term Memory (LSTM) networks. For the segmentation module, we adopt a Collapsed Nonparametric von Mises-Fisher Mixture Model (Co-vMFMM), formulated within a Bayesian nonparametric framework. This model automatically adapts its complexity to the input data without requiring a predefined number of clusters. An efficient variational Bayes learning algorithm is developed to perform inference in a collapsed parameter space. Extensive experiments on publicly available fMRI datasets demonstrate the effectiveness and robustness of the proposed method in delineating functionally coherent brain sub-regions.},
  archive      = {J_ESWA},
  author       = {Wentao Fan and Wenchuan Zhang and Xiao Dong and Nizar Bouguila},
  doi          = {10.1016/j.eswa.2025.129739},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129739},
  shortjournal = {Expert Syst. Appl.},
  title        = {Clustering-based brain functional segmentation via deep collapsed nonparametric von mises-fisher mixture models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An optimized hierarchical path planning method based on deep reinforcement learning for mobile robots. <em>ESWA</em>, <em>298</em>, 129736. (<a href='https://doi.org/10.1016/j.eswa.2025.129736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of elderly mobile robot technology, the training efficiency and path planning of robots have become key issues in research. Current mobile robot training faces challenges such as local optima and slow convergence speeds. To address these issues, this paper proposes a hierarchical path planning method based on deep reinforcement learning (H-DDQN). This method first introduces a global path planning module, which uses a density function to select high-value key points. In areas with dense obstacles, these key points provide the robot with effective global path guidance, enabling it to avoid getting stuck in a local optimum due to reliance solely on local information. In the local path planning module, we introduce a spatial attention mechanism based on global information, which weights global path points to enable the robot to focus on critical areas, thereby enhancing local decision-making capabilities and addressing dynamic obstacles on the basis of global optimality. Finally, this paper designs a new comprehensive reward function that combines path guidance from global key points with goal-oriented dense rewards, avoiding excessive unnecessary exploration and providing timely feedback to accelerate the model’s convergence speed. Experimental results show that compared to other existing algorithms, the H-DDQN algorithm converges more quickly during training and generates shorter and more efficient paths. In dynamic obstacle environments, the algorithm also demonstrates strong adaptability, combining global and local capabilities to achieve superior performance.},
  archive      = {J_ESWA},
  author       = {Jilin Zhang and Jia Qiao and Ke Huang and Menghua Zhang},
  doi          = {10.1016/j.eswa.2025.129736},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129736},
  shortjournal = {Expert Syst. Appl.},
  title        = {An optimized hierarchical path planning method based on deep reinforcement learning for mobile robots},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Assessing the renewable energy sources for sustainable energy generation systems: Interval-valued q-rung orthopair fuzzy SWARA-TOPSIS. <em>ESWA</em>, <em>298</em>, 129735. (<a href='https://doi.org/10.1016/j.eswa.2025.129735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renewable Energy Sources (RESs) help decarbonize power systems, but selecting among them is a challenging decision problem due to multiple, often conflicting, technical, economic, environmental, and health-related criteria. Consequently, numerous studies in the literature have attempted to address this decision-making issue using objective, subjective, and fuzzy decision-making procedures. However, there are still unaddressed research gaps in the literature, particularly regarding the explicit modeling of expert hesitation and ambiguity in real-world RES selection cases. The current study develops a decision-making model based on Step-wise Weight Assessment Ratio Analysis (SWARA) and Technique of Order Preference Similarity to the Ideal Solution (TOPSIS) methods integrated with Interval-Valued q-Rung Orthopair Fuzzy Sets (IV-q-ROFSs) to fill these gaps. Unlike previous studies that have predominantly applied conventional fuzzy MCDM techniques, our model introduces the first integration of IV-q-ROFS into RES selection. This novelty enables a more accurate representation of expert hesitation and uncertainty. The study is applied to a real industrial case in Turkey, where six RES alternatives are evaluated across 43 criteria by five senior experts under the supervision of a three-member professionals’ board. Furthermore, the structured robustness check and systematic literature mapping ensure that the proposed approach is methodologically robust and practically relevant for policymakers and energy planners. The application results of the developed model demonstrate that the estimated energy production potential of the RES and the effects of carcinogens generated from utilizing these energy sources are the critical factors influencing the selection of the most appropriate RESs. Solar energy ranked first among the alternatives. The applicability and validity of the developed model are examined by a comprehensive robustness check consisting of tests of sensitivity, comparison, and resilience to the rank reversal problem. Overall, the study provides (i) a novel methodological framework integrating IV-q-ROFS with SWARA and TOPSIS, (ii) empirical evidence from a comprehensive real-world RES selection case, and (iii) policy-relevant insights into the drivers of renewable energy adoption.},
  archive      = {J_ESWA},
  author       = {Ömer Faruk Görçün and Ahmet Aytekin and Selçuk Korucuk and Erfan Babaee Tirkolaee},
  doi          = {10.1016/j.eswa.2025.129735},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129735},
  shortjournal = {Expert Syst. Appl.},
  title        = {Assessing the renewable energy sources for sustainable energy generation systems: Interval-valued q-rung orthopair fuzzy SWARA-TOPSIS},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing liver cancer detection: An innovative deep learning approach combining GAN, ResNet, and vision transformer. <em>ESWA</em>, <em>298</em>, 129734. (<a href='https://doi.org/10.1016/j.eswa.2025.129734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver cancer is a complex and life-threatening disease with significant diagnostic and therapeutic challenges. Automated liver cancer detection assists radiologists in identifying tumors and their severity accurately. In recent years, several deep-learning techniques have been implemented for diagnosing liver tumors and classification. Despite advancements in deep learning for medical imaging, existing liver cancer detection approaches continue to face several critical limitations. These include suboptimal diagnostic accuracy due to inadequate feature extraction, excessive computational demands that hinder real-time deployment, significant class imbalance within medical datasets leading to biased predictions, and overfitting caused by limited annotated training data. To address these challenges, this study introduces a novel and automated deep learning framework called CustomLiverNet, specifically designed for accurate and efficient liver cancer diagnosis using Computed Tomography images. The Generative Adversarial Network is introduced for generating realistic synthetic images, effectively improving the performance of the proposed technique and reducing class imbalance problems. The proposed technique integrates the strengths of Residual Networks and Vision Transformer to extract significant information from the input images and further enhance the performance of the proposed framework. The Residual Networks capture both low-level and high-level semantic features, whereas the Vision Transformer derives global and contextual feature representations from the input images. The model designs a customized fusion layer for combining the extracted features from both Residual Networks and Vision Transformer models. The classification layer predicts whether the liver tumor is benign or malignant. Further, Gradient-Weighted Class Activation Mapping is applied to highlight the critical regions of the image to enhance model transparency. The CustomLiverNet framework was trained and validated on two publicly available liver cancer datasets, including the liver tumor segmentation dataset, which contains 131 contrast-enhanced abdominal Computed Tomography scans, and the 3D image reconstruction for comparison of algorithm database, which includes 20 computed tomography scans. Experimental evaluation using standard metrics shows that CustomLiverNet achieved an accuracy of 98.79 %, precision of 98.64 %, recall of 98.58 %, and specificity of 98.35 %. These results demonstrate that the proposed model holds strong potential for enhancing early and accurate liver cancer diagnosis compared to previous studies.},
  archive      = {J_ESWA},
  author       = {Shivani Joshi and Avinash Dwivedi and Rajiv Kumar and Ashish Kumar and Raju Kumar and Amrita},
  doi          = {10.1016/j.eswa.2025.129734},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129734},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing liver cancer detection: An innovative deep learning approach combining GAN, ResNet, and vision transformer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unleashing the power of large language models for low-resource relation triplet extraction by structure-to-text data generation. <em>ESWA</em>, <em>298</em>, 129733. (<a href='https://doi.org/10.1016/j.eswa.2025.129733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scaling language models have revolutionized widespread NLP tasks, yet little investigation has been conducted to assess the ability of Large Language Models (LLMs) to explore low-resource relation triplet extraction. This paper investigates essential methodologies, k -shot demonstration of in-context learning, and many-shot instruction tuning for few-shot and zero-shot relation triplet extraction using FlanT5, supported by exhaustive experiments. To enhance low-resource setting performance, we further propose different types of demonstration examples and task-related instructions for data generation. Specifically, we leverage LLMs to construct a structured prompt template for generating synthetic training data based on structured text and efficiently explore the boundary issues of examples in both instruction tuning and in-context learning, assessing their impact on model performance. To address the challenge of extracting multiple relation triplets from a single sentence, we design a novel Multiple Triplet Search (MTS) algorithm. Furthermore, we find that in-context learning can match the performance of previous prompt learning methods. Additionally, integrating synthetic data with the LLM can improve existing solutions in low-resource scenarios, achieving new state-of-the-art results. Experiments conducted on six relation extraction datasets demonstrate the efficacy of the proposed model for the zero-shot and few-shot RTE tasks. Our source code is publicly available at https://github.com/Phevos75/LLMRTE.},
  archive      = {J_ESWA},
  author       = {Qian Guo and Yi Guo and Jin Zhao},
  doi          = {10.1016/j.eswa.2025.129733},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129733},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unleashing the power of large language models for low-resource relation triplet extraction by structure-to-text data generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LDATA-net: Dynamic feature adaptation for efficient feature learning in resource-limited UAV detection. <em>ESWA</em>, <em>298</em>, 129725. (<a href='https://doi.org/10.1016/j.eswa.2025.129725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) image analysis faces the dual challenges of complex background interference and limited onboard computational resources, particularly when processing extreme scale variations across multiple viewpoints. Existing approaches typically enhance detection accuracy by increasing model complexity, but this often leads to parameter proliferation that exceeds the deployment limits of airborne platforms. To address this fundamental contradiction, we propose LDATA-Net (Lightweight Dynamic Aggregation Task-Aligned Network), which pioneers a “Dynamic Feature Adaptation” design paradigm aimed at achieving synergistic optimization between parameter efficiency and detection accuracy. This framework systematically realizes end-to-end dynamic adaptive capabilities through three core components that operate collaboratively across feature extraction, fusion, and detection stages: (1) Dynamic Multi-Branch Depthwise Block (DMBD-Block), whose core innovation is our proposed novel operator DIDWConv, which adaptively adjusts receptive fields according to input features to capture targets of extreme scales and orientations; (2) Lightweight Dynamic Aggregation Network (LDANet), which effectively preserves critical spatial contextual information through hierarchical fusion architecture and dynamic weighting mechanisms; (3) Dynamic Adaptive Head (DA-Head), which effectively mitigates task conflicts through geometric and semantic dynamic feature alignment. LDATA-Net achieves 35.4 %, 77.9 %, and 51.2 % AP 50 on VisDrone2019, DOTA1.0, and AI-TODv2 datasets respectively with only 2.8M parameters, establishing a new paradigm for designing memory-efficient yet high-performance detection systems, particularly for resource-constrained heterogeneous computing aviation platforms.},
  archive      = {J_ESWA},
  author       = {Shuming Lin and Sang Feng and Junnan Tan},
  doi          = {10.1016/j.eswa.2025.129725},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129725},
  shortjournal = {Expert Syst. Appl.},
  title        = {LDATA-net: Dynamic feature adaptation for efficient feature learning in resource-limited UAV detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploring intra- and inter-organizational collaboration opportunities across a technological knowledge ecosystem: A metapath2vec approach. <em>ESWA</em>, <em>298</em>, 129724. (<a href='https://doi.org/10.1016/j.eswa.2025.129724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing complexity and scale of technological knowledge ecosystems, organizations face challenges in identifying intra- and inter-organizational collaboration opportunities. In this respect, prior studies have proposed patent-based approaches, but they are subject to several limitations: (1) insufficient consideration of technological relationships within the ecosystem, (2) simplified unit of analysis, and (3) limited organization-centric assessments. This study proposes a network embedding and text-reranking approach to explore potential intra- and inter-organizational collaboration opportunities. First, the technological knowledge ecosystem is represented as a heterogeneous patent network comprising patents, inventors, assignees, and technology classification codes. Second, inventor nodes are embedded using metapath2vec, which performs random walks along predefined metapaths to capture diverse knowledge flows within the ecosystem. Third, potential collaborators are explored through (1) screening candidates based on technological reachability, which measures the possibility of knowledge exploration based on contextual similarity within the network, and (2) reranking candidates based on technological relevance, which quantifies the possibility of knowledge exploitation based on the similarity of technological know-how and experiences. Finally, ten quantitative patent indicators are developed to assess the implications of these opportunities at both the inventor and organization levels. The validity of the proposed approach is demonstrated through a case study involving 28,888 US patents and 9,196 inventors in the field of energy storage technology. This study contributes to advancing the theoretical understanding of technological knowledge ecosystems while also serving as a supplementary tool to explore organizational collaboration opportunities.},
  archive      = {J_ESWA},
  author       = {Jaemin Chung and Jaewoong Choi and Janghyeok Yoon},
  doi          = {10.1016/j.eswa.2025.129724},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129724},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploring intra- and inter-organizational collaboration opportunities across a technological knowledge ecosystem: A metapath2vec approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved actor-critic architecture with PPO for the traveling salesman problem. <em>ESWA</em>, <em>298</em>, 129723. (<a href='https://doi.org/10.1016/j.eswa.2025.129723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traveling salesman problem (TSP) is a classic NP-hard problem in combinatorial optimization with extensive practical applications. In this paper, we present an improved Actor-Critic architecture incorporating Proximal Policy Optimization (PPO) to effectively solve TSP. We introduce adaptive temperature scheduling, comprehensive state representation, and layer normalization to enhance learning stability. Experimental results demonstrate our Improved Actor-Critic approach achieves significant improvements ranging from 8.7 % to 55.9 % for different problem sizes compared to established reinforcement learning baselines including Q-Learning, SARSA, Double Q-Learning, Actor-Critic with Experience Replay (ACER), and Trust Region Policy Optimization (TRPO), with particularly strong performance on smaller instances between 20 to 100 cities. When testing on standard TSPLIB benchmarks, our method shows consistent advantages of 12 % to 33 % compared to classical approaches While tabular methods become computationally infeasible beyond 250 cities due to memory constraints, our approach maintains high solution quality for problems up to 1432 cities on our experimental setup (Intel® Core™i9-10900X CPU @ 3.70GHz × 20 with four NVIDIA Quadro RTX 5000 GPUs). Our ablation studies confirm the importance of each component in our proposed architecture, in which the improved state representation provides the most significant contribution to our model performance. This research significantly advances reinforcement learning approaches to combinatorial optimization, with practical implications for logistics, telecommunications, and manufacturing. The developed source code is available at: https://github.com/LetuQingge/TSP_Environment .},
  archive      = {J_ESWA},
  author       = {Hailemicael Lulseged Yimer and Pei Yang and Letu Qingge},
  doi          = {10.1016/j.eswa.2025.129723},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129723},
  shortjournal = {Expert Syst. Appl.},
  title        = {An improved actor-critic architecture with PPO for the traveling salesman problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Synchronization of semi-markov jump two-time-scale fuzzy neural networks dealing with dual-scale hybrid attacks and its application. <em>ESWA</em>, <em>298</em>, 129718. (<a href='https://doi.org/10.1016/j.eswa.2025.129718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the synchronization issue of the semi-Markov jump two-time-scale fuzzy neural networks dealing with dual-scale hybrid attacks is addressed, in which the dual-scale hybrid attacks mean that hybrid attacks can be encountered in different time scales transmission channels. Based on mismatched membership functions, a new ϵ -dependent combined synchronization controller is proposed to ensure the synchronization of the master semi-Markov jump two-time-scale fuzzy neural networks and the slave ones while it is capable of resisting independent dual-scale hybrid attacks. Through the development of a Lyapunov function incorporating the singular perturbation parameter ϵ , stability conditions and a computational approach for determining the synchronization controller gain are derived for semi-Markov jump two-time-scale fuzzy neural networks. Finally, some simulations and two encryption and decryption processes are used to show the effectiveness of obtained results.},
  archive      = {J_ESWA},
  author       = {Feng Li and Ya-Nan Wang and Lei Su and Sangmoon Lee},
  doi          = {10.1016/j.eswa.2025.129718},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129718},
  shortjournal = {Expert Syst. Appl.},
  title        = {Synchronization of semi-markov jump two-time-scale fuzzy neural networks dealing with dual-scale hybrid attacks and its application},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated recognition and measurement of cellular and dendritic microstructures in alloys via machine learning. <em>ESWA</em>, <em>298</em>, 129717. (<a href='https://doi.org/10.1016/j.eswa.2025.129717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dendritic or cellular morphologies of alloys and metals formed during casting processes significantly influence key properties such as mechanical strength, toughness, hardness, and electrical or thermal conductivities. The literature presents correlations between these properties and the microstructural length scale, which requires accurate characterization at the micrometer level. However, traditional evaluation methods demand extensive experimental efforts, including careful metallographic preparation, high-quality imaging, and a large number of measurements for statistical reliability - often relying on analyst proficiency. This study proposes a machine learning-based workflow tailored for the automated processing of microstructure images. The approach enables the autonomous measurement of key microstructural features while minimizing bias and inconsistencies among analysts. By integrating advanced image processing techniques with object detection algorithms based on Convolutional Neural Networks (CNNs), the method autonomously identifies microstructural morphologies and quantifies their spacing scales. Three model types-Cell, Dendrite, and Hybrid (exhibiting both dendritic and cellular features)-were trained and validated on using a dataset of 200 images. Among them, the Cell detection model achieved the highest performance, with a mean Average Precision (mAP) of 78.77 %, followed by the Hybrid (75.63 %) and Dendrite (72.87 %) models. Finally, the automated measurements models were applied to literature images and compared to reported microstructural growth correlations.},
  archive      = {J_ESWA},
  author       = {Guilherme Marim da Silva and Rafael Kakitani and Carlos Henrique da Silva Santos and Amauri Garcia and Noé Cheung},
  doi          = {10.1016/j.eswa.2025.129717},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129717},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated recognition and measurement of cellular and dendritic microstructures in alloys via machine learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Online reinforcement learning strategies driven artificial bee colony algorithm for bi-objective distributed reentrant flowshops scheduling problem with sequence-sependent setup time. <em>ESWA</em>, <em>298</em>, 129716. (<a href='https://doi.org/10.1016/j.eswa.2025.129716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of manufacturing systems, reentrancy has become prevalent in many production environments. This study investigates a bi-objective distributed reentrant flow shop scheduling problem with sequence-dependent setup times (DRFSP-SDST). The objectives are to minimize the total energy consumption (TEC) and the maximum completion time (makespan), simultaneously. First, a bi-objective mathematical model for the DRFSP-SDST is formulated based on practical reentrant production scenarios. Second, the artificial bee colony (ABC) algorithm and its variants are employed to solve the DRFSP-SDST. According to the characteristics of the DRFSP-SDST, six local search operators are specifically designed to enhance the performance of the proposed algorithms. For promoting greener and more energy-efficient production, two speed-scaling strategies are developed. Third, two reinforcement learning (RL) algorithms, Q-learning and State-Action-Reward-State-Action (SARSA), are integrated into the iterative process as online learning strategies to guide the selection of high-quality local search strategies during the iterations of the proposed algorithms. For each RL algorithm, two distinct selection strategies for local search operators are designed. Finally, the effectiveness of the proposed enhancement strategies is evaluated through comprehensive numerical experiments on 36 benchmark instances. The performance of the proposed algorithms is further validated via the Friedman test. The experimental results and analysis demonstrate that the ABC algorithm enhanced by SARSA-based local search exhibits superior competitiveness in solving the DRFSP-SDST.},
  archive      = {J_ESWA},
  author       = {Ao Yao and Kaizhou Gao and Ponnuthurai Nagaratnam Suganthan and Hongyan Sang},
  doi          = {10.1016/j.eswa.2025.129716},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129716},
  shortjournal = {Expert Syst. Appl.},
  title        = {Online reinforcement learning strategies driven artificial bee colony algorithm for bi-objective distributed reentrant flowshops scheduling problem with sequence-sependent setup time},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Defects inspection system for building facades using drones and deep learning method. <em>ESWA</em>, <em>298</em>, 129715. (<a href='https://doi.org/10.1016/j.eswa.2025.129715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular inspection and maintenance of building facades are essential for preserving structural integrity and aesthetic quality, especially in aging urban high-rises. While drone-based visual inspection powered by artificial intelligence (AI) offers benefits in speed, safety, and scalability, existing methods are typically limited to single defect types or uniform facade categories due to the challenges of detecting multi-scale defects in complex, heterogeneous environments. This study introduces an automated multiclass defects inspection system for building facades by integrating drone technology, an AI-driven segmentation platform, and automatic report generation. Central to the system is a segmentation AI model capable of detecting multiclass defects with orders-of-magnitude differences in scale across diverse facade backgrounds. To handle the pixel imbalance of defects ranging from fine cracks to large spalling and glass breakage, the model is built upon EfficientUNet++, trained on a carefully curated dataset and optimized using adjustable batch sizes and active learning rates to improve multi-scale feature learning and mitigate overfitting. Evaluations on validation and out-of-sample datasets demonstrate that the proposed model achieves superior performance across all defect classes. Real-world drone experiments further confirm the model’s practical applicability, with high recall rates in detecting spalling, water seepage, cracks, and glass breakage across different types of facades. This work pioneers a robust, scalable, and efficient AI-based framework for automated multiclass facade defect inspection, providing actionable information for engineers and supporting urban infrastructure maintenance.},
  archive      = {J_ESWA},
  author       = {Xiaoling Zhou and Robert Lee Kong Tiong},
  doi          = {10.1016/j.eswa.2025.129715},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129715},
  shortjournal = {Expert Syst. Appl.},
  title        = {Defects inspection system for building facades using drones and deep learning method},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-modal multitask learning for automated quantitative characterization of infrastructure airhole defects. <em>ESWA</em>, <em>298</em>, 129713. (<a href='https://doi.org/10.1016/j.eswa.2025.129713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative characterization of apparent quality defects in infrastructure is a crucial component of operations and maintenance. It enables rapid assessment of defect severity and supports the timely formulation of preventive strategies. However, a singular visual modality struggles to simultaneously ensure the dual tasks of defect detection and measurement accuracy. To solve these problems, this paper proposes a novel framework for cross-modal multitask learning networks, which comprehensively integrates the advantages of image detection and point cloud measurement. The pixel points identified in the image are mapped to their corresponding three-dimensional coordinates in the point cloud through intensive feature matching. A measurement strategy for the inherent characteristics of the defect is subsequently proposed. Based on prior knowledge of the defect, the area and volume of defects are quantified accurately. Finally, extensive experiments on detection, matching and measurement demonstrate the efficacy of the proposed method. The results provide a valuable reference for the quantitative characterization of infrastructure defects.},
  archive      = {J_ESWA},
  author       = {Yu Wang and Yingchao Dai and Xiaodong Gan and Zhengtao Yang and Zhou Wu},
  doi          = {10.1016/j.eswa.2025.129713},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129713},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-modal multitask learning for automated quantitative characterization of infrastructure airhole defects},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Language proficiency assessment of autistic children using large language models. <em>ESWA</em>, <em>298</em>, 129712. (<a href='https://doi.org/10.1016/j.eswa.2025.129712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language impairment is a common comorbidity in children with autism spectrum disorder (ASD), and language proficiency assessment is a primary method for identifying such impairments. However, traditional assessment tools are often subjective and inefficient, while existing computer-assisted methods are limited by a narrow focus and insufficient use of natural language samples. To address these issues, this study proposes a framework for assessing children’s language abilities based on large language models (LLMs). We first preprocess the natural language samples from children and design multiple assessment dimensions and workflows. To enhance the stability of the assessment, we introduce a multi-expert voting mechanism and perform a comparative analysis of various large language models’ performance. The experimental results demonstrate a strong correlation between the framework’s assessment results and the Mullen Scales of Early Learning (MSEL) verbal developmental quotients, with a Pearson correlation coefficient of 0.8 ( p < 0.001). Furthermore, the results show that the multi-dimensional evaluation can accurately differentiate between ASD and typically developing (TD) children, achieving a classification accuracy of 0.98. These findings suggest that the proposed framework has significant potential for improving the accuracy of ASD identification.},
  archive      = {J_ESWA},
  author       = {Saige Qin and Min Liu and Tongquan Wei and Qiaoyun Liu},
  doi          = {10.1016/j.eswa.2025.129712},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129712},
  shortjournal = {Expert Syst. Appl.},
  title        = {Language proficiency assessment of autistic children using large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EQUINAS: Equilibrium-guided differentiable neural architecture search. <em>ESWA</em>, <em>298</em>, 129711. (<a href='https://doi.org/10.1016/j.eswa.2025.129711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has significantly mitigated the performance collapse issue in Differentiable Architecture Search (DARTS) by either refining architecture parameters to better reflect the true strengths of operations or developing alternative metrics for evaluating operation significance. However, the actual role and impact of architecture parameters remain insufficiently explored, creating critical ambiguities in the search process. To address this gap, we conduct a rigorous theoretical analysis demonstrating that the change rate of architecture parameters reflects the sensitivity of the supernet’s validation loss in architecture space, thereby influencing the derived architecture’s performance by shaping supernet training dynamics. Building on these insights, we introduce the concept of a Stable Equilibrium State to capture the stability of the bi-level optimization process and propose the Equilibrium Influential ( E I ) metric to assess operation importance. By integrating these elements, we propose EQUINAS, a differentiable NAS approach that leverages the Stable Equilibrium State to identify the optimal state during the search process and derives the final architecture using the E I metric. Extensive experiments across diverse datasets and search spaces demonstrate that EQUINAS achieves competitive test accuracy compared to state-of-the-art methods while significantly reducing search costs. Additionally, EQUINAS shows remarkable performance in Transformer-based architectures and excels in real-world applications such as image classification and text recognition.},
  archive      = {J_ESWA},
  author       = {Weisheng Xie and Xiangxiang Gao and Xuwei Fang and Hui Li and Chen Hang and Shaoyuan Li},
  doi          = {10.1016/j.eswa.2025.129711},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129711},
  shortjournal = {Expert Syst. Appl.},
  title        = {EQUINAS: Equilibrium-guided differentiable neural architecture search},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Freq-DETR: Frequency-aware transformer for real-time small object detection in unmanned aerial vehicle imagery. <em>ESWA</em>, <em>298</em>, 129710. (<a href='https://doi.org/10.1016/j.eswa.2025.129710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in unmanned aerial vehicle (UAV) and remote sensing technologies have propelled UAV object detection to the forefront of computer vision research. Despite significant progress in deep learning-based detection algorithms, critical challenges persist in small object detection, including high-frequency information loss, inadequate multiscale feature representation, etc. To address these limitations, this paper proposes Freq-DETR, a frequency-aware real-time transformer detection framework leveraging frequency domain analysis to enhance edge detail preservation and global contextual modeling through three novel innovations. First, the frequency-enhanced convolution module (FECM) synergistically integrates spatial and frequency features via dual-branch processing; Second, the decoupled intra-feature scale interaction module (DSC-Clo block) facilitates the integration of high-frequency local and low-frequency global information; Finally, the attention-guided selective feature pyramid network (AGS-FPN) employs context-aware attention for high-level screening feature fusion. Extensive evaluations on the VisDrone2019 benchmark demonstrate that Freq-DETR outperforms the baseline RT-DETR by 4.9 % m a p @ 50 gain while maintaining computational efficiency. There are also remarkable improvements on both UAVDT and HIT-UAV datasets. Ablation investigations and visual interpretability analyses further confirm the complementary benefits of its frequency-domain components and the framework’s robustness in complex aerial scenarios.},
  archive      = {J_ESWA},
  author       = {Jiayi Chen and Ningzhong Liu and Han Sun and Yu Wang},
  doi          = {10.1016/j.eswa.2025.129710},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129710},
  shortjournal = {Expert Syst. Appl.},
  title        = {Freq-DETR: Frequency-aware transformer for real-time small object detection in unmanned aerial vehicle imagery},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Companion learning networks: A deep reinforcement learning algorithm with partner networks. <em>ESWA</em>, <em>298</em>, 129709. (<a href='https://doi.org/10.1016/j.eswa.2025.129709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep reinforcement learning (DRL) agents suffer from severe reward instability during late-stage exploration, particularly when encountering novel states in complex continuous environments. A variety of existing studies focus on improving an agent’s reward exploration. However, they ignore the instability problem that arises when the agent faces new states in the later stages of exploration. This paper proposes a novel companion learning network (CLN) based on the idea that the guidance can accelerate human learning efficiency and reduce the risk of making mistakes. The CLN integrates a short-term partner network to intensively learn localized environmental patterns, offering adaptive action guidance for recent states. Simultaneously, a global Q-network dynamically incorporates the partner’s decaying guidance signals, balancing autonomous exploration with error mitigation. As training progresses, the partner’s influence gradually diminishes, allowing the Q-network to solidify robust policies without persistent dependence. Extensive experiments on four OpenAI Gym environments demonstrate that the CLN can significantly improve the exploration stability in most tested scenarios, achieving up to 49% reduction in late-stage reward standard deviation compared to baseline DRL methods.},
  archive      = {J_ESWA},
  author       = {Jin Xu and Jinfeng Bu and Yu Zhang and Jia-Dong Zhang and Chi-Yin Chow},
  doi          = {10.1016/j.eswa.2025.129709},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129709},
  shortjournal = {Expert Syst. Appl.},
  title        = {Companion learning networks: A deep reinforcement learning algorithm with partner networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Expensive multiobjective immune algorithm using a novel differential evolution in objective space. <em>ESWA</em>, <em>298</em>, 129708. (<a href='https://doi.org/10.1016/j.eswa.2025.129708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating offspring solutions with strong convergence and diversity is critical when solving expensive multiobjective optimization problems due to the limited number of objective function evaluations. However, existing algorithms produce offspring solutions in the decision space, causing significant uncertainty in obtaining offspring with strong convergence and diversity. To address this issue, we devise a novel differential evolution based on the objective space rather than the decision space, called Differential Objective Evolution (DOE). Specifically, DOE generates objective values with strong convergence and diversity and then maps these values to the decision space to achieve high-quality offspring. Furthermore, we utilize a multiobjective immune algorithm to produce high-quality samples for effectively training the mapping in DOE. When compared with eleven recently proposed algorithms on 105 expensive multiobjective optimization problems, the experiments demonstrate the superiority of our algorithm and the contributions of DOE in both population convergence and diversity.},
  archive      = {J_ESWA},
  author       = {Yuchao Su and Wu Lin and Daxin Zhu and Anhui Tan and Ka-Chun Wong and Qiuzhen Lin},
  doi          = {10.1016/j.eswa.2025.129708},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129708},
  shortjournal = {Expert Syst. Appl.},
  title        = {Expensive multiobjective immune algorithm using a novel differential evolution in objective space},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Talk with graph: A fuzzy sentiment-aware framework for explainable recommendation. <em>ESWA</em>, <em>298</em>, 129707. (<a href='https://doi.org/10.1016/j.eswa.2025.129707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User reviews reflect user preferences and item characteristics, optimizing the predictive accuracy and explanation generation of personalized recommendation systems. However, existing models face challenges due to subjective uncertainty in user feedback and a lack of transparency. Reviews often contain ambiguous emotional expressions, with the same product receiving positive, neutral, and negative sentiments. Many recommendation models assume alignment between ratings and review sentiments, but in practice, users may give high ratings while expressing dissatisfaction or vice versa. These inconsistencies complicate accurate modeling of user preferences. To address these issues, a Large Language Model (LLM)-driven sentiment-enhanced heterogeneous graph neural network framework is proposed. This framework jointly models interaction data and fuzzy sentiment information from reviews to improve both recommendation accuracy and explainability. By leveraging LLM with dual-prompt strategies, high-quality sentiment distributions and semantic insights are extracted. Review sentiments are then quantified using intuitionistic fuzzy numbers to address data sparsity and uncertainty, capturing implicit relationships between users, items, and entities in a sentiment-enhanced heterogeneous relational graph. A fuzzy sentiment-weighted graph convolutional network (FSGCN) is introduced for dynamic higher-order feature learning, adjusting sentiment weights based on user-item interactions and emotional context. The framework also integrates LLM-driven query interpretation to generate recommendations with transparent, context-aware rationales. This approach enables users to understand the reasoning behind recommendations, significantly enhancing explainability and trust.},
  archive      = {J_ESWA},
  author       = {Zhinan Li and Zhenyu Liu and Guodong Sa and Mingjie Hou and Jiacheng Sun and Jianrong Tan},
  doi          = {10.1016/j.eswa.2025.129707},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129707},
  shortjournal = {Expert Syst. Appl.},
  title        = {Talk with graph: A fuzzy sentiment-aware framework for explainable recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Geodesic-based path planning for port transfer robots on riemannian manifolds. <em>ESWA</em>, <em>298</em>, 129706. (<a href='https://doi.org/10.1016/j.eswa.2025.129706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid intelligent transformation of the automotive industry and the surge in production volume, intelligent autonomous robots equipped with integrated perception and planning systems are playing an increasingly vital role in vehicle transfer operations. Optimizing dispatch paths of robots is essential for improving overall operational efficiency, yet achieving a balance among path length, feasibility, and safety margin remains a significant challenge. To address this issue, we propose a geodesic-based path planning method formulated on Riemannian manifolds. The approach jointly considers directional motion constraints, steering effort, and obstacle accessibility boundaries to construct a Riemannian metric tensor that encodes local path cost structures. This transforms the planning task into a geodesic shortest path problem, which is efficiently solved using the Geometric heat flow (GHF) method. The resulting paths naturally comply with kinematic constraints and exhibit strong obstacle-avoidance capabilities, significantly enhancing safety and executability. Extensive simulations and real-world experiments in high-density port yard environments demonstrate the practicality and robustness of the proposed method under complex spatial constraints and obstacle configurations.},
  archive      = {J_ESWA},
  author       = {Runjiao Bao and Junzheng Wang and Shoukun Wang},
  doi          = {10.1016/j.eswa.2025.129706},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129706},
  shortjournal = {Expert Syst. Appl.},
  title        = {Geodesic-based path planning for port transfer robots on riemannian manifolds},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A social balance theory-based modeling framework for group-to-empirical decision-making transition with cognitive inertia and trust propagation. <em>ESWA</em>, <em>298</em>, 129705. (<a href='https://doi.org/10.1016/j.eswa.2025.129705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by empirical decision-making (EDM) processes, we propose a novel modeling framework where agents iteratively integrate social neighbors’ opinions into their cognitive inertia sequences (CISs), gradually prioritizing their accumulated CISs over time. This framework simulates the transition from group decision-making (GDM) to EDM through dynamic trust/distrust propagation and aggregation mechanisms grounded in social balance theory–capturing relational scenarios such as “a friend of a friend is a friend”, “a friend of an enemy is an enemy”, “an enemy of a friend is an enemy”, and “an enemy of an enemy is a stranger”. The paradigm incorporates two core mechanisms: (1) an endogenous cognitive inertia mechanism that uses the psychological serial-positioning effect to model cognitive inertia weights, accounting for primacy, recency, and U-shaped memory effects; and (2) an exogenous mechanism that quantifies comprehensive trust/distrust degrees via opinion similarity, stability similarity, and network structure similarity. To prevent followers from falling into cognitive freezing, a cluster leader-based consensus-reaching strategy is introduced. Extensive comparative experiments on real-world network datasets confirm the model’s effectiveness and robustness.},
  archive      = {J_ESWA},
  author       = {Jianglin Dong and Yiyi Zhao and Shangqun Mu and Haixia Mao and Jiangping Hu},
  doi          = {10.1016/j.eswa.2025.129705},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129705},
  shortjournal = {Expert Syst. Appl.},
  title        = {A social balance theory-based modeling framework for group-to-empirical decision-making transition with cognitive inertia and trust propagation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OTPS-VO: Enhanced RGB-D odometry for indoor service robots leveraging structural features. <em>ESWA</em>, <em>298</em>, 129704. (<a href='https://doi.org/10.1016/j.eswa.2025.129704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) is essential for indoor service robots to achieve reliable navigation and mapping. While point and line features have been extensively utilized to enhance the accuracy of visual odometry (VO), current methods often overlook the rich geometric information embedded in the spatial relationships among structural lines. In particular, the parallelism and collinearity within groups of line segments are underexploited, and geometric constraints are typically applied only heuristically or post hoc, limiting robustness in low-texture and repetitive environments. To address these challenges, a robust VO system is proposed that integrates structural feature grouping with adaptive MW tracking. A unified feature extraction strategy is introduced to detect point and line features simultaneously, improving computational efficiency. To mitigate pose drift caused by unreliable line segments, a set of parallel line features is constructed based on local geometric constraints, and a novel reprojection error model is formulated to enhance pose estimation. Furthermore, a tracking strategy based on local Manhattan World (MW) structure is developed to ensure low-drift estimation across various structured indoor scenes. Extensive experiments on multiple public datasets and a custom-built service robot platform demonstrate that the proposed method outperforms existing state-of-the-art approaches under dynamic lighting conditions and in environments rich in lines and planes. The system also operates at a real-time speed of 30 frames per second, meeting the requirements of practical robotic applications.},
  archive      = {J_ESWA},
  author       = {Zhiyu Wang and Weili Ding and Ying Zhang and Changchun Hua},
  doi          = {10.1016/j.eswa.2025.129704},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129704},
  shortjournal = {Expert Syst. Appl.},
  title        = {OTPS-VO: Enhanced RGB-D odometry for indoor service robots leveraging structural features},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive gated meta graph retention network: A model for urban traffic flow prediction. <em>ESWA</em>, <em>298</em>, 129703. (<a href='https://doi.org/10.1016/j.eswa.2025.129703'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is crucial for urban transportation systems. Existing models are still deficient in training efficiency and modeling dynamic spatial-temporal dependencies, various external factors, time-varying topology. Based on this, this paper introduces the Adaptive Gated Meta Graph Retention Network (AGMGRN), a novel model for spatial-temporal traffic flow prediction. Specifically, the AGMGRN integrates the attention mechanism with the retention network to model spatial-temporal dependencies. The AGMGRN proposes a gated dynamic connection block to enhance the model’s dynamic modeling capabilities. The AGMGRN considers the influence of external factors on traffic conditions through meta-learning approaches. The AGMGRN proposes an adaptive graph block to construct time-varying topologies. Experiments on four actual large-scale datasets demonstrate that the AGMGRN achieves superior prediction accuracy and high applicability.},
  archive      = {J_ESWA},
  author       = {Xing Li and Yuequan Bao},
  doi          = {10.1016/j.eswa.2025.129703},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129703},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive gated meta graph retention network: A model for urban traffic flow prediction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DASF-GRL: Dynamic agent-scaling framework with game-augmented reinforcement learning for defensive counter-air operations. <em>ESWA</em>, <em>298</em>, 129702. (<a href='https://doi.org/10.1016/j.eswa.2025.129702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defensive Counter-Air (DCA) operations are pivotal for modern air defense, but existing studies are limited by static defender populations and oversimplified attacker models. We address these limitations with the Dynamic Agent-Scaling Framework with Game-Augmented Reinforcement Learning (DASF-GRL), which dynamically scales defender populations based on real-time threat levels. Specifically, we introduce a hybrid imitation-reinforcement training strategy that integrates attention mechanisms into critic networks to enable dynamic agent scaling. By incorporating a safety barrier function rooted in differential game theory, we constrain agents’ action spaces and enhance policy reliability. Furthermore, we developed a DCA simulation platform supporting reinforcement learning validation and designed a novel Apollonius-based penetration strategy for attackers to improve algorithmic robustness. Experiments demonstrate that DASF-GRL adaptively adjusts defender populations across scenarios involving 20, 40, and 60 attackers, markedly outperforming baseline methods in convergence speed and defense success rates. This framework offers novel theoretical paradigms and practical tools for intelligent decision-making in DCA environments.},
  archive      = {J_ESWA},
  author       = {Yuxuan Chen and He Luo and Guoqiang Wang},
  doi          = {10.1016/j.eswa.2025.129702},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129702},
  shortjournal = {Expert Syst. Appl.},
  title        = {DASF-GRL: Dynamic agent-scaling framework with game-augmented reinforcement learning for defensive counter-air operations},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Coordinated low-carbon economic scheduling of integrated electricity-heat-gas-hydrogen-methanol multi-microgrids considering electricity-methanol transaction. <em>ESWA</em>, <em>298</em>, 129701. (<a href='https://doi.org/10.1016/j.eswa.2025.129701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uneven spatial and temporal distribution of renewable energy resources poses significant challenges for multi-microgrid (MG) systems, resulting in high operational costs and low renewable energy utilization. To overcome these challenges, this work investigates a peer-to-peer electricity transaction and hydrogen-methanol-hydrogen technology-based methanol transaction among multi-MG. Besides, to realize net-zero emissions and carbon cycle utilization, the carbon capture system and hydrogen blending system are introduced into MG to reduce carbon dioxide emissions and capture and reform carbon dioxide for methanol synthesis equipment. Additionally, a cooperative operation model based on the Nash bargaining theory for multi-MGs under the transaction amount and price constraints of electricity and methanol is constructed. Due to the characteristics of non-convex and non-linear, the Nash bargaining is transformed into minimizing operation costs (sub-problem one) and maximizing payment benefits (sub-problem two). During the process of benefit allocation in sub-problem two, this work adopts a nonlinear energy sharing mapping method to quantify the comprehensive contribution rate of each MG to the multi-MG system, thereby achieving fair allocation of benefits. Finally, the alternating direction multiplier method is used to solve the model, effectively protecting the privacy of each MG. The simulation results demonstrate that a multi-MG system considering electricity and methanol transactions can effectively decrease carbon emissions and the total operational costs by 21.53% and 27.01% compared to only considering electricity transactions, respectively. Overall, the proposed electricity and methanol transactions strategy simultaneously reduces the overall system operation costs and carbon emissions, underscoring its advantages and significance.},
  archive      = {J_ESWA},
  author       = {Jiale Li and Bo Yang and Yiming Zhou and Hongchun Shu and Hongbiao Li and Dengke Gao and Lin Jiang},
  doi          = {10.1016/j.eswa.2025.129701},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129701},
  shortjournal = {Expert Syst. Appl.},
  title        = {Coordinated low-carbon economic scheduling of integrated electricity-heat-gas-hydrogen-methanol multi-microgrids considering electricity-methanol transaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Heterogeneous cloud resource allocation: A case study on real-time transcoding in live streaming. <em>ESWA</em>, <em>298</em>, 129700. (<a href='https://doi.org/10.1016/j.eswa.2025.129700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosion in popularity of crowdsourced live streaming (CLS) has led to a huge increase in demand for cloud resources to support real-time video transcoding. CLS transcoding is real-time, geographically distributed and computationally intensive. Therefore, transcoding service providers need to cost-effectively utilize diverse heterogeneous cloud resources, while guaranteeing quality of service standards to ensure a good streaming experience for the viewers. To support the above, we developed a novel proactive-reactive resource allocation framework that optimizes the overall cost of supporting the CLS transcoding service using heterogeneous edge and cloud computing resources. The offline proactive policy evaluator aims to provide a good and adaptable resource usage plan in advance, matching the predicted demand with the heterogeneous resources. The reactive execution module monitors the actual demand online and controls the resource usage to compensate for deviations from the offline prediction. Our experiments show that the proposed approach leads to a cost reduction of 42 % compared to the fixed usage ratio strategy based on expert knowledge.},
  archive      = {J_ESWA},
  author       = {Yinuo Li and Jin-Kao Hao and Kwong Meng Teo and Liwei Song},
  doi          = {10.1016/j.eswa.2025.129700},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129700},
  shortjournal = {Expert Syst. Appl.},
  title        = {Heterogeneous cloud resource allocation: A case study on real-time transcoding in live streaming},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive multi-step path planning for multi-robot in dynamic environments based on hybrid optimization approach. <em>ESWA</em>, <em>298</em>, 129699. (<a href='https://doi.org/10.1016/j.eswa.2025.129699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-robot path planning problem requires algorithms with high convergence speed and accuracy, as well as the completeness of the search probability for the optimal path. The integration of metaheuristic algorithms in path planning has proven to be remarkably efficient. This paper introduces a novel hybrid metaheuristic algorithm, Beluga Whale-Crayfish Optimization (BWCOA), for enhanced global optimization in path planning applications. While the Crayfish Optimization (COA) demonstrates superior convergence speed, its inherent probabilistic path completeness remains suboptimal. To address this limitation, we present three key innovations: a dynamic probability completion mechanism, adaptive convergence acceleration factors, and balanced exploration–exploitation trade-off parameters. The proposed BWCOA synergizes Beluga Whale Optimization (BWO)’s basin-hopping capability with COA’s swarm intelligence through parallel combined exploration strategies. To prove its powerfulness, a series of comparative analyses were conducted between BWCOA and other leading algorithms across two comprehensive test function suites. The numerical experiment results underscore the significant superiority of BWCOA over its counterparts. In the context of path planning simulations, BWCOA demonstrated notable improvements over COA within the same number of function evaluations, with average enhancement rates of 6.49 %, 7.42 %, 15.09 %, 76.42 %, and 0.73 % across five evaluation metrics. Similarly, when compared to BWO on the same set of indicators, BWCOA showed average improvement rates of 22.39 %, 27.71 %, 70.53 %, 260.86 %, and 41.22 %. Furthermore, the running time of BWCOA is comparable to that of similar algorithms.},
  archive      = {J_ESWA},
  author       = {Liguo Yao and Guanghui Li and Taihua Zhang and Abdelazim G. Hussien and Yao Lu},
  doi          = {10.1016/j.eswa.2025.129699},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129699},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive multi-step path planning for multi-robot in dynamic environments based on hybrid optimization approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage evolutionary algorithm based on hybrid penalty strategy and its application to multi-UAV path planning. <em>ESWA</em>, <em>298</em>, 129698. (<a href='https://doi.org/10.1016/j.eswa.2025.129698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained optimization problems with complex and dynamic constraints pose significant challenges for evolutionary algorithms, as the constraints reshape the solution space and create conflicts between feasibility maintenance and global exploration. To address this issue, this study proposes TSC-PSODE, a two-stage evolutionary algorithm based on a hybrid penalty strategy. The algorithm employs an external penalty in the early stage to preserve population diversity and enhance exploration, while an internal penalty in the later stage accelerates convergence toward high-quality feasible solutions. In addition, a cooperative strategy combining differential evolution operators strengthens robustness and helps the population escape local optima. Experimental evaluations on the CEC2017 benchmark suite (the IEEE Congress on Evolutionary Computation 2017 benchmark) and multi-Unmanned Aerial Vehicle path planning tasks demonstrate that TSC-PSODE consistently outperforms state-of-the-art algorithms. The results confirm that the proposed method not only provides an effective mechanism for constraint handling, but also achieves a favorable balance between exploration and exploitation by maintaining diversity and accelerating convergence. In practical terms, TSC-PSODE is capable of generating safe and feasible flight paths for multiple UAVs in complex environments, highlighting its adaptability and competitiveness for real-world applications.},
  archive      = {J_ESWA},
  author       = {Eryang Guo and Yuelin Gao and Chenyang Hu},
  doi          = {10.1016/j.eswa.2025.129698},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129698},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-stage evolutionary algorithm based on hybrid penalty strategy and its application to multi-UAV path planning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Critical commentary on “Reptile search algorithm (RSA): A nature-inspired meta-heuristic optimizer”. <em>ESWA</em>, <em>298</em>, 129697. (<a href='https://doi.org/10.1016/j.eswa.2025.129697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ESWA},
  author       = {Ngaiming Kwok},
  doi          = {10.1016/j.eswa.2025.129697},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129697},
  shortjournal = {Expert Syst. Appl.},
  title        = {Critical commentary on “Reptile search algorithm (RSA): A nature-inspired meta-heuristic optimizer”},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 2PADMS: Two-stage prediction and data migration strategy based on hard disk failure time. <em>ESWA</em>, <em>298</em>, 129696. (<a href='https://doi.org/10.1016/j.eswa.2025.129696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of global data volume, the usage of hard disk drives (HDDs) is also increasing rapidly. Consequently, the number of failed disks is continuously rising, which can affect storage service quality and even lead to data loss when failures occur.In recent years, the active fault-tolerant technology, which collects hard disks’ Self Monitoring Analysis and Reporting Technology (SMART) data-set, predicts hard disk failure by machine learning model, and repairs near-failure disks’ data to health disks in advance, has become a common research hotspot in both academia and industry. Aiming at the existing problems such as interference characteristics, inaccurate failure time prediction, competition of system resources between data migration and front service, this paper researches the two-stage prediction model and data migration strategy based on hard disk failure time, including the two-stage hard disk information feature selection method, the two-stage prediction method of hard disk failure time, and the data migration elastic system resource allocation strategy. Feature selection is performed by combining embedding methods with visualization, and the importance of the selected features is evaluated using a random forest model. Based on the feature importance, further refinement is carried out to obtain the final feature set. Before predicting the failure time of hard drives, XGBoost is first used in a voting manner to identify drives predicted to be faulty. Then, a trained Bidirectional Long Short-Term Memory network (Bidirectional LSTM) enhanced with a self-attention mechanism is employed to predict the exact failure time.Experimental results show that on the Backblaze dataset, the model achieves a mean absolute error of 1.24 when predicting failure times. The recall rate for predicting failures within 7 days reaches 98.79 %, the error rate is 0.30 %, the F1 score is 99.24 %, and the precision is 99.69 %. The elastic system resource allocation strategy for data migration improves business IOPS by 47.19 % and reduces latency by 38.68 %.},
  archive      = {J_ESWA},
  author       = {Huiyuan Qiang and Yuequan Li and Hongzhang Yang and Ping Wang and Yaofeng Tu and Shang Yang},
  doi          = {10.1016/j.eswa.2025.129696},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129696},
  shortjournal = {Expert Syst. Appl.},
  title        = {2PADMS: Two-stage prediction and data migration strategy based on hard disk failure time},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EEG emotion recognition through a domain-adversarial multi-feature fusion network. <em>ESWA</em>, <em>298</em>, 129694. (<a href='https://doi.org/10.1016/j.eswa.2025.129694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate recognition of EEG signals linked to emotions is crucial for neuroscience and human-computer interaction. However, variability in EEG emotion recognition among individuals results in inconsistent feature distributions and limited generalization across subjects. To enhance the robustness of the model, we propose a deep learning approach integrating a domain adversarial migration network with an attention mechanism. Initially, a feature extractor with a hierarchical architecture (low-medium-high levels) is employed to capture multi-scale EEG features, which are then normalized for age and encoded for genderand education before being aligned with EEG features through spatio-temporal replication. Subsequently, global distribution alignment is achieved using multi-kernel maximum mean difference (MK-MMD), subdomain adversarial alignment is accomplished with a gradient inversion layer (GRL), and decision boundary clarity is enhanced through joint emotion classification loss. The generalization capability and effectiveness of the model are validated using the DEAP and DREAMER datasets, offering insights for cross-subject emotion recognition research and applications.},
  archive      = {J_ESWA},
  author       = {Weitong Sun and Yuping Su and Yumei Zhang and Xiaojun Wu},
  doi          = {10.1016/j.eswa.2025.129694},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129694},
  shortjournal = {Expert Syst. Appl.},
  title        = {EEG emotion recognition through a domain-adversarial multi-feature fusion network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DFHD: Dual-granularity fusion network using historical drugs for drug recommendation. <em>ESWA</em>, <em>298</em>, 129693. (<a href='https://doi.org/10.1016/j.eswa.2025.129693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug recommendation is a task in clinical medicine aimed at suggesting a set of safe and effective medications based on a patient’s electronic health records. Current approaches either rely on diagnoses and procedures documented in electronic health records to recommend drug combinations or focus on enhancing drug recommendation safety by considering drug-drug interactions. However, these approaches often overlook the significance of historical medication information in drug recommendation despite its strong correlation with current diagnostic and prescription recommendation. Therefore, we propose a Dual-granularity Fusion Network using Historical Drugs. Specifically, at the time-series modeling level, recurrent neural networks are used to extract time-series features from historical drug data to construct coarse-grained drug characterizations. At the molecular structure modeling level, a graph neural network is used to build a relationship map between drug molecular structures and drug substructures to capture the fine-grained interactions within drug molecules. In addition, we designed a historical drug molecule awareness module to capture historical drug information during drug molecule modeling so as to identify the drugs that really help to cure patients. To effectively integrate dual-granularity information, we design a dual-granularity fusion module to realize the synergistic learning of temporal and structural features. To ensure drug safety, we introduce the DDI loss function to adaptively adjust the loss weights based on the drug interaction risk results, taking into account the optimization goals of efficacy and safety. Our source code is available at https://github.com/AK-321/DFHD .},
  archive      = {J_ESWA},
  author       = {Kang An and Ming-Yu Lu and Yan-Kai Tian and Yi-Jia Zhang},
  doi          = {10.1016/j.eswa.2025.129693},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129693},
  shortjournal = {Expert Syst. Appl.},
  title        = {DFHD: Dual-granularity fusion network using historical drugs for drug recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An acoustic-electromagnetic detection system based on joint parameter estimation of atomic norm algorithm. <em>ESWA</em>, <em>298</em>, 129692. (<a href='https://doi.org/10.1016/j.eswa.2025.129692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time delay and Doppler shift parameters in radar system echo signals serve as effective tools for multi-target identification and localization in covert environments. However, the nonlinear characteristics of stationary targets are often masked by surrounding environmental factors, and traditional joint parameter estimation algorithms tend to suffer from high computational complexity and errors during demodulation. To address these challenges, this paper proposes an acoustic-electromagnetic intermodulation detection system based on a novel atomic-paradigm algorithm, which ensures localization accuracy with minimal computational complexity and zero false alarms. Specifically, the system excites the target by introducing acoustic field energy coupling, generating discernible micromotion features. The resulting acoustically modulated signal is then modeled as a two-dimensional line spectral estimation problem, capturing the target’s time delay and Doppler shift. Furthermore, the joint parameter estimation algorithm is enhanced by relaxing dyadic constraints under sufficient conditions. In our experiments, a harmonic radar physical system is constructed to simultaneously localize and measure multiple non-clustered micromotion targets. The recognition accuracy is quantitatively evaluated using a classical neural network model, achieving 86.9 % accuracy across five classified targets. The improved algorithm’s performance in joint parameter estimation is also assessed under varying signal-to-noise ratios and demodulation error rates, with a detailed time complexity analysis provided.},
  archive      = {J_ESWA},
  author       = {Sheng Wu and Yilin Cai and Yijing Zheng and Dingzhao Li and Hongjun Lai and Haixin Sun},
  doi          = {10.1016/j.eswa.2025.129692},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129692},
  shortjournal = {Expert Syst. Appl.},
  title        = {An acoustic-electromagnetic detection system based on joint parameter estimation of atomic norm algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel convex-hull-based algorithm for classification problems with imbalanced and overlapping data. <em>ESWA</em>, <em>298</em>, 129691. (<a href='https://doi.org/10.1016/j.eswa.2025.129691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is a fundamental task in supervised machine learning. This problem becomes challenging when dealing with imbalanced and overlapping datasets. In such cases, learning algorithms often perform well in identifying the labels of majority class data points but exhibit high error rates in predicting the minority class. This paper proposes an innovative method based on the convex-hull concept to enhance classification for imbalanced and overlapping datasets. Unlike undersampling approaches that may lead to the loss of valuable information, our method focuses on preserving the data. The process begins by clustering the data points for each class separately in such a way that no points from the opposite class fall within the convex-hull of each cluster. Then, the support vector machine (SVM) is used to separate every cluster of a given class from the data points of the opposite class. Afterward, data points inside the SVM boundaries are considered as non-overlapping, while those outside the SVM boundaries are identified as overlapping data. The XGBoost algorithm is then employed to classify the data points within the overlapping region. Extensive experiments on a variety of simulated and real-world datasets confirm the effectiveness of the proposed method in terms of various evaluation metrics, compared to existing relevant algorithms for handling imbalanced and overlapping datasets.},
  archive      = {J_ESWA},
  author       = {Farnaz Hooshmand and Sogol Peik-Mortazavi},
  doi          = {10.1016/j.eswa.2025.129691},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129691},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel convex-hull-based algorithm for classification problems with imbalanced and overlapping data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unbiased representation learning via feature decoupling network for cross-scene hyperspectral image classification. <em>ESWA</em>, <em>298</em>, 129690. (<a href='https://doi.org/10.1016/j.eswa.2025.129690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For hyperspectral cross-scene classification (HSIC) tasks, the model is trained on the source domains (SDs) and applied directly to the unseen target domains (TDs). For this domain generalization (DG) challenge, a significant issue is the contradiction between the overparameterized model and the limited training domain, which results in the absorption of spurious correlations from environmental features. To alleviate this contradiction, this study proposes a domain extension generator with a feature decoupling network (FDNet). The generator initially decouples the SD into reflectance and shading components, treating them as causal and environmental features, respectively. Considering possible causal residues in environmental features, the shading components are shuffled by style to eliminate undesired correlations. Then, the reflectance and sparsified shading are reconstructed for extension, enriching the training diversity without environmental interference. In addition, to enhance the stability of class-level causal representation, a supervised aggregation strategy is designed to minimize the intra-class distance of the reflectance domain, and supervised contrastive learning is employed to enhance the class-domain semantic consistency information. Comparative analysis with advanced domain generalization and adaptation approaches on three HSI datasets validates the superiority in accuracy and Kappa coefficient metrics of the proposed method.},
  archive      = {J_ESWA},
  author       = {Hanqing Zhao and Lianlei Lin and Zongwei Zhang and Sheng Gao and Junkai Wang},
  doi          = {10.1016/j.eswa.2025.129690},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129690},
  shortjournal = {Expert Syst. Appl.},
  title        = {Unbiased representation learning via feature decoupling network for cross-scene hyperspectral image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated prompt engineering pipelines: Fine-tuning LLMs for enhanced response accuracy. <em>ESWA</em>, <em>298</em>, 129689. (<a href='https://doi.org/10.1016/j.eswa.2025.129689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presented an Automatic Role Prompting System that seeks to improve the performance of the Large Language Model (LLM) by allowing models to assume varied roles through role-based prompting and, as a result, qualitatively improve the relevance of outputs. Our Automatic Role Prompting System’s target audience is people who do not have domain knowledge. The guiding framework (consisting of an Automated Script for discovering roles and fields layered on top of prompt engineering, and Natural Language Inference (NLI) models trained in advance), was robustly tested through the use of three datasets: our set of 1990 curated prompts, WikiQA, and the AwesomeChatGPTPrompts. We implemented a novel evaluation strategy using GPT-Eval, which scales prompts according to completeness, clarity, and relevance. We found substantially better performance than traditional rule- and template-based approaches, yielding accuracy improvements as high as 97.6 %. Overall, this work demonstrates the promise of an Automated Role Prompting System to help people engage and work more effectively and efficiently with Large Language Models (LLMs).},
  archive      = {J_ESWA},
  author       = {Samar Hendawi and Tarek Kanan and Mohammed Elbes and Ala Mughaid and Shadi Alzu’bi},
  doi          = {10.1016/j.eswa.2025.129689},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129689},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated prompt engineering pipelines: Fine-tuning LLMs for enhanced response accuracy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid fusion network using convolutional vision transformers for landslide identification. <em>ESWA</em>, <em>298</em>, 129688. (<a href='https://doi.org/10.1016/j.eswa.2025.129688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNN) have made great strides in the segmentation of remote sensing images, but they still have certain inherent drawbacks when working with small targets and complex geological structures. These drawbacks include incomplete contextual information integration, blurry edges, and inaccurate target localisation. This study suggests using a hybrid CNN-Transformer network to improve the segmentation of landslide regions in high-resolution remote sensing images in order to overcome these difficulties. A comprehensive investigation has been conducted on the use of CNN and transformers to accomplish the task of semantic segmentation. According to experimental data, our model outperforms the state-of-the-art CNN-based, Transformer-based, and even CNN-plus-Transformer combination models for image segmentation tasks by a large margin. When it comes to landslide area segmentation, it performs exceptionally well.},
  archive      = {J_ESWA},
  author       = {S. Sreelakshmi and S.~S. Vinod Chandra},
  doi          = {10.1016/j.eswa.2025.129688},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129688},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid fusion network using convolutional vision transformers for landslide identification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards intelligent online cross-selling. <em>ESWA</em>, <em>298</em>, 129686. (<a href='https://doi.org/10.1016/j.eswa.2025.129686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ubiquity of online cross-selling for fashion demands a large number of qualified outfit compositions. This paper targets practical and intelligent online cross-selling by providing a more accurate fashion compatibility model and a reliable evaluation protocol for evaluating the fashion compatibility model. Firstly, a Hierarchical Outfit Network (HON) is proposed to leverage multi-layer relations among attributes, items, and outfits. The awareness of multiple relations hidden in various outfits enables the HON to outperform all state-of-the-art methods on fill-in-the-blank (FITB) accuracy and compatibility Area Under Curve (AUC) on the Maryland and Type-aware test sets. Meanwhile, a new evaluation protocol is introduced to assess the fashion compatibility model more objectively and accurately, namely, Aesthetic 100 (A100). A100 possess three desirable characteristics: 1) Completeness . All types of standards in the fashion aesthetic system are covered through two tests, namely LAT (Liberalism Aesthetic Test) and AAT (Academicism Aesthetic Test); 2. Reliability . It is an agnostic protocol and consistent with major indicators. It provides an objective and fair assessment for model comparison. 3. Explainability . A100 assesses the model on more fine-grained dimensions, e.g. , Color, Material, and Balance demonstrating its superiority in identifying essential characteristics of fashion aesthetics. Experimental results demonstrate the progress of A100 in the aspects of Reliability and Explainability. The evaluation results on A100 also show the generalization ability of HON from both quantitative and qualitative perspectives. Finally, solutions for multiple applications in fashion retailing are proposed to show how HON can be utilized to help online cross-selling.},
  archive      = {J_ESWA},
  author       = {Kaicheng Pang and Xingxing Zou and Zowie Broach and Waikeung Wong},
  doi          = {10.1016/j.eswa.2025.129686},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129686},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards intelligent online cross-selling},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GCMF-net: Global-aware cross-attention and mask-guided fusion for multispectral object detection. <em>ESWA</em>, <em>298</em>, 129679. (<a href='https://doi.org/10.1016/j.eswa.2025.129679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multispectral Object Detection has shown significant advantages under various lighting and weather conditions, with efficient fusion of RGB and thermal information playing a key role. Previous studies have demonstrated the effectiveness of feature fusion based on convolutional neural networks, but limited local feature interactions hinder the capture of global complementary information. To address these limitations, some methods adopt complex fusion strategies to enhance complementary feature extraction, yet fail to mitigate feature redundancy, which negatively impacts detection performance. In this paper, we propose a novel Global-aware Cross-attention and Mask-guided Fusion (GCMF) module for Multispectral Object Detection, following a fusion-refinement paradigm. In the fusion stage, we first introduce Efficient Channel Attention with Weighted Max-Pooling (ECA-WM) to focus on key information within each modality and achieve implicit alignment before fusion. Subsequently, the Global-aware Cross-Attention Transformer (GCAT) effectively captures complementary cross-modal information and models global features. In the refinement stage, the Mask-guided Refinement Strategy (MRS) generates segmentation masks to distinguish target features from the background. These masks are applied before and after cross-modal interaction to highlight target-relevant information while suppressing irrelevant features, resulting in highly discriminative fused representations. Extensive experimental comparisons demonstrate that the proposed GCMF fusion strategy achieves state-of-the-art performance on the publicly available FLIR, LLVIP and DVTOD datasets, with absolute improvements of 2.8 %, 4.2 % and 4.0 % over the previous methods, respectively. Moreover, the proposed strategy is general and effective, making it adaptable to various detection frameworks.},
  archive      = {J_ESWA},
  author       = {Zhong Qu and Jin Yang and Shufang Xia},
  doi          = {10.1016/j.eswa.2025.129679},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129679},
  shortjournal = {Expert Syst. Appl.},
  title        = {GCMF-net: Global-aware cross-attention and mask-guided fusion for multispectral object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Oriented bounding box detection algorithm for dense scenarios of robotic arm operation. <em>ESWA</em>, <em>298</em>, 129678. (<a href='https://doi.org/10.1016/j.eswa.2025.129678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the national promotion of intelligent manufacturing and the ’Industry4.0’ strategy, the demand for intelligent robotic arms in industrial production has steadily increased. However, challenges such as occlusion, significant object scale variations, and strict real-time requirements have made target detection in densely packed environments more challenging. This study, based on the YOLOv11 algorithm, proposes an efficient oriented bounding box detection method aimed at improving the model’s performance in feature extraction, computational efficiency, and network lightweighting to tackle target detection challenges in dense industrial settings. A Dynamic-Cross-Stage-Dual-Conv module was designed to enhance the Bottleneck section, employing a parallel dual-branch structure for local feature extraction and global context fusion. Simultaneously, a CIoU loss function with geometric perception was introduced to improve object localization accuracy and strengthen the network’s ability to handle densely stacked objects. Next, a Modulated-Deform-Conv deformable convolution module was integrated into the Backbone structure, dynamically adjusting the convolution kernel sampling positions, enabling the network to learn deformation features in dense scenes, improving adaptability to shape and scale variations while reducing computational load. Additionally, a C3K2_FasterBlock lightweight structure, utilizing partial convolutions and sparse connections, was proposed to minimize redundant calculations and optimize feature interactions. On a custom-built dense object dataset, the model achieved a 2.9 % increase in mAP@0.5 and reduced computational cost by 14 %. Finally, the improved model was deployed on the Jetson Orin Nano development board, demonstrating its practical value in robotic arm recognition and grasping tasks in dense industrial environments, offering a new paradigm for future applications.},
  archive      = {J_ESWA},
  author       = {Jinshun Dong and Lixia Deng and Dapeng Wan and Chenxu Liu and Jianqin Yin and Meiqi Guo and Hongyu Zhang and Shoujun Lin and Haiying Liu and Lida Liu},
  doi          = {10.1016/j.eswa.2025.129678},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129678},
  shortjournal = {Expert Syst. Appl.},
  title        = {Oriented bounding box detection algorithm for dense scenarios of robotic arm operation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CrossModalNet: A dual-modal object detection network based on cross-modal fusion and channel interaction. <em>ESWA</em>, <em>298</em>, 129677. (<a href='https://doi.org/10.1016/j.eswa.2025.129677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in complex environments, particularly under conditions such as low illumination or adverse weather, remains a significant challenge. Multispectral detection techniques that integrate visible and infrared imagery offer a promising solution by leveraging complementary modality information. However, substantial discrepancies between these modalities hinder traditional fusion strategies, which often fail to adaptively align and integrate features, resulting in information loss and diminished detection performance. To overcome this limitation, we propose CrossModalNet, a novel cross-modal fusion and channel interaction framework. CrossModalNet comprises two key modules: Convolutional Attention Interaction Module (CAIM) and Bidirectional Cross-Modal Attention Module (BiCAM). CAIM enables effective cross-modal integration across varying semantic levels by employing convolutional attention mechanisms combined with pixel-wise channel guidance. In parallel, BiCAM enhances inter-modal feature complementarity by modeling channel-level interactions through bidirectional attention pathways. Extensive experiments conducted on four public multispectral datasets, FLIR, LLVIP, M3FD, and VEDAI, demonstrate that the proposed method consistently outperforms existing state-of-the-art approaches across multiple performance metrics. Moreover, with an inference speed of 12.6 FPS on embedded platforms, the proposed model is suitable for real-time deployment.},
  archive      = {J_ESWA},
  author       = {Hanyun Li and Linsong Xiao and Lihua Cao and Di Wu and Yangfan Liu and Yi Li and Yunfeng Zhang and Haiyang Bao},
  doi          = {10.1016/j.eswa.2025.129677},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129677},
  shortjournal = {Expert Syst. Appl.},
  title        = {CrossModalNet: A dual-modal object detection network based on cross-modal fusion and channel interaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IPMMG: Information propagation with multi-granularity morphology-guided for nuclear segmentation and classification. <em>ESWA</em>, <em>298</em>, 129676. (<a href='https://doi.org/10.1016/j.eswa.2025.129676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclear segmentation and classification play a crucial role in pathological image analysis. However, it is frequently challenged by blurred nuclear boundaries and complex structures in digital pathology slides, due to factors such as staining techniques and imaging methods, posing a significant challenge for accurate segmentation and classification. To this end, we propose a novel and efficient approach for nuclear identification, termed Information Propagation with Multi-Granularity Morphology-Guided Network (IPMMG). Specifically, IPMMG progressively captures edge morphology information from different network layers while simultaneously incorporating structural morphology features at multiple granularities. By explicitly propagating features related to both the edge and the structure, our approach constrains semantic features to focus on contours of the region of interest in the nuclear segmentation task, thus mitigating the challenge of blurred morphology. Experiments on public datasets demonstrate that IPMMG achieves state-of-the-art (SOTA) performance in segmentation, as measured by Dice and IoU scores, while also attaining competitive results in classification with DQ, SQ, and PQ metrics. In particular, our proposal IPMMG excels in handling nuclei with blurred edges and complex structures.},
  archive      = {J_ESWA},
  author       = {Dawei Fan and Jun Li and Chengfei Cai and Lihui Lin and Riqing Chen and Yanping Chen and Lifang Wei},
  doi          = {10.1016/j.eswa.2025.129676},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129676},
  shortjournal = {Expert Syst. Appl.},
  title        = {IPMMG: Information propagation with multi-granularity morphology-guided for nuclear segmentation and classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MECA: Modular editing via customized expert networks and adaptors in large language models. <em>ESWA</em>, <em>298</em>, 129675. (<a href='https://doi.org/10.1016/j.eswa.2025.129675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Updating language models with new information through targeted edits without resorting to expensive full model retraining remains a critical challenge, particularly when aiming to preserve pre-existing capabilities. In this work, we introduce M odular E diting via C ustomized expert networks and A daptors) (MECA), a unified framework that selectively integrates new knowledge into language models. MECA employs a module-level deferral router to evaluate whether incoming queries fall within the scope of existing edit requests. Queries are then dynamically routed to either customized editing experts or key-value adaptors. This modular strategy ensures that updates are localized, thereby mitigating risks of unintended alterations on unrelated outputs. We validate our approach on sequential editing tasks using Llama2-7B, Llama2-13B and Falcon 11B, benchmarked across two diverse datasets ZsRE and Hallucination. Experimental results show that MECA consistently outperforms several state-of-the-art knowledge editing techniques, achieving improved integration of new information while preserving the model’s original performance. Our analysis further demonstrates that the deferral routing mechanism for selecting modules effectively balances editing precision with overall model stability.},
  archive      = {J_ESWA},
  author       = {Roseline Nyange and Shanbao Qiao and Seung Hoon Na},
  doi          = {10.1016/j.eswa.2025.129675},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129675},
  shortjournal = {Expert Syst. Appl.},
  title        = {MECA: Modular editing via customized expert networks and adaptors in large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable hybrid bio-inspired feature selection framework using RSVP-evoked p300 EEG signals for identity authentication. <em>ESWA</em>, <em>298</em>, 129674. (<a href='https://doi.org/10.1016/j.eswa.2025.129674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EEG-based personal identification confronts critical hurdles, including high dimensionality, noise, and real-time variability. While RSVP and P300 paradigms provide cognitive-response-driven security, feature extraction challenges prevent practical deployment. Although deep learning has addressed unstructured EEG data, pinpointing optimal RSVP and P300-specific features remains an unresolved issue. To overcome these limitations, we introduced a hybrid GWO-MSE-XAI framework integrating Grey Wolf Optimization (GWO), Multiscale Entropy (MSE), and SHAP-based Explainable AI (XAI) to select the most relevant features from RSVP-evoked P300 EEG signals. The framework prioritizes discriminative feature selection, improves class separability, and incorporates a hybrid cross-entropy loss function fused with Fisher’s score-based feature selection. Benchmark-driven optimization refines EEG-specific feature subsets, while evaluation using classifiers (Random Forest, LightGBM, CatBoost, XGBoost) demonstrates substantial dimensionality reduction, faster convergence, and superior performance (98.89% accuracy). Experimental results confirm robustness, scalability, and enhanced interpretability, positioning the framework as a viable solution for EEG-based identity authentication in real-world RSVP and P300 applications.},
  archive      = {J_ESWA},
  author       = {S Abinayaa and S.S. Sridhar},
  doi          = {10.1016/j.eswa.2025.129674},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129674},
  shortjournal = {Expert Syst. Appl.},
  title        = {An explainable hybrid bio-inspired feature selection framework using RSVP-evoked p300 EEG signals for identity authentication},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interlink reconfiguration against cascading failures on cyber-physical power systems based on an improved memetic algorithm. <em>ESWA</em>, <em>298</em>, 129673. (<a href='https://doi.org/10.1016/j.eswa.2025.129673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical power systems (CPPSs) are the deep integration of advanced information and other technologies applied to the grid to achieve fundamental changes in the power industry. Thus, it is very significant to enhance the robustness of the power communication system in order to ensure security. For instance, when an interdependent CPPSs is under attack, the failure can diffuse along interconnect topology to the whole system, even causing a system crash. Recall that most of the existing models are one-to-one coupling structures. Drawing close to reality, we develop a modified memetic algorithm to reconstruct CPPSs with multiple-to-multiple interlinks, called MA-Multiple, which is dedicated to improving the robustness of CPPSs. To improve the accuracy of the optimal solution of the MA-Multiple, we devise a crossover operator (CO) based on the null model to increase population diversity. Further improving the suitability of algorithms on CPPSs, we propose a new Kirchhoff centrality (KIC) based on the approximation of the inverse matrix to measure network connectivity and design a local search operator (LSO). In the experiment, we comprehensively compare the MA-Multiple with four closely relevant methods in different scenarios. The results imply that MA-Multiple performs better in enhancing network robustness and resisting attacks.},
  archive      = {J_ESWA},
  author       = {Wei Lin and Li Xu and Yuexin Zhang and Jie Li},
  doi          = {10.1016/j.eswa.2025.129673},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129673},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interlink reconfiguration against cascading failures on cyber-physical power systems based on an improved memetic algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective portfolio optimization for stock return prediction using machine learning. <em>ESWA</em>, <em>298</em>, 129672. (<a href='https://doi.org/10.1016/j.eswa.2025.129672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach that integrates stock return prediction with the mean–variance (MV) model to enhance the performance of the original model. Firstly, stock returns are predicted using machine learning algorithms, including Robust Linear Regression (OLS-H), Random Forest (RF), and Long Short-Term Memory Networks (LSTM), to select a pre-screened stock pool composed of stocks with high predicted returns. Secondly, a linear weighting method combines the predictions above with the MV model, constructing the Mean-Variance-Forecast Error (MVF) model and determining the investment proportions for the pre-selected stocks. Finally, empirical research is conducted using the components of the CSI 300 Index as sample data. The results indicate that the RF + MVF model outperforms other models and the CSI 300 Index in return and risk metrics. At the same time, a sensitivity analysis of relevant parameters further confirms that considering return uncertainty is beneficial for improving the out-of-sample performance of the MV model.},
  archive      = {J_ESWA},
  author       = {Meiyu Huang and Shili Dang and Miraj Ahmed Bhuiyan},
  doi          = {10.1016/j.eswa.2025.129672},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129672},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective portfolio optimization for stock return prediction using machine learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EKT-ML: An efficient knowledge tracing model with multi-task learning. <em>ESWA</em>, <em>298</em>, 129671. (<a href='https://doi.org/10.1016/j.eswa.2025.129671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) aims to trace a student’s mastery of knowledge, known as knowledge states, and has become a popular research area, with Self-Attention (SA)-based KT models achieving the state-of-the-art performance. However, existing SA-based KT models seem to still have issues that need further investigation. Firstly, there commonly exists incorrect question-knowledge concept (Q-KC) mapping, yet most models fail to address this issue. Secondly, existing SA-based KT models suffer from high time complexity due to their extensive use of the SA mechanism. Finally, from real-world datasets, we observe that there exists a repeated attempts pattern which is often overlooked by existing KT models. Motivated by the above observations, we propose a novel Efficient Knowledge Tracing Model with Multi-task Learning (EKT-ML), an SA-based model with three crucial features. Firstly, we formulate the KT as a Multi-task Learning, with Q-task and KC-task as two tasks; by training them simultaneously and treating Q-KC mapping as shared information, the proposed EKT-ML tends to mitigate the impact of incorrect Q-KC mapping. Moreover, we propose an SVD-MLP component to replace the initial SA layers commonly used in existing SA-based KT models, thereby reducing the time complexity of EKT-ML. Finally, experimental results show that EKT-ML improves performance by up to 8.84 % across four metrics on three widely used datasets. Furthermore, it demonstrates that the EKT-ML has reduced time complexity compared with the benchmark baseline.},
  archive      = {J_ESWA},
  author       = {Wei Liu and Bo Yang and Haotian Su and Yaowei Wang and Qing Li},
  doi          = {10.1016/j.eswa.2025.129671},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129671},
  shortjournal = {Expert Syst. Appl.},
  title        = {EKT-ML: An efficient knowledge tracing model with multi-task learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention dilated deep learning network-based distributed data mining with energy efficient heuristic-aided routing model in WSN. <em>ESWA</em>, <em>298</em>, 129670. (<a href='https://doi.org/10.1016/j.eswa.2025.129670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Sensor Networks (WSNs) are comprised of autonomous nodes, where the physical devices and other equipment are embedded for monitoring the environment. Yet, it consumes larger energy consumption while it fails to provide the optimal routing path. The data aggregation in WSN is accomplished by several classification approaches, but the delay and utilization of the resource are high. So, it is necessary to solve the challenges by implementing the developed model for the energy efficient routing in WSN. A distributed data mining scheme is developed based on a deep learning approach to provide greater energy efficiency and optimal load balancing in WSN. The distributed data mining is performed to distribute the appropriate data to the sensor nodes. This data distribution highly reduces the overhead at the fusion center. The data are categorized via Fused Deep Structural Network (FDSNet), where the Attention-based Dilated Deep Temporal Context Networks (DTCN) are fused with a Deep Shallow Network. The necessary data are distributed to the sensor nodes. The optimal routing is carried out based on optimal path selection using Stability Bound-based Energy Valley Optimizer (SBEVO). The optimal routing is done via the multi-objective functions such as “energy consumption, PDR, delay, and shortest path”. The energy-efficient data transmission is accomplished with the help of developed distributed data mining with a routing scheme. The developed energy-efficient optimal routing in WSN is compared to conventional routing approaches with several performance metrics to show energy efficiency. While comparing with existing methods, the developed model attains the value of 0.95% with regards of accuracy, precision, and F1-score. These findings of the developed model show accurate performance with an efficient routing mechanism in WSN.},
  archive      = {J_ESWA},
  author       = {Kiran Goud Palakuri and Manjeet Singh},
  doi          = {10.1016/j.eswa.2025.129670},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129670},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attention dilated deep learning network-based distributed data mining with energy efficient heuristic-aided routing model in WSN},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Curriculum learning for a hybrid approach for aspect-based sentiment analysis. <em>ESWA</em>, <em>298</em>, 129669. (<a href='https://doi.org/10.1016/j.eswa.2025.129669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past years, the amount of unstructured online review data has grown exponentially. Many people express their opinions about different aspects of goods and services on the Web. Aspect-Based Sentiment Analysis (ABSA) automatically extracts the sentiments with respect to aspects given in a sentence. We improve the training procedure of the state-of-the-art Hybrid Approach for Aspect-Based Sentiment Analysis with deep contextual word embeddings and hierarchical attention (HAABSA++). In this method, a domain sentiment ontology is used as a main classifier, and if it is not conclusive, a neural network is employed as a back-up. We extend the training of the neural network by incrementally adding more difficult instances, also known as curriculum learning. Restaurant reviews obtained from the SemEval-2015 and SemEval-2016 datasets are used to evaluate the effect of implementing curriculum learning. Using baby steps curriculum learning and a specific curriculum strategy, the accuracy of HAABSA++ is improved from 86.3 % to 87.5 %.},
  archive      = {J_ESWA},
  author       = {Nana Lange and Flavius Frasincar and Maria Mihaela Truşcǎ},
  doi          = {10.1016/j.eswa.2025.129669},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129669},
  shortjournal = {Expert Syst. Appl.},
  title        = {Curriculum learning for a hybrid approach for aspect-based sentiment analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new edge detection method for noisy image based on discrete fractional wavelet transform and improved canny algorithm. <em>ESWA</em>, <em>298</em>, 129668. (<a href='https://doi.org/10.1016/j.eswa.2025.129668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge detection is a key technique for extracting object structures and region boundaries in images, serving as an important foundation for visual tasks such as image segmentation and object recognition. However, during real-world image acquisition, various types of noise are inevitably introduced into the images. Traditional edge detection methods suffer significant performance degradation in noisy environments, often resulting in false edges or missing true edges. To address this issue, this paper proposes a novel edge detection method for noisy images. The method begins by adaptively selecting an optimal fractional order p , based on the distribution characteristics of the image’s subband modulus coefficients. This order is then used to perform a p -order discrete fractional wavelet transform (DFRWT) on the noisy image. Then, within the DFRWT domain, an enhanced Canny algorithm is applied to detect edges. This algorithm improves upon the standard method by replacing the traditional gradient operator with a more robust fractional-order Sobel operator to compute the gradient magnitude. This detection process is performed on both the low- and high-frequency subbands to capture features at different scales. Finally, the edge images from the low- and high-frequency components are reconstructed to obtain the final edge detection result. Experimental results demonstrate that, compared to four representative edge detection algorithms, the proposed method exhibits superior noise robustness and edge preservation capability in noisy environments.},
  archive      = {J_ESWA},
  author       = {Xiaozhong Yang and Chunmeng Li},
  doi          = {10.1016/j.eswa.2025.129668},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129668},
  shortjournal = {Expert Syst. Appl.},
  title        = {A new edge detection method for noisy image based on discrete fractional wavelet transform and improved canny algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-constrained EBSD image inpainting via adversarial graph learning: Bridging crystallographic rules and multimodal deep learning. <em>ESWA</em>, <em>298</em>, 129667. (<a href='https://doi.org/10.1016/j.eswa.2025.129667'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electron Backscatter Diffraction (EBSD) is a crucial characterisation method in materials engineering. The reliability of EBSD data is essential in the aerospace, nuclear, and automotive industries, as material performance greatly affects operational safety. While industrial practice makes perfect EBSD data difficult, with sample preparation errors, beam drift, and instrumental noise corrupting up to one-third of datasets. Automated crystallographic fidelity restoration solutions are needed because corrupted data force engineers to abandon valuable experiments or manually restore datasets at risk of errors. Current image inpainting techniques fail to maintain crystallographic constraints, resulting in restorations that violate the basic rules for crystalline materials. A novel physics-constrained framework is proposed to fill this gap. It integrates adversarial learning with graph neural networks (GNNs) for crystallographically consistent EBSD image inpainting. The proposed GTRG method consists of three elements: i ) a generative adversarial network (GAN) for reconstructing grain boundaries; i i ) a crystallography-guided graph transformer (T) that converts pixel data into orientation-boundary graphs; and i i i ) a regression graph convolutional network (RGCN) that links grain, orientation and boundaries to predict missing crystal orientations. The framework mandates a single orientation per grain and preserves grain boundary structure through structured graph representations. A strategy for creating automated EBSD datasets that incorporates realistic corruption patterns supports effective model training and evaluation. Experimental validation shows better performance than current methods, with a 3.5 % improvement in SSIM (0.950 vs. 0.918) and a 63.0 % reduction in FID (16.55 vs. 44.70) compared to AOT-GAN. The study on aerospace niobium alloys further validates practical utility, showing statistically consistent grain orientation and size distributions (Kolmogorov-Smirnov D = 0.02 , p > 0.98 ). This work introduces two key advancements: 1) the first integration of graph neural networks with adversarial learning for topology-aware image inpainting, and 2) a physics-informed framework bridging computer vision and materials science, enabling effective restoration of corrupted EBSD data for subsequent engineering applications.},
  archive      = {J_ESWA},
  author       = {Baiyang Zheng and Jiongran Wen and Yat-Sze Choy and Chengwei Fei},
  doi          = {10.1016/j.eswa.2025.129667},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129667},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-constrained EBSD image inpainting via adversarial graph learning: Bridging crystallographic rules and multimodal deep learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Three-way large-scale group decision-making under incomplete multi-scale information systems: A perspective of quantum social networks. <em>ESWA</em>, <em>298</em>, 129666. (<a href='https://doi.org/10.1016/j.eswa.2025.129666'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The gathering and sharing of information lay the groundwork for decision-making, while large-scale group decision-making (LSGDM) strategies address biases, promoting a more comprehensive evaluation of alternatives. Regarding information representation, incomplete multi-scale information systems (MSISs), as an application of granular computing, combine inputs from decision-makers (DMs) and tackle data gaps through multi-level analysis to foster LSGDM. Furthermore, given the interference effect among DMs, quantum social networks (SNs) and three-way decisions (TWD) are vital for effective decision-making. Quantum SNs provide a framework for modeling complex trust relationships among DMs, while TWD offers a structured approach to manage uncertainty. Therefore, this paper seeks to investigate quantum SN-guided three-way LSGDM under incomplete MSISs. First, MSISs are designed to gather information across spatial dimensions. Second, trust propagation paths within SNs are aggregated using quantum theory. Following community clustering through the Leiden algorithm, each community is further divided into core and fringe regions by three-way clustering (TWC), where core alternatives reflect the central members and fringe alternatives represent uncertain members. Third, to achieve intra-group consensus, the weights of DMs in fringe regions and those with low consensus levels are adjusted, while for inter-group consensus, the weight and decision information of community representatives with low consensus levels are modified. Fourth, alternatives are classified using the TWD method, which is grounded in the Dempster-Shafer theory and incorporates the enhanced belief Jensen-Sharma-Mittal ( E B J S M ) divergence. Finally, air quality datasets are used to validate the practicality of this method through sensitivity analysis, simulation analysis, comparative analysis, and statistical analysis.},
  archive      = {J_ESWA},
  author       = {Rui Li and Chao Zhang and Hamido Fujita and Wentao Li and Witold Pedrycz and Oscar Castillo},
  doi          = {10.1016/j.eswa.2025.129666},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129666},
  shortjournal = {Expert Syst. Appl.},
  title        = {Three-way large-scale group decision-making under incomplete multi-scale information systems: A perspective of quantum social networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GDCR: Geometry-enhanced directional consistency representation for point cloud analysis. <em>ESWA</em>, <em>298</em>, 129665. (<a href='https://doi.org/10.1016/j.eswa.2025.129665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point clouds provide discrete representations of 3D scenes. The relative positions and directions between points collectively describe the objects. Variations in sampling angles, distances, or noises can introduce perturbations, disrupting these spatial and directional relationships. These pose significant challenges for achieving robust feature representations. However, research on the robust representation of point clouds is limited. Although advanced models achieve impressive performance, they exhibit poor robustness to perturbations. To address this issue, we propose Geometry-enhanced Directional Consistency Representation (GDCR), a novel method designed to enhance robustness. In GDCR, we introduce Statistic-based Geometric Reasoning (SGR) to achieve precise spatial geometric estimation for discrete point sets, explicitly enriching spatial geometric information. Furthermore, GDCR vectorizes features embedded with SGR information and applies feature rotation and relative direction refinement in the expanded feature space for robust directional representation. GDCR improves the flexibility and directional expressiveness of point cloud features, significantly improving robustness against perturbations. Extensive experiments demonstrate that GDCR exhibits outstanding robustness while surpassing or matching the performance of state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Ziming Wang and Boxiang Zhang and Ming Ma and Yue Wang and Taoli Du and Ying Wang and Wenhui Li},
  doi          = {10.1016/j.eswa.2025.129665},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129665},
  shortjournal = {Expert Syst. Appl.},
  title        = {GDCR: Geometry-enhanced directional consistency representation for point cloud analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). APMoE-net: Fourier amplitude-phase joint enhancement and MoE compensation for low-light image enhancement. <em>ESWA</em>, <em>298</em>, 129664. (<a href='https://doi.org/10.1016/j.eswa.2025.129664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-Light Image Enhancement (LLIE) plays a crucial role in computer vision applications. Beyond spatial-based approaches, recent works have explored the Fourier domain. To better preserve structural details in extremely dark scenes, infrared modality has also been introduced as a robust prior for capturing scene geometry. However, existing methods suffer from limited enhancement performance due to the independent modeling of Fourier amplitude and phase, the limitations of cross-modal guidance, and the information loss in sequential feature extraction. To address these challenges, we propose APMoE-Net, a dual-stage Fourier network framework with amplitude-phase joint enhancement and spatial Mixture of Experts (MoE) compensation. Stage one performs coarse enhancement by leveraging infrared images to jointly optimize Fourier amplitude and phase, enabling mutual guidance learning between them. Subsequently, a Modality Refinement Module leverages edge information to refine infrared inputs, producing a refined modality map as a more accurate cross-modal prior for subsequent processing. The second stage employs a dual-branch design for texture refinement. Our key innovation lies in the MoE Compensation Module integrated within the Multi-scale Convolution Branch. This module employs a dynamic routing network to selectively activate specialized experts, enabling the recovery of fine-grained textures that are lost during sequential processing. Meanwhile, the Fourier Branch integrates the refined modality map to improve overall detail and contrast. Comprehensive experiments demonstrate that APMoE-Net surpasses state-of-the-art (SOTA) methods in both qualitative and quantitative evaluations. Notably, APMoE-Net achieves outstanding performance with a lightweight design, offering an efficient LLIE solution.},
  archive      = {J_ESWA},
  author       = {Mengen Cai and Tongshun Zhang and Pingping Liu and Qiuzhan Zhou},
  doi          = {10.1016/j.eswa.2025.129664},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129664},
  shortjournal = {Expert Syst. Appl.},
  title        = {APMoE-net: Fourier amplitude-phase joint enhancement and MoE compensation for low-light image enhancement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced edge detection of harmful algal blooms using diffusion probability models and sobel-convolutional attention mechanisms. <em>ESWA</em>, <em>298</em>, 129663. (<a href='https://doi.org/10.1016/j.eswa.2025.129663'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection and identification of harmful algal bloom (HAB) images are crucial for developing effective early warning systems for HABs. However, existing edge detection models, primarily designed for natural scenes, struggle with HAB-specific challenges such as blurred cell contours and interference from impurity bubbles. To address these issues, we propose a novel edge detection approach tailored for marine HABs, integrating a diffusion probability model with Sobel convolutional inter-layer attention mechanisms. Firstly, we develop an image enhancement algorithm specifically for HABs images, significantly improving real-time dynamic sampling data by enhancing contrast, edges, and texture features. Next, we introduce the SIAnet network, which utilizes inter-layer attention and convolutional operations to generate comprehensive global information. This network enhances feature correlation by aggregating shared features across multiple layers and modeling both long-range and short-range dependencies, effectively suppressing noise and background interference. This facilitates precise extraction of algae boundaries and morphological characteristics. Additionally, an improved Sobel operator is employed to generate supplementary edge features, accelerating the training process. Experimental results demonstrate that the proposed method achieves robust performance on the HABs dataset, with an Optimal Dataset Scale (ODS) of 0.645, an Optimal Image Scale (OIS) of 0.702, and an Average Precision (AP) of 0.813. Compared to existing methodologies, our approach demonstrates strong generalization on BSDS and BIPED datasets, significantly enhancing performance and mitigating typical CNN issues of edge thickening and fragmentation. It offers essential technical support for efficient HAB early warning system development.},
  archive      = {J_ESWA},
  author       = {Gengkun Wu and Yining Fan and Xin Tian and Chao Cui and Jiazheng Han},
  doi          = {10.1016/j.eswa.2025.129663},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129663},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced edge detection of harmful algal blooms using diffusion probability models and sobel-convolutional attention mechanisms},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predictive modeling of biogeographical ancestry using a novel SNP panel and supervised learning approaches. <em>ESWA</em>, <em>298</em>, 129662. (<a href='https://doi.org/10.1016/j.eswa.2025.129662'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring an individual’s BioGeographical Ancestry (BGA) through DNA analysis is a valuable tool in various fields such as forensic science, especially when traditional methods fail to identify suspects or victims. Advances in Next-Generation Sequencing (NGS) have revolutionized genomic data acquisition, enabling the development of comprehensive Single Nucleotide Polymorphism (SNP) panels for ancestry inference. This study assessed the effectiveness of a novel panel containing 3234 SNPs at both inter-continental and a more detailed BGA level, using various supervised Machine Learning (ML) models, including Categorical Naive Bayes, Penalized Multinomial Logistic Regression, Linear Support Vector Machines, Random Forest, and tree-based Gradient Boosting. A nested cross-validation approach was employed for model tuning and evaluation, with balanced accuracy as the main performance metric to address class imbalance. At the inter-continental level, all ML models demonstrated high balanced accuracy, confirming their reliability for BGA inference. However, performance declined at the more detailed continental level, likely due to a combination of factors including increased class imbalance, reduced sample sizes for certain populations, and the inherent complexity of distinguishing genetically and geographically proximate groups. Nonetheless, promising results were observed for South Asians, Northeast Asians, Europeans, and West Africans classes. In contrast, performance was notably lower for underrepresented classes such as Inner Asians. Misclassification patterns at both levels appeared to reflect known geographical and historical relationships, although further analysis revealed that these were often concentrated in underrepresented or genetically complex groups. These findings highlighted the potential of this SNP panel and ML approaches as valuable tools for forensic investigations.},
  archive      = {J_ESWA},
  author       = {Cosimo Grazzini and Giorgia Spera and Stefania Morelli and Daniele Castellana and Giulia Cosenza and Michela Baccini and Giulia Cereda and Elena Pilli},
  doi          = {10.1016/j.eswa.2025.129662},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129662},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predictive modeling of biogeographical ancestry using a novel SNP panel and supervised learning approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RL-CoSeg: A reinforcement learning-based collaborative localization and segmentation framework for medical image. <em>ESWA</em>, <em>298</em>, 129661. (<a href='https://doi.org/10.1016/j.eswa.2025.129661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmenting small regions of interest (ROIs) from abdominal CT images presents significant challenges, particularly due to class imbalance and variations in the sizes of foreground objects. A commonly adopted solution is the two-stage segmentation. However, this approach has two key limitations: i) Difficulty in balancing localization accuracy and target preservation. To reduce information loss in the first stage, existing methods typically enlarge the predicted bounding boxes, which improves coverage but compromises localization precision. ii) Independent optimization of the two stages, which lacks a collaborative mechanism. This fragmented pipeline limits the flow of information between stages, thereby constraining performance improvements. To address these limitations, we propose a reinforcement learning-based collaborative localization and segmentation (RL-CoSeg) framework, which comprises three sub-networks: localization network (LN), segmentation network, and localization-segmentation collaboration network (LSCN). The LN integrates prior knowledge and incorporates a dynamic reward mechanism to enhance the accuracy and efficiency of target detection through reinforcement learning (RL) strategies. The LSCN further introduces segmentation predictions as a reward signal, which, together with the localization reward, jointly drives policy learning. In addition, a heuristic exploration strategy is employed to avoid local optima and improve training stability. This design strengthens the information interaction and collaborative performance between the two tasks. Experimental results demonstrate that the proposed method achieves superior collaborative performance in small-target medical image segmentation.},
  archive      = {J_ESWA},
  author       = {Feilong Xu and Feiyang Yang and Xiaoli Zhang and Zhaojun Liu},
  doi          = {10.1016/j.eswa.2025.129661},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129661},
  shortjournal = {Expert Syst. Appl.},
  title        = {RL-CoSeg: A reinforcement learning-based collaborative localization and segmentation framework for medical image},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SH-ETRs:Learning soft-hard rules with entity type constraints for document-level relation extraction. <em>ESWA</em>, <em>298</em>, 129660. (<a href='https://doi.org/10.1016/j.eswa.2025.129660'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction (DocRE) aims to extract relations between entity pairs across the entirety of a document. Current methods have begun to adopt logical rules to enhance the performance of DocRE models. However, the pipeline’s rule learning framework will suffer from the issue of error propagation, and the end-to-end method may lead to mistakes in rule reasoning. Additionly, they ignore entity type information when learning the rules. To address these issues, we propose a novel framework named Soft-Hard Rules with Entity Type Constraints (SH-ETRs) for improving the rules’ expressiveness and quality. Specifically, we first propose a Hard Entity Type Rules Module (H-ETRs) to learn entity type information and provide hard rule constraints. Then, we propose a Soft Entity Type Rule Reasoning Module (S-ETRs), which parameterizes the rule inference process and reduces error propagation during the process. Furthermore, by applying a rule consistency loss function to S-ETRs, we achieve the learning of soft rules under hard rule constraints, thereby aiming to prevent the learning of inaccurate rules during the training process. The experimental results demonstrate that our method outperforms existing rule learning frameworks, achieving state-of-the-art performance with an F1 score of 74.39 and an IgnF1 score of 67.43 across three public datasets and two baseline models.},
  archive      = {J_ESWA},
  author       = {Haisong Chen and Nisuo Du and Qing He and Yuji Wang},
  doi          = {10.1016/j.eswa.2025.129660},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129660},
  shortjournal = {Expert Syst. Appl.},
  title        = {SH-ETRs:Learning soft-hard rules with entity type constraints for document-level relation extraction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MCAD-EUC: Multi-context adaptive decoding with entropy-based uncertainty calibration for knowledge conflict mitigation. <em>ESWA</em>, <em>298</em>, 129659. (<a href='https://doi.org/10.1016/j.eswa.2025.129659'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The knowledge sources of large language models (LLMs) encompass both parametric internal knowledge and external contextual information. However, conflicts between these two sources can significantly impair model performance. Existing methods typically assume a priori correctness of either the context or the parametric knowledge, lacking dynamic coordination mechanisms and being limited to single-context scenarios. To address this issue, this work proposes a lightweight and training-free decoding method, M ulti- C ontext A daptive D ecoding ( MCAD-EUC ), which dynamically measures the effectiveness of both knowledge through E ntropy based U ncertainty C alibration. It does not concern itself with whether the knowledge is false or true, the internal or the external, but balancing them according to their contributions to correctly answering the question. Particularly, MCAD-EUC is naturally multi-contextual. It can dynamically amplify the distribution of golden context while mitigating the influence of noisy context, thereby optimizing the final logits for predicting the next token during the decoding process. To comprehensively evaluate the model performance in multi-context scenarios, this work constructs MCQA, a multi-context question answering dataset that includes golden context, irrelevant context, and six categories of misleading context (crowd, logic, temporal, authority, emotional, numeric), simulating the diversity of noise in real-world settings. Extensive experiments on four LLMs and four MCQA datasets demonstrate that MCAD-EUC achieves an average accuracy improvement of 3.17 % over the best-performing baseline methods. Further sensitivity analysis confirms that the entropy-based adaptive weighting mechanism consistently outperforms all fixed-weight settings. Our dataset and code will be publicly available.},
  archive      = {J_ESWA},
  author       = {Yimin Ou and Yifan Wang and Ping Jian and Tianhe Zhang and Xing Pei},
  doi          = {10.1016/j.eswa.2025.129659},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129659},
  shortjournal = {Expert Syst. Appl.},
  title        = {MCAD-EUC: Multi-context adaptive decoding with entropy-based uncertainty calibration for knowledge conflict mitigation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable knowledge tracing with dual-level knowledge states. <em>ESWA</em>, <em>298</em>, 129658. (<a href='https://doi.org/10.1016/j.eswa.2025.129658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) is a critical technology for achieving personalized learning. It estimates learners’ knowledge states and predicts future performance using historical interaction data. Despite recent advances, two significant challenges remain. First, the accuracy of knowledge state modeling is limited by the insufficient fusion of multi-scale information across temporal and spatial dimensions. Second, a trade-off persists between improving predictive performance and enhancing interpretability. This paper proposes an interpretable knowledge tracing method based on dual-level knowledge states (DIKT) to address these challenges. From the temporal perspective, DIKT incorporates a forgetting-aware RoLinear Transformer and a semantic similarity-based review mechanism to model learners’ problem-level knowledge states. From the spatial perspective, it leverages a Knowledge Concept (KC) relational graph to propagate influence among related KCs and dynamically update learners’ concept-level knowledge states through three sequential learning phases: forgetting, aggregation, and updating. Student performance is predicted using a two-parameter Item Response Theory (IRT) model, which incorporates guess and slip parameters to account for response anomalies. We conduct extensive comparisons between DIKT and 20 state-of-the-art KT models on five widely used public datasets. Experimental results demonstrate that DIKT achieves superior performance while preserving interpretability, highlighting its practical potential for real-world educational applications. The code is available at https://github.com/ting214/DIKT .},
  archive      = {J_ESWA},
  author       = {Yanting Li and Tao Zhou and Tianyu Cai and Shenggen Ju},
  doi          = {10.1016/j.eswa.2025.129658},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129658},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interpretable knowledge tracing with dual-level knowledge states},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RASpan: Improving toponym recognition through span representation model with retrieval augmentation. <em>ESWA</em>, <em>298</em>, 129657. (<a href='https://doi.org/10.1016/j.eswa.2025.129657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Toponym recognition aims to identify place names from natural language texts, which is vital for various applications including geographic information retrieval, emergency response, and natural disaster analysis. Currently, mainstream studies mainly adopt deep learning models for toponym recognition. However, these approaches encounter significant limitations due to the inherent ambiguity, variation, and abbreviation of toponyms. To address these issues, we propose a novel Span Representation Model with R etrieval A ugmentation ( RASpan ) that leverages more accurate span representation and effective external geo-entity information to enhance the semantic representation of place names for improving the performance of toponym recognition. On the one hand, RASpan retrieves diverse geo-entities and concatenates geo-entity knowledge with an input sequence to construct a new prompt sequence. On the other hand, RASpan utilizes the prompt encoder based on the language model to encode this prompt sequence and employs a dedicated span representation module to obtain more accurate span representations. In addition, a new geo-entity prediction task is designed to learn the entire representation of each geo-entity while minimizing noise interference. Experiments on three publicly available datasets demonstrate that our model achieves new state-of-the-art results, highlighting the effectiveness of RASpan in toponym recognition by introducing prior geo-entity knowledge.},
  archive      = {J_ESWA},
  author       = {Hui Wu and Anran Yang and Zhinong Zhong and Ye Wu and Fei Yang and Luo Chen and Ning Jing},
  doi          = {10.1016/j.eswa.2025.129657},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129657},
  shortjournal = {Expert Syst. Appl.},
  title        = {RASpan: Improving toponym recognition through span representation model with retrieval augmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An interpretable automated optimized machine learning for predicting concrete compressive strength. <em>ESWA</em>, <em>298</em>, 129656. (<a href='https://doi.org/10.1016/j.eswa.2025.129656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel, interpretable, and automated machine learning (AutoML) framework for accurately predicting the compressive strength of environmentally sustainable concrete mixtures that incorporate supplementary cementitious materials (SCMs) by addressing the growing need for transparent and data driven tools in structural material design, particularly for concrete mixes enriched with various SCMs. A robust unified dataset of 1,317 samples was curated by integrating peer-reviewed experimental studies for this study. The proposed methodology incorporates feature contribution ranking through mutual information, model screening with AutoML to identify the most effective regression models, Bayesian optimization for fine-tuning model parameters, and interpretability techniques including SHAP and counterfactual analysis. The best performance metrics, in training include R 2 of 0.999, a mean absolute error 0.114, root mean squared error 0.7094, and mean absolute percentage error of 0.51 %, in testing phase R 2 of 0.944, a mean absolute error 3.479, root mean squared error 4.8173, and mean absolute percentage error of 9.86 %. The weakest performance, with a training R 2 of 0.982 and a mean absolute error of 1.911 MPa, root mean squared error 2.7990 and mean absolute percentage error 5.43 %, in testing phase R 2 of 0.786 and a mean absolute error of 5.754 MPa, root mean squared error 9.4336 and mean absolute percentage error 16.16 %. The interpretability analysis values provided insights into the most important features, such as curing time and cement are crucial in predicting the strength. Counterfactual analysis further validated the model by illustrating the significant impact of cement, age and water on concrete strength.},
  archive      = {J_ESWA},
  author       = {Aparna Kamarthi and Baskar Kaliyamoorthy},
  doi          = {10.1016/j.eswa.2025.129656},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129656},
  shortjournal = {Expert Syst. Appl.},
  title        = {An interpretable automated optimized machine learning for predicting concrete compressive strength},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT. <em>ESWA</em>, <em>298</em>, 129655. (<a href='https://doi.org/10.1016/j.eswa.2025.129655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative AI paraphrased text can be used for copyright infringement and the AI paraphrased content can deprive substantial revenue from original content creators. Despite this recent surge of malicious use of generative AI, there are few academic publications that research this threat. In this article, we demonstrate the ability of pattern-based similarity detection for AI paraphrased news recognition. We propose an algorithmic scheme, which is not limited to detect whether an article is an AI paraphrase, but, more importantly, to identify that the source of infringement is the ChatGPT. The proposed method is tested with a benchmark dataset specifically created for this task that incorporates real articles from BBC, incorporating a total of 2,224 articles across five different news categories, as well as 2,224 paraphrased articles created with ChatGPT. Results show that our pattern similarity-based method, that makes no use of deep learning, can detect ChatGPT assisted paraphrased articles at percentages 96.23% for accuracy, 96.25 for precision, 96.21% for sensitivity, 96.25% for specificity and 96.23% for F1 statistic.},
  archive      = {J_ESWA},
  author       = {Konstantinos F. Xylogiannopoulos and Petros Xanthopoulos and Panagiotis Karampelas and Georgios A. Bakamitsos},
  doi          = {10.1016/j.eswa.2025.129655},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129655},
  shortjournal = {Expert Syst. Appl.},
  title        = {The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic collaborative evolutionary network: A novel spatio-temporal feature extraction framework for EEG emotion recognition. <em>ESWA</em>, <em>298</em>, 129654. (<a href='https://doi.org/10.1016/j.eswa.2025.129654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, significant progress has been made in emotion recognition research based on electroencephalogram (EEG) signals. However, existing methods face two key limitations: on one hand, the reliance on fixed physical connections or static topological relationships makes it difficult to effectively represent the dynamic non-Euclidean spatial characteristics between EEG electrodes; on the other hand, spatiotemporal feature extraction is often conducted independently. This lack of a collaborative mechanism for spatiotemporal features results in insufficient fine-grained emotional representation capability. To address these issues, a dynamic collaborative evolutionary network (DCENet) is proposed based on graph-aware enhancement and global convolutional Transformer for EEG emotion recognition. DCENet constructs the causal relationship between electrodes by constructing the graph-aware enhancement (GAE) module, obtains spatial features with the causal relationship, and enhances key features. At the same time, DCENet constructs the global convolutional Transformer (GCT) module, which utilizes the global modeling advantage of the Transformer and the local perception ability of the convolutional operation to capture the temporal features with different scales. In addition, DCENet adaptively fuses temporal and spatial features through the local differential fusion (LDF) module to achieve cross-domain feature alignment and feature alignment of emotion categories to collaboratively evolve emotion representation features with more fine-grained information. This paper conducts experiments on the SEED, SEED-IV, and MPED datasets to validate the effectiveness of DCENet. The experimental results show that the model achieves cross-subject average accuracies of 87.55 %, 73.04 %, and 27.72 % on SEED, SEED-IV, and MPED, respectively, outperforming the state-of-the-art methods. The source code is publicly available at: https://github.com/cvmdsp/DCENet .},
  archive      = {J_ESWA},
  author       = {Shuaiqi Liu and Zhihui Gu and Yuan Zhang and Yanling An and Shuhuan Zhao and Bing Li and Yudong Zhang},
  doi          = {10.1016/j.eswa.2025.129654},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129654},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic collaborative evolutionary network: A novel spatio-temporal feature extraction framework for EEG emotion recognition},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Trust in recommender systems: A survey. <em>ESWA</em>, <em>298</em>, 129653. (<a href='https://doi.org/10.1016/j.eswa.2025.129653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust-based recommender systems incorporate interpersonal trust relationships into the recommendation process, operating on the principle that users are more likely to accept suggestions from people they trust. Empirical studies have shown that trust-aware approaches often deliver more accurate recommendations than their trust-unaware counterparts. In this comprehensive, up-to-date survey, we analyze a variety of trust-based recommendation methods, categorize different trust inference techniques, and examine how trust is integrated into recommendation algorithms. We then organize the investigated approaches according to a clear taxonomy, explore their underlying concepts, and highlight the key challenges and open issues that remain in the field.},
  archive      = {J_ESWA},
  author       = {Imane Akdim and Loubna Mekouar and Youssef Iraqi},
  doi          = {10.1016/j.eswa.2025.129653},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129653},
  shortjournal = {Expert Syst. Appl.},
  title        = {Trust in recommender systems: A survey},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Composite human activity recognition utilizing knowledge distillation and sensor fusion focusing on resource constrained microcontrollers. <em>ESWA</em>, <em>298</em>, 129652. (<a href='https://doi.org/10.1016/j.eswa.2025.129652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a cost-effective, low-computation system for composite Human Activity Recognition (HAR) that leverages knowledge-distilled neural networks on a Microcontroller Unit (MCU) to minimize reliance on cloud processing. A key contribution of this work is the investigation of plantar pressure sensor data within a knowledge distillation framework, addressing a notable gap in the existing literature. The proposed solution centers around the ESP32-S3 DevKit C1, equipped with a dual-core 240 MHz Tensilica chip, 320 KiB of usable Static Random Access Memory (SRAM), and built-in Wi-Fi and Bluetooth. Significantly, both the teacher and the student models surpass existing state-of-the-art methods, achieving F1-scores of 99.33 %, 98.36 %, and 97.68 % respectively, in classifying a comprehensive set of 21 activities (15 composite and 6 simple). The distilled student models demonstrate remarkable efficiency, with execution times of 1.83 and 0.64 s, memory footprints of only 62 KB and 82 KB, and flash memory usage of approximately 209 KB and 127 KB, while maintaining low power consumption of 210 mW and 215 mW, respectively. Furthermore, we have developed an end-to-end prototype that integrates the ESP32-S3 with a WitMotion Inertial Measurement Unit (IMU) sensor. This system autonomously manages data acquisition, feature extraction, and inference in under 7 s with a total power consumption of approximately 295 mW.},
  archive      = {J_ESWA},
  author       = {Athar Noor Mohammad Rafee and John Clear and Jannatun Noor},
  doi          = {10.1016/j.eswa.2025.129652},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129652},
  shortjournal = {Expert Syst. Appl.},
  title        = {Composite human activity recognition utilizing knowledge distillation and sensor fusion focusing on resource constrained microcontrollers},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Med-D3CG: Wavelet-based diffusion in the difference domain for cross-modality medical image generation. <em>ESWA</em>, <em>298</em>, 129651. (<a href='https://doi.org/10.1016/j.eswa.2025.129651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The synthesis of cross-modal medical images plays a vital role in bridging diagnostic gaps between imaging modalities such as CT, MRI, and PET. This integration enables a more comprehensive evaluation of a patient’s condition, improving diagnostic accuracy and aiding clinical decision-making. However, the performance of conditional denoising diffusion probabilistic models is often hindered by pronounced structural and intensity discrepancies between modalities, as well as the inherently slow nature of the diffusion process. To address these challenges, this paper proposes Wavelet-Based Diffusion in the Difference Domain for Cross-Modality Medical Image Generation (Med-D3CG), a novel framework that transforms the synthesis process by emphasizing the difference domain. Instead of directly generating target images like conventional methods, Med-D3CG models the residual information between conditioned and target images. This strategy allows the framework to accurately capture essential structural and intensity variations between modalities, leading to more precise and realistic image synthesis. Additionally, Med-D3CG integrates the Discrete Wavelet Transform (DWT) to improve efficiency, accelerating the diffusion process while maintaining high image fidelity. On SynthRAD2023 and HMIFD datasets, state-of-the-art performance is achieved on pelvis and HMIFD using Med-D3CG , with the best Learned Perceptual Image Patch Similarity (LPIPS) and competitive FID observed on brain. Code and pretrained models are provided at https://github.com/ZgzTTTer/Med-D3CG .},
  archive      = {J_ESWA},
  author       = {Guangzhen Zhu and Midi Wan and Wenming Cao and Zhiwen Yu and Jin Hu and Bing Li and Xiaotao Fan},
  doi          = {10.1016/j.eswa.2025.129651},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129651},
  shortjournal = {Expert Syst. Appl.},
  title        = {Med-D3CG: Wavelet-based diffusion in the difference domain for cross-modality medical image generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Two-stage feature selection utilizing three-way adaptive neighborhood characteristic measure and optimal combination search. <em>ESWA</em>, <em>298</em>, 129650. (<a href='https://doi.org/10.1016/j.eswa.2025.129650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neighborhood rough set model(NRSM) has shown its powerful capacity in feature selection. However, a challenge still exists in describing the diversity between the attributes deeply while avoiding the impact caused by the neighborhood parameters. To address this problem, in this paper, we propose a two-stage feature selection by utilizing a three-way adaptive characteristic measure and an optimal combination search. First, we define a fitness function for applying the Stochastic Fractal Search(SFS) to design an novel adaptive neighborhood rough set model(ANRSM). To better utilize the construction characteristic of the adaptive model and reduce the computational cost, the lower and upper approximations of the SFS-based ANRSM are redefined through the fitness function. Second, based on the two approximations, we analyze the fitness function thresholds that can partition the universe into three regions and design the three-way adaptive neighborhood characteristic regions, which provide a more direct classification of samples without the inclusion and union operations. Third, we design different measures for the samples in diverse regions based on their corresponding characteristic. Afterward, a three-way adaptive characteristic measure is designed by integrating the three measures to evaluate the uncertainty of attributes. Then, we apply the measure to design a feature selection approach with greedy search. Considering that the greedy strategy may output redundant attributes, we introduce an optimal combination search approach through a novel wrapper technology to explore the potential optimal feature combinations. Compared with nine algorithms on fourteen public datasets, the experimental results show the effectiveness of our algorithm.},
  archive      = {J_ESWA},
  author       = {Bowen Lin and Duoqian Miao and Caihui Liu and Hongyun Zhang and Ruizhi Wang and Witold Pedrycz},
  doi          = {10.1016/j.eswa.2025.129650},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129650},
  shortjournal = {Expert Syst. Appl.},
  title        = {Two-stage feature selection utilizing three-way adaptive neighborhood characteristic measure and optimal combination search},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New semi-supervised fuzzy C-means clustering with asymmetric deviation constraints and fast algorithm. <em>ESWA</em>, <em>298</em>, 129648. (<a href='https://doi.org/10.1016/j.eswa.2025.129648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised clustering leverages prior information to improve algorithm performance and is widely valued by researchers. This paper analyzes the traditional semi-supervised fuzzy C-means (SFCM) objective function, noting that as a labeled sample’s membership degree aligns with its prior information, the impact of this information on the deviation constraint weakens. This reduces its supervisory effect on optimizing the membership partition matrix, especially with a large regularization factor. To overcome this, we propose a novel semi-supervised fuzzy C-means method based on an asymmetric deviation constraint and develop a two-level alternating iterative optimization algorithm, supported by theoretical convergence analysis using Zangwill’s theorem and the bordered Hessian matrix. To address the slow convergence and high computational cost typical of semi-supervised fuzzy clustering, we further enhance the algorithm with affinity filtering and a membership scaling scheme for improved efficiency. Experimental results demonstrate that our methods significantly outperform existing state-of-the-art techniques, advancing semi-supervised fuzzy C-means clustering.},
  archive      = {J_ESWA},
  author       = {Chengmao Wu and Jun Hou},
  doi          = {10.1016/j.eswa.2025.129648},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129648},
  shortjournal = {Expert Syst. Appl.},
  title        = {New semi-supervised fuzzy C-means clustering with asymmetric deviation constraints and fast algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BayesAHDD: A new bayesian rule-based adaptive hypersphere data description for few-shot one-class classification. <em>ESWA</em>, <em>298</em>, 129647. (<a href='https://doi.org/10.1016/j.eswa.2025.129647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot one-class classification (FS-OCC) is a challenging classification problem that involves learning from a very limited number of training samples, all from a single class. Recently, several data description methods have been proposed to address the FS-OCC problem. Unlike conventional one-class classification problems, the few-shot setting requires the model to generalize to novel tasks with previously unseen positive classes. Most existing methods learn decision boundaries in the feature space without explicitly modeling the underlying data distributions, which limits the generalization ability of the learned representations. To address this issue, we propose Bayesian Rule-based Adaptive Hypersphere Data Description (BayesAHDD), a probabilistic framework that represents data with multivariate Gaussian distributions and performs classification according to the Bayes decision rule. Based on the assumption that negative samples are more dispersed in the feature space, BayesAHDD models the negative class by scaling the positive class variance vector element-wise using a learnable vector. To address the challenges of exploding gradients and numerical overflow, we impose a lower bound on the positive class variance vector and introduce a trainable parameter that integrates the class prior probability ratio with the normalization constants of the Gaussian class-conditional densities. Experimental results on both benchmark and domain-specific datasets show that BayesAHDD consistently outperforms existing baselines and state-of-the-art FS-OCC methods. Moreover, quantitative analysis demonstrates that the learned feature representations exhibit superior discriminative ability compared to those produced by previous approaches.},
  archive      = {J_ESWA},
  author       = {Yuchen Ren and Xiabi Liu and Yan Pei and Yunlong Li and Yongxia Wei},
  doi          = {10.1016/j.eswa.2025.129647},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129647},
  shortjournal = {Expert Syst. Appl.},
  title        = {BayesAHDD: A new bayesian rule-based adaptive hypersphere data description for few-shot one-class classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A network selection algorithm for space-air-ground integrated network based on location prediction model and multi-attribute decision making. <em>ESWA</em>, <em>298</em>, 129646. (<a href='https://doi.org/10.1016/j.eswa.2025.129646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an indispensable component of 5G and even the future 6G networks, the Space-Air-Ground Integrated Network (SAGIN) is envisioned to provide ubiquitous network connectivity and services by integrating satellite, aerial, and terrestrial networks. However, due to the frequent network selection of in-vehicle terminals, the user’s Quality of Service (QoS) can significantly deteriorate. To address this issue, a network selection algorithm based on terminal location prediction has been proposed. Firstly, we enhanced the Particle Swarm Optimization (PSO) algorithm to optimize the hyper-parameters of the Long Short-Term Memory (LSTM) network, thereby improving the accuracy of terminal location prediction. After constructing the network sets of the current terminal position and the predicted position, respectively, we designed a network selection judgment mechanism with a dynamically adjustable switching threshold based on Fuzzy Logic and K-Means theory. Finally, through the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) algorithm, we have achieved robust network selection in fast-moving scenarios. The simulation results show that the proposed algorithm can adaptively adjust the switching threshold and provide precise positions. Compared to existing algorithms, it can significantly reduce the number of candidate networks and the number of selections, thereby reducing the computational load and increasing the throughput of users.},
  archive      = {J_ESWA},
  author       = {Jianli Xie and Weicheng Pan and Lei Wu and Zishan Wu},
  doi          = {10.1016/j.eswa.2025.129646},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129646},
  shortjournal = {Expert Syst. Appl.},
  title        = {A network selection algorithm for space-air-ground integrated network based on location prediction model and multi-attribute decision making},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Anomaly detection based on graph neural networks incorporating with domain knowledge for industrial cyber-physical systems. <em>ESWA</em>, <em>298</em>, 129645. (<a href='https://doi.org/10.1016/j.eswa.2025.129645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective anomaly detection heavily relies on accurately modeling the normal behavior of the industrial cyber-physical systems (ICPSs). Current popular data-driven black-box methods’ performance depends on the quantity and quality of data from the ICPS, rather than integrating with the intrinsic characteristics of the system, such as mass conservation and structural dependencies of industrial processes. The data used to train these models often fails to cover all operating conditions of ICPSs, resulting in a distributional mismatch between training and testing data. This limitation significantly reduces the generalization capability of trained data-driven models for detecting anomalies under unseen and unknown operational conditions. Meanwhile, constructing well-generalized behavior models using white-box mechanism models (MM)–which represent the internal behavior of controllers and physical processes using first-principles equations or physical laws, such as conservation principles and kinetic dynamics–is not always feasible in real-world industrial applications. To address this issue, this paper presents a novel anomaly detection approach employing a domain knowledge-embedded hybrid graph neural network (HGNN) that integrates control, physical, and structural characteristics of ICPSs into a data-driven modeling framework. It establishes a domain knowledge-based MM to predict the behavior of controllers and physical processes, and utilizes a HGNN model with embedded state topology and spatial distribution knowledge to compensate for the predictive error of MM, forming a hybrid model called mechanism-embedded HGNN (MEHGNN). This model can detect anomalies in unknown operational conditions by analyzing the predictive error of MEHGNN. In the experiments, MEHGNN raises the detection accuracy of GNNs from 36.6 %–82.4 % to 79.4 %–96.3 % under distribution shift scenarios, achieving the best detection performance among all compared methods.},
  archive      = {J_ESWA},
  author       = {Xin Du and Chunjie Zhou and Yu-Chu Tian and Bo Xu},
  doi          = {10.1016/j.eswa.2025.129645},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129645},
  shortjournal = {Expert Syst. Appl.},
  title        = {Anomaly detection based on graph neural networks incorporating with domain knowledge for industrial cyber-physical systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predictive modeling and multi-objective optimization of screw whirling milling based on ISSA-BP embedded NSGA-III algorithm. <em>ESWA</em>, <em>298</em>, 129644. (<a href='https://doi.org/10.1016/j.eswa.2025.129644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In screw whirling milling, the relationship between machining quality and processing parameters exhibits highly nonlinear characteristics. The traditional multiple regression models may not be able to capture this complex relationship accurately. Therefore, it is necessary to consider more flexible and applicable algorithms to establish their connections and optimize processing parameters. It can improve the accuracy and reliability of products, and provide more scientific method guidance for screw whirling milling processing. The originality of this article lies in proposing an adaptive dynamic optimization hybrid model. This model combines improved sparrow search algorithm optimized backpropagation (ISSA-BP) and non-dominated sorting genetic algorithm (NSGA-III). It can effectively adapt to dynamic data and find the optimal balance point among multiple objectives to better predict and optimize responses (cutting force, vibration, roughness, and residual compressive stress) in screw whirling milling. Firstly, a suitable network structure is identified by comparing the effects of five improvement strategies, population size, and the ratio of producers to scouters on the sparrow search algorithm. Then, an ISSA-BP prediction model is developed for four responses based on this structure. On this basis, the superiority of the established ISSA-BP model is verified by comparing prediction performance of five algorithms, and the relative prediction errors are all within 2%. The R 2 values of the models are all above 0.99, and they also perform well in indicators such as MAE (Mean Absolute Error), MSE (Mean Squared Error), MAPE (Mean Absolute Percentage Error), and RMSE (Root Mean Squared Error). Then, ISSA-BP model is encapsulated and embedded into the optimization algorithm as the fitness function of NSGA-III. Finally, with the processing parameters of whirling milling as constraints, the NSGA-III algorithm is used to solve the proposed model and obtain the Pareto optimal solution set. Choosing appropriate processing parameters according to different needs in actual machining can help improve the quality and efficiency of screw machining.},
  archive      = {J_ESWA},
  author       = {Chao Liu and Hao Ding and Juanjuan Zheng and Yan He and Shaofu Huang and Junbo Tuo and Zuqing Luo and Gang Shen},
  doi          = {10.1016/j.eswa.2025.129644},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129644},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predictive modeling and multi-objective optimization of screw whirling milling based on ISSA-BP embedded NSGA-III algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A survey of large language models for data challenges in graphs. <em>ESWA</em>, <em>298</em>, 129643. (<a href='https://doi.org/10.1016/j.eswa.2025.129643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are a widely used paradigm for representing non-Euclidean data, with applications ranging from social network analysis to biomolecular prediction. While graph learning has achieved remarkable progress, real-world graph data presents a number of challenges that significantly hinder the learning process. In this survey, we focus on four fundamental data-centric challenges: (1) Incompleteness , real-world graphs have missing nodes, edges, or attributes; (2) Imbalance , the distribution of the labels of nodes or edges and their structures for real-world graphs are highly skewed; (3) Cross-domain Heterogeneity , graphs from different domains exhibit incompatible feature spaces or structural patterns; and (4) Dynamic Instability , graphs evolve over time in unpredictable ways. Recently, Large Language Models (LLMs) offer the potential to tackle these challenges by leveraging rich semantic reasoning and external knowledge. This survey focuses on how LLMs can address four fundamental data-centric challenges in graph-structured data, thereby improving the effectiveness of graph learning. For each challenge, we review both traditional solutions and modern LLM-driven approaches, highlighting how LLMs contribute unique advantages. Finally, we discuss open research questions and promising future directions in this emerging interdisciplinary field. To support further exploration, we have curated a repository of recent advances on graph learning challenges: https://github.com/limengran98/Awesome-Literature-Graph-Learning-Challenges .},
  archive      = {J_ESWA},
  author       = {Mengran Li and Pengyu Zhang and Wenbin Xing and Yijia Zheng and Klim Zaporojets and Junzhou Chen and Ronghui Zhang and Yong Zhang and Siyuan Gong and Jia Hu and Xiaolei Ma and Zhiyuan Liu and Paul Groth and Marcel Worring},
  doi          = {10.1016/j.eswa.2025.129643},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129643},
  shortjournal = {Expert Syst. Appl.},
  title        = {A survey of large language models for data challenges in graphs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Region-aware prediction strategy based on shared points and multiple scales for dynamic multi-objective optimization. <em>ESWA</em>, <em>298</em>, 129642. (<a href='https://doi.org/10.1016/j.eswa.2025.129642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic multi-objective optimization problems, effectively predicting and tracking the Pareto optimal front (POF) under environmental changes has been one of the core challenges. In this paper, we propose a region-aware prediction strategy based on shared points and multiple scales (RADMOEA) that combines global and local characteristics, aiming to enhance the algorithm’s ability to sense and adapt to POF. Firstly, the center-point movement strategy is used to move the non-dominated solution set from the previous moment to obtain the non-dominated solution set after the movement. The actual non-dominated solution set at the current moment and the non-dominated solution set after the movement share points in the objective space, and these shared points divide the non-dominated solution set at the current moment into several subregions. Within each region, all individuals are appropriately rescaled, and a local coordinate system is established. Then, within the local coordinate system, each individual is associated with the nearest post-movement non-dominated individual. Finally, new populations adapted to environmental changes are generated by combining centroid movement directions, Gaussian perturbations, and multi-scale individual association relationships. The proposed strategy is compared with six advanced algorithms, and the experimental results demonstrate that RADMOEA is effective in tracking the POF under dynamic environments.},
  archive      = {J_ESWA},
  author       = {Yaru Hu and Sitong Wang and Junwei Ou and Zhenlin Mei and Juan Zou and Shengxiang Yang},
  doi          = {10.1016/j.eswa.2025.129642},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129642},
  shortjournal = {Expert Syst. Appl.},
  title        = {Region-aware prediction strategy based on shared points and multiple scales for dynamic multi-objective optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A transformer network for multi-dimensional nonuniform aperture synthesis radiometer image inversion. <em>ESWA</em>, <em>298</em>, 129641. (<a href='https://doi.org/10.1016/j.eswa.2025.129641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Passive microwave remote sensing plays a vital role in Earth observation, with applications in soil moisture, ocean salinity, and atmospheric monitoring. However, improving spatial resolution at low frequencies remains challenging. Recently, combining multiple small antenna arrays into a larger one has emerged as a technological approach to enhance spatial resolution. Nevertheless, aperture synthetic radiometers formed by such combinations usually consist of non-uniform antenna arrays (one-dimensional, two-dimensional, or three-dimensional). Compared with regular antenna arrays, they complicate the inversion of brightness temperature (BT) images. This paper proposes NASRT, a transformer-based inversion method designed for multi-dimensional non-uniform ASRs. The network extracts and fuses spectral and UVW spatial distribution features from the visibility function (VF), and introduces a learnable position weight matrix during training to capture spatial information of the non-uniform array. Through supervised learning, NASRT effectively maps the VF to BT images. Simulations across 1-D, 2-D, and 3-D NASR scenes demonstrate that NASRT achieves higher accuracy and stability than traditional methods. In a 1-D NASR indoor experiment, the proposed method also shows improved inversion accuracy and lower sidelobes, validating its effectiveness.},
  archive      = {J_ESWA},
  author       = {Jian Dong and Jiaxin Li and Chengwang Xiao and Rigeng Wu and Haofeng Dou and Wenjing Wang and Yuanchao Wu and Liangbing Chen},
  doi          = {10.1016/j.eswa.2025.129641},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129641},
  shortjournal = {Expert Syst. Appl.},
  title        = {A transformer network for multi-dimensional nonuniform aperture synthesis radiometer image inversion},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OceanAgent: A small-scale multi-modal assistant for ocean exploration. <em>ESWA</em>, <em>298</em>, 129640. (<a href='https://doi.org/10.1016/j.eswa.2025.129640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extraction of key information and the subsequent generation of actionable knowledge from multimodal data are critical for ocean exploration. Traditional knowledge generation methods rely heavily on expert experience and are labor-intensive. Recently, Large Multimodal Models (LMMs) have shown exceptional capabilities for knowledge generation from multimodal data in many complex tasks. These models also have potential to assist knowledge mining in ocean exploration. However, two major challenges faced by the LMMs when used in ocean exploration include the scarcity of ocean instruction-following data and the degradation of underwater visual environments. In this paper, a small-scale LMM for ocean exploration, named the OceanAgent, is designed. First, a swarm-intelligence-based leaderless multi-agent collaboration framework is proposed to generate visual instruction-following data. Subsequently, we present a visual-language connector to simultaneously extract multi-scale features. It is formed by integrating a multi-scale residual network with a multi-layer perceptron, which can enhance the model’s performance on severely low-quality images. Experiments show that the proposed method for constructing visual instruction-following datasets improves both the textual quality and visual dialogue. When severely degraded ocean visual data are processed using the trained OceanAgent, the image description accuracy and image comprehension are improved by 23.6 % and 21.6 %, respectively, compared to existing models. Additionally, the model demonstrates superior domain expertise, with a 95.7 % win rate in dialogue quality assessments.},
  archive      = {J_ESWA},
  author       = {Yun Xu and Yue Liu and Junpeng Shang and Jianmin Lin and Dongfang Ma},
  doi          = {10.1016/j.eswa.2025.129640},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129640},
  shortjournal = {Expert Syst. Appl.},
  title        = {OceanAgent: A small-scale multi-modal assistant for ocean exploration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPS-GAD: Spectral-spatial graph structure learning for anomaly detection in heterophilic graphs. <em>ESWA</em>, <em>298</em>, 129639. (<a href='https://doi.org/10.1016/j.eswa.2025.129639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection(GAD) plays a critical role in fields such as fraud detection and network security. Although existing graph anomaly detection methods have achieved promising performance, most graph neural networks (GNNs) rely on the homophily assumption, which presumes that connected nodes share similar labels. However, real-world graphs frequently exhibit pronounced heterophily. Owing to class imbalance, normal nodes tend to have lower heterophily while anomalous nodes display higher heterophily. Furthermore, feature inconsistency induced by node camouflage exacerbates the detection challenge, rendering many existing approaches ineffective. To overcome these limitations, we propose SPS-GAD, a spectral-spatial graph structure learning framework specifically designed for detecting anomalous nodes in heterophilic graphs. First, to alleviate the feature inconsistency resulting from node camouflage, we develop a node reconstruction module that learns intermediate node representations to mitigate camouflage-induced bias, and applies spectral filters to extract the graph’s inherent structural features. Second, to address the heterophily disparities arising from class imbalance, we introduce a subgraph-type-aware spectral filtering module that leverages edge scores generated by an edge partitioner to segregate the graph into homophilic, ambiguous, and heterophilic subgraphs. Distinct spectral filters are subsequently applied to capture features across various frequency bands. Additionally, we integrate a neighbor-type-aware graph attention module that employs edge scores within an attention mechanism to guide the feature aggregation process, thereby enhancing spatial representation learning. Experimental evaluations on six real-world datasets reveal that SPS-GAD significantly outperforms all baseline methods in key metrics such as F1-Macro and AUC, thereby confirming its effectiveness in graph anomaly detection. The source code is publicly available at https://github.com/cozy24/SPS-GAD .},
  archive      = {J_ESWA},
  author       = {Chen Zhu and Yaying Zhang},
  doi          = {10.1016/j.eswa.2025.129639},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129639},
  shortjournal = {Expert Syst. Appl.},
  title        = {SPS-GAD: Spectral-spatial graph structure learning for anomaly detection in heterophilic graphs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient vision transformer-based 3D adaptive residual densenet with gated recurrent unit for early detection of alzheimer disease from magnetic resonance imaging. <em>ESWA</em>, <em>298</em>, 129638. (<a href='https://doi.org/10.1016/j.eswa.2025.129638'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precise identification of Alzheimer’s disease (AD) holds a crucial position in patient healthcare, particularly in the early stages. This early detection is essential, as it allows patients to understand the severity of the disease and take preventive measures before irreversible brain damage occurs. Although recent studies have harnessed machine learning techniques for Computer-Aided Diagnosis (CAD) of AD, many of these research efforts have encountered limitations in diagnostic performance. In this research, a novel AD detection system using Magnetic Resonance Imaging (MRI) is developed to identify subtle brain changes at an early stage through deep learning strategies. The goal is to reduce the risk for individuals facing challenges such as aging and brain-related diseases. The MRI images were obtained from the internet. The detection phase begins by receiving the MRI images. A Vision Transformer-based 3D Adaptive Residual DenseNet combined with a Gated Recurrent Unit (VARD-GRU) architecture is employed for effective AD identification. Here, the model parameters are optimized using the proposed Fitness-based Walrus Optimization Algorithm (FWOA). The AD detection system’s performance is evaluated against several existing frameworks using validation metrics to assess its effectiveness. The accuracy of the developed FWOA-VARD-GRU model is 94.11%. The results demonstrate that the FWOA-VARD-GRU model significantly enhances diagnostic accuracy, outperforming comparable methods. The model’s effectiveness confirms its strong capability in detecting early-stage AD. This system offers a promising approach to reduce risks for individuals affected by aging and neurological conditions by enabling timely and accurate detection.},
  archive      = {J_ESWA},
  author       = {Dr. A. Hemlathadhevi and Indumathy Paranthaman and Moorthy Agoramoorthy and Dr. Hari Kumar Palani},
  doi          = {10.1016/j.eswa.2025.129638},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129638},
  shortjournal = {Expert Syst. Appl.},
  title        = {An efficient vision transformer-based 3D adaptive residual densenet with gated recurrent unit for early detection of alzheimer disease from magnetic resonance imaging},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Pareto optimization of two-agent scheduling on parallel batch machines. <em>ESWA</em>, <em>298</em>, 129637. (<a href='https://doi.org/10.1016/j.eswa.2025.129637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a Pareto optimization problem of scheduling jobs of two competing agents on parallel batch machines. The jobs have equal processing times and non-identical job sizes. The objective is to find Pareto optimality and the corresponding schedules for minimizing both agents’ makespans. We analyze and identify an approximate Pareto region with a guarantee of 2-approximate Pareto optimal. We propose an integrated algorithm to find the approximate Pareto optimal points. Our computational study shows that the proposed algorithm outperforms the widely used non-dominated sorting genetic algorithm (NSGA-II), and that the obtained approximate Pareto optimal front is very close to the Pareto optimal front.},
  archive      = {J_ESWA},
  author       = {Cui-Lin Zhang and Guo-Qiang Fan},
  doi          = {10.1016/j.eswa.2025.129637},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129637},
  shortjournal = {Expert Syst. Appl.},
  title        = {Pareto optimization of two-agent scheduling on parallel batch machines},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid fleet composition and scheduling for road-based cross-border logistics under cost differentiation: A bi-level programming approach. <em>ESWA</em>, <em>298</em>, 129636. (<a href='https://doi.org/10.1016/j.eswa.2025.129636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the dual pressure of explosive growth in cross-border e-commerce demand and increasing timeliness requirements from overseas customers, cross-border logistics service providers are compelled to establish logistics facilities and deploy fleets across multiple regions to ensure rapid response. However, during freight transportation, the lack of effective management over these complex and heterogeneous fleets—particularly in terms of fleet composition and routing decisions—has led to high transportation costs and low operational efficiency. This study is grounded in the practical operational context of cross-border logistics in the Guangdong–Hong Kong–Macau Greater Bay Area and models a multi-level, multi-node cross-border transportation network. To minimize the overall operational cost, the problem is addressed from two interrelated decision-making perspectives: fleet composition at the strategic level and routing planning at the operational level. Thus, a bi-level programming model is proposed to systematically capture the hierarchical structure and the logical relationship between these two decision layers. Furthermore, the model incorporates cost differences among trucks with different functional capabilities to reflect the significant disparity in logistics cost structures between domestic and overseas operations. To address the above multi-objective mixed-integer linear programming (MILP) problem, a tailored Non-dominated Sorting Genetic Algorithm II (MNSGA-II) is developed. Several key components of the algorithm are modified and enhanced to improve its search efficiency and solution quality in handling the problem’s complexity. Comparative experiments against classical algorithms demonstrate the superior solution quality and robustness of the proposed approach. The influence of cost differentials on composition and scheduling decisions is further analyzed, providing practical insights for the strategic planning of cross-border logistics systems.},
  archive      = {J_ESWA},
  author       = {Zhi Tang and Ting Qu and Yanghua Pan and George Q. Huang},
  doi          = {10.1016/j.eswa.2025.129636},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129636},
  shortjournal = {Expert Syst. Appl.},
  title        = {Hybrid fleet composition and scheduling for road-based cross-border logistics under cost differentiation: A bi-level programming approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A diversity-based niching differential evolution with neighborhood competition for nonlinear equation systems. <em>ESWA</em>, <em>298</em>, 129635. (<a href='https://doi.org/10.1016/j.eswa.2025.129635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving nonlinear equation systems (NESs) has long been a fundamental challenge in the field of optimization. Due to the existence of multiple roots, such problems often exhibit complex and multimodal characteristics. Although numerous differential evolution-based algorithms have been developed to solve NESs, most of them employ only a single mutation operator, which is not adaptable to different problem scenarios. To this end, a diversity-based niching differential evolution with neighborhood competition (DNDE) is proposed to solve NESs. First, a control mechanism that takes into account population diversity and the evolutionary stage is proposed to adaptively assign appropriate mutation strategies to each subpopulation (niche), thereby enhancing the efficiency of root-finding. Second, a neighborhood priority competition mechanism is proposed to reduce cross-peak competition between populations, which ensures local convergence while improving global convergence. Finally, a reinitialization strategy based on opposition learning is introduced to guide the population toward more promising areas of the search space. Experimental results on 18 complex NESs and two real-world engineering problems show that DNDE outperforms many advanced algorithms in both root rate and success rate, demonstrating its effectiveness and value in practical applications.},
  archive      = {J_ESWA},
  author       = {Jianwei Li and Xinchao Zhao and Lingyu Wu and Yizhan Wu and Lingjuan Ye},
  doi          = {10.1016/j.eswa.2025.129635},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129635},
  shortjournal = {Expert Syst. Appl.},
  title        = {A diversity-based niching differential evolution with neighborhood competition for nonlinear equation systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Ill-posed regions-aware self-supervised stereo matching with left-right consistency. <em>ESWA</em>, <em>298</em>, 129634. (<a href='https://doi.org/10.1016/j.eswa.2025.129634'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stereo matching presents a significant challenge due to the difficulty in accurately matching pixels between two images. These challenging pixels are typically found in ill-posed regions, which include areas with weak or repetitive textures, occlusions, and invisible regions. In recent years, there has been extensive research into stereo matching methods based on deep learning. However, these methods often struggle to accurately handle ill-posed regions, resulting in limited improvements in accuracy. To address this issue, this paper introduces a stereo matching model, IASSM-LRC, that is not constrained by disparity range. This model employs self-attention and cross-attention from the Transformer for dense attention computation and generates an initial disparity map. To effectively manage ill-posed regions, invalid masks are generated using left and right disparity maps. The initial disparity map is then fine-tuned through these invalid masks. IASSM-LRC is trained in an unsupervised manner. Experimental results from multiple different scenes demonstrate that the IASSM-LRC model exhibits strong disparity prediction performance. On KITTI2015, its D1-fg metric is 13.48 %, outperforming both PASM-Net’s 16.36 % and Flow2Stereo’s 14.62 %. The prediction results on the self-built calibration board dataset and Middlebury dataset show that the model has better predictive performance for both textureless and repetitive texture regions and has better generalization performance.This method can improve disparity measurement and depth measurement in binocular universal scenes.},
  archive      = {J_ESWA},
  author       = {Shengwei Yang and Yuehang Wang and Zenghui Li and Shan Zhou and Zheng Wang and Yining Hu and Lizhe Xie},
  doi          = {10.1016/j.eswa.2025.129634},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129634},
  shortjournal = {Expert Syst. Appl.},
  title        = {Ill-posed regions-aware self-supervised stereo matching with left-right consistency},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TGNet: Texture-enhanced guidance network for RGB-D salient object detection. <em>ESWA</em>, <em>298</em>, 129633. (<a href='https://doi.org/10.1016/j.eswa.2025.129633'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D salient object detection achieves salient region localization in complex scenes by fusing RGB images and depth images. Existing methods typically employ two-stream networks to extract features separately followed by cross-modal fusion. However, differences between heterogeneous modalities can easily lead to feature degradation during cross-modal fusion, while the inherent noise interference in low-quality depth maps may generate cumulative effects during multi-stage propagation, severely constraining detection performance. To address these challenges, this paper proposes a texture-enhanced guided network. The core innovations lie in three aspects: during the feature encoding stage, a texture-enhanced module is constructed to utilize high-frequency texture information from RGB images through attention mechanisms for hierarchical optimization of depth features; in the feature fusion stage, a dual-path adaptive interaction module is designed to establish cross-modal semantic correlations via channel-spatial cooperative driving mechanisms, effectively suppressing redundant feature interference; for the decoding reconstruction stage, a dynamic hierarchical guidance mechanism is proposed to drive progressive calibration of low-level spatial details by high-level semantic features through learnable cross-scale transformation modules. Extensive experiments conducted on five benchmark datasets demonstrate that our method achieves competitive performance compared to other approaches.},
  archive      = {J_ESWA},
  author       = {Xiaogang Song and Hexiang Huang and Qin Zhao and Xinwei Guo and Xinhong Hei},
  doi          = {10.1016/j.eswa.2025.129633},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129633},
  shortjournal = {Expert Syst. Appl.},
  title        = {TGNet: Texture-enhanced guidance network for RGB-D salient object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-stream temporal-spatial forgery detection via phase-consistent edge features and 3D visual state-space modeling. <em>ESWA</em>, <em>298</em>, 129632. (<a href='https://doi.org/10.1016/j.eswa.2025.129632'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deepfake, as a generative technology, has opened up new avenues for the development of the film, television, and art industries. However, its abusive use has triggered serious social security threats, such as infringement of portrait rights and the spread of misinformation, which has drawn widespread attention to research on deepfake detection techniques. Current deep learning-based face forgery detection methods face critical challenges: 1) insufficient focus on common forgery traces leads to poor generalization performance on datasets generated by unknown forgery methods; 2) traditional spatio-temporal feature fusion mechanisms struggle to balance the representational weights of spatial details and temporal dynamics, and exhibit inadequate robustness against post-processing operations like compression and cropping. To address these issues, this paper first designs a phase consistency edge artifact mining module is designed to extract common forgery traces from edge textures by leveraging the deep-phase information of images, significantly enhancing the model’s generalization ability. Second, a multi-frame synthesis strategy is designed to effectively integrate spatial and temporal features while balancing the network’s attention to these two feature domains. Third, a visual state-space model based on 3D scanning is designed, which for the first time employs the Mamba model to analyze spatio-temporal forgery patterns, notably improving the robustness of the model against unknown perturbations. Experimental results on standard benchmarks–FaceForensics++, Celeb-DFv2, WildDeepfake and DFDC(Preview)–demonstrate that the proposed method achieves state-of-the-art performance in three core dimensions: detection accuracy, cross-dataset generalization, and robustness against perturbations.},
  archive      = {J_ESWA},
  author       = {Zhong Chen and Siyang Wang and Zuxi Wang},
  doi          = {10.1016/j.eswa.2025.129632},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129632},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-stream temporal-spatial forgery detection via phase-consistent edge features and 3D visual state-space modeling},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LSTT: Long short-term feature enhancement transformer for video small object detection. <em>ESWA</em>, <em>298</em>, 129631. (<a href='https://doi.org/10.1016/j.eswa.2025.129631'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging temporal information is crucial for small object detection in videos. Existing methods typically incorporate long-term or short-term temporal information uniformly, neglecting distinct cues from different frames that are essential for small object detection. In this paper, we propose LSTT, an end-to-end multi-frame fusion network that concurrently extracts global scene context from long-term frames and fine-grained appearance and motion cues from short-term frames. First, we introduce a progressive spatiotemporal sampling module that sparsely samples long-range frames and densely samples short-range frames. Second, we design a spatiotemporal alignment encoder module to extract frame-level temporal and spatial pixel features. Finally, We propose a long short-term feature aggregation module that employs a dynamic query generator to derive adaptive queries by implicitly modeling motion relationships among short-term frames, and guides a cascaded fusion of aggregated features from long-term, short-term, and current frames to fuse temporal information. Compared to state-of-the-art methods, our LSTT achieves absolute gains of 1.4 % and 2.1 % in detection precision on VisDrone-VID and UAVDT datasets, respectively.},
  archive      = {J_ESWA},
  author       = {Jinsheng Xiao and Wenbo Liu and Ruidi Chen and Yuchen Yan and Wei Yang},
  doi          = {10.1016/j.eswa.2025.129631},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129631},
  shortjournal = {Expert Syst. Appl.},
  title        = {LSTT: Long short-term feature enhancement transformer for video small object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scale-invariant information bottleneck for domain generalization. <em>ESWA</em>, <em>298</em>, 129628. (<a href='https://doi.org/10.1016/j.eswa.2025.129628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One significant challenge in deep learning is the inability to effectively generalize to new data whose distribution differs from that of the training data. Hence, domain generalization has received increasing attention in related fields. Classical methods aim to identify an invariant predictor that can recognize invariant representations across all the training domains. However, these methods limit the model to rely solely on invariant representations, which hinders the learning of important finer details. To address this challenge, we propose a Scale-invariant Information Bottleneck (SIB) method to identify both invariant and scale-invariant features. We subsequently introduce a tractable loss function derived from the variational analysis. This novel method captures more detailed information, including fine textures and unique characteristics, while also eliminating irrelevant or spurious representations by using information bottleneck. Finally, extensive experiments conducted on Rotated MNIST, Colored MNIST, Colored Fashion-MNIST, PACS, Office-Home and Camelyon17-WILDS validate the effectiveness of our SIB method in addressing the domain generalization problems. Notably, our approach outperforms 14 existing methods with an average improvement of 4.74 %. More significantly, it surpasses 6 recent, related methods by an average of 2.21 %. Furthermore, we demonstrate the superiority of our method through the analysis of hidden feature maps and representations.},
  archive      = {J_ESWA},
  author       = {Mengyao Li and Jiangshe Zhang and Chunxia Zhang and Junmin Liu and Lizhen Ji},
  doi          = {10.1016/j.eswa.2025.129628},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129628},
  shortjournal = {Expert Syst. Appl.},
  title        = {Scale-invariant information bottleneck for domain generalization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal pricing for transfer of development rights under risk sharing: The context of china’s inter-provincial construction land quota trading. <em>ESWA</em>, <em>298</em>, 129627. (<a href='https://doi.org/10.1016/j.eswa.2025.129627'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific and rational prices are determinant for the success of transfer of development rights (TDR). Nevertheless, previous studies largely overlook the multifaceted impacts of risks on pricing, hampering market participation and value revelation. This is especially relevant in the context of China’s inter-provincial construction land quota trading due to its broader scope and dynamic complexities. This study addresses this gap by proposing an integrated decision-making framework to identify TDR risk factors and determine the optimal pricing for TDR under risk sharing. Results show that among 28 identified risk factors across the trading lifecycle, pre-transaction (remediation application and remediation acceptance) risk factors exhibit lower weights (0.017 and 0.218) but demand greater responsibility from quota-sending governments (80.5% and 73.0%); quota transfer risk factors hold the highest weight (0.306), with nearly balanced responsibility sharing between trading parties; while post-transaction (remediation acceptance and post monitoring) risk factors (weighted at 0.215 and 0.218) should be borne mainly by quota-receiving governments (64.1% and 60.9%). A paradigmatic trading case study between Muli and Jiashan Counties empirically reveals that risk factors elevate the optimal price to 621171.89 yuan/mu—24.23% above the current national standard price—by increasing costs, reducing profits, decreasing the supply–demand ratio, and complicating ecological compensation. These findings underscore the importance of risk responsibility management and risk-based pricing mechanisms.},
  archive      = {J_ESWA},
  author       = {Jia-He Zhou and Yu-Jia Wei and Yu-Ming Zhu and Hong-Li Lin},
  doi          = {10.1016/j.eswa.2025.129627},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129627},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimal pricing for transfer of development rights under risk sharing: The context of china’s inter-provincial construction land quota trading},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent urban on-street parking space management for autonomous vehicles. <em>ESWA</em>, <em>298</em>, 129626. (<a href='https://doi.org/10.1016/j.eswa.2025.129626'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curbside lanes are valuable spatial assets, with on-street parking, driving, and other travel modes competing for the space. Autonomous vehicle (AV) transport is expected to park at the curbside for diverse purposes, raising conflicts between driving and parking in the city centre. This study presents a framework to determine on-street parking configurations under different traffic flow and parking supply scenarios for the downtown region. The main contribution stems from solving the macro-level parking configuration problem using customised metaheuristics while considering microscopic AV operations. We tested the framework using a road network comprising a downtown central business district and adjacent urban areas. Among the considered metaheuristics, the discrete particle swarm optimisation outperformed the genetic algorithm in minimising network-level travel delays but at the cost of higher computational time. Three main empirical findings are derived. First , parking lanes are more likely to be assigned to edges in downtown areas or those with lower traffic and driving speeds. Second , high parking supply negatively affects the macroscopic fundamental diagram by increasing congestion and reducing flow efficiency, but such an effect diminishes in congested networks. Third , there exists an optimal parking supply level (40 % in the case study) for most flow rate conditions that can help reduce congestion. The proposed framework was validated through a case study in Midtown Manhattan, New York City. This study provides valuable insights for urban and transportation agencies to manage on-street parking lane assignments to balance parking and driving demands in the AV transport era. The approach has broader applicability as it is transferable to human-driven vehicles and mixed autonomy scenarios.},
  archive      = {J_ESWA},
  author       = {Qiming Ye and Prateek Bansal and Yuxiang Feng and Simon Hu and Panagiotis Angeloudis},
  doi          = {10.1016/j.eswa.2025.129626},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129626},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent urban on-street parking space management for autonomous vehicles},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-session interest extraction for recommendation. <em>ESWA</em>, <em>298</em>, 129625. (<a href='https://doi.org/10.1016/j.eswa.2025.129625'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, due to device privacy restrictions, sometimes we can only obtain anonymous users’ interaction behavior within a single session. This type of recommendation is called session-based recommendation. Modeling users’ interest based on session data is one of the core issues in session-based recommendation. However, most existing methods only model users’ interest within individual sessions, neglecting information propagation across sessions. This paper addresses this challenge by designing a contrastive learning module based on clustering to model inter-session information propagation. Specifically, in addition to propagating information within sessions using hypergraph convolution, a cluster algorithm is applied to group all nodes across sessions. Then a contrastive learning loss is designed based on the clustering results to facilitate information propagation across sessions, thereby explicitly modeling the semantic similarity of similar items across different sessions. We call our model Clustering Hypergraph Neural Network (CluHNN). CluHNN explicitly learns the correlation between similar items across different sessions, improving the quality of item representations and, consequently, yielding better interest representations through cross-session information propagation. Experimental results on two real-world datasets show the effectiveness of the proposed CluHNN. For example, in terms of MRR@20, CluHNN achieves significant improvements of 1.3 % and 2.0 % relative gains over the strongest baseline, respectively.},
  archive      = {J_ESWA},
  author       = {Jin Jin and Chaoqun Li and Liangxiao Jiang},
  doi          = {10.1016/j.eswa.2025.129625},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129625},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-session interest extraction for recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Incorporating estimated depth maps and multi-modal pretraining to improve salient object detection in optical remote sensing images. <em>ESWA</em>, <em>298</em>, 129624. (<a href='https://doi.org/10.1016/j.eswa.2025.129624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a burgeoning theme in optical remote sensing image (ORSI) analysis, salient object detection (SOD) plays a vital role in traffic monitoring, agriculture, disaster management, and other fields. However, the existing ORSI-SOD methods are all single-modal (RGB images primarily), which suffer from performance drop when facing complex scenes (e.g., intricate backgrounds, low contrast scenes, and similar objects). To address this challenge, we introduce estimated depth map to complement RGB image in ORSI-SOD for the first time, which provides 3D geometric cues to improve detection accuracy in complex scenes, thus advancing ORSI-SOD from single-modal to multi-modal. Furthermore, we design a novel pretraining framework: multi-modal reconstructed image pretraining (MMRIP) to pretrain SOD model in multi-modal ORSI-SOD. MMRIP initially utilizes a masked autoencoder (MAE) to restore the masked RGB image; subsequently, it feeds the restored RGB image and clean depth map to the SOD model to generate the saliency map, which can help SOD model more effectively integrate cross modal information and extract better feature. Besides, we present a simple RGB-D SOD model, namely SimSOD, which is pretrained by MMRIP for ORSI-SOD. SimSOD has two major components: DFormer (encoder) and MLP head (decoder). Specifically, we first input RGB image and depth data into the encoder to generate four multi-scale features, then use the decoder to fuse these features and yield the prediction result. Without bells and whistles, our proposed method outperforms the state-of-the-art methods on three public ORSI-SOD datasets. The code can be accessed at: https://github.com/Voruarn/MMRIP .},
  archive      = {J_ESWA},
  author       = {Yuxiang Fu and Wei Fang},
  doi          = {10.1016/j.eswa.2025.129624},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129624},
  shortjournal = {Expert Syst. Appl.},
  title        = {Incorporating estimated depth maps and multi-modal pretraining to improve salient object detection in optical remote sensing images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An approach for linking dynamic network information models based on ontology matching. <em>ESWA</em>, <em>298</em>, 129622. (<a href='https://doi.org/10.1016/j.eswa.2025.129622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic network information models are typically heterogeneous and isolated systems that impede effective interoperability, significantly hindering end-to-end service integration and data sharing across network segments. To address this challenge, we propose a new approach for linking heterogeneous dynamic network models based on ontology matching, which can be applied in various domains utilizing dynamic networks. For ontologies matching we use different existing duplicate detection algorithms but we reduce the computational complexity of ontology matching due to splitting initial set of matched entities into a number of subsets using domain knowledge. Using telecommunications as case study, we represent operator networks as knowledge graphs and match them with standardized model ontologies using business process context to create an Extended Operator Network Ontology. Our approach ensures linking of dynamic network models used in operators information systems that is of primary importance for implementing complex business processes, and providing integrated services while maintaining existing models.},
  archive      = {J_ESWA},
  author       = {Tianxing Man and Igor Kulikov and Jiafeng Yang and Nataly Zhukova},
  doi          = {10.1016/j.eswa.2025.129622},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129622},
  shortjournal = {Expert Syst. Appl.},
  title        = {An approach for linking dynamic network information models based on ontology matching},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved differential evolution algorithm combined with vector NFP and mixed-integer programming for solving 2D irregular layout problem. <em>ESWA</em>, <em>298</em>, 129621. (<a href='https://doi.org/10.1016/j.eswa.2025.129621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-dimensional irregular layout problem, which involves placing convex or non-convex components within a confined boundary without overlaps, is NP-complete and widely encountered in industrial applications such as glass cutting, garment manufacturing, and packaging. To overcome the limitations of existing methods in computational efficiency and material utilization, we propose a new hybrid algorithm IDE-V-NFP-MIP: (1) An improved differential evolution (IDE) algorithm combines the memory mechanism to guide the crossover and mutation operations; (2) A vector No-Fit Polygon (V-NFP) algorithm effectively handles complex geometric constraints, including voids and degradation; (3) A mixed-integer programming (MIP) model ensures accurate layout and non-overlapping constraints. Experimental results demonstrate superior performance: IDE ranked first in CEC2022 Friedman tests, while practical applications show 22.10% reduction in board length and 41.47% improvement in filling rate. The framework successfully handles real-world garment cutting applications and large-scale problems up to 1,280 polygons, demonstrating significant improvements in both computational efficiency and solution quality for industrial layout optimization. The source code for the algorithm is available at https://github.com/xhj-6/IDE-V-NFP-MIP .},
  archive      = {J_ESWA},
  author       = {Huijie Xu and Qifang Luo and Yongquan Zhou},
  doi          = {10.1016/j.eswa.2025.129621},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129621},
  shortjournal = {Expert Syst. Appl.},
  title        = {An improved differential evolution algorithm combined with vector NFP and mixed-integer programming for solving 2D irregular layout problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent localization of FDIA in smart grids: A multi-level wavelet spatio-temporal graph embedding approach. <em>ESWA</em>, <em>298</em>, 129620. (<a href='https://doi.org/10.1016/j.eswa.2025.129620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of smart grid security, the precise identification of False Data Injection Attack (FDIA) is crucial for ensuring the stable operation of power systems. Existing approaches for handling measurement data often overlook the correlation between local time–frequency variations caused by FDIA nodes and global spatial information in analyzing measurement data, leading to inaccurate localization. To address this issue, we propose a novel approach: a multilevel wavelet spatio-temporal map embedded FDIA localization method. Initially, a multi-resolution time–frequency signal decomposition model is utilized to separate the time–frequency mutation signals induced by FDIA from the measurement data using fast wavelet transform. Subsequently, a multi-channel time–frequency feature extraction technique is developed to capture the mutation characteristics of FDIA in time–frequency signals. This involves extracting detailed features of the time–frequency signals pre and post-attack via a multi-channel convolution operation encompassing “temporal-local-global” aspects. Finally, we propose an FDIA localization model based on multi-level graph wavelet embedding. The model embeds spatio-temporal information into time–frequency features via graph wavelet convolution and builds a spatio-temporal dependency map through multi-level neighborhood sampling. To mitigate measurement loss and noise, graph smoothing regularization and graph dropout are introduced during training. A graph attention mechanism further captures spatio-temporal dependencies among nodes, enabling accurate FDIA localization. Experimental results verify the effectiveness of the proposed method.},
  archive      = {J_ESWA},
  author       = {Zhaoyang Qu and Feng Liang and Nan Qu and Tao Jiang and Xiaoyu Xu},
  doi          = {10.1016/j.eswa.2025.129620},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129620},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent localization of FDIA in smart grids: A multi-level wavelet spatio-temporal graph embedding approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-driven 5G-IoT optimization: Q-learning for real-time energy and network resource management. <em>ESWA</em>, <em>298</em>, 129619. (<a href='https://doi.org/10.1016/j.eswa.2025.129619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the integration of the 5G-enabled Internet of Things has revolutionized through high-speed data transmission, ultra-low latency, and interconnectivity of massive devices. However, the proliferation of 5G-enabled Internet of Things introduces major challenges, such as energy inefficiency and unreliable data delivery in the resource constrained Internet of Things devices. This research proposes a novel Q-Learning-based optimization framework tailored to address these challenges by integrating Radio Frequency energy harvesting, adaptive beamforming, and dynamic resource allocation within the massive Multiple-Input-Multiple-Output system. The proposed model utilizes reinforcement learning to manage the network resources including modulation schemes, beamforming, and energy allocation. By modeling the optimization problem as a Markov Decision Process, the proposed framework dynamically adapts to real-time network conditions to enhance energy efficiency, reliable data delivery, and throughput. The experimental validation demonstrates that the Q-Learning-based strategy effectively optimizes the energy efficiency as well as data transmission and achieves a higher energy efficiency of 98.87 %, higher packet delivery ratio of 98.85 %, lower latency of 1.5 ms, and higher throughput of 200Mbps compared to existing methodologies. This result indicates that the proposed Q-Learning-based framework has the potential to enhance the sustainability and reliability of the 5G-enabled Internet of Things.},
  archive      = {J_ESWA},
  author       = {Bavethra Murthy and Palani Uthirapathy},
  doi          = {10.1016/j.eswa.2025.129619},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129619},
  shortjournal = {Expert Syst. Appl.},
  title        = {AI-driven 5G-IoT optimization: Q-learning for real-time energy and network resource management},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-behavioral recommendation algorithm based on decoupled graph convolution. <em>ESWA</em>, <em>298</em>, 129618. (<a href='https://doi.org/10.1016/j.eswa.2025.129618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommendation models primarily rely on display feedback and typically utilize a single type of user-item interaction data, which often results in significant data sparsity issues. In contrast, multi-behavioral recommendation models leverage various behaviors such as browsing, favoriting, and other interactions. These additional behaviors help improve the prediction of user-item interactions. Existing multi-behavioral recommendation methods often overlook the potential factors influencing multi-behavioral interactions and the differences between various behavior types. In this study, we introduce a multi-behavioral recommendation algorithm utilizing decoupled graph convolution (MBR-DGC), which effectively mitigates the data sparsity of the target behaviors and improves recommender system performance by capturing the differences between the semantics of different behaviors. Specifically, we construct multiple non-overlapping independent isomorphic graphs and separate potential factors affecting the interactions among users, items, and behaviors using decoupled convolutional networks to reconstruct the node features of users in different behaviors. Afterwards, multi-behavioral features of users are aggregated using contrastive learning to achieve personalized multi-behavioral information aggregation. Experimental results on multiple datasets show that MBR-DGC effectively leverages multi-behavioral data, significantly enhancing recommendation performance compared to other state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xu Yu and Pengju Ding and Jie Yu and Junyu Lin and Lei Guo and Guanfeng Liu and Liang Xi},
  doi          = {10.1016/j.eswa.2025.129618},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129618},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-behavioral recommendation algorithm based on decoupled graph convolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An information aggregation decision making method for UAV swarm intelligence system based on joint communication and proximal strategy. <em>ESWA</em>, <em>298</em>, 129617. (<a href='https://doi.org/10.1016/j.eswa.2025.129617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swarm intelligence aggregation system represents a key capability in current-generation UAV swarm, demonstrating robust collective intelligence. Currently, leveraging Multi-Agent Deep Reinforcement Learning (MADRL) offers a promising approach for building UAV swarm intelligence aggregation systems. However, the MADRL methods are difficult to cope with the challenge of exponential increase in computation when facing the collaboration problem of large-scale swarms, and the agents also have the problem of partial observability of the environment. This paper proposes an Information Aggregation Decision Method for UAV swarm based on Joint Communication and Proximal Strategy (IADM-JCPS). This method designs a communication information aggregation (CIA) network to enable UAVs to gather observation information from neighbor UAVs, and uses the attention mechanism to screen important information. Then, the aggregated information is used as part of the input of the policy network to increase the information diversity of the decision-making process. Finally, the gradient clipping mechanism is used to trim the policy gradient to enhance the stability of the training process. A UAV swarm multi-target tracking (MTT) mission scenario is designed to verify the effectiveness of the proposed IADM-JCPS algorithm. Experimental results show that the proposed algorithm is superior to the baseline algorithm in terms of task collaboration and scalability.},
  archive      = {J_ESWA},
  author       = {Zhaotian Wei and Ruixuan Wei},
  doi          = {10.1016/j.eswa.2025.129617},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129617},
  shortjournal = {Expert Syst. Appl.},
  title        = {An information aggregation decision making method for UAV swarm intelligence system based on joint communication and proximal strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning-based trajectory planning for AGVs in dynamic environment. <em>ESWA</em>, <em>298</em>, 129616. (<a href='https://doi.org/10.1016/j.eswa.2025.129616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a learning-based framework for rapid trajectory planning of autonomous ground vehicles (AGVs) in dynamic environments. The approach integrates optimization techniques with deep learning to design a real-time planner capable of generating kinematically feasible trajectories. A continuous iterative method is first developed for dataset construction, enabling efficient generation of optimal trajectory sets. Based on this dataset, a neural network is trained to learn the mapping between AGV states and actions while capturing their temporal dependencies. During online planning, the trained model produces decision actions from the current state and sensor feedback, enabling real-time planning of safe and feasible trajectories. Results demonstrate the effectiveness of the proposed framework.},
  archive      = {J_ESWA},
  author       = {Runda Zhang and Zhida Xing and Senchun Chai and Yuanqing Xia and Runqi Chai},
  doi          = {10.1016/j.eswa.2025.129616},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129616},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning-based trajectory planning for AGVs in dynamic environment},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Model-agnostic post-hoc explainability for recommender systems. <em>ESWA</em>, <em>298</em>, 129608. (<a href='https://doi.org/10.1016/j.eswa.2025.129608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems often benefit from complex feature embeddings and deep learning algorithms, which deliver sophisticated recommendations that enhance user experience, engagement, and revenue. However, these methods frequently reduce the interpretability and transparency of the system. In this research, we develop a systematic application, adaptation, and evaluation of deletion diagnostics in the recommender setting. The method compares the performance of a model to that of a similar model trained without a specific user or item, allowing us to quantify how that observation influences the recommender, either positively or negatively. To demonstrate its model-agnostic nature, the proposal is applied to both Neural Collaborative Filtering (NCF), a widely used deep learning-based recommender, and Singular Value Decomposition (SVD), a classical collaborative filtering technique. Experiments on the MovieLens and Amazon Reviews datasets provide insights into model behavior and highlight the generality of the approach across different recommendation paradigms.},
  archive      = {J_ESWA},
  author       = {Irina Arévalo and Jose L. Salmeron},
  doi          = {10.1016/j.eswa.2025.129608},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129608},
  shortjournal = {Expert Syst. Appl.},
  title        = {Model-agnostic post-hoc explainability for recommender systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AERO-net: AutoEncoder-driven residual optimization network for latent bias correction of WRF-ROMS. <em>ESWA</em>, <em>298</em>, 129607. (<a href='https://doi.org/10.1016/j.eswa.2025.129607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable assessment of precipitation is crucial for incorporating meteorological and hydrological research into industrial and agricultural applications. Accurately estimating precipitation is a challenging task. In addressing this problem, we propose to develop AERO-Net, a novel deep learning framework designed to correct spatial, temporal, and amplitude biases in WRF-ROMS precipitation data. The integration of the Weather Research and Forecasting (WRF) model with the Regional Ocean Modeling System (ROMS) makes it a valuable tool for precipitation forecasting. AERO-Net incorporates autoencoders (AEs) for handling fluctuation and generalizing latent space representations, a latent module (LM) for transforming WRF-ROMS data into bias-corrected representations, a residual module (RM) for error minimization via boost, and a calibration module (CM) for improving near-zero precipitation. Empirical results show that AERO-Net achieves a balanced error reduction across precipitation cohorts grouped by intensity, reducing the macro-averaged root mean square error (macro RMSE) by 3.6 mm/day and the macro-averaged mean absolute deviation (macro MAD) by 0.68 mm/day compared to the original WRF-ROMS. AERO-Net is seen to improve the correlation coefficient (CC) by 26.32 %, increasing it from 0.38 to 0.48, in comparison to the original WRF-ROMS. These findings underscore its potential as an effective solution for enhancing precipitation estimates in high-resolution modeling systems.},
  archive      = {J_ESWA},
  author       = {Passin Pornvoraphat and Kanoksri Sarinnapakorn and Ken-Ichi Fukui and Peerapon Vateekul},
  doi          = {10.1016/j.eswa.2025.129607},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129607},
  shortjournal = {Expert Syst. Appl.},
  title        = {AERO-net: AutoEncoder-driven residual optimization network for latent bias correction of WRF-ROMS},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Contrastive learning and physics oriented evaluation for advanced segmentation in electron tomography. <em>ESWA</em>, <em>298</em>, 129606. (<a href='https://doi.org/10.1016/j.eswa.2025.129606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods are now achieving strong results for segmentation tasks, and the standard metric for evaluating methods is the Intersection over Union (IOU). However, we show in this paper that IOU is not efficient in evaluating the quality of segmentation for electron tomography (ET) images of zeolites. We perform a physics-oriented evaluation to ensure that the segmentation results yield coherent physical measures. We also formalize Mixed Supervised / Self-Supervised Contrastive Learning Segmentation (M3S-CLS), a semi-supervised approach using a contrastive learning approach that uses expert annotations to train the neural network model. A detailed comparison of this method with a standard cross-entropy-based model is provided. In addition, we publish a database of five fully segmented ET volumes along with corresponding baseline results. The code and the database is available at http://gitlab.univ-st-etienne.fr/labhc-iscv/M3S-CLS .},
  archive      = {J_ESWA},
  author       = {Cyril Li and Christophe Ducottet and Maxime Moreaud and Sylvain Desroziers and Valentina Girelli Consolaro and Virgile Rouchon and Ovidiu Ersen},
  doi          = {10.1016/j.eswa.2025.129606},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129606},
  shortjournal = {Expert Syst. Appl.},
  title        = {Contrastive learning and physics oriented evaluation for advanced segmentation in electron tomography},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DSANet: Deep surrounding-aware network for camouflaged object detection via cross-refinement mirror strategy. <em>ESWA</em>, <em>298</em>, 129605. (<a href='https://doi.org/10.1016/j.eswa.2025.129605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged objects often closely resemble their surroundings, causing standard RGB images to be confounded by background, texture, and color variations. This often leads to incomplete or absent target segmentation, reducing overall accuracy. To address this issue, we present a Deep Surrounding-Awareness Mirror Network (DSANet) for camouflaged object detection, leveraging depth information to expose objects incongruent with their environment, thus improving localization accuracy. First, a Convolutional Spatial Gating module processes batched RGB and depth inputs, suppressing extraneous background noise while isolating fine-grained segmentation and structural features and unifying channel representation. Subsequently, a Deep Surrounding-Awareness Localization module and a Contour-Guided Integrity Aggregation module collaboratively refine and merge multi-level features, focusing on the global form of camouflaged objects while iteratively enhancing segmentation detail. Finally, a Guided Residual Channel Attention module further refines low-layer structural cues. Extensive experiments on ten challenging benchmark datasets using four widely used evaluation metrics demonstrate that our method exhibited superior performance, outperforming 40 state-of-the-art methods. The results demonstrate the versatility of our model. The source code and results of our method are available at https://github.com/lixu11/DSANet.},
  archive      = {J_ESWA},
  author       = {Xu Li and Xiaosheng Yu and Peng Chen},
  doi          = {10.1016/j.eswa.2025.129605},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129605},
  shortjournal = {Expert Syst. Appl.},
  title        = {DSANet: Deep surrounding-aware network for camouflaged object detection via cross-refinement mirror strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FTUAttack: Feature truncation unrestricted attack based on stable diffusion model. <em>ESWA</em>, <em>298</em>, 129604. (<a href='https://doi.org/10.1016/j.eswa.2025.129604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of adversarial example generation and defense, compared to restricted attacks with L p -norm constraints, unrestricted attacks without L p -norm constraints emanate better visual imperceptibility. Existing unrestricted attacks typically manipulate the semantic content of examples (e.g. texture or color) to generate adversarial examples. However, current works usually ignore multifaceted features or loss optimization strategy, which limits attack performance. In this paper, we draw inspiration from stable diffusion model and propose a unrestricted attack method called Feature Truncation Unrestricted Attack (FTUAttack) to achieve both better transferability and imperceptibility. Specifically, we promote the performance of unrestricted attacks from the perspectives of both diffusion principle and feature truncation for the first time. Firstly, we propose a Global Deep Feature Extractor (GDFE) module to truncate global feature for the subsequent diffusion denoising process. Secondly, to further boost the transferability, we design a novel Critical Latent Feature Extractor (CLFE) module to obtain critical local feature that need to be truncated during the denoising process and investigate the influence of the different segmentation ways on critical local feature. Thirdly, we propose Multi-Loss Fusion (MLF) strategy to balance the conflict between perturbations and examples’ quality by guiding the optimization direction. Extensive experiments on various model structures and datasets demonstrate the superiority of our attack over the existing attack methods.},
  archive      = {J_ESWA},
  author       = {Shaojie Han and Gangzheng Zhai and Kun Chen and Shihui Zhang},
  doi          = {10.1016/j.eswa.2025.129604},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129604},
  shortjournal = {Expert Syst. Appl.},
  title        = {FTUAttack: Feature truncation unrestricted attack based on stable diffusion model},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial-temporal hierarchical decoupled masked autoencoder: A self-supervised learning framework for electrocardiogram. <em>ESWA</em>, <em>298</em>, 129603. (<a href='https://doi.org/10.1016/j.eswa.2025.129603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difficulty of labeling Electrocardiogram (ECG) has prompted researchers to use self-supervised learning to enhance diagnostic performance. Masked autoencoders (MAE) are a mainstream paradigm where models learn a latent representation of the signal by reconstructing masked portions of the ECG. However, existing methods lack a specific design for the spatial–temporal characteristics of ECG. Specifically, leads represent spatial projections of cardiac activity, while timestamps capture temporal patterns, and the two correspond to different axes of information. Existing MAE frameworks tend to unify them prematurely, potentially weakening critical local dependencies. In this paper, we propose a Spatial-Temporal Hierarchical Decoupled Masked Autoencoder (STHD-MAE). This framework decouples ECG into isolated leads or time steps in the shallow layer to capture local dependencies with different views, then aligns spatial–temporal representations and re-establishes global dependencies in the deep layer to comprehensively represent pathological information. We also design a medical report fusion module during pre-training, which uses cross-attention to align the ECG report text encoded by a medical language model with the signal’s latent representation, thereby guiding the encoder to focus on pathological information through implicit cross-modal learning. We validate the effectiveness of STHD-MAE on multiple downstream classification and reconstruction tasks. The results show that STHD-MAE outperforms existing self-supervised learning methods by approximately 2% in F1-scores for both coarse-grained and fine-grained classification performance, and its reconstruction quality also exceeds the baseline generative model.},
  archive      = {J_ESWA},
  author       = {Xiaoyang Wei and Zhiyuan Li and Yuanyuan Tian and Mengxiao Wang and Yanrui Jin and Weiping Ding and Chengliang Liu},
  doi          = {10.1016/j.eswa.2025.129603},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129603},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spatial-temporal hierarchical decoupled masked autoencoder: A self-supervised learning framework for electrocardiogram},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GARE-net: Geometric contextual aggregation and regional contextual enhancement network for image-text matching. <em>ESWA</em>, <em>298</em>, 129602. (<a href='https://doi.org/10.1016/j.eswa.2025.129602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The local correspondence learning has gained increasing attention in image-text matching, which establishes fine-grained alignments between image regions and textual words to improve both interpretability and accuracy. While these approaches have made significant progress in identifying meaningful semantic correspondences, one critical limitation persists in current methods, i.e., overlooking the crucial spatial position information of visual regions in cross-modal interaction. To address this challenge, we propose a novel Geometric contextual Aggregation and Regional contextual Enhancement Network (GARE-Net) that introduces two innovative components: the Geometric Contextual Feature Aggregation (GCFA) module and the Regional Contextual Feature Enhancement (RCFE) module. Specifically, GCFA generates the spatial geometric information of visual regions to enhance the region features by feature aggregation. RCFE further refines the aggregated region features by constructing a region graph and graph convolution. Extensive experiments and analyses are conducted on Flickr30k and MSCOCO to evaluate the importance of our framework. The results demonstrate the superiority of our method in image-text matching. Moreover, the ablation studies and visualization case studies also highlight the importance of geometric contextual feature aggregation and regional contextual feature enhancement. The code is available at https://github.com/chinaBoy123/GARE-Net .},
  archive      = {J_ESWA},
  author       = {Fangming Zhong and Tao Zhou and Zhikui Chen and Suhua Zhang},
  doi          = {10.1016/j.eswa.2025.129602},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129602},
  shortjournal = {Expert Syst. Appl.},
  title        = {GARE-net: Geometric contextual aggregation and regional contextual enhancement network for image-text matching},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation for engineering bid evaluation. <em>ESWA</em>, <em>298</em>, 129600. (<a href='https://doi.org/10.1016/j.eswa.2025.129600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing quantum group decision-making models face significant challenges in the bid evaluation of engineering projects, including the strong subjectivity of expert evaluations, the difficulty in aggregating expert opinions, the large gap of expert opinions, and the complexity of expert psychological behaviors. To address these issues, this paper proposes a novel quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation. Firstly, a quantum Bayesian network is constructed to aggregate expert opinions and capture the interference effect among experts. Secondly, the matrix fluctuation grey correlation degree is defined and applied to the calculation of quantum interaction terms that reflect the intricate psychological behavior of experts. Subsequently, a decision item search model is proposed and applied to adjust preferences during the consensus reaching process, thereby narrowing the gap of expert opinions. The consensus effect optimization model is utilized to determine optimal values for unknown parameters within this process, effectively reducing the subjectivity of expert evaluations. Finally, the proposed model is applied to a bid evaluation of bridge anti-collision engineering project, which verifies the feasibility and effectiveness of the model, and evaluates the stability and superiority of the model through sensitivity analysis and comparative analysis.},
  archive      = {J_ESWA},
  author       = {Jiuru Zhu and Xinping Xiao and Congjun Rao},
  doi          = {10.1016/j.eswa.2025.129600},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129600},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation for engineering bid evaluation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DPCND: A dual-population based evolutionary approach for critical node detection problem in complex networks. <em>ESWA</em>, <em>298</em>, 129599. (<a href='https://doi.org/10.1016/j.eswa.2025.129599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Critical node detection is an important tool for measuring network robustness. The main purpose of critical node detection is to detect a set of nodes that cause the greatest damage to the network connectivity, and it has been applied in many fields such as social network analysis and traffic network management. As a classic non-deterministic polynomial time complete problem, critical node detection faces enormous challenges with the continuous expansion of network size. The existing methods are difficult to achieve a good balance between effectiveness and efficiency, especially when the scale of complex networks becomes larger. To this end, this paper proposes a dual population based critical node detection method (DPCND) to effectively and efficiently obtain a set of critical nodes, which utilizes the co-evolution of auxiliary population generated from reduced graph and main population generated from original graph to find the optimal solution. In the proposed algorithm, a dual population interaction mechanism consists of influence and expansion strategies is proposed for information exchange, where the influence strategy transfers candidate good solutions from the auxiliary population to the main population to improve search efficiency, and the expansion strategy provides node information of the main population to guide the expansion of search space for the auxiliary population. Finally, the experimental results on 20 real-world complex networks clearly demonstrate the effectiveness of the proposed algorithm comparing to the state-of-the-arts.},
  archive      = {J_ESWA},
  author       = {Lei Zhang and Xinyi Feng and Yuanyuan Ge and Zhanpeng Wang and Haipeng Yang},
  doi          = {10.1016/j.eswa.2025.129599},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129599},
  shortjournal = {Expert Syst. Appl.},
  title        = {DPCND: A dual-population based evolutionary approach for critical node detection problem in complex networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage evolutionary algorithm with restart scheme for an integrated robot-task-scheduling and vehicle-dispatch-scheduling problem. <em>ESWA</em>, <em>298</em>, 129598. (<a href='https://doi.org/10.1016/j.eswa.2025.129598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern agriculture, efficiently picking and distributing fresh product is crucial for the competitiveness of smart farms within the globalized agricultural market. However, the integrated scheduling problem involving both picking and distribution processes has received limited attention in existing research. To bridge this gap, this study establishes a mathematical model with dual objectives: (1) minimizing the picking completion time and (2) reducing penalties incurred due to early or delayed deliveries. A novel two-stage evolutionary algorithm incorporating a restart mechanism is proposed to effectively balance the optimization of these objectives with a high degree of consistency. The algorithm features an efficient encoding scheme and advanced genetic operators, specifically designed to enhance exploration and exploitation based on the characteristics of the problem. A comprehensive set of test instances is generated and the proposed method is benchmarked against several state-of-the-art metaheuristics from the literature. Experimental results demonstrate that the proposed algorithm outperforms the competing approaches by a significant margin for solving the problem under consideration.},
  archive      = {J_ESWA},
  author       = {Yiran Pan and Xuan He and Nan Li and Zhonghua Miao},
  doi          = {10.1016/j.eswa.2025.129598},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129598},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-stage evolutionary algorithm with restart scheme for an integrated robot-task-scheduling and vehicle-dispatch-scheduling problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An initial value insensitive method for phase equilibrium calculation: Constrained quadratic interpolation optimization algorithm. <em>ESWA</em>, <em>298</em>, 129597. (<a href='https://doi.org/10.1016/j.eswa.2025.129597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The successful simulation of constrained differential evolution (CDE) algorithm for solving phase equilibrium calculation has first verified that heuristic optimization algorithms are effective ways to solve this kind of problems. Their insensitivity to initial values overcomes the limitations associated with two kinds of traditional methods, i.e., direct solution methods based on Newton’s method and indirect solution methods based on thermodynamic principles. This article proposes a constrained quadratic interpolation optimization algorithm (CQIO) for obtaining the satisfactory solutions of phase equilibrium calculation under given volume, temperature, and moles (NVT-flash). The proposed CQIO regards the total Helmholtz free energy of a NVT-flash problem as its objective function, while the moles vector and volume of a certain phase as its decision variables. The consistency between the four cases’ experimental results of CQIO and those of published articles demonstrates the effectiveness of CQIO in solving NVT-flash problems. Then the computational overhead and algorithmic stability of CQIO were analyzed. In Cases 1, 2 and 3, the average CPU time of CQIO compared to CDE has increased by 46.98 % , 54.56 % and 21.02 % respectively. The Std values of CQIO are significantly smaller than those of CDE in all cases except for Example 2. The proposed CQIO greatly promotes the application of heuristic algorithm in the field of phase equilibrium calculation.},
  archive      = {J_ESWA},
  author       = {Wangyu Tong and Baoduo Su and Yaqian Zhan},
  doi          = {10.1016/j.eswa.2025.129597},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129597},
  shortjournal = {Expert Syst. Appl.},
  title        = {An initial value insensitive method for phase equilibrium calculation: Constrained quadratic interpolation optimization algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge graph life cycle for cognitive agents – A case study on automated negotiation in smart grids. <em>ESWA</em>, <em>298</em>, 129596. (<a href='https://doi.org/10.1016/j.eswa.2025.129596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) can enhance cognitive artificial agents by improving their semantic understanding, adaptability to dynamic contexts, explainability, continuous learning, and informed, case-based decision-making. However, the development of any KG rarely follows an explicit and structured procedure to improve its consistency, modifiability, and interoperability. This ultimately restricts the utility of KGs for real-world agentic AI systems. To overcome this limitation, this paper proposes a life cycle for developing and evolving KGs in domain-specific applications, encompassing three phases to i) conceptualize the problem domain and competency questions, ii) formalize a schema using ontologies, and iii) implement the KG to foster agents’ cognition through queries and graph data science. The proposed approach is validated with a case study on context-aware automated negotiations within smart grids, where agents negotiate for energy trading while considering private and contextual circumstances. Agents may take actions with or without the aid of a KG, and can adopt one of three negotiation strategy configurations: heuristic, metaheuristic, or reinforcement learning-based. Negotiation outcomes consistently indicate that, regardless of the configuration employed, the use of a KG improves agents’ rewards by at least 1.21 % and up to 90.91 %. Results highlight that the proposed life cycle enables the integration of contextual and domain-specific data and metadata into a KG that enhances agents’ learning, while also allowing for the development and selection of relevant queries and graph data science algorithms to improve the strategic behavior of negotiation agents with cognitive abilities.},
  archive      = {J_ESWA},
  author       = {Dan E. Kröhling and Ernesto C. Martínez},
  doi          = {10.1016/j.eswa.2025.129596},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129596},
  shortjournal = {Expert Syst. Appl.},
  title        = {Knowledge graph life cycle for cognitive agents – A case study on automated negotiation in smart grids},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Research on multi-objective optimization of multi-endpoint VRP with time window for the distribution of seasonal products by multi-homing heterogeneous fleets. <em>ESWA</em>, <em>298</em>, 129595. (<a href='https://doi.org/10.1016/j.eswa.2025.129595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a novel VRP variant integrating seasonal demand fluctuations, heterogeneous vehicle sources, and multi-endpoint constraints, focusing on the distribution of seasonal products in a steel parts enterprise. It tackles the complex vehicle routing problem with time windows involving heterogeneous fleets, which encompass different vehicle sources (owned and rented), types (fuel-powered and electric), capacities, ranges, and endpoints. To balance enterprise profitability, greenhouse gas emissions, and environmental quality, we develop a mathematical model centered on optimizing distribution costs, greenhouse gas emissions, and vehicle utilization. Drawing inspiration from ancient competitive activities, we propose a novel Huashan Swords Algorithm (HSSA). Through simulations using real enterprise data, we demonstrate the HSSA’s effectiveness, with comparative experiments against existing advanced algorithms highlighting its superiority. Applying the algorithm to design logistics distribution schemes, we conduct in-depth tests considering different customer groups and fuel station distributions. Analyzing the results from the perspectives of profitability, emissions, and environmental quality, we offer targeted operational suggestions for the enterprise based on its situation, geographical characteristics, and fiscal policies. Moreover, we provide recommendations to local governments on fuel station construction and vehicle subsidy policies, contributing practical solutions to both enterprise operations and regional development.},
  archive      = {J_ESWA},
  author       = {Zhang Yanhu and Yan Lijuan and Kong ShuMei and Miao Decheng},
  doi          = {10.1016/j.eswa.2025.129595},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129595},
  shortjournal = {Expert Syst. Appl.},
  title        = {Research on multi-objective optimization of multi-endpoint VRP with time window for the distribution of seasonal products by multi-homing heterogeneous fleets},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revealing the correlation between economic indicators and gold prices for forecasting: Medium term forecast framework with data patch. <em>ESWA</em>, <em>298</em>, 129594. (<a href='https://doi.org/10.1016/j.eswa.2025.129594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting gold prices through the analysis of key economic indicators such as inflation rates, Government Bond Yields, and the U.S. Dollar Index, alongside historical Gold Prices, is crucial for enabling investors to better understand market dynamics and make vital decisions to maximize returns. However, previous studies have faced challenges in extracting hidden factors related to gold price prediction from diverse economic indicators, and the comprehensive exploration of gold price data is yet to be fully achieved. To address this, the present study introduces a mid to long-term gold price prediction model named DPformer. This model utilizes a patching strategy to investigate the relationships between different economic indicators and Gold Prices. It also employs a decomposition approach to discover the mid to long-term trend characteristics and yearly seasonal patterns of Gold Prices. The core of the model integrates a Transformer module, which is solely based on an Encoder structure, and enhances it with multiple attention mechanisms and convolutions. This enhancement allows the improved Transformer model to more effectively capture the long-term dependencies of Gold Prices. The empirical results demonstrate that DPformer consistently outperforms a suite of advanced models widely adopted in terms of mid to long-term forecasting accuracy, including LSTM, GRU, Transformer, DLinear, and PatchTST. Notably, for the 30-step gold price prediction task, DPformer achieves a 21.78 % reduction in Mean Squared Error compared to PatchTST. Moreover, by quantitatively analyzing how various economic indicators influence gold price forecasts, this study provides substantial support for investors in making informed decisions at critical moments.},
  archive      = {J_ESWA},
  author       = {Guanhao Bao and Yunbo Niu and Baisheng Cui and Wanying Ji},
  doi          = {10.1016/j.eswa.2025.129594},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129594},
  shortjournal = {Expert Syst. Appl.},
  title        = {Revealing the correlation between economic indicators and gold prices for forecasting: Medium term forecast framework with data patch},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-driven optimization of project portfolios in corporate ecosystems with synergies and strategic factors. <em>ESWA</em>, <em>298</em>, 129593. (<a href='https://doi.org/10.1016/j.eswa.2025.129593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the optimization of project portfolios in corporate ecosystems by considering both strategic factors and return synergies between projects. We propose a hybrid method that combines machine learning with mathematical programming to address this enhanced form of project portfolio optimization. Unlike traditional approaches, which evaluate projects mainly based on individual risks and returns, our framework considers strategic priorities and the extra value created when projects reinforce each other. Machine learning models predict synergies, while exact optimization ensures consistent portfolio selection under resource and strategic constraints. A numerical proof-of-concept illustrates the methodology. Computational experiments show that portfolios designed with synergy and strategy in mind might achieve a significantly higher performance than portfolios that do not account for project synergies. The paper also examines computational efficiency and scalability, highlighting the approach’s potential for practical application in complex and dynamic corporate ecosystems.},
  archive      = {J_ESWA},
  author       = {Patricia Rodriguez-Garcia and Angel A. Juan and Jon A. Martin and David Lopez-Lopez and Josep M. Marco},
  doi          = {10.1016/j.eswa.2025.129593},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129593},
  shortjournal = {Expert Syst. Appl.},
  title        = {AI-driven optimization of project portfolios in corporate ecosystems with synergies and strategic factors},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overview of machine learning in class imbalance scenarios: Trends, challenges, and approaches. <em>ESWA</em>, <em>298</em>, 129592. (<a href='https://doi.org/10.1016/j.eswa.2025.129592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a systematic mapping of machine learning in class imbalance scenarios, offering a broad overview of key challenges, promising emerging techniques, and established methodologies across various application domains. The investigation stands out by employing a hybrid search and selection protocol that combines methodological rigor with technical innovation. The adopted strategy integrated manual searches in reference sources with automated processes based on machine learning, semantic embeddings, and graph-based ranking algorithms. To enhance selection quality, the Quasi-Golden Set (QGS) method was used to build a reference set from manually selected articles – a critical foundation for calibrating and evaluating automated search strings. This combination ensured broad coverage of the topic while improving sensitivity and precision in identifying relevant studies. The initial analysis reviewed 25,593 publications. After screening and applying eligibility criteria, 468 articles were included in the final dataset. The results indicate that 55 % of the studies address multiple domains, with a strong predominance of tabular data ( 84 % ). SMOTE and hybrid approaches were among the most common techniques, present in 61 % of the studies. In terms of evaluation metrics, ROC-AUC was the most frequently used, followed by F1-score and accuracy – the latter noted for limitations in highly imbalanced scenarios. Building on these findings, we derive an empirically grounded taxonomy that links problem context, solution algorithms, and scenario-appropriate evaluation metrics, and we provide a minimal selection guideline table to support applied use. While sampling-based methods remain prevalent, deep learning approaches such as convolutional neural networks and graph-based models are increasingly adopted. Additionally, federated, contrastive, and semi-supervised learning are emerging as relevant paradigms, particularly suited for privacy-aware or low-label environments. This study consolidates current knowledge, identifies methodological and application gaps, and highlights trends that are likely to shape future research. It contributes both a comprehensive synthesis of the field and strategic insights for advancing machine learning techniques in the presence of class imbalance.},
  archive      = {J_ESWA},
  author       = {Gilberto Sussumu Hida and André Câmara Alves Do Nascimento},
  doi          = {10.1016/j.eswa.2025.129592},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129592},
  shortjournal = {Expert Syst. Appl.},
  title        = {Overview of machine learning in class imbalance scenarios: Trends, challenges, and approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective multi-product process planning with reconfigurable machines: Exact and metaheuristic approaches. <em>ESWA</em>, <em>298</em>, 129591. (<a href='https://doi.org/10.1016/j.eswa.2025.129591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process planning in reconfigurable manufacturing systems usually considers a single product, this reduces the efficiency of the overall production plan when multiple products are combined. This paper tackles the Multi-Product Process Planning Problem (MPPP), optimizing both individual process plans and their sequencing. We propose a 0–1 LP model, the model is relaxed by fixing the product sequencing variables and implemented in a Normal-Boundary Intersection method (NBI-es), the method uses a function for iteratively updating β values. Three metaheuristics are also developed: NSGA-II, and two variants of MOEA/D, one enhanced by Opposition-based learning (OBL). Computational experiments show that the update function enhances the performance of NBI over simple Normalized-Weighted Sum (NWS) method. Additionally, NBI-es performs better in HV metric for small size instances if it is given enough CPU times, while MOEA/D significantly outperforms NSGA-II on larger instances on most convergence and spread based metrics. OBL further enhances solution diversity for MOEA/D, albeit with less convergence. A special case of the MPPP is investigated, involving identical products: the Multi-Unit Process Planning (MUPP). An integrated approach was compared with a sequential separated approach. Results indicate that the integrated approach outperforms the separated method for smaller problem instances. Moreover, the analysis of high-quality MUPP solutions revealed a tendency towards diverse process plan combinations rather than repetitive identical ones.},
  archive      = {J_ESWA},
  author       = {Abdelkader Mechaacha and Fayçal Belkaid and Nadjib Brahimi},
  doi          = {10.1016/j.eswa.2025.129591},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129591},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective multi-product process planning with reconfigurable machines: Exact and metaheuristic approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A slack-based two-stage improved particle swarm optimization algorithm for robust scheduling of a flexible job-shop with new and remanufacturing jobs. <em>ESWA</em>, <em>298</em>, 129590. (<a href='https://doi.org/10.1016/j.eswa.2025.129590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remanufacturing has attracted increasing attention for its environmental and economic benefits. Since it is difficult to achieve economies of scale when processing small amounts of remanufacturing jobs alone, these jobs are processed in the same job-shop for new jobs in some enterprises. The processing times of remanufacturing jobs are uncertain due to unpredictable status, leading to certain impacts on scheduling performance. Therefore, we address a flexible job-shop scheduling problem with new and remanufacturing jobs to minimize makespan. To solve this problem, a slack-based two-stage improved particle optimization algorithm is proposed. The first stage aims to yield a solution set with minimum makespan, while the second stage aims to search the best robust solution with maximum total slack from the set. Both stages are executed alternately to optimize makespan and total slack. Moreover, a position updating mechanism with genetic operators and a tabu search inspired local search strategy are implemented to improve algorithmic performance. Computational experiments are conducted using adapted benchmark problems and an industrial case to validate the proposed algorithm.},
  archive      = {J_ESWA},
  author       = {Jun Liu and Zhui Gui and An Li and Qiong Liu},
  doi          = {10.1016/j.eswa.2025.129590},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129590},
  shortjournal = {Expert Syst. Appl.},
  title        = {A slack-based two-stage improved particle swarm optimization algorithm for robust scheduling of a flexible job-shop with new and remanufacturing jobs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evaluating and predicting green economic efficiency in chinese cities: A three-stage network SBM and machine learning approach. <em>ESWA</em>, <em>298</em>, 129589. (<a href='https://doi.org/10.1016/j.eswa.2025.129589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper evaluates and predicts green economic efficiency (GEE) across 248 Chinese cities from 2010 to 2021 using a three-stage network SBM model based on subsystems of economic production, social development, and environmental governance. To enhance accuracy in both assessment and forecasting, machine learning methods are incorporated, and the Dagum Gini coefficient is employed to analyze regional disparities. This study innovatively proposes a three-stage network SBM model to resolve the “black box” limitation of conventional DEA approaches, while a DEA-ML model is developed to achieve enhanced prediction accuracy. The results reveal that GEE in Chinese cities remains low, with the eastern region leading and the western region trailing. However, efficiency has improved since 2016, primarily driven by advancements in environmental governance. Regional disparities, largely attributed to interregional differences, are gradually decreasing. Among forecasting models, the backpropagation neural network (BPNN) delivers the highest accuracy, predicting sustained leadership in the east, strong growth in the northeast, and a reduction in national disparities. This study offers a comprehensive framework for evaluating and predicting GEE, providing valuable insights for sustainable development policies.},
  archive      = {J_ESWA},
  author       = {Zhishuo Zhang and Hu Liu and Yunpeng Gong and Huayong Niu},
  doi          = {10.1016/j.eswa.2025.129589},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129589},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evaluating and predicting green economic efficiency in chinese cities: A three-stage network SBM and machine learning approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HAEA: A heterogeneous alternating evolutionary algorithm for numerical optimization. <em>ESWA</em>, <em>298</em>, 129587. (<a href='https://doi.org/10.1016/j.eswa.2025.129587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid algorithm integrating a couple of individual evolutionary algorithms (sub-algorithms) is widely recognized as an effective approach to enhance both robustness and optimization performance. Nevertheless, such integration often destroys the structure of the sub-algorithm and makes it difficult to incorporate additional evolutionary algorithms. To address these limitations, this study introduces a novel framework, the Heterogeneous Alternating Evolutionary Algorithm (HAEA), designed to integrate multiple evolutionary algorithms while enabling the flexible addition, removal, and replacement of internal sub-algorithms. To facilitate the integration of a broad spectrum of sub-algorithms, this study draws inspiration from the particle swarm optimization algorithm to devise a suite of information indicators for the transmission of optimization information between sub-algorithms with disparate structures. Furthermore, HAEA is endowed with an adaptive mechanism that dynamically modifies the selection probabilities of its sub-algorithms based on their long-term and short-term performance throughout the evolutionary process. We conducted a comparative analysis of HAEA against all its sub-algorithms across three widely recognized function test sets: CEC2013, CEC2017, and CEC2022. Meanwhile, we applied the HAEA separately to basic metaheuristic algorithms and advanced evolutionary algorithms in recent years and conducted two comparative experiments. Both experimental results show that HAEA outperforms all sub-algorithms in terms of robustness and optimization performance. Its distinctive flexibility allows for the incorporation of additional superior evolutionary algorithms in the future, thereby enhancing its overall performance.},
  archive      = {J_ESWA},
  author       = {Taiyong Li and Tianhao Yi and Zhenda Hu and Wu Deng and Donglin Zhu and Zhilong Xie and Jiang Wu},
  doi          = {10.1016/j.eswa.2025.129587},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129587},
  shortjournal = {Expert Syst. Appl.},
  title        = {HAEA: A heterogeneous alternating evolutionary algorithm for numerical optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep analysis on MLSY for fractional-order higher-dimension-valued neural networks under the action of free quadratic coefficients. <em>ESWA</em>, <em>298</em>, 129586. (<a href='https://doi.org/10.1016/j.eswa.2025.129586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, free quadratic coefficients are proposed in order to deeply study the flexible criteria of synchronization problem for two kinds of fractional-order higher-dimension-valued neural networks (FOHDVNN) with usual neurons and threshold ones, respectively. First, the uniform system is constructed for two kinds of FOHDVNN which contains both fractional-order octonion-valued neural networks (FOOVNN) and fractional-order quaternion-valued neural networks (FOQVNN). Based on higher-dimension algebra multiplication rules, the studied FOHDVNN are directly decomposed into the eight or four subsystems in real-valued field. Subsequently, free quadratic coefficients are taken into the establishment of two types of Lyapunov-Krasovskii functional (LKF) which is newer and more general. Then, mainly based on the very recent lemmas and Lyapunov theories, the flexible criteria are generally acquired for the global Mittag-Leffler synchronization (MLSY) problem of FOHDVNN. The final criteria have the advantage in being easily calculated and widely used. It is worth noting that the optimal solutions of these criteria can be obtained through the genetic algorithm and the synchronization performance can be improved by optimizing the quadratic coefficients. Finally, three simulation examples are presented to express the availability and progress of the derived results.},
  archive      = {J_ESWA},
  author       = {Jianying Xiao and Yongtao Li},
  doi          = {10.1016/j.eswa.2025.129586},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129586},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep analysis on MLSY for fractional-order higher-dimension-valued neural networks under the action of free quadratic coefficients},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complex-order darwinian particle swarm optimization. <em>ESWA</em>, <em>298</em>, 129584. (<a href='https://doi.org/10.1016/j.eswa.2025.129584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Particle Swarm Optimization (PSO) algorithm has been one of the most effective methods for solving various complex optimization problems. However, non-adaptive versions of the PSO do not use historical information for performance enhancement and suffer from performance degradation problems. This paper presents a Complex-Order Darwinian PSO (CoDPSO) algorithm, which effectively enhances the performance of the PSO. A complex-order derivative mechanism is introduced into the velocity update rule to improve local exploitation using historical velocity information. Additionally, a Degradation Elimination (DE) strategy is designed to mitigate performance drop during the optimization process. Sensitivity analysis is conducted to evaluate the impact of control parameters on the algorithm’s behavior, demonstrating its robustness across a wide range of settings. Comparative experiments on CEC 2022 benchmark functions show that the CoDPSO outperforms other PSO variants in terms of accuracy, stability, and convergence. Wilcoxon statistical tests further confirm the significance of these improvements. The experimental results indicate the feasibility and efficiency of the CoDPSO.},
  archive      = {J_ESWA},
  author       = {Xiaobo Wu and Liping Chen and Huafeng Li and António M. Lopes and Chuang Liu and Yangquan Chen and Yi Chai},
  doi          = {10.1016/j.eswa.2025.129584},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129584},
  shortjournal = {Expert Syst. Appl.},
  title        = {Complex-order darwinian particle swarm optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-objective framework for predicting public opinion trends on infectious diseases using NSGA-II and interval predictions. <em>ESWA</em>, <em>298</em>, 129583. (<a href='https://doi.org/10.1016/j.eswa.2025.129583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting public opinion trends during major infectious disease outbreaks is critical for guiding effective public health responses. However, predicting public opinion remains challenging because it is influenced by socio-economic, psychological, and media factors. This paper presents a novel framework for predicting public opinion trends related to significant infectious diseases, with a focus on COVID-19 as a case study. The proposed framework identifies the key factors influencing public opinion development and enables both point and interval predictions. The framework uses information ecology theory and applies the NSGA-II algorithm to select the features that best drive public opinion trends. By incorporating this framework, accurate point forecasts are produced alongside prediction intervals, effectively quantifying the uncertainty inherent in public opinion dynamics. This approach minimizes the quality-driven loss function to generate precise prediction intervals, providing decision-makers with critical insights into public opinion fluctuations during epidemics. The results offer valuable, real-time public sentiment warnings, supporting timely and effective interventions in epidemic prevention and control efforts.},
  archive      = {J_ESWA},
  author       = {Futian Weng and Meng Su and Petr Hajek and Mohammad Zoynul Abedin},
  doi          = {10.1016/j.eswa.2025.129583},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129583},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-objective framework for predicting public opinion trends on infectious diseases using NSGA-II and interval predictions},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep reinforcement learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism. <em>ESWA</em>, <em>298</em>, 129581. (<a href='https://doi.org/10.1016/j.eswa.2025.129581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core challenge for multimodal multi-objective problem (MMOP) resolution lies in maintaining synergistic interactions between convergence and diversity. However, the existing algorithms usually consider convergence-first, which neglect to consider both diversity and convergence into account during the evolutionary process. Likewise, the optimization methods tend to gravitate toward locally optimal regions rapidly, leading to lose diversity for the local PS. This paper proposes a Deep Reinforcement Learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism (DRLMMEA) to investigate the impact of different operator selection on the performance of MMEAs, which greatly helps to balance the convergence and diversity. DRLMMEA utilizes Q-Network to select the operator with the highest reward to enhance the population’s search ability. An improved sorting method (ISM) based on neighborhood dominance updates the population by sorting individuals according to their convergence quality, thereby enhancing convergence performance in the objective space. Moreover, this study proposes a series-parallel mechanism, a series structure enhances the diversity in the decision space, while the parallel structure reduces the computational burden of the algorithm evidently. The proposed Deep Reinforcement Learning-assisted operator selection mechanism, which enables effective balance between diversity and convergence, and an improved crowding distance approach that enhances convergence performance. DRLMMEA undergoes comprehensive testing against 6 contemporary approaches using MMF and IDMP benchmark problems, achieving supremacy in 4 principal performance metrics according to experimental findings. The multimodal gearbox parameter optimization is addressed using the proposed DRLMMEA, which demonstrates superior performance against 6 algorithms in comparative evaluations. It has demonstrated a significant role in solving the MMOPs with the imbalance between convergence and diversity.},
  archive      = {J_ESWA},
  author       = {Ying Huang and Xiaojian Cao and Benben Zhou and Wei Li and Shuling Yang and S.M. Shafi and Zhou Yang},
  doi          = {10.1016/j.eswa.2025.129581},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129581},
  shortjournal = {Expert Syst. Appl.},
  title        = {A deep reinforcement learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evolutionary multitasking optimization based on cross-task association mapping strategy. <em>ESWA</em>, <em>298</em>, 129580. (<a href='https://doi.org/10.1016/j.eswa.2025.129580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multitasking optimization, knowledge transfer between tasks through subspace generation has been widely employed to enhance the convergence performance of algorithms. However, this approach fails to account for the inter-task knowledge mapping relationships. Therefore, cross-task knowledge transfer during the optimization process remains inherently blind, potentially leading to mismatched subspace information and consequently degrading the algorithm’s performance. To address this issue, this paper proposes a multitask evolutionary algorithm based on an association mapping strategy and an adaptive population reuse mechanism, namely PA-MTEA. Specifically, to fully represent the correlations between multitask domains and enhance the adaptability of transfer solutions in target tasks, this paper introduces a subspace projection strategy based on partial least squares, which achieves the correlation mapping between the source and target tasks during the dimensionality reduction of the search space. Additionally, to further enhance knowledge transfer across tasks, an alignment matrix is obtained by adjusting the subspace Bregman divergence after deriving the respective subspaces, minimizing variability between task domains. Finally, to balance the global exploration of algorithms with local exploitation, an adaptive population reuse mechanism based on the residual structure is designed. This mechanism reuses historically successful individuals to guide the evolutionary direction of the population, thus improving the algorithm’s convergence performance. Experimental results on various benchmark suites and real-world cases demonstrate that PA-MTEA exhibits significantly superior performance compared to six other advanced multitask optimization algorithms.},
  archive      = {J_ESWA},
  author       = {Tao Yin and Lizhong Yao and Xin Zong and Pengjie Qin and Haoming Dong},
  doi          = {10.1016/j.eswa.2025.129580},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129580},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evolutionary multitasking optimization based on cross-task association mapping strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UniTask+: Exploring and unifying strong and weak task-aware consistency for semi-supervised blastocyst image segmentation. <em>ESWA</em>, <em>298</em>, 129578. (<a href='https://doi.org/10.1016/j.eswa.2025.129578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of different tissues within blastocysts is essential for embryologists to objectively observe and evaluate embryos, thereby contributing to a higher success rate of in vitro fertilization treatment. Inspired by the primary observation of skeletal patterns and boundary information by clinical doctors, we present an interesting task-aware view for blastocyst segmentation with semi-supervised learning, focusing on task-invariant and task-specific dependencies of segmentation. Firstly, we explore one strong-correlation task with bidirectional transformation between its outputs and the segmentation results, and another weak-correlation task with monodirectional transformation from segmentation maps. The correlation among different tasks inspires us to propose Task-Aware Smoothness (TAS) Assumption , thereby deducing different types of task-aware consistency. Then, a new Unified Task-aware Consistency Interaction (UniTask+) framework is developed to unify and fully take advantage of these strong, weak, and strong-to-weak task-aware consistency. It is comprised of a medical segmentation (MS) branch to implement segmentation and two extra branches performing strong/weak-correlation tasks based on the same backbone. Concretely, a level-set (LS) branch promotes the strong consistency while a point-set (PS) branch stimulates the weak consistency with underlying task perturbations. Numerous experiments have been conducted on the inner cell mass (ICM), blastocyst, proving the effectiveness of our tactics. Furthermore, we have also conducted experiments with datasets from the left atrium (LA), which shares similar structural features with embryos, to validate the robustness of the model. Our methods have shown prominent improvements over up-to-date SSL methods, which advocates our precedent hypothesis.},
  archive      = {J_ESWA},
  author       = {Hua Wang and Linwei Qiu and Jingfei Hu and Jicong Zhang},
  doi          = {10.1016/j.eswa.2025.129578},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129578},
  shortjournal = {Expert Syst. Appl.},
  title        = {UniTask+: Exploring and unifying strong and weak task-aware consistency for semi-supervised blastocyst image segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep asymmetric semantic hashing with probability shifting for multi-label image retrieval. <em>ESWA</em>, <em>298</em>, 129577. (<a href='https://doi.org/10.1016/j.eswa.2025.129577'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing has been widely used in large-scale multimedia retrieval due to its advantages in terms of low storage cost and computational efficiency. Deep hashing algorithms can jointly learn semantic features and hash functions, encoding the original data into compact binary codes with significant discriminative power. However, in multi-label scenarios, especially when the number of samples is extremely large, a high negative-positive imbalance may occur, particularly when the proportion of negative samples is too high, which can lead to bias in the semantic relationships between the learned images. To solve this problem, symmetric losses such as focal loss were proposed, which treat positive and negative samples equally, but the retrieval results are suboptimal. This may be because the equal-weighted processing strategy causes the model to over-focus on hard negative samples and ignore the learning of positive sample features. Besides, mislabeled negative samples, especially those with a probability close to 1, can lead the model to learn incorrect features, harming its discrimination ability, reducing accuracy and recall, and causing overfitting and poor generalization. Accordingly, this paper proposes a novel hashing model, Deep Asymmetric Semantic Hashing with Probability Shifting framework (DASH-PS), for discriminative binary code learning. Specifically, by combining asymmetric focusing strategy and probability shifting strategy, asymmetric semantic loss is designed to solve negative-positive imbalance and ground-truth mislabeling. To keep the contribution of positive samples while focusing on hard negative samples, asymmetric focusing strategy is proposed to decouple negative and positive samples and assign different attenuation factors. By offsetting the probability of negative samples, probability shifting strategy completely discards easy negative samples and very hard negative samples suspected of being mislabeled. Additionally, an adaptive asymmetric learning mechanism is proposed to reduce the fixed difference in average probabilities between positive and negative samples, thereby simplifying hyperparameter selection and improving retrieval efficiency. Extensive experimental results on multiple benchmark datasets validate that our DASH-PS outperforms various state-of-the-art hashing methods. The code for the implementation of our DASH-PS framework is available at https://github.com/QinLab-WFU/DASH-PS.},
  archive      = {J_ESWA},
  author       = {Yongyue Fu and Qibing Qin and Jinkui Hou and Congcong Zhu and Lei Huang and Wenfeng Zhang},
  doi          = {10.1016/j.eswa.2025.129577},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129577},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep asymmetric semantic hashing with probability shifting for multi-label image retrieval},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-informed tensor autoencoder with memory for video anomaly detection. <em>ESWA</em>, <em>298</em>, 129576. (<a href='https://doi.org/10.1016/j.eswa.2025.129576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video data can be naturally represented as tensors. Despite great progress in anomaly detection with memory-augmented autoencoders, the memory module therein can only handle vectors and inevitably breaks tensor structures, thus leading to performance degradation. Moreover, after the mapping of the encoder, some abnormal features may directly fall into the normal convex polytope, as autoencoders only use the output error to guide the construction of latent variables without imposing any constraint. The memory module can not handle these abnormal features, so that the abnormal observations may not be identified. To solve these problems, we propose a Physics-Informed Tensor AutoEncoder (PITAE) framework, which incorporates both neural networks and physical laws, i.e., tensor operation rules. Specifically, we design a tensor decomposition network followed by an explicit tensor operation to decompose the latent variable into low-rank and sparse components, and only the low-rank component is inputted to the decoder. In this way, we reserve the tensor structure and meanwhile impose a low-rank constraint on the latent variable, thereby compressing the features of normal samples into a ”smaller” region where anomalies are less likely to fall into. Consequently, the non-low-rank anomalies can be identified. But the low-rank anomalies may still not be identified. To further solve this problem, we design a tensor Memory module, and the overall model is named as PITAEM. Finally, based on the proposed framework, we design a novel composite anomaly score to identify anomalies of various kinds. Experiments on various video datasets demonstrate the effectiveness of the proposed method, especially in the small data regime.},
  archive      = {J_ESWA},
  author       = {Jianan Liu and Chunguang Li},
  doi          = {10.1016/j.eswa.2025.129576},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129576},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-informed tensor autoencoder with memory for video anomaly detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A robust medical image encryption technique using inverse cosine chaotic map. <em>ESWA</em>, <em>298</em>, 129574. (<a href='https://doi.org/10.1016/j.eswa.2025.129574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid proliferation of digital imaging technologies, the need for robust and lightweight image encryption techniques has become increasingly critical, particularly for medical, military, and personal data applications. In this paper, we propose a novel image encryption scheme based on a one-dimensional inverse cosine chaotic map (1D-ICC), which introduces a highly sensitive and structurally complex nonlinear dynamical system. The proposed method integrates a dynamic Josephus-based intra-block scrambling mechanism, a global zigzag permutation strategy, and an adaptive diffusion process guided by chaotic sequences, thereby enhancing the confusion and diffusion characteristics of the cipher. Unlike conventional approaches, our scheme dynamically derives the encryption key from the SHA-512 hash of the original image, ensuring both sensitivity to plaintext changes and resistance to known-plaintext and chosen-plaintext attacks. The use of the 1D-ICC map, featuring a tunable control parameter r 5 enables rich chaotic behavior even in one dimension, reducing computational complexity without sacrificing security. Comprehensive experiments validate the robustness and efficiency of the encryption scheme, with performance metrics including correlation coefficients below 0.003, information entropy of 7.9993, a Number of Pixels Change Rate (NPCR) of 99.61 %, and a Unified Averaged Changed Intensity (UACI) of 33.42 %. These results demonstrate that our method surpasses several existing techniques in both security strength and computational performance, underscoring the potential of the 1D-ICC map for practical image encryption applications.},
  archive      = {J_ESWA},
  author       = {Jackson J and Perumal R},
  doi          = {10.1016/j.eswa.2025.129574},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129574},
  shortjournal = {Expert Syst. Appl.},
  title        = {A robust medical image encryption technique using inverse cosine chaotic map},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing text classification with neural label embedding and weakly-supervised learning. <em>ESWA</em>, <em>298</em>, 129569. (<a href='https://doi.org/10.1016/j.eswa.2025.129569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the widespread adoption of deep-learning-based models in a range of linguistic tasks including the fundamental text classification. These deep neural networks, however, often face challenges due to the limited availability of large-scale training data with high-quality label annotations. Furthermore, while supervised learning has proven to be superior in training sentence representations for downstream tasks like text classification, this aspect has received relatively little attention. In this study, a novel model named L abel Em bedding joint with We akly-supervised C lassification ( LemWec ) is proposed, which aims to establish a unified framework by combining supervised sentence embedding with multiclass classification. For supervised sentence embeddings, the model incorporates seed information such as label names and designs an encoder network with a new pooling layer. Additionally, the model adopts a pseudo-labeling approach to leverage a substantial amount of unlabeled samples. This approach specifically addresses the drawback of generating pseudo-labels with the highest confidence and introduces a noise adaptation method to mitigate this issue. The results of extensive experiments conducted on four real-world datasets demonstrate that the proposed LemWec model can significantly enhance the performance of text classification when compared to a comprehensive set of baselines.},
  archive      = {J_ESWA},
  author       = {Xiao Jing and Zhe Li and Zhiang Wu and Dejun Mu},
  doi          = {10.1016/j.eswa.2025.129569},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129569},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing text classification with neural label embedding and weakly-supervised learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Self-supervised ZINB-based kernel representation learning of single-cell RNA sequencing data. <em>ESWA</em>, <em>298</em>, 129568. (<a href='https://doi.org/10.1016/j.eswa.2025.129568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell clustering plays a vital role in single-cell RNA sequencing (scRNA-seq) data analysis. Although many deep cell clustering methods have been proposed to cluster the scRNA-seq data, they overlook the structural partitioning objectives during the representation learning process, leading to challenges with non-linearly separable structures. In this paper, we present a novel end-to-end deep kernel cell clustering model for scRNA-seq data based on self-supervised ZINB-based kernel representation learning, named scDKC, which simultaneously learns cell kernel representations and identifies cell clusters. Specifically, a kernel-aid hybrid representation learning encoder is developed to effectively learn the separable kernel representation of cells, consisting of cells’ expression characteristics and cell-cell topological interactions. To guide the direction of kernel representation learning, a ZINB-based kernel representation learning decoder is designed by capturing the global probabilistic structure, the representation and the cell graph structure of the scRNA-seq data. By leveraging the clustering self-supervised strategy, representation self-supervised strategy, ZINB-based distribution self-supervised strategy, and kernel self-supervised strategy, scDKC optimizes cell cluster label assignment and learns cell kernel representations through a joint mutual self-supervised mechanism. Extensive experiments on 15 real scRNA-seq datasets, comparing scDKC with 10 competing methods, highlight its competitive advantages.},
  archive      = {J_ESWA},
  author       = {Lina Ren and Maoxuan Yao and Ruizhang Huang and Yongbin Qin},
  doi          = {10.1016/j.eswa.2025.129568},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129568},
  shortjournal = {Expert Syst. Appl.},
  title        = {Self-supervised ZINB-based kernel representation learning of single-cell RNA sequencing data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dual uncertainty-aware fusion framework for face expression recognition in the wild. <em>ESWA</em>, <em>298</em>, 129567. (<a href='https://doi.org/10.1016/j.eswa.2025.129567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Expression Recognition(FER) is a key task in the broader landscape of affective computing and human-computer interaction, enabling machines to interpret human emotions. To better learn discriminative features under complex facial variations, recent FER research has increasingly adopted multi-branch fusion architectures that aim to capture complementary features from diverse perspectives. However, existing multi-branch fusion strategies, including static weighting, simple concatenation, or uncertainty-aware modeling, lack the capacity to comprehensively capture and reconcile the reliability variations across both individual instances and structural branches. To overcome these limitations, we propose a novel multi-branch fusion strategy, named Dual Uncertainty-Aware Fusion Framework(DUAFF), which improves the discriminability of integrated features by simultaneously modeling instance-wise uncertainty and inter-branch correlations. Specifically, the proposed method comprises two complementary modules: Instance-Discrepant Uncertainty-Aware Fusion Module (ID-UAFM) and Branch-Discrepant Uncertainty-Aware Fusion Module (BD-UAFM). ID-UAFM is introduced to perform channel-wise entropy analysis between semantically distinct samples to estimate instance-level uncertainty, enabling selective channel-wise fusion that emphasizes reliable representations while suppressing uncertain responses. BD-UAFM is further proposed to capture structural uncertainty by evaluating the relative reliability of features across multiple branches and adaptively weighting their contributions based on inter-branch discrepancies. Experimental results demonstrate that the proposed DUAFF consistently outperforms POSTER across three benchmark datasets, achieving accuracy improvements of 0.23 % on RAF-DB, 0.69 % on FER2013, and 0.29 % on AffectNet (7-class), thereby confirming its effectiveness in enhancing the reliability and discriminability of facial representations.},
  archive      = {J_ESWA},
  author       = {Wenfeng Jiang and Ziyi Zhao and Lin Wang and Fang Liu and Chunmei Qing and Xiaofen Xing and Xiangmin Xu and Weiquan Fan and Zhanpeng Jin},
  doi          = {10.1016/j.eswa.2025.129567},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129567},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dual uncertainty-aware fusion framework for face expression recognition in the wild},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Forecasting tourism stock index dynamics: A multiscale deep learning framework integrating emerging media data. <em>ESWA</em>, <em>298</em>, 129566. (<a href='https://doi.org/10.1016/j.eswa.2025.129566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel multiscale and multivariable deep learning framework for tourism stock index forecasting. To address the research gap concerning emerging media’s impact on the tourism sector, our study innovatively integrate multi-source data, including Douyin (China’s prominent short video platform), into our predictive model. Our methodology employs a multiscale decomposition strategy to streamline feature extraction complexity, coupled with an enhanced temporal convolutional network model incorporating soft-thresholding denoising to mitigate noise interference. Furthermore, we implement an adaptive differentiated prediction strategy to optimize model flexibility. Empirical analysis utilizing the CSI Tourism Stock Index demonstrates that our proposed model outperforms benchmark models in both predictive accuracy and stability, thereby validating its efficacy in tourism stock index forecasting.},
  archive      = {J_ESWA},
  author       = {Feng Shen and Shuai Huang and Wanqing Zhao and Dao Lan},
  doi          = {10.1016/j.eswa.2025.129566},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129566},
  shortjournal = {Expert Syst. Appl.},
  title        = {Forecasting tourism stock index dynamics: A multiscale deep learning framework integrating emerging media data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing adversarial transferability through frequency-domain boundary samples tuning. <em>ESWA</em>, <em>298</em>, 129565. (<a href='https://doi.org/10.1016/j.eswa.2025.129565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer-based attacks evaluate the robustness of deep learning models and advance adversarial research to improve the security and reliability of deep learning and its applications. Previous efforts have improved the transferability through advanced gradients, augmented models, or augmented data. In this paper, we understand and enhance the transferability from a new perspective. Delving into intermediate features, we empirically find a difference between the distances of adversarial and original samples from cluster centers of the original classes. The adversarial samples are simultaneously far from both the original samples and the cluster centers, close to generalized decision boundaries. Based on this observation, we propose a novel spectrum tuning attack. Boundary samples are utilized to guide the generation of adversarial samples that are far away from the cluster centers. Specifically, randomized boundary samples are generated by frequency-domain transformations. With the gradients of the diverse boundary samples, the adversarial perturbation moves the examples away from cluster centers, thus approaching generalized decision boundaries. In the optimization process, conjugate directions are employed to avoid oscillations and stabilize the update direction. Given the strong Wolfe parameters, the analysis of the descent direction and current gradient further ensures the convergence speed and stability of the optimization. In addition, Gaussian preprocessing is introduced to smooth the update direction, further stabilize the direction and enhance the transferability. The proposed method is flexible enough to be combined with existing methods to further improve the transferability. Experiments conducted on the ImageNet-compatible dataset validate the effectiveness of the proposed method, e.g., 92.6 % success rate against nine defense methods.},
  archive      = {J_ESWA},
  author       = {Shuyan Cheng and Peng Li and Keji Han and Yangjun Xiong and He Xu and Ruchuan Wang},
  doi          = {10.1016/j.eswa.2025.129565},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129565},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing adversarial transferability through frequency-domain boundary samples tuning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). When graph anomaly breaks the coherence: A multi-evidence approach with language models. <em>ESWA</em>, <em>298</em>, 129557. (<a href='https://doi.org/10.1016/j.eswa.2025.129557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection is critical in domains such as healthcare and economics, where identifying deviations can prevent substantial losses. However, current detection methods, primarily reliant on Graph Neural Networks (GNNs), suffer from a critical limitation: they make judgment on a single piece of evidence – the classification of learned node representations. This “single-verdict” approach is inherently susceptible to misjudgments arising from noisy or biased representations. To address this limitation, we introduce Multi-AD, a novel Multi-evidence-based graph Anomaly Detection framework that leverages the power of Language Models (LMs) to enable more robust and reliable anomaly detection. We provide a paradigm shift by constructing multiple evidence sequences for each target node, and employing LMs to assess the coherence of these sequences. By aggregating coherence scores across multiple sequences, Multi-AD leverages converging evidence to make more informed decisions about anomaly status as the presence of anomalous nodes disrupts coherence. Furthermore, we introduce a coherence-aware edge representation method to enhance the discriminative power of the constructed sequences and a multi-round adaptive integration strategy to handle challenging scenarios where normal nodes might be surrounded by anomalies. Extensive experiments demonstrate that Multi-AD consistently outperforms state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xuan Cheng and Jiahui Lu and Chunjing Xiao and Meiyi Yang and Meihui Zhong and Fan Zhou},
  doi          = {10.1016/j.eswa.2025.129557},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129557},
  shortjournal = {Expert Syst. Appl.},
  title        = {When graph anomaly breaks the coherence: A multi-evidence approach with language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal joint subspace model for parkinson’s disease diagnosis. <em>ESWA</em>, <em>298</em>, 129556. (<a href='https://doi.org/10.1016/j.eswa.2025.129556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is an irreversible neurodegenerative disorder that significantly impacts patients’ lives. Accurate early diagnosis prediction is crucial for providing timely treatment to delay disease progression. However, current diagnostic methods predominantly rely on the experience and judgment of clinicians, introducing subjectivity and a lack of standardized, quantitative measures. Sparse subspace learning, as a machine learning technique, can extract critical information from multimodal data while addressing issues such as noise, high-dimensional complexity, and class imbalance. Our study utilizes longitudinal, multimodal neuroimaging data collected at multiple time points to develop a diagnostic model for PD. The approach involves extracting latent local features and leveraging deep learning techniques to generate a comprehensive global feature subset. Adaptive sparse selection is employed to reduce feature redundancy. Finally, support vector machine is used for classification and regression tasks, specifically for PD diagnosis and disease progression score prediction. Extensive experiments were conducted on the PPMI dataset, achieving an accuracy of 90.78 % for Scan Without Evidence of Dopaminergic Deficit (SWEDD) vs. Normal Control (NC) classification, 83.79 % for PD vs. NC, and 91.50 % for PD vs. SWEDD. The results demonstrate that the proposed method improves PD classification and prediction performance, showing promise for early diagnostic applications.},
  archive      = {J_ESWA},
  author       = {Haojie Song and Haijun Lei and Yukang Lei and Zhongwei Huang and Jiaqiang Li and Tianfu Wang and Peng Yang and Baiying Lei},
  doi          = {10.1016/j.eswa.2025.129556},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129556},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multimodal joint subspace model for parkinson’s disease diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A spectral relevance analysis approach to pattern recognition of financial time series. <em>ESWA</em>, <em>298</em>, 129555. (<a href='https://doi.org/10.1016/j.eswa.2025.129555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding patterns in financial time series is crucial for improving prediction accuracy in algorithmic trading and risk management. This paper presents a novel AI-based computer vision approach for classifying financial time series. Historical price sequences are transformed into Gramian Angular Difference Field (GADF) images and fed into a convolutional neural network (CNN) for pattern recognition. To interpret the CNN’s decision-making process, we apply Spectral Relevance Analysis (SpRAy), enabling the identification of distinct clusters based on relevance maps. Clustering the images according to their relevance profiles reveals groups with significantly higher predictive performance compared to the full dataset. The corresponding relevance patterns highlight favorable price movement structures and are identified via the associated clusters.},
  archive      = {J_ESWA},
  author       = {Christine Distler and Yarema Okhrin and Jonathan Pfahler},
  doi          = {10.1016/j.eswa.2025.129555},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129555},
  shortjournal = {Expert Syst. Appl.},
  title        = {A spectral relevance analysis approach to pattern recognition of financial time series},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel object detection system for computer night vision images using residual 3D transformer-based YoloV8 with adaptive GRU in edge and cloud sector. <em>ESWA</em>, <em>298</em>, 129554. (<a href='https://doi.org/10.1016/j.eswa.2025.129554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object identification is one of the computer vision-based methods used in locating and labelling objects in images. Object detection has been greatly advanced as it is now applicable for detecting night vision images with great accuracy. Most accurate object detection at night can be useful in many applications like nighttime driving, regulating harsh traffic in harsh weather conditions, and surveillance. Object detection in normal conditions can be smoother, but low illumination and harsh weather can lead to low versatility. Images captured at night can reflect a lot of noise with low visual features. Due to its challenging nature, a highly effective object detection model is a challenge for high-level applications. Traditional models still face issues and challenges related to uneven light conditions, brightness variations, different light sources, and noisy backgrounds that need to be addressed. Thus, it is necessary to develop an object detection model for dealing with images with low illumination and varying light conditions. Hence, in this work, an effective object detection framework is implemented for night vision images. At first, from the standard datasets, the significant night vision images are fetched and fed into the proposed model as a Residual 3D Transformer-based YoloV8 with an Adaptive Gated Recurrent Unit (R3DT-YAGRU) for detecting the objects. This includes combining spatial–temporal modelling capabilities into YOLOv8, particularly using 3D transformers for improved feature extraction and an adaptive GRU to manage temporal dependencies at night. Here, the Modified Random Variable-based Dollmaker Optimization Algorithm (MRV-DOA), which is a metaheuristic algorithm motivated by the doll-making procedure. Also, it helps in balancing the exploration phase and exploitation phase to discover the best solutions and is used for tuning the parameters of the R3DT-YAGRU model. At last, the experimental validation is carried out for the recommended object detection process by comparing with other models to establish the supremacy of the suggested work. From the study, the suggested framework achieves an accuracy of 96%, leading to enhanced decision making and better accuracy than other conventional models. The work has prepared its implementation accessible at https://github.com/charlesvprabhu56/Object-Detection .},
  archive      = {J_ESWA},
  author       = {V.Charles Prabu and Queen Mary Vidya. M and V. Sathiyamoorthi and P. Durgadevi and M. Gowthami},
  doi          = {10.1016/j.eswa.2025.129554},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129554},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel object detection system for computer night vision images using residual 3D transformer-based YoloV8 with adaptive GRU in edge and cloud sector},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning diversified features for pulmonary hypertension detection using chest X-ray. <em>ESWA</em>, <em>298</em>, 129553. (<a href='https://doi.org/10.1016/j.eswa.2025.129553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to traditional Computed Tomography (CT) scans and floatation catheters, chest X-ray offers an efficient, safe and timely examination paradigm, with broader range of scenarios (including intensive care units), for the detection of Pulmonary Arterial Hypertension (PAH). However, it is difficult to learn the variable radiological features of PAH from X-rays due to its low resolution and low contrast. To address the above issues, we propose a diversified features learning framework to fully explore the PAH-related representation from chest X-ray. We first employ a Chest Feature Enhancement Attention (CFEA) module to enhance the initial feature representation. Then, we employ the Deep Temporal Anti-Interference Metric Learning (TAIML) module to fully explore the PAH-related features. We incorporate the information on the temporal evolution of patients’ conditions. Specifically, a patient x , after undergoing treatment, may exhibit two possible states: x + (ill) and x − (cured). Therefore, we can define the distance d ( x , x + ) as the intra-class structural distance, and the distance d ( x , x − ) as the inter-class safe distance. Unlike existing metric learning, we adopt a new strategy: we push positive samples towards negative samples, but ensure distance between them is no less than d ( x , x − ) , thereby enhancing intra-class diversity while maintaining discriminability. Meanwhile, we ensure that the distance between positive samples is greater than d ( x , x + ) , thereby preserving the intra-class structure. Through these two steps, we can learn a diversified but discriminative representation of PAH. Comprehensive experiments showed the our model achieved an impressive accuracy of 86.27 % and an AUC of 0.857 in identifying PAH patients. The code is available at https://github.com/zgfdmn/PAH .},
  archive      = {J_ESWA},
  author       = {Chengjin Yu and Huanghui Wang and Yuanting Yan and Zhuyang Chu and Dongsheng Ruan},
  doi          = {10.1016/j.eswa.2025.129553},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129553},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning diversified features for pulmonary hypertension detection using chest X-ray},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TriHAtt-BERT-DBiLSTM: Deep learning model for medical emergency prediction from the unstructured data. <em>ESWA</em>, <em>298</em>, 129552. (<a href='https://doi.org/10.1016/j.eswa.2025.129552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the emergency triage has faced several challenges, including insufficient manual triage with physicians, limited medical resources contributing to incorrect triage, overcrowding in the emergency department (ED), and extended patient waiting time. Hence, the Medical Emergency prediction remains the major research area that identifies emergencies about specific diseases using the Medical Transcriptions (MT) provided by physicians. However, the existing methods face the challenges of handling the ambiguity of words, unstructured data, and increased computation complexity. Consequently, this research proposes the Tri-Head Attention-based Bidirectional Encoder Representations from Transformers enabled Distributed Bidirectional Long-Short Term Memory (TriHAtt-BERT-DBiLSTM) for predicting medical emergencies. Specifically, the proposed approach integrates the Tri-Head Attention mechanisms into BERT, which is further hybridized with the DBiLSTM model that offers the synergic strength of providing the dense feature representations to capture the complex dependencies, and enhancement of model ability with the structured parameters to facilitate the medical emergency prediction. Besides, the utilization of BERT in the proposed approach assists in capturing more complex language representations and further executes a better embedding representation of words. The TriHAtt-BERT-DBiLSTM model surpasses other state-of-the-art techniques and achieves 96.40% of accuracy, 96.12% of F1-score, 96.09% of precision, and 96.15% of recall for medical emergency prediction.},
  archive      = {J_ESWA},
  author       = {Amita Mishra and Sunita Soni},
  doi          = {10.1016/j.eswa.2025.129552},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129552},
  shortjournal = {Expert Syst. Appl.},
  title        = {TriHAtt-BERT-DBiLSTM: Deep learning model for medical emergency prediction from the unstructured data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). System-level integration of deep learning and computer vision for contact ring seal defect detection in semiconductor manufacturing. <em>ESWA</em>, <em>298</em>, 129551. (<a href='https://doi.org/10.1016/j.eswa.2025.129551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contact ring seals (CRSs) used in electroplating processes during semiconductor manufacturing are susceptible to degradation through chemical etching, electrochemical dissolution, and mechanical wear mechanisms. Despite the implementation of state-of-the-art surface treatment and coating technologies to mitigate CRS corrosion, manual intervention remains frequently required to address this problem. Conventional static defect detection systems for CRSs rely on predefined regions of interest (ROIs) and threshold-based defect area calculations, with surface anomalies identified by comparing the percentage of defective areas within these ROIs. However, this approach exhibits detection failures for millimeter-scale defects, low-contrast anomalies, and geometrically irregular patterns, especially under complex or dynamic environmental conditions. To address these systematic detection failures, we developed a dynamic defect detection system for CRSs by integrating artificial intelligence and traditional computer vision algorithms, achieving a 5.2x improvement in defect detection sensitivity. This system achieved detection accuracy and recall values of over 99 % as well as a response time of 1.43 s average latency, thereby demonstrating a substantial performance improvement compared to a static system, which achieved a recall rate of 18.9 % on the adopted dataset. The system satisfies real-time processing requirements while substantially reducing the need for manual intervention in defect detection and increases production efficiency. Finally, the experimental results of this study indicated that the postprocessing approaches used in the developed system enabled it to flexibly adapt to the different requirements of various production environments.},
  archive      = {J_ESWA},
  author       = {Ting-Han Chen and Hsin-Hung Chou and Shuang Zou and Yu-Han Chen and Sun-Yuan Hsieh},
  doi          = {10.1016/j.eswa.2025.129551},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129551},
  shortjournal = {Expert Syst. Appl.},
  title        = {System-level integration of deep learning and computer vision for contact ring seal defect detection in semiconductor manufacturing},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complementary information-guided interactive fusion network for HSI and LiDAR data joint classification. <em>ESWA</em>, <em>298</em>, 129549. (<a href='https://doi.org/10.1016/j.eswa.2025.129549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of land remote sensing using single-modal data has reached a bottleneck, which has spurred significant interest in the joint utilization of multimodal remote sensing data to enhance classification performance. However, existing methods exhibit limitations in extracting intricate local and global features. Furthermore, achieving effective information interaction and deep fusion between multimodal datasets remains an unresolved challenge. To address these issues, we propose a Complementary Information-Guided Interactive Fusion Network (CIGIF-Net) for the classification of hyperspectral image (HSI) and light detection and ranging (LiDAR) data. The core idea of our approach leverages the capability of Convolutional Neural Networks (CNNs) to extract local spatial features while utilizing the strengths of Transformers in modeling long-range dependencies. Furthermore, our method facilitates deep fusion by designing mechanisms for the interactive integration of multimodal local spatial features, complemented by guidance from multimodal data during long-range dependency modeling, thereby improving overall classification performance. Specifically, CIGIF-Net incorporates multiscale feature learning, interactive feature fusion, and the complementary information-guided attention mechanism. Initially, CNNs are used to learn multiscale local spatial features. Subsequently, we perform an interactive fusion of multimodal spatial information based on channel attention techniques. Finally, the complementary information-guided attention mechanism dynamically utilizes complementary insights to inform deeper attention distributions, which guide global feature construction and enable efficient information aggregation. This methodology allows for the comprehensive extraction and synergistic utilization of complementary information across multimodal datasets. Extensive experiments conducted on three widely recognized HSI and LiDAR datasets demonstrate that the proposed CIGIF-Net achieves superior classification performance.},
  archive      = {J_ESWA},
  author       = {Shufang Xu and Qiyuan Xue and Zhonghao Chen and Shuyu Fei and Hongmin Gao},
  doi          = {10.1016/j.eswa.2025.129549},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129549},
  shortjournal = {Expert Syst. Appl.},
  title        = {Complementary information-guided interactive fusion network for HSI and LiDAR data joint classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GPT–empowered question–answer dataset for informative and empathetic support for korean childhood cancer survivors. <em>ESWA</em>, <em>298</em>, 129548. (<a href='https://doi.org/10.1016/j.eswa.2025.129548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite improvements in survival rates, childhood cancer survivors in South Korea still face significant challenges in accessing the psychological and informational support they need. To address these challenges, we developed the Korean Childhood Cancer Survivor Question-Answer (KCCSQA) dataset in which contains 3876 question-answer pairs. The questions were sourced from websites, academic articles, and an online survey, where 119 childhood cancer survivors contributed 1283 questions. We used GPT-4 Turbo to generate the responses, followed by an expert evaluation by 11 specialists to ensure factual accuracy, complementarity, comprehensibility, and empathy. The overall quality of the GPT-generated responses was rated 4.98 out of 6, indicating a high level of quality. To enhance the dataset, we integrated a relational knowledge graph to mitigate hallucinations in the AI-generated answers, achieving a performance of 0.979 in hallucination detection. Additionally, a pseudo-scoring system was implemented for continuous quality assessment. The dataset’s effectiveness was evaluated through a pilot study involving 14 childhood cancer survivors, who interacted with a retrieval-based QA system using a single-turn chatbot format. The mean satisfaction rating was 4.36 on a 6-point Likert scale, and all participants expressed a willingness to use the system again.},
  archive      = {J_ESWA},
  author       = {Kyubum Hwang and Mirae Kim and Min Ah Kim and Chaerim Park and Yehwi Park and Chungyeon Lee and Jooyoung Lim and Hayoung Oh},
  doi          = {10.1016/j.eswa.2025.129548},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129548},
  shortjournal = {Expert Syst. Appl.},
  title        = {GPT–empowered question–answer dataset for informative and empathetic support for korean childhood cancer survivors},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A decision support system for open-pit mining optimisation with dynamic uncertainty and GPU-based parallel repair approach. <em>ESWA</em>, <em>298</em>, 129544. (<a href='https://doi.org/10.1016/j.eswa.2025.129544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an advanced Decision Support System (DSS) for long-term open-pit mine planning that integrates established optimization techniques—Large Neighborhood Search (LNS), Simulated Annealing (SA), and Dantzig-Wolfe decomposition—within a novel GPU-accelerated framework addressing geological uncertainty and computational complexity. The key methodological contributions include dynamic uncertainty modelling with time-dependent factors capturing geological confidence degradation and GPU-parallelized evaluation architecture enabling industrial-scale mine planning. Validation using 50,000 blocks across 10 geological scenarios demonstrates robust economic performance, achieving mean NPV of $1.514 billion with limited variability (standard deviation $16 million). The GPU-parallelized architecture achieves 29.6 % average computational speedup with peaks of 37 % compared to CPU implementations, enabling concurrent evaluation of 262,144 mining scenarios. Risk analysis reveals P90 Value-at-Risk of $1.488 billion, indicating strong downside protection. The system maintains profit margins exceeding 95 % across all scenarios with cumulative cash flow reaching $1.789.4 million by period 6. Narrow risk envelopes (P10-P90 spread <$60 M) demonstrate robust performance under uncertainty, providing mining companies with practical tools for risk-informed strategic decision-making.},
  archive      = {J_ESWA},
  author       = {Iman Rahimi},
  doi          = {10.1016/j.eswa.2025.129544},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129544},
  shortjournal = {Expert Syst. Appl.},
  title        = {A decision support system for open-pit mining optimisation with dynamic uncertainty and GPU-based parallel repair approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TriHID: Towards verifiable domain adaptation-based IoT intrusion detection in heterogeneous environment. <em>ESWA</em>, <em>298</em>, 129543. (<a href='https://doi.org/10.1016/j.eswa.2025.129543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread deployment of IoT devices in daily applications, securing them against intrusions has become increasingly critical. Domain adaptation (DA)-based intrusion detection is a promising approach that transfers knowledge from a source domain to improve detection in a target IoT domain. However, effective DA methods must address various types of domain heterogeneity - such as differences in feature representation, intrusion distribution, and attack strategies. Existing intrusion detection datasets rarely consider these aspects, limiting their utility for evaluating heterogeneous DA approaches. To bridge this gap, we introduce TriHID , a new dataset specifically designed to capture heterogeneities from three perspectives. We evaluate four types of DA-based IoT intrusion detectors - multi-source, semi-supervised, unsupervised, and open-set on TriHID. Experimental results demonstrate that TriHID enables robust training and comprehensive evaluation of DA-based intrusion detection methods in heterogeneous IoT settings.},
  archive      = {J_ESWA},
  author       = {Jiashu Wu and Yang Wang},
  doi          = {10.1016/j.eswa.2025.129543},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129543},
  shortjournal = {Expert Syst. Appl.},
  title        = {TriHID: Towards verifiable domain adaptation-based IoT intrusion detection in heterogeneous environment},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective dynamic flexible job shop scheduling using multi-head network-based deep reinforcement learning. <em>ESWA</em>, <em>298</em>, 129542. (<a href='https://doi.org/10.1016/j.eswa.2025.129542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern manufacturing environments, job shop scheduling systems are characterized by heightened complexity and ever-changing dynamics, often involving multi-objective optimization and the need to accommodate unanticipated events like new job insertions and uncertain machine availability, underscores the necessity for effective real-time multi-objective scheduling approaches. Therefore, to tackle the multi-objective dynamic flexible job shop scheduling problem (MODFJSP) involving new job insertions, this paper introduces an online scheduling framework called multi-head deep Q network (MHDQN), designed to simultaneously minimize both total tardiness and total machine idle time. The core architecture of MHDQN framework is an innovative multi-head network agent based on Dueling deep Q network (Deuling DQN), consisting of a shared network layer and objective-specific network layers. The shared network layer extracts and transforms the input global state features layer by layer, generating a high-dimensional, semantically rich shared feature. This provides a unified input foundation for the objective-specific network layers, which are responsible for extracting the specialized information related to each objective from the shared features and calculating the corresponding Q -values, thereby enabling the parallel optimization of each objective. Six combined scheduling rules are developed to form the action set, each incorporating both job and machine selection. An improved multi-objective action selection strategy is proposed, incorporating inverse sigmoid ϵ decay and Q -value maximum absolute (max-abs) normalization to optimize decision-making. Additionally, a multi-head network training mechanism leveraging the Double deep Q network (Double DQN) architecture has been developed. Extensive computational experiments demonstrate that the MHDQN outperforms widely used traditional scheduling rules, multi-objective metaheuristic algorithms, and other reinforcement learning (RL) based scheduling methods, showing significant advantages and strong generalizability in multi-objective optimization tasks.},
  archive      = {J_ESWA},
  author       = {Kai Li and Bao Zheng and Liping Xu and Fulong Xie and Zhicheng Wang},
  doi          = {10.1016/j.eswa.2025.129542},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129542},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective dynamic flexible job shop scheduling using multi-head network-based deep reinforcement learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A possibilistic programming approach in an integrated fuzzy periodic review model and clustering strategy for optimizing platelet supply chain. <em>ESWA</em>, <em>298</em>, 129539. (<a href='https://doi.org/10.1016/j.eswa.2025.129539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Managing platelet supply chains poses significant challenges due to the product’s short shelf life, highly uncertain demand, and the critical nature of its medical use. Previous studies in the blood supply chain rely on fixed-order quantities and ignore collaborative inventory-sharing strategies, which can lead to either excessive waste or severe shortages. However, in many real-world situations, fixed order quantities are often insufficient to accommodate fluctuating demand, especially in healthcare systems. Moreover, existing distribution models in the literature often overlook the equitable allocation of services across hospitals, leading to disparities in access to critical healthcare resources. This study proposes a novel two-phase decision-making framework that integrates a fuzzy periodic review inventory model with a cluster-based reactive transshipment strategy to optimize platelet supply and distribution. In Phase I, a fuzzy periodic review model determines optimal order quantities under uncertain demand using a possibilistic chance-constrained programming approach. In Phase II, hospitals are clustered based on service levels, enabling equitable transshipment among facilities to reduce disparities and improve overall responsiveness. A real-world case study from Tehran province is used to evaluate the model’s effectiveness. Results show an approximate 6% reduction in total shortages and a 2% improvement in average service levels. The proposed framework offers actionable insights for healthcare managers aiming to enhance resilience, equity, and efficiency in critical medical supply chains.},
  archive      = {J_ESWA},
  author       = {Seyyed-Mahdi Hosseini-Motlagh and Mohammad Reza Ghatreh Samani and Hannaneh Kordhaghi},
  doi          = {10.1016/j.eswa.2025.129539},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129539},
  shortjournal = {Expert Syst. Appl.},
  title        = {A possibilistic programming approach in an integrated fuzzy periodic review model and clustering strategy for optimizing platelet supply chain},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep-insights guided evolutionary algorithm for optimization. <em>ESWA</em>, <em>298</em>, 129538. (<a href='https://doi.org/10.1016/j.eswa.2025.129538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) are a class of optimization algorithms inspired by the theory of biological evolution. They solve optimization problems by emulating the processes of natural selection. EAs produce abundant data during evolution, which contains valuable information that reflects their evolutionary patterns. Effectively utilizing this information can enhance the algorithms’ effectiveness and efficiency. Deep learning excels at extracting knowledge from data. Inspired by this, we propose a novel insights-infused framework that utilizes deep neural networks to learn the evolutionary processes of EAs and extract useful synthesis insights from the evolutionary data. These synthesis insights not only guide the algorithm to evolve in a better direction on the original problems, but also improve its performance on new problems. The choice of neural networks is important. During pre-training, to reduce the inductive bias introduced by human prior knowledge, we design an MLP model to process the data. Additionally, we develop a variable-length encoding method to enable MLP networks to handle variable-length data. To verify the transfer evolution ability of synthesis insights, we devise a self-evolution strategy that fine-tunes the network using only the data generated by the algorithm itself, without introducing any external knowledge, when dealing with new problems. Experimental results demonstrate that the synthesis insights extracted from the CEC2014 dataset guide the algorithms to evolve in a better direction for the CEC2014 problems, and in addition enhance their performance on new problems like CEC2017, CEC2022 and the real-world optimization problems.},
  archive      = {J_ESWA},
  author       = {Kun Bian and Juntao Zhang and Hong Han and Jun Zhou and Yifei Sun and Shi Cheng},
  doi          = {10.1016/j.eswa.2025.129538},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129538},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep-insights guided evolutionary algorithm for optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MambaGen: Efficient visual representation learning for automatic radiology report generation. <em>ESWA</em>, <em>298</em>, 129537. (<a href='https://doi.org/10.1016/j.eswa.2025.129537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation focuses on producing comprehensive and clinically precise medical reports based on radiographic images, thereby improving medical efficiency and alleviating the burden on radiologists. Although existing deep learning methods have demonstrated superior performance, they are constrained by the local receptive field of convolutional neural networks and are inadequate for modeling long-range dependencies, making it challenging to detect critical lesion features in medical images. Recently, State Space Models (SSMs), particularly Mamba, have shown great potential in modeling long-range dependencies with linear computational complexity. Inspired by this, we propose MambaGen, the enhanced Mamba model specifically designed for radiology report generation tasks. Specifically, we design a Mamba-Visual Recalibration Module (MVRM), which utilizes a two-stage training strategy to effectively capture the efficient visual representation of medical images. This first stage combines convolutional layers with SSMs to model long-sequence dependencies and learn multi-level visual feature information. This second stage introduces local convolution and a channel attention mechanism to further recalibrate the local feature and mitigate channel redundancy. Comprehensive experiments on widely available datasets, such as IU X-Ray and MIMIC-CXR, demonstrate our model’s superior performance compared to existing methods, particularly with an improvement of 2.7 % on the BLEU-4 metric. The code is available at https://github.com/Eleanorhxd/MambaGen.git .},
  archive      = {J_ESWA},
  author       = {Xiaodi Hou and Xiaobo Li and Simiao Wang and Mingyu Lu and Hongfei Lin and Yijia Zhang},
  doi          = {10.1016/j.eswa.2025.129537},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129537},
  shortjournal = {Expert Syst. Appl.},
  title        = {MambaGen: Efficient visual representation learning for automatic radiology report generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multistep diesel vehicle emissions forecasting with an efficient transformer enhanced by temporal-frequency fusion and covariate interaction. <em>ESWA</em>, <em>298</em>, 129532. (<a href='https://doi.org/10.1016/j.eswa.2025.129532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling nitrogen oxide (NO x ) emissions from diesel vehicles is a critical environmental challenge. Advanced SCR strategies depend on accurate multistep forecasting of NO x and ammonia (NH 3 ), but existing models often struggle with error accumulation and the non-stationary dynamics of emissions data. In this work, we first establish a new benchmark for this task, confirming that handling data non-stationarity is essential for robust prediction. Building on this insight, we propose FiTformer, a novel Transformer architecture that adopts an encoder-only framework to jointly forecast both NO x and NH 3 concentrations, where we introduce Intra-series Temporal-Frequency Fusion mechanism to capture intrinsic emissions dynamics and Inter-series Covariate Interaction mechanism to model external influences. Validated on real-world engine data, FiTformer consistently outperforms baseline models across all evaluated prediction horizons, with up to 44.1 % MAE and 36.9 % SMAPE reductions in 24-step NO x prediction and similarly strong gains for NH 3 prediction, compared to the state-of-the-art baseline TimesNet. Its high computational efficiency (0.30G MACs and 8.3 ms/iter) along with robust generalization and high resilience to data imperfections, underscores its suitability for real-time embedded SCR control, enabling more effective strategies for NO x reduction and NH 3 slip minimization.},
  archive      = {J_ESWA},
  author       = {Yuhan Luo and Yujun Zhang and Ying He and Kun You and Wei Huang and Wenqing Liu and Hao Xie},
  doi          = {10.1016/j.eswa.2025.129532},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129532},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multistep diesel vehicle emissions forecasting with an efficient transformer enhanced by temporal-frequency fusion and covariate interaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An EEG-based dual-stream spatial-spectral-temporal large model for self-limited epilepsy with centrotemporal spikes. <em>ESWA</em>, <em>298</em>, 129530. (<a href='https://doi.org/10.1016/j.eswa.2025.129530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-limited epilepsy with centrotemporal spikes (SeLECTS) is the most common form of focal epilepsy in childhood, accounting for 20–25 % of all childhood epilepsy cases and may be associated with cognitive dysfunction and behavioral issues. Accurate detection and assessment of epileptic discharges in EEG signals, particularly the spike-wave index (SWI), are crucial for timely intervention and treatment. Manual analysis of EEG data is labor-intensive and prone to errors, underscoring the need for automated methods. In the present study, we propose a novel D ual-Str e am Sp a tial- S pectral- T emporal L arge model (DeaSTL) that leverages a large-scale EEG architecture to effectively capture the multidimensional characteristics of EEG signals associated with SeLECTS syndrome. Our model integrates multi-view temporal representations and spatial-spectral representations through a dual-stream approach, enhancing the learning of complex patterns in EEG data. We introduce the S JTU Se L ECTS E EG D ataset (SLED), a comprehensive EEG dataset from 212 patients diagnosed with SeLECTS, including annotations for abnormal discharge detection, wake-sleep period classification, and SWI estimation. Addressing the previously unexplored problem of SWI prediction, we provide a novel method for quantifying the severity of epileptic discharges during sleep. Extensive experiments demonstrate that our DeaSTL model significantly outperforms several state-of-the-art methods across multiple tasks, showcasing its potential for clinical application in assisting diagnosis and treatment planning.},
  archive      = {J_ESWA},
  author       = {Lin Zhang and Yun Ren and Fang Yuan and Xuqin Chen and Shikui Tu and Lei Xu},
  doi          = {10.1016/j.eswa.2025.129530},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129530},
  shortjournal = {Expert Syst. Appl.},
  title        = {An EEG-based dual-stream spatial-spectral-temporal large model for self-limited epilepsy with centrotemporal spikes},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic learning of sample ambiguity-driven sample weighting for medical image classification. <em>ESWA</em>, <em>298</em>, 129527. (<a href='https://doi.org/10.1016/j.eswa.2025.129527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have delivered impressive results in medical image classification tasks. However, their performance is still challenging in medical scenarios with limited data, where training set biases such as label noise or class imbalance impede model learning. Dynamic learning based sample weighting achieves adaptive adjustment of sample importance through learnable weight functions and shows great potential in improving model robustness. Nevertheless, existing methods directly employ model states such as loss value or training accuracy to evaluate sample importance, ignoring the role of ambiguous samples in model optimization. This limitation hinders the performance of dynamic learning based sample weighting in medical image classification. In this paper, we propose a new sample weighting approach based on sample ambiguity and dynamic learning for improving medical image classification, named DLSA-SW. We introduce a dual-space sample ambiguity method by evaluating the category proximity in the feature space and the prediction confidence in the label space. Subsequently, to dynamically calculate sample weights according to sample ambiguity, a learnable sample weighting network is developed to adaptively adjust the weights during training to guide the task model. DLSA-SW performs alternate optimization to enable mutual adaptation of the sample weighting network and the task network. We evaluate the effectiveness of our approach on three medical image classification benchmarks: PatchCamelyon for lymph node histopathology classification, ISIC 2020 for skin lesion classification, and MTC for medullary thyroid cancer classification. DLSA-SW outperforms existing state-of-the-art sample weighting methods on all three datasets and yields substantial improvements over methods without sample weighting. These results demonstrate the robustness and practical applicability of our approach in clinical diagnostic tasks.},
  archive      = {J_ESWA},
  author       = {Guanxiu Yi and Xiabi Liu and Ling Ma and Mengqiao Han and Lijuan Niu},
  doi          = {10.1016/j.eswa.2025.129527},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129527},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic learning of sample ambiguity-driven sample weighting for medical image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LST-rPPG: A long-range spatio-temporal model for high-accuracy heart rate variability measurement. <em>ESWA</em>, <em>298</em>, 129526. (<a href='https://doi.org/10.1016/j.eswa.2025.129526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG) is a non-contact manner of measuring heart rate variability (HRV) by deriving blood volume pulse (BVP) signals from facial videos. The performance of rPPG-based HRV measurement is challenging due to short-range noises (e.g., head movements) suppression and sufficient-duration BVP signal generation. Recent Transformer-based rPPG methods have shown advantages of global spatio-temporal feature modeling in eliminating noise and recovering high-quality BVP signals. However, these methods often face significant computational and memory constraints, limiting duration scalability of the generated BVP signals that might decrease HRV measurement performance. To address the above issue, this paper proposes a duration-scalable Transformer-based rPPG method, capable of global Long-range Spatio-Temporal modelling (LST), termed LST-rPPG, to generate high-quality BVP signals with a much longer duration. On the one hand, by employing spatial and temporal encoders, the original image-based rPPG issue is converted to a time-series problem. Besides, a sparse computation mechanism is integrated into the temporal encoder. This combination allows LST-rPPG to recover flexible-duration BVP signals, supporting continuous modeling of segments beyond 30 s with low computation and memory overhead. On the other hand, a dynamic loss function with stringent temporal constraints is designed to guarantee the quality of the generated BVP signals. Comprehensive experiments are performed on two public datasets, PURE and UBFC-RPPG, and the results demonstrate the feasibility of LST-rPPG for generating high-quality BVP signals with a much longer duration while requiring substantially fewer computational resources. Besides, LST-rPPG achieves at least the second-best results during all experiments.},
  archive      = {J_ESWA},
  author       = {Jiajie Li and Juan Cheng and Rencheng Song and Yu Liu},
  doi          = {10.1016/j.eswa.2025.129526},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129526},
  shortjournal = {Expert Syst. Appl.},
  title        = {LST-rPPG: A long-range spatio-temporal model for high-accuracy heart rate variability measurement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel scheme integrating graph-based analysis and opposition-based learning for S-box optimization by population-based metaheuristics. <em>ESWA</em>, <em>298</em>, 129524. (<a href='https://doi.org/10.1016/j.eswa.2025.129524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The non-linearity of symmetric block cryptographic algorithms, which is crucial for resisting linear and differential cryptanalysis, depends on the design of substitution boxes. This work proposes a novel scheme, named GOM, combining opposition-based learning with graph-based representation to be integrated into three population-based metaheuristics. This scheme is applied to address the 8 × 8 S-box design problem. The GOM-enhanced metaheuristics improve population diversity and convergence, achieving a non-linearity of 112. Hardware simulations indicate that GOM-based designs require similar resources to AES, while side-channel evaluations confirm their resilience against power analysis attacks. Scalability is supported by successful results on 10 × 10 and 12 × 12 S-boxes. The design of GOM, leveraging generalizable components such as opposition-based learning and graph-based representations, suggests its potential applicability to other population-based metaheuristics and optimization problems.},
  archive      = {J_ESWA},
  author       = {Francisco González and Ricardo Soto and José M. Lanza-Gutiérrez and Broderick Crawford},
  doi          = {10.1016/j.eswa.2025.129524},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129524},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel scheme integrating graph-based analysis and opposition-based learning for S-box optimization by population-based metaheuristics},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Functional consistency of LLM code embeddings: A self-evolving data synthesis framework for benchmarking. <em>ESWA</em>, <em>298</em>, 129523. (<a href='https://doi.org/10.1016/j.eswa.2025.129523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding models have demonstrated strong performance in tasks like clustering, retrieval, and feature extraction while offering computational advantages over generative models and cross-encoders. Benchmarks such as MTEB have shown that text embeddings from large language models (LLMs) capture rich semantic information, but their ability to reflect code-level functional semantics remains unclear. Existing studies largely focus on code clone detection, which emphasizes syntactic similarity and overlooks functional understanding. In this paper, we focus on the functional consistency of LLM code embeddings, which determines if two code snippets perform the same function regardless of syntactic differences. We propose a novel data synthesis framework called Functionality-Oriented Code Self-Evolution to construct diverse and challenging benchmarks. Specifically, we define code examples across four semantic and syntactic categories and find that existing datasets predominantly capture syntactic properties. Our framework generates four unique variations from a single code instance, providing a broader spectrum of code examples that better reflect functional differences. Extensive experiments on three downstream tasks-code clone detection, code functional consistency identification, and code retrieval-demonstrate that embedding models significantly improve their performance when trained on our evolved datasets. These results highlight the effectiveness and generalization of our data synthesis framework, advancing the functional understanding of code.},
  archive      = {J_ESWA},
  author       = {Zhuohao Li and Wenqing Chen and Jianxing Yu and Zhichao Lu},
  doi          = {10.1016/j.eswa.2025.129523},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129523},
  shortjournal = {Expert Syst. Appl.},
  title        = {Functional consistency of LLM code embeddings: A self-evolving data synthesis framework for benchmarking},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semisupervised graph U-net with G-ConvLSTM for hyperspectral image classification. <em>ESWA</em>, <em>298</em>, 129522. (<a href='https://doi.org/10.1016/j.eswa.2025.129522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have demonstrated the effectiveness for hyperspectral image (HSI) classification, but still face challenges, such as insufficient exploitation of data structure information, limited labeled samples, and high susceptibility to noise and outliers. To address these issues, a semisupervised graph U-Net with graph convolutional long short-term memory is proposed for HSI classification, abbreviated as SSGU-Net. Specifically, we design a novel graph convolutional long short-term memory feature extractor to learn discriminative spatial-spectral joint features by simultaneously modeling the correlations in the spatial and spectral domains. Then, we develop a semisupervised graph U-Net with mutually inverse operation of the graph pooling and the graph unpooling modules which uses both labeled samples and unlabeled samples to train a well-parameterized network for HSI classification. In particular, to suppress the effects of noise and outliers, the graph pooling module is designed to selectively retain discriminative samples and fully learn the optimal correlation between these retained samples. Meanwhile, the graph unpooling module employs the local spatial context to reconstruct the reduced samples, thus restoring the pooled data to its original scale for classification task. Extensive experiments show the effectiveness of the proposed method, achieving overall accuracy gains of 5.22 %, 1.58 %, and 1.57 % over the state-of-the-art competitors on the Indian Pines, University of Pavia, and Houston datasets, respectively.},
  archive      = {J_ESWA},
  author       = {Jin-Yu Yang and Heng-Chao Li and Xin-Ru Feng and Feng Gao and Qian Du and Antonio Plaza},
  doi          = {10.1016/j.eswa.2025.129522},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129522},
  shortjournal = {Expert Syst. Appl.},
  title        = {Semisupervised graph U-net with G-ConvLSTM for hyperspectral image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Chat with one voice: Mitigating semantic disparity across languages for multilingual open-domain dialogue response generation systems. <em>ESWA</em>, <em>298</em>, 129521. (<a href='https://doi.org/10.1016/j.eswa.2025.129521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the Internet, building a multilingual dialogue generation system to attract more users while reducing costs in the global market has become increasingly important. However, current end-to-end multilingual approaches often face semantic disparity issues across languages. When given parallel queries with the same semantics but in different languages, the generated responses may vary in meaning across languages, which may greatly affect the stability and reliability of multilingual systems in different language scenarios. We attribute this issue to open-domain/model uncertainty and language differences. To mitigate this issue, we first propose a novel Anchor-based Semantic Constraint (ASC) designed to reduce semantic disparity across languages for Encoder-Decoder Transformers. ASC employs language-independent anchor signal to guide the behaviors in both the encoder and decoder, thereby reducing uncertainty. Additionally, ASC incorporates a two-stage tuning process to further minimize the impact of language differences by ensuring the encoder remains language-independent. Extensive experiments and in-depth analyses conducted on XDailyDialog demonstrate that ASC can effectively mitigate semantic disparity across languages and will not compromise dialogue response quality like the previous related baselines.},
  archive      = {J_ESWA},
  author       = {Sixing Wu and Jiahao Chen and Jiong Yu and Wei Zhou},
  doi          = {10.1016/j.eswa.2025.129521},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129521},
  shortjournal = {Expert Syst. Appl.},
  title        = {Chat with one voice: Mitigating semantic disparity across languages for multilingual open-domain dialogue response generation systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards CPU performance prediction: New challenge benchmark dataset and novel approach. <em>ESWA</em>, <em>298</em>, 129520. (<a href='https://doi.org/10.1016/j.eswa.2025.129520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CPU performance prediction based on hardware characteristics is crucial for system design and resource management. However, this field faces two major challenges. First, collecting real-world data is challenging due to the diversity of CPU products and the specialized nature of hardware characteristics. This field lacks a standard dataset with unified hardware characteristics, wide data coverage, and comprehensive benchmarks. Second, existing methods based on hardware simulation models or machine learning exhibit notable shortcomings, such as lengthy simulation test cycles and low prediction accuracy. To bridge these gaps, we first collect, preprocess, and standardize historical data from the 4th Generation Intel® Xeon® Scalable Processors across multiple benchmark suites to create a new dataset, named PerfCastDB. Subsequently, we design a deep learning based model called Nova CPU Performance Predictor (NCPP) as the baseline for this new dataset. The NCPP network is designed based on group attention mechanism. It effectively quantifies the implicit relationships between hardware characteristics within and across groups and comprehensively models the impact of various hardware characteristics on CPU performance prediction. We conduct comparative experiments using the proposed PerfCastDB dataset. Compared to existing approaches, NCPP achieves superior evaluation results, demonstrating its effectiveness. Furthermore, we have open-sourced part of the dataset and the NCPP network code to facilitate subsequent research. The resources can be accessed at https://github.com/xiaoman-liu/NCPP .},
  archive      = {J_ESWA},
  author       = {Xiaoman Liu},
  doi          = {10.1016/j.eswa.2025.129520},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129520},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards CPU performance prediction: New challenge benchmark dataset and novel approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Glyph graph isomorphism network for structure recognition of oracle bone inscription. <em>ESWA</em>, <em>298</em>, 129519. (<a href='https://doi.org/10.1016/j.eswa.2025.129519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structure recognition of oracle bone inscription glyphs plays an important role in studying the evolutionary process of oracle bone inscriptions and the history of the Shang Dynasty. Currently, most methods have decomposed oracle bone inscription glyphs into multilevel features, which are used to recognize hierarchical feature fusion. This strategy cannot recognize the primitive internal structures of keypoints, strokes, and components. Moreover, mainstream graph neural networks cannot fully utilize the rich structural information of oracle bone inscription glyphs, resulting in their inability to meet the needs of structure recognition. So we have developed a graph structure recognition method to implement structure recognition of oracle bone inscription glyphs. A graph extraction method is given to get the structure of oracle bone inscription glyphs; each graph structure’s representation vector can be learned by a glyph graph isomorphism network, which is developed to recognize the graph of oracle bone inscription glyphs to enhance the discriminability representation of the structure. Our model has achieved advanced results across structure recognition experiments in the HWOBC dataset and the Oracle-50K dataset.},
  archive      = {J_ESWA},
  author       = {Zhan Zhang and Hanbin Liu and Xingkun Zhang and Yiyuan Wang and Feng Gao and An Guo and Han Zhang and Qingju Jiao and Bang Li and Yongge Liu},
  doi          = {10.1016/j.eswa.2025.129519},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129519},
  shortjournal = {Expert Syst. Appl.},
  title        = {Glyph graph isomorphism network for structure recognition of oracle bone inscription},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An integrated decision-making framework to evaluate the route alternatives in overweight/oversize transportation. <em>ESWA</em>, <em>298</em>, 129516. (<a href='https://doi.org/10.1016/j.eswa.2025.129516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overweight and oversized transport (O&OT) has become one of the most critical elements of project logistics, driven by advancements in transportation and lifting technologies that now allow high-volume loads to be moved across long distances. This type of transportation operation, also called abnormal transportation, is greatly affected by technical factors such as the weight and geometry of the load, road surface, axle load limitations, slope, and ground strength, as well as external variables such as weather conditions, traffic density, and legal regulations. In planning and operational processes, Decision-Makers (DMs) and practitioners who plan and execute operations without adequately considering these factors and variables can lead to delays in operations, serious risks, and loss of productivity. This research proposes a flexible decision support model that integrates Step-wise Weight Assessment Ratio Analysis (SWARA) and Logarithmic Percentage Change-driven Objective Weighting (LOPCOW), and a ranking technique; i.e., Mixed Aggregation by Comprehensive Normalization Technique (MACONT) techniques to address the decision problems related to route selection, one of the most critical problems in transporting heavy and bulky loads, and to produce reasonable solutions. The proposed model significantly reduces information losses by processing subjective and objective information and integrating subjective (SWARA) and objective (LOPCOW) methods. Unlike traditional ranking approaches, the MACONT method combines three different normalization techniques to determine the ranking performance of alternatives. In this way, it provides more reliable and accurate results by reducing the deviations of the results provided by the single normalization technique. In addition, it shows each alternative’s good and bad performance compared to the others and is more convincing about the results obtained. According to the results obtained by applying the proposed model, fuel consumption (0.096) is determined as the most effective and critical factor in selecting the route on which heavy and bulky loads will be transported. In this context, choosing routes that allow lower fuel consumption can contribute to reducing carbon emissions and external costs arising from transportation. The extensive robustness and validation check to test the proposed model prove that the proposed model is a reliable, robust, and practical decision-making tool for making reasonable and rational decisions in O&OT.},
  archive      = {J_ESWA},
  author       = {Ömer Faruk Görçün and Pradip Kundu and Hande Küçükönder and Gürkan Doğan and Erfan Babaee Tirkolaee},
  doi          = {10.1016/j.eswa.2025.129516},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129516},
  shortjournal = {Expert Syst. Appl.},
  title        = {An integrated decision-making framework to evaluate the route alternatives in overweight/oversize transportation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EvoMapX: An explainable framework for metaheuristic optimization algorithms. <em>ESWA</em>, <em>298</em>, 129514. (<a href='https://doi.org/10.1016/j.eswa.2025.129514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population-based optimization algorithms (POAs) are widely adopted solutions for NP-hard and complex high-dimensional optimization problems. However, their internal dynamics often remain opaque, limiting trust and insight into how solutions evolve. This paper introduces EvoMapX, a novel explainable framework designed to interpret the internal dynamics of population-based optimization algorithms. EvoMapX includes three interpretable structures to visualize evolutionary optimization dynamics: the Operator Attribution Matrix (OAM) quantifies the contribution of specific operators over iterations; the Population Evolution Graph (PEG) traces the ancestry and transformation of candidate solutions; and the Convergence Driver Score (CDS) identifies which operators drive convergence, helping interpret why the algorithm improved. EvoMapX was evaluated across four POAs on the CEC 2021 test suite in order to demonstrate how it reveals meaningful textual and graphical insights into algorithm behavior. EvoMapX paves the way for interpretable metaheuristic optimization. The source code of EvoMapX is available at https://www.github.com/Bilal20252025/EvoMapX},
  archive      = {J_ESWA},
  author       = {Bilal H. Abed-Alguni},
  doi          = {10.1016/j.eswa.2025.129514},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129514},
  shortjournal = {Expert Syst. Appl.},
  title        = {EvoMapX: An explainable framework for metaheuristic optimization algorithms},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BDOS: An orthogonal sum based on belief of permutation events and element distances in random permutation set. <em>ESWA</em>, <em>298</em>, 129513. (<a href='https://doi.org/10.1016/j.eswa.2025.129513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random permutation set (RPS) extends Dempster-Shafer evidence theory by incorporating event order information, providing a powerful framework for modeling uncertainty. However, existing orthogonal sum methods within the RPS framework may encounter loss of order information and counterintuitive belief distribution during permutation event fusion. To address these two issues, this paper proposes a new method termed belief-distance-based orthogonal sum (BDOS). BDOS operates through three core mechanisms: order-information preservation via mathematical constructs like order-space and inverse mapping; belief-value weighting that prioritizes events with high belief mass for rational outcomes; and element-distance weighting that incorporates dissimilarity among permutations to improve ordinal accuracy. Numerical examples validate the effectiveness of BDOS in permutation event fusion, with comparative results demonstrating its advantages in order retention and belief distribution. Furthermore, BDOS is applied to threat assessment, illustrating its rationality and effectiveness in handling uncertainty and threat ranking.},
  archive      = {J_ESWA},
  author       = {Xiaoyan Su and Xu Chen and Hong Qian and Cheng Jiang},
  doi          = {10.1016/j.eswa.2025.129513},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129513},
  shortjournal = {Expert Syst. Appl.},
  title        = {BDOS: An orthogonal sum based on belief of permutation events and element distances in random permutation set},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fine-grained similarity retrieval of lesion areas in lung CT images based on visual similarity matching of image blocks. <em>ESWA</em>, <em>298</em>, 129510. (<a href='https://doi.org/10.1016/j.eswa.2025.129510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Objective With the rapid growth in the number of medical images, the need for content- based medical image retrieval (CBMIR) in clinical aid diagnosis is becoming increasingly important. Most current content-based CT image similarity retrieval methods use the entire CT image, ignoring the fact that the localized lesion region is the main target of similarity retrieval; Methods To address this issue, the paper proposes a fine-grained similarity retrieval method for lung CT images based on image block( IB ) similarity matching, taking lung CT images as an example. In this method, two enabling techniques are introduced: 1) a hybrid Convolution and Vision Transformer Model(CVTM) that effectively captures both local texture and global context features of lesion regions; 2) the iDS high-dimensional index designed to accelerate retrieval among IB ; Results With the aid of these techniques, fine-grained similarity retrieval optimization of lung CT images can be achieved, which facilitates more accurate lesion-level comparison and supports clinical decision-making; Conclusions Extensive experiments are conducted to indicate that the proposed fine-grained similarity retrieval method achieves excellent performance, with a mAP of 91.33%. Meanwhile, the retrieval efficiency of the iDS high-dimensional index is about 150% higher than that of sequential retrieval, especially when the retrieval radius is large and the database size is substantial.},
  archive      = {J_ESWA},
  author       = {Yi Zhuang and Jiayu Zhang and Yujia Ge and Nan Jiang},
  doi          = {10.1016/j.eswa.2025.129510},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129510},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fine-grained similarity retrieval of lesion areas in lung CT images based on visual similarity matching of image blocks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Traffic prediction using an active causality recurrent graph convolutional network. <em>ESWA</em>, <em>298</em>, 129506. (<a href='https://doi.org/10.1016/j.eswa.2025.129506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of our daily lives is significantly influenced by traffic conditions, highlighting the importance of incorporating complex spatiotemporal dependencies in interconnected traffic data for effective prediction. Although recent advancements have demonstrated prediction accuracy using graph convolutional networks, their depends heavily on the accuracy of the graph structures that represent the spatial relationships within the traffic network. To address this challenge, we introduce a novel approach to traffic prediction, the Active Causal Recurrent Graph Convolution Network (ACRGCN), as shown in Fig. 2. ACRGCN offers a new framework that effectively integrates a causal-embedded approach for traffic prediction, leveraging both structural and feature information from correlated traffic time series. Additionally, it incorporates a time-varying dynamic Bayesian network to capture the intricate spatiotemporal topology of traffic data. The model extracts spatiotemporal dependencies from traffic signals using the Active Causality Graph Recurrent Module (ACGRM), while efficiently modeling nonlinear traffic propagation patterns. Furthermore, ACRGCN employs a deep learning-based module that functions as a hyper-network, progressively generating dynamic causal graphs. Finally, extensive experiments on multiple real-world traffic graph datasets validate ACRGCN, and the results demonstrate its superiority over state-of-the-art method},
  archive      = {J_ESWA},
  author       = {Jinde Zhu and Junhao Yuan and Fulan Ye and Trong-The Nguyen and Ruoxi Wang and Wu Zeng and Chien-Chun Liu},
  doi          = {10.1016/j.eswa.2025.129506},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129506},
  shortjournal = {Expert Syst. Appl.},
  title        = {Traffic prediction using an active causality recurrent graph convolutional network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Shielding federated learning: Mitigating label transferability against poisoning attacks in cloud-edge-client system. <em>ESWA</em>, <em>298</em>, 129502. (<a href='https://doi.org/10.1016/j.eswa.2025.129502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical computing architecture of cloud-edge-client (CEC) formed with the combination of cloud computing and edge computing can provide processing, storage and low-latency services close to end devices. To protect data privacy, federated learning (FL), as a novel intelligent edge computing framework with localized training mechanisms, has been integrated into edge computing to form a system called CEC-FL and is widely studied. However, they are susceptible to potential poisoning attacks. Existing poisoning attack methods are mostly explored by performing malicious operations on training samples or labels directly and implementing corresponding defense strategies: they are designed to ignore the label transferability and diverse attack environments and are not work against stealthy security threats, mainly because they do not take into account the inherent vulnerabilities of the attack environment. Yet few general defense schemes have been developed. In response to the above vulnerabilities, in this work, we explore a B arycenter Po isoning method with L abel T ransferability (BPoLT) initiated by malicious attackers, resulting in a dynamic attack capability on the CEC-FL system. To address poisoning attacks, we provide a two-phase defense algorithm Res isting L abel T ransferability Pois oning called ResLT-Pois to distinguish malicious attackers from benign participants. Extensive experimental results demonstrate that our scheme is feasible and effective in dealing with the vulnerability of the CEC-FL system.},
  archive      = {J_ESWA},
  author       = {Yaru Zhao and Yihao Cao and Jianbiao Zhang and Zhaoqian Zhang and Weiru Wang},
  doi          = {10.1016/j.eswa.2025.129502},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129502},
  shortjournal = {Expert Syst. Appl.},
  title        = {Shielding federated learning: Mitigating label transferability against poisoning attacks in cloud-edge-client system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SAMForecast: A hybrid model of self-attention and mamba with adaptive wavelet transform for time series forecasting. <em>ESWA</em>, <em>298</em>, 129498. (<a href='https://doi.org/10.1016/j.eswa.2025.129498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting faces significant challenges due to the variability and complexity of real-world data. Traditional methods often require manual adjustments of wavelet transform parameters, which are labor-intensive and prone to over-fitting or inadequate feature extraction. To address these limitations, this study proposes SAMForecast, a novel hybrid model that integrates Adaptive Wavelet Transform, self-attention mechanisms, and the selective state space model. We introduce an Adaptive Wavelet Block that dynamically adjusts decomposition levels and basis functions using a Mixture of Experts network and lifting scheme, eliminating the need for manual parameter tuning. Furthermore, the model deeply integrates the attention mechanism of the Transformer architecture, leveraging its advantages in capturing complex dependencies to identify correlations between time series data. By combining self-attention with Mamba, SAMForecast effectively captures both global dependencies and local key features in time series, enhancing robustness against noise and redundant information. SAMForecast demonstrates promising performance in multivariate time series forecasting tasks, showcasing an average 2 % performance improvement compared to existing models across datasets in energy, transportation, and other fields. The code is available at https://github.com/Kiki-V/SAMForecast-main .},
  archive      = {J_ESWA},
  author       = {Dunlu Peng and Qiqi Lin},
  doi          = {10.1016/j.eswa.2025.129498},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129498},
  shortjournal = {Expert Syst. Appl.},
  title        = {SAMForecast: A hybrid model of self-attention and mamba with adaptive wavelet transform for time series forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive hypergraph-based convolution network with dual spatiotemporal attention for PM2.5 forecasting. <em>ESWA</em>, <em>298</em>, 129497. (<a href='https://doi.org/10.1016/j.eswa.2025.129497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate PM2.5 prediction is crucial for effective environmental management and public health protection, yet current models show limited dynamic adaptability to complicated air pollution scenarios. Robust models are essential to support timely interventions in response to sudden pollution events or rapidly changing air quality patterns. However, existing models predominantly rely on predefined graph structures and pairwise spatial relationships, limiting their ability to capture the complex and dynamic interactions inherent in PM2.5 pollution. Furthermore, such models often assume equal contributions from neighboring nodes, neglecting heterogeneity and compromising predictive accuracy. To address these limitations, we propose an Adaptive Hypergraph-based Convolution Network with a Dual Spatiotemporal Attention mechanism (AHCN-DA) for PM2.5 forecasting. This framework leverages representation learning and hypergraph structures to capture and integrate pairwise as well as higher-order spatial interactions, producing richer spatial-feature representations. The dual spatiotemporal attention mechanism dynamically assigns time-varying weights to neighboring nodes based on their relevance to target nodes, effectively mitigating the impact of irrelevant inputs. Additionally, AHCN-DA integrates a dilated convolution network with multi-scale kernels to capture temporal patterns effectively across varying scales. Extensive experiments on the 2023 China National Air Quality Dataset show significant improvements in predictive accuracy, particularly in enhancing the proportion of high-precision monitoring stations, with an R 2 of 0.9224, outperforming baseline models. Our findings underscore the effectiveness of AHCN-DA in enhancing prediction accuracy under complex pollution response patterns, contributing to more informed decision-making in environmental management.},
  archive      = {J_ESWA},
  author       = {Haipeng Gao and Chonghui Qian and Yang Su and Wei Zhang and Hengjun Huang},
  doi          = {10.1016/j.eswa.2025.129497},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129497},
  shortjournal = {Expert Syst. Appl.},
  title        = {An adaptive hypergraph-based convolution network with dual spatiotemporal attention for PM2.5 forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Solving equilibrium for adversarial team games utilizing fictitious team play with refined team plans. <em>ESWA</em>, <em>298</em>, 129496. (<a href='https://doi.org/10.1016/j.eswa.2025.129496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial team games represent scenarios where cooperation and competition coexist and hold numerous applications in the real world. These scenarios are particularly challenging due to asymmetric information among team members and limited communication capabilities. Fictitious team-play extend self-play algorithms to these scenarios, offering a novel approach to obtain equilibrium. However, it depends on normal-form team plans, which expand exponentially with game size, significantly constraining their applicability in large games. To overcome the challenge of computing equilibrium in large scale imperfect information team games, we propose a team self-play algorithm that utilizes refined team plans. Specifically, we pre-solve the equilibrium in a perfect recall environment to extract essential team plans from the original strategy space. To adapt these plans to an imperfect recall environment, we construct an auxiliary game with transformed ex ante coordinated information based on the original game and then solve equilibrium in auxiliary game to derive equilibrium for the original game. The experiments demonstrate the effectiveness of our team self-play algorithm in eight different Kuhn poker scenarios. Compared to existing team self-play algorithms, our method efficiently handles large games and exhibits superior convergence compared to reinforcement learning based algorithms. Additionally, our experiments offer valuable insights and guidance on adapting equilibrium strategies from perfect recall environments to those with imperfect recall.},
  archive      = {J_ESWA},
  author       = {Jinheng Xiao and Chen Qiu and Yingying Xu and Jiajia Zhang and Shuhan Qi and Xuan Wang},
  doi          = {10.1016/j.eswa.2025.129496},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129496},
  shortjournal = {Expert Syst. Appl.},
  title        = {Solving equilibrium for adversarial team games utilizing fictitious team play with refined team plans},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Proactive-BiLSTM: Glaucoma detection using FUNDUS and OCT retinal images. <em>ESWA</em>, <em>298</em>, 129490. (<a href='https://doi.org/10.1016/j.eswa.2025.129490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma detection identifies the early signs of eye conditions that can lead to vision loss by analyzing the retinal images to detect abnormalities, such as increased intraocular pressure, changes in the optic nerve head, or structural alterations in the retina. The challenges faced by the existing models include the difficulty in detecting subtle features, variability in image quality, and complex patterns that may resemble normal variations. Moreover, the traditional models struggle to adapt to the evolving patient data, capture long-term dependencies, and often suffer from lower accuracy. Hence, this research proposes the Proactive Hybridized Bidirectional Long Short-Term Memory (BiLSTM) model for Glaucoma detection. The proactive hybridized BiLSTM model is designed to enhance the detection of glaucoma by processing the retinal images. The proactive hybridized BiLSTM model enables the model to capture complex temporal dependencies and relationships within the data, which are crucial for identifying subtle patterns indicative of glaucoma, for which multifaceted feature extraction is employed. Moreover, the Proactive Hybridized BiLSTM model adapts to dynamic changes in the data to learn and predict glaucoma-related features, ultimately improving detection performance over time. The proposed Proactive hybridized BiLSTM model attains higher accuracy, sensitivity, and specificity of 96.65%, 96.51%, and 96.79% using the OCT and FUNDUS image dataset.},
  archive      = {J_ESWA},
  author       = {M.Kiran Mayee and M.Humera Khanam and Shaik Lathifa Tabasum},
  doi          = {10.1016/j.eswa.2025.129490},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129490},
  shortjournal = {Expert Syst. Appl.},
  title        = {Proactive-BiLSTM: Glaucoma detection using FUNDUS and OCT retinal images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DBCD: Deep balanced community detection via consensus-guided joint optimization in attributed networks. <em>ESWA</em>, <em>298</em>, 129487. (<a href='https://doi.org/10.1016/j.eswa.2025.129487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current deep learning methods for community detection in attributed networks face a critical limitation: they often fail to identify communities that are both structurally cohesive and semantically similar, thereby falling short of the balance typically observed in human-labeled partitions. This shortcoming stems from the absence of explicit mechanisms to jointly optimize these two objectives. In this paper, this challenge is addressed by proposing Deep Balanced Community Detection (DBCD), a novel unsupervised framework for community detection that balances topology and semantics. DBCD first constructs a powerful topology-semantic clustering consensus by integrating insights from both structural and attribute spaces. This consensus then steers a Graph Neural Network to simultaneously maximize global neural modularity and local cross-view consistency, while adaptively determining the number of communities. Extensive experiments reveal a striking result: DBCD consistently discovers communities that surpass the topology-semantic balance of the ground truth across multiple real-world networks. An empirical Pareto frontier analysis further validates that DBCD achieves a non-dominated solution, establishing it as a strong competitor among state-of-the-art methods. The source code of DBCD is available at https://github.com/wy980125/DBCD .},
  archive      = {J_ESWA},
  author       = {Yan Wang and Yupeng Liu and Xiaojie Sun and Jun Fu},
  doi          = {10.1016/j.eswa.2025.129487},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129487},
  shortjournal = {Expert Syst. Appl.},
  title        = {DBCD: Deep balanced community detection via consensus-guided joint optimization in attributed networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Network traffic forecasting with transfer learning-based algorithm for long continuous missing data. <em>ESWA</em>, <em>298</em>, 129484. (<a href='https://doi.org/10.1016/j.eswa.2025.129484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate network traffic forecasting is critical for power dispatch networks. Network traffic forecasting aims to use historical data to predict future network traffic trends. Different from other networks, the traffic data of the power dispatch network is mainly composed of the port traffic from routers and switches. However, network accidents in power enterprises can cause long periods of missing network traffic data, reducing the number of learning samples for network traffic prediction models and making the forecasting results unreliable. Due to the long periods of missing data, this paper uses transfer learning (TL) to impute missing data with the knowledge from a relevant task, which has ample samples. However, the imputation result contains complex source and target data characteristics. Therefore, this paper introduces the idea of frequency decomposition to decompose the imputation results into different sub-sequences through variational mode decomposition (VMD). Additionally, this paper uses long short-term memory (LSTM) networks to extract the potential features of decomposition results. Finally, this paper combines TL, VMD, and LSTM to design the TL-VMD-LSTM algorithm. The effectiveness of the proposed algorithm is validated using inflow and outflow traffic data from two State Grid Corp. of China networks. The results demonstrate that TL-VMD-LSTM has excellent generalization performance, with mean absolute percentage errors (MAPEs) of 0.380 % and 0.734 % for the Provincial access network and Information region network, respectively.},
  archive      = {J_ESWA},
  author       = {Yang Yang and Zhihao Chen and Yuchao Gao and Zijin Wang and Zhe Ding and Jinran Wu},
  doi          = {10.1016/j.eswa.2025.129484},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129484},
  shortjournal = {Expert Syst. Appl.},
  title        = {Network traffic forecasting with transfer learning-based algorithm for long continuous missing data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-dimensional multi-objective feature selection with niche-based binary differential evolution. <em>ESWA</em>, <em>298</em>, 129478. (<a href='https://doi.org/10.1016/j.eswa.2025.129478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a critical step in machine learning and data mining, aiming to identify the most relevant features from a dataset to improve model performance while reducing computational costs. In high-dimensional data, as the dimensionality of data increases rapidly, feature selection faces an enormous search space, limiting the efficiency and effectiveness of traditional methods. To address these challenges, multi-objective optimization algorithms have emerged as a promising strategy for feature selection due to their ability to optimize multiple conflicting objectives simultaneously. We propose a niche-based binary differential evolution algorithm (MONBDE) for high-dimensional multi-objective feature selection. MONBDE enhances feature selection performance through several mechanisms: a niche-based binary differential evolution operator, redundant solution repair mechanism and an environmental selection strategy. In experiments, the proposed algorithm was compared with five advanced multi-objective optimization algorithms and tested on 15 benchmark datasets using three common metrics. Experimental results show that the MONBDE algorithm outperforms comparative algorithms in terms of classification accuracy and feature subset size across most datasets. The proposed strategy effectively eliminates redundant and irrelevant solutions in feature selection, leading to a significant improvement in model classification performance.},
  archive      = {J_ESWA},
  author       = {Xuezhi Yue and Xiang Zuo and Pengfei Ling and Chao Xiong and Hu Peng and Yuan Zeng},
  doi          = {10.1016/j.eswa.2025.129478},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129478},
  shortjournal = {Expert Syst. Appl.},
  title        = {High-dimensional multi-objective feature selection with niche-based binary differential evolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DFCNet: Dual-path fusion with intra-slice features and cross-slice constraints for cervical cancer CTV segmentation. <em>ESWA</em>, <em>298</em>, 129477. (<a href='https://doi.org/10.1016/j.eswa.2025.129477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and rapid segmentation of the clinical target volume (CTV) is essential for cervical cancer radiotherapy. However, due to the soft boundaries of CTV, complex connections with surrounding tissues, and high interpatient variability, existing deep learning methods still face significant challenges, particularly for image slices that lack clear boundary information or where applicators are distant from CTV edges. Hence, we introduce DFCNet, a dual-path fusion network with cross-slice consistency constraints for CTV segmentation. The first path employs a dual-stream intra-slice feature encoding module to capture local and inter-regional details, thereby refining boundary delineation amidst the complex interplay with adjacent tissues. The second path integrates a cross-slice consistency constraint module to address soft boundaries and high interpatient variability, while ensuring the coherence and smoothness of the segmentation results. A feature fusion and decoding module combines semantic features from both paths, improving CTV region accuracy. Tests on 432 cervical cancer brachytherapy cases show DFCNet outperforms eighteen state-of-the-art segmentation methods, with Dice score improvements over two percentage points. The second path and feature fusion module can enhance other U-Net-based models, boosting their CTV segmentation performance. DFCNet excels in high-precision CTV segmentation, particularly for challenging slices, demonstrating its potential to improve cervical cancer radiotherapy accuracy, efficiency, and patient outcomes.},
  archive      = {J_ESWA},
  author       = {Mingxu Huang and Deyu Sun and Chaolu Feng and Ming Cui and Dazhe Zhao and Yuhua Gao},
  doi          = {10.1016/j.eswa.2025.129477},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129477},
  shortjournal = {Expert Syst. Appl.},
  title        = {DFCNet: Dual-path fusion with intra-slice features and cross-slice constraints for cervical cancer CTV segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Competitive e-commerce platforms’ data provision and pricing strategies with different attribution behaviors of users. <em>ESWA</em>, <em>298</em>, 129466. (<a href='https://doi.org/10.1016/j.eswa.2025.129466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of data, numerous e-commerce platforms are actively collecting consumer data to obtain business insights. However, consumers and merchants on platforms exhibit diverse attribution behaviors, including single-homing and multi-homing (access to only one platform/multiple platforms), not only affecting the platform’s market scale but also complicating their data provision strategies and data pricing strategies. Inspired by this practice, this paper considers varying attribution behaviors and studies the data operation strategies of competitive platforms. By constructing a two-period game model, we capture the entire process of platform’s data collection and provision, and solve the equilibrium decisions by reverse solution method. This research aims to identify the impact of attribution behaviors on platforms’ data strategies, thereby filling the gap in analyzing this issue from the perspective of two-sided platforms. Results show that when both groups of users (consumers and merchants) are multi-homing, platform facing higher operational costs may benefit more from implementing low data provision but high data pricing strategy, while more cost-efficient platform may choose the opposite strategy. This strategy is still applicable when only one group of users (consumers) becomes single-homing. However, once both groups of users are single-homing, both platforms’ strategies will change. Specifically, when merchant’s cross-side network effect (CNE) intensity is relatively low (high), compared with less cost-efficient platform, platform enjoying cost efficiencies should provide more (less) data at a relatively high (low) price. Moreover, platforms should cautiously provide data when both groups of users are single-homing, as it may hurt profits.},
  archive      = {J_ESWA},
  author       = {Wei Chen and Yijia Hu and Ronghua Sui and Zili Guan and Yi Liu},
  doi          = {10.1016/j.eswa.2025.129466},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129466},
  shortjournal = {Expert Syst. Appl.},
  title        = {Competitive e-commerce platforms’ data provision and pricing strategies with different attribution behaviors of users},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Emergency logistics planning through optimizing the multi-trip vehicle routing with time windows and limited trip duration. <em>ESWA</em>, <em>298</em>, 129465. (<a href='https://doi.org/10.1016/j.eswa.2025.129465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the multi-trip vehicle routing problem with time windows (MTVRPTW) and its variants have been extensively studied, their application in natural disaster contexts remains underexplored. This study addresses this gap by developing a model and solution algorithm for the MTVRPTW with limited trip duration (MTVRPTW-LD), tailored to emergency supplies distribution in the early post-disaster phase. First, we replace the service-dependent loading time in traditional models with service-dependent unloading time and formulate an MTVRPTW-LD model to minimize total operational time, encompassing travel, service, and unloading times, based on the characteristics of emergency supplies distribution. Furthermore, a more practical method for calculating travel time is proposed to enhance the model’s applicability. Subsequently, a branch-and-price algorithm is designed to solve the MTVRPTW-LD model, in which the cumulative relative deprivation cost (CRDC) is introduced to improve equity in emergency supplies distribution. Finally, we conduct numerical experiments on Solomon instances and test instances generated based on emergency scenarios. The results show that, in the test instances, incorporating CRDC can improve the equity by up to 34.3 %.},
  archive      = {J_ESWA},
  author       = {Longfei Fan and Zhongming Wu and Zaiwu Gong and David Z.W. Wang},
  doi          = {10.1016/j.eswa.2025.129465},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129465},
  shortjournal = {Expert Syst. Appl.},
  title        = {Emergency logistics planning through optimizing the multi-trip vehicle routing with time windows and limited trip duration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Regularity model-driven large-scale multi-objective evolutionary algorithm based on dual-information offspring reproduction strategy. <em>ESWA</em>, <em>298</em>, 129460. (<a href='https://doi.org/10.1016/j.eswa.2025.129460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Pareto set (PS) of a continuous multi-objective optimization problem exhibit a distribution along a low-dimensional manifold structure. This regularity property significantly contributes to generating high-quality offspring in large-scale multi-objective evolutionary algorithms (LSMOEAs). However, conventional regularity model-based algorithms face several challenges when dealing with large-scale multi-objective optimization problems (LSMOPs), including high computational costs for modeling, difficulty in capturing the true PS structure, and neglecting individual directional information. To address these challenges, we propose a dual-information offspring reproduction strategy that considers both the distribution information of the population and the directional information of the outstanding individuals. Specifically, this strategy comprises a sampling approach based on an augmented regularity model specifically designed for LSMOPs. Leveraging this model, we explore and exploit the decision space to sample a promising set of solutions. Additionally, the strategy also involves a search method based on competitive learning among individuals. By assigning a positive evolutionary direction to losing solutions, we update the losing solutions to generate high-quality offspring. We continuously refine the proposed regularity model to approximate the true PS more closely. In extensive experiments on large-scale multi-objective benchmark functions, we compare our algorithm with eight state-of-the-art algorithms. The results demonstrate that our approach excels in handling LSMOPs.},
  archive      = {J_ESWA},
  author       = {Ying Wu and Ziliang Du and Gonglin Yuan and Zhenzhou Tang and Ferrante Neri and Yaqing Hou},
  doi          = {10.1016/j.eswa.2025.129460},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129460},
  shortjournal = {Expert Syst. Appl.},
  title        = {Regularity model-driven large-scale multi-objective evolutionary algorithm based on dual-information offspring reproduction strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GlobalCLIP: Zero-shot manufacturing anomaly detection with adaptive self-cyclic emsemble learning. <em>ESWA</em>, <em>298</em>, 129448. (<a href='https://doi.org/10.1016/j.eswa.2025.129448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately identifying product defects and process anomalies in manufacturing processes is a critical task for product quality and system stability. Although the existing unsupervised anomaly detection methods do not require the annotation of anomalies, they are difficult to deal with the zero-shot scenario faced by multi-variety and small-batch production where there is no available data. In addition, many zero-shot detection algorithms need to represent the image features in tensor form with multiple local feature vectors, and then measure each local feature to infer the overall anomaly of the object. In this paper, we propose GlobalCLIP, a novel approach for zero-shot anomaly detection using only global feature vectors to enhance performance. Specifically, we use CLIP model to aggregate the global features, and design two kinds of adaptive modules from the error level and uncertainty level to realize the series integration of different discriminant models. The adaptive modules encourage the model to learn both normal and abnormal patterns with different granularity, and the self-cyclic training progressively improves model performance. Experiments show that compared to many unsupervised/weakly supervised methods, the performance of GlobalCLIP maintains its advantage even without known samples, and achieves significant improvement over available zero-shot methods.},
  archive      = {J_ESWA},
  author       = {Haoyuan Shen and Enrico Zio and Jiawei Xiong and Yizhong Ma},
  doi          = {10.1016/j.eswa.2025.129448},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129448},
  shortjournal = {Expert Syst. Appl.},
  title        = {GlobalCLIP: Zero-shot manufacturing anomaly detection with adaptive self-cyclic emsemble learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Key performance indicator-related process monitoring for irregular scenarios with incomplete data. <em>ESWA</em>, <em>298</em>, 129440. (<a href='https://doi.org/10.1016/j.eswa.2025.129440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern industries exhibit irregular characteristics due to factors such as mode transitions, incomplete data and outliers. Accurate monitoring of key performance indicators (KPIs) in irregular processes is essential for improving product quality and reducing scrap rates. This paper proposes a novel KPI-related process monitoring method that leverages the multiple kernel learning (MKL) technique, designed specifically for irregular scenarios with incomplete data. First, a novel MKL-based nonlinear matrix completion is proposed that utilizes a hierarchical strategy-based algorithm to estimate the missing values in incomplete data and the linear coefficients of multiple kernels. In addition, the corresponding convergence analysis is given. Based on the estimated completed data matrix, a novel MKL-based feature correlation analysis is proposed for indirect prediction of KPIs. Two statistics are established for detecting KPI-related and KPI-unrelated faults, respectively. A numerical case and an industrial example demonstrate that the proposed method not only accurately identifies the missing data, but also effectively detects the KPI-related faults.},
  archive      = {J_ESWA},
  author       = {Yanyu Chen and Hao Ma and Yan Wang and Xiang Liu},
  doi          = {10.1016/j.eswa.2025.129440},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129440},
  shortjournal = {Expert Syst. Appl.},
  title        = {Key performance indicator-related process monitoring for irregular scenarios with incomplete data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel approach to anomaly detection in critical CPSs: The ERXAI-MS algorithm. <em>ESWA</em>, <em>298</em>, 129437. (<a href='https://doi.org/10.1016/j.eswa.2025.129437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, practical machine learning methodologies are extensively employed for the automation of detecting the intrusion available in the network. In key infrastructure scenarios involving communication strategies, the interplay between different industrial control systems and the inherent connection to the Internet environment through the Internet of Things renders them vulnerable to cyber threats. Considering the substantial volume of network traffic within critical Cyber-Physical Systems, conventional machine-learning approaches utilized for detecting anomalies prove to be ineffective. Hence, newly designed machine learning methods, with a focus on deep learning, are demonstrating effective applications in identifying and categorizing anomalies on both network and individual device levels. This article introduces an innovative Ensemble Random Explainable Artificial Intelligence Meerkat Search algorithm designed for the identification of cyber threats. To augment the effectiveness of the suggested method, it employs a dual-step process for the detection of network irregularities. During the initial phase, the approach involves data pre-processing and dimensionality reduction through the application of Kernel Principal Component Analysis to select the most suitable features. In the subsequent stage, the novel Ensemble Random Explainable Artificial Intelligence Meerkat Search algorithm is employed for classification. The effectiveness of the approach presented in this study is evaluated on diverse datasets, encompassing information collected within the Internet of Things context, specifically IoT-23 and LITNET-2020 datasets. The findings of the assessment of the suggested method are deliberated upon, including the examination of statistical significance and a comparative analysis with contemporary approaches in the field of network anomaly detection. Evaluations confirmed this robust model attained 98.56% accuracy, 97.78% precision, 98.2% F1-score, and produced less FPR of 1.55%.},
  archive      = {J_ESWA},
  author       = {Prabakeran Saravanan and Annamalai Balaji and Hemalatha Murugan and Manickam Muruganantham and Indumathi Varadharajan},
  doi          = {10.1016/j.eswa.2025.129437},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129437},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel approach to anomaly detection in critical CPSs: The ERXAI-MS algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved DQN-based recommender system on three-way decision. <em>ESWA</em>, <em>298</em>, 129431. (<a href='https://doi.org/10.1016/j.eswa.2025.129431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems, which utilize algorithms and data analysis to provide personalized suggestions to users, have become an indispensable part of modern life. However, traditional recommendation algorithms face challenges such as the cold start problem, lack of diversity, and limited scalability. Reinforcement learning (RL), particularly deep reinforcement learning (DRL), emerges as a promising solution to these problems by allowing agents to learn optimal strategies through interaction with their environment. Nevertheless, as the scale of data increases, RL-based recommendation systems often struggle to achieve a good balance between exploration and exploitation, impacting the overall performance of the algorithms. In this paper, we propose a reinforcement learning-based recommendation algorithm enhanced by a three-way decision (3WD) framework to address the exploration-exploitation balance challenge. The 3WD algorithm, rooted in rough set theory, categorizes decision outcomes into acceptance, rejection, and uncertainty regions. By applying 3WD in the action selection process of RL, we optimize the trade-off between exploration and exploitation, thereby improving the quality and computational efficiency of recommendations. Additionally, we introduce a dynamic threshold adjustment mechanism to adaptively refine the decision boundary during the action selection process in reinforcement learning, further enhancing the algorithm’s performance. Using the MovieLens dataset as a foundation, we conduct extensive experiments with several randomly generated data sets to evaluate the proposed method. Our results demonstrate that the 3WD-based RL algorithm outperforms traditional methods, such as epsilon-greedy and Softmax, in terms of runtime, recommendation accuracy, and error rate. Notably, the dynamic threshold adjustment model exhibits greater stability and surpasses static methods in recommendation success rates. These findings highlight the effectiveness of combining 3WD with RL in recommendation systems, providing a powerful and efficient solution to the challenges faced by traditional methods. Finally, we analyze the limitations of the model based on the experimental results and propose avenues for future research.},
  archive      = {J_ESWA},
  author       = {Zian Chen and Bao Qing Hu},
  doi          = {10.1016/j.eswa.2025.129431},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129431},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improved DQN-based recommender system on three-way decision},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IntegralGP: Volumetric estimation of subterranean geochemical properties in mineral deposits by fusing assay data with different spatial supports. <em>ESWA</em>, <em>298</em>, 129429. (<a href='https://doi.org/10.1016/j.eswa.2025.129429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an Integral Gaussian Process (IntegralGP) framework for volumetric estimation of subterranean properties in mineral deposits. It provides a unified representation for data with different spatial supports, which enables blasthole geochemical assays to be properly modelled as interval observations rather than points. This approach is shown to improve regression performance and boundary delineation. A core contribution is a description of the mathematical changes to the covariance expressions which allow these benefits to be realised. The gradient and anti-derivatives are obtained to facilitate learning of the kernel hyperparameters. Numerical stability issues are also discussed. To illustrate its application, an IntegralGP data fusion algorithm is described. The objective is to assimilate line-based blasthole assays and update a block model that provides long-range prediction of Fe concentration beneath the drilled bench. Heteroscedastic GP is used to fuse chemically compatible but spatially incongruous data with different resolutions and sample spacings. Domain knowledge embodied in the structure and empirical distribution of the block model must be generally preserved while local inaccuracies are corrected. Using validation measurements within the predicted bench, our experiments demonstrate an improvement in bench-below grade prediction performance. For material classification, IntegralGP fusion reduces the absolute error and model bias in categorical prediction, especially instances where waste blocks are mistakenly classified as high-grade.},
  archive      = {J_ESWA},
  author       = {Anna Chlingaryan and Arman Melkumyan and Raymond Leung},
  doi          = {10.1016/j.eswa.2025.129429},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129429},
  shortjournal = {Expert Syst. Appl.},
  title        = {IntegralGP: Volumetric estimation of subterranean geochemical properties in mineral deposits by fusing assay data with different spatial supports},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep multi-view least squares support vector machine with consistency and complementarity principle based on cross-output knowledge transfer. <em>ESWA</em>, <em>298</em>, 129406. (<a href='https://doi.org/10.1016/j.eswa.2025.129406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a Deep Multi-view Least Squares Support Vector Machine with Consistency and Complementarity Principles based on Cross-Output Knowledge Transfer (MDCTM), which has four distinctive features: 1) It integrates the idea of deep stacking architecture, which is the first attempt to use transfer learning to form deep architectures in multi-view learning. It can enhance the ability to handle complex problems. Starting from the second layer, it incorporates extra input attributes that consider the predictions made by all preceding layers, effectively revealing the manifold structure of the original data. 2) Each layer follows the consistency and complementarity principles, which can fully excavate the information in multi-view data. In each layer, the model is solved by an alternating optimization strategy. 3) Cross-output knowledge transfer leverages predictions from earlier layers to improve the learning of subsequent ones, which can improve the classification performance of the model. Additionally, the extent of cross-output knowledge transfer between sequential layers can be assessed autonomously and effectively by utilizing a fast leave-one-out cross-validation method. 4) The model allows random assignment of model parameters in each layer, such as weights and kernel widths, boosting learning speed. Numerical experiments demonstrate the model’s effectiveness and efficiency.},
  archive      = {J_ESWA},
  author       = {Shuangrui Jia and Sijie Liang and Ziyi Mo and Chunxiao Liu and Huiru Wang and Chen Chen},
  doi          = {10.1016/j.eswa.2025.129406},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129406},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep multi-view least squares support vector machine with consistency and complementarity principle based on cross-output knowledge transfer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A study on the modeling of long-term trend and short-term fluctuation: Fourier-enhanced adaptive koopman operator for carbon emission forecasting. <em>ESWA</em>, <em>298</em>, 129388. (<a href='https://doi.org/10.1016/j.eswa.2025.129388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Koopman operator provides a new way to model complex data patterns, revealing the intrinsic dynamics of time series from a dynamical system perspective. Despite its potential, the Koopman operator has received limited attention in time series forecasting, particularly in addressing these complex, real-world challenges such as carbon emission dynamics characterized by nonlinearity, non-stationarity, and multi-scale coupling effects. To this end, this study proposes a novel forecasting paradigm, Fourier-Enhanced adaptive Koopman operator for carbon emission forecasting (F-KOCE). This approach conceptually extends traditional Koopman frameworks by embedding a spectral-decoupled time series representation into a dual Koopman learning structure, which enables the model to linearize nonlinear dynamics across multiple time scales in a theoretically grounded and practically adaptive manner. By integrating Fourier filter decomposition into Koopman operator theory, F-KOCE separates raw emissions into long-term trends and short-term fluctuations while achieving global linearization of system dynamics. A learnable Koopman operator captures intrinsic temporal structures, while a multi-granularity adaptive weight learning strategy enhances resilience against data variability. To further improve robustness, we introduce an adaptive residual fusion structure for block-level feature compression, noise suppression, and cross-scale information fusion. Additionally, the effective Trend Corrector mechanism dynamically modulates the influence of trend and fluctuation components, refining predictive accuracy. Beyond point forecasting, the framework is also extended to interval forecasting, providing uncertainty-aware predictions. Extensive experiments conducted on 36 Carbon Monitor datasets across six regions and six sectors demonstrate the superiority of F-KOCE over advanced existing models across multiple evaluation metrics. These results confirm the framework’s efficacy in capturing high-dimensional emission dynamics and underscore the potential of Koopman operator theory in carbon forecasting. By offering a robust, interpretable, and data-driven approach, F-KOCE provides valuable insights for climate policy formulation.},
  archive      = {J_ESWA},
  author       = {Jinxing Che and Wei Dong and Qian Sun and Yuhua Zhang},
  doi          = {10.1016/j.eswa.2025.129388},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129388},
  shortjournal = {Expert Syst. Appl.},
  title        = {A study on the modeling of long-term trend and short-term fluctuation: Fourier-enhanced adaptive koopman operator for carbon emission forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A cooperative co-evolutionary algorithm with core-based grouping strategy for large-scale 0–1 knapsack problems. <em>ESWA</em>, <em>298</em>, 129364. (<a href='https://doi.org/10.1016/j.eswa.2025.129364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 0–1 knapsack problem (KP) is a well-known combinatorial optimization problem with wide real-world applications. While evolutionary algorithms have demonstrated promise in solving 0–1 KPs, their performance deteriorates as the problem dimension increases. Cooperative co-evolution (CC) is an algorithmic framework based on a divide-and-conquer strategy, which has been used in solving large-scale optimization problems. Inspired by the similarity between item grouping in the 0–1 KP and decomposition strategies in CC, this paper proposes a novel grouping strategy that uses the position information of break items and profit-to-weight ratio to solve large-scale 0–1 KP. The strategy aims to divide the large-scale 0–1 KP into multiple subproblems, thus having a reduced search space for each subproblem. To enhance population diversity and search efficiency, the profit-to-weight ratio is used to generate an initial elite population. Additionally, to obtain the complete solution for the original large-scale KP, a subgroup merging method is designed to accelerate convergence and further improve population diversity. A three-phase repair operator is developed to fix infeasible solutions directly to create more feasible solutions. The resulting cooperative co-evolutionary algorithm is compared with ten state-of-the-art algorithms for solving 0–1 KPs with variables ranging from 100 to 5,000, including EAs, CC-based approaches, and a deep reinforcement learning method. Experimental results show that the proposed algorithm exhibits higher solution accuracy and faster convergence than other competing algorithms. The CC framework takes considerably less running time than high-performing algorithms, providing an overall novel approach for solving large-scale 0–1 KPs.},
  archive      = {J_ESWA},
  author       = {Xiaotong Li and Shuwei Zhu and Wei Fang and Kalyanmoy Deb},
  doi          = {10.1016/j.eswa.2025.129364},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129364},
  shortjournal = {Expert Syst. Appl.},
  title        = {A cooperative co-evolutionary algorithm with core-based grouping strategy for large-scale 0–1 knapsack problems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Life cycle cost reliability assessment for strategic real estate decision-making. <em>ESWA</em>, <em>298</em>, 129329. (<a href='https://doi.org/10.1016/j.eswa.2025.129329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real estate projects prioritize minimizing initial development costs while often overlooking the long-term financial implications of their decisions. This short-term focus frequently leads to increased operational, maintenance, and renewal expenses, ultimately reducing overall profitability. Life Cycle Costing (LCC) provides a comprehensive approach to evaluating total project costs over time; however, its adoption remains limited due to challenges such as data constraints, uncertainty about future cost savings, and the lack of standardized performance measurement tools. To tackle these issues, this paper proposes a structured LCC reliability assessment model designed for real estate decision-makers. The model systematically identifies and analyzes key cost factors across all project phases, including construction, operation, renewal, maintenance, and end-of-life, while integrating technical, economic, environmental, and social dimensions. A structured survey was employed to quantify and prioritize these cost factors, facilitating the development of category-specific LCC models and a standardized evaluation framework. Additionally, a benchmarking scale was created to measure the reliability of input factors. Although this study emphasizes the reliability dimension, it establishes a foundation for the future integration of an optimization module to enhance decision-making and maximize life cycle cost efficiency. The proposed model has been automated to improve usability and accessibility, allowing stakeholders to make informed investment decisions that promote long-term financial sustainability in real estate development.},
  archive      = {J_ESWA},
  author       = {Elin A. Eldars and Amin A. Sorour},
  doi          = {10.1016/j.eswa.2025.129329},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129329},
  shortjournal = {Expert Syst. Appl.},
  title        = {Life cycle cost reliability assessment for strategic real estate decision-making},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Balancing forecast accuracy and switching costs in online optimization of energy management systems. <em>ESWA</em>, <em>298</em>, 129305. (<a href='https://doi.org/10.1016/j.eswa.2025.129305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the integration of forecasting and optimization in energy management systems, focusing on how switching costs, penalties incurred from frequent operational adjustments, affect the balance between forecast accuracy and stability in online decision-making. We develop a theoretical framework analyzing Fixed Horizon Control (FHC) algorithms under switching costs, deriving performance bounds that reveal trade-offs between commitment periods and forecast properties. We introduce a novel Scenario Distribution Change (SDC) metric for measuring temporal consistency in probabilistic forecasts. The framework is validated through empirical evaluation using a real-world battery scheduling case study based on the CityLearn 2022 challenge, comparing deterministic and stochastic optimization approaches across different commitment periods. Theoretical analysis reveals that switching costs create a U-shaped relationship between commitment period and performance, with optimal commitment depending on forecast stability. Empirical results demonstrate that switching costs significantly alter the accuracy-stability trade-off: while traditional approaches favor frequent updates (1-hour commitment), incorporating switching costs makes longer commitment periods (3+ hours) optimal when combined with stable forecasts. Stochastic optimization with scenario averaging reduces forecast error sensitivity by up to 2.9 % in grid costs compared to deterministic approaches. This work contributes the first theoretical bounds linking forecast stability to switching costs in energy systems, the SDC metric for evaluating probabilistic forecast stability, empirical evidence that longer commitment periods can outperform frequent updates under switching costs, and practical guidelines showing that forecast stability should be factored into decision-making frameworks for energy management systems in the presence of switching costs.},
  archive      = {J_ESWA},
  author       = {Evgenii Genov and Julian Ruddick and Christoph Bergmeir and Majid Vafaeipour and Thierry Coosemans and Salvador García and Maarten Messagie},
  doi          = {10.1016/j.eswa.2025.129305},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129305},
  shortjournal = {Expert Syst. Appl.},
  title        = {Balancing forecast accuracy and switching costs in online optimization of energy management systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid bee colony algorithm for crack repair trajectory planning based on focal attention guided lightweight segmentation. <em>ESWA</em>, <em>298</em>, 129267. (<a href='https://doi.org/10.1016/j.eswa.2025.129267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic arm trajectory planning of crack repair is critical for automated road maintenance. However, existing crack repair face two main challenges: loss of trajectory edge information and redundant planned distances. This study introduces an automated pavement crack repair system that integrates a lightweight crack segmentation model (Lightweight Focal Modulation, LFM-Net) and a repair trajectory planning algorithm (Fixed Neighborhood Search-Artificial Bee Colony, FNS-ABC). Specifically, LFM-Net incorporates conformer-based focal modulation attention (CFMA), enhancing the detailed information during the decoding phase. Additionally, the FNS-ABC enhances the ABC algorithm by incorporating a fixed neighborhood search strategy, effectively reducing redundant planning paths. The system is executed using a self-developed robotic arm with an edge computing unit. Extensive testing in three typical road scenarios-independent cracks, intersection cracks, and complex cracks-demonstrated that the system achieved a mean Intersection over Union (mIoU) of 83.93 %. Finally, the system exhibited an idle trajectory of 79.51 mm when addressing complex cracks, highlighting its superior performance in repair trajectory planning.},
  archive      = {J_ESWA},
  author       = {Jianqi Zhang and Xu Yang and Wei Wang and Yuhang Zhao and Hainian Wang and Yixue Chen},
  doi          = {10.1016/j.eswa.2025.129267},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129267},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid bee colony algorithm for crack repair trajectory planning based on focal attention guided lightweight segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep-learning based big data analysis for developing a smart supply chain for increased efficiency. <em>ESWA</em>, <em>298</em>, 129246. (<a href='https://doi.org/10.1016/j.eswa.2025.129246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data analysis (BDA) in supply chain management (SCM) is receiving growing attention in the present business environment. This is due to the fact that BDA has a wide range of applications in SCM, including customer behaviour analysis, trend analysis, and demand prediction. The increase in information volume has caused the efficiency and effectiveness of traditional procedures to decline, considering this, researchers have developed techniques that have a high capacity to investigate and comprehend vast amounts of data due to the limitations of these tactics in dissecting and interpreting a lot of information. This study represents a hybrid paper that combines a systematic literature review, a methodological proposal using BP neural networks. The main objective of this paper is to recognize the uses of deep learning in SCM. By fostering a calculated system, this paper recognizes the commitments of deep learning strategies in choosing and sectioning providers, foreseeing store network gambles, and assessing requests and deals, creation, stock administration, transportation and circulation, manageable turn of events, and roundabout economy. The novelty in this paper is the Backpropagation (BP) neural networks with big data-driven demand forecasting in supply chains. This method can improve the accuracy of demand forecasting in supply chain management. The study includes a thorough survey of the applications of predictive BDA in SC request gauging. The review highlighted the BDA methodologies used for production network request estimation and comparatively classified them. We collected and analysed these studies as tactics and methodologies for the popular forecast. Seven standard tactics were selected and studied, along with their benefits and drawbacks. Finally, the box-cox transformation representation over years in which for the year 2011–01, it starts with a box-cox value of 9.7 and it inclined till 2011–06 and then declined very exponentially in 2012–07 at 9 and then it keeps on incrementing and reached at 11 at the year 2013–07. Then from 2014 to 2015, the pattern didn’t lower below the box-cox value 10.},
  archive      = {J_ESWA},
  author       = {Sreekumar Narayanan and Sudhir Ramadass and K. Thilagavathi and Rajiv Kumar},
  doi          = {10.1016/j.eswa.2025.129246},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129246},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep-learning based big data analysis for developing a smart supply chain for increased efficiency},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
