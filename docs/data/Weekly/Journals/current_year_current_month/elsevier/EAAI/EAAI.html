<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EAAI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eaai">EAAI - 271</h2>
<ul>
<li><details>
<summary>
(2025). A novel weight-optimized machine-learning hybrid model for daily river runoff prediction. <em>EAAI</em>, <em>162</em>, 112396. (<a href='https://doi.org/10.1016/j.engappai.2025.112396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The daily runoff process has been characterized as nonlinear and unsteady due to the impacts of watershed precipitation and evaporation, vegetation coverage rate, reservoir operations and other human activities. In recent years, machine-learning (ML) models have been widely applied in the daily runoff predictions, but the robustness and effectiveness of individual ML model is always limited. A novel weight optimization scheme has been introduced to ML models to obtain accurate predictions of daily river runoff. Variational modal decomposition method is adopted in the dataset preprocessing, and the runoff prediction performance of various classic ML models, including Genetic Algorithm-Back Propagation neural network (GA-BP), Long Short-Term Memory network (LSTM), Elman neural network (Elman) and Genetic Algorithm-Support Vector Machine (GA-SVM) are subsequently evaluated. A particle swarm optimization (PSO) based weight optimization strategy is proposed to combine different types of ML models, thus more accurate and robust results could be obtained. The ten-fold cross-validation method has been adopted and the performance of the optimized hybrid models are further evaluated for different schemes. A case study at Hankou hydrological station demonstrates that root mean square error (RMSE) and mean absolute percentage error (MAPE) is improved by 35.7 %, 75.8 % respectively for the optimized hybrid model. The present study shares useful insights to the comprehensive optimization of various ML models in the intelligent management of water resources.},
  archive      = {J_EAAI},
  author       = {Zhonglian Jiang and Jianglong Ying and Zhen Yu and Xiao Chu and Chengqiang Yu},
  doi          = {10.1016/j.engappai.2025.112396},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112396},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel weight-optimized machine-learning hybrid model for daily river runoff prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent assessment of habitat quality based on multiple machine learning fusion methods. <em>EAAI</em>, <em>162</em>, 112395. (<a href='https://doi.org/10.1016/j.engappai.2025.112395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating habitat quality can help balance the relationship between economic development and biodiversity conservation, and it serves as a foundation for constructing an ecological security pattern. However, research on the intelligent construction of habitat quality is limited. This study develops a comprehensive framework to assess habitat quality based on optimized machine learning methods. The findings of the research are as follows: (1) From the perspective of human-machine interactive interpretation, ensemble learning is used to enhance the performance of basic classifiers, resulting in a classification map with high precision and recall. (2) The particle swarm optimization (PSO) algorithm can improve the goodness of fit of the Extreme Gradient Boosting (XGBoost) inversion model by 4–5 %. (3) The habitat quality inversion method based on XGBoost-PSO has high credibility and application value, with its texture structure being the result of both expert experience and image information interaction. (4) The model demonstrates certain application potential in downscaling; under the seven-band perspective, the blue and near-infrared bands are the most important, while in the four-band perspective, green and near-infrared bands take precedence.},
  archive      = {J_EAAI},
  author       = {Kui Yang and Dongge Cui and Chengrui Wang and Qi Tang and Linguang Miao},
  doi          = {10.1016/j.engappai.2025.112395},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112395},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent assessment of habitat quality based on multiple machine learning fusion methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Health state estimation of retired batteries based on physical constraints. <em>EAAI</em>, <em>162</em>, 112390. (<a href='https://doi.org/10.1016/j.engappai.2025.112390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing use of retired lithium-ion batteries, accurately monitoring their health status has become increasingly important. This study proposed a method to estimate the health of retired batteries by embedding their capacity degradation characteristics directly into the loss function of a Bidirectional Long Short-Term Memory (BiLSTM) network, combined with a Physically Informed Neural Network (PINN) model. The model is developed by incorporating the dynamics of the solid electrolyte interface (SEI) membrane, which evolves as the lithium-ion poles of the retired battery move. By combining these dynamics with the governing equations of motion, a partial differential equation (PDE) is derived. This approach integrates physical constraints, data-driven learning, and PDEs into a composite loss function. The proposed method is validated on two different datasets under varying operating temperatures. The results show that the PINN-BiLSTM model achieves a Root Mean Square Percentage Error (RMSPE) of 0.024, representing a 9.67 % improvement over the PINN-LSTM. This adaptive PINN method offers highly accurate health state predictions across temperature variations, thus supporting the sustainable use of retired batteries in secondary applications and helping to mitigate energy scarcity.},
  archive      = {J_EAAI},
  author       = {Fei Xia and Qianwen Dong and Lin Xia and Zhenyi An and Ziyang Xia and Chunyang Gong},
  doi          = {10.1016/j.engappai.2025.112390},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112390},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Health state estimation of retired batteries based on physical constraints},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimisation approach guided by crack variation mechanism in the informer prediction model. <em>EAAI</em>, <em>162</em>, 112381. (<a href='https://doi.org/10.1016/j.engappai.2025.112381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring (SHM) faces a fundamental challenge in reconciling predictive performance with physical interpretability for infrastructure diagnostics. Conventional deep learning (DL) approaches neglect essential mechanisms governing crack width variation—including thermal gradients, hysteretic responses, and phase-shifted correlations—limiting their reliability in real-world applications. To bridge this gap, we propose a mechanism-guided optimization (MGO) framework that integrates domain knowledge into the Informer architecture through physics-informed enhancements: auto-correlation modeling for capturing temperature-crack hysteresis, static gated fusion for multi-feature integration, and adaptive elastic net regularization for feature selection. Validated on cable-stayed bridge monitoring data, our framework achieves significant mean absolute error reductions (MAE) (5 %–60 %) and root mean square error reductions (RMSE) (10 %–55 %) versus baseline Informer across all cracks and prediction horizons, with diebold-mariano (DM) tests confirming statistical superiority in most cases. Crucially, it demonstrates superior precision relative to six state-of-the-art benchmarks across all evaluation scenarios. The ordinary least squares (OLS)-enhanced variant further delivers volatility reduction, while sensor failure tests establish quantifiable robustness benchmarks through MAE progression from 0.013 mm to 0.391 mm. This work establishes an interpretable, physics-grounded paradigm that explicitly links environmental drivers to structural degradation.},
  archive      = {J_EAAI},
  author       = {Xujia Liu and Youliang Ding and Fei Xu and Yichao Xu and Kang Yang},
  doi          = {10.1016/j.engappai.2025.112381},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112381},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimisation approach guided by crack variation mechanism in the informer prediction model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm. <em>EAAI</em>, <em>162</em>, 112376. (<a href='https://doi.org/10.1016/j.engappai.2025.112376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, global climate warming has led to a significant increase in both the frequency and intensity of tropical cyclones (TCs). The development of TCs is often accompanied by frequent lightning activities. The risk of lightning strikes to high offshore wind turbines is substantially elevated. This study evaluates the lightning risk faced by offshore wind farms influenced by tropical cyclones. Firstly, TC paths are analyzed in both spatial and temporal dimensions by linking them with lightning data to examine the distribution of TC-related lightning, and the lightning strike characteristics of offshore wind turbines are investigated. Secondly, a Bayesian Optimization (BO)-based eXtreme Gradient Boosting (XGBoost) model for lightning risk assessment is proposed, incorporating characteristics of TC lightning and offshore wind farms as input variables. The proposed BO-XGBoost model outperforms XGBoost, Bidirectional Long Short-Term Memory (Bi-LSTM), Support Vector Machine (SVM) and Neural Network (NN), achieving a precision of 98.9 % and a recall of 98.9 % on the test set. Additionally, SHapley Additive exPlanations (SHAP) value analysis indicates that TC lightning characteristics and offshore wind farm characteristics significantly impact the model output, enhancing the accuracy of the model. The assessment outcomes provide a theoretical basis for future offshore wind farm planning and guidance for lightning protection measures in offshore wind farms.},
  archive      = {J_EAAI},
  author       = {Qibin Zhou and Kehan Chen and Xiaoyan Bian and Shangjie Chen and Gaopeng Lu},
  doi          = {10.1016/j.engappai.2025.112376},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112376},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm. <em>EAAI</em>, <em>162</em>, 112368. (<a href='https://doi.org/10.1016/j.engappai.2025.112368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the convergence of mobile communication, sensing, and computational networks in sixth-generation technology, the integration of sensing and communication with unmanned aerial vehicles (UAVs) is promising. This paper focuses on the contribution of artificial intelligence in optimizing the deployment of UAV swarms for multi-objective target detection applications in sixth-generation networks. Specifically, the artificial intelligence contribution lies in the development of an improved multi-objective particle swarm optimization (IMOPSO) algorithm for solving a complex multi-objective deployment problem. The problem aims to simultaneously optimize communication rate, sensing quality, and energy consumption in the deployment of UAV swarms. To address this, the proposed IMOPSO incorporates chaotic initialization, Lévy flight mutation, dynamic mutation rate, and an elimination mechanism based on opposition-based learning. These innovations are designed to enhance the algorithm’s ability to explore the solution space effectively, overcome premature convergence to local solutions, and improve solution quality. In terms of engineering applications, the IMOPSO is applied to the deployment of UAV swarms for target detection, demonstrating its ability to enhance communication and sensing performance while reducing energy consumption in practical scenarios. Through extensive simulations, we show that the IMOPSO outperforms traditional optimization methods and other baseline algorithms, achieving superior results across all optimization objectives. Specifically, the IMOPSO achieves approximately 5% higher transmission data rate, 9% better sensing quality, and 19% lower energy consumption compared to baseline algorithms across multiple test scenarios. Furthermore, the solutions obtained are not only closer to the optimal front but also more concentrated, indicating higher-quality results.},
  archive      = {J_EAAI},
  author       = {Hongjuan Li and Haiyuan Chen and Miao Wang and Jiahui Li and Hui Kang and Yuzhuo Guan and Xu Lin},
  doi          = {10.1016/j.engappai.2025.112368},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112368},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complete information extraction for monocular depth estimation using a dual framework. <em>EAAI</em>, <em>162</em>, 112337. (<a href='https://doi.org/10.1016/j.engappai.2025.112337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to address the problem of efficient extraction of complete multi-scale information for supervised monocular depth estimation. Most of the existing depth estimation methods are based on Convolutional Neural Network (CNN). By gradually exploring the contextual and semantic features, they have achieved good results in scene depth estimation. However, with the expansion of the receptive field, global information limited by the local induction bias is gradually suppressed, resulting in the performance cannot be further improved. Recently, Transformer-based methods have been widely used to model the global correlation between features. Nevertheless, since the Transformer networks are not spatially aware enough, they usually lose local details and have no clear mechanism for reusing features when processing images. The Transformer networks perform self-attention mechanism at each location and cannot directly obtain information from other locations for features. Therefore, we propose a novel dual framework called as Transformer-CNN, which includes the Transformer-branch and the CNN-branch for monocular depth estimation. Specifically, the Transformer-branch is able to model the global contextual information and the CNN-branch can capture local spatial relationships in images. However, simply fusing these two independent branches may result in insufficient feature aggregation. To this end, we design a Parallel Feature Interaction Module (PFIM), which contains a Self-Attention Module (SAM) and a Cross-Attention Module (CAM), so as to highlight features from the Transformer-branch and the CNN-branch respectively and extract complementary information between the two branches. Meanwhile, in order to make full use of the low-level features with low quality in the scene, we propose a Low-level Information Acquisition Module (LIAM) to capture texture-related information and preserve texture details in the CNN-branch. Finally, to address the lack of multi-scale contextual information in Vision Transformer (ViT), we introduce a Wide Area Multi-scale Decoder (WAMD), which incorporates the multi-scale feature representations into the decoder part via a Wide Area Attention (WAA). Extensive experiments on benchmark datasets collected in the outdoor and indoor environments demonstrate the competitive results of the proposed method, compared with the state-of-the-art monocular depth estimation methods.},
  archive      = {J_EAAI},
  author       = {Bin Li and Dazheng Zhou and Xianjie Gao and Mingliang Zhang},
  doi          = {10.1016/j.engappai.2025.112337},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112337},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complete information extraction for monocular depth estimation using a dual framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models. <em>EAAI</em>, <em>162</em>, 112335. (<a href='https://doi.org/10.1016/j.engappai.2025.112335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Artificial Intelligence (AI)-based weather forecasting is growing rapidly, with continuous progress in model development, techniques, and performance improvements. This paper provides a comprehensive overview of AI-based weather forecasting models, focusing on their current status, challenges, and directions for further development. A review of more than 40 models, primarily proposed after 2015, underscores the importance of critically examining various aspects of AI-based forecasting. Unlike previous reviews that targeted only a limited number of models or features, this study addresses a complete set of aspects and analyzes existing challenges from multiple perspectives. These aspects include the Machine Learning (ML) and Deep Learning (DL) methods used, datasets, predictand parameters, overfitting, and capability for forecasting extreme weather, lead time, spatiotemporal scale, performance criteria, overfitting, data assimilation, data-driven models, and the analysis of state-of-the-art (SOTA) models such as FengWu, ClimaX, Pangu-Weather, FourCastNet, GraphCast, GenCast, and Artificial Intelligence Forecasting System (AIFS) from various viewpoints. The review also discusses current challenges, including limited historical data and data quality, small-scale weather forecasting, model explainability, uncertainty, extreme weather prediction, physical constraints, temporal adaptation, and generalization, and outlines potential future directions.},
  archive      = {J_EAAI},
  author       = {Saeid Haji-Aghajany and Witold Rohm and Piotr Lipinski and Maciej Kryza},
  doi          = {10.1016/j.engappai.2025.112335},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112335},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning. <em>EAAI</em>, <em>162</em>, 112330. (<a href='https://doi.org/10.1016/j.engappai.2025.112330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The textual adversarial attack aims to fool existing models into making erroneous predictions by adding strategic perturbations to normal data without affecting the user’s understanding. Recently, methods based on Pre-trained Language Models (PLMs) and Large Language Models (LLMs) have shown promising performance in various Natural Language Processing (NLP) downstream tasks. However, due to significant deviations between the original and perturbed texts, these methods struggle to achieve satisfactory results in defending against textual adversarial attacks, especially in Chinese, which has unique syntactic structures. To address this issue, we propose a domain adaptation method for defending against Chinese textual adversarial attacks through a prompt-tuning model, which effectively mitigates the discrepancy between different domains. Specifically, the original and perturbed texts are treated as the source and target domains, respectively, with the textual adversarial defense task framed as a cross-domain classification problem. The soft prompt-tuning model trained in the source domain is iteratively adapted to uncover the true label information in the target domain. The graph attention network is incorporated to integrate Chinese syntactic structure information with semantic features. Through a voting mechanism on predicted labels generated by the iterative model, soft prompt-tuning is further optimized for cross-domain classification tasks. Extensive experimental results demonstrate the superior effectiveness of our method in Chinese textual adversarial defense tasks compared to baseline methods, including the state-of-the-art fine-tuning approaches for PLMs and LLMs.},
  archive      = {J_EAAI},
  author       = {Yi Zhu and Zhenglong Li and Yun Li and Yunhao Yuan and Jipeng Qiang},
  doi          = {10.1016/j.engappai.2025.112330},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112330},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection. <em>EAAI</em>, <em>162</em>, 112321. (<a href='https://doi.org/10.1016/j.engappai.2025.112321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slow Feature Analysis (SFA) has shown considerable success in the field of industrial process fault detection. Nonetheless, due to its unsupervised nature, SFA relies solely on the normal training data and overlooks the incorporation of prior process knowledge, which consequently diminishes its efficacy in early fault detection. To mitigate this limitation, this paper introduces the concept of Zero-Shot Learning (ZSL) and proposes an improved SFA approach, referred to as ZSL-SFA. This novel method leverages fault semantic representations as auxiliary knowledge to enhance fault detection sensitivity in industrial process monitoring. The ZSL-SFA framework implements a dual-model collaborative monitoring system: (1) a primary SFA model is developed using normal operational data to capture the dynamic characteristics of the process; and (2) a semantic encoding mechanism, grounded in expert knowledge, is devised to build the auxiliary model, where a probabilistic attribute learner adaptively extracts semantic information from fault attribute descriptions, facilitating effective fault knowledge transfer through similarity analysis. The monitoring outcomes from both the primary and auxiliary models are integrated using a Bayesian fusion strategy, culminating in a comprehensive ZSL-SFA monitoring system. The main advantage of this method is its ability to fully exploit prior process knowledge to enhance the basic SFA model without the need for additional labeled fault samples. Experimental validations on the Tennessee-Eastman process simulation platform are performed to indicate that the proposed ZSL-SFA method surpasses the basic SFA method in terms of fault detection performance.},
  archive      = {J_EAAI},
  author       = {Wenjie Yang and Xiaogang Deng and Lumeng Huang and Yuping Cao},
  doi          = {10.1016/j.engappai.2025.112321},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112321},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction. <em>EAAI</em>, <em>162</em>, 112318. (<a href='https://doi.org/10.1016/j.engappai.2025.112318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {T-cell receptor sequences (TCR-seq) are closely related to cancers, and in particular, cancer-related TCR-seq are crucial in cancer diagnosis and treatment. Current prediction methods for cancer-related TCR-seq often focus solely on the sequence structure, neglecting its spatial structure. Therefore, we propose a multimodal deep learning method based on parallel and residual structures (MDPR) for the detection of cancer-related TCR-seq. MDPR can effectively integrate the spatial and sequence structure of TCR-seq for accurately identifying cancer-related sequences. First, we introduce a TCR-seq encoding method based on atomic three-dimensional spatial coordinates, allowing for more effective extraction of the spatial structural features of TCR-seq. Second, we use high-dimensional word vectors instead of the amino acid feature vectors traditionally used by other researchers. Third, we pretrain the spatial feature extraction module and then conduct joint training with the sequence feature extraction module. This approach allows the model to better consider the relationship between the two modalities, thereby improving prediction accuracy. Finally, MDPR achieved an area under the curve (AUC) of 0.971 after ten rounds of three-fold cross-validation on the dataset. The AUC of MDPR is 5% higher than that of the previous best method. In short, we propose an artificial intelligence method called MDPR, and apply it to the biomedical field. MDPR can be obtained from https://github.com/biomg/MDPR .},
  archive      = {J_EAAI},
  author       = {Junjiang Liu and Shusen Zhou and Mujun Zang and Chanjuan Liu and Tong Liu and Qingjun Wang},
  doi          = {10.1016/j.engappai.2025.112318},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112318},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering. <em>EAAI</em>, <em>162</em>, 112317. (<a href='https://doi.org/10.1016/j.engappai.2025.112317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is a significant application for wearable devices, which primarily identifies current human activities by analyzing sequential sensor data. The real-time data recording of wearable devices enables the collection of vast amount of unlabeled data. Utilizing this data for self-supervised contrastive pre-training of HAR models presents a feasible solution to the decline in recognition performance due to limited labeled data. However, traditional contrastive learning frameworks are primarily designed based on positive and negative sample pairs in the image domain. The relatively simple sequence data of HAR is prone to generating incorrect negative pairs, thus pre-training HAR models solely in this manner is unsatisfactory. Given the phenomena described above, this paper proposes an Instance Prediction and Clustering Self-supervised Contrastive Learning Framework (IPCSC) for HAR, considering the characteristics of human activity data. IPCSC circumvents negative sample pairs, instead extracting contrastive information at the instance perspective by prediction tasks among various augmented views of samples and integrating clustering concepts for contrastive learning from a holistic perspective. The primary objective is to enable the model to discern critical information within human activity data and distinguishable features between different activities, thereby improving the model’s pre-training efficacy and enhancing its downstream activity recognition performance. Numerous experimental analyses demonstrate that IPCSC outperforms other self-supervised methods, achieving an average F1-Score performance improvement of 5.65%, 4.11%, and 7.99% over supervised baselines on the UCI-HAR, MobiAct, and MotionSense datasets, respectively, with only 1% of the labeled data.},
  archive      = {J_EAAI},
  author       = {Zhixuan Yang and Kewen Li and Zongchao Huang and Zhifeng Xu and Xinyuan Zhu and Yuan Xiao},
  doi          = {10.1016/j.engappai.2025.112317},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112317},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised method for learning path-augmented knowledge graph embedding. <em>EAAI</em>, <em>162</em>, 112315. (<a href='https://doi.org/10.1016/j.engappai.2025.112315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) consist of factual triples that describe relations between entities in the real world. Knowledge graph embedding (KGE) aims to map entities and relations into constantly low-dimensional vectors, which is important for lots of downstream tasks (e.g., KG completion and information retrieval). Current KGE methods primarily rely on explicit structural patterns, neglecting latent contextual semantics behind those structures and resulting in sub-optimal performance. While some methods incorporate additional data (e.g., textual descriptions), such dependencies limit applicability due to additional data requirements. Furthermore, most KGE models suffer from limited supervision with sparse labeled triples, restricting their capacity to learn comprehensive semantic features. Inspired by the simple but effective self-supervised language model word2vec, one interesting question is: Can KGE be performed as a simple self-supervised language model ? To achieve this, we innovatively propose a self-supervised KGE framework that learns entity and relation embeddings by adapting word2vec’s skip-gram objective to path sequences extracted from KGs. Our framework employs separate embedding spaces for entities and relations with an entity-relation mapping mechanism for effective interaction between the two embedding spaces. Further, to enhance the training efficiency, we introduce a markov chain-based negative sampling strategy, which generates semantically meaningful negative samples by preserving the structural contexts along KG paths. Our framework, which is the first attempt to follow the context-based self-supervised idea of language models to conduct KGE tasks, addresses the constraints of label-dependent supervised KGE techniques and obviates the requirement for external information, while simultaneously enabling effective extraction of the implicit contextual semantics inherent in triple structures. Experiments on two widely-used KGE datasets show state-of-the-art performance, demonstrating our framework’s ability to learn semantically rich representations solely from graph structure.},
  archive      = {J_EAAI},
  author       = {Tong Shen and Fu Zhang and Jingwei Cheng},
  doi          = {10.1016/j.engappai.2025.112315},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112315},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A self-supervised method for learning path-augmented knowledge graph embedding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion. <em>EAAI</em>, <em>162</em>, 112313. (<a href='https://doi.org/10.1016/j.engappai.2025.112313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence-based single-cell RNA sequencing (scRNA-seq) technology is widely used in cell type identification and disease research, but its data often contain a large number of missing values and zero values due to technical limitations and biological differences. These zero values not only affect downstream analysis, but also make it difficult to distinguish technical zero values from biological zero values. Therefore, this paper proposes a scRNA-seq data interpolation method (sc-MKNMF) based on non-negative matrix factorization and multi-kernel similarity network fusion for the first time. This method improves the accuracy of cell clustering by accurately filling some zero values. First, sc-MKNMF uses gene-cell dual-level analysis to distinguish technical zero values from biological zero values, and then calculates the similarity network of multi-kernel fusion of genes and cells respectively. Then, this method uses non-negative matrix factorization combined with similarity network to construct the objective function, and introduces sparse regularization terms to ensure the similarity between genes and cells and improve stability. In addition, sc-MKNMF is also equipped with an efficient optimization algorithm to promote its convergence by continuously updating the objective function. Finally, the verification and comparative experiments on 12 scRNA-seq datasets show that the sc-MKNMF method outperforms other advanced data interpolation methods. In addition, the extension of sc-MKNMF to the two tasks of cell trajectory inference and differentially expressed gene analysis showed significant improvement and excellent versatility.},
  archive      = {J_EAAI},
  author       = {Pei Liu and Cheng Chen and Hao Liu and Jin Gu and Xinya Chen and Ying Su and Zhiyuan Cheng and Xiaoyi Lv and Chen Chen},
  doi          = {10.1016/j.engappai.2025.112313},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112313},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention. <em>EAAI</em>, <em>162</em>, 112311. (<a href='https://doi.org/10.1016/j.engappai.2025.112311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cercospora leaf spot (CLS) is a widespread disease that seriously threatens beet yield and sugar quality. Timely detection enables farmers to take early control measures and reduce economic losses. Although artificial intelligence (AI)-based methods are replacing manual inspection in agriculture, CLS detection in complex field environments remains highly challenging due to subtle early-stage symptoms and severe occlusions caused by overlapping leaves and weeds. To address these challenges, this paper presents Cercospora Leaf Spot–You Only Look Once (CLS–YOLO), an enhanced detection model built upon You Only Look Once version 11 (YOLOv11), incorporating novel modules specifically designed for accurate CLS detection under challenging field conditions. To improve the detection of weak and early-stage symptoms, we design the Multi-Scale Large Kernel Decomposition (MSLKD) module, which enhances feature extraction for subtle lesions. Furthermore, we develop the Spatial-Channel Interaction Attention (SCIA) module to mitigate detection errors arising from occlusion and fragmented disease patterns by refining multi-scale feature representations. Experimental results demonstrate CLS–YOLO achieves superior performance, reaching an mAP@0.5 of 73.6% ± 0.2% and an mAP@0.5:0.95 of 40.6% ± 0.3% over five independent runs, outperforming twelve mainstream object detection algorithms while maintaining lightweight efficiency. To validate generalization capability across scenarios, crops, and diseases, we conducted comparative experiments on two public crop disease datasets, where our method achieved superior overall performance. In summary, this study provides an effective AI-driven solution for precise crop disease detection, contributing to the practical advancement of intelligent agriculture.},
  archive      = {J_EAAI},
  author       = {Hualong Dong and Yi Lu and Yurong Qian and Xuefei Ning and Ting Chen and Ke Tang},
  doi          = {10.1016/j.engappai.2025.112311},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112311},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ElecBench: A large language model benchmark in electric power domain. <em>EAAI</em>, <em>162</em>, 112310. (<a href='https://doi.org/10.1016/j.engappai.2025.112310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have made substantial advancements in the field of natural language processing, necessitating the development of new benchmarks to accurately track their progress. In this paper, we introduce ElecBench, the first benchmark specifically designed for the electric power domain. ElecBench comprises 24 datasets spanning different scenarios, covering general electric power knowledge and four specific business applications, with a total of 34,030 data entries. Furthermore, we evaluate the performance of a series of open-source Chinese LLMs on ElecBench. Our experiments demonstrate that ElecBench serves as an effective benchmark for electric power scenarios and highlight that existing LLMs require further optimization to gain domain-specific knowledge and achieve better performance.},
  archive      = {J_EAAI},
  author       = {Sai Zhang and Qiaochu Huang and Qiang Zhang and Xiao Liang and Weiwei Liu and Kunlun Gao and Fei Zhou and Congcong Shi},
  doi          = {10.1016/j.engappai.2025.112310},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112310},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ElecBench: A large language model benchmark in electric power domain},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-enhanced edge-INverse attention network for skin lesion segmentation. <em>EAAI</em>, <em>162</em>, 112306. (<a href='https://doi.org/10.1016/j.engappai.2025.112306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer, particularly melanoma, is one of the most aggressive and deadly forms of cancer with its incidence rising globally. Early detection is crucial for improving survival rates, but the traditional dermatoscopy method is a highly time-consuming and subjective process. To resolve this issue, we propose a novel Feature-Enhanced Edge-INverse attention network (FEEINnet) model that helps to segment the skin lesion region more accurately. FEEINnet consists of three sub-networks: Feature Enhanced Mechanism (FEM) learns and extracts the fine-grained enhanced features from informative channels, the Edge Attention Mechanism (EAM) helps to precisely identify the edges of the lesion region and the INverse Attention Mechanism (INAM) generates inverse attention maps which emphasize the less confident or ambiguous regions thereby increasing the segmentation accuracy iteratively. These three sub-networks collectively help to improve feature extraction, enhance boundary detection, and refine segmentation maps, even in challenging scenarios with varying lesion sizes, shapes and pigmentation. FEEINnet consistently outperforms existing models, achieving a F1-score of 95.55%, 95.53%, and 94.52%; Intersection over Union (IoU) of 92.76%, 92.43%, and 91.34%; and Structural Similarity Index Measure (SSIM) of 94.63%, 93.51%, and 91.85% on the Human Against Machine 10000 (HAM10000), Pedro Hispano Hospital ( P H 2 ), and International Skin Imaging Collaboration 2018 (ISIC2018) datasets, respectively. The obtained results demonstrate that the proposed model has a greater ability to segment complex skin lesions more accurately.},
  archive      = {J_EAAI},
  author       = {Shivamm Warambhey and Aravindkumar Sekar},
  doi          = {10.1016/j.engappai.2025.112306},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112306},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-enhanced edge-INverse attention network for skin lesion segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method. <em>EAAI</em>, <em>162</em>, 112305. (<a href='https://doi.org/10.1016/j.engappai.2025.112305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault-free functioning of Heating, Ventilation, and Air Conditioning (HVAC) systems is essential for reducing energy waste in modern-day buildings. Hence, data-driven approaches for HVAC fault detection have gained popularity. Faults become more severe with time. Fault detection reveals the presence of an anomaly, but it does not convey how critical the fault severity is. Fault severity indication provides this essential context, enabling urgent resource allocation to more severe faults, adding practical significance. However, faults being rare, obtaining substantial data at different severity levels to train supervised Machine Learning models is a realistic challenge. Therefore, we propose a method for estimating fault severity in an unsupervised setting. We define a robust Severity Indicator (SI) that reflects the shift in the severity levels of a fault. First, we define a healthy domain boundary for fault-free data using One-Class Support Vector Machines. SI scores are then computed using a novel adaptive feature weighing algorithm that assigns weights to individual features, adaptively, for every fault. We focus on detecting the shift in severity, rather than quantifying it. The study of the robustness of SI for different faults in HVAC subsystems, chillers, and air handling units (AHUs) yields consistently promising results. Our comparative analysis shows that our method outperforms the unweighted approach and existing state-of-the-art techniques for fault severity estimation. Notably, our method excels in detecting low-severity faults, addressing a common limitation in current methods.},
  archive      = {J_EAAI},
  author       = {Ramnath V. Prabhu Bam and Rajesh S. Prabhu Gaonkar and Clint Pazhayidam George},
  doi          = {10.1016/j.engappai.2025.112305},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112305},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning. <em>EAAI</em>, <em>162</em>, 112301. (<a href='https://doi.org/10.1016/j.engappai.2025.112301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failures in propulsion components, such as propellers, can critically affect flight safety; thus, early failure detection, preferably before flight, is essential. Traditional fault-diagnosis methods typically rely on additional sensors or operational data, which may not be available or practical in all situations. This study addresses these challenges by introducing motor-electric-signal-based fault diagnosis that is independent of airframe configuration and can detect faults, even when the aircraft is not in operation. However, difficulties arise owing to poor class variance in motor-electric-signal data and the challenge of obtaining fault data. To overcome these issues, a semi-supervised learning model based on a modified variational autoencoder-generative adversarial network (VAE-GAN) is proposed, which predicts faults using only normal motor-electric-signal data. Additionally, a new preprocessing method and patch-based ensemble inference technique are introduced to improve the poor class-variance characteristics of the data, thereby enhancing the prediction performance. This work demonstrates that propeller faults can be successfully diagnosed using motor-electric signals without the need for additional sensors or fault-data acquisition.},
  archive      = {J_EAAI},
  author       = {Sanga Lee and Dohyeong Kim and Minkyun Noh and Shinkyu Jeong and Jikang Kong and Youngjun Yoo},
  doi          = {10.1016/j.engappai.2025.112301},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112301},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue. <em>EAAI</em>, <em>162</em>, 112292. (<a href='https://doi.org/10.1016/j.engappai.2025.112292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid flow shop scheduling problem (HFSP) is a prominent challenge in advanced manufacturing systems. Existing research often overlooks the impact of workers in production shops or treats worker fatigue as a static parameter, failing to capture its nonlinear accumulation and recovery effects on processing efficiency. However, with the advent of Industry 5.0, there has been a growing emphasis on the critical role of human factors in production scheduling. As a result, designing an effective algorithm for HFSP that considers human factors has become a prominent research focus. In this paper, an extended distributed heterogeneous hybrid flow shop scheduling problem with the dynamic effects of worker fatigue (DHHFSP-WF) is investigated. To address this problem, a Deep Q-Network-based multi-objective optimization algorithm (DQNMOEA) is designed to minimize makespan, total energy consumption (TEC), and total worker idle time (WIT). In DQNMOEA, a four-dimensional vector encoding scheme considering worker allocation represents solution, and a reconstruction strategy ensures initial population quality and diversity. Moreover, an improved order crossover, two-point crossover, and a segment-based recombination mutation method are proposed to enhance the global search performance of the algorithm. Then, a problem-specific local search strategy is designed for each layer of the vector, allowing the Deep Q-Network (DQN)-based adaptive decision-making mechanism to perform local perturbations on the current non-dominated solutions in the most suitable dimensions. Finally, seven algorithms are adopted to make a comparison on 36 sets of instances, the experimental results indicate that DQNMOEA exhibits competitive performance in solving DHHFSP-WF.},
  archive      = {J_EAAI},
  author       = {Jianlin Zhang and Longbin Ma and Wu Zhao and Jie Cao and Zuohan Chen and Tianpeng Xu},
  doi          = {10.1016/j.engappai.2025.112292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate. <em>EAAI</em>, <em>162</em>, 112279. (<a href='https://doi.org/10.1016/j.engappai.2025.112279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary program diffing, or simply binary diffing, is a type of program analysis technique that quantifies the similarity between two binary programs to derive their differences. In particular, binary diffing is an essential technique for uncovering vulnerabilities and potential attack vectors in industrial control systems, where patch deployment is complicated by closed and restricted environments. Studies on binary diffing can be broadly categorized into dynamic analysis-based, static analysis-based, and neural network-based approaches. Each category of existing studies has its shortcomings, including limited coverage, low accuracy, and issues with on-demand learning. In this paper, we propose the binary diffing with sampling-and-aggregate, a hierarchical binary diffing model that generates inductive code representations based on graph sampling-and-aggregate. Our model sequentially produces instruction-level embedding, block-level embedding, and function-level embedding from the inter-procedural control flow graph of a given program, and then performs hierarchical code diffing based on these embeddings. We formally define the detailed models and present the algorithm of hierarchical binary diffing. Additionally, we conduct a thorough analysis of this algorithm, deriving several advantages. We implemented a prototype and evaluated it on a large-scale dataset in a cross-version, cross-optimization, and obfuscation settings. Our prototype showed F1-scores up to 0.96 and 0.968 in cross-version setting for function and basic block diffing, respectively. Also, our method demonstrated its robustness over several binary obfuscations. In conclusion, our proposal, which generates basic block- and function-level embedding by considering the control flow, has solid advantages on binary diffing and shows the robustness on the binary tampering.},
  archive      = {J_EAAI},
  author       = {Seungho Jeon and Kijong Koo and Daesung Moon and Jung Taek Seo},
  doi          = {10.1016/j.engappai.2025.112279},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112279},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network. <em>EAAI</em>, <em>162</em>, 112278. (<a href='https://doi.org/10.1016/j.engappai.2025.112278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Excavator arms are integral to the mining and construction industries, where real-time excavation load prediction is a critical element for the advancement of automated excavation technology. This study presents a novel Physics-guided Neural Network (PGNN) designed to predict the excavating force of hydraulic cylinders used in earthwork excavation. The PGNN model synergizes the physical load model of excavators with a Gated Recurrent Unit (GRU) neural network and is optimized using the Hyperband algorithm to attain both high-speed and precise forecasting. Through comparative experiments, the study validates the PGNN model's ability to achieve optimal response speed and precision in predicting excavation loads. Additionally, the predictive performance of the PGNN model is assessed via a Hardware-in-the-loop (HIL) test, conducted within the context of an actual excavation experiment. This research introduces a promising approach that seamlessly integrates physics-based modeling with machine learning techniques, facilitating real-time load forecasting for excavators. The findings pave the way for more efficient and precise excavation processes, with implications for the broader fields of mining and construction automation.},
  archive      = {J_EAAI},
  author       = {Jinshi Chen and Yue Yu and Dongyang Huo and Han Zhang and Jingyan Wang},
  doi          = {10.1016/j.engappai.2025.112278},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112278},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plug-and-play fine grained neural cognitive diagnosis framework. <em>EAAI</em>, <em>162</em>, 112276. (<a href='https://doi.org/10.1016/j.engappai.2025.112276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive diagnosis (CD) is a core task in intelligent education, which accurately assesses students’ mastery of specific knowledge concepts (KCs) by analyzing their answer records. However, existing methods mainly rely on explicit interaction data and use diagnostic models for automatic knowledge proficiency inference. These methods lack systematic optimization for fine-grained knowledge level representation, making it difficult to fully reflect students’ true learning status. To address this, this paper introduces a Plug-and-Play F ine Grained N eural C ognitive D iagnosis Framework (FNCD) with Knowledge-Level Constraint Awareness . The framework combines a knowledge proficiency evaluation module with students’ answer records and a Q-matrix to statically assess knowledge mastery. It uses a student similarity construction method based on random grouping to reveal latent learning pattern associations. Additionally, it employs a multi-scale relational learning strategy and a Top-k attention-enhanced graph network mechanism to dynamically adjust the student similarity relationship network, accurately modeling the complex learning relationships between students. Ultimately, a joint training mechanism is used to optimize the outputs of each module, significantly improving the rationality, interpretability, and accuracy of CD. The experimental results demonstrate that FNCD, as an artificial intelligence-driven plug-and-play module, can be effectively integrated into existing CD models to enhance the modeling of fine-grained knowledge mastery and improve diagnostic accuracy, showcasing the application potential of artificial intelligence in personalized education.},
  archive      = {J_EAAI},
  author       = {Xinjie Sun and Qi Liu and Kai Zhang and Weiyin Gong and Shuanghong Shen and Fei Wang and Yan Zhuang and Meikai Bao and Shijin Wang and Yuling Ma and Enhong Chen},
  doi          = {10.1016/j.engappai.2025.112276},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112276},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Plug-and-play fine grained neural cognitive diagnosis framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight citrus detection and counting method based on deep learning model. <em>EAAI</em>, <em>162</em>, 112268. (<a href='https://doi.org/10.1016/j.engappai.2025.112268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picking robots have become an important development direction of smart agriculture, and the accurate detection, counting and lightweight deployment of fruits are the technical basis for realizing robot picking. However, due to complex weather conditions and the possible mutual occlusion between branches and citrus, it is challenging to accurately detect and count citrus in orchards. This study proposes a lightweight small target detection model for detecting and counting citrus, and deploys it on the citrus detection platform. The model first introduces FasterNet Block into the cross-stage partial feature fusion module of the backbone network to reduce the number of parameters and calculations while improving the detection accuracy of the network. Secondly, a multi-scale attention mechanism is added to the backbone network to enhance the feature extraction ability of the network. Finally, a bounding box loss function based on a dynamic non-monotonic focusing mechanism is used to increase the model convergence speed and further improve the model accuracy. Experimental results show that the model has an accuracy of 92.7%, an average precision of 91.7%, and a model size of only 5.37 megabytes. The lightweight model is applied to the citrus detection platform. Based on this application, a citrus counting method is proposed, which obtains a mean absolute error (MAE) of 0.92, a root mean square error (RMSE) of 1.28, a determination coefficient ( R 2 ) of 0.98, and a frame rate of 80.6 per second, which meets the requirements of real-time citrus detection and counting. This provides technical support for the subsequent deployment and counting research of picking robots.},
  archive      = {J_EAAI},
  author       = {Jiqing Chen and Mingchang Zhang and Bin Lu and Quan Chen and Zhiwu Jiang and Peilin Li and Jingyao Gai},
  doi          = {10.1016/j.engappai.2025.112268},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112268},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight citrus detection and counting method based on deep learning model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes. <em>EAAI</em>, <em>162</em>, 112245. (<a href='https://doi.org/10.1016/j.engappai.2025.112245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate seismic risk assessment of railway embankments is critical for risk mitigation, seismic design, and emergency planning. However, conventional methods often suffer from computational inefficiency and complexity. This study proposes a novel machine learning (ML) framework to rapidly and accurately evaluate probabilistic seismic demand and risk for railway embankments. Latin hypercube sampling is utilised to generate representative soil parameter samples to construct numerical models for simulating dynamic responses under near-fault pulse-like ground motions. The peak permanent settlement (PPS) of the embankment surface is used as the key performance metric. Multiple ML models, including decision trees, random forests (RFs), extreme gradient boosting (XGBoost), artificial neural networks (ANNs), and a stacked ML model that integrates RFs, XGBoost, and ANNs, are trained and compared. The stacked ML model outperforms the other models and achieves the highest predictive accuracy for the PPS. SHapley Additive exPlanations are used to identify the velocity spectrum intensity (VSI) and the internal friction angle of the embankment as the most influential factors. Seismic fragility and risk curves are subsequently developed. The VSI and a power-law seismic hazard function are combined to estimate the annual exceedance probabilities for three seismic design criteria levels. The proposed ML framework significantly enhances the efficiency of seismic risk analysis while maintaining high precision, thereby providing a transformative approach for the seismic assessment of railway embankments.},
  archive      = {J_EAAI},
  author       = {Pan Si and Liang Tang and Shuang Tian and Xianzhang Ling and Yanfang Liu},
  doi          = {10.1016/j.engappai.2025.112245},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112245},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events. <em>EAAI</em>, <em>162</em>, 112236. (<a href='https://doi.org/10.1016/j.engappai.2025.112236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic Principal Component Analysis (PPCA) is widely used in process monitoring. However, its underlying assumption that data follows a Gaussian distribution limits its effectiveness in handling Low Probability Events (LPEs), which often deviate from this assumption. To address this challenge, we propose a novel method called Sparse Filtering-based Improved Mixed-Gaussian Probabilistic Principal Component Analysis (SFIMPPCA) for enhanced LPEs detection. First, a Sparse Filtering (SF) preprocessing technique with an incremental structure is employed to extract the most discriminative features. Second, to address the distortion caused by LPEs, a dynamic ratio correction mechanism based on statistical variability is introduced, followed by a newly designed Mixed-Gaussian Probabilistic Principal Component Analysis (MPPCA). Third, a Bayesian Optimization Algorithm (BOA) is applied to automatically adjust control limits, enhancing the accuracy and reliability of fault detection. The effectiveness of the proposed method is validated using the Tennessee Eastman (TE) process and the Tin Chemical Process (TCP). Experimental results demonstrate that the proposed method significantly improves performance under LPEs conditions, achieving a 10%–12% improvement in most cases.},
  archive      = {J_EAAI},
  author       = {Chuangyan Yang and Jiande Wu and Peng Li and Xun Lang and Mingxi Ai and Hancheng Wang},
  doi          = {10.1016/j.engappai.2025.112236},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112236},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation. <em>EAAI</em>, <em>162</em>, 112219. (<a href='https://doi.org/10.1016/j.engappai.2025.112219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain gaps can often cause dramatic performance deterioration when applying medical image segmentation models trained on the source domain to the target domain. Although unsupervised domain adaptation methods can address the domain gap challenge to some extent, their reliance on accessing source images largely hampers their practical applicability, as source data are often inaccessible due to privacy concerns. Moreover, the low-quality characteristic of medical images can further degrade the domain adaptation performance of segmentation models. To address these issues, we propose the Masked-AutoEncoder-guided Diffusion (MAE-Diff) framework for source-free domain adaptive medical image segmentation. MAE-Diff mainly consists of a Masked AutoEncoder (MAE) Module for effective feature extraction and domain adaptation, and a Diffusion Module for effective segmentation of low-quality medical images. On source images, the MAE encoder is trained to extract image-specific features, and the Diffusion Module is trained to generate segmentation maps following a gradual denoising strategy, under the guidance of features extracted by the MAE encoder. Training on the target domain involves only fine-tuning MAE (trained on the source images) with target images, allowing MAE-Diff to adapt to the target domain distribution. Inference on target images can then be made by the source-based Diffusion Module, under the guidance of features extracted by the MAE encoder fine-tuned on the target images. Extensive experiments on three datasets demonstrate the effectiveness of the proposed framework for source-free domain-adaptive medical image segmentation. The code of MAE-Diff is available at https://github.com/xuss804/MAEDiff .},
  archive      = {J_EAAI},
  author       = {Shanshan Xu and Le Xu and Yeqing Yang and Lixia Tian},
  doi          = {10.1016/j.engappai.2025.112219},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112219},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule. <em>EAAI</em>, <em>162</em>, 112199. (<a href='https://doi.org/10.1016/j.engappai.2025.112199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first-order Takagi–Sugeno–Kang (TSK) fuzzy classifiers are famous for their high computational efficiency and strong interpretability, but they often struggle to learn from complex and large-scale datasets, and perform not very well compared to higher-order TSK fuzzy classifiers. To address this issue, in this paper we propose a novel Dynamic-Static Siamese TSK Fuzzy classifier with Inductive-Reflection Deep Fuzzy rule. It aims to enhance the model’s self-learning capabilities by utilizing Siamese network to integrate deep fuzzy knowledge and fine-grained knowledge without the need for a teacher model. The innovations of this study are as follows: (1) The deep fuzzy rules in the proposed classifier are enriched with an “Inductive-Reflection” process, which reduces constraints on traditional basic fuzzy rule and aligns rule acquisition more closely with general human thinking manners; (2) The proposed method includes a mechanism for self-learning and improvement from both deep and fine-grained fuzzy knowledge, eliminating the complexity of retraining a new teacher model; (3) An adaptive learning function is developed to effectively adjust the learning process, adapting to tasks with different complexities. Extensive experiments results on benchmark datasets, as well as two real-world datasets, demonstrate the effectiveness of the proposed classifier in terms of classification accuracy and weighted F1-score.},
  archive      = {J_EAAI},
  author       = {Xiongtao Zhang and Qihuan Shi and Yunliang Jiang and Qing Shen and Jungang Lou and Ruiqin Wang},
  doi          = {10.1016/j.engappai.2025.112199},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112199},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology. <em>EAAI</em>, <em>162</em>, 112113. (<a href='https://doi.org/10.1016/j.engappai.2025.112113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is a network of interconnected devices that collect, monitor, analyze, and exchange data. This technology plays a crucial role in the smart city infrastructure by seamlessly interconnecting various nodes. The extensive application and recognition of IoT across multiple city domains, such as healthcare, transportation, energy, education, and agriculture, bring significant challenges, with security among the most pressing. Traditional hardware technologies like Complementary Metal Oxide Semiconductor (CMOS) and Very Large Scale Integration (VLSI) suffer from limitations such as high power consumption and insufficient scalability, which hinder secure and sustainable IoT deployment. Such limitations have prompted the need to seek other technologies that would serve the dual purpose of providing security as well as energy. Quantum-based technologies can become adequate candidates offering promising solutions to make IoT devices and sustainable systems more secured. Quantum-dot Cellular Automata (QCA) has been proposed as a nanotechnology with the potential of consuming ultra-low powers, less area, and high-speed operation. QCA enhances security through sustainable computing objectives by minimizing energy usage. To improve the future security and efficiency of IoT hardware, this paper suggests a QCA-based Arithmetic Logic Unit (ALU). This ALU can generate more than 12 logical and arithmetic operations. Designed together with the majority gates, XOR gates, multiplexers, and full adders, the ALU is simulated using the QCA-Designer 2.0.3. Simulated results indicate improvements in the number of cells and reduced occupied area relative to the earlier designs. These results indicate the potential of QCA technology in enabling secure, energy-efficient, and compact computing architecture applicable in the future IoT.},
  archive      = {J_EAAI},
  author       = {Maryam Zaker and Seyed Sajad Ahmadpour and Nima Jafari Navimipour and Muhammad Zohaib and Neeraj Kumar Misra and Sankit Kassa and Ahmad Habibizad Navin and Arash Heidari and Mehdi Hosseinzadeh and Omar I. Alsaleh},
  doi          = {10.1016/j.engappai.2025.112113},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112113},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GhostPointNet: A deep learning-based method for ghost point noise detection in four-dimensional (4D) millimeter-wave radar point clouds of underground mine. <em>EAAI</em>, <em>161</em>, 112380. (<a href='https://doi.org/10.1016/j.engappai.2025.112380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high dust concentration, multi-metal supports, and narrow winding tunnels in underground mines collectively lead to frequent ghost point noise in four-dimensional (4D) millimeter-wave radar point clouds, posing serious challenges for mining perception and localization. To address this, we propose a deep learning algorithm, named GhostPointNet, for 4D millimeter-wave radar ghost point detection in underground mining environments. From an artificial intelligence perspective, this model thoroughly considers the multi-modal features of 4D millimeter-wave radar and the environmental complexity of underground mines. It incorporates multi-parameterized spatial information inputs in both Cartesian and Spherical coordinates, coupled with “Double T-Net” adaptive alignment correction, while integrating non-spatial information such as radar power and Doppler data to achieve multi-modal representation and end-to-end discrimination between ghost points and real points. Experimental validation shows that GhostPointNet achieves excellent performance in underground mining scenarios with 92.45 % accuracy and 95.84 % F1-score, outperforming traditional filtering, clustering, and machine learning algorithms. From an engineering application perspective, GhostPointNet is specifically designed for ghost noise detection in underground mines. Even in complex scenarios such as mine tunnel intersections and turns, it preserves critical structural points. Its end-to-end neural network simplifies post-processing procedures, enhances operational efficiency, and provides stable and reliable perceptual support for subsequent tasks such as autonomous mine locomotive navigation and three-dimensional (3D) structure reconstruction. Experimental results demonstrate that this method surpasses baseline approaches in ghost point detection, real point preservation, and generalization capability, providing significant support for improving underground mining safety and efficiency.},
  archive      = {J_EAAI},
  author       = {Hu Liu and Zhenghua Zhang and Jing Yang and Jörg Benndorf and Xiaofei Wang and Jiaqi Dong and Zitao Lin and Guoliang Chen},
  doi          = {10.1016/j.engappai.2025.112380},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112380},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GhostPointNet: A deep learning-based method for ghost point noise detection in four-dimensional (4D) millimeter-wave radar point clouds of underground mine},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid ensemble learning for predicting peak deviatoric stress in soil-rock mixtures from triaxial test data. <em>EAAI</em>, <em>161</em>, 112377. (<a href='https://doi.org/10.1016/j.engappai.2025.112377'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peak deviatoric stress ( q f ) is an important mechanical property index of soil-rock mixtures (SRM). However, determining it through experiments is a challenging and time-consuming task. This study presents a weighted averaging ensemble model for predicting the q f of SRM. 585 sets of consolidated drained triaxial test data for SRM were collected to construct the proposed models. Firstly, taking the extreme gradient boosting (XGBoost) as an example, the accuracy of the models established with different input parameter combinations was tested to determine the optimal inputs. Then, five artificial intelligence models were used to train the dataset, and the Bayesian optimization method was adopted for hyperparameter adjustment. Based on the prediction results, two base models (i.e. XGBoost and random forest (RF)) with good performance were selected from these five models, and a novel weighted averaging ensemble model was developed to predict the q f of SRM. The coefficient of determination (R 2 ), root mean squared error (RMSE) and mean absolute error (MAE) values of the ensemble model were 0.990, 220.0 kPa (kPa) and 118.4 kPa, respectively, for all datasets, indicating that this model has great potential in predicting the q f of SRM. In addition, the robustness, parameter patterns and the SHapley Additive exPlanations (SHAP) analysis of the ensemble model were also conducted in this study. The results of this study can be applied to rapid analysis of mechanical parameters for SRM in engineering, and are of great significance for geotechnical engineering design and disaster prevention.},
  archive      = {J_EAAI},
  author       = {Ruiliang Zhang and Xinhua Xue},
  doi          = {10.1016/j.engappai.2025.112377},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112377},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid ensemble learning for predicting peak deviatoric stress in soil-rock mixtures from triaxial test data},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph attention neural network for advancing medical imaging by enhancing segmentation and classification. <em>EAAI</em>, <em>161</em>, 112372. (<a href='https://doi.org/10.1016/j.engappai.2025.112372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor classification and segmentation using Magnetic Resonance Imaging (MRI) scans remain challenging due to limited spatial relationships and the inability of conventional models, such as Convolutional Neural Networks (CNNs), to effectively capture structural dependencies. To address these limitations, this study introduces GANN-Med (Graph Attention Neural Network for Medical Imaging), a novel framework designed to improve the accuracy and reliability of brain tumor detection, segmentation, and classification. The framework utilizes the publicly available Brain Tumor MRI dataset and applies preprocessing followed by wavelet transform to extract both spatial and frequency features, generating wavelet-based node embeddings that represent fine textures and overall tumor structure. These features are modeled as a graph and processed through a U-Net (U-shaped Convolutional Network) architecture integrated with Graph Attention Networks (GATs), enabling adaptive attention to be directed to critical tumor regions. The segmented tumor regions are then classified using GraphSAGE (Graph Sample and Aggregation) with a pooling aggregator, which supports inductive neighborhood learning while preserving topological consistency. Unlike existing models such as mResU-Net (Modified Residual U-Net) and LG-GNN (Local-Global Graph Neural Network), GANN-Med uniquely combines wavelet-based multi-resolution graph embeddings with attention mechanisms in a unified architecture. Experimental results demonstrate a significant performance boost, including an 18.47 % increase in Dice Similarity Coefficient (DSC), notable improvements in Jaccard Index and sensitivity, a 21.04 % reduction in false positives, and an overall classification accuracy of 93.2 %, with a balanced accuracy of 91.8 % across glioma, meningioma, pituitary, and no tumor classes. Additionally, the model achieves minimal training and validation losses of 43.2 % and 41.6 %, respectively, highlighting its potential to minimize misdiagnosis and contribute to more accurate, early-stage clinical decision-making in neuro-oncology.},
  archive      = {J_EAAI},
  author       = {Meshari D. Alanazi and Khaled Kaaniche and Mohammed Albekairi and Turki M. Alanazi and Munid Alanazi and Ghulam Abbas},
  doi          = {10.1016/j.engappai.2025.112372},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112372},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph attention neural network for advancing medical imaging by enhancing segmentation and classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy scheduling in distributed heterogeneous printed circuit board assembly lines: Feedback assisted neighborhood-based search coupling with rapid evaluations. <em>EAAI</em>, <em>161</em>, 112353. (<a href='https://doi.org/10.1016/j.engappai.2025.112353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Printed Circuit Board (PCB) production involves multiple heterogeneous and highly automated assembly lines running concurrently. These assembly lines involve complex processes with uncertain and fuzzy production times, presenting significant challenges for scheduling. Moreover, PCB production is notably affected by carryover sequence-dependent setup times (CSDST) and the need for product grouping, further complicating the scheduling process. To address these challenges, this paper formulates the scheduling problem as a fuzzy distributed heterogeneous flowshop group scheduling problem with carryover sequence-dependent setup times (FDHFGSP/CSDST). A novel and effective feedback-assisted population-based neighborhood search (FPBNS) algorithm, coupling with rapid evaluation of neighboring solutions, is proposed to solve this problem. The feedback strategy operates on two main levels: evaluating population quality and adjusting the search process. Additionally, an integrated heuristic method is employed to generate a high-quality and diverse initial population. To further enhance solution quality, a collaborative operation is designed to improve interaction between solutions. This comprehensive algorithm significantly enhances its adaptability in PCB manufacturing, providing an efficient solution to the complex scheduling challenges of real-world production environments. Comprehensive and systematic experiments were conducted to evaluate the effectiveness of the proposed algorithm and related methods, demonstrating its superior performance in solving the complex scheduling problem in PCB manufacturing.},
  archive      = {J_EAAI},
  author       = {Zhen-duo Han and Biao Zhang and Chao Lu and Lei-lei Meng and Wen-qiang Zou},
  doi          = {10.1016/j.engappai.2025.112353},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112353},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy scheduling in distributed heterogeneous printed circuit board assembly lines: Feedback assisted neighborhood-based search coupling with rapid evaluations},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A high-precision acupoint recognition and localization model for acupuncture robot end-effectors. <em>EAAI</em>, <em>161</em>, 112348. (<a href='https://doi.org/10.1016/j.engappai.2025.112348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate acupoint recognition is fundamental to therapeutic efficacy of acupuncture robots, presenting a crucial challenge in medical robotics: high-precision, real-time localization of sparse features on deformable skin surfaces. To address this, we propose the Acupoint Recognition Network (ACU-Net) for reliable acupoint identification to guide robotic acupuncture. From an artificial intelligence (AI) perspective, the core contribution of ACU-Net lies in its novel modules. The Convolutional Dilatation with Residual and Split (CDRS) module uses dilated convolution to expand the receptive field and overcomes the sparsity of acupoint features by capturing both anatomical contexts and subtle local gradients. The Cross-Scale Feature Fusion (CSFF) architecture integrates spatial and semantic information more effectively than standard Feature Pyramid Network (FPN). Formulated as a keypoint regression task, the network is jointly optimized using a weighted Object Keypoint Similarity (OKS)-based loss function. Evaluated on a physician-annotated, large-scale chest acupoint dataset, ACU-Net has achieved a mean Average Precision (AP 50-95 (B)) of 94.1 % for acupoint bounding boxes and 99.5 % for acupoint points (AP 50-95 (P)), outperforming mainstream Convolutional Neural Networks (CNNs) and Transformer models. Its average prediction error (0.282 cm) on volunteers represents a 30.9 % reduction compared to the second-best model of Real-Time Multi-person Pose Estimation (RTMPose). Robustness test on an independent forearm dataset confirmed its precision. Attention visualization showed strong focus on acupoint regions. Testing on chest acupoint under adverse imaging conditions of low illumination and information loss demonstrated its reliability with zero missed detection. This work significantly advances the development of acupuncture robotics for intelligent diagnosis and treatment.},
  archive      = {J_EAAI},
  author       = {Ailing Tan and Hao Mu and Wei Ma and Yu'e Lv and Haoyu Wang and Yong Zhao},
  doi          = {10.1016/j.engappai.2025.112348},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112348},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A high-precision acupoint recognition and localization model for acupuncture robot end-effectors},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Eviformer: An uncertainty fault diagnosis framework guided by evidential deep learning. <em>EAAI</em>, <em>161</em>, 112328. (<a href='https://doi.org/10.1016/j.engappai.2025.112328'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unpredictable signals are commonly encountered during equipment operation, and existing deep learning-based fault diagnosis methods often fail to accurately evaluate the uncertainty of diagnostic results, limiting the model's capacity to respond to unexpected signals. To address this challenge, this study introduces a modified Transformer model based on deep evidential learning—Eviformer. The proposed model first employs a Swin-Transformer (ST)-based distribution projector, which preserves the advantages of ST in extracting features from vibration signals and simultaneously projects these signals directly into a Dirichlet distribution with second-order probabilities. Furthermore, by incorporating novel evidence correction terms and a constraint factor to reconstruct the evidence constraint loss, more precise uncertainty quantification in diagnostic predictions is achieved. Using a gear-bearing vibration dataset, comparative experiments were conducted across various scenarios, including out-of-distribution gear faults, faults in unmonitored components, noise interference, and variable speed conditions. The results demonstrate that the proposed method can promptly issue uncertainty-based warnings when encountering vibration signals that significantly differ from the training set distribution, thereby offering essential support for maintenance decisions.},
  archive      = {J_EAAI},
  author       = {Jingjie Luo and Fucai Li and Xiaolei Xu and Wenqiang Zhao and Dongqing Zhang},
  doi          = {10.1016/j.engappai.2025.112328},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112328},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Eviformer: An uncertainty fault diagnosis framework guided by evidential deep learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale spatiotemporal feature fusion for super-resolution video reconstruction in dynamic scenes. <em>EAAI</em>, <em>161</em>, 112327. (<a href='https://doi.org/10.1016/j.engappai.2025.112327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-quality geospatial video reconstruction is vital for applications such as urban surveillance and disaster assessment. However, existing methods often suffer from motion blur and visual artifacts due to hardware limitations and dynamic environments with rapid motion, frequent background changes, and lighting variations. To address these challenges, we propose a novel video super-resolution method called Multi-Scale Spatiotemporal Feature Fusion for Video Super-Resolution. This approach leverages artificial intelligence techniques to extract rich spatiotemporal features using a multi-scale deformable convolutional pyramid with parallel branches. It integrates contextual residual learning and optical flow estimation to capture spatial details and compensate for missing temporal information. A hybrid spatiotemporal attention mechanism adaptively fuses key features across frames through dynamic weighting, suppressing background interference and enhancing target-region representation. The framework includes an explicit motion compensation module for precise frame alignment, followed by upsampling to generate high-resolution frames with improved perceptual quality. A multi-task joint loss function optimizes structural fidelity, motion consistency, and visual realism. Experimental results on the University of Alberta Detection and Tracking dataset and Video for Super-Resolution benchmark show the method achieves a peak signal-to-noise ratio of 30.62 dB and a structural similarity index of 0.92, surpassing state-of-the-art methods by up to 4.28 dB and improving perceptual metrics such as Learned Perceptual Image Patch Similarity and Flip Loss in Perception. Ablation studies confirm each module's contribution. The model runs efficiently at 24.8 ms per frame, demonstrating potential for real-time applications. This approach offers a robust and efficient solution for high-resolution geospatial video reconstruction.},
  archive      = {J_EAAI},
  author       = {mengqin Yang and yanhui Wang and yang Yang and chunhua Peng},
  doi          = {10.1016/j.engappai.2025.112327},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112327},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale spatiotemporal feature fusion for super-resolution video reconstruction in dynamic scenes},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable framework based on integrated sensor fusion and deep learning to estimate stability in high-speed micromilling of thin-walled titanium alloy. <em>EAAI</em>, <em>161</em>, 112326. (<a href='https://doi.org/10.1016/j.engappai.2025.112326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel deep learning (DL) framework based on multi-sensor fusion based on vibration and audio signals with transfer learning has been developed and validated for chatter onset prediction in micromilling of thin-walled titanium (TC4) alloys. The DL framework has been trained and validated with individual sensor data, labelled using machined surface micrographs and cutting tool condition. A total of 879,840 spectrograms has been generated for training via signal segmentation and augmentation methods that yielded a validation accuracy of 89 % during training phase. The trained DL model has been tested on the unlabelled fused signal data to make the DL model adapt to the unseen patterns in the signals recorded during real-time machining. The proposed DL framework based on fused signals outperformed individual sensor-based detection methods by demonstrating an increment of 33 % in accuracy, with a mean absolute error of 0.027416 and R 2 of 0.987. Ablation studies confirm that fusing signals enhances the DL model's performance, yielding a 21 % and 29 % improvement in precision and recall, respectively. The optimal fusion strategy reduced chatter misclassification, with one instance of misclassification. The proposed framework presents a robust, explainable DL approach that can be readily used for adaptive control of cutting conditions in different manufacturing processes. The industry readiness of the DL model has been demonstrated by testing the pretrained model on turning process. The DL model shows 95.31 % prediction accuracy with only three misclassifications out of sixty-four test conditions.},
  archive      = {J_EAAI},
  author       = {Sethurao Gururaja and Kundan K. Singh},
  doi          = {10.1016/j.engappai.2025.112326},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112326},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable framework based on integrated sensor fusion and deep learning to estimate stability in high-speed micromilling of thin-walled titanium alloy},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Liquid metal microfluidic cooling system for high-efficiency thermal management via learning-based genetic algorithm. <em>EAAI</em>, <em>161</em>, 112324. (<a href='https://doi.org/10.1016/j.engappai.2025.112324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High heat flux density is a critical factor that limits the performance and reliability of miniaturized, high-power microelectronic systems. This study proposes a liquid metal (LM)-based microfluidic cooling system optimized through a data-driven computational framework based on an enhanced Genetic Algorithm (LC-GA), aiming to deliver an efficient thermal management solution for high-density integrated systems. By integrating LM near-junction cooling with microchannel heat dissipation in a silicon substrate, we developed a heterogeneous three-dimensional interconnect cooling architecture capable of optimizing thermal performance through algorithm-guided parameter tuning. To validate the proposed method, four distinct microchannel configurations were designed, fabricated, and experimentally tested. LM was introduced into the channels to conduct both experimental cooling tests and thermal performance simulations on a simulated heat source. The results demonstrate that this LM-based microfluidic cooling system, optimized through computational parameter determination, can effectively dissipate heat from chips with power consumption up to 800 W while maintaining stable thermal performance. Additionally, a response surface methodology combined with enhanced LC-GA was utilized for multi-factor sensitivity analysis and multi-objective optimization, enabling automatic determination of optimal design and operating parameters to balance thermal resistance and pressure drop. The optimized configuration reduced the maximum chip temperature to approximately 357.54 K, lowered the system pressure requirement, and improved the Performance Evaluation Criterion (PEC) to 2.327. This work provides a data-driven optimization approach that supports the development of high-performance integrated microsystems through algorithm-assisted thermal design.},
  archive      = {J_EAAI},
  author       = {Yucheng Wang and Antong Bi and Kaiyu Chen and Shenxin Yu and Wanping Gao and Wenyi Zhang and Yuwan Wu and Zhiqiang Li and Shaoxi Wang},
  doi          = {10.1016/j.engappai.2025.112324},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112324},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Liquid metal microfluidic cooling system for high-efficiency thermal management via learning-based genetic algorithm},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HoloFluoNet: Live cell imaging intelligence based on fused holography and fluorescence for virtual staining, cell segmentation, classification, and viability analysis. <em>EAAI</em>, <em>161</em>, 112323. (<a href='https://doi.org/10.1016/j.engappai.2025.112323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluorescence microscopy enables detailed visualization of subcellular structures but is limited by phototoxicity, photobleaching, and labor-intensive labeling. In contrast, digital holographic microscopy (DHM) offers label-free, quantitative phase imaging but lacks biochemical specificity. To integrate the strengths of both modalities, we propose HoloFluoNet, a deep learning-based framework that generates virtual fluorescence information from phase images acquired by DHM. Using a dual-mode imaging system, we simultaneously captured phase and fluorescence images of live cancer cells. The fluorescence data were used to construct biologically grounded supervision signals, including nuclei masks and multi-class cell viability labels. From a single-phase image, HoloFluoNet predicts a virtual nuclei mask, a distance map for boundary refinement, and a viability mask. The architecture incorporates multi-scale feature extractor, and attention mechanisms, optimized with novel inclusion and exclusion loss functions. Post-processing using the watershed algorithm ensures accurate segmentation of overlapping cells. The final registered image provides label-free virtual staining for nuclei localization, viability assessment, and class-specific morphological profiling. HoloFluoNet achieved a Dice score of 0.8685 and an Aggregated Jaccard Index (AJI) of 0.7883, outperforming conventional deep learning models such as U-Net, Fully Convolutional Network (FCN), Pyramid Scene Parsing Network (PSPNet), and DeepLab v3+. These improvements were statistically validated using one-way analysis of variance (p < 0.01). Ablation experiments confirmed the complementary roles of architectural modules and novel loss functions, while robustness tests under noisy and low-quality conditions revealed high stability to low contrast and moderate noise. With an inference speed of 0.123 s per image, the model enables real-time cellular analysis. By bridging structural and molecular imaging, HoloFluoNet provides an efficient, label-free alternative to fluorescence microscopy, with promising applications in artificial intelligence (AI)-assisted drug screening, cancer research, and live-cell monitoring.},
  archive      = {J_EAAI},
  author       = {Seonghwan Park and Jaeseong Lee and Jaewoo Park and Inkyu Moon},
  doi          = {10.1016/j.engappai.2025.112323},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112323},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HoloFluoNet: Live cell imaging intelligence based on fused holography and fluorescence for virtual staining, cell segmentation, classification, and viability analysis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Method for ensuring quasi-maximum stability of a system with interval deviations by a robust controller parametric synthesis. <em>EAAI</em>, <em>161</em>, 112320. (<a href='https://doi.org/10.1016/j.engappai.2025.112320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that ensuring reliable stability of automatic control systems with interval and stochastic parameter deviations is critical for aviation and other critical areas. Therefore, this article proposes a method for synthesizing Proportional-Integral-Derivative controller parameters based on the coefficient approach to stability analysis (through the characteristic polynomial neighboring coefficients ratios) with an extension to interval uncertainties and the stability quasi-maximum degree integration into the multi-criteria optimization Non-Dominated Sorting Genetic Algorithm II. Scientific contribution and novelty lie in combining analytical sufficient stability conditions (including verification by Kharitonov polynomials and dominant polynomial analysis) with multi-objective optimization taking into account parameter errors and energy costs, which allows obtaining stable and economical Proportional-Integral-Derivative settings for discrete two-channel systems. The results are confirmed by numerical experiments on a helicopter turboshaft engine two-channel control system model with real on-board data. It is shown that the optimal parameter vector provides overshoot of ≈1.43 % and transient process time of ≈1.12 s and maintains stability with local changes in coefficients (±3 … 7 %) and in Monte-Carlo tests. At the same time, a comparative analysis with traditional and neural network controllers showed the proposed approach's advantage in key metrics.},
  archive      = {J_EAAI},
  author       = {Denys Baranovskyi and Serhii Vladov and Valerii Sokurenko and Oleksandr Muzychuk and Victoria Vysotska and Maryna Bulakh},
  doi          = {10.1016/j.engappai.2025.112320},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112320},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Method for ensuring quasi-maximum stability of a system with interval deviations by a robust controller parametric synthesis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust deep learning model selection with data augmentation for automatic detection of tessellated fundus images and explainable artificial intelligence based interpretation. <em>EAAI</em>, <em>161</em>, 112316. (<a href='https://doi.org/10.1016/j.engappai.2025.112316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust deep learning system for automatically classifying retinal fundus images into two classes—normal and tessellated—is presented in this study. Visual Geometry Group – 16 is used as the base model, taking advantage of transfer learning to develop an efficient framework for fundus image classification. The approach uses nine different model architectures and makes use of a dataset of 352 fundus images that was increased to 4865 samples using sophisticated data augmentation techniques. Of these, Model_8 performed the best, achieving a loss of 0.129 % and an impressive accuracy of 99.39 %. The suggested approach ensures higher performance and dependability by combining rigorous data augmentation, efficient preprocessing, and model fine-tuning techniques. Furthermore, Explainable Artificial Intelligence was used to improve the interpretability of the model and visualize important aspects such as features or imposed pathologies in fundus images more clearly. The study offers promising support to ophthalmologists by offering precise automated diagnoses for the early identification and treatment of retinal disorders.},
  archive      = {J_EAAI},
  author       = {Kachi Anvesh and Shanmugasundaram Hariharan and Bharati M. Reshmi and Qiang Xu and Joan Lu and Vinay Kukreja and Murugaperumal Krishnamoorthy},
  doi          = {10.1016/j.engappai.2025.112316},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112316},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust deep learning model selection with data augmentation for automatic detection of tessellated fundus images and explainable artificial intelligence based interpretation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Camera-invariance correlation learning and inter-domain-specific distinct representation for person re-identification. <em>EAAI</em>, <em>161</em>, 112314. (<a href='https://doi.org/10.1016/j.engappai.2025.112314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) in person re-identification (ReID) experiences performance degradation due to two primary factors: (1) the information changes across cameras among intra-domain identity samples within the source and target domains; and (2) the inter-domain gap when applied to an unexplored image domain, which makes it a challenging task. The majority of current methodologies predominantly address the inter-domain gap while overlooking the impact of the intra-domain issue. To overcome this limitation, this paper proposes an effective invariance representation ReID (IR-ReID) network that encompasses camera-invariance correlation learning (CICL) and Transformer-based, inter-domain-specific discriminative representation (IDSR), supported by curriculum learning, with the aim of concurrently addressing both of these pivotal issues. Specifically, a CICL module is designed to explore intra-domain distinct features of an individual captured by multiple cameras across the source and target domains. Secondly, an IDSR module is proposed to address the inter-domain gap issue. Thirdly, a curriculum learning-driven strategy is introduced for sample training, systematically guiding our network in learning samples progressively, ranging from easy to difficult instances. Meanwhile, a cluster-based constraint loss is presented to further optimize the clustering results. Finally, extensive experiments are conducted on three well-known datasets, which demonstrate the effectiveness and superiority of our proposed approach in comparison to the prevailing state-of-the-art methodologies.},
  archive      = {J_EAAI},
  author       = {Shangdong Zhu and Yunzhou Zhang and Peng Duan},
  doi          = {10.1016/j.engappai.2025.112314},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112314},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Camera-invariance correlation learning and inter-domain-specific distinct representation for person re-identification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applications of machine vision technology for conveyor belt deviation detection: A review and roadmap. <em>EAAI</em>, <em>161</em>, 112312. (<a href='https://doi.org/10.1016/j.engappai.2025.112312'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conveyor belt deviation is a frequent challenge in product transportation filed, and failure to promptly detect and rectify this anomaly not only significantly reduces transport efficiency but also poses a risk of serious safety accidents, leading to enormous economic losses. Traditional contact-based deviation detection technologies, with their inherent limitations of high costs and complicated maintenance, have struggled to meet the practical demands of long-distance conveyor belt inspection. In this context, non-contact machine vision technology has emerged as a prominent solution in the field of conveyor belt deviation detection, thanks to its notable advantages of a simple hardware structure and round-the-clock operational capability. Recently, with the rapid development of artificial intelligence theories, this research field has accumulated a series of effective solutions that have been proven through machine vision practical applications. This paper delves into the technical principles of the existing solutions, systematically summarizes them and objectively evaluates their strengths and weaknesses in practical applications. Based on this foundation, this paper also provides an insight on the future development trends of intelligent monitoring for conveyor belt deviation, aiming to offer valuable reference and guidance to technicians in related fields.},
  archive      = {J_EAAI},
  author       = {Jiaming Han and Ting Fang and Wensheng Liu and Chenxiao Zhang and Molin Zhu and Jibin Xu and Jie Ji and Xianhua He and Zhang Wang and Min Tang and Chong Dong and Long Ma and Xinlong Yang},
  doi          = {10.1016/j.engappai.2025.112312},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112312},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Applications of machine vision technology for conveyor belt deviation detection: A review and roadmap},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic aperture radar target recognition with limited training data based on frequency-domain-assisted dual-stream attention hierarchical deformable convolutional networks. <em>EAAI</em>, <em>161</em>, 112309. (<a href='https://doi.org/10.1016/j.engappai.2025.112309'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of synthetic aperture radar (SAR) automatic target recognition (ATR), the recognition performance of deep learning methods is often constrained by sample scarcity. To address this issue, this paper proposes a frequency-domain-assisted dual-stream attention hierarchical deformable convolutional network (DAHDF-Net). A frequency-domain-assisted dataset construction method is designed to extend the representational diversity of the sample feature space. Then, a parallel input architecture of frequency-space dual-stream features is constructed, and the adaptive dynamic fusion of frequency-domain stream features with spatial-domain stream features is realized by using a channel attention module in the frequency-domain stream. To enhance the expressiveness of the network on the basis of modulated deformation convolution, a hierarchical residual (H-residual) module is designed. Moreover, a triple hybrid loss is proposed to address the issues of high deformation, which makes classification difficult, and the fuzzy decision boundaries between categories. Experiments were conducted on the moving and stationary target acquisition and recognition (MSTAR) dataset and the FUSAR-Ship dataset. Among them, DAHDF-Net achieves recognition accuracies of 99.75 % and 97.48 % on all training sets and 10-way 25-shot under standard operating condition (SOC) of MSTAR, which demonstrated superior recognition accuracy compared to current state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Shanliang Yuan and Hongyuan Gao and Xiaoyuan Gu and Jingya Ma},
  doi          = {10.1016/j.engappai.2025.112309},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112309},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synthetic aperture radar target recognition with limited training data based on frequency-domain-assisted dual-stream attention hierarchical deformable convolutional networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale distance similarity entropy: A novel complexity measurement for gearbox fault diagnosis. <em>EAAI</em>, <em>161</em>, 112308. (<a href='https://doi.org/10.1016/j.engappai.2025.112308'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entropy-based methods have gained increasing attention in fault diagnosis due to their capability in quantifying the intrinsic complexity and dynamic behavior of time series signals. Vibration signals from gearboxes are typically nonlinear, nonstationary, and transient, often spanning multiple time scales, thus requiring robust multi-scale analysis for accurate condition assessment. However, existing multi-scale entropy methods, prone to missing local variations and vulnerable to noise, often yield incomplete features and low diagnostic accuracy with high computational costs. To overcome these challenges, this paper proposes a novel complexity measurement method termed multi-scale distance similarity entropy, which integrates distance similarity entropy with a multi-scale coarse-graining process. By computing element-wise distances and mapping them through a Gaussian kernel function, multi-scale distance similarity entropy captures subtle nonlinear variations in vibration signals while effectively suppressing noise interference. It estimates the similarity distribution between adjacent vectors, enabling sensitive tracking of dynamic complexity changes in mechanical vibration data. Experimental validation on two gearbox datasets encompassing both single and compound faults demonstrates that multi-scale distance similarity entropy achieves superior classification accuracies of 98.63 % and 97.14 %, respectively. The method also shows strong robustness under random impulse noise and low signal-to-noise ratio conditions, along with high computational efficiency, particularly in small-sample scenarios. These characteristics make it highly suitable for online real-time fault diagnosis in complex and noise contaminated industrial environments involving diverse and compound fault patterns.},
  archive      = {J_EAAI},
  author       = {Tao Wang and Shin Yee Khoo and Zhi Chao Ong and Pei Yi Siow and Teng Wang},
  doi          = {10.1016/j.engappai.2025.112308},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112308},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale distance similarity entropy: A novel complexity measurement for gearbox fault diagnosis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JSSM-DTA: Joint sequence-structure modeling with multi-scale transformers for explainable drug-target affinity prediction. <em>EAAI</em>, <em>161</em>, 112303. (<a href='https://doi.org/10.1016/j.engappai.2025.112303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-Target Affinity (DTA) prediction is a pivotal task in drug discovery, aiming to quantify the strength of interactions between drug molecules and their biological targets, such as proteins. Despite significant advancements in deep learning-based methods, several challenges persist. Scale mismatches obstruct functional group-specific representations, leading to suboptimal feature extraction and loss of critical interaction patterns. Additionally, the inability to fully exploit molecular graph structures weakens hierarchical dependency modeling, while ineffective feature fusion hampers the integration of heterogeneous molecular representations, restricting the capture of intricate drug-target interaction dynamics. To address these challenges, this work introduces JSSM-DTA, a novel Joint Sequence-Structure Modeling framework that integrates Multi-Scale Transformers with intermodal feature attention to enhance DTA prediction. JSSM-DTA formulates a unified representation space through the Adaptive Convolutional Transformer (ACT) and the Multi-Scale Diffusion Transformer (MSDT), where ACT refines sequential feature extraction by capturing intricate local dependencies and long-range contextual relationships, while MSDT preserves hierarchical learning, optimizing both global topological organization and fine-grained interactions. Additionally, the Factorized Inter-layer Interaction Module constructs joint embeddings by seamlessly integrating heterogeneous representations, enabling robust feature fusion. The proposed model was evaluated on Davis, KIBA, Metz and BindingDB datasets, demonstrating superior predictive accuracy over state-of-the-art methods. Explainability analysis reveals key molecular substructures and binding interactions, enhancing transparency in decision-making and establishing JSSM-DTA as a benchmark for both accuracy and interpretability in DTA prediction.},
  archive      = {J_EAAI},
  author       = {Uma E. and Mala T.},
  doi          = {10.1016/j.engappai.2025.112303},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112303},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {JSSM-DTA: Joint sequence-structure modeling with multi-scale transformers for explainable drug-target affinity prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyclic translations between pathomics and genomics improve automatic cancer diagnosis from whole slide images. <em>EAAI</em>, <em>161</em>, 112302. (<a href='https://doi.org/10.1016/j.engappai.2025.112302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incorporating genomic characterization into histopathological image modeling brings substantial value to enhancing diagnostic accuracy and supporting the development of targeted and effective treatment strategies. However, prevailing multi-modal integration methods often assume the availability of both pathomics and genomics data in both training and testing phases, overlooking the challenge of data absence due to prohibitive costs. In this paper, we propose a multi-modal cyclic feature generation network (MCFGN) that facilitates cyclic translations between pathomics and genomics to acquire a unified representation of multi-modal data. This approach enables the use of pathological images alone as input to generate joint representations during the testing phase. First, we utilize a general-purpose, self-supervised vision encoder to embed histological image patches as distinctive visual tokens. Next, we hierarchically aggregate patch-level tokens to region-level and slide-level, generating improved whole slide image (WSI) representations. We build self-supervised Masked Autoencoders (MAE) to initialize the hierarchical aggregator. Finally, to incorporate genomic characterization into the learning process, we develop a novel cross-modal cyclic feature generation module to create an intermediate joint representation of pathological and genetic features for patient diagnosis. Evaluations have been conducted on two public datasets from The Cancer Genome Atlas Breast Invasive Carcinoma (TCGA-BRCA) and Non-Small Cell Lung Cancer (TCGA-NSCLC) for various diagnostic tasks, including cancer subtyping and biomarker status prediction. Experiments indicate that our MCFGN model improves predictive performance in cancer diagnosis using histological slides, yielding an 8.7% improvement in area under the curve (AUC) for the cancer subtyping task and a 14.1% gain for biomarker prediction.},
  archive      = {J_EAAI},
  author       = {Xinyu Hao and Hongming Xu and Xiaofeng Wang and Tong Wang and Timo Hamalainen and Fengyu Cong},
  doi          = {10.1016/j.engappai.2025.112302},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112302},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cyclic translations between pathomics and genomics improve automatic cancer diagnosis from whole slide images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multimodal industrial anomaly detection method based on mask training and teacher–student joint memory. <em>EAAI</em>, <em>161</em>, 112299. (<a href='https://doi.org/10.1016/j.engappai.2025.112299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the teacher–student framework has been applied to both single-modality detection and multimodal detection, which realizes anomaly detection based on the feature difference between the teacher model and the student model. However, current multimodal teacher–student models use the same teacher model to extract two-dimensional (2D) image and three-dimensional (3D) point cloud features. The point cloud features extracted by the teacher model pre-trained on images are not the optimal feature representation. To further improve the performance of the teacher–student framework on the multimodal anomaly detection task, this paper proposes M ultimodal T eacher- S tudent J oint M emory ( MTSJM ). MTSJM constructs a teacher–student joint memory bank for each modality, the feature distance between the test sample and the memory bank is used as the anomaly indicator. This distance reflects the feature differences between the test sample and the normal sample at multiple levels, including the teacher–teacher, teacher–student, and student–student levels. Then, this paper proposes a mask-based student model training method. While ensuring that the student learns the feature of normal regions, mask training increases the feature difference of non-normal regions between the student and the teacher. On the MVTec 3D Anomaly Detection (MVTec 3D-AD) dataset, the proposed MTSJM achieves effective anomaly detection performance, reaching 95.7% mean Image-level Area Under the Receiver Operator Curve (I-AUROC) and 97.2% mean Area Under the Per-Region Overlap (AUPRO). In addition, MTSJM achieves 99.3% I-AUROC and 99.6% Pixel-level AUROC (P-AUROC) on a real-world vehicle stamping part task, which further illustrates the applicability of MTSJM on the multimodal anomaly detection task.},
  archive      = {J_EAAI},
  author       = {Yi Liu and Changsheng Zhang and Xingjun Dong and Yufei Yang},
  doi          = {10.1016/j.engappai.2025.112299},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112299},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multimodal industrial anomaly detection method based on mask training and teacher–student joint memory},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuse MetaFormer with convolutional neural networks for three-dimensional model classification. <em>EAAI</em>, <em>161</em>, 112298. (<a href='https://doi.org/10.1016/j.engappai.2025.112298'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimedia technology is widely applied to artificial intelligence and it is key to the performance of artificial intelligence systems, such as computer-aided design system, virtual reality system, the augmented reality system, medical image processing system, and game development system. With the development of multimedia technology, the number of three-dimensional (3D) models in network or database is becoming larger and larger. It is important to classify 3D models. In order to improve accuracy of three-dimensional model classification, a method of 3D model classification fusing MetaFormer with CNN (Convolutional Neural Networks) is proposed. 3D model is projected into two-dimensional (2D) views through the fixed-view projection, and representative views are selected by the clustering algorithm. Points sampled randomly from representative view are used to calculate its shape descriptors. View feature is extracted from representative view by MetaFormer. Shape feature is extracted from shape descriptors of representative view by Convolutional Neural Networks. View feature and shape feature of representative view are fused. At the same time, majority voting algorithm is used to determine category of 3D model based on the fusion of view features and shape features. Experiments are conducted on ModelNet10 dataset. Experimental results show that the proposed method achieves better results than others.},
  archive      = {J_EAAI},
  author       = {Xueyao Gao and Haomin Wu and Chunxiang Zhang and Yongzeng Xue},
  doi          = {10.1016/j.engappai.2025.112298},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112298},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuse MetaFormer with convolutional neural networks for three-dimensional model classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent design of broadband metasurface based on spectrum prediction neural network and transition simulated annealing algorithm. <em>EAAI</em>, <em>161</em>, 112297. (<a href='https://doi.org/10.1016/j.engappai.2025.112297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, metasurfaces have demonstrated considerable potential for application across various fields, including wireless communication, Internet of Things, holographic imaging, and radar systems. With the rapid development of artificial intelligence and its application in other disciplines, metasurface design based on artificial intelligence techniques, particularly deep learning, has attracted widespread attention. In this paper, we propose a novel scheme that integrates deep neural networks with an enhanced simulated annealing algorithm to achieve intelligent design of broadband metasurfaces. Firstly, we construct and train a neural network capable of accurately predicting the amplitude and phase responses of an isotropic metasurface structure, achieving a Mean Absolute Error of 1.36° on the test set. Subsequently, we develop a novel simulated annealing algorithm that is integrated with the prediction neural network to form an intelligent optimization framework. This approach can effectively search for the solution space to accurately achieve arbitrary target phase response, with a very low Mean Squared Error calculated on the test set. Furthermore, we validate the effectiveness of the proposed model and algorithm through a practical application that demonstrates broadband dispersion characteristics within the frequency range of 9–11 Gigahertz (GHz). Additionally, the prediction model can employ transfer learning strategy to adapt to various operating frequency bands, significantly enhancing its generalization capabilities. The proposed intelligent design methodology introduces a novel pathway for rapidly designing metasurface in complex application scenarios, serving as a valuable reference for the engineering design of devices in electronics, optics, and wireless communication.},
  archive      = {J_EAAI},
  author       = {Yin Zhang and Yuxin Dai and Yiyu Fan and Jun Yu},
  doi          = {10.1016/j.engappai.2025.112297},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112297},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent design of broadband metasurface based on spectrum prediction neural network and transition simulated annealing algorithm},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Industrial fabric defect-generative adversarial network (IFD-GAN): High-fidelity fabric cross-scale defect samples synthesis method for enhancing automated recognition performance. <em>EAAI</em>, <em>161</em>, 112296. (<a href='https://doi.org/10.1016/j.engappai.2025.112296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {—High-quality defect samples and datasets are the cornerstone for enhancing the performance of deep learning detection algorithms for fabric defects. Constraints, such as the complexity of fabric textures, the diversity and sporadic occurrence of defects, the insufficient scale, and the significant class imbalance of datasets, impede improvements in detection accuracy and generalization of detection models, thereby limiting industrial application. To address the issues above, a two-stage generative model for fabric defect images called Industrial Fabric Defect-Generative Adversarial Network (IFD-GAN), based on contrastive learning mutual information mechanism, was introduced. The Pixel-level Defect-Background Stripper (DBS) was devised for precise localization, and the Longitude-Latitude Self-Attention Mechanism (LLSA) was proposed to efficiently focus on defect foreground details, facilitating decoupling and efficient extraction of defect features. The combination of the two, along with the structural similarity loss function, collectively regulates the coordination and consistency between defect and background textures. An industrial-grade fabric defect dataset was collected for IFD-GAN training and generative testing. The model's effectiveness in generating defect images was evaluated based on dimensions such as fidelity and diversity. IFD-GAN is used to enhance this dataset, and the system compared the performance of advanced object detection models trained on the datasets before and after the enhancement. Extensive experimental results show that IFD-GAN can accomplish high-fidelity generation of high-resolution cross-scale fabric defect images in an unsupervised environment, significantly contributing to the creation of more balanced and diverse large-scale industrial fabric defect datasets and the enhancement of defect detection networks in precision, robustness, and generalizability.},
  archive      = {J_EAAI},
  author       = {Shun Xu and Sheng Cheng and Shuyang Jin and Xudong Hu and Weitao Wu and Zhong Xiang},
  doi          = {10.1016/j.engappai.2025.112296},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112296},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Industrial fabric defect-generative adversarial network (IFD-GAN): High-fidelity fabric cross-scale defect samples synthesis method for enhancing automated recognition performance},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample-efficient planning-control framework for autonomous underwater vehicle docking using lightweight cross Q-learning. <em>EAAI</em>, <em>161</em>, 112293. (<a href='https://doi.org/10.1016/j.engappai.2025.112293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous Underwater Vehicles (AUVs) are essential for long-duration missions in underwater sensor networks, but their operation is constrained by limited onboard energy and low-bandwidth communication. Docking stations are deployed to support energy replenishment and data transfer, requiring AUVs to autonomously plan return trajectories and achieve precise docking. Traditional motion planning and control methods for AUV docking often decouple global motion planning from local control or rely on accurate dynamics models, while existing deep reinforcement learning (DRL) approaches frequently neglect sample efficiency. This work presents a novel DRL framework that tightly integrates motion planning and control while emphasizing sample efficiency to enable reliable and efficient AUV docking. The docking task is formulated as an Markov Decision Process (MDP), in which a structured reward function is defined to guide the agent towards goal-directed behavior in an interpretable and sample-efficient manner. A lightweight Cross Q-Learning (CrossQ-Lite) algorithm is developed by removing target networks and incorporating batch normalization, achieving stable learning with approximately 92.8% fewer parameters while maintaining comparable performance. Simulation results demonstrate that, under the proposed MDP formulation, CrossQ-Lite achieves a minimum of 1 . 39 × higher sample efficiency and improved training stability compared to state-of-the-art DRL baselines. The trained model reliably completes AUV docking tasks, providing a practical and high-performance solution for autonomous underwater sensor networks.},
  archive      = {J_EAAI},
  author       = {Kaixin Zhang and Yuelong Xu and Minghao Zhao and Yu Jiang},
  doi          = {10.1016/j.engappai.2025.112293},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112293},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sample-efficient planning-control framework for autonomous underwater vehicle docking using lightweight cross Q-learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault diagnosis of wind turbine based on dual-channel feature aggregation network with attentional mechanism. <em>EAAI</em>, <em>161</em>, 112291. (<a href='https://doi.org/10.1016/j.engappai.2025.112291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind turbines are subjected to alternating stresses and shock loads during operation, and the collected vibration signals are nonlinear, non-stationary and contain noise, resulting in subtle fault features that are difficult to extract. In order to extract discriminative features from vibration signals under variable speed operating conditions, a dual-channel feature aggregation network (DCNet) with attention mechanism is developed in this paper. First, a Parallel Patch-Aware Convolutional Module (PPCM) is constructed to extract feature information of different scales and levels from Time–Frequency Representations (TFR). Specifically, convolutional operations are performed in both the spatial and frequency domains, endowing it with local–global capturing capabilities and efficiency. Then, to improve the network operation rate, Haar Wavelet Downsampling (HWD) is embedded into the DCNet architecture. The core idea is to reduce the spatial resolution of features through Haar wavelet transform while preserving as many discriminative features as possible. Additionally, Channel Prior Convolutional Attention (CPCA) is introduced to enable DCNet to focus on more critical feature parts by dynamically allocating channel and spatial attention weights, thereby suppressing redundant feature interference. Finally, in the Deep Feature Fusion Module (DFFM), a cross-attention mechanism is adopted for global interaction, fusing features from different channels to achieve feature enhancement. To obtain good diagnostic results under variable speed conditions, we apply a label smoothing algorithm to assist model training. The experimental results show that the proposed model has high diagnostic accuracy, can generalize effectively, and it still maintains high diagnostic accuracy under noise and variable speed working conditions.},
  archive      = {J_EAAI},
  author       = {Haiyu Guo and Xingzheng Guo and Xiaoguang Zhang and Fanfan Lu and Chuang Liang},
  doi          = {10.1016/j.engappai.2025.112291},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112291},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis of wind turbine based on dual-channel feature aggregation network with attentional mechanism},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new deep learning framework for intelligent aerial monitoring of power transmission line insulators. <em>EAAI</em>, <em>161</em>, 112290. (<a href='https://doi.org/10.1016/j.engappai.2025.112290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transmission line insulators are critical components for maintaining the integrity and efficiency of power transmission lines. Monitoring the health, performance, and efficiency of this network has always been of interest since the past. Traditional and field inspection methods are often tedious, costly, and prone to human error. In order to monitor the condition of transmission lines and overcome traditional challenges, this study proposes an intelligent monitoring framework using unmanned aerial vehicle (UAV) imaging and advanced deep learning models to identify and classify insulator defects. The dataset used in this study consists of 870 original images, 600 healthy images, 140 damaged images, and 130 images of flashover insulators collected from UAV flights and online sources. To increase the diversity of the training data, a data augmentation technique was used, increasing the number of images to 1952 samples and dividing the data into 80 % training sets and 20 % test sets. While the current evaluation is performed on this dataset, real-world experiments will be considered in future studies to further validate the model. In this approach, three scenarios were considered to evaluate and detect these errors. The first scenario used an independent convolutional neural network (CNN) for feature extraction and classification, achieving an accuracy of 82.54 %. The second scenario combined CNN with transfer learning (TL) techniques to improve feature representation, achieving an accuracy of 95.99 %. Scenario Three integrated a hybrid CNN model with a long short-term memory network, achieving an average accuracy of 99.67 % in fault detection and classification. The results demonstrate the superiority and robustness of the proposed hybrid model, providing a reliable and cost-effective solution for transmission line insulator monitoring. This study highlights the significant potential of combining UAV imagery with deep learning algorithms, reassuring the audience of the effectiveness of the proposed solution.},
  archive      = {J_EAAI},
  author       = {Reza Rahimi Nejadbougar and Ebadat Ghanbari Parmehr and Alireza Afary and Samira Mavaddati},
  doi          = {10.1016/j.engappai.2025.112290},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112290},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new deep learning framework for intelligent aerial monitoring of power transmission line insulators},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal generative network based on deep long short-term memory autoencoder for hand skeleton data sequences reconstruction and recognition. <em>EAAI</em>, <em>161</em>, 112289. (<a href='https://doi.org/10.1016/j.engappai.2025.112289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks attract the highest research focus in the developing field of Hand Gesture Recognition (HGR). Nevertheless, these approaches presented a challenging task in adapting to time-series data. In skeleton-based HGR, extracting spatial–temporal information remains a challenge. In recent times, recurrent neural networks have exhibited exceptional performance in detecting desired hand gestures by processing of varied length time-series data. Although they outperform traditional methods when huge training data is accessible, their effectiveness significantly diminishes when data availability is constrained. In this study, we introduce an unsupervised data augmentation network known as the Spatial-Temporal Generative Network (STGN), which reconstructs both the spatial and temporal information of the input sequences by leveraging a Deep Long Short-Term Memory Auto-Encoder (DLSTM-AE) network. Consequently, the DLSTM-AE combined with different Long Short-Term Memory (LSTM) network variations, forming an integrated network that can be trained end-to-end for HGR. Through experimentation conducted on the LeapGestureDB dataset (Leap Motion-based Gesture Dataset) and RIT dataset (Rochester Institute of Technology Hand Gesture Dataset), we prove that data reconstruction using STGN had a prominent effect on improving the accuracy of recognizing time-series based hand gestures. For all experiments, the best recognition results are achieved in the augmented dataset. Accuracies were improved on all tested LSTM networks from 2 to 10%. For reproducible research, the code is available at: https://github.com/AMEURsafa/STGN .},
  archive      = {J_EAAI},
  author       = {Safa Ameur and Mohamed Ali Mahjoub and Anouar Ben Khalifa},
  doi          = {10.1016/j.engappai.2025.112289},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112289},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spatial-temporal generative network based on deep long short-term memory autoencoder for hand skeleton data sequences reconstruction and recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural dynamic fluid reconstruction technique for four-dimensional imaging of combustion flame based on deep learning. <em>EAAI</em>, <em>161</em>, 112288. (<a href='https://doi.org/10.1016/j.engappai.2025.112288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional optical diagnostic techniques based on the principles of tomographic imaging enable the acquisition of rich three-dimensional information in experimental flow fields through reconstruction calculations. However, for tasks involving the reconstruction of three-dimensional flow fields at high temporal resolutions, existing methods incur high computational costs, low reconstruction efficiency, and struggle to achieve high spatiotemporal resolution measurements. This paper proposes the Neural Dynamic Fluid Reconstruction Technique (NDFRT) based on deep learning. NDFRT incorporates the time dimension into the reconstruction scope to achieve the four-dimensional reconstruction of dynamic flow fields using neural networks. NDFRT has the following technical advantages: (1) ultra-high spatiotemporal reconstruction resolution; (2) good computational efficiency, with the reconstruction parameter scale only half that of traditional voxel-based methods; (3) the ability to perform three-dimensional frame prediction of dynamic fluids. We validated the proposed method using numerical simulation and experimental jet flame reconstruction and compared it with the traditional algebraic reconstruction technique (ART). Experimental results demonstrate that NDFRT outperforms traditional ART methods in terms of computational efficiency, reconstruction resolution, and reconstruction accuracy.},
  archive      = {J_EAAI},
  author       = {Fuhao Zhang and Zhiyin Ma and Can Gao and Gang Xun and Qingchun Lei and Xuesong Li},
  doi          = {10.1016/j.engappai.2025.112288},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112288},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural dynamic fluid reconstruction technique for four-dimensional imaging of combustion flame based on deep learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BeltDiff: Diffusion-based self-labeled generation system for conveyor belt damage detection. <em>EAAI</em>, <em>161</em>, 112287. (<a href='https://doi.org/10.1016/j.engappai.2025.112287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The damages of conveyor belt are abnormal occurrence of industrial production line, generally resulting in serious economic losses. While utilizing deep-learning-based methods in belt damage detection task, models training is challenging due to the prevalent scarcity of both numbers and diversity in dataset, leading to the restricted performance and limited accuracy in practical applications. To address this issue, we propose a novel self-labeled generation system based on diffusion model, for creating effective and large-scale conveyor belt detection datasets. Specifically, the training of our system is divided into three stages for progressive task decomposition and interpretable user control. Among the generation process, we focus on the textual prompt alignment and shape guidance to generate more reasonable and high-quality damaged belt images. Meanwhile, larger scale datasets are created via our method on two scenes, including base scene with limited samples, and brand new scenes with no damaged samples, which compose 9636 and 7500 images respectively. By evaluating the quality of damaged images, and the relations between generated and real images, our method demonstrates its effectiveness on generating damaged belt image pairs with annotations. Further, for verifying the validity of our generative datasets, we implement numerous experiments of 4 types of popular detection models training on different settings. The results demonstrate that our datasets support effective accuracy improvement, comparing with the base datasets and the classic augmented datasets, specifically increased by up to 14.4% in the brand new scenes with no damaged samples.},
  archive      = {J_EAAI},
  author       = {Peixian Zhuang and Yuanxiu Cai and Xi Liu and Xianchao Zheng and Fuheng Xiao and Jiangyun Li},
  doi          = {10.1016/j.engappai.2025.112287},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112287},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {BeltDiff: Diffusion-based self-labeled generation system for conveyor belt damage detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust deep learning based model for denoising phonocardiogram signals in clinical environments. <em>EAAI</em>, <em>161</em>, 112286. (<a href='https://doi.org/10.1016/j.engappai.2025.112286'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A cardiac auscultation, being a very popular first line cardiovascular diseases screening method, typically produces phonocardiogram signals contaminated by background sounds, e.g., speech and movement of other patients and doctors/nurses, phone ringing and door knocking/opening/closing, and internal physiological body noises, e.g., lung sounds, muscle contraction and motion artifacts, as it is usually done in a noisy environment and it is not possible to suppress all the internal physiological body noises. So, a quality of the recording is finally decreased. Moreover, this can strongly affect a subsequent analysis/classification of the captured recording and can also lead to its incorrect classification. In this paper, we propose a novel deep convolutional architecture that integrates the bidirectional long short-term memory layers with the transformer blocks involving multi-head attention mechanism, which is particularly designed for denoising phonocardiogram signals. The performance of the proposed artificial intelligence-based approach is evaluated through synthetic data generated by using one public phonocardiogram dataset and two public real-world hospital ambient/respiratory sound databases as well as by deploying two public and renowned real-world clinical environment datasets containing phonocardiogram signals contaminated by various environmental and physiological noises recorded during the clinical auscultations. The deployed complex evaluation strategy assures a higher robustness and generalizability of the proposed approach. As also a result of that, the proposed model outperforms the current state-of-the-art approaches and provides the significant improvements in all the assessed signal quality and noise suppression metrics and over all the involved benchmark datasets. Finally, it should be noted here that the model achieved an average estimated SNR of 14.984 dB and 11.924 dB for the PASCAL and CirCor22 dataset respectively, which represent the renowned real-world clinical environment datasets.},
  archive      = {J_EAAI},
  author       = {Maros Jakubec and Eva Lieskovska and Peter Pocta},
  doi          = {10.1016/j.engappai.2025.112286},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112286},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust deep learning based model for denoising phonocardiogram signals in clinical environments},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based end-to-end point restoration network for filtering temporarily-static objects from point cloud. <em>EAAI</em>, <em>161</em>, 112284. (<a href='https://doi.org/10.1016/j.engappai.2025.112284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precision of map-based localization systems is pivotal for advanced navigation and autonomous vehicle technologies. This study addresses the challenge of dynamic environments where temporarily-static objects, such as vehicles, introduce occlusion and temporal alterations to the mapping landscape, leading to inaccuracies in mapping and localization. We propose a transformer-based deep learning model that removes temporarily-static objects and refines occluded areas in raw point cloud data, thereby enhancing both mapping and localization. Our method leverages a transformer-based point restoration network trained on a novel dataset that does not require human-driven manual annotation and predicts point clouds free of temporarily-static objects. The approach was validated through experiments demonstrating improved qualitative and quantitative results. The results display the importance of our method by removing temporarily-static objects and refining occluded areas. The proposed method achieves a 26.4 % reduction in Chamfer Distance L1 (CD-L1), 33.1 % reduction in Chamfer Distance L2 (CD-L2), and a 30.2 % relative improvement in the harmonic mean of precision and recall (F-Score) over the baseline network, demonstrating significantly enhanced model for filtering. This research contributes to artificial intelligence (AI)-enabled autonomous navigation by offering a systematic solution to a common problem in dynamic environments, setting a new filtering technology for mapping systems.},
  archive      = {J_EAAI},
  author       = {Sabir Hossain and Xianke Lin},
  doi          = {10.1016/j.engappai.2025.112284},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112284},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer-based end-to-end point restoration network for filtering temporarily-static objects from point cloud},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-view gait recognition based on discriminative global–local feature representation and learning. <em>EAAI</em>, <em>161</em>, 112282. (<a href='https://doi.org/10.1016/j.engappai.2025.112282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance of gait recognition can be heavily influenced by deformation of walking silhouettes due to variations of view angle. Cross-view gait recognition is still one of the most challenging problems in pattern recognition community. In this paper, we propose a new cross-view gait recognition algorithm by discriminative global–local feature representation and learning. First, we design cross-view convolutional neural network for learning global gait feature representations underlying binary walking silhouettes sequences. Second, we propose to extract local gait features by partial spatial–temporal sequence and local feature extractors, which can represent the motion characteristics and temporal changes of different human body parts. Both global and local features in our proposed method are extracted from different gait representations to provide spatial–temporal information from diverse aspects, and they are fused on feature level to further reduce the sensitivity to variations of view angle and improve the performance of gait recognition. Finally, we introduce deep metric learning framework and propose a robust, effective, and view-related loss function, named view triplet loss function, to learn discriminative gait features. Compared with triplet loss, the proposed loss function explores hierarchical relationship of the variations of view angles, which achieves better intra-subject compactness and inter-subject separability. Experimental results on CASIA-B, OULP and OUMVLP gait datasets demonstrate the feasibility and advantage of our proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Muqing Deng and Yi Zou and Zhi Zeng and Xiaoreng Feng and Yanjiao Wang and Yuan Liu},
  doi          = {10.1016/j.engappai.2025.112282},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112282},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cross-view gait recognition based on discriminative global–local feature representation and learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel clustering-ensemble learning model for day-ahead photovoltaic power forecasting. <em>EAAI</em>, <em>161</em>, 112281. (<a href='https://doi.org/10.1016/j.engappai.2025.112281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate day-ahead photovoltaic power forecasting (PPF) is essential for grid scheduling and transaction planning. However, time series prediction models based on historical meteorological and photovoltaic power data often struggle to capture long-term dependencies. Existing research typically employs multivariate regression models to establish mapping relationships between numerical weather prediction (NWP) and photovoltaic power data, yet still exhibits deficiencies in weather pattern recognition and consideration of temporal patterns. Therefore, this paper proposes a novel clustering-ensemble learning model to enhance predictive performance. In the proposed deep time-series clustering algorithm, key features from NWP data are extracted for clustering, addressing the inefficiencies of traditional clustering methods in handling high-dimensional data. A weighted Warp-Euclidean distance is proposed to capture sequence trend homogeneity and spatial similarity, overcoming the limitations of Euclidean distance in time-series data. The ensemble learning model combines the advantages of two gradient boosting tree models to handle nonlinear features and high-dimensional data, while introducing lag features to enhance temporal dynamic learning capability. This approach enhances the stability and mitigates the limitations associated with relying primarily on weather-related features. This study utilizes NWP and measured photovoltaic data from two stations in Hebei Province, China. Results demonstrate superior performance compared to other clustering algorithms and prediction models in day-ahead PPF tasks, achieving R 2 scores of 0.952 and 0.943 on two public photovoltaic datasets, representing improvements of 0.020 and 0.017 over optimal benchmark models. The proposed framework provides theoretical guidance for the stable operation of grid-connected photovoltaic systems.},
  archive      = {J_EAAI},
  author       = {Feifei Yang and Xueqian Fu and Zhengshuo Li and Dawei Qiu and Hamed Badihi},
  doi          = {10.1016/j.engappai.2025.112281},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112281},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel clustering-ensemble learning model for day-ahead photovoltaic power forecasting},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence-based phonocardiogram signal classification using segment-specific multi-domain features for cardiovascular and arterial disease. <em>EAAI</em>, <em>161</em>, 112280. (<a href='https://doi.org/10.1016/j.engappai.2025.112280'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart diseases are the leading cause of death globally, and early diagnosis coupled with timely treatment can save lives. The human heart produces sounds that reflect the functions of its valves and chambers, with murmurs often indicating abnormal heart behavior. The phonocardiogram (PCG) analysis offers a quick, easy, and affordable diagnostic method for detecting such conditions. The PhysioNet/2016 dataset, containing annotated heart sound recordings, has advanced automated heart sound classification research. Despite the dataset encompassing nine classes of heart diseases, it has primarily been used for binary classification tasks. Multi-class classification is challenging due to overlapping acoustic features among certain heart conditions and signal variability. To address these issues, we implemented segment specific feature extraction across six domains — time, frequency, amplitude, wavelet, spectrum, signal processing — and evaluated various machine learning classifiers. Our findings revealed that the Random Forest classifier outperformed others, leading us to integrate it into our model. On the testing dataset, it attained 94% accuracy, 93% sensitivity and 93% specificity for binary classification Our model achieved 89% accuracy, 80% sensitivity and 98% specificity for nine-class classification including both valve diseases and artery-related conditions.},
  archive      = {J_EAAI},
  author       = {Syeda Sana Bukhari and Shahab U. Ansari and Khurram Khan Jadoon and Raja Hashim Ali},
  doi          = {10.1016/j.engappai.2025.112280},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112280},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial intelligence-based phonocardiogram signal classification using segment-specific multi-domain features for cardiovascular and arterial disease},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic forecasting of non-ferrous metal prices based on outlier treatment algorithms, quantile regression based deep learning and two-phase multi-objective optimization. <em>EAAI</em>, <em>161</em>, 112277. (<a href='https://doi.org/10.1016/j.engappai.2025.112277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of non-ferrous metal prices plays a crucial role in helping enterprises optimize production, control costs, and manage risks, as well as in enabling countries and industries to formulate resource strategies, ensure economic security, and promote sustainable development. However, existing research still has limitations in outlier detection, uncertainty analysis, and model optimization, making it difficult to meet the forecasting needs in complex market environments. To fill these gaps, this study proposes a novel combined probabilistic forecasting framework for non-ferrous metal prices. First, this study utilizes outlier treatment algorithms to achieve robust outlier detection and correction. Second, multiple quantile regression-based deep learning models are established for probabilistic forecasting. Subsequently, a two-phase multi-objective optimization strategy is proposed. Specifically, the first phase is designed to optimize the upper quantile half-interval and lower quantile half-interval of each quantile regression-based deep learning model, while the second phase is used to optimize the combined weights of the aforementioned single model to synergistically enhance interval reliability and prediction accuracy. Finally, silver and aluminum futures prices are used as illustrative case studies. The experimental results show that the proposed model outperforms the benchmark method in terms of interval coverage and prediction accuracy. This study provides a scientific basis and reference for industrial production optimization, investment decision-making and resource management planning.},
  archive      = {J_EAAI},
  author       = {Pei Du and Fangrui Gui and Lijie Shan and Qianyi Xing and Jianzhou Wang},
  doi          = {10.1016/j.engappai.2025.112277},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112277},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probabilistic forecasting of non-ferrous metal prices based on outlier treatment algorithms, quantile regression based deep learning and two-phase multi-objective optimization},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying nonlinear roll damping and restoring parameters via physics-informed neural network. <em>EAAI</em>, <em>161</em>, 112275. (<a href='https://doi.org/10.1016/j.engappai.2025.112275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To effectively characterize a ship’s roll motion, developing a robust dynamic model that incorporates accurate damping and restoring parameters is essential. Given that only limited free-decay measurements have been measured, an efficient physics-informed neural network-based approach has been developed to simultaneously determine the nonlinear damping and restoring parameters associated with ship rolling. Rather than relying on a large dataset to train a neural network for parameter identification, the proposed method incorporates the physical equations of roll motion into the residual networks, ensuring that the identified parameters adhere to their physical interpretation. Three numerical cases, encompassing computational fluid dynamics (CFD) analyses, and laboratory experiments, are presented to show the superior performance of the developed method. Key findings indicate that the proposed method effectively identifies the investigated parameters with high precision while maintaining consistent performance across various initial roll angle conditions. Compared to traditional methods, the proposed approach offers significant advantages, including reduced reliance on large datasets, automated parameter identification without manual tuning, and the ability to incorporate physical constraints directly into the learning process. These features make the method particularly suitable for real-world applications where data is sparse or costly to obtain.},
  archive      = {J_EAAI},
  author       = {Shuai Cong and Jinwei Sun and Qianying Cao and Changhong Zhi and Shixuan Liu},
  doi          = {10.1016/j.engappai.2025.112275},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112275},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identifying nonlinear roll damping and restoring parameters via physics-informed neural network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection in offshore open radio access network using long short-term memory models on a novel artificial intelligence-driven cloud-native data platform. <em>EAAI</em>, <em>161</em>, 112274. (<a href='https://doi.org/10.1016/j.engappai.2025.112274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Radio Access Network (RAN) is a critical component of modern telecommunications infrastructure, currently evolving towards disaggregated and open architectures. These advancements are pivotal for integrating intelligent, data-driven applications aimed at enhancing network reliability and operational autonomy through the introduction of cognitive capabilities, as exemplified by the emerging Open Radio Access Network (O-RAN) standards. Despite its potential, the nascent nature of O-RAN technology presents challenges, primarily due to the absence of mature operational standards. This complicates the management of data and intelligent applications, particularly when integrating with traditional network management and operational support systems. Divergent vendor-specific design approaches further hinder migration and limit solution reusability. These challenges are compounded by a skills gap in telecommunications business-oriented engineering, which remains a key barrier to effective O-RAN deployment and intelligent application development. To address these challenges, Boldyn Networks developed a novel cloud-native data analytics platform, specifically designed to support scalable Artificial Intelligence (AI) integration within O-RAN deployments. This platform underwent rigorous testing in real-world scenarios, and applied advanced AI techniques to improve operational efficiency and customer experience. Implementation involved adopting Development Operations (DevOps) practices, leveraging data lakehouse architectures tailored for AI applications, and employing sophisticated data engineering strategies. The platform successfully addresses connectivity challenges inherent in real-world offshore wind farm deployments using Long Short-Term Memory (LSTM) models for anomaly detection in network connectivity. After integrating the LSTM models into the network control, more than 90 percent of connectivity issues were reduced in runtime. This marks a step toward autonomous, self-organizing, and self-healing networks.},
  archive      = {J_EAAI},
  author       = {Abdelrahim Ahmad and Peizheng Li and Robert Piechocki and Rui Inacio},
  doi          = {10.1016/j.engappai.2025.112274},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112274},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Anomaly detection in offshore open radio access network using long short-term memory models on a novel artificial intelligence-driven cloud-native data platform},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural design through reinforcement learning. <em>EAAI</em>, <em>161</em>, 112273. (<a href='https://doi.org/10.1016/j.engappai.2025.112273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Structural Optimization gym (SOgym), a novel open-source Reinforcement Learning (RL) environment designed to advance machine learning in Topology Optimization (TO). SOgym enables RL agents to generate physically viable and structurally robust designs by integrating the physics of TO into the reward function. To enhance scalability, SOgym leverages feature-mapping methods as a mesh-independent interface between the environment and the agent, allowing efficient interaction with the design variables regardless of mesh resolution. Baseline results use a model-free Proximal Policy Optimization agent and a model-based DreamerV3 agent. Three observation space configurations were tested. The Topology Optimization game ( TopOpt game) inspired configuration, an interactive educational tool for designing structures to minimize compliance under volume constraints, performed best in terms of performance and sample efficiency. The 100 million parameter DreamerV3 model (DreamerV3-100M) produced structures with compliance values approximately 54 % higher than those from traditional optimization methods and a 0 % disconnection rate, an improvement over supervised learning approaches that often struggle with disconnected load paths. When comparing the learning rates of the agents to those of engineering students from the TopOpt game experiment, the DreamerV3-100M model shows a learning rate approximately four orders of magnitude lower, an impressive feat for a policy trained from scratch through trial and error. These results suggest RL's potential to solve continuous TO problems and its capacity to explore and learn from diverse design solutions. SOgym provides a platform for developing RL agents for structural design challenges and is publicly available to support research in the field.},
  archive      = {J_EAAI},
  author       = {Thomas Rochefort-Beaudoin and Aurelian Vadean and Niels Aage and Sofiane Achiche},
  doi          = {10.1016/j.engappai.2025.112273},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112273},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Structural design through reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-channel selection for epileptic seizure identification through a custom machine learning model. <em>EAAI</em>, <em>161</em>, 112272. (<a href='https://doi.org/10.1016/j.engappai.2025.112272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy affects millions of people worldwide, triggering undesirable motor and sensory events that drastically impair the quality of life of those affected. Detecting this condition through a monitoring system can be extremely useful in identifying epileptic seizures without relying exclusively on a specialist. Our goal is to identify these seizures using personalized supervised machine learning models – eXtreme Gradient Boosting – for each patient, employing only one electroencephalogram input channel. Our methodology explores the relationship between the selected input channel and the topographic location of epileptic seizures modeled for the patient. The results revealed notable accuracy performances for the three patients investigated: 100%, 99%, and 88%, after applying the proposed time filter that checks for the presence/absence of a seizure every 3 s. Furthermore, it was possible to observe that the results are consistent with the affected area in each patient, demonstrating the effectiveness of the method in selecting the single channel. This approach demonstrates the feasibility of detecting convulsive seizures using only one input channel and underscores the need to extend the methodology to more patients.},
  archive      = {J_EAAI},
  author       = {Jusciaane Chacon Vieira and Ignacio Sanchez-Gendriz and Luiz Affonso Guedes},
  doi          = {10.1016/j.engappai.2025.112272},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112272},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Single-channel selection for epileptic seizure identification through a custom machine learning model},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IMobileTransformer: A fusion-based lightweight model for rice disease identification. <em>EAAI</em>, <em>161</em>, 112271. (<a href='https://doi.org/10.1016/j.engappai.2025.112271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rice blast, sheath blight, leaf scald, bacterial leaf blight, and brown spot severely threaten rice yield. To address the limitations of current deep learning methods in rice disease recognition, particularly their insufficient integration of local and global features, this study proposes an Improved MobileTransformer (IMobileTransformer) model. The proposed architecture synergistically combines MobileNet’s strengths in local feature extraction and lightweight architecture with Transformer’s superior capability in global information processing. Specifically, the model is designed with three functional branches: a) a MobileNet branch utilizing inverted residual structure with depthwise separable convolution layers to reduce parameters and computational complexity, b) a Transformer branch modified from Swin-Transformer architecture, where the Multilayer Perceptron (MLP) layer is enhanced by splitting input feature channels through an Inception-based structure to maintain global feature extraction efficiency while minimizing computational overhead, and c) a feature fusion branch that concatenates reshaped outputs from both branches through channel-wise stacking, enabling effective integration of local and global representations. Experimental results show that compared to classical models such as MobileNetV3-Large, EfficientNet-B0, Vision Transformer Base/16 (ViT-B/16), Shifted Window Transformer (Swin-Transformer), Tiny Vision Transformer (TinyViT), Mobile Vision Transformer (MobileViT), LocalViT-S, IMobileTransformer achieves a recognition accuracy of 99.62% for rice diseases, with improvements of 1.71%, 0.91%, 38.09%, 4.17%, 1.99%, 1.5% and 0.42%, respectively, providing an effective solution for rice disease recognition.},
  archive      = {J_EAAI},
  author       = {Yang Lu and Haoyang Zhou and Peng Wang and Erzhi Wang and Gongfa Li and Tongjian Yu},
  doi          = {10.1016/j.engappai.2025.112271},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112271},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IMobileTransformer: A fusion-based lightweight model for rice disease identification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized and safe medication recommendation based on convolutional neural network and transformer architecture. <em>EAAI</em>, <em>161</em>, 112267. (<a href='https://doi.org/10.1016/j.engappai.2025.112267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the accumulation of electronic health records (EHRs), artificial intelligence (AI) based medical services such as medication recommendation (MR) has aroused widespread concern. However, existing drug recommendation models suffer from inadequate patient representation and adverse drug–drug interactions (DDIs). To address these challenges, we propose an AI-based personalized and safe medication recommendation method based on convolutional neural network and transformer architecture (CT-PASMR). Specifically, convolutional neural network (CNN) and transformer are combined in parallel (CAT) to model local relationships in a patient’s single visit and long-term dependencies in sequential EHR data, respectively. Subsequently, graph attention networks (GATs) are deployed to capture drug co-occurrences and adverse DDIs with various weights, generating safe drug representations. Moreover, a joint loss function is introduced to balance accuracy and safety in CT-PASMR. Finally, the experimental results on MIMIC (Medical Information Mart for Intensive Care)-III and MIMIC-IV datasets demonstrate that CT-PASMR achieves competitive performance on seven evaluation metrics such as DDI rate, Jaccard index and F1 score, compared with nine state-of-the-art (SOTA) baseline models. Ultimately, ablation studies and further analysis confirm the efficacy of CATs and GATs in providing personalized and safe medication recommendations. Code, qualitative results, and trained weights will be available at the link: https://github.com/gefengru/CT-PASMR .},
  archive      = {J_EAAI},
  author       = {Fengru Ge and Xiaomei Yu and Xue Li and Xingxu Fan and Yanjie Zhao},
  doi          = {10.1016/j.engappai.2025.112267},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112267},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Personalized and safe medication recommendation based on convolutional neural network and transformer architecture},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning with similarity enhancement for dimensionality reduction. <em>EAAI</em>, <em>161</em>, 112266. (<a href='https://doi.org/10.1016/j.engappai.2025.112266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensionality reduction aims to reduce the number of dimensions while preserving crucial information. As a self-supervised learning approach, contrastive learning provides a novel perspective for dimensionality reduction. However, most contrastive learning methods focus on optimizing similarity, which have limitations in reducing feature redundancy. Moreover, the dependence on negative pairs introduces computational overhead. To address these problems, we propose Contrastive Learning with Similarity Enhancement for Dimensionality Reduction (CLSDR), which integrates neighborhood embedding into the contrastive learning framework. Specifically, CLSDR uses k -nearest neighbors sampling to construct positive pairs. We design a multi-level loss function that captures the diversity of data while maintaining the consistency of local and global features. In addition, we propose a nonlinear similarity optimization mechanism based on logarithmic smoothing, which adjusts the gradient of similarity loss, improving the stability during the training process. Experimental results demonstrate that CLSDR significantly outperforms several state-of-the-art methods. Especially, on the Street View House Numbers dataset, CLSDR achieves 66.7% and 62.3% Top-1 accuracy with two classifiers in 64-dimensional embedding space, which have 10.6% and 38.4% improvement over the best competing approach. Thus, CLSDR exhibits strong robustness and scalability across different dimensions.},
  archive      = {J_EAAI},
  author       = {Qi Yang and Changpeng Wang and Linlin Feng and Lizhen Ji and Jiangshe Zhang},
  doi          = {10.1016/j.engappai.2025.112266},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112266},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contrastive learning with similarity enhancement for dimensionality reduction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-modal approach for detecting drivers’ distraction using bio-signal and vision sensor fusion in driver monitoring systems. <em>EAAI</em>, <em>161</em>, 112265. (<a href='https://doi.org/10.1016/j.engappai.2025.112265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to a report by the World Health Organization (WHO), approximately 1.3 million people lose their lives annually owing to traffic accidents. The majority of road traffic accidents stem from driver negligence. Recently, there has been a growing interest in utilizing deep learning and machine learning technologies to enhance the safety and efficiency of road traffic, with the aim of addressing issues arising from driver inattentiveness. Most studies focus on detecting abnormal driver behavior using driving sensors or driver images; however, they often overlook physiological factors such as the driver's bio-signals. Considering that the driver's state, including fatigue, stress, and concentration, can significantly affect driving safety, it is crucial to build models that consider biometric information. Therefore, this study proposes a multi-modal transformer model called Bio-Vision Transformer (BiViT) that comprehensively considers both driver bio-signals and images. The BiViT model uses a vision transformer to extract features from driver images and employs a time-series transformer to capture features from the driver's bio-signals. In addition, the interactions between the extracted features are modeled, and the joint fusion method is employed as the feature-fusion approach. To validate the proposed model, performance comparisons and analyses were conducted using commonly used models in image analysis. The experimental results demonstrated that the proposed BiViT model exhibited high performance, with an accuracy of 0.91 and a harmonic mean of precision and recall (F1-score) of 0.91, surpassing the performance of the comparison models.},
  archive      = {J_EAAI},
  author       = {Byeongjoon Noh and Myeongseok Park and Yechan Han and Jaeyun Kim},
  doi          = {10.1016/j.engappai.2025.112265},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112265},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-modal approach for detecting drivers’ distraction using bio-signal and vision sensor fusion in driver monitoring systems},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural network with generative adversarial training for node classification on class imbalanced data. <em>EAAI</em>, <em>161</em>, 112264. (<a href='https://doi.org/10.1016/j.engappai.2025.112264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Node classification in class-imbalanced graph data remains a critical challenge, as traditional graph neural networks (GNNs) either assume class-balanced graph structures or inadequately address class imbalance. This often results in predictive bias, where majority classes are favored while minority classes are underrepresented. To overcome this limitation, this study introduces a novel graph neural network with generative adversarial training (GNN-GAN), where the GNN extracts latent features from input node attributes balanced through data synthesis using a conditional generative adversarial network (GAN) and data fusion strategy. The GNN and GAN are trained synchronously to ensure GAN synthesizes samples that match real data distribution, while GNN adjusts to the quality of synthesized data in a timely manner. A data fusion strategy combines synthetic and real samples to mitigate class imbalance and maintain classification accuracy. Experiments on several benchmark graph datasets demonstrate that the GNN-GAN consistently outperforms state-of-the-art baselines. A comprehensive ablative study further validates the advantages of the synchronized training procedure, offering insights into the model's robustness across graph datasets with varying structures and imbalance ratios.},
  archive      = {J_EAAI},
  author       = {Xiaoqi Zhou and Peixin Shi},
  doi          = {10.1016/j.engappai.2025.112264},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112264},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph neural network with generative adversarial training for node classification on class imbalanced data},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-based feature absorption approach for improving lightweight object detectors in adverse weather conditions. <em>EAAI</em>, <em>161</em>, 112263. (<a href='https://doi.org/10.1016/j.engappai.2025.112263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although cutting-edge lightweight detectors have achieved desirable performance in favorable weather conditions, they again failed to accurately identify objects within low-quality scenes captured in inclement environments, especially during rainy nighttime. These detectors face difficulties learning beneficial information for detection because objects are obscured by rain and low-light conditions. To address the aforementioned challenges, we introduce an innovative and effective Diffusion-based Feature Absorption Learning (Diff-FAL) approach, to reinforce the performance of lightweight detection models in nighttime with rain interference. By developing an unsupervised training strategy based on the diffusion model, the proposed approach assists lightweight detectors absorb useful features from degraded images. To this end, our Diff-FAL framework comprises three distinct subnetworks: a Feature Optimization (FO) subnetwork, a Feature Mutation (FM) subnetwork, and a Lightweight Detection (LD) subnetwork. The FO subnetwork is designed to produce sharp, detailed features from rainy night images and the FM subnetwork is developed to transfer those features to the LD subnetwork. Comprehensive experiments on various datasets confirmed the superiority of our model, outperforming the compared method by up to 28.01% and 30.16% in accuracy on two published datasets: the rainy nighttime (RNT) and real rainy images (rRain) datasets, respectively, while maintaining high-speed performance during inference.},
  archive      = {J_EAAI},
  author       = {Quoc-Viet Hoang and Trung-Hieu Le},
  doi          = {10.1016/j.engappai.2025.112263},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112263},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Diffusion-based feature absorption approach for improving lightweight object detectors in adverse weather conditions},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-modal model for removal of crack image shadow based on language prior information. <em>EAAI</em>, <em>161</em>, 112262. (<a href='https://doi.org/10.1016/j.engappai.2025.112262'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-vision based crack detection highly depends on the quality of images and it remains to be a challenging task due to the effects of shadow. The utilization of deep learning algorithm, guided by prior information, has been demonstrated effective in the removal of shadows. However, it has limitations in handling images with shadowed cracks. A deep learning method incorporating language prior information and a multi-modal model is proposed in this study to improve the removal of shadow effects in restoring the crack images. Natural language processing (NLP) is used to extract the language prior information from image text description to enhance the crack recognition, and OTSU method is used to obtain the image prior information. A novel multi-modal model, named as the Text-based Shadow Removal Network (TSRNet), for the removal of shadow in crack image, is proposed to have better crack restoration capability. Bayesian optimization approach is also employed to optimize the network architecture improving the prediction precision of TSRNet. The proposed framework for shadow removal is verified using an open-source shadowed concrete crack image dataset and a new dataset from experiment. Results indicate that the language prior information can enhance the TSRNet model with better performances of shadow removal for real-world crack images compared with other existing models.},
  archive      = {J_EAAI},
  author       = {Gang Liu and Xuming Li and Qingshan Yang and S.S. Law and Changjun Deng},
  doi          = {10.1016/j.engappai.2025.112262},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112262},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-modal model for removal of crack image shadow based on language prior information},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development and implementation of a hybrid visual prediction algorithm for robotic smart tomato harvesting. <em>EAAI</em>, <em>161</em>, 112261. (<a href='https://doi.org/10.1016/j.engappai.2025.112261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces new algorithms designed specifically for smart tomato harvesting, which combines predictions from two independently trained YOLOv8 (You Only Look Once version 8) models, each specialized on different datasets to detect tomatoes and classify their ripeness stages—ripe, unripe, and semi-ripe—while also computing their center points. To enhance detection accuracy under varying field conditions, multiple fusion strategies were developed, including a hybrid algorithm that integrates union and confidence-weighted summation methods. The Hybrid Algorithm achieved the best performance, surpassing the original models and other fusion techniques. It attained F1 scores of 0.697 and 0.694 at confidence thresholds of 0.5 and 0.9, respectively, compared to the original models' F1 scores of 0.670 and 0.648 at confidence 0.5, and 0.481 and 0.497 at confidence 0.9. This corresponds to an improvement of 4.0 % and 7.6 % at confidence 0.5, and 44.3 % and 39.6 % at confidence 0.9, demonstrating the hybrid algorithm's stability and superiority, particularly at higher thresholds. Furthermore, the system utilizes a high-resolution RGB (Red, Green, Blue) camera for real-time image capture, enhancing model performance in complex agricultural environments. This study validates the effectiveness of confidence-based fusion in developing robust and accurate vision systems for precision agriculture.},
  archive      = {J_EAAI},
  author       = {Giuseppe Carbone and Angad Singh Gurtatta and Dmitry Malyshev},
  doi          = {10.1016/j.engappai.2025.112261},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112261},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development and implementation of a hybrid visual prediction algorithm for robotic smart tomato harvesting},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal multi-level feature representation learning for flow pattern identification of oil-water two-phase flow. <em>EAAI</em>, <em>161</em>, 112260. (<a href='https://doi.org/10.1016/j.engappai.2025.112260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the difficulty of the traditional experimental methods in real-time monitoring and identification of the flow process, this paper introduces a novel flow pattern identification method of the vertical oil-water two-phase flow based on multi-modal multi-level feature representation. The one-dimensional electromagnetic signals are encoded into two-dimensional feature spaces to explore their structural complexity, evolutionary probability laws and nonlinear characteristics in multimodal domain, thereby generating a multi-modal representation of the electromagnetic signals. Subsequently, a multi-modal multi-level feature fusion network is developed for flow pattern identification network, which flexibly leverages effective information across different modalities and levels, thereby enhancing the identifying accuracy. Experimental results demonstrate that the proposed method achieves high accuracy on the constructed multi-modal dataset, proving its feasibility and effectiveness in identifying the flow pattern of the oil-water two-phase flow in vertical pipes.},
  archive      = {J_EAAI},
  author       = {Weihang Kong and Yaohan Chi and He Liu and Hongbao Tang and He Li},
  doi          = {10.1016/j.engappai.2025.112260},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112260},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-modal multi-level feature representation learning for flow pattern identification of oil-water two-phase flow},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Defining and evaluating decision and composite risk in language models applied to natural language inference. <em>EAAI</em>, <em>161</em>, 112253. (<a href='https://doi.org/10.1016/j.engappai.2025.112253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite their impressive performance, large language models (LLMs) are known to pose important risks. One such set of risks arises from misplaced confidence, whether over-confidence or under-confidence, that the models have in their inference. While the former is well studied, the latter is not, leading to an asymmetry in understanding the comprehensive risk of the model based on misplaced confidence. In this paper, we address this asymmetry by defining two types of risk (decision and composite risk), and proposing an experimental framework consisting of a two-level inference architecture and appropriate metrics for measuring such risks in both discriminative and generative LLMs. The first level relies on a decision rule that determines whether the underlying language model should abstain from inference. The second level (which applies if the model does not abstain) is the model’s inference. This framework has direct implications for error-sensitive LLM-based engineering applications where reliable decision-making is critical, such as healthcare and finance. Through detailed experiments on four natural language commonsense reasoning datasets using both an open-source ensemble-based transformer model and a generative LLM, we demonstrate the practical utility of our evaluation framework. Our results show that the framework can get an LLM to confidently respond to an extra 20.1% of low-risk inference tasks that other methods might misclassify as high-risk, and skip 19.8% of high-risk tasks, which would have been answered incorrectly.},
  archive      = {J_EAAI},
  author       = {Ke Shen and Mayank Kejriwal},
  doi          = {10.1016/j.engappai.2025.112253},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112253},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Defining and evaluating decision and composite risk in language models applied to natural language inference},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced machine learning techniques for predicting wear performance in graphene oxide particulate interpenetrating polymer network composites. <em>EAAI</em>, <em>161</em>, 112252. (<a href='https://doi.org/10.1016/j.engappai.2025.112252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research investigates the wear behavior of hybrid polymeric composites made from synthetic glass and natural cotton fibers, reinforced with varying proportions of Graphene Oxide (GO) (0 %, 1 %, 3 %, 5 %, 7 %, 9 %). The effect of fiber arrangement and Graphene Oxide (GO) incorporation on wear rate and Coefficient of Friction (CoF) was evaluated using the Pin-On-Disk method, with analysis based on Taguchi's L 32 Orthogonal Array. The optimal parameters were found at 6 min, 5 % GO, 300 revolutions per minute (rpm) speed, 20 mm (mm) track diameter, and 10 N (N) load, achieving a minimum wear rate of 0.612 × 10 −4 cubic millimeters per newton-meter (mm 3 /N-m) and a CoF of 0.151. Predictive modeling was performed to predict the wear rate and coefficient of friction using supervised machine learning algorithms, including Linear Regression, Decision Tree, and Random Forest, to forecast material behavior. Performance evaluation using Confusion Matrix, Distribution Analysis, and various metrics showed that the Decision Tree model excelled, achieving near-perfect predictive power with a Mean Squared Error (MSE) of 0 and an R-squared value of 0.9999. The model demonstrated 100 % accuracy, with precision, recall, and F1-scores all equal to 1. This research demonstrates the effectiveness of combining natural and synthetic fibers with GO, along with the predictive power of machine learning in optimizing material properties.},
  archive      = {J_EAAI},
  author       = {Eastus Russel and S. Madhu and Judy S and Edwin Geo Varuvel and G.B. Santhi and G. Suresh and Femilda Josephin J.S and Mohammed F. Albeshr and Farzad Kiani},
  doi          = {10.1016/j.engappai.2025.112252},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112252},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Advanced machine learning techniques for predicting wear performance in graphene oxide particulate interpenetrating polymer network composites},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Health state evaluation and analysis of equipment considering multi-scale data fusion. <em>EAAI</em>, <em>161</em>, 112251. (<a href='https://doi.org/10.1016/j.engappai.2025.112251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current researches of health state evaluation of equipment have increasingly emphasized the integration of data and knowledge to improve evaluation accuracy and interpretability, which leads to the emergence of hybrid information-based methods as a research hotspot. However, there are issues with redundant health indicators, multi-scale data with different features and measurement units, and interpretability measures in the evaluation. In this paper, an interpretable health state evaluation and analysis method of equipment is proposed based on trustworthy evidential reasoning rule (TERR). To deal with redundancy in health indicators, a multi-scale data analysis model is proposed based on the clustering analysis and Kruskal-Wallis test. It can select the optimal health indicators that effectively preserve the original evaluation information while reducing the model complexity. To integrate the selected indicators with uncertainty, a TERR-based multi-scale data fusion model is proposed, where the evidence weight, reliability, and trustworthiness are simultaneously considered. Also, an interpretable parameter optimization model is constructed to alleviate the uncertainty in initial evidential parameters. To study the interpretability of TERR, two sensitivity analysis methods are proposed, and the performance coefficient matrix of the model output to the perturbation is derived mathematically. This shows how the interpretability of TERR is enhanced and which external parameter has the greatest impact on outputs. Finally, a case study of health state evaluation of laser inertial measurement unit (LIMU) validates the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Shuai-Wen Tang and Jiang Jiang and Jian-Bin Sun and Zhuo-Ting Yu},
  doi          = {10.1016/j.engappai.2025.112251},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112251},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Health state evaluation and analysis of equipment considering multi-scale data fusion},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unmanned surface vehicle autonomous racing and obstacle avoidance with robust adversarial deep reinforcement learning. <em>EAAI</em>, <em>161</em>, 112250. (<a href='https://doi.org/10.1016/j.engappai.2025.112250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an autonomous racing control method for Unmanned Surface Vehicles (USVs) based on robust adversarial deep reinforcement learning (ADRL) algorithm, which leverages the strengths of both deep reinforcement learning and adversarial training. Adversarial obstacles and various tracks are employed to train a policy, so the proposed method can enhance the robustness and generalization of autonomous USV racing while ensuring effective obstacle avoidance. A simulation environment for USV racing was developed to conduct the experiments with Unity3D. The performance of the proposed method in handling diverse track scenarios and obstacle avoidance is demonstrated through simulations. Quantitative results show that ADRL achieves dramatic improvements over baseline DRL methods: collision rates are reduced by 99.85%, task completion rates are improved by 73.75%, and navigation time efficiency is enhanced by approximately 3% while maintaining superior safety performance.},
  archive      = {J_EAAI},
  author       = {Jingyu Liu and Yuanda Wang and Changyin Sun},
  doi          = {10.1016/j.engappai.2025.112250},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112250},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unmanned surface vehicle autonomous racing and obstacle avoidance with robust adversarial deep reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale constitutive modeling of anisotropic plasticity: Coupling the visco-plastic self-consistent model with the recurrent neural network and its implementation in finite element analysis. <em>EAAI</em>, <em>161</em>, 112249. (<a href='https://doi.org/10.1016/j.engappai.2025.112249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anisotropic and nonlinear strain-path-dependent nature of metal plasticity poses a major challenge for accurate constitutive modeling in finite element (FE) analysis. Traditional macroscale models are easily implemented but lack accuracy, while crystal plasticity (CP) models offer high fidelity at the cost of computational efficiency. To bridge this gap, we propose a deep neural network smart constitutive (DNNSC) framework that combines the visco-plastic self-consistent (VPSC) model with a gated recurrent unit (GRU) network. A VPSC model calibrated on pure aluminum generated 14,000 strain-paths for training GRU-based network. The optimized model has a prediction accuracy of up to 96 % on unknown strain-paths. Subsequently, the DNNSC model was implemented into the FE analysis through Fortran programming, and a benchmark simulation for thin sheet stamping was successfully performed. The simulation results demonstrated that the DNNSC model significantly improved prediction performance compared to conventional macroscale constitutive models. Especially, the ear height and plate thickness were accurately predicted with an accuracy of 91.85 % and 95.84 %, compared to only 68.85 % and 86.59 % achieved by the Yld model. Meanwhile, the simulation time was reduced to approximately one-tenth that of the fully coupled CP model, because the latter required calculating and homogenizing the mechanical responses of hundreds of grains at each integration point during the simulation. The DNNSC framework bridges the gap between CP models and FE simulations of plastic forming and breaks down the barrier between modeling and practical application. Furthermore, this framework can be extended to other materials by re-calibrating VPSC parameters and fine-tuning DNN parameters.},
  archive      = {J_EAAI},
  author       = {Ziwei Zhou and Liang Cheng and Huaidong Song and Haijing Guo and Ruolin Li and Lingyan Sun and Bin Tang},
  doi          = {10.1016/j.engappai.2025.112249},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112249},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiscale constitutive modeling of anisotropic plasticity: Coupling the visco-plastic self-consistent model with the recurrent neural network and its implementation in finite element analysis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An online reinforcement learning method to improve control adaptability in robot-aided rehabilitation. <em>EAAI</em>, <em>161</em>, 112248. (<a href='https://doi.org/10.1016/j.engappai.2025.112248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rehabilitation robotics enables consistent and personalized therapy but still relies on complex, expert-driven tuning of control parameters. To address this, a reinforcement learning strategy based on Q-learning is proposed to autonomously adapt key parameters during upper-limb rehabilitation, without requiring prior task-specific knowledge. A systematic evaluation is conducted across combinations of control parameters (radial stiffness and execution time), performance-based reward functions (pointing accuracy and movement smoothness), and exploration strategies ( ɛ - greedy and Upper Confidence Bound). The Q-learning agent selects discrete actions (increase, decrease, or maintain the current value) for each control parameter, enabling real-time adaptation based on observed performance. The method is validated using a Kuka robotic arm in experiments involving 16 right-handed healthy subjects (13 males, 3 females) and 8 right-handed individuals simulating impaired motor behavior (5 males, 3 females). Motion signals are acquired through internal robot sensors, while a wearable physiological monitoring system define the Q-learning agent state. Reward improvement and exploration ratio are analyzed as key performance indicators and statistically compared across all tested conditions using the Mann–Whitney test. The results demonstrate that the proposed algorithm effectively adjusts control parameters online, with performance influenced by the reward function, exploration strategy, and selected control actions. Reward improvements of 0 . 11 ± 0 . 09 ( ɛ - greedy , reward based on pointing ability) and 0 . 13 ± 0 . 11 (reward based on smoothness, Upper Confidence Bound strategy) were observed in healthy subjects, indicating enhancements in pointing accuracy and movement smoothness. In simulated pathological cases, improvements of 0 . 08 ± 0 . 13 and 0 . 06 ± 0 . 16 were observed, respectively.},
  archive      = {J_EAAI},
  author       = {Rita Molle and Christian Tamantini and Clemente Lauretti and Emilio Maria Romano and Loredana Zollo},
  doi          = {10.1016/j.engappai.2025.112248},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112248},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An online reinforcement learning method to improve control adaptability in robot-aided rehabilitation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast prediction and compensation of curing deformation behaviours of composite parts with complex geometry based on neural operator on riemannian manifolds. <em>EAAI</em>, <em>161</em>, 112247. (<a href='https://doi.org/10.1016/j.engappai.2025.112247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling the curing deformation of composite parts is becoming increasingly challenging with the ever-increasing performance requirements of aerospace equipment. Mould surface compensation, which adjusts the mould surface to minimise the discrepancy between the cured part geometry and the nominal part geometry, has become a primary deformation control way in engineering. The existing mirror compensation methods focus on the deformation dominated by spring-in and are challenging for complex deformation modes. Surrogate model-based shape optimisation provides a feasible idea, but establishing a surrogate model to predict curing deformation fields on complex part geometries remains a challenge. Therefore, this study explores a novel neural operator-driven framework for fast curing deformation prediction and compensation. A clustering-based deformation field segmentation method is proposed to manipulate the mould surface morphing using limited design variables. The neural operator on Riemannian manifolds is introduced for the first time to establish the surrogate model between the mould surface and the curing deformation fields on complex part geometries. To control the global error distribution of the composite part, two error metrics are designed to optimise the mould surface by genetic algorithm. The verification results show that the proposed framework exhibits significant potential in predicting and compensating for the curing deformation field of composite parts with complex geometry.},
  archive      = {J_EAAI},
  author       = {Lu Chen and Yingguang Li and Jingyan Su and Weiwei Xu and Lin Hu and Gengxiang Chen and Xu Liu and Xiaozhong Hao},
  doi          = {10.1016/j.engappai.2025.112247},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112247},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast prediction and compensation of curing deformation behaviours of composite parts with complex geometry based on neural operator on riemannian manifolds},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced detection of acute leukemia: A hybrid machine learning framework with adaptive weight-optimized level set evolution. <em>EAAI</em>, <em>161</em>, 112244. (<a href='https://doi.org/10.1016/j.engappai.2025.112244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, a novel, multistage framework is developed for the automated detection of Acute Lymphoblastic Leukemia (ALL) and Acute Myeloid Leukemia (AML), addressing challenges due to the inclusion of overlapping cells, noise, and unwanted cells. It integrates an Adaptive Weight-Optimized Level Set Evolution (AWOLSE) scheme to ensures precise and accurate segmentation, coupled with a marker-controlled watershed algorithm to improve performance in regions of cell overlap and contact. It ensures more reliable cell boundary delineation. For classification, a hybrid model combining the strengths of Random Forest (RF) and Support Vector Machine (SVM) is employed that delivering superior performance by leveraging the complementary advantages of these classifiers. Furthermore, feature extraction with the Gray Level Co-occurrence Matrix (GLCM), followed by feature selection with Principal Component Analysis (PCA), aids in the identification of relevant features. The suggested methodology beats its competitors, providing the best ALL identification results on the Acute Lymphoblastic Leukemia Image Database (ALLIDB), with 99.07% accuracy, 97.96% recall, 100.00% specificity, and 100.00% precision. Similarly, on the American Society of Hematology (ASH) database, the technique achieves superior AML identification results with 96.25% accuracy, 95.00% recall, 97.50% specificity, and 97.44% precision.},
  archive      = {J_EAAI},
  author       = {Pradeep Kumar Das and Adyasha Sahu and Sukadev Meher and Rutuparna Panda and Ajith Abraham},
  doi          = {10.1016/j.engappai.2025.112244},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112244},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced detection of acute leukemia: A hybrid machine learning framework with adaptive weight-optimized level set evolution},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based secure tracking control for nonlinear interconnected systems: An event-triggered solution approach. <em>EAAI</em>, <em>161</em>, 112243. (<a href='https://doi.org/10.1016/j.engappai.2025.112243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a secure tracking control method for nonlinear interconnected systems based on reinforcement learning, addressing both security constraints and mismatched conditions in such systems. By utilizing system augmentation techniques, the tracking control problem is reformulated into a stabilization problem for the augmented system, simplifying the original control task. Drawing inspiration from the Chinese philosophical principle, we further transform the problem into a zero-sum game framework. Moreover, a control barrier function (CBF) is incorporated into a cost function to ensure that system trajectories remain within a predefined safe region. An event-triggered mechanism is introduced, and an event-based safety Hamilton–Jacobi–Isaacs (HJI) equation is established. An adaptive single evaluation network is designed, leveraging experience replay techniques to solve the HJI equation. Finally, the Lyapunov method is employed to prove the uniform ultimate boundedness of both the tracking error and the weight error. The effectiveness of the proposed method is validated through numerical examples.},
  archive      = {J_EAAI},
  author       = {Chunbin Qin and Suyang Hou and Mingyu Pang and Zhongwei Wang and Dehua Zhang},
  doi          = {10.1016/j.engappai.2025.112243},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112243},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning-based secure tracking control for nonlinear interconnected systems: An event-triggered solution approach},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A quantized subtraction-convolution network for industrial lightweight edge interpretable diagnosis. <em>EAAI</em>, <em>161</em>, 112241. (<a href='https://doi.org/10.1016/j.engappai.2025.112241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addressing the prevalent challenges of delayed fault diagnosis, deployment complexity of advanced deep learning models on low-cost edge devices, and limited model interpretability, this study proposed an edge-cloud collaborative interpretable diagnosis based on quantized subtraction-convolution network. Firstly, an interpretable quantized subtraction-convolution network with lightweight three-layer structure is designed. Inspired by the adaptive spectral subtraction, a learnable sparse pulse kernel is designed to extract the fault feature as the subtraction layer. Subsequently, the convolution and classification layers are then integrated to produce interpretable results for efficient identification. To facilitate deployment and updates on edge devices, the quantized subtraction-convolution network is decomposed into a lightweight edge architecture and corresponding parameters. It can be deployed on edge devices, and an edge-cloud collaborative framework addresses its training and compression. Considering the sparse characteristics of quantized subtraction-convolution network, a sparse pulse quantization strategy and quantization-aware training technique were developed to compress the model parameters. Finally, a low-cost edge fault diagnosis node prototype with quantized subtraction-convolution network is designed for real-time edge fault diagnosis. Experiments shown that the proposed method achieved average accuracy of 99.88 percent with compression ratio of 9.5. The memory usage, floating-point operations per second, and average power consumption are respectively only 54 kilo binary byte, 0.053 mega binary byte, and 6.67 mJ. Actual gear edge diagnosis experiments confirmed the effectiveness, which can implement model inference in 0.045 s at the edge fault diagnosis node. It is anticipated that the proposed method will find extensive application in the industrial edge interpretable diagnosis.},
  archive      = {J_EAAI},
  author       = {Qihang Wu and Jun Luo and Wenbin Huang and Xiaoxi Ding},
  doi          = {10.1016/j.engappai.2025.112241},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112241},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A quantized subtraction-convolution network for industrial lightweight edge interpretable diagnosis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight multi-level feature integration transformer for image super-resolution. <em>EAAI</em>, <em>161</em>, 112240. (<a href='https://doi.org/10.1016/j.engappai.2025.112240'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based methods have attracted significant attention in the field of image super-resolution. However, existing approaches typically concentrate on a single level of information for image reconstruction, and neglect the critical role of multi-level information in feature representation, resulting in the low utilization of the potential capabilities of Transformer. To address this limitation, we propose a novel Transformer model, named as Multi-Level Differential Window Attention Transformer (MLDAT), designed for multi-level information fusion. Specifically, our approach introduces a self-attention module based on differential windows to comprehensively extract and integrate feature information across varying window sizes. Additionally, we introduce a High-order Global Attention Module (HGAB) to combine the second-order attention with global self-attention, which facilitates the establishment of relationships between local features and the overall global feature context within an image while complementing local window information. Extensive experimental results demonstrate that our model can significantly improve the performance of image super-resolution , and achieves the better results compared with existing methods.},
  archive      = {J_EAAI},
  author       = {Shuheng Wang and Ziao Gong and Mengda Li and Shen Wu and Yilin He},
  doi          = {10.1016/j.engappai.2025.112240},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112240},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightweight multi-level feature integration transformer for image super-resolution},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional object detection for autonomous driving via deep learning: A review. <em>EAAI</em>, <em>161</em>, 112238. (<a href='https://doi.org/10.1016/j.engappai.2025.112238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of autonomous driving technology, there is an increasing demand for highly accurate and real-time vehicle perception systems. From an artificial intelligence (AI) perspective, three-dimensional (3D) object detection benefits from recent progress in deep neural networks, convolutional neural networks (CNNs), and transformer architectures, which provide powerful tools for feature extraction, spatial reasoning, and multi-modal data fusion. These AI techniques enable robust, uncertainty-aware predictions by effectively modeling complex sensor data. From an engineering standpoint, 3D object detectors serve as critical components in autonomous driving systems by translating AI-derived insights into real-time, high-accuracy vehicle perception. This paper reviews the research progress of deep learning-based 3D object detection algorithms in autonomous driving. First, commonly used data acquisition sensors are systematically categorized, and the most widely adopted 3D detection datasets and evaluation metrics are introduced; the standard 3D bounding-box representation and core network architectures are also explained. Second, algorithms are classified according to input data type: 1) single-modal methods, including vision-based, 3D data dimensionality reduction, point cloud-based, transformer-based, mamba-based, and hybrid point cloud approaches; 2) multi-modal methods, subdivided into serial fusion and parallel fusion strategies within network pipelines. The characteristics, contributions, and limitations of each category are summarized, and representative algorithms are compared across datasets to identify research trends. Finally, current challenges, such as sparse data handling, domain shifts, and real-time constraints, are examined, and prospective directions for future development are proposed.},
  archive      = {J_EAAI},
  author       = {Jiaqi Cai and Yiquan Wu},
  doi          = {10.1016/j.engappai.2025.112238},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112238},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-dimensional object detection for autonomous driving via deep learning: A review},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unscented kalman filter neural network with double-layer decomposition algorithm applied to the prediction of current efficiency in aluminum electrolysis processes. <em>EAAI</em>, <em>161</em>, 112237. (<a href='https://doi.org/10.1016/j.engappai.2025.112237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive modeling in predictive optimization control technology can effectively reduce energy consumption and improve production efficiency in the electrolytic aluminum process (EAP). Among the various modeling approaches, artificial neural networks (ANN) have been widely adopted in the EAP due to their strong capability to capture nonlinear relationships inherent in complex industrial systems. However, conventional ANN heavily rely on historical data to achieve optimal models, which limits their accuracy and generalization performance under strong disturbances and time-varying conditions. To address these problems, this article proposes a novel dynamic prediction model of unscented Kalman filter neural network with double-layer decomposition (UKFNN-DD), building upon the foundation of Kalman filter neural network (KFNN). First, singular value decomposition (SVD) is adopted to compute the square root of covariance matrices, enhancing the numerical robustness of the prediction algorithm and overcoming the shortcomings of traditional Cholesky decomposition. Furthermore, a dual-layer KFNN strategy is introduced to overcome the absence of one-step-ahead prediction in conventional state-space formulations. By applying a two-stage correction to the state variables using measurement data, the proposed method improves the adaptability of the model to external environmental variations. Finally, the prediction error of the state variables is optimized using a gradient descent algorithm, which improves the stability and reliability of the model’s prediction performance. Experimental results demonstrate that the proposed method significantly outperforms baseline methods, achieving a 4.38-fold reduction in mean absolute error (MAE) and a 77.29-fold reduction in the sum of squared errors (SSE), thereby verifying its superiority in dynamic prediction for aluminum electrolysis.},
  archive      = {J_EAAI},
  author       = {Xiaoyan Fang and Xihong Fei and Zhenyi Xu and Lei Su and Jing Wang},
  doi          = {10.1016/j.engappai.2025.112237},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112237},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unscented kalman filter neural network with double-layer decomposition algorithm applied to the prediction of current efficiency in aluminum electrolysis processes},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature super-resolution-based method for small-scale target detection and segmentation in side-scan sonar. <em>EAAI</em>, <em>161</em>, 112235. (<a href='https://doi.org/10.1016/j.engappai.2025.112235'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of side-scan sonar in underwater target detection plays a significant role in marine engineering construction and ocean resource exploration. However, existing methods for small object detection often suffer from limited accuracy and robustness. To address this issue, we propose a feature super-resolution-based approach for detecting and segmenting small targets in side-scan sonar images. During network training, a feature super-resolution branch is first constructed. Both low-level and high-level features from the backbone of the You Only Look Once (YOLO) network are fed into this branch. After processing through an encoder-decoder architecture, a super-resolved feature map is reconstructed, and the network is optimized via backpropagation to enhance the ability to extract features of small targets. Furthermore, an exponential decay strategy is adopted to define the loss weights of different branches, establishing a branch-aware training mechanism to improve training effectiveness. During inference, the super-resolution branch is discarded to balance detection accuracy and inference efficiency. Experimental results demonstrate that the proposed method achieves superior performance in detecting and segmenting small-scale targets in side-scan sonar imagery, achieving state-of-the-art results on two public side-scan sonar small object datasets. Additionally, this approach can be extended as a training strategy for side-scan sonar target detection and segmentation networks. The source code is available at https://github.com/Yang-Code984/FSR_Sonar .},
  archive      = {J_EAAI},
  author       = {Zhiwei Yang and Jianhu Zhao and Xi Zhao and Chao Huang},
  doi          = {10.1016/j.engappai.2025.112235},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112235},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature super-resolution-based method for small-scale target detection and segmentation in side-scan sonar},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven prediction of thermal and flow fields in magnetized boger-micropolar tri-hybrid nanofluids via deep artificial neural networks. <em>EAAI</em>, <em>161</em>, 112232. (<a href='https://doi.org/10.1016/j.engappai.2025.112232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a deep learning framework for predicting the thermal and flow behavior of Boger micropolar tri-hybrid nanofluids under magnetized axial squeezing flow between two parallel disks. The fluid comprises gold, silver, and diamond nanoparticles dispersed in a water-based solution, forming a high-performance ternary hybrid heat transfer medium. A fully connected artificial neural network with three hidden layers (32–16–8 neurons) and hyperbolic tangent activation functions was trained on synthetic data generated using a boundary value problem solver. The model predicts four key physical quantities: axial velocity, streamwise velocity, microrotation, and temperature profile. Quantitative evaluation reveals excellent agreement between machine learning predictions and numerical benchmarks, with mean absolute errors consistently below 0.02 and coefficients of determination exceeding 0.99 across all outputs. Sensitivity analysis reveals the impact of the solvent fraction and vortex viscosity parameters on flow penetration and thermal stratification near the boundaries. This work introduces a novel combination of Boger–micropolar fluid dynamics, magnetohydrodynamic squeezing flow, and tri-hybrid nanoparticles into a unified ANN (Artificial Neural Networks) based surrogate, enabling accurate multi-output prediction of strongly coupled nonlinear fields. The proposed approach offers a scalable machine learning model for real-time optimization of nanofluid-based thermal management systems in engineering applications.},
  archive      = {J_EAAI},
  author       = {Mohammad Jalili and Hesam Ehsani and Ali Mirzagoli Ganji and Amirali Shateri and Mehdi mahboobtosi and Yuping Wu and Payam Jalili and Bahram Jalili and Davood Domiri Ganji},
  doi          = {10.1016/j.engappai.2025.112232},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112232},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven prediction of thermal and flow fields in magnetized boger-micropolar tri-hybrid nanofluids via deep artificial neural networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable knowledge recommendation for product innovation concept design based on knowledge graph and multi-task learning. <em>EAAI</em>, <em>161</em>, 112231. (<a href='https://doi.org/10.1016/j.engappai.2025.112231'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of product innovation concept design, by enhancing the transparency of the knowledge recommendation process and providing designers with explainable recommendation results, decision-making time can be reduced, and design efficiency can be improved. Existing explainable knowledge recommendation methods can generate textual explanation information, but they often overlook the dynamic nature of the design process, which negatively affects the accuracy of the recommendations. To address this issue, the current study proposes a knowledge recommendation method for product innovation concept design based on knowledge graph (KG) and multi-task learning. Specifically, a TransD-based model is first constructed to perform the knowledge graph embedding (KGE) task. Then, KGE and Gated Recurrent Unit (GRU) are used to obtain dynamic knowledge demands across different temporal scales from the historical interactions of designers to enhance recommendation accuracy. A multi-task learning framework is subsequently introduced to enable feature sharing between the two tasks, improving the generalization and effectiveness of the model. Finally, an explanation strategy is designed by combining embedded knowledge and paths to provide optimal explainability information. Experimental results demonstrate that, compared with other state-of-the-art knowledge recommendation algorithms, the proposed method not only offers explainable recommendation results but also achieves higher accuracy, making it more suitable for real-world recommendation scenarios.},
  archive      = {J_EAAI},
  author       = {Yida Hong and Wenqiang Li and Hai Xiang and Chuanxiao Li and Changfu Wan},
  doi          = {10.1016/j.engappai.2025.112231},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112231},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable knowledge recommendation for product innovation concept design based on knowledge graph and multi-task learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards reproducible machine learning-based process monitoring and quality prediction research for additive manufacturing. <em>EAAI</em>, <em>161</em>, 112223. (<a href='https://doi.org/10.1016/j.engappai.2025.112223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive manufacturing (AM) is increasingly adopted across industries for its ability to support design flexibility, rapid prototyping, and mass customization. Machine learning (ML)-based cyber-physical systems (CPSs) have been extensively developed to improve the print quality of AM. However, the reproducibility of these systems has not been thoroughly investigated due to a lack of formal evaluation methods. Reproducibility, a critical component of trustworthy artificial intelligence, is achieved when an independent team can replicate the findings or artifacts of a study using a different experimental setup and achieve comparable performance. In many publications, critical information necessary for reproduction is often missing due to a lack of comprehensive AM and ML domain knowledge, resulting in systems that fail to replicate the reported performance. Integrating AM and ML domain knowledge, this paper proposes a reproducibility investigation pipeline and a reproducibility checklist for ML-based AM process monitoring and quality prediction systems. Based on the CRoss Industry Standard Process (CRISP) methodology, the pipeline guides researchers through the key steps required to reproduce a study, while the checklist systematically extracts information relevant to reproducibility from the publication. We validated the proposed approach through two case studies: reproducing a fused filament fabrication warping detection system and a laser powder bed fusion melt pool area prediction model. Both case studies confirmed that the pipeline and checklist successfully identified missing information, improved reproducibility, and enhanced the performance of reproduced systems. Based on the proposed checklist and leveraging large language models, a reproducibility survey was conducted to assess the current reproducibility status within this research domain.},
  archive      = {J_EAAI},
  author       = {Jiarui Xie and Mutahar Safdar and Andrei Mircea and Bi Cheng Zhao and Yan Lu and Hyunwoong Ko and Zhuo Yang and Yaoyao Fiona Zhao},
  doi          = {10.1016/j.engappai.2025.112223},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112223},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards reproducible machine learning-based process monitoring and quality prediction research for additive manufacturing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Degradation-based predictive energy management for intelligent fuel cell hybrid electric vehicles with a novel deep reinforcement learning architecture. <em>EAAI</em>, <em>161</em>, 112222. (<a href='https://doi.org/10.1016/j.engappai.2025.112222'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The degradation of fuel cell systems (FCS) affects the energy management performance of fuel cell hybrid electric vehicles (FCHEVs), especially in the case of severe degradation. This study develops a novel predictive energy management architecture, which consists of the Extended Long Short-Term Memory (xLSTM) and Soft Actor-Critic (SAC). Specifically, the speed predictor is built using xLSTM network and leverages the speed and position information of the preceding and following vehicles. In order to provide a reliable basis for energy management in degradation scenarios, an FCS degradation model is developed, which enables the dynamic mapping of output efficiency curves under varying state-of-health (SOH) conditions. Sequentially, a SAC-based agent is employed as the energy management strategy (EMS), which innovatively takes full account of the impact of the FCS SOH on energy allocation, achieving proactive degradation-aware energy allocation. Simulation results demonstrate that the developed xLSTM architecture achieves a 71 % improvement in speed prediction accuracy compared to Transformer-based models within the Next Generation Simulation validated scenario. Moreover, at SOH = 90 %, the newly designed EMS reduces operational costs by 8.7 % and 10.7 % compared to conventional methods under the New European Driving Cycle and Worldwide Harmonized Light Vehicles Test Procedure, while decreasing FCS degradation costs by 17 % and 51 %, respectively. The innovative approach not only elevates energy efficiency but also prolongs FCS operational longevity via intelligent SOH-aware, which establishes a new paradigm for lifecycle-optimized energy management in FCHEVs.},
  archive      = {J_EAAI},
  author       = {Zhigen Nie and Zhuangfeng Shi and Yufeng Lian and Hao Song},
  doi          = {10.1016/j.engappai.2025.112222},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112222},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Degradation-based predictive energy management for intelligent fuel cell hybrid electric vehicles with a novel deep reinforcement learning architecture},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Observer based fault tolerant control design for saturated nonlinear systems with full state constraints via a novel event-triggered mechanism. <em>EAAI</em>, <em>161</em>, 112221. (<a href='https://doi.org/10.1016/j.engappai.2025.112221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety plays a crucial role in many promising applications as they must comply with stringent safety regulations while staying within physical limits. Therefore, safety fault-tolerant systems with saturated nonlinearities and input constraints are investigated in this paper. An event-triggered safety fault tolerant control (FTC) method based on adaptive dynamic programming (ADP) is proposed. The constrained state is modeled using a smooth mapping function, thus transforming the original system into an unconstrained framework. A fault observer is designed for unknown actuator faults occurring in the system. When an unknown fault occurs in the system, the actuator is compensated in real time according to the fault. The optimal safety value function is approximated by constructing a single critic neural network (NN). Then, a novel event-triggered mechanism is proposed, which allows the algorithm to obtain the optimal control law without constructing the event-triggered Hamilton–Jacobi–Bellman (HJB) equation. In addition, by adjusting the size of the parameter τ under the event triggered condition, different demands on the number of event triggers are realized, which in turn ensures the efficient use of resources while leading to the trade-off of optimal control. This paper also incorporates an empirical playback technique in the design of the critic’s update law to address the challenges associated with continuous incentive requirements. It is theoretically proven that all signals of the system are consistent with the limit bounds, thus ensuring the stability of the system.},
  archive      = {J_EAAI},
  author       = {Chunbin Qin and Mingyu Pang and Zhongwei Wang and Suyang Hou and Dehua Zhang},
  doi          = {10.1016/j.engappai.2025.112221},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112221},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Observer based fault tolerant control design for saturated nonlinear systems with full state constraints via a novel event-triggered mechanism},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cybersecurity enhancement using conditional generative adversarial network with transformer-based conditional variational autoencoder. <em>EAAI</em>, <em>161</em>, 112220. (<a href='https://doi.org/10.1016/j.engappai.2025.112220'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since, Artificial Intelligence is highly developing and concatenating into several domains, cybersecurity is an important field of delivering both the advantages and disadvantages. In addition to this, Artificial Intelligence is applied in a wide variety of applications like healthcare sector, content creation and entertainment and financial industries. Therefore, this work finds the efficiency of Artificial Intelligence -oriented cybersecurity metrics in succeeding the digital environment over elevating cyber threats. Here, the developed models consist of two different stages while implementing the model. In the first stage, the essential dataset is assembled from the benchmark data source. These datasets are assembled by using Generative Artificial Intelligence (Gen Artificial Intelligence networks). Consequently, the raw data is given as an input to Conditional Hybrid Network for cybersecurity enhancement. Further, the Transformer-based Conditional Variational Autoencoders with Spatial-temporal Attention are designed for feature extraction that is subjected to the Conditional Generative Adversarial Network for classifying the cyber attacks. Henceforth, the developed network is evaluated and designed with multiple measures. Comparing baseline models, the suggested network obtains higher performance for developing security over cyber networks.},
  archive      = {J_EAAI},
  author       = {Prithvipal Singh and Sandeep Singh and Gurupdesh Singh and Amritpal Singh},
  doi          = {10.1016/j.engappai.2025.112220},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112220},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cybersecurity enhancement using conditional generative adversarial network with transformer-based conditional variational autoencoder},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modal transfer enhanced deep learning for structural dynamic response with sparse spatial data. <em>EAAI</em>, <em>161</em>, 112218. (<a href='https://doi.org/10.1016/j.engappai.2025.112218'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse spatial data in structural health monitoring (SHM) presents significant challenges due to large spatial gaps and high uncertainty, which hinder the generalization ability and performance of traditional data-driven methods that rely on dense sensor networks. To address this issue, this paper proposes a novel modal transfer-enhanced deep learning (MT-DL) model for the reconstruction and prediction of structural dynamic responses. The core idea is to integrate physical modal information (mode shapes) into the deep learning framework via transfer learning. This integration enables the model to capture the spatial correlation among structural nodes, even under extremely limited data conditions. The MT-DL model is initially validated on a simply supported beam with varying stiffness, where it demonstrates significantly higher reconstruction accuracy compared to both conventional deep learning (DL) approaches and the graph convolutional network (GCN) model under sparse sensor conditions. To demonstrate the model's robustness and generalizability, it is further applied to the dynamic response reconstruction of a continuous beam subjected to moving loads, a plate with complex boundary conditions under impact loading, and a slender flexible riser undergoing vortex-induced vibration (VIV). The results show that the proposed MT-DL model, by incorporating physical principles into data-driven learning, not only enhances prediction accuracy with minimal data but also offers improved physical interpretability. This approach provides a promising solution for structural monitoring in scenarios where dense sensor instrumentation is impractical or cost-prohibitive.},
  archive      = {J_EAAI},
  author       = {Yangyang Liao and Yajuan Xie and Hesheng Tang and Zihan Xia and Songtao Xue},
  doi          = {10.1016/j.engappai.2025.112218},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112218},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A modal transfer enhanced deep learning for structural dynamic response with sparse spatial data},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep learning pipeline for coronary artery analysis in X-ray angiography. <em>EAAI</em>, <em>161</em>, 112217. (<a href='https://doi.org/10.1016/j.engappai.2025.112217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X- ray angiography is a primary and essential assistive method for the accurate diagnosis of coronary blockage. Segmentation of coronary arteries and analysis of coronary artery blockage are the two primary tasks performed by cardiologists. We have proposed Coronary Artery Segmentation, Blockage Detection, and Measurement (CASBloDaM) a state-of-the-art pipeline integrated deep learning framework with conventional image processing techniques to achieve accurate coronary artery analysis in X-ray angiographic images. A new private dataset of 214 X-ray angiographic images is prepared for training, validation, and testing of the model by manual pixel annotation. The UNet3+ deep learning model is trained on X-ray angiographic images for accurate artery segmentation while multiple image processing techniques are developed to perform blockage detection and measurement. The model shows excellent performance in artery segmentation and the dice score of 0.989, accuracy of 0.985, specificity of 0.913 and sensitivity of 0.847 is achieved during the testing which is superior when compared against the previous reported works. An accuracy of 0.853, 0.882 and 0.725 are achieved by the proposed catheter detection, sub-artery removal and blockage detection algorithms respectively when evaluated for 150 test images. The proposed methodology achieved a Mean Square Error (MSE) of 28.66 and an R-square of 0.81 for blockage percentage estimation, and an MSE of 69.91 with an R-square of 0.99 for blockage location, compared to manual calculations. The novelty of the present work is the end-to-end integrated framework which can accurately perform coronary artery analysis in X-ray angiographic images and propose its clinical usage.},
  archive      = {J_EAAI},
  author       = {Karan V. Padariya and Abhishek Raval and Pranay Soni and Harsh Kapadia},
  doi          = {10.1016/j.engappai.2025.112217},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112217},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel deep learning pipeline for coronary artery analysis in X-ray angiography},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-teacher knowledge distillation-based framework for long-term respiratory monitoring and prediction with a novel flexible wearable sensor in healthcare engineering. <em>EAAI</em>, <em>161</em>, 112216. (<a href='https://doi.org/10.1016/j.engappai.2025.112216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Respiratory monitoring plays a critical role in early health warnings and preventive care, offering significant potential for advancements in healthcare engineering. Wearable respiratory monitoring devices, known for their compact design, portability, and real-time capabilities, face challenges such as limited long-term comfort, environmental interference, and signal inaccuracies. In this study, we propose a novel wearable respiratory monitoring framework, RAMP, which integrates an innovative artificial muscle-based flexible sensor system with advanced deep learning modules. The system is designed to reconstruct and analyze respiratory data across various human activities and predict long-term respiratory function. Utilizing a multi-teacher knowledge distillation mechanism, the framework optimizes a student model for enhanced prediction accuracy. Experimental results demonstrate the mean absolute percentage error (MAPE) of 7.28 and mean absolute error (MAE) of 11.92, highlighting the feasibility and effectiveness of system. This work advances the development of portable health monitoring devices and provides a robust foundation for long-term respiratory activity assessment and forecasting, contributing to the broader field of healthcare engineering and personalized medicine.},
  archive      = {J_EAAI},
  author       = {Ke Li and Qing Wang and Haoke Liu and Mingke Wang and Suiyuan Zhu and Xiang Wang and Jing Qin},
  doi          = {10.1016/j.engappai.2025.112216},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112216},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-teacher knowledge distillation-based framework for long-term respiratory monitoring and prediction with a novel flexible wearable sensor in healthcare engineering},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic mask network based on spiking neural convolutional model for missing modality brain tumor segmentation. <em>EAAI</em>, <em>161</em>, 112215. (<a href='https://doi.org/10.1016/j.engappai.2025.112215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor segmentation is a medical image processing task aimed at accurately locating and isolating tumor regions from brain scan images (e.g., Magnetic Resonance Imaging, MRI) in order to help doctors in diagnosis, treatment planning and surgical navigation. Automatic brain tumor segmentation is extremely challenging due to incomplete feature representation in the case of missing modalities and insufficient inter-modal information interaction. To this end, this paper proposes a novel dynamic threshold mask Transformer network for the missing modality brain tumor segmentation task, which is designed based on the nonlinear spiking neural convolutional model. The network consists of four independent encoders and a shared decoder to extract the features of each modality and perform shared representation learning. Among them, the dynamic threshold mask Transformer introduces learnable embedding vectors, generates dynamic masks on top of static masks to achieve fine-grained feature filtering, and enhances the ability of inter-modal information interaction. The adaptive gating weighting module and the channel cross spiking neural P attention module fuse modal features layer by layer in both spatial and channel dimensions to strengthen the modeling capability of local and global features. We conducted extensive comparative experiments on different missing modal cases in the BraTS2020 and BraTS2018 datasets. The experimental results show that the method effectively improves the robustness of missing modalities and the performance of brain tumor segmentation while maintaining the computational efficiency, and has good generalization ability and practicality.},
  archive      = {J_EAAI},
  author       = {Junjie Li and Rui Cai and Bing Li and Hong Peng},
  doi          = {10.1016/j.engappai.2025.112215},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112215},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic mask network based on spiking neural convolutional model for missing modality brain tumor segmentation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing accuracy in fall detection and prediction for elderly individuals using ensemble wavelet neural network and maximal overlap discrete wavelet transform. <em>EAAI</em>, <em>161</em>, 112213. (<a href='https://doi.org/10.1016/j.engappai.2025.112213'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Falls are the second-largest risk factor for the health of the elderly. Various researchers have proposed approaches for monitoring health and falls using only the Internet of Things (IoT) and sensors. However, relying on a single sensor limits accuracy in fall risk prediction. Data from multiple sensors can be used to classify human posture through learning-based algorithms stemming from machine learning. Recently, posture-detecting sensors have become increasingly popular, with InvenSense's Inertial Measurement Unit 9250 (IMU 9250) being a notable example for detecting elderly motion and transmitting data to a computer. This paper proposes the Ensemble Wavelet Network Framework (EWNNET) for fall prediction and detection using the Maximal Overlap Discrete Wavelet Transform (MODWT). The inertial measurement unit (IMU) dataset, containing real-time posture data from seven sensors, is split into 80 % for training and 20 % for testing. The EWNNET approach is compared with other machine-learning methods for fall detection, showing improved accuracy, sensitivity, precision, F-score, and specificity, with a 96.7 % classification success rate.},
  archive      = {J_EAAI},
  author       = {Safa Hussein Mohammed and Yangyu Fan and Guoyun Lv and Shiya Liu},
  doi          = {10.1016/j.engappai.2025.112213},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112213},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing accuracy in fall detection and prediction for elderly individuals using ensemble wavelet neural network and maximal overlap discrete wavelet transform},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leakage localization methodology based on dynamic pressure signal for subsea pipeline. <em>EAAI</em>, <em>161</em>, 112212. (<a href='https://doi.org/10.1016/j.engappai.2025.112212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leakage is one of the most critical failure forms of subsea pipeline. The accurate leakage localization is of great significance to ensure the safe and reliable transportation of subsea pipeline. Leakage locations are considered to be discretely distributed along the subsea pipeline. However, an overabundance of nodes in leakage localization model is caused by excessive discretization. The performance of a leakage localization model with much localization points is poor. Furthermore, the data collected in site usually contains a lot of noise which reduce the effectiveness of leakage localization. A leakage localization methodology based on dynamic pressure signal for subsea pipeline is proposed in this paper. A noise reduction model based on variational mode decomposition (VMD) algorithm combined with power spectral density (PSD) is established to reduce noise of leakage signal. An improved K-means grouping model is developed to mining data for inherent similarity and cluster leakage characteristic. It improves robustness of the leakage localization model. A radial basis function (RBF) neural network leakage localization model optimized by the pelican optimization algorithm (POA) is used to identify the location of leakage. A leakage experiment is used to study performance of this methodology. The localization accuracy of the proposed leakage localization methodology is more than 90 %, the localization error is less than 16 cm. After neural network combined with improved grouping model, average leakage localization accuracy increased by 15.65 %, average absolute error decreased 8.64 cm. The proposed methodology provides an effective tool for leakage localization of critical equipment in subsea production system.},
  archive      = {J_EAAI},
  author       = {Guowei Ji and Baoping Cai and Xuelin Liu and Yi Jiang and Yixin Zhao and Qingping Li and Lei Gao and Kaizheng Wu},
  doi          = {10.1016/j.engappai.2025.112212},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112212},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leakage localization methodology based on dynamic pressure signal for subsea pipeline},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing entity and relation extraction with dynamic hard negative augmentation framework. <em>EAAI</em>, <em>161</em>, 112211. (<a href='https://doi.org/10.1016/j.engappai.2025.112211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity and relation extraction, a fundamental task in information extraction, plays a crucial role in modeling unstructured text by identifying meaningful entities and their semantic relationships. While existing methods have shown effectiveness, they still face challenges in accurately identifying entity boundaries and extracting complex relationships. These challenges primarily arise from current contrastive learning approaches, which uniformly handle all negative samples in boundary detection and relation extraction without emphasizing the learning of hard negative samples. Additionally, the scarcity of hard negative samples limits the exploration of the state space near the anchors. To tackle these challenges, we introduce Dynamic Hard Negative Augmentation, an innovative framework designed to strategically explore and generate hard negative samples, thereby enhancing the learning of challenging cases through adaptive contrastive learning. During the negative sample augmentation process, we employ adversarial training to explore underrepresented areas of hard negative samples, generating a comprehensive coverage of the hard negative sample space to effectively explore the state space. We further introduce a dynamic enhancement mechanism that continuously optimizes the proportion of hard negative samples during training, ensuring targeted learning of these challenging cases.},
  archive      = {J_EAAI},
  author       = {Qibin Li and Shengyuan Bai and Nai Zhou and Nianmin Yao},
  doi          = {10.1016/j.engappai.2025.112211},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112211},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing entity and relation extraction with dynamic hard negative augmentation framework},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NashDQNSleep: Nash-based deep Q-network adaptive sleep scheduling for energy efficiency and age of information optimization in industrial internet of things. <em>EAAI</em>, <em>161</em>, 112210. (<a href='https://doi.org/10.1016/j.engappai.2025.112210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fresh and timely data is essential for the sustainable operation of Industrial Internet of Things (IIoT) systems, which support real-time monitoring and decision-making tasks. Sensor nodes typically need to remain active for long durations to maintain data freshness, resulting in high energy consumption. Traditional sleep scheduling methods often trade off energy savings with data freshness, and many rely on centralized sink-node coordination, which can create communication bottlenecks and increase energy use. This paper introduces NashDQNSleep , a novel decentralized sleep scheduling algorithm that uniquely combines game-theoretic modeling with deep reinforcement learning to address these challenges. Unlike conventional DQN approaches that optimize node behavior independently or centrally, NashDQNSleep formulates the scheduling problem as a general-sum stochastic game and uses Deep Q-Networks (DQNs) to compute Nash equilibria. This enables sensor nodes to make autonomous, yet strategically coordinated decisions based on peer-to-peer information exchange, achieving a stable and efficient balance between energy consumption and data freshness without centralized control. Extensive simulations on diverse IIoT network topologies demonstrate that NashDQNSleep improves energy efficiency by up to 35%, reduces Age of Information (AoI) by 40%, and increases successful data transmissions by 15%–20% compared to state-of-the-art decentralized and centralized methods. These results establish NashDQNSleep as an effective, scalable, and practical solution for reliable and sustainable IIoT operations.},
  archive      = {J_EAAI},
  author       = {Partha Sarathi Banerjee and Soumyapriya Goswami and Debashis De},
  doi          = {10.1016/j.engappai.2025.112210},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112210},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {NashDQNSleep: Nash-based deep Q-network adaptive sleep scheduling for energy efficiency and age of information optimization in industrial internet of things},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel contrastive learning framework for multi-parameter optimization in 3D printing. <em>EAAI</em>, <em>161</em>, 112209. (<a href='https://doi.org/10.1016/j.engappai.2025.112209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive manufacturing (3D printing) revolutionizes prototyping and production through unparalleled material efficiency. However, part quality remains highly sensitive to parameter variations, where subtle deviations induce defects, material waste, and process instability. Traditional quality control methods – reliant on rule-based heuristics or manual inspections – fail to address complex multi-parameter interactions and fine-grained anomalies, limiting industrial scalability. This article focuses on an important issue in 3D printing: How can we develop a robust, automated framework to simultaneously detect and classify subtle multi-parameter anomalies in 3D printing, overcoming the limitations of manual and single-defect-focused approaches? We propose a supervised contrastive learning framework integrating Vision Transformers (ViT) to learn discriminative feature representations for multi-parameter optimization. By maximizing intra-class similarity and inter-class separation, our model captures nuanced variations across printing scenarios. The ViT architecture processes real-time printing images, while contrastive loss ensures compact feature clusters for “Low”, “Optimal”, and “High” parameter classes. Experimental evaluations on open-source datasets demonstrate our framework achieves 8.45% accuracy, outperforming conventional CNNs by 10.11%. Real-world validation shows robust performance across critical parameters: flow rate (86.5% accuracy in nominal ranges), feed rate (87% accuracy), and extrusion temperature (90% accuracy at optimal settings). The ViT’s self-attention mechanism enables precise detection of localized anomalies, such as under-extrusion and layer misalignment.},
  archive      = {J_EAAI},
  author       = {Jieyang Peng and Simon Kreuzwieser and Dongkun Wang and Andreas Kimmig and Zhi Fan and Jianing Li and Jivka Ovtcharova},
  doi          = {10.1016/j.engappai.2025.112209},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112209},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel contrastive learning framework for multi-parameter optimization in 3D printing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight model based on multi-scale feature fusion for ultrasonic welding surface defect detection. <em>EAAI</em>, <em>161</em>, 112208. (<a href='https://doi.org/10.1016/j.engappai.2025.112208'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasonic welding technology is crucial in industrial and medical fields, relying on precise surface defect detection for quality assurance. Traditional methods suffer from low accuracy, efficiency, high costs, and complex implementation. Additionally, current neural networks for ultrasonic surface defect detection struggle to balance parameter optimization with detection accuracy. To solve this problem, we proposed a lightweight model based on multi-scale feature fusion for the Ultrasonic Weld Surface Defect Detection Network (UWSDNet). First, the feature extraction module with reparameterization technology (FRT) and application of efficient multi-scale attention (EMA) are proposed to alleviate network redundant parameters and computational overhead brought by welding background. Secondly, the multi-core feature enhancement module (MCM) is introduced. It enhances multi-scale object detection with fewer parameters to cope with the actual edge deployment of ultrasonic welding. Finally, the lightweight asymmetric detection head (LADH) and contextual and spatial feature calibration network (CSFCN) are introduced into the network. To improve the multi-core dimensional feature capture capability, to solve the problem of large size span of ultrasonic welding surface defects. Experimental evaluations on a self-built ultrasonic welding wire harness defect dataset show that UWSDNet achieves the mean average precision (mAP) of 88.9%, the precision of 95.6% with parameters of 12.7M. In addition, UWSDNet achieves excellent performance on the publicly available NEU-DET dataset, demonstrating strong generalization and application potential in industrial defect detection.},
  archive      = {J_EAAI},
  author       = {Rui Liu and Lun Zhao and Yu Ren and Zhonghua Shen and Liya Li and Jianfeng Luo and Zeshan Abbas},
  doi          = {10.1016/j.engappai.2025.112208},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112208},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight model based on multi-scale feature fusion for ultrasonic welding surface defect detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial neural network solution for magnetohydrodynamic ternary hybrid second-grade nanofluid in rotating jeffery-hamel flow under heat generation: Entropy generation analyses. <em>EAAI</em>, <em>161</em>, 112207. (<a href='https://doi.org/10.1016/j.engappai.2025.112207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research-work examines entropy generation in Magnetohydrodynamic (MHD) ternary hybrid nanofluid under rotating Jeffery-Hamel flow with heat generation alongside thermal radiation. Using appropriate similar transformation equations, the original partial differential equations (PDEs) are converted into nonlinear ordinary differential equations (ODEs), while Artificial Neural Networks (ANNs), which highly extensively used as universal function approximators, is considered in this investigation. In fact, to provide efficient solutions for the nonlinear transformed problem of the magnetohydrodynamic ternary hybrid second-grade nanofluid in rotating Jeffery-Hamel flow, solvers consider log-sigmoid, radial basis and tan-sigmoid activation functions, optimized with an interior point method to generate optimal weights of each considered ANN model. The model relies on assumptions of incompressible steady flow together with negligible viscous energy loss and usage of Rosseland radiation approximation. The predictions made through the Artificial Neural Network (ANN) match numerical benchmarks successfully thus demonstrating better accuracy when modeling velocity, temperature and entropy profiles. The research data indicates that systems attaining better thermal qualities operate effectively under elevated nanoparticle levels and radiation conditions which provides fundamental knowledge to enhance thermal system design. The results from the proposed schemes match numerical solutions precisely thus showing their high accuracy for evaluating ternary hybrid nanofluid flow and heat behavior. Results show that the velocity and temperature profiles of the Magnetohydrodynamic (MHD) ternary hybrid nanofluid reveal significant improvements at higher thermal volume fractions of nanoparticles. The rate of flow increases, perhaps because inertial forces prevail over viscous forces, thereby improving flow dynamics. With higher Radiation numbers associated with higher permeability, the local temperature gradients decrease promoting heat transfer rates within the fluid.},
  archive      = {J_EAAI},
  author       = {Nouar Ahcene and Amar Dib and Farhan Lafta Rashid and Kezzar Mohamed and Mohamed Rafik Sari and Manal Elzain and Hamiden Abd El-Wahed Khalifa},
  doi          = {10.1016/j.engappai.2025.112207},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112207},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial neural network solution for magnetohydrodynamic ternary hybrid second-grade nanofluid in rotating jeffery-hamel flow under heat generation: Entropy generation analyses},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent compound fault decoupling of rolling bearing based on parallel capsule network. <em>EAAI</em>, <em>161</em>, 112206. (<a href='https://doi.org/10.1016/j.engappai.2025.112206'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complex working environment of rolling bearings, various components such as inner ring, outer ring, rolling element and cage in bearing may interact with each other, leading to a compound fault formed by a variety of single fault coupling. Most methods generally regard compound faults as single faults, ignoring the interaction between single faults, which is not conducive to decoupling compound faults into multiple single faults and formulating maintenance plans. Moreover, the capsule network requires stacking multiple capsule layers to enhance performance, which significantly increases model parameters and consumes substantial memory resources. Therefore, a compound fault intelligent decoupling method based on parallel capsule network combining dynamic routing and attention routing is proposed in this study. Firstly, the Omni-Scale block is added to the feature extraction part, which can cover different sizes of receptive fields to enhance the feature extraction ability of the network. Secondly, an attention routing module is proposed, which realize the transmission of information from low-level capsules to high-level capsules by calculating the correlation between the same layers. Finally, the parallel capsule decoupling layer is constructed by using dynamic routing and attention routing. This method is especially suitable for practical engineering scenarios where compound bearing fault samples are limited and computational resources are constrained, providing a lightweight and effective solution for intelligent fault diagnosis. Experimental results show that the proposed method significantly reduces model complexity while maintaining high diagnostic performance under small-sample conditions, with the ablation study further confirming the meaningful contribution of each core module.},
  archive      = {J_EAAI},
  author       = {Renwang Song and Chenyu Jiao and Hui Shi and Linying Chen},
  doi          = {10.1016/j.engappai.2025.112206},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112206},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent compound fault decoupling of rolling bearing based on parallel capsule network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning-based strategic bidding in electricity markets via variational autoencoder-assisted competitor behavior learning. <em>EAAI</em>, <em>161</em>, 112205. (<a href='https://doi.org/10.1016/j.engappai.2025.112205'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a deregulated electricity market, self-interested producers have incentives to offer strategically for maximizing their own profits. While deep reinforcement learning (DRL) has shown great potential for solving such strategic bidding problems, existing methods typically oversimplify strategic action spaces and neglect the influence of competitors' offering behaviors. To bridge these gaps, this paper proposes a novel DRL-based framework to model and solve the strategic bidding problem of an individual producer by jointly considering price-quantity offering actions and the dynamic behaviors of market competitors. First, a bilevel optimization model is formulated to incorporate offering actions on price-quantity pairs. Then, a data-driven framework that combines a variational autoencoder with a density-based clustering method is proposed to learn and capture competitors' offering behaviors. Finally, an imitation learning-integrated DRL algorithm is developed to improve learning stability and solution quality for strategic bidding with price-quantity actions and competitors' offering behaviors. Case studies on the IEEE-30 bus system show that the proposed framework obtains a 28.12 k$ (24.25 %) increase in average profit compared to the existing approach, demonstrating its effectiveness and adaptability under dynamic market conditions.},
  archive      = {J_EAAI},
  author       = {Fei Hu and Yong Zhao and Yaowen Yu and Yuanzheng Li},
  doi          = {10.1016/j.engappai.2025.112205},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112205},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement learning-based strategic bidding in electricity markets via variational autoencoder-assisted competitor behavior learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep-supervised framework utilizing edge features and global texture features for distortion rectification in fisheye images. <em>EAAI</em>, <em>161</em>, 112204. (<a href='https://doi.org/10.1016/j.engappai.2025.112204'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fisheye cameras, with their ultra-wide field of view, are increasingly deployed in urban environments. However, the severe radial distortion inherent in fisheye imagery presents formidable challenges for downstream computer vision tasks, including object recognition, motion estimation, and semantic segmentation. To address this issue, a deeply supervised framework for distortion rectification that leverages edge features and global texture information (DR-EGT) is proposed, which uniquely integrates edge-aware structural features with global texture information under a unified deep supervision strategy. Unlike conventional approaches that rely solely on texture priors or geometric assumptions, DR-EGT introduces a hierarchical supervision mechanism that simultaneously leverages low-level edge contours and high-level texture semantics to guide the distortion correction process. This joint supervision enables the network to learn the distortion flow field of the entire image, which facilitates the reconstruction of geometrically accurate and perceptually sharp undistorted images. On the Places2 dataset, DR-EGT outperforms existing advanced methods, achieving a 12.12 % increase in PSNR (Peak Signal-to-Noise Ratio), 7.44 % improvement in SSIM (Structural Similarity Index Measure), 16.42 % reduction in MAE (Mean Absolute Error), and a 78.17 % gain in FID (Fréchet Inception Distance), demonstrating its superior reconstruction fidelity and perceptual quality. The results demonstrate the ability of DR-EGT not only correct complex fisheye distortion but also suppress post-correction artifacts and visual degradation.},
  archive      = {J_EAAI},
  author       = {Yicheng Chen and Shuang Li and Yuhuan Gu and Chang Feng and Changhai Zhai},
  doi          = {10.1016/j.engappai.2025.112204},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112204},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep-supervised framework utilizing edge features and global texture features for distortion rectification in fisheye images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectrum prior-based and visibility fusion method for underwater image enhancement. <em>EAAI</em>, <em>161</em>, 112203. (<a href='https://doi.org/10.1016/j.engappai.2025.112203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When light propagates in water, it undergoes scattering and absorption phenomena, which typically result in haze, high blur, low contrast and color distortion, making it extremely challenging to obtain high-quality images. To address these issues, many existing methods target image enhancement by correcting specific aspects such as color shift or contrast. However, challenges like poor visibility and low-light conditions are often overlooked. In this paper, we proposed a spectrum prior-based and visibility fusion method (SPV) to enhance underwater images in terms of color, contrast, and visibility. Unlike existing methods, SPV complements the advantages of both physical and non-physical models, comprehensively addressing the problems of reduced visual visibility, color distortion, and low contrast caused by low-light environments, thereby significantly improving the overall image quality. We proposed a dehazing module based on spectral information priors, which reliably restores image quality under complex water conditions. Additionally, we introduced a color correction module based on human color perception and employed morphological operations, effectively solving the issues of color shift and unclear contours in underwater images. Furthermore, we proposed a visibility enhancement module based on the fuzzy c-means clustering method to improve image contrast and visibility, particularly under low-light conditions. Finally, through a detail enhancement fusion module, we simultaneously addressed problems related to color shift, low contrast, and low visibility. SPV showed excellent performance in application tests including feature point matching, geometric rotation estimation, and edge detection. Comparative experiments on four real underwater datasets against 14 advanced enhancement methods demonstrated promising results.},
  archive      = {J_EAAI},
  author       = {Qifeng Liu and Xin Yan and Lu Shen and Qiang Li},
  doi          = {10.1016/j.engappai.2025.112203},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112203},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spectrum prior-based and visibility fusion method for underwater image enhancement},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated multi-criteria decision-making approach with unknown weight information under probabilistic dual-hesitant pythagorean fuzzy environment and its application to supplier selection. <em>EAAI</em>, <em>161</em>, 112202. (<a href='https://doi.org/10.1016/j.engappai.2025.112202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preference ranking organization method for enrichment evaluation (PROMETHEE) has been proved to be one of the most effective techniques to rank alternatives of multi-criteria decision-making (MCDM) problems. However, the existing PROMETHEE cannot accurately adjust the representation range of uncertain information. Besides, the weight determination in PROMETHEE heavily relies on the decision matrix of alternatives on the criteria. Moreover, the information aggregation in PROMETHEE models lacks consideration of the interrelationship among criteria. To address the aforementioned shortcomings, this paper introduces a novel MCDM method that integrates the best-worst method (BWM) and PROMETHEE to help the decision-maker (DM) select the optimum alternative under the probabilistic dual-hesitant Pythagorean fuzzy (PDHPF) environment. Firstly, we extend PROMETHEE method to PDHPF scenario, which not only helps the DM depict subjective evaluations, but also provides the DM with a laxer constraint to present decision information. Secondly, the PDHPF power weighted Hamy mean operator (PDHPFPWHM) is utilized to aggregate the preference information of PROMETHEE. Additionally, the BWM method is utilized and extended to the PDHPF environment for acquiring optimal weights of criteria. The high efficiency and consistency of BWM are well-suited for the complex PDHPF environment. Finally, the method is applied to a semiconductor supplier selection case to demonstrate the validity, superiority, and feasibility of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Huzhi Xue and Haihua Xie and Butian Zhao and Jun Wang},
  doi          = {10.1016/j.engappai.2025.112202},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112202},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An integrated multi-criteria decision-making approach with unknown weight information under probabilistic dual-hesitant pythagorean fuzzy environment and its application to supplier selection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach for understanding the parking demand for internal access roads in hub car parks. <em>EAAI</em>, <em>161</em>, 112201. (<a href='https://doi.org/10.1016/j.engappai.2025.112201'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hubs serve as pivotal nodes within urban transport networks, and the car parks associated with these hubs constitute an integral component. The prevalent practice in China of utilizing internal access roads within car parks for passenger pick-up by online car-hailing vehicles has engendered a novel category of parking demand. However, this development presents a significant challenge to the efficient operation of hub car parks. A thorough analysis and comprehension of the parking demand for internal access roads is essential in devising suitable management strategies to enhance parking efficiency. Initially, this study categorizes the parking demand for internal access roads into three distinct groups, applying parking duration and the number of entries as classification criteria. Subsequently, considering the number of train frequencies, the categorized parking demands are forecasted independently utilizing the Long Short-Term Memory (LSTM) model, complemented by the Shapley Additive exPlanations (SHAP) method for model interpretation. Ultimately, Vector Autoregression (VAR) is employed to investigate the interaction mechanism between the parking demand for parking spaces and the parking demand for internal access roads. The findings indicate that optimal predictive performance is attained when employing a time interval of 15 min and an input step size of 4. Competition between the parking demand for internal access roads and the parking demand for parking spaces primarily occurs within respective categories, underscoring the need for external interventions when these demands are imbalanced.},
  archive      = {J_EAAI},
  author       = {Qianyi Hu and Weidong Liu and Chenyu Yan and Chu Zhang and Jun Chen and Changyin Dong},
  doi          = {10.1016/j.engappai.2025.112201},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112201},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel approach for understanding the parking demand for internal access roads in hub car parks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning for disease-specific prediction of high-cost patients. <em>EAAI</em>, <em>161</em>, 112200. (<a href='https://doi.org/10.1016/j.engappai.2025.112200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-cost patients incur disproportionately high medical expenses, and identifying them proactively is crucial for effective healthcare management. While previous research has focused on identifying high-cost patients based on overall expenditure, there has been a lack of studies analyzing them in the context of specific diseases. This study addressed this gap by leveraging data from the National Health Insurance Service (NHIS) of South Korea, spanning 2015 to 2019, to develop predictive models for identifying these patients. We trained models using data from 880,000 individuals to predict high-cost patients in 2019 using resource-efficient machine learning algorithms such as Extreme Gradient Boosting (XGBoost), Random Forest (RF), and Neural Networks (NN) that minimize computational overhead, with undersampling techniques applied to handle data imbalance. We focused on the six major disease categories that account for the highest medical expenditures in South Korea: diseases of the musculoskeletal system (DMS), circulatory system (DCS), eye and ear (DEA-DEM), digestive system (DDS), genitourinary system (DGS), and respiratory system (DRS). We discovered that disease-specific analyses revealed important predictive factors that were not apparent in aggregate analyses. For example, hemoglobin levels emerged as crucial predictors for DCS, while body mass index (BMI) proved essential for DMS prediction. These findings enhance our understanding of the factors contributing to high medical costs and provide a foundational framework for healthcare providers and policymakers to develop more targeted and effective health management strategies.},
  archive      = {J_EAAI},
  author       = {Inwoo Tae and Hyeongwoo Kong and Junghye Lee and Yongjae Lee},
  doi          = {10.1016/j.engappai.2025.112200},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112200},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning for disease-specific prediction of high-cost patients},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing mean conditional value-at-risk portfolios through deep neural network stock prediction. <em>EAAI</em>, <em>161</em>, 112198. (<a href='https://doi.org/10.1016/j.engappai.2025.112198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio optimization is essential in financial decision-making, requiring a balance between risk minimization and return maximization. Effective stock selection significantly influences portfolio performance. Traditional methods often struggle to effectively integrate advanced risk assessment techniques with stock selection. To enhance portfolio diversification and improve risk-adjusted returns, this study integrates deep learning-based stock selection with the mean conditional Value-at-Risk (MCVaR) model and entropy constraints to enhance portfolio diversification and risk-adjusted returns. Various deep neural networks, including Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), Multi-Layer Perceptrons (MLP), and Radial Basis Function Neural Networks (RBFN), are employed to rank stocks based on risk and return characteristics. The top-ranked stocks with the lowest risk are selected for portfolio construction. The entropy constraint is introduced to prevent excessive weight concentration, ensuring a well-diversified portfolio. Historical datasets from the Bombay Stock Exchange (BSE), India, B3 Stock Exchange, Brazil, and Shanghai Stock Exchange, China, are used for validation, with performance assessed on an out-of-sample dataset. Additionally, the efficacy of the suggested approach is evaluated by contrasting it with other machine learning and conventional portfolio optimization techniques. Experimental results demonstrate that the LSTM+MCVaR model with entropy constraint consistently outperforms other deep learning and conventional optimization methods, achieving superior cumulative returns and Sharpe ratios. The findings highlight the potential of combining LSTM forecasting with MCVaR optimization and entropy regularization for robust, diversified portfolio construction.},
  archive      = {J_EAAI},
  author       = {Jyotirmayee Behera and Pankaj Kumar},
  doi          = {10.1016/j.engappai.2025.112198},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112198},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing mean conditional value-at-risk portfolios through deep neural network stock prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and analysis of an unbiased intelligent recommendation system for all-rounders in cricket based on multiple criteria decision making. <em>EAAI</em>, <em>161</em>, 112197. (<a href='https://doi.org/10.1016/j.engappai.2025.112197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing and analyzing an unbiased intelligent all-rounder recommendation system in cricket is a critical and complex decision-making task, where performance prediction itself is a crucial issue. The majority of existing works on cricket focus on batsmen, bowlers, and teams. However, performance analyses of all-rounders are hardly found. Hence, the motivation of this paper is to propose an artificial intelligence (AI)-based method for assessing the performance of all-rounders utilizing various multiple-criteria decision-making (MCDM) techniques. With this goal in mind, effective attributes are considered for evaluating all-rounder bowling and batting performances. Case studies using a set of 20 all-rounders have been taken from the recent International Cricket Council (ICC) all-rounders list to determine their ranking. The performance of various MCDM techniques is investigated using ICC rankings, with the Spearman Rank Correlation Coefficient applied to the One Day International (ODI) format. The results indicate that the Criteria Importance Through Intercriteria Correlation (CRITIC)-VlseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR) method yields quite promising insights, achieving a higher correlation with ICC rankings (Spearman Rank Correlation: 0.794) and hence can be used as an intelligent AI-based all-rounder recommendation system. Finally, we have also conducted a sensitivity analysis on the ranking outcomes of all-rounders to examine the utility and robustness of our proposed MCDM approach. The proposed approach is beneficial for team selectors, analysts, and fantasy sports platforms, offering a fairer and more reliable ranking of all-rounders.},
  archive      = {J_EAAI},
  author       = {Nayan Ranjan Das and Imon Mukherjee and Goutam Paul},
  doi          = {10.1016/j.engappai.2025.112197},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112197},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design and analysis of an unbiased intelligent recommendation system for all-rounders in cricket based on multiple criteria decision making},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic analysis-based recommender system using sequential clustering and convolutional neural network. <em>EAAI</em>, <em>161</em>, 112196. (<a href='https://doi.org/10.1016/j.engappai.2025.112196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of user preferences and generation of personalized recommendations remain as critical challenges in intelligent recommendation systems. In this study, we propose a novel recommendation model that transforms the rating prediction problem into a single-label multiclass classification task. The model integrates three key components: (1) ordered clustering information derived from user review text similarity, (2) rating rank similarity reflecting users’ behavioral tendencies, and (3) a convolutional neural network (CNN) to extract semantic representations from user textual data. First, user review embeddings are clustered to capture high-level semantic preferences, where cluster indices are utilized as ordered categorical features. Second, rating rank similarity features are constructed by comparing the relative ranking of items rated by similar users. These features are fused and fed into a CNN model, which outputs a predicted rating class (e.g., 1–5 stars) for each unobserved item, treated as a single-label classification target. To generate final Top-N recommendations, we further incorporate user-specific rating habits and item popularity to re-rank the classification outputs. The experimental results on public benchmark datasets indicate that our model substantially improves the prediction accuracy and recommendation quality compared with existing baselines. The proposed method offers a robust and interpretable approach to bridging textual review semantics, user behavior, and deep learning for rating-aware personalized recommendation.},
  archive      = {J_EAAI},
  author       = {Yanjun Xu and Chunqi Tian and Wei Wang and Lizhi Bai},
  doi          = {10.1016/j.engappai.2025.112196},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112196},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semantic analysis-based recommender system using sequential clustering and convolutional neural network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ranking-oriented cross-modal hashing. <em>EAAI</em>, <em>161</em>, 112195. (<a href='https://doi.org/10.1016/j.engappai.2025.112195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep cross-modal hashing has become a mainstream solution for multimedia retrieval. Most methods utilize pair-wise or multi-wise loss as proxies for ranking consistency, focusing primarily on local relational patterns. However, these schemes are not well aligned with global ranking metrics, which consider the relative order among all candidate items. This misalignment may push semantically similar items down the list. Additionally, such methods heavily rely on the selection of negative samples, which can cause training instability and require careful tuning. To address this problem, we propose a novel Ranking-Oriented Cross-Modal Hashing (ROCMH) framework, which performs global ranking optimization based on a vision-language model. Specifically, we design a differentiable ranking-oriented objective, called cross-modal ranking alignment loss. It smoothly simulates discrete ranking and naturally models ranking relations in candidate lists, thereby promoting more consistent cross-modal ranking. Meanwhile, considering the perceptual gap between visual and textual, we suggest a nanoparam training strategy with modality-aware prompts. This strategy greatly reduces the number of trainable parameters while ensuring that each modality provides unique signals for semantic information learning. Extensive experiments on three public datasets demonstrate that the method achieves superior retrieval performance and reduces the number of trainable parameters to less than 0.2% of the vision-language model. The source code is available: https://github.com/QinLab-WFU/ROCMH .},
  archive      = {J_EAAI},
  author       = {Yadong Huo and Qibing Qin and Wenfeng Zhang and Lei Huang},
  doi          = {10.1016/j.engappai.2025.112195},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112195},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ranking-oriented cross-modal hashing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Matching quality-guided model-free satellite pose estimation. <em>EAAI</em>, <em>161</em>, 112194. (<a href='https://doi.org/10.1016/j.engappai.2025.112194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of learning-based techniques and large-scale public datasets, satellite pose estimation has seen significant progress for the past several years. However, most of current methods still rely on a known three-dimensional (3D) model of the object for the pose estimation, limiting its generalization and wide application. To this end, we propose a model-free pose estimation method, which takes as input only a set of images. The proposed method consists of two stages, i.e. the reconstruction stage and pose estimation stage, of which the former reconstructs a 3D model from the input images and the pose is estimated via two-dimensional (2D)-3D feature matching by the latter. More importantly, a matching quality guidance strategy is introduced to further improve the robustness to in-plane rotation during feature matching. Additionally, since no known 3D model is assumed, our method generalizes well to novel objects without retraining. We provide evaluation results on datasets of several satellites with different structures, which demonstrate impressive performances without known models against current methods.},
  archive      = {J_EAAI},
  author       = {Zhaoshuai Qi and Yating Liu and Yanning Zhang},
  doi          = {10.1016/j.engappai.2025.112194},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112194},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Matching quality-guided model-free satellite pose estimation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prebuilt spatiotemporal index: An exploration of efficient real-time data storage in intelligent transportation systems. <em>EAAI</em>, <em>161</em>, 112193. (<a href='https://doi.org/10.1016/j.engappai.2025.112193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread deployment of Internet of Things (IoT) devices in Intelligent Transportation Systems (ITS), real-time spatiotemporal data has grown rapidly. Hybrid data-bases have emerged as the mainstream solution for managing such data. The LSM R*-tree, which integrates Log-Structured Merge-trees (LSM-trees) for time-series ingestion and R*-trees for spatial queries, is now a widely used spatiotemporal index. However, storage schemes based on LSM R*-tree structures involve real-time index construction, leading to significant overhead and write latency. To address these challenges, this paper proposes a prebuilt index-based data storage workflow that shifts index construction ahead of data writing. This approach allows the database to directly apply the prebuilt index at write time, thereby minimizing real-time construction costs and enhancing write performance. To support index prebuild, we propose a lightweight embedding scheme, Index2Vec, specifically designed for R*-tree structures. Based on this, we extend the Transformer architecture and develop the R*-tree Prediction Network for ITS (RTPN4ITS), which achieves efficient inference on resource-constrained edge devices. Experimental results show that the prebuilt R*-tree index improves query efficiency by up to 90% over time-index-only schemes and enhances write performance by nearly 50% compared to real-time indexing. The proposed RTPN4ITS model achieves robust accuracy across varying traffic densities, reaching 85% accuracy in dense conditions. Moreover, the Index2Vec embedding enhances the Transformer’s structural awareness. In summary, this paper proposes an efficient prebuilt indexing strategy and lightweight embedding-based model for real-time spatiotemporal data management in ITS.},
  archive      = {J_EAAI},
  author       = {Yiran Shao and Kangshuai Zhang and Yong Zhou and Zhenwu Chen and Yang Yang and Lei Peng},
  doi          = {10.1016/j.engappai.2025.112193},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112193},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prebuilt spatiotemporal index: An exploration of efficient real-time data storage in intelligent transportation systems},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An error complementarity-based iterative learning approach via categorical boosting for student performance prediction. <em>EAAI</em>, <em>161</em>, 112192. (<a href='https://doi.org/10.1016/j.engappai.2025.112192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting student performance is important in achieving academic success and student development in many educational applications (e.g., academic early warning and early interventions). To accurately predict student performance, we propose an error complementarity-based iterative learning approach for student performance prediction. Our goal is to improve the prediction performance by iteratively reducing the prediction error. Specifically, in model construction, we first select the most important features to train the target estimator. Then, we obtain the errors between the target and predicted values. These errors are used to train the error estimator using the remaining features. Similarly, we iteratively train the model to learn from the errors until the desired conditions are met. In model prediction, we predict the testing sample using the target estimator to obtain the predicted value. Next, we predict the error for the next iteration using the corresponding error estimator. This process is repeated, and the final prediction is obtained by adding the predicted value and the error values. The extensive experiments from different educational datasets show that by using our error complementarity-based iterative learning approach, the proposed model outperforms the competing models for prediction accuracy. Furthermore, statistical testing conducted over 20-run experiments confirms the significant advantage of our proposed model. This suggests the iterative learning is effective for predicting student performance.},
  archive      = {J_EAAI},
  author       = {Zongwen Fan and Jin Gou and Cheng Wang},
  doi          = {10.1016/j.engappai.2025.112192},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112192},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An error complementarity-based iterative learning approach via categorical boosting for student performance prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated cross-device cluster dynamic time planning warping algorithm in the industrial internet of things. <em>EAAI</em>, <em>161</em>, 112191. (<a href='https://doi.org/10.1016/j.engappai.2025.112191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Production lines and heterogeneous devices generate diverse time-series data in the Industrial Internet of Things (IIoT). This diversity necessitates frequent updates of local models when using federated learning (FL). FL has become widespread in the IIoT, these continual model updates can hinder timely information exchange among cross-industry devices. They constrain the system's ability to handle high concurrency in read and write operations. Therefore, we propose a federated cross-device cluster dynamic time planning warping (Fed-cDTW) tailored for the IIoT. We incorporate each device's historical behavior data by constructing a functional characteristic distance matrix. We design a symmetric time warping lower bound function to measure the similarity among multi-source time-series data. This approach enables an adaptive, dynamically organized industrial device cluster. Meanwhile, we employ the federated dynamic (FedD) dual-weight optimization within the device cluster to enhance the models' generalization and robustness. The experimental results evaluated the performance of the proposed method. We compare our method with baselines, Fed-cDTW improves classification accuracy by 0.8 percentage points (pp), 1.7 pp, 9.6 pp, 14.4 pp, and 49.5 pp. Convergence is accelerated by 0.04, 0.05, 0.35, 0.42, and 0.46. Total communication cost is reduced by 40 megabytes (MB), 56 MB, 84 MB, 120 MB, and 168 MB.},
  archive      = {J_EAAI},
  author       = {Yifan Zhao and Shibao Sun and Pengcheng Zhao and Yatong Wang and Jianfeng Liu},
  doi          = {10.1016/j.engappai.2025.112191},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112191},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Federated cross-device cluster dynamic time planning warping algorithm in the industrial internet of things},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based prediction of compressive strength in sustainable self-compacting concrete. <em>EAAI</em>, <em>161</em>, 112190. (<a href='https://doi.org/10.1016/j.engappai.2025.112190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance and durability of conventional concrete (CC) is significantly influenced by supplementary cementitious materials (SCMs) and recycled coarse aggregate (RCA). Thus, the intrusion of enrich SCMs with RCA in the cementitious matrix delivers utmost properties. This research focuses on the use SCMs and RCA in the self-compacting concrete (SCC) system and their sustainability in the development of concrete resources. Standard experimental methods for forecasting the compressive strength (CS) of SCC have constraints in terms of efficiency, time consumption, and cost. Thus, its prediction is crucial without the need for laborious experimental procedures. This work employs and evaluates a multiplicity of machine learning (ML) models to predict the CS of the cementitious matrix to tackle these issues. Thus, considered a more effective and cost-saving solution in comparison with traditional approaches. Therefore, ML approaches like, gene expression programming (GEP), decision trees (DT), and support vector regression (SVR) were employed. The performance of the model is evaluated by employing the coefficient of determination (R 2 ), statistics, and uncertainty analysis. Individual Conditional Expectation (ICE), and Partial Dependence Plot (PDP) are used to analyze the effect of parameters on strength. The findings suggest that GEP performs best achieving superior R 2 > 0.90 for the training, validation, and test data sets with a lower error. While, the uncertainty analysis shows that all modeled values lie below the threshold value. The ICE and PDP graphs confirms that cement, age, and water-cement ratio have highly relation to outcomes. The RCA replacement ratio is more important than the CA one, and SCMs play an essential role in the development of concrete compressive strength, although not as much as cement. In addition, SP depicts major contribution to SCC. Moreover, graphical user interface (GUI) is also developed to help users/researcher that will facilitate them to estimate the strength of SCC in practical applications.},
  archive      = {J_EAAI},
  author       = {Jingguo Gou and Athar Zaman and Furqan Farooq},
  doi          = {10.1016/j.engappai.2025.112190},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112190},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning-based prediction of compressive strength in sustainable self-compacting concrete},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust fuzzy twin support vector machine with kernel-target alignment for binary classification. <em>EAAI</em>, <em>161</em>, 112189. (<a href='https://doi.org/10.1016/j.engappai.2025.112189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many algorithms similar to the twin version of the support vector machine and their variants have shown better results in the binary classification of nonlinear data points. But in the presence of outlier and noise, these algorithms exhibit low generalization efficiency. To alleviate this challenge, recently proposed, kernel-target alignment based fuzzy least square twin bounded support vector machine (KTA-FLSTBSVM) used fuzzy membership values and is solved using least squares. Inspired by this strategy, for further improvement, we propose a novel approach called decision support kernel-target alignment based fuzzy least square twin bounded support vector machine (DS-KFIFTBSVM). DS-KFIFTBSVM considers the kernelized fuzzy membership values with the regularized twin support vector machine and solves for linear and nonlinear data points using a functional iterative approach. In DS-KFIFTBSVM, the solution is obtained by solving a linearly convergent iterative scheme rather than solving quadratic programming problems. The proposed DS-KFIFTBSVM offers better generalization efficiency, which has been evaluated using both linear and Gaussian kernels, mostly on artificially developed and publicly accessible datasets with diverse dimensionalities. In terms of various performance evaluation metrics, including specificity, precision, false positive rate, rate of misclassification error, F_score, and geometric mean in linear and non-linear cases, DS-KFIFTBSVM outperforms various baseline approaches. It shows the highest accuracy in various datasets, including 98.1884 % for musk dataset (linear kernel) and 100 % for the glass dataset (Gaussian kernel). Further statistical analysis confirms its classification efficiency.},
  archive      = {J_EAAI},
  author       = {Deepak Gupta and Barenya Bikash Hazarika and Umesh Gupta and Witold Pedrycz},
  doi          = {10.1016/j.engappai.2025.112189},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112189},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust fuzzy twin support vector machine with kernel-target alignment for binary classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive assessment of pore-scale segmentation techniques for image-based multiphase flow characterization in porous media. <em>EAAI</em>, <em>161</em>, 112188. (<a href='https://doi.org/10.1016/j.engappai.2025.112188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation of multiphase fluid flow behavior based on pore-scale imaging is significantly influenced by the accuracy of the segmentation techniques. This study sheds light on the influence of various traditional and Artificial Intelligence (AI) algorithms on the major static, dynamic, volumetric, and topological properties of the porous media. The traditional methods include the Gaussian Mixture Model (GMM), Multi-Otsu’s thresholding (MOT), and Random Walk (RW), and the AI-based techniques include Trainable Weka (TW), as well as seven deep convolutional autoencoder architectures. The assessment was carried out by comparing the calculated phase fraction, contact angle, capillary pressure, effective permeability, and topology for multiphase flow images of Bentheimer sandstone. The results revealed that combining Residual Networks (ResNet) and UNet structures (UResNet) marginally performs better based on the statistical metrics. Compared to ground-truth watershed images, applying other approaches except TW yielded acceptable static and volumetric parameters. The main discrepancies were in contact angles, capillary pressure, and phase topology. These discrepancies also influenced calculated effective permeabilities, yielding unrealistic trends. UResNet provided the best accuracy, considering the watershed the ground truth. MOT and RW showed similar performance, while GMM performed inconsistently throughout the analysis and TW produced acceptable results for certain fractional flows. The segmentation approaches affected topological features most, whereas properties such as phase fractions were less affected. The inconsistent behavior and effectiveness of used algorithms indicate that the analysis of multiphase images necessitates a meticulous choice of segmentation techniques, emphasizing AI-based algorithms that ensure consistency across all evaluations.},
  archive      = {J_EAAI},
  author       = {Javad Siavashi and Mohammad Sharifi},
  doi          = {10.1016/j.engappai.2025.112188},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112188},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comprehensive assessment of pore-scale segmentation techniques for image-based multiphase flow characterization in porous media},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Land use and land cover change detection from multisource satellite imagery – A hybrid convolutional neural network approach. <em>EAAI</em>, <em>161</em>, 112187. (<a href='https://doi.org/10.1016/j.engappai.2025.112187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing and satellite imagery analysis enable us to observe and understand environmental changes over time. However, such an endeavor can be complex and time-consuming. To overcome this challenge, we propose a framework for leveraging Google Earth Engine (GEE) to analyze Earth's surface changes over time. Our framework starts by assessing land cover changes using satellite imagery, evaluating the effectiveness of vegetation indices in classification, and generating accurate land cover maps for a specific region. We examine the validity of this framework on the area near Rio Do Sul, located in the Santa Catarina district of Brazil, to classify and recognize the alteration in land use and land cover (LULC) from 2019 to 2023. In this effort, we develop a pre-trained Convolutional Neural Network (CNN) for feature extraction from the Landsat 8, Sentinel-1, and Sentinel-2 images and then link those into the random forest (RF) algorithm for spatial morphology and temporal change logic to map the long-term annual time series and detect changes in the region at hand. The novelty of this study arises from developing a CNN-RF hybrid model and implementing a data preprocessing pipeline, which includes progressive techniques for cloud masking and radiometric calibration, to ensure higher accuracy and reliability in land use and land cover classification. This CNN-RF hybrid model successfully traced the increasing and decreasing rate in the built-up area, water bodies, forest, fallow land, plantations, and grassland with an overall accuracy of 96.39 % and 94.15 % for 2019 and 2023, respectively.},
  archive      = {J_EAAI},
  author       = {M.S. Babitha and A. Diana Andrushia and N. Anand and M.Z. Naser and Y. Pari},
  doi          = {10.1016/j.engappai.2025.112187},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112187},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Land use and land cover change detection from multisource satellite imagery – A hybrid convolutional neural network approach},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safety monitoring digital twin-based centralized model consolidation mechanism using dynamic node selection for multi-worker safety prediction. <em>EAAI</em>, <em>161</em>, 112186. (<a href='https://doi.org/10.1016/j.engappai.2025.112186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction industry remains one of the most hazardous sectors, requiring innovative solutions to safeguard workers, especially in complex, dynamic outdoor environments. Digital Twin (DT) technology offers promising capabilities for real-time safety monitoring through virtual replicas of physical systems. However, existing DT frameworks rarely integrate comprehensive safety monitoring via a centralized model consolidation mechanism, such as Federated Learning (FL), which is explicitly tailored for multi-worker scenarios. Addressing this challenge, this paper proposes a FL-based Safety Monitoring Digital Twin (SMDT) framework designed to enhance multi-worker safety in resource-constrained settings. This enables real-time safety monitoring and control by representing on-site workers as virtual objects within a synchronized DT environment. A dynamic node selection mechanism based on client performance is employed to optimize global model convergence in FL. To validate the proposed approach, an edge computing-based experimental testbed using actual Raspberry Pi devices was implemented, using real-world construction safety data including worker status, weather conditions, and building structural parameters. Experimental results demonstrate the effectiveness of the proposed framework in significantly improving safety predictions and real-time monitoring efficiency. This research establishes a foundational work towards safer construction sites through intelligent, synchronized safety monitoring systems.},
  archive      = {J_EAAI},
  author       = {Sa Jim Soe Moe and Atif Rizwan and Anam Nawaz Khan and Rongxu Xu and Do Hyeun Kim},
  doi          = {10.1016/j.engappai.2025.112186},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112186},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Safety monitoring digital twin-based centralized model consolidation mechanism using dynamic node selection for multi-worker safety prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Universal entity linking. <em>EAAI</em>, <em>161</em>, 112185. (<a href='https://doi.org/10.1016/j.engappai.2025.112185'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity linking is a process of connecting mentions of entities in a document to corresponding entries in a knowledge base. Traditional models for entity linking often require specific fine-tuning to work with knowledge bases other than those they were originally pretrained on, which limits their flexibility and scalability. Building on the concept of entity profile generation, we propose a novel approach that enables entity linking across various knowledge bases without the need for such fine-tuning. Our pipeline leverages a fine-tuned Large Language Model, a generic embedding model, and a vector store to achieve high precision on the TweekiGold and Reuters-128 datasets. Additionally, it demonstrates strong retrieval rates across the TweekiGold , Reuters-128 , and ISTEX-1000 Wikidata entity linking datasets. We also illustrate the applicability of our method to other knowledge bases, using the Agrovoc knowledge base as an example. This solution offers a more versatile and scalable approach to entity linking.},
  archive      = {J_EAAI},
  author       = {Adam Aron Rynkiewicz and Raul Palma and Piotr Formanowicz},
  doi          = {10.1016/j.engappai.2025.112185},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112185},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Universal entity linking},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A search method for fractured-vuggy reservoir inter-well connectivity path based on multi-modal multi-agent. <em>EAAI</em>, <em>161</em>, 112184. (<a href='https://doi.org/10.1016/j.engappai.2025.112184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex geological structure of carbonate reservoirs and the intricate fracture-vuggy configurations obscure inter-well connectivity, making its evaluation challenging. Conventional studies primarily rely on seismic static data to delineate fracture-vuggy reservoirs, but the limited recognition accuracy hampers the precise characterization of inter-well connectivity and the spatial configuration of fractures and vugs. To address this, this study constructs a 3D (Three-Dimensional) search environment and use multi-modal static and dynamic data and proposes a multi-agent connected channel search model based on deep reinforcement learning. The model treats multiphase fluid as an agent and incorporates Swin Transformer (Shift Window Transformer) to extract large-scale fracture features from seismic data, providing global prior information for path search. A Graph Attention Network is established based on dynamic response relationships to extract spatial geological features, while a multi-head self-attention mechanism captures real-time fluid interactions in various directions. The model fuses multi-modal features, including seismic attributes and production data, to generate decisions and automatically search for inter-well connectivity channels. Experiments were conducted using the WE1 and WE5 well groups from the fault-controlled karst reservoirs in the Tahe oilfield, with results compared against tracer tests. The findings demonstrate that the proposed model's automatic search paths closely align with seismic data and tracer test results, effectively capturing the spatial distribution of fractures and vugs across different scales. This validates the model's effectiveness in evaluating inter-well connectivity in complex carbonate reservoirs.},
  archive      = {J_EAAI},
  author       = {Wenbin Jiang and Dongmei Zhang and Hong Cao and Xiaofeng Wang},
  doi          = {10.1016/j.engappai.2025.112184},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112184},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A search method for fractured-vuggy reservoir inter-well connectivity path based on multi-modal multi-agent},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continuous spatio temporal prompts for visual tracking. <em>EAAI</em>, <em>161</em>, 112183. (<a href='https://doi.org/10.1016/j.engappai.2025.112183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, visual single-object tracking methods utilize online template updates to combine temporal information. However, these methods rely on confidence scores to evaluate the reliability of the current template, which may result in a template not being updated for an extended period. Moreover, advanced trackers select bounding boxes based solely on the similarity between the template and the search area, which can lead to tracking drift when encountering deformable or similar targets. To alleviate these limitations, we propose a Spatio Temporal Prompt Tracker (STPTrack), which utilizes the prior information about small changes of object state between successive frames. Different from previous tracking methods that mainly rely on templates and similarity scores, STPTrack transfers the object position and shape information of the previous frame to the current frame as continuous spatio temporal prompt for the first time, and realizes the efficient fusion of spatio temporal information through the prompt encoder and the fusion decoder module. Specifically, it encodes the bounding box coordinates or mask information of the previous frame and the response points of the current frame as prompt features, and then combines prompt tokens with search tokens through the fusion decoder to provide the potential location of the object for the search feature map. Our STPTrack sets a new state-of-the-art performance on six tracking benchmark datasets.},
  archive      = {J_EAAI},
  author       = {Meng Sun and Xiaotao Liu and Yifan Li and Hongyu Wang and Dian Yuan and Jing Liu},
  doi          = {10.1016/j.engappai.2025.112183},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112183},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Continuous spatio temporal prompts for visual tracking},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Length-aware center loss for sequence to sequence thai scene text recognition. <em>EAAI</em>, <em>161</em>, 112182. (<a href='https://doi.org/10.1016/j.engappai.2025.112182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thai scene text recognition is a challenging task because Thai can be written in both horizontal and vertical directions, allowing characters to be stacked vertically. To address this issue, our previous work combined vertically stacked characters to create new characters. However, this strategy introduced many similar characters. In this paper, we further investigate this problem and propose the Length-aware Center Loss (LC) for Thai scene text recognition. The original center loss was designed for single object recognition tasks. When applied to multi-label tasks like text recognition, center loss is only effective when the lengths of the labels and prediction results are consistent. This can lead to an extreme case where all images receive incorrect predicted text lengths to minimize loss, severely interfering with the recognition process. Therefore, we propose the Length-aware Center Loss for text recognition. We also design the Length Supervision Module (LSM) and the Feature Clustering Module (FCM) to work alongside the LC loss. LSM predicts text length to provide additional supervision signals, while FCM aims to improve recognition performance by minimizing the distance between the features of corresponding class centers. Since there is no publicly available Thai scene text dataset, we have collected a new dataset containing more than 170,000 samples. Extensive experiments conducted on this dataset show that our method achieves superior performance in both string-level and character-level accuracy compared to other methods.},
  archive      = {J_EAAI},
  author       = {Hongjian Zhan and Chun Li and Bing Yin and Yue Lu},
  doi          = {10.1016/j.engappai.2025.112182},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112182},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Length-aware center loss for sequence to sequence thai scene text recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-based vision-language model for zero-shot anomaly detection in medical images. <em>EAAI</em>, <em>161</em>, 112181. (<a href='https://doi.org/10.1016/j.engappai.2025.112181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of diagnostic technology, the ability to detect pathological areas such as tumors and polyps has significantly improved. This progress provides medical imaging specialists with more precise visual information to support anomaly identification, diagnosis, treatment planning, and patient monitoring. However, existing unsupervised and semi-supervised anomaly detection methods struggle with data privacy constraints, limited annotated medical datasets, and challenges in generalization. Zero-Shot Anomaly Detection (ZSAD), which enables the detection of unseen categories without requiring class-specific training, has emerged as a promising solution by leveraging the vision-language alignment capabilities of Vision-Language Models (VLMs), such as Contrastive Language-Image Pretraining (CLIP). Despite recent progress, ZSAD remains hindered by high noise levels, sparse targets, and poor adaptability in complex medical imaging scenarios. To address these issues, we propose a novel framework: DiffusionCLIP, a diffusion-based VLM for zero-shot anomaly detection in two-dimensional medical images. Specifically, DiffusionCLIP integrates diffusion models into the VLM to progressively denoise multi-level features extracted from the CLIP visual encoder, enhancing feature robustness and discriminability. A multi-level feature fusion strategy is designed to aggregate multi-scale representations from different depths of the visual encoder, ensuring complementary semantic alignment across layers. In addition, a dynamically modulated weight loss function is introduced to adaptively balance the learning of hard and easy samples, further improving model generalization. Extensive experiments on multiple benchmark medical imaging datasets, demonstrate that the proposed method significantly outperforms existing zero-shot anomaly detection approaches in terms of accuracy, robustness, and generalization.},
  archive      = {J_EAAI},
  author       = {Yanhui Chen and Hongkang Tao and Zan Yang and Yunkang Cao and Chen Jiang and Longhua Hu and Pengwen Xiong and Haobo Qiu},
  doi          = {10.1016/j.engappai.2025.112181},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112181},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Diffusion-based vision-language model for zero-shot anomaly detection in medical images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surface roughness prediction in turning processes for grey cast iron: A hybrid machine learning approach integrating infrared thermography. <em>EAAI</em>, <em>161</em>, 112180. (<a href='https://doi.org/10.1016/j.engappai.2025.112180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workpiece surface quality is a critical control parameter in machining processes, influencing functional performance, dimensional precision, and wear resistance. However, accurately predicting surface roughness is complex, often limited by the computational demands of traditional high-precision methods and the reliance of existing models solely on cutting parameters, hindering real-time monitoring. This research introduces a hybrid Artificial Neural Network (ANN) methodology specifically developed for predicting surface roughness of grey cast iron GG-25 workpieces machined in turning processes, a material previously unstudied in this context. The methodology integrates real-time infrared thermal measurements from multiple defined regions of interest (ROIs) within the tool-workpiece contact zone, along with cutting parameters. Experimental results demonstrated that feed rate (f) is the most significant cutting parameter (effect = 0.43) affecting surface quality, followed by its combination with cutting speed (V c ) (effect = −0.25) and cutting speed (effect = 0.18). Correlation and non-linear regression analyses revealed complex, often exponential relationships between temperature and surface roughness, showing temperature an upward trend as machining progressed. The developed ANN achieves a correlation coefficient (R) value of 0.99 both when predicting the roughness arithmetic mean deviation (Ra) parameter in training conditions and when using data from experiments not used in training (validations data). Moreover, the model reaches a correlation coefficient value of 0.85 (test data) under cutting conditions different from those used in experiments, demonstrating robustness, significantly outperforming Support Vector Regression (SVR). This model represents a highly potential tool for real-time online inspection.},
  archive      = {J_EAAI},
  author       = {Sergio Aguado and Marcos Pueo and Raquel Acero and Ana Cristina Majarena and Jorge Santolaria},
  doi          = {10.1016/j.engappai.2025.112180},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112180},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Surface roughness prediction in turning processes for grey cast iron: A hybrid machine learning approach integrating infrared thermography},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Legendre multiwavelet-based feature attention guidance lightweight network for accurate steel surface defect classification. <em>EAAI</em>, <em>161</em>, 112179. (<a href='https://doi.org/10.1016/j.engappai.2025.112179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steel surface defects can significantly affect the quality and appearance of industrial products such as aerospace, construction application fields, and so on. Due to the multi-scale morphology, low contrast, and random positions of the defects, achieving a favorable balance between detection accuracy and speed remains challenging in practical applications. To address these challenges, this paper combines Legendre multiwavelet (LW) with feature attention guidance (FAG) mechanism to devise a novel high-accuracy lightweight network (LWFAG-LNet) for surface defect classification. More precisely, LW bases with rich regularities are first utilized to match complex geometric characteristics across multi-wavelet and multi-scale resolution levels. Subsequently, the FAG module effectively fuses shallow high-resolution detailed features with deep low-resolution contextual features, significantly reducing the depth of the convolutional neural network (CNN). To the third step, a lightweight CNN module with four convolutional blocks is designed to further extract deep features while preserving the most valuable defect information. The proposed model achieves the highest recognition accuracy with a simple structure and a compact parameter configuration. Extensive experiments are conducted on the Northeastern University-Classification (NEU-CLS), Xsteel surface defect dataset (X-SDD), and Kungliga Tekniska Högskolan Royal Institute of Technology Textures under varying Illumination, Pose and Scale (KTH-TIPS) dataset to verify the model's effectiveness and generalization capability. The results reach classification accuracies of 99.80 %, 98.49 %, and 99.06 %, outperforming existing models by about 1.45 %, 3.45 %, and 2.04 %, respectively. In summary, the proposed LWFAG module can be flexibly applied to various lightweight network frameworks, demonstrating great potential for real-time surface defect detection.},
  archive      = {J_EAAI},
  author       = {Xiaoyang Zheng and Weishuo Liu and Yan Huang},
  doi          = {10.1016/j.engappai.2025.112179},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112179},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Legendre multiwavelet-based feature attention guidance lightweight network for accurate steel surface defect classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting object hue bin in the CIECAM02 uniform color space using a multi-layer perceptron for optimal spectrum generation. <em>EAAI</em>, <em>161</em>, 112178. (<a href='https://doi.org/10.1016/j.engappai.2025.112178'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an innovative enhancement to an existing multi-channel light-emitting diode luminaire by integrating artificial intelligence and image analysis capabilities. The system captures an image of the object to be illuminated using a custom-developed Android application. The dominant color in the image is first identified, and then a multi-layer perceptron neural network classifies it into one of 16 hue bins within a uniform color appearance model. This classification process enables the luminaire to select a predefined spectrum designed to enhance the visual appeal of the illuminated object. To ensure robust hue bin classification, we developed a rich dataset with 7920 samples, collected using eleven smartphones under ten distinct light sources. Using this diverse dataset, thirteen multi-layer perceptron neural networks with varying input features were trained and compared, achieving hue classification accuracies, precision, and recall all ranging from 95 % to 99 % on the test set. One of the trained multi-layer perceptron networks was integrated into the Android application, with an inference time of 90 μs on a mid-range smartphone, demonstrating the practical application of artificial intelligence for on-demand hue analysis and lighting optimization. This advancement not only enhances the luminaire's functionality but also enriches the user experience by providing intelligent, on-demand lighting solutions tailored to the object's dominant color.},
  archive      = {J_EAAI},
  author       = {Esmat Kishani Farahani and Kaveh Ahmadian Tazehmahaleh},
  doi          = {10.1016/j.engappai.2025.112178},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112178},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting object hue bin in the CIECAM02 uniform color space using a multi-layer perceptron for optimal spectrum generation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized zero-shot fault diagnosis method for chillers based on cross-modal information compression. <em>EAAI</em>, <em>161</em>, 112177. (<a href='https://doi.org/10.1016/j.engappai.2025.112177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical chiller fault diagnosis applications, target fault training data is often inaccessible, which poses significant challenges to the effectiveness of data-driven diagnostic approaches. Generalized zero-shot fault diagnosis (GZSFD) aims to detect and classify all fault types without relying on fault samples from all categories during training. GZSFD models are trained exclusively on data from seen faults—those with available historical data—making them prone to bias toward these seen classes during inference. However, existing methods fail to exploit the fine-grained semantics of fault attributes, resulting in suboptimal performance when addressing feature bias toward seen classes. In this article, an innovative GZSFD framework for chillers based on cross-modal information compression is proposed to overcome this difficulty. This method constructs a cross-modal feature fusion attention (CmFFA) and information compression module, and integrates them into a variational autoencoder with generative adversarial network (VAEGAN), and establishes a CmFFA-VAEGAN network to synthesize high-quality unseen fault samples. Specifically, the CmFFA module effectively aligns local regions of the virtual samples with key words in the textual attributes, enabling the model to attend to fine-grained semantic information and robustly fuse features from different modalities. This facilitates the generation of virtual samples that more accurately reflect the characteristics of the target modality. In addition, an information bottleneck (IB) layer is introduced at the output of the generator to compress redundant information within the fused features, retaining only the key information most relevant to the data augmentation task. This design enhances cross-modal consistency between the synthesized samples and their corresponding attributes, while alleviating the feature shift of unseen class samples toward seen categories. Extensive experiments are designed and executed on the chiller dataset. Experimental results demonstrate that the proposed framework effectively mitigates the bias of synthesized unseen fault samples toward seen categories, leading to a significant improvement in diagnostic accuracy.},
  archive      = {J_EAAI},
  author       = {Kexin Jiang and Xuejin Gao and Huayun Han and Huihui Gao and Yongsheng Qi and Xi Zhang and Liang Zhao},
  doi          = {10.1016/j.engappai.2025.112177},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112177},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generalized zero-shot fault diagnosis method for chillers based on cross-modal information compression},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing rotation you only look once version 8 for accurate detection of arbitrarily-oriented and multi-scale construction material in complex environment. <em>EAAI</em>, <em>161</em>, 112176. (<a href='https://doi.org/10.1016/j.engappai.2025.112176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Construction material detection is integral to effective material management. While deep learning-based methods have advanced automatic detection, challenges such as arbitrarily oriented objects, similar features, large object scale variations, and noise interference still limit accuracy. This study proposes an enhanced detection method based on improved rotation you only look once version 8, incorporating three key innovations. First, the large selective kernel network employs a spatial selection mechanism to dynamically adjust the network's receptive field, capturing key features and contextual information of various materials in complex construction scenarios. This enhances object detection performance in feature-similar environments. Second, the poly kernel inception network combines non-dilated multi-scale convolutions to extract dense texture features from differently sized objects, while using contextual anchor attention to capture long-range information for small objects. These components work together to improve multi-scale object detection. Third, the rectangular self-calibration module uses horizontal and vertical pooling to model rectangular attention regions, capturing axial global context. Its shape self-calibration function adjusts these regions to better fit arbitrarily oriented construction materials, enhancing focus on objects while suppressing noise interference. Experimental results show a mean average precision of 0.871–2.7 % higher than the baseline model and surpassing other state-of-the-art methods—while maintaining real-time detection speed at 28.3 frames per second. The proposed method improves material detection accuracy in complex construction environments, enabling refined material management on-site. This supports material entry and exit tracking, on-site usage monitoring, inventory management, and procurement planning, while also strengthening lean control of construction progress and costs.},
  archive      = {J_EAAI},
  author       = {Yujie Lu and Yuanjun Nong and Dayu Zhu and Shuo Wang},
  doi          = {10.1016/j.engappai.2025.112176},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112176},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing rotation you only look once version 8 for accurate detection of arbitrarily-oriented and multi-scale construction material in complex environment},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-term forecasting of monthly reservoir inflow using deep and machine-learning-based algorithms. <em>EAAI</em>, <em>161</em>, 112175. (<a href='https://doi.org/10.1016/j.engappai.2025.112175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study provides a method for dynamic flow forecasting to detect how to move between periods with high and low-flow peaks. In other words, the model continues by gaining a deep insight into the long-term stable changes of the time series. Four-time horizons (5, 10, 15 and 20 years) were chosen to forecast the streamflow. These time horizons represent the ability of this method to detect the continuation of its movement in the short, medium, and long term. In this study, a dynamic and recurrent cycle is used to forecast river streamflow based on long-short-term memory (LSTM) and artificial neural network (ANN) models. The 12-month time delay of precipitation and streamflow of the Zayanderud river from 1970 to 2019 was used as input variables for training and validation of the models. In each stage of the forecasting process, 1 year (12 months) is forecasted and used as input for the next stage. The results show that the ANN model performs better in shorter time horizons and the LSTM model in longer time horizons, respectively. The best performance of the ANN model occurs in the 10-year forecast (Mean Absolute Percentage Error (MAPE) = 44.3, Nash–Sutcliffe efficiency coefficient (NSCE) = 0.58, Root Mean Square Error (RMSE) = 43.75) and the best performance of the LSTM model occurs in the 15-year forecast (MAPE = 48.9, NSCE = 0.54, RMSE = 47.12). Finally, the selected period is used to forecast the streamflow in future periods when observational data are not available.},
  archive      = {J_EAAI},
  author       = {Bahram Ghenaati and Mohammad Reza Nikoo and Mohammad G. Zamani},
  doi          = {10.1016/j.engappai.2025.112175},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112175},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long-term forecasting of monthly reservoir inflow using deep and machine-learning-based algorithms},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characteristics detection of surface agglomerated abrasive on electroplated diamond wire: A measurement method based on semantic segmentation. <em>EAAI</em>, <em>161</em>, 112173. (<a href='https://doi.org/10.1016/j.engappai.2025.112173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroplated Diamond Wire (EDW) serves as the primary tool for cutting semiconductor materials. Abrasive agglomeration on its surface induces sudden fluctuations in sawing force, exacerbates material surface damage, and shortens tool lifespan. However, existing testing methods primarily focus on abrasive counts while generally lacking effective means to quantify key characteristics of agglomerated abrasives (e.g., density, maximum size, and number of abrasives contained), leading to substantial limitations in the EDW quality assessment system. To address this critical gap, this study proposes a U-shape Network (UNet)-based semantic segmentation model for EDW surface abrasive grain segmentation, termed Electroplated Diamond Wire U-shape Network (EDW-UNet). By integrating Atrous Spatial Pyramid Pooling (ASPP) and Mamba-like Linear Attention (MLLA), EDW-UNet enhances the detection of multi-scale targets and the accuracy of complex boundary segmentation, enabling precise segmentation of both single and agglomerated abrasives on EDW surfaces. Experimental results demonstrate that EDW-UNet achieves a mean Intersection over Union of 0.917 and a mean Pixel Accuracy of 0.961 on the test set, outperforming the baseline UNet and other mainstream models, with an inference speed of up to 12.82 frames per second. For the first time, a feature extraction algorithm developed from the segmentation results enables measurement of key parameters, including the density, maximum size, and number of abrasives contained in agglomerates. This study not only addresses the technical gap in quantitative detection of agglomerated abrasive features but also provides a novel high-precision, quantitative standard for optimizing EDW manufacturing processes and assessing product quality, thereby enhancing the cutting efficiency and yield of semiconductor materials. The code is available at: https://github.com/huangwenbin123/EDW-UNet .},
  archive      = {J_EAAI},
  author       = {Wenbin Huang and Yufei Gao and Shengtan Hu and Dameng Cheng},
  doi          = {10.1016/j.engappai.2025.112173},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112173},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Characteristics detection of surface agglomerated abrasive on electroplated diamond wire: A measurement method based on semantic segmentation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk-response coupling in underground structures under liquefiable soil conditions: A causality-informed dynamic bayesian network integrated framework. <em>EAAI</em>, <em>161</em>, 112171. (<a href='https://doi.org/10.1016/j.engappai.2025.112171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underground structures in liquefiable soils face complex seismic risks that can trigger cascading failures. This study proposes a Granger causality-informed Dynamic Bayesian network (G-DBN) framework to capture the temporal propagation of seismic risk in such systems. Firstly, a system risk assessment model integrates multiple performance indicators through Cloud Model (CM) to quantify overall risk levels, considering uncertainties associated with soil liquefaction and structural responses. Subsequently, a structural dynamic risk inference model is established using Dynamic Bayesian network (DBN), combining Granger Causality (GC) analysis with engineering-informed relationships to define the network structure. The input features include key structural state variables such as tunnel cross-section convergence ( T 4 ), tunnel uplift displacement ( T 6 ), station uplift displacement ( S 5 ), and inter-story drift angle ( S 6 ), and the aggregated structural risk indicator serves as the target variable. This framework enables the temporal propagation of risk across interconnected structural nodes, and elucidates the mechanisms by which liquefiable soil deformations and structural responses interact within the soil-structure system. Results showed that the risk characteristic value (Expectation , E x ) decreased from 29.12 % (percentage) to 5.21 % as the Peak Ground Acceleration (PGA, expressed in units of gravitational acceleration g) increased from 0.1 g to 0.7 g. The proposed G-DBN model demonstrates robust predictive capabilities, achieving coefficient of determination ( R 2 ) values exceeding 0.95 across multiple seismic intensity conditions. Additionally, tunnel cross-section convergence ( T 4 ) was identified as the most critical factor affecting risk propagation in the coupled underground systems. By integrating holistic risk quantification with dynamic propagation analysis, this study offers a robust tool for understanding dynamic risk evolution and supports decision-making for seismic resilience of underground infrastructure in liquefiable soils.},
  archive      = {J_EAAI},
  author       = {Heqi Kong and Xiaohua Bao and Jun Shen and Xiangcou Zheng and Xiangsheng Chen},
  doi          = {10.1016/j.engappai.2025.112171},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112171},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Risk-response coupling in underground structures under liquefiable soil conditions: A causality-informed dynamic bayesian network integrated framework},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural operator-enabled forward and inverse modeling of laser-induced surface acoustic waves and applications in nondestructive evaluation. <em>EAAI</em>, <em>161</em>, 112170. (<a href='https://doi.org/10.1016/j.engappai.2025.112170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser-induced surface acoustic wave (SAW)-driven nondestructive evaluation offers high-resolution, non-contact characterization of subsurface microstructures. However, its practical application is often limited by the high computational costs associated with traditional numerical simulation methods. Recently, machine learning has emerged as an attractive alternative to accelerate these simulations. In this paper, we develop a neural operator-enabled framework for both forward and inverse modeling of laser-induced SAW propagation. A general dataset with randomly generated subsurface structures is used to evaluate and quantify the model's performance in both wave propagation and subsurface inversion problems. Three potential applications are then investigated: subsurface crack localization, multilayer structure characterization and polycrystalline grain imaging. The results demonstrate that the neural operator-enabled model achieves satisfactory accuracy even in the presence of noise and source waveform variations, underscoring its potential as an efficient and accurate surrogate model for practical nondestructive evaluation using laser-induced SAWs.},
  archive      = {J_EAAI},
  author       = {Zaiwei Liu and Zhongqing Su},
  doi          = {10.1016/j.engappai.2025.112170},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112170},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural operator-enabled forward and inverse modeling of laser-induced surface acoustic waves and applications in nondestructive evaluation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective double Q-learning-based hyper-heuristic algorithm for aluminum production and transportation integrated scheduling problem. <em>EAAI</em>, <em>161</em>, 112169. (<a href='https://doi.org/10.1016/j.engappai.2025.112169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cooperative process of electrolytic aluminum production and aluminum liquid distribution is a typical distributed integrated scheduling problem. The aluminum production and transportation integrated scheduling problem (APTISP) is a strong coupling problem that is studied with the optimal objectives of total completion time and total energy consumption. A mathematical model is constructed for the APTISP. A multi-objective double Q-learning-based hyper-heuristic (MDQHH) algorithm is designed to solve the APTISP. In the MDQHH algorithm, a heuristic rule-based initialization operation is designed to generate the initial population of the APTISP. Nine problem-specific low-level perturbation heuristics are constructed to explore the APTISP solution space. A dynamically adjustable ε -greedy strategy is designed to select the low-level perturbation heuristics, and ε gradually decreases as the learning process progresses. Two Q-tables are utilized alternately to select actions and update the Q-values based on the current solution in each iteration. The experimental results show that the MDQHH algorithm outperforms several state-of-the-art comparison algorithms in addressing the performance of APTISP.},
  archive      = {J_EAAI},
  author       = {Fuqing Zhao and Ting Yang and Tianpeng Xu and Jianlin Zhang},
  doi          = {10.1016/j.engappai.2025.112169},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112169},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-objective double Q-learning-based hyper-heuristic algorithm for aluminum production and transportation integrated scheduling problem},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable multi-agent reinforcement learning for factory-wide dynamic scheduling in semiconductor manufacturing. <em>EAAI</em>, <em>161</em>, 112168. (<a href='https://doi.org/10.1016/j.engappai.2025.112168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time dynamic scheduling in modern manufacturing is highly complex due to frequent disturbances and intricate operational constraints. While reinforcement learning (RL) has shown promise, existing approaches often rely on extensive dispatching rules and struggle to scale to factory-wide settings. This study introduces a scalable multi-agent RL (MARL) framework with a leader–follower structure, enabling decentralized agents to handle sub-problems while maintaining global coordination through abstract goals. To further enhance robustness, a limited rule-based conversion algorithm is proposed to mitigate performance degradation from poor agent decisions. Our experimental results demonstrate that the proposed model outperforms the state-of-the-art deep RL-based scheduling methods in various aspects. Additionally, the proposed model provides the most robust scheduling performance to demand changes. Overall, the proposed MARL-based scheduling model presents a promising solution to the real-time scheduling problem, with potential applications in various manufacturing industries.},
  archive      = {J_EAAI},
  author       = {Jaeyeon Jang and Diego Klabjan and Han Liu and Nital S. Patel and Xiuqi Li and Balakrishnan Ananthanarayanan and Husam Dauod and Tzung-Han Juang},
  doi          = {10.1016/j.engappai.2025.112168},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112168},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scalable multi-agent reinforcement learning for factory-wide dynamic scheduling in semiconductor manufacturing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on global path planning algorithm based on indoor map partition preprocessing. <em>EAAI</em>, <em>161</em>, 112167. (<a href='https://doi.org/10.1016/j.engappai.2025.112167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robots utilize Simultaneous Localization and Mapping (SLAM) technology to generate environmental maps and determine their locations within these environments. Subsequently, they employ path planning algorithms to complete navigation tasks. Although existing path planning algorithms are relatively mature, they still exhibit inefficiencies in complex indoor environments. To address this issue, this paper introduces an Indoor Map Partitioning Preprocessing (IMPP) algorithm, which identifies and segments irregularly shaped, complex rooms to accelerate the path planning process. The method initially utilizes the Robot Operating System (ROS) to construct an indoor map dataset and subsequently applies an image segmentation model to identify and enclose rooms. By combining image processing techniques with path planning algorithms, this method can obtain room index information and successfully exclude irrelevant areas from the path planning process. Ultimately, the IMPP algorithm is integrated with a variety of global path planning algorithms. Experimental results demonstrate that in complex indoor environments, this method significantly surpasses existing partitioning methods in terms of room recognition accuracy. Moreover, it decreases the number of expansion points in global path planning algorithms, significantly enhancing processing speed and efficiency.},
  archive      = {J_EAAI},
  author       = {Jifan Yang and Xiaoling Li and Xiaoyang Liu and Xunding Pan and Lei Wang},
  doi          = {10.1016/j.engappai.2025.112167},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112167},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on global path planning algorithm based on indoor map partition preprocessing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ensemble transfer learning strategy for short-term electricity load forecasting of data-sparse buildings. <em>EAAI</em>, <em>161</em>, 112166. (<a href='https://doi.org/10.1016/j.engappai.2025.112166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The “data silos” caused by the lack of available historical or shared information is an important reason affecting forecasting performance of building’s short-term power demand, thus limits the flexibility of demand response of building group. Knowledge’s transfer learning (TL) from similar domains has been proved an efficient tool to enhance target prediction’s performance. To improve data-sparse building’s energy forecasting accuracy and robustness simultaneously, an ensemble strategy based on different TL models is proposed in this study. Firstly, a two-stage similar data selection method is proposed for source domain construction. The multi-kernel maximum mean discrepancy (MK-MMD) is used for selecting similar buildings to the target one; the nearest neighbor search (NNS) method is adopted for picking the most helpful data from the similar buildings to form the dataset of source domain. To determine the optimal number of source domains for transfer learning, an objective function is also formulated. Then, two effective TL models, i.e., instance-based TL (IBTL) and model-based TL (MBTL) are both built as sub models. On this basis, a parallel ensemble framework is designed with model weights adjusted by multiple linear regression. For case study, a public data set containing 1,449 buildings is treated as candidate source domain set for knowledge transfer, and two educational buildings with sparse historical data are treated as target buildings for hourly electricity load forecasting. Forecasting results show that compared with the previous reported TL models, the proposed ensemble strategy always achieves the best performance in two cases and the prediction accuracies are improved by 41.8% and 29.3% (MAPE) respectively. The impact of source domain number and target data amount on prediction performance are also analyzed and discussed in details.},
  archive      = {J_EAAI},
  author       = {Xingqiao Liu and Borui Wei and Wenping Xue and Xiaoying Li and Kangji Li},
  doi          = {10.1016/j.engappai.2025.112166},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112166},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An ensemble transfer learning strategy for short-term electricity load forecasting of data-sparse buildings},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent multispectral image recognition by using credibility-based square root cubature kalman filters and broad particle swarm learning. <em>EAAI</em>, <em>161</em>, 112165. (<a href='https://doi.org/10.1016/j.engappai.2025.112165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes intelligent multispectral image recognition by using credibility-based Square Root Cubature Kalman Filters (SRCKF) and broad particle swarm learning to address the issue of low recognition accuracy in multispectral target detection using Kalman filtering. This method initially enhances the estimation accuracy of SRCKF by integrating credibility theory. Secondly, the regression parameters of a Broad Learning System (BLS) are tuned with Particle Swarm Optimization (PSO), forming a PSO-BLS network that offers fast, lightweight feature learning. The PSO-BLS acts as an regressor that compensates residual errors produced by the credibility-based SRCKF, thereby refining the overall filtering precision. Subsequently, a particle swarm-optimized broad learning neural network is employed to rectify the SRCKF results from a compensatory standpoint, thereby enhancing the system’s filtering precision. Ultimately, the adaptive search window generated by Camshift(Continuously adaptive Mean shift) can be employed as an input for the credibility SRCKF, thereby facilitating the acquisition of more reliable real-time observation data. Finally, in the experimental part, the proposed algorithm is validated by the MNIST(Modified National Institute of Standards and Technology) dataset , CIFAR-10(Canadian Institute For Advanced Research) dataset, GTOT(Grayscale-Thermal Object Tracking) dataset and OTB2015(Object Tracking Benckmark 2015) dataset respectively for its generalization ability and robustness in static classification tasks and the effectiveness of dynamic target detection and tracking in real lighting scenes, Occlusion and motion blur scenes, while the performance is more advantageous than some mainstream algorithms.},
  archive      = {J_EAAI},
  author       = {Quanbo Ge and Zijian Xue and Hao Wang and Yuanliang Wang},
  doi          = {10.1016/j.engappai.2025.112165},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112165},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent multispectral image recognition by using credibility-based square root cubature kalman filters and broad particle swarm learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accidents analysis of mining industry through semantic text representation and dimensionality reduction: An integrated clustering framework. <em>EAAI</em>, <em>161</em>, 112164. (<a href='https://doi.org/10.1016/j.engappai.2025.112164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant improvements in worker health and safety in recent decades, the mining industry still experiences fatal and non-fatal accidents. This underscores the critical need for a more nuanced understanding of accident causation patterns through accident data analysis. While conventional analytical approaches have yielded valuable insights, the extensive information embedded within text-based accident narratives remains underutilized. To address this gap, this study presents an artificial intelligence (AI)-based framework that integrates transformer-based natural language processing, nonlinear dimensionality reduction, and unsupervised machine learning to analyze and cluster accident narratives from the U.S. mining industry. Specifically, this study uses Sentence-BERT (SBERT), a sentence embedding model based on Bidirectional Encoder Representations from Transformers (BERT), to extract the high-dimensional semantical representation of accident narratives. These embeddings are then mapped to a low-dimensional space using the Uniform Manifold Approximation and Projection (UMAP) technique, followed by clustering with the k-means algorithm and subsequent hazard-focused cluster analysis. The primary contribution to AI lies in demonstrating the effectiveness of combining modern sentence embedding techniques with dimensionality reduction and clustering for the semantic analysis of safety-related narratives. From an engineering standpoint, this framework enables the identification of latent accident patterns that can inform hazard detection and guide safety interventions in the mining industry. The resulting clusters reveal diverse accident patterns across mining operations. In clusters associated with underground mining, a high proportion of incidents (ranging from 84 to 98 %) involved no equipment, with distinct injury patterns: torso injuries (67 %) from over-exertion, lower extremity injuries (58 %) from slips/falls, and upper extremity injuries from over-exertion (95 %) and material handling (85 %). Equipment-related clusters revealed strong associations with drilling tools (92 %), loaders (98 %), and bolting equipment (96 %). Clusters associated with strip/quarry/open pit operations exhibited a high frequency of vehicle-related accidents (98 % transportation, 99 % loaders), often resulting in multiple body part injuries. Milling operation clusters show 52–97 % no-equipment accidents, with injury patterns similar to those in underground mining. Additionally, noise-induced hearing loss (96–97 %) was observed in clusters spanning all mining operation types. These findings offer actionable insights for safety professionals and support data-driven, targeted interventions in the mining industry.},
  archive      = {J_EAAI},
  author       = {Abid Ali Khan Danish and Snehamoy Chatterjee and Kumar Vaibhav Raj and Rennie Kaunda and Hugh Miller and Aref Majdara},
  doi          = {10.1016/j.engappai.2025.112164},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112164},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Accidents analysis of mining industry through semantic text representation and dimensionality reduction: An integrated clustering framework},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight and improved you only look once model using GhostWise convolution and attention mechanism for accurate plant disease detection. <em>EAAI</em>, <em>161</em>, 112163. (<a href='https://doi.org/10.1016/j.engappai.2025.112163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence enables early plant disease detection to support food security, yet achieving high accuracy with low computational cost on multi-class datasets remains challenging. To bridge this gap and solve the problem, we propose an improved version of the “You Only Look Once version 8 nano” (YOLOv8n) model that integrates a convolutional block attention module and custom coarse-to-fine modules into the baseline YOLOv8n architecture. To improve both efficiency and detection performance, the proposed model incorporates a combination of Ghost module and Depthwise convolution for lightweight feature extraction. Additionally, the attention modules emphasize important spatial and channel-wise features, helping the model focus better on critical information. The performance of the proposed model is compared with YOLO models including YOLOv5n, YOLOv5s, YOLOv7, YOLOv8n, and YOLOv8s. The experimental results show that the improved model outperforms the benchmark YOLO models. In addition, the improved model achieves mean Average Precision at Intersection over Union threshold of 0.5 ( mAP@0.5 ) 0.742, representing an improvement of 3.37 % over the baseline YOLOv8n. For the metric mean Average Precision at thresholds from 0.5 to 0.95 ( mAP@0.5:0.95 ), the improved model shows an improvement of 5.13 % over YOLOv8n. The precision measure reveals an improvement of 8.99 % and F1 score of 0.6856 outperforms YOLOv8n by 5.85 %. In addition, generalization experiments are conducted using commonly preferred plant disease datasets. These results validate the robustness, accuracy and stability of the improved model in effectively detecting plant leaf diseases.},
  archive      = {J_EAAI},
  author       = {Bunyamin Dikici and Mehmet Fatih Bekciogullari and Hakan Acikgoz and Serkan Ozbay},
  doi          = {10.1016/j.engappai.2025.112163},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112163},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight and improved you only look once model using GhostWise convolution and attention mechanism for accurate plant disease detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid optimization approach for syngas-fueled gas turbines: Integrating inverse problem solving and machine learning techniques. <em>EAAI</em>, <em>161</em>, 112162. (<a href='https://doi.org/10.1016/j.engappai.2025.112162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the efficiency of gas turbines powered by syngas derived from gasification, combining a detailed thermodynamic model with a hybrid optimization approach that integrates inverse problem solving via the Levenberg-Marquardt (LM) algorithm and supervised machine learning using Gradient Boosted Trees (GBT). The LM method is used to estimate turbine and compressor performance parameters based on efficiency maps extracted through a custom image processing routine. These maps are applied to calibrate isentropic efficiencies and define the system's operational boundaries. The resulting performance curves enhance the accuracy of the thermodynamic cycle model. To identify optimal operating conditions that maximize thermal efficiency and minimize entropy generation, the inverse problem formulation is integrated with the GBT model, enabling data-driven optimization based on simulated system behavior. All modeling and simulations are conducted in Wolfram Mathematica version 14.0, while verification is performed with the commercial software Gasturb version 14.0, using syngas composition data available in the literature. As a case study to demonstrate the method's applicability, syngas obtained from sewage sludge gasification is analyzed. The findings after optimization indicated an average thermal efficiency of 40 % when using syngas. The analysis revealed that the fuel mass flow rate contributes approximately 45 % to the efficiency gains and more than 70 % to the exergy reduction, while the excess air ratio contributes around 50 % to the cycle's efficiency. The study demonstrates the value of integrating LM-based modeling and GBT optimization, indicating significant potential for enhancing the performance of syngas-fueled turbines. Moreover, it highlights syngas from sewage sludge as a promising sustainable energy source.},
  archive      = {J_EAAI},
  author       = {Hiago David Zogbi Silva Oliveira and Vítor Caldeira de Andrada Bastos and York Castillo Santiago and Isabela Florindo Pinheiro},
  doi          = {10.1016/j.engappai.2025.112162},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112162},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid optimization approach for syngas-fueled gas turbines: Integrating inverse problem solving and machine learning techniques},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-wavelet adaptive basis network for long-term time series forecasting. <em>EAAI</em>, <em>161</em>, 112161. (<a href='https://doi.org/10.1016/j.engappai.2025.112161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based models have demonstrated remarkable efficacy in long-term time series forecasting. Nevertheless, their fixed-scale feature extraction and static spectral processing limit adaptability to inherent multi-scale temporal dependencies. Additionally, conventional self-attention mechanisms struggle to effectively model hierarchical temporal structures. To address these limitations, we propose the Frequency-Wavelet Adaptive Basis Network (FWBNet), a novel framework that integrates three synergistic components including a Multi-scale Adaptive Basis Module (MS-ABM) for multi-resolution feature extraction, a Dual-Stream Wavelet Cross-Attention (DWCA) system with learnable wavelet transformations, and a computationally efficient Frequency-domain Multi-Layer Perceptron bottleneck (FreMLP bottleneck) for selective spectral processing. The MS-ABM innovatively integrates multi-scale features of time series through an adaptive basis function selection mechanism, dynamically fusing characteristics at different scales to form hierarchical representations. These multi-dimensional representations are then processed by the DWCA system, which establishes an efficient modeling framework for cross-scale temporal dependencies by combining bi-directional attention with learnable wavelet transforms. Building upon this foundation, the FreMLP bottleneck layer strategically performs selective feature optimization in the frequency domain, extracting key frequency information through spectral sparsification techniques to form an end-to-end multi-scale temporal feature learning pipeline. Experimental evaluations on six benchmark datasets demonstrate that FWBNet significantly outperforms state-of-the-art models, achieving mean squared error (MSE) reductions of 14% for multivariate and 21% for univariate predictions. This study presents a comprehensive framework for effective multi-scale temporal information integration in complex time series forecasting applications.},
  archive      = {J_EAAI},
  author       = {Qiang Lai and Yang You},
  doi          = {10.1016/j.engappai.2025.112161},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112161},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Frequency-wavelet adaptive basis network for long-term time series forecasting},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balanced sample repository for knowledge distillation in data-free image classification scenario. <em>EAAI</em>, <em>161</em>, 112160. (<a href='https://doi.org/10.1016/j.engappai.2025.112160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address strict data security and privacy requirements in the field of knowledge distillation for image classification, generative network-based data-free knowledge distillation produces fake images for training student models to perform image classification tasks. However, we discover that the datasets consisting of those fake images often suffer from imbalances, such as unclear class margins, uneven intra-class distribution, and skewed label distribution, impeding classification accuracy. To this end, this paper proposes the balanced sample repository method for data-free knowledge distillation in the context of image classification, comprising three components: dynamic pseudo-supervised loss weight (DLW), biased label generator (BLG), and intra-class homogeneity operator (IHO). Specifically, DLW adjusts the pseudo-supervised loss weight to maintain distinct class margins, BLG uses the roulette algorithm to balance label distribution, and IHO employs local outlier factors to remove outliers and homogenize intra-class distributions. The fake images generated by the generative network are initially stored in the sample repository, and those three components achieve a balanced dataset by influencing this sample repository. The experiments conducted across five recognized image classification datasets demonstrate that the proposed method achieves competitive results and produces more balanced samples.},
  archive      = {J_EAAI},
  author       = {Yafeng Sun and Xingwang Wang and Junhong Huang and Shilin Chen},
  doi          = {10.1016/j.engappai.2025.112160},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112160},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Balanced sample repository for knowledge distillation in data-free image classification scenario},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight detection model for green navel oranges in natural environments. <em>EAAI</em>, <em>161</em>, 112157. (<a href='https://doi.org/10.1016/j.engappai.2025.112157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In natural environments, the detection of green navel oranges in the unstructured plantings of Gannan navel oranges presents challenges, including low model accuracy and excessive parameter size. This paper integrates existing technologies to propose a lightweight green tangerine detection model based on You Only Look Once version 5s (YOLOv5s). The aim is to improve the accuracy of green tangerine identification and detection in natural environments through model improvements. Firstly, the original YOLOv5 network model is optimized by replacing the original CSPDarknet53 (Cross Stage Partial Darknet53) backbone network with MobileNetV3 in order to reduce model parameters. Concurrently, the Squeeze-and-Excitation (SE) module in the network is substituted with the Convolutional Block Attention Module (CBAM), resulting in a lightweight network. Secondly, CBAM is integrated into the C3 network (cross-stage partial bottleneck with three convolutional layers) in the neck region to enhance the model's ability to extract green navel orange features after lightweighting. Finally, improve the loss function of the model to reduce the positioning error of the model for low-quality targets. The experimental results demonstrate that the enhanced model attains a 3.6 % enhancement in precision, 2.3 % in recall, and 2.1 % in mean Average Precision (mAP) in comparison with the original YOLOv5 model. The model's size is 3.9 megabytes (MB), representing a reduction of 72.9 % from the original 14.4 MB. Research shows that our method provides an efficient and accurate solution for identifying green navel orange targets in complex environments, with potential application value in agricultural automation for orchard management and monitoring.},
  archive      = {J_EAAI},
  author       = {Dongyuan Zhang and Qiusheng Li and Xindi Yuan},
  doi          = {10.1016/j.engappai.2025.112157},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112157},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight detection model for green navel oranges in natural environments},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient real-time instance segmentation of garment for intelligent robot tie-dye based on you only look once version 11 network. <em>EAAI</em>, <em>161</em>, 112156. (<a href='https://doi.org/10.1016/j.engappai.2025.112156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tie-dye, as an intangible cultural heritage with a long history, has gained global popularity due to its unique artistic value and versatile craftsmanship. However, its reliance on manual operation leads to low production efficiency and inconsistent quality. To address this, we propose an improved You Only Look Once version-11 (YOLOv11) instance segmentation model, Garment-YOLO, to efficiently segment the garment regions of robotic tie-dye by artificial intelligence technology. First, the C3k2_DynamicMixFormer (C3k2_DMF) module introduces dynamic kernel weight selection mechanism and multi-scale fusion to effectively balance local details and global information. Meanwhile, the Dual-Cross Recalibration Feature Pyramid Network (DCR-FPN) is proposed to enhance the detail preservation of edge region by selectively aggregating semantic and boundary information. Furthermore, the Superior-Head replaces depthwise convolution (DWConv) with part convolution (PConv), significantly reducing model complexity while maintaining performance. Experimental results demonstrate that Garment-YOLO achieves 167.4 frames per second (FPS) and maintains an optimal trade-off between inference speed and segmentation accuracy, reaching 91.9 % mean average precision (mAP)50–95 (Box), 91.5 % mAP50-95 (Mask). To further validate its practical performance, we conducted a 72-h production-line comparison, showing that compared to the baseline, we increase the product qualification rate by 24.6 %, reduce dye waste by 19.4 %, and increase the total production by 52.5 % compared to manual tie-dye. This study not only provides a feasible solution for the intelligent transformation of traditional tie-dye but also contributes to the preservation and development of this intangible cultural heritage. The code will be released on GitHub ( https://github.com/fudifu123/GARMENT-YOLO ). A video that intuitively introduces our research ( https://www.bilibili.com/video/BV13MgczAEkB ).},
  archive      = {J_EAAI},
  author       = {Difei Feng and Qihong Zhou and Lei Xiao and Kunfeng Ge and Hangzhou Ma and Li Zhou},
  doi          = {10.1016/j.engappai.2025.112156},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112156},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient real-time instance segmentation of garment for intelligent robot tie-dye based on you only look once version 11 network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep patch network with spatiotemporal meta-parameter learning for soft sensor modeling of industrial processes. <em>EAAI</em>, <em>161</em>, 112155. (<a href='https://doi.org/10.1016/j.engappai.2025.112155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft sensing techniques have been widely employed in industrial processes to predict hardly measurable quality variables using easily measurable process variables. Effective modeling strategies for representing spatiotemporal features are highly desired in soft sensing applications for dynamic industrial processes. Deep networks, such as graph convolutional network and gated recurrent unit, are frequently employed to capture the spatial or temporal characteristics of sequential data. Nevertheless, effectively modeling and utilizing spatiotemporal heterogeneity remains a challenging problem. Thereby, a p atch network with spatiotemporal m eta- p arameter l earning (PMPL) is proposed in this paper, which presents an uniform framework of modeling spatiotemporal heterogeneous feature representations for soft sensing. In PMPL, a patching strategy is utilized to segment times series into sub-series-level patches, allowing the retention of local semantic information while capturing long-term dependencies. Next, a novel spatiotemporal meta-parameter learning approach is proposed to generate specific parameters for a spatial encoder, temporal encoder and spatiotemporal decoder through establishing corresponding embedding layers. In this way, the spatial, temporal and spatiotemporal dependencies within the process data can be adaptively captured and comprehensively refined from a uniform perspective. Extensive experiments are conducted based on two real production processes, which illustrate the feasibility and efficacy of the proposed model.},
  archive      = {J_EAAI},
  author       = {Xudong Shi and Kangping Du and Weili Xiong and Humberto Morales and Adriana Amicarelli},
  doi          = {10.1016/j.engappai.2025.112155},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112155},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep patch network with spatiotemporal meta-parameter learning for soft sensor modeling of industrial processes},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep bioinspired evolutionary stacking algorithm for unpaired multimodal cell classification calibration. <em>EAAI</em>, <em>161</em>, 112153. (<a href='https://doi.org/10.1016/j.engappai.2025.112153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-modality deep learning approaches for cell image classification exhibit inherent limitations in informational diversity when processing cross-institutional datasets acquired under varied imaging protocols. In contrast, multimodal cell imaging has emerged as a promising alternative for addressing data heterogeneity through comprehensive information integration. This study introduces a novel multimodal alternate training decision-making architecture based on a stacking algorithm for unpaired multimodal cell classification calibration. The method leverages deep bioinspired evolutionary networks combined with kernel-based support vector machines. Specifically, deep base classifiers incorporating multimodal concepts are derived from heterogeneous cell datasets. Each base classifier employs a bioinspired strategy to perform alternate training between two evolutionary densely connected attention networks. To mitigate class imbalance, where diseased cells are significantly outnumbered by normal cells, we incorporate a Shannon entropy loss term. Finally, multiple kernel-based support vector machines serve as meta classifiers, transforming high-level multimodal concepts into a separable feature space for robust decision-making. Experimental results demonstrate the superiority of our approach over existing algorithms for unpaired multimodal cell image classification. Our findings emphasize the importance of alternate training intra-modality classifiers and inter-modality fusion calibration for accurate and reliable medical image classification. All source code for this work will be publicly available on GitHub.},
  archive      = {J_EAAI},
  author       = {Lili Zhao and Di Xu and Xueping Tan and Jinzhao Yang and Weiping Ding and Hengde Zhu and Lichi Zhang and Qian Wang},
  doi          = {10.1016/j.engappai.2025.112153},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112153},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep bioinspired evolutionary stacking algorithm for unpaired multimodal cell classification calibration},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal-frequency joint hierarchical transformer with dynamic windows for speech emotion recognition. <em>EAAI</em>, <em>161</em>, 112152. (<a href='https://doi.org/10.1016/j.engappai.2025.112152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech Emotion Recognition (SER) aims to identify the emotional state of a speaker from speech signals, serving as a critical prerequisite for achieving natural human–computer interaction. In speech signals, emotional information is inherently distributed across diverse frequency bands and temporal scales, with emotional cues in distinct regions exhibiting varying levels of heterogeneity or interdependence. Existing Transformer-based methods face limitations in precisely localizing salient temporal-frequency regions and modeling their inter-regional relationships. To address these challenges, a temporal-frequency joint hierarchical Transformer with dynamic window mechanisms, abbreviated as TF-DWFormer, is proposed to capture critical emotional cues and their contextual dependencies across temporal-frequency dimensions. It operates through several principal phases: Firstly, a feature reconstruction module is designed to extract temporal, frequency, and temporal-frequency representations of emotional speech. Secondly, a high-low frequency-based emotion-aware partitioning strategy is designed to achieve the division of emotional regions. Thirdly, a local window within a hierarchical Transformer analyzes static intra-region correlations to capture fine-grained emotional patterns, while a dynamic window adaptively models temporal evolution across regions, learning dynamic inter-region relationships. Lastly, a dual-cross-attention mechanism is employed to synergize comprehensive emotion representation from different domains. Our evaluation experiments demonstrate that the proposed TF-DWFormer method achieves recognition accuracies of 73.68%, 91.67%, 92.59%, 74.42%, and 50.54% on the datasets IEMOCAP, CASIA, EMODB, eNTERFACE05, and MELD, respectively, outperforming existing SER methods. These results confirm the capability of TF-DWFormer to precisely localize salient regions, robustly model inter-region dependencies, and effectively fuse multi-domain information, providing a promising solution for advancing SER technology.},
  archive      = {J_EAAI},
  author       = {Yonghong Fan and Heming Huang and Huiyun Zhang and Ziqi Zhou},
  doi          = {10.1016/j.engappai.2025.112152},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112152},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Temporal-frequency joint hierarchical transformer with dynamic windows for speech emotion recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional reconstruction and fracture segmentation based on X-ray and computed tomography paired dataset. <em>EAAI</em>, <em>161</em>, 112151. (<a href='https://doi.org/10.1016/j.engappai.2025.112151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some orthopedic surgeries, the use of three-dimensional (3D) computed tomography (CT) scanning technology is not feasible due to scene limitations, leaving doctors to rely on two-dimensional (2D) X-ray images for real-time diagnosis. However, X-ray images lack 3D information, making accurate diagnosis challenging. Developing an algorithm to convert 2D X-ray images into 3D CT images, while simultaneously combining high-quality 3D reconstruction with precise fracture segmentation, offers a promising solution to the problem. In this study, we propose a novel artificial intelligence (AI)-driven framework named 3D reconstruction and segment anything model (3DRecSAM). The reconstruction image enhancer (RIE) is designed to achieve high-precision 3D reconstruction and provide high-quality feature initialization for fracture segmentation. Meanwhile, the mamba segment anything model (MSAM), based on the segment anything model (SAM) architecture, is developed for accurate fracture segmentation. We introduce a Kolmogorov–Arnold network (KAN)-based attention fusion module (KAF), which facilitates the joint optimization of the RIE reconstruction network and the MSAM segmentation network. Furthermore, the selective scanning mamba with KAN (SKM) is incorporated to enhance feature extraction for both RIE and MSAM. Mamba efficiently captures long-range dependencies and sequential patterns, while KAN’s learnable activation functions facilitate adaptive feature fusion and non-linear representation. To train and evaluate 3DRecSAM, we introduce the real X-ray and CT paired dataset (XCPData), which is publicly available on GitHub: https://github.com/YuanGao1201/XCPData .},
  archive      = {J_EAAI},
  author       = {Yuan Gao and Yuan Zhou and Da Chen and Jiachen Li and Mingle Zhou and Gang Li and Yunbo Gu and Jean-Louis Coatrieux and Yang Chen},
  doi          = {10.1016/j.engappai.2025.112151},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112151},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-dimensional reconstruction and fracture segmentation based on X-ray and computed tomography paired dataset},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised domain adaptation for lithology classification using dynamic entropy-based prototype learning. <em>EAAI</em>, <em>161</em>, 112150. (<a href='https://doi.org/10.1016/j.engappai.2025.112150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lithology classification plays a crucial role in geological exploration and resource evaluation. However, the significant distribution discrepancies between source and target domains, coupled with the unavailability of source domain data, pose substantial challenges to traditional domain adaptation methods. To address these challenges, we propose an innovative framework, Unsupervised Domain Adaptive Dynamic Entropy Prototype Learning (UDADEPL), which leverages a source-free unsupervised domain adaptation strategy for lithology classification. The UDADEPL framework consists of a frozen source pre-trained model and a trainable target model, incorporating a dynamic entropy-based prototype learning matrix for reliable sample selection and centroid-based pseudo-label learning for iterative optimization. Additionally, an information maximization loss and source domain regularization loss are integrated into a curriculum learning strategy to balance feature extraction and domain adaptation. This approach enables the model to effectively handle complex lithological boundaries and class imbalances in the target domain. Extensive experiments on datasets from the Tarim Oilfield and Hugoton–Panoma field demonstrate the superiority of UDADEPL over traditional machine learning and advanced deep learning models. UDADEPL achieves superior classification accuracy, outperforming the best baseline models, especially in cross-domain adaptation and complex lithology identification.},
  archive      = {J_EAAI},
  author       = {Hengxiao Li and Yahui Liu and Lu Liu},
  doi          = {10.1016/j.engappai.2025.112150},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112150},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised domain adaptation for lithology classification using dynamic entropy-based prototype learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transforming physics-informed machine learning to convex optimization. <em>EAAI</em>, <em>161</em>, 112149. (<a href='https://doi.org/10.1016/j.engappai.2025.112149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Machine Learning (PIML) offers a powerful paradigm of integrating data with physical laws to address important problems in engineering, such as parameter estimation, inferring hidden physics, equation discovery, and state prediction. However, PIML, such as Physics-Informed Neural Networks (PINNs), still lack the necessary accuracy, stability, and interpretability when applying in practical engineering due to many serious optimization challenges including the spectral bias, non-convex optimization, multi-objective optimization, and non-smooth optimization. In this study, we propose the Convex-PIML based on convex optimization and basis functions widely used in well-established numerical solvers to overcome all these limitations. The linear combination of B-splines is utilized to approximate the data, promoting the convexity of the loss function. By dividing variables into blocks and replacing the non-convex loss terms with convex approximations, the problem is further converted into a sequence of successively refined approximated convex optimization problems. This conversion known as Block Successive Convex Approximation (BSCA) allows the use of well-established convex optimization algorithms, obtaining solutions effectively and efficiently. Furthermore, an adaptive knot optimization method is introduced to mitigate the spectral bias issue of PIML, further improving the performance. The proposed fully adaptive framework by combining the adaptive knot optimization and BSCA is tested in scenarios with distinct types of physical prior. The results indicate that optimization problems are effectively solved in these scenarios, highlighting the potential of the framework for broad applications. Note that the Convex-PIML is also flexible since many other basis functions can also be incorporated to handle different systems.},
  archive      = {J_EAAI},
  author       = {Letian Yi and Siyuan Yang and Ying Cui and Zhilu Lai},
  doi          = {10.1016/j.engappai.2025.112149},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112149},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transforming physics-informed machine learning to convex optimization},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time fuzzy tracking control for networked suspension systems under gilbert-elliott fading channels. <em>EAAI</em>, <em>161</em>, 112148. (<a href='https://doi.org/10.1016/j.engappai.2025.112148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the finite-time ℓ 2 − ℓ ∞ fuzzy tracking control problem for networked suspension systems operating under Gilbert-Elliott fading channels. Firstly, the suspension system is established based on interval type-2 fuzzy rules to effectively describe the nonlinearity and uncertainty inherent in the model. Secondly, the Gilbert-Elliott model is employed to characterize the random switching behavior of channel states (good channel and fading channel) under real-world conditions. The timely identification of the current channel state is achieved through a mode detection method. To address channel fading and communication constraints, a novel mode-dependent controller is proposed. Simultaneously, we aim to minimize unnecessary and redundant communication. The hybrid scheduling strategy of the FlexRay protocol is utilized to transmit the measurement output data to the observer, and a saturation function is introduced in the observer to minimize the impact of outliers. Subsequently, the design conditions for stochastic finite-time boundedness and ℓ 2 − ℓ ∞ performance of the augmented system is proposed. Finally, simulation results demonstrate that the proposed algorithm is practically viable in dealing with complex environments, such as Gilbert-Elliott fading channels, outliers, and communication constraints.},
  archive      = {J_EAAI},
  author       = {Li-Juan Cai and Xiao-Heng Chang and Xin-Yue Zhao},
  doi          = {10.1016/j.engappai.2025.112148},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112148},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Finite-time fuzzy tracking control for networked suspension systems under gilbert-elliott fading channels},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RT-FedFlow: An efficient framework for real-time traffic signal optimization using federated multi-agent reinforcement learning. <em>EAAI</em>, <em>161</em>, 112147. (<a href='https://doi.org/10.1016/j.engappai.2025.112147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of Traffic Signal Control (TSC) is a critical component of the Intelligent Transportation System (ITS) in smart cities, aiming to eliminate traffic congestion and improve urban mobility. However, traditional approaches to TSC often rely on centralized data processing, limiting scalability and adaptability to real-time traffic dynamics while raising concerns about data privacy, communication, and computation. To address these challenges, this paper proposes the RT-FedFlow, a novel federated multi-agent reinforcement-learning (FMARL) framework for real-time traffic signal optimization. The framework employs enhanced FMARL techniques to enable decentralized collaboration among multiple traffic signal agents, optimizing traffic flow while seamlessly balancing local adaptability and global coordination. Federated model aggregation enables agents to collaboratively learn a global policy while preserving local data privacy, with each reinforcement learning (RL) agent independently optimizing its policy. Next, an advanced reward mechanism is designed to minimize congestion and reduce waiting times. Moreover, a hierarchical communication and coordination strategy is adopted to facilitate efficient local interaction among agents and global model aggregation to improve overall system performance. In addition, the framework enables real-time optimization and prioritization of emergency vehicles through a dedicated preemption module. Compared to existing TSC models, RT-FedFlow significantly improves traffic signal coordination and response times by dynamically adapting to complex, real-time traffic conditions. The proposed RT-FedFlow framework is implemented and evaluated using the SUMO simulator. Extensive simulation results demonstrate that RT-FedFlow outperforms all benchmark models, achieving a 15.49 % reduction in average inference time, a 3.07 % reduction in average queue length, a 13.04 % reduction in average intersection delay, a 0.20 % improvement in fuel consumption, and a 5.35 % emergency vehicle clearance time.},
  archive      = {J_EAAI},
  author       = {Ayaz Akbar and Syed Sajid Ullah and Abdul Malik and Saeed Mian Qaisar},
  doi          = {10.1016/j.engappai.2025.112147},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112147},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RT-FedFlow: An efficient framework for real-time traffic signal optimization using federated multi-agent reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid data-driven model for state of health estimation of lithium-ion battery with capacity recovery. <em>EAAI</em>, <em>161</em>, 112146. (<a href='https://doi.org/10.1016/j.engappai.2025.112146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The failure of lithium-ion batteries has attracted the attention of researchers. Monitoring the degradation process through sensor-based state-of-health (SOH) assessment enables early detection of anomalies and facilitates timely interventions to prevent catastrophic failures. During battery degradation, the phenomenon of capacity recovery makes it complicated to accurately evaluate the SOH. However, existing works usually neglect this phenomenon. In this paper, we propose a hybrid model focusing on capacity recovery. The model consists of four modules: a feature extraction module, a data decomposition module, a global trend assessment module, and a local fluctuation assessment module. Specifically, in the feature extraction module, a convolutional neural network extracts features from the input data that effectively characterize the capacity degradation process. The data decomposition module applies empirical mode decomposition (EMD) to separate local fluctuations caused by capacity recovery from the global degradation trend. These components are then input into their respective assessment modules. Additionally, the local fluctuation assessment module incorporates an attention mechanism that adaptively identifies the similarity between extracted features and health states, thereby enhancing the evaluation of local fluctuations. The proposed model is validated using the NASA (National Aeronautics and Space Administration) battery dataset, demonstrating its effectiveness in addressing the challenges of SOH prediction under capacity recovery conditions.},
  archive      = {J_EAAI},
  author       = {Yu Lin and Luo Zhou and Jianhai Yan and Shuguang He},
  doi          = {10.1016/j.engappai.2025.112146},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112146},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid data-driven model for state of health estimation of lithium-ion battery with capacity recovery},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel localization algorithm integrated with sensor fusion for position estimation of mobile robot in the road following and roundabout environment. <em>EAAI</em>, <em>161</em>, 112145. (<a href='https://doi.org/10.1016/j.engappai.2025.112145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel Artificial Intelligence algorithm based autonomous mobile robot localization in road environments is presented in this paper. The sensor fusion data, employing camera and odometry, are used to build the local maps for road environment. The localization of the robot is performed using a novel Artificial Intelligence algorithm, called Priori-Posteriori-Laser-Simulator, to find the position and heading-angle of robot along movement in two phases, namely priori and posteriori stages as 1st phase and Kalman filter in 2nd phase. In the priori stage, the path of the robot is planned in the built-map using Laser Simulator through generating a series of points as lines to drive the robot in the middle of the road environments. In the posteriori-stage, the position and robot heading angle are measured using sensor fusion system and the laser-simulator updates the position accordingly through a comparison between the planned and actual positions. The Kalman filter is used in 2nd phase to remove noise and enhance to enhance the localization accuracy. The proposed algorithm has been tested in indoor and outdoor road environments to show its effectiveness and performance for localizing robot in such environments. It is also compared with fuzzy-logic, adaptive H-infinity filter, fuzzy logic with Kalman filter and Oriented-Rotated Binary Simultaneous Localization and Mapping 2 algorithms on localizing robot at road environment. Results show the capability of the proposed algorithm to enable the robot to move effectively in road environments, recognize the features of road terrains and localize the robot during autonomous navigation in road environments.},
  archive      = {J_EAAI},
  author       = {Mohammed A.H. Ali and Nukman Yusoff and Bushroa Abd Razak and Sherzod Turaev and Rawad Abdulghafor and Aisha Muhammad},
  doi          = {10.1016/j.engappai.2025.112145},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112145},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel localization algorithm integrated with sensor fusion for position estimation of mobile robot in the road following and roundabout environment},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electroencephalography-based emotion recognition using a dual-stream multi-scale spatiotemporal convolutional capsule network. <em>EAAI</em>, <em>161</em>, 112144. (<a href='https://doi.org/10.1016/j.engappai.2025.112144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, emotion recognition using electroencephalogram (EEG) signals has gained significant attention. However, shallow convolutional neural networks used in EEG emotion recognition are ineffective at capturing spatial relationships between features, adversely affecting model performance. To solve this problem, this study proposes a dual-stream multi-scale spatiotemporal convolutional capsule network aimed at improving EEG-based emotion recognition. The novelty of our approach is the dual-stream multi-scale spatiotemporal design, which enables parallel extraction and fusion of temporal and spatial EEG features at multiple scales, offering a richer and more discriminative representation for emotion recognition. Specifically, a dual-stream feature construction module is developed to extract multi-scale temporal and spatial features from raw EEG signals. A hybrid spatiotemporal attention mechanism enhances feature fusion, while a capsule-based classifier improves recognition accuracy by modeling relationships between local and global features. Experimental results using subject-dependent 10-fold cross-validation show average accuracies of 97.72%, 97.56%, and 97.82% for valence, arousal, and dominance on the Dataset for Emotion Analysis using Physiological signals(DEAP), with average F1 scores of 97.83%, 97.51%, and 97.68%. For the Dataset for Emotion Analysis using Physiological signals(DREAMER 1 ), the average accuracies are 96.48%, 96.32%, and 96.35%, with corresponding F1 scores of 96.23%, 95.74%, and 95.66%. The proposed method outperforms existing state-of-the-art approaches on both datasets, reducing the number of parameters by 58.07% and decreasing inference time by approximately 50.86% and 33.39%, compared to Residual Network 18. Additionally, in the subject-independent leave-one-subject-out cross-validation, the proposed method demonstrated results that significantly outperformed the baseline model across both datasets. Experiments show that the proposed method enhances spatiotemporal feature extraction and improves emotion recognition accuracy. This method reduces computational resource consumption and enhances recognition accuracy, thereby facilitating efficient algorithm development and deployment for real-time emotion monitoring and related applications.},
  archive      = {J_EAAI},
  author       = {Han Cai and Pengfei Lu and Xiaofang Wang and Yuxing Wang},
  doi          = {10.1016/j.engappai.2025.112144},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112144},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Electroencephalography-based emotion recognition using a dual-stream multi-scale spatiotemporal convolutional capsule network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse structural design with generative and probabilistic autoencoders and diffusion models. <em>EAAI</em>, <em>161</em>, 112143. (<a href='https://doi.org/10.1016/j.engappai.2025.112143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional structural design is a forward trial-and-error process. Designers need to iterate through different design solutions and conduct structural analysis until the design meets the codes and standards. This study proposes and investigates a generative machine learning (ML) framework for inverse design of continuous beam systems. Three generative ML models, including conditional variational autoencoder (CVAE), conditional autoencoder with maximum likelihood estimation (CAE-MLE), and denoising diffusion models (DDMs) are trained and fine-tuned on the CBeamXP (Continuous Beam Cross-section Predictors) dataset with 1,000,000 beam sections to generate the cross sectional properties. Research results show that CAE-MLE achieves the highest generation accuracy and robustness, while CVAE offers more variability through latent space sampling. DDMs provide controllable generation variability via a stochasticity parameter in the inverse diffusion process. The proposed framework enables efficient generation of multiple design solutions and can potentially accelerate the conceptual design workflows in structural engineering. This work also demonstrated the feasibility toward artificial intelligence (AI)-assisted structural design using generative approaches and tabular datasets.},
  archive      = {J_EAAI},
  author       = {Bozhou Zhuang and Adrien Gallet and Danny Smyl},
  doi          = {10.1016/j.engappai.2025.112143},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112143},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inverse structural design with generative and probabilistic autoencoders and diffusion models},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective generative design framework and realization for quasi-serial manipulator: Considering kinematic and dynamic performance. <em>EAAI</em>, <em>161</em>, 112142. (<a href='https://doi.org/10.1016/j.engappai.2025.112142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a framework for optimizing the linkage mechanism of a quasi-serial manipulator for target tasks. The process is illustrated through a case study of a two-degree-of-freedom (2-DOF) linkage mechanism, which significantly influences the workspace of the quasi-serial manipulator. First, a diverse set of quasi-serial mechanisms is generated with workspaces that satisfy the target task and is converted into three-dimensional computer-aided design (3D CAD) models. Then, kinematic and dynamic analyses are conducted to compute workspace and payload torque labels for surrogate model training. Adaptive sampling is employed to identify an appropriate amount of training data for accurate prediction, while ensemble models are utilized to enhance robustness. After model training, a multi-objective optimization problem is formulated under the mechanical and dynamic constraints of the manipulator. The design objective is to recommend quasi-serial mechanisms with optimized kinematic (workspace) and dynamic (payload torque) performance that fulfill the target task. To explore the underlying physics of the Pareto solutions obtained via the Non-Dominated Sorting Genetic Algorithm (NSGA-II), various data mining techniques are applied to extract design rules that offer practical guidance. Finally, a detailed manipulator is realized using 3D-printed parts with topology optimization, and its performance is verified through a payload test. These results demonstrate the potential of the proposed framework for broader mechanism applications and its capability to support practical design decisions through design rule extraction.},
  archive      = {J_EAAI},
  author       = {Sumin Lee and Sunwoong Yang and Namwoo Kang},
  doi          = {10.1016/j.engappai.2025.112142},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112142},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective generative design framework and realization for quasi-serial manipulator: Considering kinematic and dynamic performance},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain and deep learning-enabled IoT device-to-device authentication approach for smart cities using 5th generation technology. <em>EAAI</em>, <em>161</em>, 112141. (<a href='https://doi.org/10.1016/j.engappai.2025.112141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As smart cities evolve, the increasing number of Internet of Things (IoT) devices requires secure authentication mechanisms for device-to-device (D2D) communication, especially within 5G networks. To address security challenges in D2D communication, Blockchain (BC) technology is utilized. Existing methods face issues like single-point failure attacks, high implementation costs, and data privacy concerns. This work aims to develop a secure and efficient authentication model leveraging BC technology and a Deep Q Network (DQN) for key generation to enhance IoT security in smart city applications. A novel authentication model, Deep Q Network-SecAuth (DQN-SecAuth), is proposed for secure D2D communication using BC. The model involves key entities such as the Registration Authority Center (RAC), blockchain, and IoT devices. The authentication process includes six stages: setup, registration, key generation, authentication, new device addition, and formal verification. In the key generation stage, the secret key is generated using a Deep Learning (DL) model named DQN. The proposed model also incorporates encryption, hash functions, Chebyshev polynomials, and XOR operations to ensure security. The DQN-SecAuth model achieved a minimum computational time of 9.525 s and memory usage of 42.897 megabytes (Mb), consensus delay of 0.420 s, energy consumption of 0.715 J, latency of 0.469 s, power consumption of 0.270 kW-hour (kWh), and throughput of 0.804 megabits per second (Mbps). The key novelty of this work is the use of a DQN for adaptive key generation, integrated into a BC-based authentication framework. This combination enhances security, reduces computational overhead, and outperforms traditional static key-generation and authentication methods in smart city IoT environments.},
  archive      = {J_EAAI},
  author       = {K. Prabhu Chandran and Bhuvaneswari P and Sivasankaran V and Vimala S},
  doi          = {10.1016/j.engappai.2025.112141},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112141},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Blockchain and deep learning-enabled IoT device-to-device authentication approach for smart cities using 5th generation technology},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergency medical facility site selection in drone-based relief operations using an enhanced T-spherical fuzzy frank combined compromise solution method. <em>EAAI</em>, <em>161</em>, 112140. (<a href='https://doi.org/10.1016/j.engappai.2025.112140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) play a vital role in disaster response operations, emphasizing the need for efficient site selection for emergency medical facilities (EMFs). This study presents a structured framework for evaluating candidate sites and identifying critical criteria for establishing EMFs in drone-based relief operations. It proposes a novel T-spherical fuzzy (T-SF) multi-criteria group decision-making framework for EMF site selection. The framework integrates the T-SF-Entropy method and a hybrid subjective–objective weighting scheme that combines stepwise weight assessment ratio analysis and the method based on the removal effects of criteria. This integration enables a more reliable aggregation of expert opinions. The framework applies T-SF Frank aggregation operators in the modified combined compromise solution method to rank potential sites under multi-disaster conditions. A real-world case study evaluates alternative sites using the critical criteria and demonstrates the practical utility of the proposed model in the field of emergency engineering logistics. Quantitative analysis shows that the “urban logistics hub” achieves the highest compromise index due to its advantages in proximity, infrastructure, and supply chain access. Sensitivity analysis confirms that variations in parameters do not affect the stability of rankings. This study uses artificial intelligence to support intelligent decision-making in disaster response. It provides an effective engineering application that optimizes UAV-based healthcare deployment, enhances resource allocation, and improves the speed and accuracy of emergency medical responses.},
  archive      = {J_EAAI},
  author       = {Rajdip Mahajan and Saptadeep Biswas and Vladimir Simic and Dragan Pamucar and Abhijit Baidya and Uttam Kumar Bera},
  doi          = {10.1016/j.engappai.2025.112140},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112140},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Emergency medical facility site selection in drone-based relief operations using an enhanced T-spherical fuzzy frank combined compromise solution method},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature description attention: Channel-independent local–global fusion for multi-scale feature representation. <em>EAAI</em>, <em>161</em>, 112139. (<a href='https://doi.org/10.1016/j.engappai.2025.112139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent deep convolutional networks, attention mechanisms rely heavily on global information to generate attention weights, but few methods can effectively recalibrate global features based on local object characteristics. To address this gap, we introduce a masked-averaging strategy that adaptively selects regions of interest from the feature map, allowing local features to encode and reflect global information. By combining these local descriptors with global averages and maximums into a multi-scale Bag-of-Visual-Words (BoVW), our method jointly captures salient point, local region, and global context, resulting in richer and more discriminative feature representations. Additionally, we propose Feature Batch Normalization (FBN) to facilitate cross-channel interactions, further enhancing the performance of attention modules. In terms of engineering applications, to overcome the limitations of traditional channel-dependent attention under model compression and pruning, we design a channel-independent feature recalibration mechanism based on one-dimensional depthwise convolution, termed Feature Description Attention (FDA). It leverages the properties of BoVW and FBN to provide a flexible and lightweight attention module with minimal computational overhead and robust performance under quantization and pruning. Our method demonstrates consistent gains across three vision tasks: classification accuracy improves by 0.72–1.68%, object detection performance increases by 1.8–3.0% mean average precision, and segmentation accuracy rises by 1.9%. These results across different benchmarks confirm the effectiveness and generalizability of our approach. FDA offers a scalable, hardware-friendly solution for modern vision applications, especially valuable in resource-constrained settings such as mobile deployment, autonomous systems, and medical image analysis.},
  archive      = {J_EAAI},
  author       = {Yuanyang Zhu and Guangjie Han and Hongbo Zhu and Fan Zhang},
  doi          = {10.1016/j.engappai.2025.112139},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112139},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature description attention: Channel-independent local–global fusion for multi-scale feature representation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving robustness of transformers for power quality disturbance classification via optimized relevance maps. <em>EAAI</em>, <em>161</em>, 112138. (<a href='https://doi.org/10.1016/j.engappai.2025.112138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power quality disturbances (PQDs) are a critical area of research in the power systems domain. The growing complexity of modern power systems increases the variability of PQDs that may occur, making it challenging to manage power quality using traditional methods, and motivates the inclusion of machine learning models. However, these models are vulnerable to adversarial attacks. The predominant defense approach is adversarial training, which increases robustness at the price of significant increase in computational complexity of the training process, and can often lead to reduced accuracy on non-adversarial examples. In this light, this paper introduces a distinct approach to increase the robustness of Transformer-based PQD classifiers by leveraging their intrinsic explainability derived from the self-attention mechanism. By incorporating the resulting explainable features in the form of relevance maps into the loss function during the fine-tuning stage, we guide the model to focus on salient disturbance features. This method enhances the robustness against adversarial attacks, without compromising accuracy, and avoids the additional computational overhead associated with adversarial training. Experimental results show that when no adversarial attack is applied, the fine-tuning stage increases the PQD classification accuracy from 97.62% to 99.26%, thus overcoming the accuracy-robustness trade-off. Furthermore, the Transformer with the proposed fine-tuning stage is more adversarial robust than a state-of-the-art deep Convolutional neural network (DeepCNN) PQD classifier. The proposed Transformer maintains accuracy and F1 scores slightly above 88%, whereas fo DeepCNN both scores are slightly below 66.60%, thus highlighting the effectiveness of our approach.},
  archive      = {J_EAAI},
  author       = {Itamar Kapuza and Elinor Ginzburg-Ganz and Ram Machlev and Yoash Levron},
  doi          = {10.1016/j.engappai.2025.112138},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112138},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving robustness of transformers for power quality disturbance classification via optimized relevance maps},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive epipolar geometry for robust light field super-resolution. <em>EAAI</em>, <em>161</em>, 112137. (<a href='https://doi.org/10.1016/j.engappai.2025.112137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light field technology captures both spatial and angular information, densely sampled high-resolution light field images contain abundant 3-dimensional geometric information, enabling widespread applications in various industrial fields. However, existing methods for joint spatial and angular super-resolution of light field images face significant challenges when reconstructing scenes with large disparities and significant occlusions. To address this issue, we propose a geometric information enhancement module that enables efficient extraction and preservation of geometric information, and then we propose a non-disparity-based, one-stage approach that allows for the direct reconstruction of densely sampled high-resolution light field images from sparsely sampled low-resolution counterparts. Specifically, we decompose the original 4-dimensional light field image into three distinct 2-dimensional representations: spatial, angular, and epipolar plane image. Among these representations, the epipolar plane image contains abundant geometric information, which inspires us to propose a more efficient feature extractor. In addition, we introduce a progressive feature fusion strategy that better preserves geometric information extracted from epipolar plane images. Finally, to avoid errors introduced by warping operations that complicate the process of enhancing geometric information, we introduce a spatial-angular integrated upsampling module. Extensive experimental results on public datasets demonstrate that our proposed method significantly outperforms state-of-the-art approaches both quantitatively and qualitatively. Specifically, on the Occlusions dataset, our method achieved significant improvement in performance while reducing inference time by approximately 80% compared to the current best method. This efficiency gain is particularly beneficial for practical applications of the artificial intelligence algorithm.},
  archive      = {J_EAAI},
  author       = {Hao Zhang and Hao Sheng and Rongshan Chen and Da Yang and Ruixuan Cong and Zhenglong Cui and Xuefei Huang and Guanqun Su},
  doi          = {10.1016/j.engappai.2025.112137},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112137},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Progressive epipolar geometry for robust light field super-resolution},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring knee joint moment prediction models for landing task with various model architecture: Leveraging inertial measurement unit sensors data and subject-specific attributes. <em>EAAI</em>, <em>161</em>, 112136. (<a href='https://doi.org/10.1016/j.engappai.2025.112136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a comparative evaluation of deep learning models for predicting Three-Dimensional (3D) knee joint moments during landing tasks using Inertial Measurement Unit (IMU) data. We assess a range of architectures, from simple feedforward networks to complex Three-Dimensional Convolutional Neural Networks (3D-CNN), to balance predictive accuracy with computational cost. The 3D-CNN model achieved the highest performance, with relative Root Mean Squared Error (rRMSE) values of 6.08 % for the knee abduction moment, 5.3 % for the external rotation moment, and 4.9 % for the flexion moment. We further explored the effect of adding subject-specific features, which yielded modest performance gains. While these features provided some improvement, model performance primarily depended on sensor data, reinforcing the need to integrate both biomechanical and Artificial Intelligence-driven insights. From an engineering application perspective, our findings guide researchers and clinicians in selecting the most suitable model and sensor placement based on both accuracy and computational complexity. Specifically, we highlight thigh-mounted IMU as the most effective placement for capturing landing dynamics. These insights support the practical deployment of knee joint moment prediction systems in real-world settings, such as gyms or training centers, where compact sensors and limited computational resources are essential.},
  archive      = {J_EAAI},
  author       = {Tommy Sugiarto and Yi-Jia Lin and Ya-Wen Tu and Hsiao-Liang Tsai and Lin-Fen Hsieh and Chi-Tien Sun and Patrik Kutilek and Wei-Chun Hsu},
  doi          = {10.1016/j.engappai.2025.112136},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112136},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring knee joint moment prediction models for landing task with various model architecture: Leveraging inertial measurement unit sensors data and subject-specific attributes},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key region semantic information augmented transformer for image captioning. <em>EAAI</em>, <em>161</em>, 112135. (<a href='https://doi.org/10.1016/j.engappai.2025.112135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing image captioning models often face difficulties in capturing inter-object relationships and generating description that comprehensively understands the entire image content, either relying on object detectors that overlook contextual information or depending on grid features that fail to adequately model spatial interactions. This paper proposes two solutions to these challenges. The first is the introduction of a module for mining semantic information from key regions. Based on the spatial proximity and high co-occurrence between objects, this module identifies the public region covered by these objects as a key region, mines their semantic information, and incorporates it into the modeling process, which compensates for the limitations of grid features. Second, we improve the standard Transformer decoder’s architecture by innovatively introducing an adaptive gating mechanism that dynamically adjusts the alignment between textual and visual features, enhancing the model’s overall comprehension of the image. To validate our approach, we applied these modules to the Transformer framework and proposed a novel method for image captioning, called Key region Semantic information Augmented Transformer (KSAT) for Image Captioning. Extensive experiments on benchmark datasets show that the proposed method outperforms many models. Specifically, our method achieves a score of 139.6% on the offline test, and 138.4% on the official online test server on the Consensus-based Image Description Evaluation (CIDEr) metric. In qualitative evaluation, our method also outperforms other methods at generating captions for complex scenes. Overall, these results confirm the validity of our method and advance the field of artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Fuyun Deng and Wei Li and Zhixin Li},
  doi          = {10.1016/j.engappai.2025.112135},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112135},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Key region semantic information augmented transformer for image captioning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced neural-network-based iterative learning control considering iterative uncertainties for piezoelectric actuated micro-positioning platform. <em>EAAI</em>, <em>161</em>, 112134. (<a href='https://doi.org/10.1016/j.engappai.2025.112134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research aims to developing a new enhanced data-driven sliding-mode iterative learning control (E-DDSILC) strategy for piezoelectric actuated micro-positioning (PAMP) platforms. For the first time, the analysis demonstrating that errors converge to 0 in E-DDSILC is successfully extended from strictly repetitive systems to systems with non-strictly repetitive initial conditions. This generalization expands the practical application range of E-DDSILC. Simultaneously, iterative uncertainties are considered, which are the major factor affecting the performance of iterative learning control. To address these uncertainties, a diagonal recurrent neural network is employed to fit and compensate for them within a dynamic linearization model, thereby further enhancing the tracking accuracy and practicability of E-DDSILC. Finally, Several experiments are performed on a PAMP platform to compare the developed E-DDSILC method with both classical DDSILC and traditional E-DDSILC schemes. Comparative experimental results prove the superiority of the developed controller.},
  archive      = {J_EAAI},
  author       = {Miaolei Zhou and Yulong Sun and Xiuyu Zhang and Wei Gao and Chun-Yi Su},
  doi          = {10.1016/j.engappai.2025.112134},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112134},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced neural-network-based iterative learning control considering iterative uncertainties for piezoelectric actuated micro-positioning platform},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-driven multi-stage stochastic optimization for sustainable humanitarian supply chain using machine learning algorithms. <em>EAAI</em>, <em>161</em>, 112133. (<a href='https://doi.org/10.1016/j.engappai.2025.112133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The frequency and severity of natural disasters have intensified, resulting in significant human, financial, and emotional consequences. Earthquakes, in particular, have caused severe economic losses, deaths, and homelessness among millions. This study is designed to establish a comprehensive plan for managing pre- and post-disaster phases, including preparations, responses, and recovery efforts. It introduces a Multi-Stage Stochastic Programming (MSSP) model for sustainable humanitarian relief operations, optimizing location, allocation, and inventory management. The first and third stages concentrate on minimizing environmental impacts, while the second stage centers on enhancing social welfare. Simultaneously, economic cost reduction is consistently pursued in all three stages. The model's primary advantages include optimized inventory management to avoid shortages and flexible logistics strategies for timely and cost-effective delivery of relief items. Additionally, it ensures continuous aid, addressing both short-term and long-term needs to improve disaster management effectiveness and resilience. The multi-objective model is solved using Augmented Epsilon-Constraint (AEC). Furthermore, this paper employs Multi-Criteria Decision-Making (MCDM) methods to rank suppliers, leveraging Machine Learning (ML) algorithms to enhance ranking precision, thereby leading to a more responsive Supply Chain (SC). A real-world case study is then provided to illustrate the applicability and validity of the proposed model. Focusing on achieving balanced sustainability across all three stages, ensuring seamless logistics for all humanitarian supplies and affected individuals, and addressing uncertainties, the model determines the optimal quantities of all relief items to store. Through comprehensive analysis, the results provide key insights into the importance of MSSP in disaster management plans, enhancing understanding of the model's effectiveness.},
  archive      = {J_EAAI},
  author       = {Farnaz Ansari and Ali Bozorgi-Amiri and Hossein Shakibaei},
  doi          = {10.1016/j.engappai.2025.112133},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112133},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A data-driven multi-stage stochastic optimization for sustainable humanitarian supply chain using machine learning algorithms},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A theme music generation model based on hybrid variational autoencoders and conditional generative adversarial networks. <em>EAAI</em>, <em>161</em>, 112131. (<a href='https://doi.org/10.1016/j.engappai.2025.112131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The musical theme is the core melodic element that runs through a work. It is the main source of recognizable features and the basis of the overall structure of the score. However, existing music generation systems often face problems with missing thematic features and monotonous structure. These systems find it difficult to capture the complex thematic changes and long-term dependencies in music, resulting in a lack of dynamic changes, artistic expression in phrasing, and structural coherence in the generated results. In this paper, we propose a thematic music generation model based on a generative adversarial network, named Thematic Music Conditional Generative Adversarial Network (TM-CGAN), which solves these challenges through three key innovations. First, we propose a thematic fusion degree calculation module based on multi-dimensional feature metrics to overcome the theoretical limitations of existing methods, which lack explicit modeling of thematic features. Subsequently, we construct a two-dimensional image representation learning framework that preserves Musical Instrument Digital Interface (MIDI) symbolic sequences and employs convolutional neural networks (CNNs) to effectively model the multi-dimensional feature dependencies inherent in musical structures. Finally, we design a hybrid variational autoencoder-conditional generative adversarial network architecture that processes latent space modeling of thematic features through variational inference mechanisms while simultaneously optimizing generation quality through adversarial training. We conducted comprehensive experiments across three diverse MIDI music datasets to validate our approach. The experimental results demonstrate that TM-CGAN significantly outperforms state-of-the-art baseline models on multiple evaluation metrics, including generated music quality, theme representativeness, and structural integrity.},
  archive      = {J_EAAI},
  author       = {Fangzhu Jin and Peng Li and Xiaojun Wu},
  doi          = {10.1016/j.engappai.2025.112131},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112131},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A theme music generation model based on hybrid variational autoencoders and conditional generative adversarial networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Malicious detection and trust calculation using residual recurrent neural network for trust with quality of service-aware multicast routing in mobile ad-hoc network system. <em>EAAI</em>, <em>161</em>, 112130. (<a href='https://doi.org/10.1016/j.engappai.2025.112130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Mobile Ad-hoc Network is a collection of mobile nodes without any proper infrastructure. In this work, a novel trust and Quality of Service-aware multicast routing technique for Mobile Ad-hoc Network is introduced. The key scope of this research paper is to evaluate the trust with Quality of Service -aware multicast routing process in Mobile Ad-hoc Network by detecting malicious nodes. For performing the optimal routing without any suspicious attacks initially the malicious node detection is performed by Residual Recurrent Neural Network. Further, if the Mobile Ad-hoc Network model is normal and free from malicious nodes, then the true value is calculated by utilizing the outcome of malicious node detection. If the node is free from malicious then, the trust value becomes high or else the trust value becomes low. Once, the trust calculation is completed the optimal routing is performed in the Mobile Ad-hoc Network with the support of the Enhanced Artificial Rabbits Optimization algorithm. Moreover, different constraints like hop count, throughput, Packet Delivery Ratio, delay, and energy consumption are derived. Further, different experiments are evaluated to prove the effectiveness of the implemented model against several baseline technique. Hence, the developed model accomplishes superior efficiency in detecting the malicious and performs the multicast routing in the Mobile Ad-hoc Network.},
  archive      = {J_EAAI},
  author       = {Sanjaya Kumar Sarangi and Rasmita Lenka and Janmejaya Mishra and Ritarani Sahu and Arabinda Nanda},
  doi          = {10.1016/j.engappai.2025.112130},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112130},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Malicious detection and trust calculation using residual recurrent neural network for trust with quality of service-aware multicast routing in mobile ad-hoc network system},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy management system scheduling optimization based on an improved generative adversarial network deep reinforcement learning algorithm. <em>EAAI</em>, <em>161</em>, 112129. (<a href='https://doi.org/10.1016/j.engappai.2025.112129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Households, as electricity consumers, play a critical role in achieving the carbon peak and carbon neutrality goals. The development of smart grids provides technical support for the efficient integration and distribution of renewable energy, gradually extending to household users. This has led to higher demands for the stability of electricity supply to address the growing electricity demand and the uncertainties associated with renewable energy. To address this, this paper proposes an improved generative adversarial network and an enhanced deep reinforcement learning algorithm to improve the scheduling capability of the energy management system. First, we introduce an improved wasserstein generative adversarial network that combines stochastic differential equations and autocorrelation penalty terms with the generator. The experimental results demonstrate that the proposed method can generate high-quality time series data. The generated data were used to train our scheduling model, effectively enhancing its generalization capability. Secondly, We introduced the Minmax mechanism to address Q-value estimation bias by utilizing multiple Q-networks. This mechanism first divides the target Q-values into several groups, selects the maximum value from each group, and then takes the minimum among these maxima as the final target Q-value. We applied this mechanism to improve deep reinforcement learning algorithms based on multi-Q-value evaluation. Comparison experiments show that this improvement significantly enhances the algorithm’s performance, outperforming traditional algorithms in terms of convergence, volatility, and final rewards. The energy management system demonstrates stronger adaptability when handling uncertainties arising from renewable energy variations, ensuring reliable power supply and achieving balanced energy management.},
  archive      = {J_EAAI},
  author       = {Weipeng Chao and Yuanbo Shi and Yushuai Li and Meng Liu and Xiaoling Leng},
  doi          = {10.1016/j.engappai.2025.112129},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112129},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Energy management system scheduling optimization based on an improved generative adversarial network deep reinforcement learning algorithm},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep ensemble learning and error correction method for remaining useful life prediction of rolling bearings. <em>EAAI</em>, <em>161</em>, 112128. (<a href='https://doi.org/10.1016/j.engappai.2025.112128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearings are critical components of rotating machinery, and the prediction of their remaining useful life (RUL) is important for system reliability and operating efficiency. A novel RUL prediction method based on deep ensemble learning and error correction is here proposed. Firstly, the moving average filter (MAF) is applied to preprocess vibration signals for removing outliers and noise. Then, time-domain features are extracted from the processed vibration signals, and optimized to obtain imperative feature signals. Subsequently, a deep ensemble learning model is built with gated recurrent unit (GRU), bidirectional GRU (BiGRU), long short-term memory (LSTM) and bidirectional LSTM (BiLSTM) as base learners, and the overall performance of the prediction model is enhanced by introducing an error correction strategy. The MAF method is also used to smooth the trend of the RUL prediction outcomes. Finally, the proposed method is applied to two full-lifecycle rolling bearing datasets: the Prognostics and Health Management 2012 (PHM2012) dataset and the Intelligent Maintenance System (IMS) dataset. It is evaluated using mean square error (MSE), mean absolute error (MAE), and the R-square coefficient of determination (R 2 ). The test results demonstrate that the method achieves highly accurate RUL predictions: on the PHM2012 dataset, the MSE, MAE, and R 2 reach 0.000380, 0.013695, and 0.994716, respectively; on the IMS bearing dataset, the corresponding values are 0.001056, 0.015403, and 0.978346. In addition, the method outperforms traditional single models (GRU, BiGRU, LSTM, BiLSTM) as well as the Transformer model in both cases, with R 2 improvements over the Transformer of 0.011065 and 0.008744, respectively. These results highlight the superior generalization capability and robustness of the proposed method, making it applicable to industrial environments requiring reliable RUL prediction.},
  archive      = {J_EAAI},
  author       = {Wenzhe Yin and Hong Xia and Enrico Zio and Xueying Huang},
  doi          = {10.1016/j.engappai.2025.112128},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112128},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep ensemble learning and error correction method for remaining useful life prediction of rolling bearings},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maritime supply chain optimization using robust adversarial reinforcement learning. <em>EAAI</em>, <em>161</em>, 112127. (<a href='https://doi.org/10.1016/j.engappai.2025.112127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores novel strategies for analyzing and managing port productivity in a multi-stage supply chain network by integrating synchronization and reinforcement learning (RL) techniques. Current port management systems face issues with nonlinearity, high interdependency, and vulnerability to market disruptions, which might destabilize port operations. To tackle these issues, seaport operations are examined in four stages of implementation: the terminal operator, inland carrier, inland terminal operator, and consignee. Brownian motion is applied to characterize stochastic disruptions in volatile markets, and the port performance under market disruptions is analyzed using nonlinear data analytics. The dynamical analysis reveals that port management systems exhibit highly coupled nonlinear dynamics with a tendency towards instability. The complex nature of maritime port logistics requires innovative strategies to analyze container handling volumes, optimize the strategic planning of port management, and improve overall efficiency. A novel optimal policy for port operations is realized by integrating a deep deterministic policy gradient into robust adversarial deep learning. A deep reinforcement learning algorithm is employed to learn adaptively from historical port-related data and real-time container handling feedback, enabling intelligent strategies to make informed decisions and dynamically adjust policies in response to stochastic disruptions or changing market conditions. Quantitative results demonstrate that the proposed strategy achieves up to 97.78 % operating efficiency despite disturbances, and the adversarial attacks are shown to decrease port productivity by up to 77.78 % in scenarios without robust deep learning support. This study contributes to the growing field of intelligent port operations by paving the way for more adaptive and smart solutions in the maritime supply chain network.},
  archive      = {J_EAAI},
  author       = {Truong Ngoc Cuong and Sam-Sang You and Le Ngoc Bao Long and Hwan-Seong Kim and Duy Anh Nguyen and Nguyen Duy Tan},
  doi          = {10.1016/j.engappai.2025.112127},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112127},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Maritime supply chain optimization using robust adversarial reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Employing dual-path structure and soft attention mechanism to enhance recognition and classification of wild medicinal licorice in xinjiang. <em>EAAI</em>, <em>161</em>, 112126. (<a href='https://doi.org/10.1016/j.engappai.2025.112126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Licorice is highly valued in traditional Chinese medicine for its anti-inflammatory, antiviral, and immunomodulatory properties, and is widely used in the pharmaceutical, food, and cosmetic industries. Xinjiang, the largest licorice-producing region in China, faces severe overharvesting of wild licorice due to increasing market demand, threatens natural populations and fragile ecosystems. Accurate identification and classification of licorice species are crucial for environmental protection and sustainable resource utilization, as traditional methods relying on experience are inefficient, subjective, and prone to errors. This study builds on the Inception-Residual Network-Version 2 (Inception-ResNet-V2) architecture and proposes an advanced licorice recognition model called Inception-ResNet-V2-Soft Attention, Dual-path Structure, and Focal Loss (IRV2-SDF). The IRV2-SDF model integrates a soft attention mechanism that focuses on key regions, a dual-path structure for multi-scale feature extraction, and a focal loss function to address class imbalance. It aims to improve the identification and classification of three wild licorice species ( Glycyrrhiza glabra , Glycyrrhiza inflata , and Glycyrrhiza uralensis ) and associated weeds in complex environments. Trained on 3,653 images collected from Xinjiang, the model achieves an average recognition accuracy of 91.79%, surpassing traditional models, with accuracy improvements of 4.27%, 2.08%, 2.76%, and 6.36% for G. glabra , G. inflata , G. uralensis , and weeds, respectively. By effectively reducing background noise and enhancing detection capabilities, the model overcomes the limitations of traditional methods and provides a robust solution for wild licorice recognition. This research offers a technical foundation for licorice conservation and sustainable utilization and can serve as a reference for identifying other medicinal plants in complex environments.},
  archive      = {J_EAAI},
  author       = {Yuan Qin and Jianguo Dai and Guoshun Zhang and Miaomiao Xu and Jing Yang and Jinglong Liu},
  doi          = {10.1016/j.engappai.2025.112126},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112126},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Employing dual-path structure and soft attention mechanism to enhance recognition and classification of wild medicinal licorice in xinjiang},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time cooperative target tracking in cluttered environments using multiple drone swarms with adaptive fuzzy emotional learning. <em>EAAI</em>, <em>161</em>, 112125. (<a href='https://doi.org/10.1016/j.engappai.2025.112125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a real-time adaptive trajectory prediction framework for cooperative unmanned aerial vehicle (UAV) swarms engaged in dynamic target tracking within cluttered environments. The proposed system introduces a novel artificial intelligence (AI)-based control architecture combining fuzzy inference, neuro-emotional learning, and distributed multi-agent coordination. At the core of the approach is a Bidirectional Fuzzy Brain Emotional Learning Prediction (BFBEL-P) model, which integrates fuzzy logic and an online adaptive neural structure to enable trajectory forecasting without pre-training or prior knowledge of the environment. From an engineering perspective, this AI model is deployed in UAV swarm navigation, where robust decision-making, predictive coordination, and obstacle avoidance are essential for target interception missions. In contrast to conventional prediction methods, such as curve fitting, nonlinear model predictive control (MPC), and deep learning-based Long Short-Term Memory (LSTM) networks, the BFBEL-P framework offers fast convergence, low computational cost, and high adaptability. The system incorporates multi-threaded data fusion across the swarm to achieve consensus-driven predictions and maintain situational awareness, even under sensor failures or occlusions. Simulation results show that BFBEL-P improves short-term prediction accuracy by 82.2%, reduces prediction time by 15%, and achieves a 100% tracking success rate across benchmark scenarios. These results establish BFBEL-P as a reliable AI technique for distributed control in real-world UAV swarm applications, offering a promising tool for search-and-rescue, surveillance, and defense operations.},
  archive      = {J_EAAI},
  author       = {Lucas William Page and Vu Phi Tran and Duy Luan Nguyen},
  doi          = {10.1016/j.engappai.2025.112125},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112125},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time cooperative target tracking in cluttered environments using multiple drone swarms with adaptive fuzzy emotional learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical multi-scale matched masked autoencoder for industrial multi-rate time series modeling. <em>EAAI</em>, <em>161</em>, 112122. (<a href='https://doi.org/10.1016/j.engappai.2025.112122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical industrial processes, due to sensor hardware limitations, the sampling rates of different variables often vary, leading to multi-rate time series (MRTS) data. However, the distribution of multi-scale dynamics in MRTS data typically follows a step-like pattern, with intricate scale transitions from fine to coarse and complex scale-consistent dependencies across rates. Additionally, the inherent characteristics of MRTS data often result in label scarcity. Both factors present significant challenges for MRTS modeling. To address these issues, we propose a novel self-supervised learning strategy, called H ierarchical M ulti-Scale M atched M asked A utoencoder (H3MAE). Specifically, we design a scale-matching input fusion mechanism where each layer is hierarchically aligned to a specific scale, with the scale-matching integration from two sources, effectively capturing the multi-scale dynamics and cross-rate scale-consistent dependencies in MRTS data. Besides, we introduce a novel auxiliary task that imputes masked positions in the encoded representation space at each layer, aiming to achieve MRTS representation learning and mitigate label scarcity. Furthermore, we propose a unique encoder-imputer structure in each layer to enable multi-scale self-supervised learning while generating temporally aligned features satisfying the input requirements of the next layer. Experimental results on three benchmark datasets and two industrial multi-rate tasks demonstrate that our framework yields better performance in MRTS modeling. The code is publicly available at https://github.com/monolithycq/H3MAE .},
  archive      = {J_EAAI},
  author       = {Changqing Yuan and Yongfang Xie and Shiwen Xie and Jie Wang},
  doi          = {10.1016/j.engappai.2025.112122},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112122},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical multi-scale matched masked autoencoder for industrial multi-rate time series modeling},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised feature selection via latent feature representation and modified graph embedding. <em>EAAI</em>, <em>161</em>, 112121. (<a href='https://doi.org/10.1016/j.engappai.2025.112121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data in practical applications are correlated not only between samples but also between high-dimensional features. Latent representations can effectively represent such correlations. Existing latent representation methods mainly consider inter-instance relationships and rely on constructing similarity graphs. However, the interconnection information obtained by latent representations is redundant due to the noise and irrelevance of the raw data. Therefore, to address the above issues, this paper proposes an unsupervised feature selection by latent feature representation and modified graph (LFRMG, for short) embedding. First, a latent feature representation norm for learning self-representation structure is designed to explore the interconnections among features. Mining feature relationships via self-representation can solve the redundancy caused by fixed similarity graph relationships. Second, the latent feature representation is combined with modified graph regularization to achieve good feature interconnections while maintaining local data information. In addition, the l 2 , 0 -norm is utilized to select the full-row sparse projection of salient features to avoid the drawbacks of sparsity limitation and parameter tunability. A scheme for solving the closed form of l 2 , 0 is constructed. Finally, the presented approach is superior to many state-of-the-art unsupervised methods through comprehensive experiments on nine existing datasets.},
  archive      = {J_EAAI},
  author       = {Jialing Yan and Gang Hu and Guo Wei},
  doi          = {10.1016/j.engappai.2025.112121},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112121},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised feature selection via latent feature representation and modified graph embedding},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coarse-to-fine dual-branch network for ship target recognition in complex environments. <em>EAAI</em>, <em>161</em>, 112120. (<a href='https://doi.org/10.1016/j.engappai.2025.112120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harsh sea conditions and the complex and variable positions of ships significantly impact the capacity of imaging devices to capture high-quality ship images, making ship target recognition challenging in the application of artificial intelligence. Many scholars have recently proposed cascaded recognition models to address this issue. Following this method, in this paper, we propose a novel method for ship target recognition in complex environments called the coarse-to-fine dual-branch (CFDB) network. The CFDB model designs a dual-branch network from coarse to fine to lock the target area fine features and then uses peer-to-peer communication to extract and exchange learning of the target region’s final discriminative contour features, assisting in predicting ship classes in the complex environment. The proposed method is evaluated on the constructed complex in background ships (CIB-ships) dataset and the publicly available Marine Argos Recognition Ships (MAR-ships) and Game-of-Ships datasets. Compared with the suboptimal method, the proposed CFDB network exhibits improvements of 2.11%, 1.33%, and 1.24% accuracy on the CIB-ships, MAR-ships, and Game-of-ships datasets, respectively. The results demonstrate that the proposed method provides useful ideas for the dynamic monitoring of ships in real environments. Our code will be published at https://github.com/yangt1013/CFDB-master .},
  archive      = {J_EAAI},
  author       = {Yang Tian and Hao Meng},
  doi          = {10.1016/j.engappai.2025.112120},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112120},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Coarse-to-fine dual-branch network for ship target recognition in complex environments},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-scale sparse channel transformer network for image reconstruction of astronomical bright source contamination. <em>EAAI</em>, <em>161</em>, 112119. (<a href='https://doi.org/10.1016/j.engappai.2025.112119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bright source contamination has long been a challenging issue in the field of image processing, particularly in applications such as astronomical observations, satellite imaging, and nighttime surveillance. To address this issue, this paper proposes a novel Multi-Scale Sparse Channel Transformer Network (MSCformer) aimed at achieving high-quality image reconstruction under the influence of bright source contamination. The network integrates a Top-k Sparse Attention mechanism with a Channel Attention module, enabling selective focus on the most informative features and adaptive weight allocation across channels. Additionally, a Multi-Scale Dual-Gate Feedforward Network is designed to further enhance the expression of valuable features while suppressing redundant information. Experimental results demonstrate that the proposed method exhibits outstanding performance in practical applications on the Sloan Digital Sky Survey (SDSS) photometric image dataset. Compared to existing state-of-the-art techniques, MSCformer achieves significant performance improvements, with a Peak Signal-to-Noise Ratio (PSNR) of 45.093 decibel(dB), a Structural Similarity Index Measure(SSIM) of 0.978, and a Pixel Average Absolute Error (PAAE) of 0.675. This not only significantly enhances the removal of bright source contamination in the field of astronomy but also provides important reference value for subsequent research in related domains.},
  archive      = {J_EAAI},
  author       = {Yajuan Zhang and Congcong Shen and Xia Jiang and Bo Qiu and Ali Luo and Fuji Ren and Yuanlu Chen},
  doi          = {10.1016/j.engappai.2025.112119},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112119},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-scale sparse channel transformer network for image reconstruction of astronomical bright source contamination},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Seismic damage assessment of reinforced concrete frame structures based on transfer-residual networks. <em>EAAI</em>, <em>161</em>, 112118. (<a href='https://doi.org/10.1016/j.engappai.2025.112118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post-earthquake building damage assessment is a critical research focus in civil engineering due to its vital role in guiding timely and informed rescue operations. This study proposes a rapid seismic damage assessment method for reinforced concrete frame structures based on transfer-residual networks. The methodology involves pre-training a base model on a large dataset generated from computationally efficient simplified model simulations, followed by transfer learning on a smaller, high-fidelity dataset derived from refined finite element model simulations. This approach significantly enhances prediction accuracy while reducing computational costs for seismic damage assessment in new building structures. Optimization of model parameters was performed to find the optimal residual network, which achieves an accuracy of 91.2 % with a remarkable 32-fold speedup over conventional nonlinear time-history analysis methods. Moreover, the transfer-residual network enhances accuracy by 10 % compared to training from scratch. The results conclusively demonstrate the feasibility of utilizing large datasets from simplified models to improve the training accuracy of refined models with limited data, providing a valuable reference for advancing transfer learning-based frameworks in seismic damage assessment of buildings.},
  archive      = {J_EAAI},
  author       = {Chen Xiong and Zhijie Luo and Jie Zheng and Linlin Xie and Liu Mei and Lixiao Li and Wujian Long},
  doi          = {10.1016/j.engappai.2025.112118},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112118},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Seismic damage assessment of reinforced concrete frame structures based on transfer-residual networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-enabled performance-based design of three-dimensional printed engineered cementitious composites. <em>EAAI</em>, <em>161</em>, 112117. (<a href='https://doi.org/10.1016/j.engappai.2025.112117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The superior tensile ductility of engineered cementitious composites (ECC) offers a promising solution to the challenge of integrating conventional steel reinforcement in three-dimensional (3D) concrete printing (3DCP). However, the widespread adoption of 3D printed ECC (3DP-ECC) is hindered by the reliance on trial-and-error design process. The complex material component and inherent anisotropy of 3DP-ECC pose challenges for accurate property prediction and inverse design. This paper introduces a performance-based design strategy for 3DP-ECC, leveraging machine learning (ML) and multi-objective optimization. The anisotropic-mechanical properties including compressive strength and flexural strength were experimentally and statistically investigated; further, ML prediction models conbined with multi-objective optimization algorithm were developed to inversely design 3DP-ECC for specific mechanical performance requirements, while reducing carbon footprint and material cost. Specifically, an extensive database was assembled, followed by grey relational analysis (GRA) to identify the parametric sensitivity of the mechanical properties of 3DP-ECC. Three representative ML techniques were employed, with the back-propagation artificial neural network (BPANN) demonstrating superior predictive accuracy. Model interpretability analyses uncovered the importance of input parameters and their influence on predicted outcomes. Lastly, non-dominated Sorting Genetic Algorithm II (NSGA-II) integrated with the BPANN models was applied to perform the inverse design of 3DP-ECC, showing good effectiveness and accuracy. This work offers an efficient and viable avenue for performance-based design for 3DP-ECC, along with the potential to develop low-carbon cost-effective 3DP-ECC.},
  archive      = {J_EAAI},
  author       = {Wenguang Chen and Long Liang and Junhong Ye and Lingfei Liu and Neven Ukrainczyk and Liqiang Yin and Jiangtao Yu and Kequan Yu},
  doi          = {10.1016/j.engappai.2025.112117},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112117},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning-enabled performance-based design of three-dimensional printed engineered cementitious composites},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized text-to-image generation with large language and vision assistant enhanced training. <em>EAAI</em>, <em>161</em>, 112116. (<a href='https://doi.org/10.1016/j.engappai.2025.112116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized image generation aims to synthesize images of a specific identity. The identity, denoted as V ∗ , refers to an entity with distinctive visual attributes, such as a dog-shaped backpack. However, existing methods like DreamBooth and Custom Diffusion often struggle to generate images of V ∗ that accurately match the input prompts. In this work, we analyze two key issues underlying this limitation: (1) the overbinding problem , where the prompt tokens used to represent V ∗ unintentionally bind to irrelevant visual details from the reference image during training; and (2) the low language prior problem , where insufficient use of pre-trained language prior limits the model’s ability to faithfully generate all the prompt words. To overcome these challenges, we propose LLaVA-Booth, a novel personalization method for diverse, identity-preserving image generation, based on Large Language and Vision Assistant (LLaVA) enhanced training. Our method alleviates the overbinding problem by disentangling background information and solves the low language prior problem by enriching the language context. Additionally, we introduce two auxiliary objectives: (1) an identity (ID) binding loss to strengthen the identity binding and (2) a prior preservation loss to prevent language drift and encourage generation diversity. Experiments demonstrate that LLaVA-Booth effectively mitigates overbinding and enhances language priors to improve prompt fidelity, then generates diverse, high-quality, and identity-preserving images of V ∗ .},
  archive      = {J_EAAI},
  author       = {Junsheng Luan and Zhanjie Zhang and Wei Xing and Lei Zhao},
  doi          = {10.1016/j.engappai.2025.112116},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112116},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Personalized text-to-image generation with large language and vision assistant enhanced training},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-view new energy vehicle form generation design method combining kansei imagery and deep learning. <em>EAAI</em>, <em>161</em>, 112115. (<a href='https://doi.org/10.1016/j.engappai.2025.112115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the competitive landscape of new energy vehicles, exterior design has become a crucial differentiator amid functional homogenization. User preferences are central to shaping vehicle appearance, yet most perceptual design methods rely on a single viewpoint, limiting insights into complex preference patterns. This study proposes a multi-perspective mapping approach that integrates Kansei engineering with deep learning. Firstly, user core imagery is collected and mined through big data. Secondly, Kernels Network (KNet) semantic segmentation model, Residual Networks (ResNet) tri-view (front/side/rear) score prediction model and fully connected network (FCN) feature fusion model are integrated to construct a multi-view feature mapping system. Finally, the optimal combination of morphological elements is explored based on the Elite Genetic Algorithm (EGA), and the scheme is validated through generative artificial intelligence (AI) workflow. The experimental results demonstrate that, employing “Cool” as a case study, the three-view scheme and the combination scheme devised by this research process exhibit substantial superiority over the majority of the samples. Under identical parameters, the scheme with decision constraints surpasses the randomly generated scheme in terms of perceptual scores and stability. The performance of the test set and the experimental results collectively substantiate the model’s validity. This workflow—covering preference extraction, morphological decomposition, AI-driven generation, and validation—provides a scalable framework for new energy vehicle exterior design. It also demonstrates novel applications of Kansei engineering in multi-view fusion and generative form design.},
  archive      = {J_EAAI},
  author       = {Zihao Wang and Le Xi and Yifan Ding and Wenjie Fang and Kaiming Wang and Hongliang Zuo},
  doi          = {10.1016/j.engappai.2025.112115},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112115},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-view new energy vehicle form generation design method combining kansei imagery and deep learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable remaining useful life uncertainty prediction method for rolling bearing. <em>EAAI</em>, <em>161</em>, 112114. (<a href='https://doi.org/10.1016/j.engappai.2025.112114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearing remaining useful life prediction is the core technology of equipment maintenance. Although deep learning-based prediction methods have made significant breakthroughs, the problems of insufficient model explainability and prediction result uncertainty quantification have seriously constrained the credibility of maintenance decisions. Therefore, this research combines prediction uncertainty quantification with model explanation to propose an explainable uncertainty prediction method. The method includes multi-dimensional feature extraction, remaining useful life uncertainty prediction, and Shapley additive explanations interpreter. For feature extraction, multi-dimensional feature vectors are constructed as network inputs by extracting time-domain features and frequency-domain features. Then, the remaining useful life prediction interval for the rolling bearing is compressed by the proposed gated temporal quantile network. Finally, the prediction model is explained using the Shapley additive explanations interpreter. The multi-case validation results based on the Xi'an Jiaotong University and Changxing Sumyoung Technology Co., Ltd. (XJTU-SY) and Intelligent Maintenance Systems (IMS) rolling bearing full life cycle datasets show that the proposed model has an average interval coverage of 93.96 % and an average interval width of 9.92 %, which indicates that the model maintains high accuracy and robustness in different cases. The nonlinear mapping relationship between the prediction results and the features is clarified by analyzing the Shapley values. Finally, the Shapley values are used to rank the importance of the features to locate the position that may cause rolling bearing performance degradation, which provides credible decision support for the development of the predictive maintenance strategy.},
  archive      = {J_EAAI},
  author       = {Ting Zhang and Honglei Wang},
  doi          = {10.1016/j.engappai.2025.112114},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112114},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable remaining useful life uncertainty prediction method for rolling bearing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based estimation of sound transmission loss in single and double-layered rectangular functionally graded plates. <em>EAAI</em>, <em>161</em>, 112112. (<a href='https://doi.org/10.1016/j.engappai.2025.112112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a robust machine learning (ML) framework for predicting sound transmission loss (STL) in temperature-dependent functionally graded (FG) single- and double-layered plates, combining analytical modeling and data-driven approaches. The FG plates are modeled with material properties varying along the thickness via a power-law distribution, incorporating nonlinear temperature effects. A high-fidelity analytical solution is derived using first-order shear deformation theory (FSDT) and acoustic velocity potential, with governing equations formulated via Hamilton's principle and solved using the weighted residual method. To enable ML training, a large-scale parametric study generates 189,000 data points, covering variations in plate geometry, temperature, acoustic cavity depth, gradient index, and incident wave angles. ML algorithms are trained on this data to predict STL, with the extreme gradient boosting (XGBoost) algorithm demonstrating the highest accuracy (coefficient of determination R 2 = 99.38 % for training data and R 2 = 99.11 % for test data). The validated ML model is then employed to investigate key parameters—temperature, power-law index, incidence angle, cavity depth, and plate thickness—revealing their nonlinear interactions and impact on STL performance. The developed artificial intelligence (AI) framework provides an efficient tool for acoustic design optimization, offering real-time parameter tuning capabilities for engineers working with functionally graded acoustic barriers.},
  archive      = {J_EAAI},
  author       = {Chunfeng Jiang and Masoud Babaei},
  doi          = {10.1016/j.engappai.2025.112112},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112112},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning-based estimation of sound transmission loss in single and double-layered rectangular functionally graded plates},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cubic linguistic T-spherical fuzzy aggregation operator-based multi-attribute group decision-making model and its application to food waste treatment technique selection. <em>EAAI</em>, <em>161</em>, 112111. (<a href='https://doi.org/10.1016/j.engappai.2025.112111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food waste presents significant environmental, economic, and social challenges globally, contributing to resource depletion and greenhouse gas emissions. Effective treatment techniques are essential for minimizing these impacts, promoting sustainability, and supporting circular economy practices. However, selecting the most suitable food waste treatment technique is a complex multi-attribute group decision-making (MAGDM) problem that involves the simultaneous consideration of environmental, economic, and social factors under significant uncertainty. To address this challenge, this study proposes a novel cubic linguistic T-spherical fuzzy sets (CLT-SFSs) framework, which integrates linguistic T-spherical fuzzy sets and linguistic interval-valued T-spherical fuzzy sets to enhance decision-making precision under uncertainty. The proposed CLT-SF framework offers a unified structure capable of capturing both qualitative expert opinions and quantitative uncertainty ranges, offering unprecedented expressiveness for complex sustainability assessments. First, the formal definition and basic operations for CLT-SF numbers, including addition, multiplication, scalar multiplication, and scalar power, and a comparison law are established. Next, to efficiently aggregate cubic linguistic T-spherical fuzzy information, we propose the cubic linguistic T-spherical fuzzy weighted averaging and the cubic linguistic T-spherical fuzzy weighted geometric aggregation operators. These aggregation operators can effectively and comprehensively aggregate attribute values in MAGDM problems. Subsequently, utilizing these operators, a CLT-SFS-based combinative distance-based assessment model is developed to address MAGDM problems. The model's applicability and robustness are demonstrated through a real-world case study on the selection of food waste treatment techniques. A parameter analysis is also conducted to examine the sensitivity of ranking outcomes. Finally, a comparative analysis with existing methods confirms the proposed model's effectiveness, feasibility, and advantages in addressing complex decision-making scenarios. This research not only advances the theoretical framework of fuzzy decision-making but also provides a practical tool for stakeholders in waste management to make informed and sustainable choices.},
  archive      = {J_EAAI},
  author       = {Shahid Hussain Gurmani and Weiping Ding and Rana Muhammad Zulqarnain and Jiangfeng Hao},
  doi          = {10.1016/j.engappai.2025.112111},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112111},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cubic linguistic T-spherical fuzzy aggregation operator-based multi-attribute group decision-making model and its application to food waste treatment technique selection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextual and orientation correction modules enhance weakly-supervised aerial object detection in remote sensing images. <em>EAAI</em>, <em>161</em>, 112110. (<a href='https://doi.org/10.1016/j.engappai.2025.112110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenges of context and orientation ambiguity in weakly supervised aerial object detection. While current research focuses on improving detection accuracy and efficiency, it often encounters difficulties with contextual and rotational variations in aerial imagery. We propose a novel Context and Orientation Correction (COC) framework, which includes two innovative modules: a context correction module and an orientation correction module. The context correction module utilizes style normalization to guide the model in identifying atypical objects within specific contextual scenes by mitigating contextual disparities between instances and refining contextual information. Additionally, the orientation correction module aims to reduce feature distance between instances with varying orientations, leveraging contrastive learning to ensure consistent object representations. Furthermore, we introduce a category-aware aggregation loss to enhance similarity in feature representations of objects from the same category, thereby addressing the class collision issue commonly associated with contrastive learning. Our COC framework achieves 27.6% mean Average Precision and 59.8% mean Average Precision on the Detection in Optical Remote Sensing Image (DIOR) and Northwestern Polytechnical University Very High Resolution 10. v2 (NWPU VHR-10.v2) datasets, respectively, demonstrating its significant effectiveness.},
  archive      = {J_EAAI},
  author       = {Le Yang and Shunzhou Wang and Xuerong Wang and Shutong Wang and Yuting Lu and Binglu Wang},
  doi          = {10.1016/j.engappai.2025.112110},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112110},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contextual and orientation correction modules enhance weakly-supervised aerial object detection in remote sensing images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards detection of anomalous cosmic ray signals for observations acquired from cosmic ray extremely distributed observatory mobile detectors. <em>EAAI</em>, <em>161</em>, 112109. (<a href='https://doi.org/10.1016/j.engappai.2025.112109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose and test a method that allows the detection of anomalous cosmic ray signals acquired using Complementary Metal-Oxide-Semiconductor detectors. The method uses unsupervised embedding based on Principal Component Analysis which we named Eigenhits in apparent analogy to Eigenfaces. The embedding generated using Eigenhits allows the detection of potential anomalies, defined as images whose position described by the embedding relative to a given measure is above a certain distance threshold from other images. Thus, the problem of anomaly detection was reduced to the problem of detecting outliers which can be solved, for example, using clustering algorithms. We conducted tests of our approach on the Cosmic Ray Extremely Distributed Observatory (CREDO) dataset containing 13168 images and obtained satisfactory results demonstrating the stability and effectiveness of the method. The embedding generation method we propose in this paper and the evaluation of its effectiveness in detecting anomalies in images of cosmic ray events from CREDO dataset is a pioneering study with many critical applications.},
  archive      = {J_EAAI},
  author       = {Tomasz Hachaj and Łukasz Bibrzycki and Marcin Piekarczyk and Olaf Bar and Michał Niedźwiecki and Sławomir Stuglik and Piotr Homola and Dmitriy Beznosko and David Alvarez-Castillo and Bożena Poncyljusz and Ophir Ruimi and Oleksandr Sushchov and Krzysztof Rzecki and CREDO collaboration},
  doi          = {10.1016/j.engappai.2025.112109},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112109},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards detection of anomalous cosmic ray signals for observations acquired from cosmic ray extremely distributed observatory mobile detectors},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An uncertainty-aware safe-evolving reinforcement learning algorithm for decision-making and control in highway autonomous driving. <em>EAAI</em>, <em>161</em>, 112108. (<a href='https://doi.org/10.1016/j.engappai.2025.112108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rule-based and optimization-based approaches face challenges in decision-making and control for autonomous vehicles (AVs) in dynamic and complex highway scenarios. In contrast, reinforcement learning (RL) offers a more flexible and adaptable data-driven solution by allowing AVs to learn optimal actions through interactions with the environment, without requiring predefined rules or explicit programming. However, in real-world highway environments characterized by uncertainty, RL algorithm encounter difficulties in ensuring stability and safety. To address these challenges, this paper proposes an uncertainty-aware safe-evolving RL algorithm that integrates internal stability, external stability, and provable safety mechanisms. The internal stability mechanism ensures consistent performance improvements with high probability during policy updates itself, while the external stability leverages a benchmark policy as a reference to ensure the current policy performs at least as well as, if not better than, the benchmark. Furthermore, an action projection mechanism and a mixed learning procedure are incorporated to make minimal modifications to the learned policy, ensuring safety while supporting stable learning from both safe and original actions. The results show that the proposed algorithm maintains stability and safety throughout the learning process, achieves final performance comparable to traditional RL methods, and delivers higher training efficiency in a complex dynamic highway scenario in simulation. This suggests that the algorithm offers a viable solution for self-evolving systems in uncertain real-world environments, where traditional approaches may struggle.},
  archive      = {J_EAAI},
  author       = {Ping Lu and Sunan Zhang and Feihong Tan and Fulin Zhang and Yuxiang Feng and Bo Hu},
  doi          = {10.1016/j.engappai.2025.112108},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112108},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An uncertainty-aware safe-evolving reinforcement learning algorithm for decision-making and control in highway autonomous driving},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning-driven network for joint low-light enhancement and deblurring in maritime surveillance systems. <em>EAAI</em>, <em>161</em>, 112107. (<a href='https://doi.org/10.1016/j.engappai.2025.112107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {—Shipboard video surveillance systems are crucial for maritime environmental perception. However, shipborne cameras are often affected by challenges such as ship rolling and low illumination, causing motion blur and low-light degradation in captured images. These degradations significantly reduce the accuracy and robustness of sea-surface obstacle detection. To address this challenge, this paper presents a deep learning-based joint network model designed to simultaneously deblur and enhance low-light maritime images. Unlike existing step-by-step approaches that treat deblurring and low-light enhancement as separate tasks, the proposed model employs an encoder-decoder architecture to jointly address both tasks within a unified framework, thereby overcoming the limitations of separate processing. Furthermore, the model incorporates a novel adaptive wavelet curve attention mechanism and an extended spatial pyramid pooling module with dynamic global context to mitigate detail loss caused by sea surface reflections and artifacts in dynamic backgrounds. Additionally, a joint loss function is exploited to further enhance image restoration quality. Experiments on a self-constructed synthetic maritime dataset demonstrate that the proposed model achieves a Peak Signal-to-Noise Ratio (PSNR) of 31.81, a Structural Similarity Index Measure (SSIM) of 0.812, and a Learned Perceptual Image Patch Similarity (LPIPS) of 0.246, significantly outperforming existing competing methods. Moreover, evaluations on real-world degraded maritime images confirm the model's strong generalization ability and robustness. This advancement offers practical benefits for improving obstacle perception in autonomous ships navigating complex maritime environments.},
  archive      = {J_EAAI},
  author       = {Zeyuan Shao and Yong Yin and Hongguang Lyu and Qianfeng Jing and Tao Cheng},
  doi          = {10.1016/j.engappai.2025.112107},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112107},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep learning-driven network for joint low-light enhancement and deblurring in maritime surveillance systems},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A double hierarchy hesitant fuzzy forecasting model considering the influence of investor emotion and the co-movement of stock markets. <em>EAAI</em>, <em>161</em>, 112106. (<a href='https://doi.org/10.1016/j.engappai.2025.112106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stock market is a complex system influenced by various internal and external factors. Effective stock index forecasting models must balance interpretability with the ability to integrate multi-source information. While traditional fuzzy models offer high interpretability, they struggle to incorporate multiple dynamic factors. This study proposes a novel forecasting model based on double hierarchy hesitant fuzzy linguistic term sets (DHHFLTS), which integrates investor sentiment and international market co-movement. By constructing fuzzy logic rules, the model captures complex interactions underlying index fluctuations and enhances predictive accuracy in volatile environments. To evaluate its effectiveness, the model was tested on time series data from three major indices: the Shanghai Stock Exchange Composite Index (SSEC), Taiwan Capitalization Weighted Stock Index (TAIEX), and Financial Times Stock Exchange 100 Index (FTSE 100). The Root Mean Square Error (RMSE) achieved was 32.06 for the SSEC, 69.74 for the TAIEX, and 25.27 for the FTSE 100. Compared with existing benchmark methods, the proposed model demonstrates superior predictive accuracy and generalization performance. These findings confirm the model's capability in capturing multidimensional uncertainty and temporal patterns, highlighting its potential for intelligent financial forecasting and decision-making.},
  archive      = {J_EAAI},
  author       = {Liu Zhengmin and Du Chuantao and Zhang Jihao and Gao Shanshan and Liu Peide},
  doi          = {10.1016/j.engappai.2025.112106},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112106},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A double hierarchy hesitant fuzzy forecasting model considering the influence of investor emotion and the co-movement of stock markets},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Style prompt tuning for bridging visual gaps in autonomous driving. <em>EAAI</em>, <em>161</em>, 112105. (<a href='https://doi.org/10.1016/j.engappai.2025.112105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence models for semantic segmentation and image classification in autonomous driving must maintain reliability across adverse conditions such as rain, fog, snow, and nighttime. However, models trained on only clear daytime images often fail to generalize under such domain shifts. Existing unsupervised domain adaptation (UDA) methods employ image-level style transfer using generative adversarial networks (GANs) or diffusion models, which necessitate paired data and risk altering content. Therefore, this study proposes Style Prompt Tuning, a novel UDA framework that utilizes image–text models to automatically generate and optimize textual prompts representing target-domain styles. These prompts guide a U-Net-based style network to synthesize source images in the target style while preserving their semantic content. Our approach employs clustering within the Contrastive Language—Image Pretraining (CLIP) embedding space and a composite loss function, including content, style, transfer, patch, and total variation terms to optimize prompt quality. The generated stylized images augment the source dataset and are used to train more robust task models. Experiments on semantic segmentation benchmarks (Cityscapes-to-Adverse Conditions Dataset with Correspondences (ACDC), DarkZurich, BDD100k-night, and Nighttime Driving) and image classification (Visual Domain Adaptation 2017) reveal our approach to achieve improvements of +3.4 mean intersection-over-union (mIoU) and +0.8% accuracy over prior UDA methods. These results highlight our method’s practical effectiveness for real-world autonomous driving applications under visually challenging scenarios.},
  archive      = {J_EAAI},
  author       = {Suyeon Cha and Giyun Choi and Minji Kwak and Jongwon Choi},
  doi          = {10.1016/j.engappai.2025.112105},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112105},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Style prompt tuning for bridging visual gaps in autonomous driving},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing fuzzy cognitive map convergence through supervised and unsupervised learning algorithms: A case study of operational risk assessment in power distribution networks. <em>EAAI</em>, <em>161</em>, 112104. (<a href='https://doi.org/10.1016/j.engappai.2025.112104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Cognitive Maps (FCMs) are commonly used for modeling complex systems. However, their convergence challenges significantly limit their accuracy and reliability, especially in operational risk assessment. To address this issue, the current study proposes a novel approach that integrates advanced supervised and unsupervised learning algorithms: specifically, the Mesh Adaptive Direct Search (MADS) and Genetic Algorithm (GA). To meet the critical need for accurate risk modeling in power distribution networks, the proposed methodology utilizes ten years of time-series data from the Yazd Power Distribution Network as a real-life case study. This optimizes risk relationships and reduces convergence errors. The main contributions of this research are: (1) the development of an integrated FCM-based framework that improves convergence stability and accuracy through advanced learning algorithms, (2) the demonstration of the effectiveness of MADS in achieving faster convergence and lower error rates compared to GA, and (3) the provision of a data-driven, scalable solution for risk prioritization and decision-making in complex and dynamic systems. The results show a significant decrease in convergence error from 0.126 to 0.005, allowing for more precise risk analysis and mitigation strategies.},
  archive      = {J_EAAI},
  author       = {Elham Fallah Baghemoortini and Davood Shishebori and Mustafa Jahangoshai Rezaee and Armin Jabbarzadeh},
  doi          = {10.1016/j.engappai.2025.112104},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112104},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing fuzzy cognitive map convergence through supervised and unsupervised learning algorithms: A case study of operational risk assessment in power distribution networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised generative adversarial network for plant leaf disease detection. <em>EAAI</em>, <em>161</em>, 112103. (<a href='https://doi.org/10.1016/j.engappai.2025.112103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully supervised plant leaf disease segmentation methods based on convolutional neural networks (CNN) require large quantities of labeled images for training, which are time-consuming and labor-intensive to obtain in practical scenarios. Moreover, most diseases of plant leaf exhibit indistinct edge information and background noise interference, which hinders precise disease localization. To overcome these issues, a semi-supervised generative adversarial network (SSGAN) is proposed for plant leaf disease inspection. Firstly, to learn comprehensive semantic features from limited data, a semi-supervised method based on generative adversarial networks is developed to enhance the interaction of features among labeled and unlabeled disease images. Secondly, a boundary feature attention module (BFAM) is proposed to enhance edge detail representation, which makes the model pay more attention to the boundary feature of plant leaf diseases. Finally, a background noise suppression module (BNSM) is proposed to bolster the differentiation between the normal and disease areas so as to alleviate the adverse impact of background noise. The effectiveness of SSGAN is verified on two plant leaf disease datasets. The mean intersection over union (mIoU) on the apple and tomato leaf datasets improves by 2.07 % and 2.28 % respectively, compared with the suboptimal method. The testing results of experiments show that SSGAN achieves great performance on plant leaf disease segmentation under limited labeled data.},
  archive      = {J_EAAI},
  author       = {Lixiang Zhao and Jun Hao and Demin Li and Jianbo Yu},
  doi          = {10.1016/j.engappai.2025.112103},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112103},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised generative adversarial network for plant leaf disease detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Industrial device-aided data collection for real-time rail defect detection via a lightweight network. <em>EAAI</em>, <em>161</em>, 112102. (<a href='https://doi.org/10.1016/j.engappai.2025.112102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rail defect detection is challenging due to the diverse and irregular nature of defects, along with the limited availability of high-quality datasets. Existing methods struggle with effectively capturing multi-scale features for proper feature allocation and preserving crucial details in deep networks, leading to incomplete defect representation and reduced accuracy. To address these limitations, we propose Rail Defect Detection Network (REDNet), a lightweight deep learning model specifically designed for real-time rail defect detection in manufacturing and maintenance applications. We design the Multi-Scale Deep Feature Aggregation (MSDFA) module to enhance semantic consistency modeling and achieve more precise feature fusion. We develop the Adaptive Task Decomposition Head (ATDH) to address dynamic feature allocation, and we introduce the Reversible Column Network (RevCol) as the backbone to enhance feature extraction and ensure information reconstruction. Additionally, we developed a high-quality dataset using specialized equipment to address data scarcity and utilized it for training. REDNet achieved a high mean Average Precision at an Intersection over Union (IoU) threshold of 0.50 (mAP50) of 94.1% with exceptional real-time performance at 204.1 frames per second (FPS), while keeping an efficient design of 5.70 million parameters and surpassing state-of-the-art (SOTA) methods in accuracy and speed. These features make it suitable for defect detection, facilitating engineering deployment, and improve quality control in rail manufacturing and maintenance. Generalization tests on the public Microsoft Common Objects in Context (MS COCO) dataset yielded a mean Average Precision across IoU thresholds from 0.50 to 0.95 (mAP50–95) of 46.8%, further confirming the effectiveness of REDNet.},
  archive      = {J_EAAI},
  author       = {Qing Dong and Tianxin Han and Gang Wu and Lina Sun and Min Huang and Fu Zhang},
  doi          = {10.1016/j.engappai.2025.112102},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112102},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Industrial device-aided data collection for real-time rail defect detection via a lightweight network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A quantitative multi-dimensional resilience framework in process industries. <em>EAAI</em>, <em>161</em>, 112100. (<a href='https://doi.org/10.1016/j.engappai.2025.112100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process industries face significant safety challenges arising from the handling of hazardous materials, tightly coupled operations, and complex system interdependencies. Addressing these challenges requires management strategies that are both proactive and holistic rather than purely reactive. Resilience engineering embodies this approach by emphasizing a system's ability to anticipate disturbances, adapt under stress, and recover effectively. This study introduces a comprehensive, multi-dimensional framework for assessing resilience in process industries. The framework was developed through content analysis of expert interviews, a systematic literature review, and application of the spherical fuzzy Delphi method. Results revealed five primary dimensions of resilience: the organizational dimension, which encompasses leadership commitment, safety culture, and communication processes; the human resources dimension, focusing on workforce competence, training, and well-being; the individual dimension, addressing cognitive readiness, situational awareness, and decision-making skills; the risk management system dimension, which includes hazard identification, risk assessment, emergency preparedness, and continuous monitoring; and the technical dimension, covering equipment reliability, system redundancy, automation safeguards, and maintenance practices. Within these dimensions, factors such as leadership, effective communication, workforce capability, robust risk governance, and technical robustness emerged as particularly influential. By integrating these dimensions into a unified framework, our study advances theoretical understanding of resilience engineering and offers practical guidance for enhancing safety performance in process plants. Furthermore, this framework lays a foundation for future research aimed at developing standardized assessment tools, evaluating long-term outcomes of resilience interventions, and exploring the integration of emerging technologies—such as artificial intelligence, the internet of things, and advanced automation—into resilience engineering practices.},
  archive      = {J_EAAI},
  author       = {Mojtaba Emkani and Moslem Alimohammadlou and Esmaeil Zarei and Mehdi Jahangiri and Mojtaba Kamalinia},
  doi          = {10.1016/j.engappai.2025.112100},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112100},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A quantitative multi-dimensional resilience framework in process industries},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mutual transfer learning for cuff-less blood pressure estimation using photoplethysmography-based visibility graphs. <em>EAAI</em>, <em>161</em>, 112099. (<a href='https://doi.org/10.1016/j.engappai.2025.112099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cuff-less blood pressure (BP) estimation is critical to cardiovascular disease prevention and management. Photoplethysmography (PPG)-based monitoring technology offers advantages over cuff-based devices, including portability, lower power consumption, and faster measurements. However, current deep learning methods for BP estimation from PPG signals are limited by their analysis only from one-dimensional perspectives, failing to exploration of the underlying physiological patterns of cross-domain visual representations based on higher dimensional perspectives. Furthermore, conventional knowledge distillation techniques necessitate unidirectional knowledge transfer from pre-trained models, rendering it challenging to obtain feedback on the learning state of small networks for optimizing and adjusting the training process. This is inadequate for acquiring a profound understanding of the intricate mapping relationship between PPG and BP values. Therefore, this work presents a novel Transformer-based mutual transfer learning framework (MTL) that estimates BP values from phase-space reconstructed PPG signals using a multi-field complementary approach. The proposed MTL method leverages four phase-space reconstruction techniques to convert PPG signals into visibility graphs (VGs) that provide rich time-variant information. Furthermore, the joint optimization strategy with multiple losses of the soft label and structural knowledge learning enables us to transfer pre-trained knowledge from heterogeneous Transformer models and obtain cumulative multi-field complementary VG features during the fine-tuning process. We evaluate our MTL on three datasets of 1375 subjects using a subject-wise data-splitting paradigm based on five-fold cross-validation, achieving a state-of-the-art performance with estimation errors of 0.50 ± 4.94 millimeter of mercury (mmHg) and 0.21 ± 2.63 mmHg for systolic and diastolic BP, respectively. Our proposed end-to-end MTL offers a computationally efficient solution and elegant generalization ability for BP estimation using PPG-based VGs, providing a novel and innovative approach to BP monitoring that can advance cardiovascular disease prevention and management.},
  archive      = {J_EAAI},
  author       = {Chenbin Ma and Zhenchang Liu and Peng Zhang and Lishuang Guo and Haonan Zhang and Zeyu Liu and Guanglei Zhang},
  doi          = {10.1016/j.engappai.2025.112099},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112099},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mutual transfer learning for cuff-less blood pressure estimation using photoplethysmography-based visibility graphs},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Groundwater parameters estimation: A hybrid approach of convolutional layers with asynchronous and distributed bio-inspired algorithms. <em>EAAI</em>, <em>161</em>, 112098. (<a href='https://doi.org/10.1016/j.engappai.2025.112098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on aquifer hydraulic parameters estimation using bio-inspired algorithms since they can tackle groundwater model non-linearities. We propose two novel hybrid frameworks that combine the advantages of convolutional layers (CL) to enhance pattern recognition with heuristic search of Particle Swarm Optimization (PSO) and Differential Evolution (DE) algorithms. These integrations are implemented using an asynchronous and distributed approach to address efficiency issues in large-scale problems, resulting in ADPSO-CL (Asynchronous and Distributed Particle Swarm Optimization with Convolutional Layers) and ADDE-CL (Asynchronous and Distributed Differential Evolution with Convolutional Layers). The distributed method employs virtual machines, where a server generates and assigns particles to workers, which run in parallel with asynchronous iterative solution exchanges. We assess different algorithm configurations in an integrated water management model by coupling two software: Water Evaluation and Planning (WEAP) and MODFLOW. Results indicate that ADPSO-CL outperforms ADDE-CL by demonstrating more stable asynchronous communication, with fewer incomplete experiments (more than one worker was disconnected before completing all iterations), 33% in contrast to 71%. Additionally, produces results closer to the expected values, with mean absolute percentage error (MAPE) values of 78.25% for hydraulic conductivity ( K ) and 55.56% for specific yield ( S y ), compared to 299% and 209% in ADDE-CL. Moreover, ADPSO-CL has the fastest convergence rate, achieving efficient results in about half of the total iterations. This study introduces a novel and scalable architecture for intricate simulation–optimization problems, demonstrating its potential for future applications in real-world water resources planning and management.},
  archive      = {J_EAAI},
  author       = {Kiara Tesen and Hermilo Cortés and Sebastián Vicuña and Edmundo Molina-Perez and Francisco Suárez},
  doi          = {10.1016/j.engappai.2025.112098},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112098},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Groundwater parameters estimation: A hybrid approach of convolutional layers with asynchronous and distributed bio-inspired algorithms},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting power generation: A novel two-dimensional logistic fractional grey model. <em>EAAI</em>, <em>161</em>, 112097. (<a href='https://doi.org/10.1016/j.engappai.2025.112097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of power generation is essential for the stable operation of power systems, sustained economic growth, and harmonious social development. However, power systems exhibit chaotic characteristics such as complex and nonlinear dynamics during operation; for this reason, this study exploits the fact that two-dimensional logistic mapping helps with the recognition and control of the complex high-dimensional dynamics of the system. Additionally, the fractional-order chaotic system offers a more universal means to describe the chaotic phenomena, etc., and introduces the modelling mechanism of the two-dimensional logistic model and the fractional-order derivative theory into the grey model. A novel two-dimensional logistic fractional-order grey model is developed. The new model can simultaneously analyze two parallel major factors that evolve and are interrelated, and the fractional-order derivatives and nonlinear terms accurately portray the historical state and dynamic evolution process of the system, which can explore the evolution law in the time series of power generation more adequately. Furthermore, the particle swarm optimization algorithm is used to optimize the fractional order derivatives and parameters so that the adjustable model parameters can better capture the change pattern of the original power generation system data. The new model is applied to China's power generation prediction, and its validity is verified from three different perspectives through two different power generation modes as the research objects. Moreover, the new model outperforms the other seven models in its calculations. Finally, the new model effectively forecasts China's power generation for the next five years.},
  archive      = {J_EAAI},
  author       = {Mingyue Weng and Huiming Duan and Derong Xie},
  doi          = {10.1016/j.engappai.2025.112097},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112097},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting power generation: A novel two-dimensional logistic fractional grey model},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep reinforcement learning optimization algorithm based on heterogeneous graph neural network for hybrid flow shop scheduling problem with finite transportation resources. <em>EAAI</em>, <em>161</em>, 112096. (<a href='https://doi.org/10.1016/j.engappai.2025.112096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many actual process industries, transportation equipment represented by automated guided vehicles (AGVs) is widely used. However, current related research rarely considers the coordinated scheduling optimization of AGVs and production equipment. To this end, the hybrid flow shop scheduling problem (HFSP) with finite transportation resources (HFSP-FTR) in process industries is considered in this paper. Since it is necessary to consider the coordinated scheduling optimization of machines and AGVs at the same time, an end-to-end deep reinforcement learning scheduling method based on a heterogeneous graph neural network is proposed. First, a heterogeneous graph model capable of expressing any HFSP-FTR instance is constructed to visually represent the allocation relationship among jobs, machines, and AGVs. Second, a Markov decision process is formulated for solving HFSP-FTR, which specifically encompasses state features based on the heterogeneous graph model and a novel representation method for composite scheduling actions. Then, a novel heterogeneous graph neural network framework that can parallelly embed nodes of various types is proposed, aiming to derive graph-level embeddings for HFSP-FTR instances. Finally, a policy network is designed to obtain the probability distribution of each composite scheduling action being executed, and a deep reinforcement learning framework based on the multi-actor network is proposed for training. The results of numerical simulation experiments conducted on test instances with varying types demonstrate that the proposed method can acquire effective and highly generalized scheduling strategies in terms of makespan performance, outperforming other scheduling algorithms that are widely applied regarding the quality of scheduling solutions and other aspects.},
  archive      = {J_EAAI},
  author       = {Yejian Zhao and Xiaochuan Luo and Weixiang Xu and Yulin Zhang},
  doi          = {10.1016/j.engappai.2025.112096},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112096},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep reinforcement learning optimization algorithm based on heterogeneous graph neural network for hybrid flow shop scheduling problem with finite transportation resources},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unknown fault incremental learning based on shapelet prototypical network for streaming industrial signals. <em>EAAI</em>, <em>161</em>, 112094. (<a href='https://doi.org/10.1016/j.engappai.2025.112094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unknown faults represent faults that have never occurred before, they are constantly emerging due to the changing environments and operations in industrial processes. It is a challenge for existing fault diagnosis methods to continually detect unknown faults and effectively classify known faults in streaming industrial signals. This article proposes an unknown fault incremental learning method for streaming industrial signals. In this work, shapelet prototypical embedding combined with a memory distance matrix is employed to embed streaming industrial signals into a discriminative feature space. Therefore, the category information in the signals can be extracted and is not limited by the size of the sliding window. Besides, a new training paradigm based on meta-learning by sampling simulated-incremental tasks is proposed to obtain generalizable shapelets. Moreover, based on the new training paradigm, the meta-discovery module is proposed to continually detect unknown faults, and the meta-calibrate module can calibrate all prototypes into a distinguishable space. Experiments on the simulated streaming time series, benchmark Tennessee Eastman process, and real-world aluminum electrolysis process illustrate the superiority of the proposed method in terms of accuracy and interpretability. The code is available in https://github.com/XiaoxueWan/UFIL.git .},
  archive      = {J_EAAI},
  author       = {Xiaoxue Wan and Lihui Cen and Xiaofang Chen and Yongfang Xie and Zhaohui Zeng},
  doi          = {10.1016/j.engappai.2025.112094},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112094},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unknown fault incremental learning based on shapelet prototypical network for streaming industrial signals},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive attention graph convolution network with normalized embedded gaussian for rapid serial visualization presentation decoding. <em>EAAI</em>, <em>161</em>, 112093. (<a href='https://doi.org/10.1016/j.engappai.2025.112093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have been widely used in Brain Computer Interface (BCI) and have shown great prowess in identifying electroencephalogram (EEG) spatiotemporal features. However, most GCNs learn channels topological relationship by fixed adjacency matrix. This lacks connectivity strength information and ignores the data dependency. This paper proposes a data-driven adjacency matrix based on normalized embedded Gaussian function, and constructs a Gaussian-Adaptive Attention Graph Convolution Network (Gaussian-AAGCN). Brain regions connectivity is calculated by normalized embedded Gaussian function, and the topological relationship is adaptively learned by input data in a data-driven manner. This data-driven adaptive adjacency matrix avoids brain activity information loss caused by fixed adjacency matrix and improves the flexibility of graph construction. Convolutional block attention module (CBAM) is introduced to adaptive feature refinement in two independent dimensions, improving model representation ability. Experimental results show that the average area under curve (AUC), true positive rate (TPR) and false positive rate (FPR) of Gaussian-AAGCN on 14 subjects are 93.52 %, 91.59 %, and 4.58 % respectively. Compared to Transformer, Event-Related Potential Capsule Network (ERP-CapsNet), Electroencephalogram Convolutional Neural Network (EEGNet), and Multi-Granularity Information Fusion Network (MGIFNet), the AUC of Gaussian-AAGCN is higher by 18.02 %, 5.32 %, 2.62 %, and 1.82 %, respectively. Using the adaptive adjacency matrix, the model AUC and TPR are increased by about 4.8 % and 7.8 % respectively. After integrating CBAM, the AUC and TPR increased by about 3.5 % and 8 % respectively.},
  archive      = {J_EAAI},
  author       = {Mengyuan Zhao and Qingsong Ai and Kun Chen and Quan Liu and Sheng Quan Xie and Li Ma},
  doi          = {10.1016/j.engappai.2025.112093},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112093},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive attention graph convolution network with normalized embedded gaussian for rapid serial visualization presentation decoding},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GREEN: Graph reasoning enhanced encoder network for social intention-aware forecast of vessel navigating trajectory. <em>EAAI</em>, <em>161</em>, 112092. (<a href='https://doi.org/10.1016/j.engappai.2025.112092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have demonstrated that graph neural network (GNN) excel in interactive modeling, particularly by enhancing reasoning capabilities through the construction of interaction graphs, and the application of graph convolutional network (GCN). However, these methods remain heavily dependent on prior features, which limits the ability of vessels to accurately infer each other’s decision-making intentions in encounter situations. Therefore, this paper proposes graph reasoning enhanced encoder network (GREEN), which enables social community insight on multi-ships interactions, and latent intention aware for interactive trajectory forecast. The architecture of GREEN includes two layers of trajectory-graph-embedded encoders layer (TGEEL) and multi-graphs-gated fusion layer (MGGFL). In TGEEL, we respectively design intention trajectory generator unit for graph-embedded multi-ships trajectory representation via random walk process, and latent intention generator unit to forecast future navigating intentions via variational autoencoder. In MGGFL, we also design two units, where one unit is in charge of social aware construction and spatio-temporal features extraction based on interactive multi-graphs, and the other one is responsible for gated fusion of multi-scale features and forecast future trajectory using spatio-temporal attention. Experimental results across five datasets were collected from real-world maritime environments, which demonstrated that GREEN achieved improvements of 39.98%, 38.57%, 38.65%, and 63.33% in average displacement error , final displacement error, maximum displacement error, and miss rate, compared with state-of-the-art methods. The paper highlights GREEN robust potential in complex navigational scenarios, and provides pivotal support for advancing the development of intelligent maritime systems.},
  archive      = {J_EAAI},
  author       = {Junhao Jiang and Yi Zuo},
  doi          = {10.1016/j.engappai.2025.112092},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112092},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GREEN: Graph reasoning enhanced encoder network for social intention-aware forecast of vessel navigating trajectory},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffAT: Effective data augmentation with diffusion models for time series forecasting. <em>EAAI</em>, <em>161</em>, 112091. (<a href='https://doi.org/10.1016/j.engappai.2025.112091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation offers a promising solution to data scarcity in deep learning-based time series forecasting. However, current approaches face dual limitations (1) Hand-designed methods (e.g., cropping/masking): often disrupt the continuity of vital temporal patterns (such as seasonal and trend) by introducing abrupt pattern discontinuities; (2) Generative models often face difficulties in preserving task-critical features that are essential for prediction, especially when aiming to generate diverse augmented series. To tackle these dilemmas, we propose a novel conditional diffusion-based data augmentation framework, named DiffAT, for time series forecasting tasks. DiffAT synergizes: (1) Patch-wise masking reconstruction to capture structural invariants (such as autocorrelation and causality), and (2) encoding hand-designed augmentation prototypes for guiding diversity-preserving generation. DiffAT achieves dual enhancement: maintaining continuity of temporal patterns through progressive denoising process and exposing latent invariant patterns via guided diversity injection. We validate the efficacy of DiffAT through extensive experiments on seven real-world datasets, by comparing DiffAT with six state-of-the-art time series data augmentation methods. The results indicate our method can boost the forecasting performance of Autoformer by up to 6.49 % in 26/28 cases and improve forecasting performance of LightTS by up to 3.11 % in 23/28 cases on 7 real-world benchmarks. Extensive experiments also indicate that DiffAT can improve the accuracy of forecasting models in few-shot scenario (with 1 % training data) in 54/60 cases. We will release the source code upon publication.},
  archive      = {J_EAAI},
  author       = {Yang Yu and Ruizhe Ma and Wenbo Gu and Zongmin Ma},
  doi          = {10.1016/j.engappai.2025.112091},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112091},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DiffAT: Effective data augmentation with diffusion models for time series forecasting},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating reinforcement learning-based neural controllers for quadcopter navigation in windy conditions. <em>EAAI</em>, <em>161</em>, 112090. (<a href='https://doi.org/10.1016/j.engappai.2025.112090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate quadcopter navigation under windy conditions remains challenging for traditional control methods, especially in the presence of unpredictable wind gusts and strict navigational constraints. This paper evaluates Deep Reinforcement Learning (DRL) based controllers under such conditions, analysing the impact of wind domain randomisation, multi-goal training, enhanced state representations with explicit wind information, and the use of temporal data to capture affecting dynamics over time. Experiments in the AirSim simulator across four trajectories — evaluated under both no-wind and windy conditions — demonstrate that DRL-based controllers outperform classical methods, particularly under stochastic wind disturbances. Moreover, we show that training a DRL agent with domain randomisation improves robustness against wind but reduces efficiency in no-wind scenarios. However, incorporating wind information into the agent’s state space enhances robustness without sacrificing performance in wind-free settings. Furthermore, training with stricter waypoint constraints emerges as the most effective strategy, leading to precise trajectories and improved generalisation to wind disturbances. To further interpret the learned policies, we apply Shapley Additive explanations analysis, revealing how different training configurations influence the agent’s feature importance. These findings underscore the potential of DRL-based neural controllers for resilient autonomous aerial systems, highlighting the importance of structured training strategies, informed state representations, and explainability for real-world deployment.},
  archive      = {J_EAAI},
  author       = {Alain Andres and Aritz D. Martinez and Sümer Tunçay and Ignacio Carlucho},
  doi          = {10.1016/j.engappai.2025.112090},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112090},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluating reinforcement learning-based neural controllers for quadcopter navigation in windy conditions},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pixel-level semantics boosted fine-grained bird image classification. <em>EAAI</em>, <em>161</em>, 112089. (<a href='https://doi.org/10.1016/j.engappai.2025.112089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained bird image classification (FBIC) is crucial for endangered bird conservation and biodiversity research. However, existing methods often struggle to capture detailed features and manage the interference caused by complex backgrounds. To address these challenges, we propose a novel Pixel-Level Semantic Boosted Fine-Grained Bird Image Classification (PFIC) framework, which enhances fine-grained bird image classification by incorporating pixel-level semantic information. PFIC consists of two core components: the Grouped Detail Enhancement (GDE) module and the Background–Foreground Enhancement (BFE) strategy. GDE integrates multi-level pixel-level semantic information, derived from a segmentation feature extractor, into classification features via two submodules: grouped aggregation and detail enhancement. This approach enhances the model’s ability to capture fine-grained details. BFE augments training samples by restricting background ranges and applying random shifts to foreground objects, thereby improving the model’s capability to recognize foreground objects in complex environments. Experimental results demonstrate that our method achieves state-of-the-art performance on the CUB-200-2011 and NABirds datasets. Additionally, further experiments on the Stanford Cars dataset validate the framework’s potential for generalization to other fine-grained image classification tasks.},
  archive      = {J_EAAI},
  author       = {Haoxiang Ma and Yongjian Deng and Bochen Xie and Jian Liu and Hai Liu and Youfu Li and Zhen Yang},
  doi          = {10.1016/j.engappai.2025.112089},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112089},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pixel-level semantics boosted fine-grained bird image classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based soft sensor of five day biochemical oxygen demand indicators in the municipal wastewater treatment process. <em>EAAI</em>, <em>161</em>, 112088. (<a href='https://doi.org/10.1016/j.engappai.2025.112088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Five day biochemical oxygen demand (BOD 5 ) is usually used to measure whether wastewater treatment meets the standard. Previously, the development of machine learning technology was applied to predict BOD 5 for future planning of wastewater treatment. In real wastewater treatment, the monitoring of BOD 5 often lags behind for a long time, so neural network-based soft sensor methods are widely used in this field. However, the currently used BOD 5 soft sensor model has the problem of ignoring the synergistic effect of the model and stable information transmission. In order to monitor the BOD 5 concentration more accurately, a Transformer network model with embedded Long Short-Term Memory (LSTM) network is proposed in this article : LSTM is embedded into the calculation of the transformer multi-head attention, and the output method of the multi-head attention is improved so that the attention heads are output one by one in a serial manner, so it is named LSTM-Serial-Transformer (LSformer). Compared with previous models, LSformer optimizes input information through LSTM and Transformer to achieve synergistic effect, thus better capturing the characteristics of BOD 5 time series data, while reducing the risk of gradient vanishing or gradient exploding during data transmission to improve the stability of the model. Finally, the model was verified to have better soft sensor performance on a benchmark simulation model and a real-world dataset.},
  archive      = {J_EAAI},
  author       = {Xiaoling Zhang and Zhi Qi and Peng Chang and Zhiqi Hu},
  doi          = {10.1016/j.engappai.2025.112088},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112088},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer-based soft sensor of five day biochemical oxygen demand indicators in the municipal wastewater treatment process},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ForgetMe: Benchmarking the selective forgetting capabilities of generative models. <em>EAAI</em>, <em>161</em>, 112087. (<a href='https://doi.org/10.1016/j.engappai.2025.112087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of diffusion models in image generation has increased the demand for privacy-compliant unlearning. However, due to the high-dimensional nature and complex feature representations of diffusion models, achieving selective unlearning remains challenging, as existing methods struggle to remove sensitive information while preserving the consistency of non-sensitive regions. To address this, we propose an Automatic Dataset Creation Framework based on prompt-based layered editing and training-free local feature removal, constructing the ForgetMe dataset and introducing the Entangled evaluation metric. The Entangled metric quantifies unlearning effectiveness by assessing the similarity and consistency between the target and background regions and supports both paired ( Entangled-D ) and unpaired ( Entangled-S ) image data, enabling unsupervised evaluation. The ForgetMe dataset encompasses a diverse set of real and synthetic scenarios, including CUB-200-2011 (Birds), Stanford-Dogs, ImageNet, and a synthetic cat dataset. We apply LoRA fine-tuning on Stable Diffusion to achieve selective unlearning on this dataset and validate the effectiveness of both the ForgetMe dataset and the Entangled metric, establishing them as benchmarks for selective unlearning. Our work provides a scalable and adaptable solution for advancing privacy-preserving generative AI. Code is available at: https://github.com/YuZhenyuLindy/ForgetMe .},
  archive      = {J_EAAI},
  author       = {Zhenyu Yu and Mohd Yamani Idna Idris and Pei Wang and Yuelong Xia and Yong Xiang},
  doi          = {10.1016/j.engappai.2025.112087},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112087},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ForgetMe: Benchmarking the selective forgetting capabilities of generative models},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel data generation scheme for surrogate modelling with deep operator networks. <em>EAAI</em>, <em>161</em>, 112086. (<a href='https://doi.org/10.1016/j.engappai.2025.112086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operator-based neural network architectures such as deep operator networks have emerged as a promising tool for the surrogate modelling of physical systems. In general, the training data for operator surrogate modelling are generated by solving partial differential equations using the finite element method. The computationally intensive nature of data generation is one of the major bottlenecks in deploying these surrogate models, hindering the deployment of these surrogate models in practical applications. In this study, we propose a novel methodology to alleviate the computational burden associated with training data generation for deep operator networks. Unlike the existing literature, the proposed framework for data generation does not use any partial differential equation integration strategy, such as the finite element method. In the proposed strategy, the primary field consistent with the boundary conditions is first generated randomly using Gaussian process regression. Thereafter, from the primary field, the input source field is calculated using second-order accurate finite difference techniques. The computation of the derivatives from the finite difference scheme is significantly less computationally intensive and easier to implement compared to integrating the underlying governing equations, thereby reducing the computational cost associated with generating training datasets. To validate the proposed approach, we employ heat equations as a model problem and develop the surrogate model for numerous boundary value problems.},
  archive      = {J_EAAI},
  author       = {Shivam Choubey and Shailendra Rahi and Birupaksha Pal and Manish Agrawal},
  doi          = {10.1016/j.engappai.2025.112086},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112086},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel data generation scheme for surrogate modelling with deep operator networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable generalization diagnosis: Variational causal disentanglement-based coalitional game attribution network. <em>EAAI</em>, <em>161</em>, 112084. (<a href='https://doi.org/10.1016/j.engappai.2025.112084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretability and controllability are the keys to intelligent fault diagnosis in industrial scenarios. However, most intelligent methods have focused on post-hoc feature importance explanations, which cannot constrain the uncontrollable learning behavior or form an interpretable diagnosis process consistent to match expert experience. To address this problem, this paper proposes a variational causal disentanglement-based coalitional game attribution network (VCN) to achieve a controllable and interpretable modeling paradigm that can draw diagnostic conclusions with conforming to expert experience. This model enables independent causal factor disentanglement and model regularization during the training process, as well as fast explanation computation at test time. Variational causal disentanglement is defined and do-operations and variational inference processes are introduced to generate training data with independent causal factors for subsequent attribution. The coalitional game attribution establishes a coalitional game relationship between the model and the independent causal factors, and regularizes the model so that it converges to a state that conforms to logical axioms. Both laboratory and real-world data demonstrate the proposed method enables the provision of interpretable diagnostic conclusions while maintaining controllable performance. The code is available at: https://github.com/cyber-dogy/VCN-code .},
  archive      = {J_EAAI},
  author       = {Junwei Gu and Changhua Hu and Yu Wang and Mingquan Zhang and Yanzhuo Lin and Shangjing Peng and Dongdong Li},
  doi          = {10.1016/j.engappai.2025.112084},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112084},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable generalization diagnosis: Variational causal disentanglement-based coalitional game attribution network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel photovoltaic cell defect detection method: A deep learning model based on multi-scale enhanced feature extraction. <em>EAAI</em>, <em>161</em>, 112083. (<a href='https://doi.org/10.1016/j.engappai.2025.112083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasingly widespread application of clean energy technology, the global demand for photovoltaic cells is gradually increasing, and the status and defects of photovoltaic cells are also being taken seriously. However, there are various types of defects in photovoltaic cells, including those that are difficult to detect, making detection work somewhat challenging. This article proposes a novel improved model for defect detection in photovoltaic cells based on You Only Look Once (YOLO). Firstly, the Multi-Head Self-Attention (MHSA) mechanism is adopted to compensate for the shortcomings of the Cross Stage Partial Bottleneck with 2 Convolutions (C2f) module in channel feature extraction. Secondly, the Receptive-Field Coordinate Attention Convolutional (RFCAConv) operation module is utilized to expand the receptive field of defect detection in the model and increase the range of feature extraction. Finally, the Bi-directional Feature Pyramid Network (BiFPN) and Concat modules are integrated to enhance the feature relationships between the output connections of each module and strengthen the output results. The final experimental results demonstrate that the improved model achieves an accuracy of 90.3%, representing a 5.2% increase compared to the original model. Through experimental verification, the improved model proposed in this paper can not only detect defects in photovoltaic cells in electroluminescence (EL) images but also in infrared thermal images. The model has strong generalization ability.},
  archive      = {J_EAAI},
  author       = {Yu Gao and Zhanying Li and Yinghao Zhang and Kangye Zhang and Haoyang Yu},
  doi          = {10.1016/j.engappai.2025.112083},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112083},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel photovoltaic cell defect detection method: A deep learning model based on multi-scale enhanced feature extraction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wind power prediction based on hybrid deep learning and monte carlo simulation. <em>EAAI</em>, <em>161</em>, 112082. (<a href='https://doi.org/10.1016/j.engappai.2025.112082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a hybrid deep learning model combining Variational Mode Decomposition (VMD), Convolutional Neural Networks (CNN), and a Three-Dimensional Gated Neural Network (TGNN) to enhance wind power prediction accuracy. VMD decomposes wind power time series into intrinsic mode functions, CNN extracts deep features, and TGNN captures temporal dependencies with error feedback control. A Monte Carlo simulation based on the Central Limit Theorem is introduced to evaluate predictive uncertainty and interval coverage. Experimental results from three wind farms in China demonstrate that the proposed model significantly outperforms baseline hybrid models. Specifically, it achieves a coverage probability (CP) of 0.887, an average interval width (AIW) of 200.870, and a normalized mean square error (NMSE) of 0.057. Compared with the VMD-CNN-LSTM model, the proposed VMD-CNN-TGNN reduces root mean error (RMSE) by approximately 50%, indicating its superior accuracy, robustness, and practical value in wind power forecasting.},
  archive      = {J_EAAI},
  author       = {Zhiyong Guo and Qiaoli Han and Fangzheng Wei and Wenkai Qi},
  doi          = {10.1016/j.engappai.2025.112082},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112082},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Wind power prediction based on hybrid deep learning and monte carlo simulation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A parallel memetic algorithm for qubit mapping on noisy intermediate-scale quantum machines. <em>EAAI</em>, <em>161</em>, 112081. (<a href='https://doi.org/10.1016/j.engappai.2025.112081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computer technologies are advancing rapidly, but current devices are still limited to the realm of Noisy Intermediate Scale Quantum (NISQ) systems. Due to the limited set of gates and scarce physical qubit connectivity, most quantum circuit-based programs need to be transpiled to be executed on such hardware. This transpilation, which consists in converting the quantum circuit into a hardware-compliant one includes the critical qubit mapping step, where logical qubits are mapped onto physical qubits to meet the hardware connectivity constraints. In this paper, we investigate the application of Artificial Intelligence (AI) to the qubit mapping problem. More exactly, we propose a Parallel Memetic Algorithm for Qubit Mapping (PMA-QM), designed to tackle this challenge efficiently. Using a fine-tuned parallel model to accelerate this inherently computationally expensive hybrid approach, our algorithm takes problem-specific knowledge into account to optimize circuit depth, reducing execution time, and minimizing error rates consequently. PMA-QM has been experimented using various medium-to-large scale circuit benchmarks. PMA-QM outperforms the widely used SWAP-based BidiREctional (SABRE) algorithm, delivering consistently better solutions.},
  archive      = {J_EAAI},
  author       = {Jérôme Rouzé and Nouredine Melab and Jan Gmys and Daniel Tuyttens},
  doi          = {10.1016/j.engappai.2025.112081},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112081},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A parallel memetic algorithm for qubit mapping on noisy intermediate-scale quantum machines},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing non-orthogonal multiple access systems: A reconfigurable machine learning classification approach. <em>EAAI</em>, <em>161</em>, 112080. (<a href='https://doi.org/10.1016/j.engappai.2025.112080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-Orthogonal Multiple Access (NOMA) is being considered as a Multiple Access (MA) technique for the next-generation systems, due to factors such as a high per-user spectral resource allocation, grant-free transmission, support for millimeter Waves (mmWaves) and massive-MIMO (mMIMO). A practical limitation of the NOMA systems is imperfect Successive Interference Cancellation (SIC); and the involved decoding delay. This work develops a data-driven Machine Learning (ML) model providing the functionality of a SIC receiver. While most of the Deep Learning (DL) algorithms have high complexity and training times, the given ML approach utilizes the received symbol as the only primary predictor. The other two predictors are derived from the primary predictor, and utilized for the Power-Domain (PD)-NOMA symbol-decoding process. The model utilizes a developed low-complexity NOMA-ML-based Decoder (MLbD) dataset for the same. The extensive test simulations confirm the reconfigurable ML-based receiver to be at par with the existing Maximum Likelihood (MLH) decoder in terms of decoding accuracy. Still, the former supports its integration into the next-generation systems due to its reconfigurable nature and removes the drawbacks related to SIC in the NOMA systems.},
  archive      = {J_EAAI},
  author       = {Saurabh Srivastava and Rampravesh Kumar and Prajna Parimita Dash},
  doi          = {10.1016/j.engappai.2025.112080},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112080},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing non-orthogonal multiple access systems: A reconfigurable machine learning classification approach},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaborative energy-saving path planning of unmanned surface vehicle cluster based on multi-head attention mechanism and multi-agent deep reinforcement learning. <em>EAAI</em>, <em>161</em>, 112078. (<a href='https://doi.org/10.1016/j.engappai.2025.112078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a Multi-Agent Deep Reinforcement Learning (MADRL) algorithm to address the overlooked issue of energy consumption optimization in existing cluster path planning methods, enabling collaborative energy-efficient path planning for Unmanned Surface Vehicle (USV) clusters. Meanwhile, it provides an alternative MADRL approach to address practical engineering challenges. We not only consider the problems of avoiding danger, reaching the target point and avoiding path conflicts between USV, but also further consider the energy consumption and speed planning of USV cluster. Specifically, firstly, we establish the USV motion model and the USV cluster conflict model, and propose a new energy consumption model, which considers the relationship among speed, marine environment and propulsion load. Secondly, we propose a multi-head local state relevance capture mechanism-multi-agent proximal policy optimization (MLSRC-MAPPO) algorithm. This algorithm can use multi-head attention mechanism (MHA) to capture the potential dependencies between USV, thus enhancing the convergence performance of multi-agent. Finally, in order to reduce the training difficulty, we propose a multi-dimensional action space method for action networks. The experimental results demonstrate that the proposed multi-dimensional action space method has achieved significant success in the lightweighting of the action network: the number of network parameters was reduced by 89.10%, and the computational complexity was decreased by 88.94%, significantly enhancing training efficiency. Meanwhile, the MLSRC-MAPPO algorithm, by incorporating a multi-head attention mechanism, greatly improved the convergence performance of the multi-agent system. In test scenarios with both identical and different starting points, the method reduced energy consumption by 26.24% and 38.47% respectively, fully validating its effectiveness and superiority. Furthermore, comparative experiments with existing cluster energy-saving path planning methods show that the proposed method exhibits clear advantages in terms of energy consumption and path planning efficiency, further verifying its superiority. The corresponding code for this paper is as follows: https://github.com/xhpxiaohaipeng/Multi_USV_Trajectory_energy_plan},
  archive      = {J_EAAI},
  author       = {Haipeng Xiao and Lijun Fu and Chengya Shang and Yunfeng Lin and Longfei Yue and Yaxiang Fan},
  doi          = {10.1016/j.engappai.2025.112078},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112078},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Collaborative energy-saving path planning of unmanned surface vehicle cluster based on multi-head attention mechanism and multi-agent deep reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification of surface subsidence risk in deep foundation pits using a mamba fusion model. <em>EAAI</em>, <em>161</em>, 112077. (<a href='https://doi.org/10.1016/j.engappai.2025.112077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel artificial intelligence–driven neural network model, CNN-Mamba-LSTM-SA, for predicting surface settlement induced by deep foundation pit excavation. The model integrates Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), a Self-Attention (SA) mechanism, and the Mamba architecture to capture both spatial and long-range temporal dependencies in multi-source monitoring data. Bayesian optimization is employed for hyperparameter tuning, and Variational Mode Decomposition (VMD) is used for data denoising, resulting in improved prediction accuracy. To enhance model interpretability, Shapley Additive Explanations (SHAP) are applied to identify key deformation drivers, revealing groundwater level and building settlement as the most influential factors. Model performance is validated using monitoring data from the Nanjing Gemini excavation project, where it achieves superior results compared to conventional models. The CNN-Mamba-LSTM-SA model reduces Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and Root Mean Square Error (RMSE) by up to 69.77 %, 62.45 %, and 79.45 %, respectively. Further analysis through ablation experiments confirms the contribution of each module. Interestingly, the combined removal of CNN and SA results in greater performance degradation than the sum of their individual effects. Finally, a risk warning framework is developed to enable the dynamic transformation of predicted and observed settlement values into actionable risk levels. This integrated artificial intelligence approach offers a robust and interpretable tool for managing excavation-induced risks in urban geotechnical engineering.},
  archive      = {J_EAAI},
  author       = {Chenhe Ge and Pengfei Li and Mingju Zhang and Meng Yang},
  doi          = {10.1016/j.engappai.2025.112077},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112077},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identification of surface subsidence risk in deep foundation pits using a mamba fusion model},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk management in maintenance processes: A spherical fuzzy-based failure mode and effect analysis approach in the glass processing industry. <em>EAAI</em>, <em>161</em>, 112076. (<a href='https://doi.org/10.1016/j.engappai.2025.112076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality management systems are essential tools that aim to increase the competitiveness of businesses and ensure customer satisfaction by creating reliable quality control processes. In this study, the importance of the "risk-based thinking" approach of the International Organization for Standardization (ISO) 9001:2015 standard within the scope of quality management systems was emphasized, and a risk assessment was made for the maintenance process of a business in the glass processing sector. In order to eliminate the deficiencies of the failure mode and effect analysis (FMEA) method, the integration of spherical fuzzy sets (SFSs) and the Technique of Order Preference Similarity to the Ideal Solution (TOPSIS) method was used. Within the scope of the study, 17 different risks were determined by five experts from the maintenance, repair, and quality assurance departments. The experts evaluated these identified risks according to occurrence, severity, and detection factors. Then, these risks were ranked using the Spherical Fuzzy TOPSIS (SF-TOPSIS) method. Finally, different scenarios were created, and their results were discussed to provide a more comprehensive and sensitive risk management approach. This study focuses on maintenance processes in the glass processing industry as a case study. However, the risks related to the maintenance process defined in the study (e.g., machine failures, maintenance inefficiencies, spare parts shortages) are common in the manufacturing sector. Therefore, it can be applied to the sector where the application was carried out and to many different sectors and enterprises.This methodology also serves as a guide for businesses that want to manage process risks within the scope of ISO 9001:2015.},
  archive      = {J_EAAI},
  author       = {Buse Duygu Dağıdır and Barış Özkan},
  doi          = {10.1016/j.engappai.2025.112076},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112076},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Risk management in maintenance processes: A spherical fuzzy-based failure mode and effect analysis approach in the glass processing industry},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot augmentation based on variational auto-generative adversarial network with moving losses: Application to the variable stiffness prediction in composites. <em>EAAI</em>, <em>161</em>, 112075. (<a href='https://doi.org/10.1016/j.engappai.2025.112075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dataset of carbon fiber reinforced plastics (CFRP) materials presents characteristics of high-dimensional, low-rank, and sparse, which pose difficulties in the combination of mechanical modeling. In this paper, a Variational Auto-Generative Adversarial Network (VAGAN) with moving losses is proposed as a data augmentation method, which extends the size of the CFRP dataset covering components, processes, elasticity, and strengths factors, and increases the information conveyed in the surrogate modeling. A compression strength prediction model for CFRP laminates was constructed by combining the component, process, and mechanical tensor with a neural network optimized by the search algorithm. Combined with the data augmentation strategy, not only was the amount of data expanded, but the prediction accuracy was also significantly improved. The allowable value of compression strength is analyzed and calculated by the predicted values, which brings direct benefits in simplifying the test.},
  archive      = {J_EAAI},
  author       = {Zhicen Song and Yunwen Feng and Cheng Lu and Jiaqi Liu},
  doi          = {10.1016/j.engappai.2025.112075},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112075},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Few-shot augmentation based on variational auto-generative adversarial network with moving losses: Application to the variable stiffness prediction in composites},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multivariate time series forecasting based on temporal decomposition and graph neural network. <em>EAAI</em>, <em>161</em>, 112074. (<a href='https://doi.org/10.1016/j.engappai.2025.112074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is quite challenging to forecast the Multivariate Time Series (MTS) accurately due to the high dimensionality of MTS and the entangled correlation between variables. Recently, graph-based networks have been demonstrated to be an effective model to handle the complex correlations between MTS. However, all existing graph-based methods construct the graph model of the MTS using only the shallow correlations from the raw MTS data, ignoring the deep-rooted correlations hidden in the features. In this paper, we propose for the first time to construct a comprehensive graph model of MTS that incorporates both shallow correlations from raw data and hidden correlations from decomposed temporal properties. Then, we propose a novel graph-based MTS forecasting framework, which optimizes the graph structure jointly with the model parameters. By doing so, the graph structure can adaptively model the correlations of MTS at a deep level, while the joint optimization can make the constructed graph compatible with the forecasting tasks of MTS, contributing to a globally optimal solution. Finally, we conduct extensive experiments on seven real-world datasets, the results demonstrate the superiority of our method on MTS forecasting over the state-of-the-art baselines. The source codes of the experiments with datasets are available at https://github.com/ironweng/MF-TDGNN .},
  archive      = {J_EAAI},
  author       = {Yan Qiao and Pei Zhao and Junjie Wang and Rongyao Hu and Minyue Li and Xinyu Yuan and Meng Li and Zhenchun Wei and Cuiying Feng},
  doi          = {10.1016/j.engappai.2025.112074},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112074},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multivariate time series forecasting based on temporal decomposition and graph neural network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified framework for lung disease screening using chest X-ray images. <em>EAAI</em>, <em>161</em>, 112073. (<a href='https://doi.org/10.1016/j.engappai.2025.112073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest X-ray (CXR) imaging is a crucial diagnostic tool for identifying respiratory diseases. The existing methods face challenges such as misclassification caused by overlapping radiologic patterns and the shortage of trained radiologists. However, previous studies have utilized deep learning (DL) models to overcome these limitations, but they struggle with imbalanced datasets, and noise sensitivity. In addition, most of the studies are based on the binary classification of CXR images. Thus, the proposed framework integrates segmentation and multi-class classification for improved generalization and robustness. In this work, artificial intelligence techniques like encoder–decoder and ensemble learning are utilized for segmentation and classification of CXR images that offers reliable, and efficient solution. The output of the presented framework classifies the CXR images into four different classes, along with their corresponding class score. The proposed classification model is ensemble of three pre-trained DL architectures. The last five layers of these base models are fine tuned to match the classification process and combined through a multi-layer perceptron classifier for improved accuracy. The proposed model achieves overall accuracy of 88.98%, and area under curve value of 0.9753, outperforming several state-of-the-art models. It is a lightweight model and demonstrates significant robustness under noisy conditions compared to other models. Moreover, the proposed segmentation and ensemble models are trained and tested on different datasets to obtain greater robustness. The data augmentation is also employed to address class imbalance nature of dataset and enhance the generalization capability. Further, statistical analysis is performed to present the comprehensive comparison among the models.},
  archive      = {J_EAAI},
  author       = {Bhavana Singh and Pushpendra Kumar},
  doi          = {10.1016/j.engappai.2025.112073},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112073},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A unified framework for lung disease screening using chest X-ray images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid bayesian model updating and non-dominated sorting genetic algorithm framework for intelligent mix design of steel fiber reinforced concrete. <em>EAAI</em>, <em>161</em>, 112071. (<a href='https://doi.org/10.1016/j.engappai.2025.112071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steel fiber reinforced concrete (SFRC) improves the strength and toughness of conventional concrete, but the high cost and carbon footprint of fibers challenge the balance among performance, cost and sustainability. To address this, an intelligent mix design framework is proposed to optimize compressive and splitting tensile strengths, cost and emissions. Based on 671 experimental records, posterior models were built using Markov Chain Monte Carlo sampling and Bayesian model updating, enabling accurate strength predictions. Compared to traditional regression methods, R 2 scores improved by 15.7 % and 12.4 %, confirming its predictive advantage. Cost-wise, materials dominate, while emissions mainly arise from production, transport and mixing. A non-dominated sorting genetic algorithm identified optimal designs under given constraints. Results show that reducing water-to-cement and aggregate-to-cement ratios, and increasing sand ratio and fiber reinforcement index, enhances SFRC strength. Larger coarse aggregates reduce compressive strength but have limited effect on tensile strength. Optimization suggests potential cost and emission reductions of up to 60 %. Moreover, for compression-prone components, fiber use is inefficient due to high cost and emissions, whereas for crack-resistant or strength-balanced elements, fiber inclusion offers a more sustainable alternative to merely lowering the water-to-cement ratio. The proposed framework enables tailored SFRC mix designs, guiding the efficient use of steel fibers.},
  archive      = {J_EAAI},
  author       = {Yong Yu and Jie Su and Bo Wu},
  doi          = {10.1016/j.engappai.2025.112071},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112071},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid bayesian model updating and non-dominated sorting genetic algorithm framework for intelligent mix design of steel fiber reinforced concrete},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional human pose estimation based on multi-scale spatial–temporal transformer. <em>EAAI</em>, <em>161</em>, 112068. (<a href='https://doi.org/10.1016/j.engappai.2025.112068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, transformer-based methods have become dominant in the domain of three-dimensional (3D) human pose estimation, yet the U-net model based on convolutional neural networks (CNN) struggles to model long temporal sequences, and sequence-to-frame (Seq2frame) and sequence-to-sequence (Seq2seq) approaches often fail to preserve dependencies at the start and end of sequences. To address these challenges, this paper proposes a Multi-Scale Spatial–Temporal Transformer network (MSST). This network utilizes Sequence Padding Module (SPM) to extract edge features of the first and last frames, and employs Spatial–Temporal Transformer (STT) to model the spatial–temporal correlations of keypoints. Additionally, we design a Multi-Scale Module (MSM) that analyzes the human skeletal topology to extract multi-scale features of keypoints, local information, and global information, and fuse semantic information at different scales. Finally, we utilize regression heads to project the processed keypoint feature information into 3D space. We conduct quantitative evaluations on two benchmark datasets using four evaluation metrics and design multiple sets of comparative experiments to validate the effectiveness of the proposed modules. Experimental results demonstrate that the proposed network achieves excellent performance.},
  archive      = {J_EAAI},
  author       = {Xiaogang Song and Yongxin Cui and Jichen Chen and Xinhong Hei},
  doi          = {10.1016/j.engappai.2025.112068},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112068},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-dimensional human pose estimation based on multi-scale spatial–temporal transformer},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SharpEdge: High-quality data-driven monocular depth estimation for enhanced boundary precision. <em>EAAI</em>, <em>161</em>, 112067. (<a href='https://doi.org/10.1016/j.engappai.2025.112067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While existing monocular depth estimation methods have achieved commendable performance, they often fall short in accurately distinguishing object boundaries. This deficiency largely stems from the inherent noise in dataset acquisition, such as unclear edges and missing depth information. To address these challenges, this paper introduces a novel, high-quality, data-driven monocular depth estimation method tailored for autonomous driving. The approach significantly enhances depth predictions with clearer object boundaries and reduced noise, making it well-suited for real-time, safety-critical applications. Central to our approach is the Self-Adaptive Consistency Filtering mechanism, which dynamically selects high-quality training samples, ensuring that the model learns from the most reliable data and reducing the impact of noise. Additionally, we introduce a Dual-Prior Learning strategy that combines geometric and semantic edge priors. Unlike traditional methods that rely solely on raw depth maps, our approach enhances boundary detection by providing detailed guidance on object contours. This leads to more accurate depth estimation, especially in complex regions where other methods struggle. Empirical evaluations on popular benchmark datasets show that our approach leads to performance improvements of 1.2% on the autonomous driving dataset KITTI and 1.8% on the indoor scene dataset NYU. Compared with recent state-of-the-art methods such as DPT and NewCRFs, our approach achieves superior performance, particularly in recovering fine object boundaries and maintaining spatial consistency across diverse scenes. These results highlight the strong generalization ability of our method, demonstrating that it can enhance depth estimation quality across diverse environments — improving edge precision and spatial coherence, which are critical for autonomous vehicles navigating both complex and dynamic scenarios.},
  archive      = {J_EAAI},
  author       = {Mengke Song and Luming Li and Xu Yu and Chenglizhao Chen and Shanchen Pang},
  doi          = {10.1016/j.engappai.2025.112067},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112067},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SharpEdge: High-quality data-driven monocular depth estimation for enhanced boundary precision},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review on vision-based gaze estimation: Advance in computer vision and deep learning. <em>EAAI</em>, <em>161</em>, 112066. (<a href='https://doi.org/10.1016/j.engappai.2025.112066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eye gaze estimation is all about figuring out where a person is looking by analyzing eye movements. This is usually done using cameras or eye-tracking devices, a key technique in computer vision. Gaze estimation has a wide range of uses—from helping people interact with computers more naturally (HCI), monitoring drivers, enhancing virtual reality experiences, and reading emotional cues in affective computing. Deep learning has improved how accurately and reliably these systems work in recent years. Models like Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Generative Adversarial Networks (GANs) have made it easier to detect and interpret eye movements in complex settings. This review closely examines how gaze estimation works, the datasets commonly used, and both traditional and deep learning-based methods. It also points out what's working well, where current methods fall short, and what researchers still need to solve. The goal is to offer helpful insights for anyone working to improve or apply gaze tracking technologies in real-world scenarios.},
  archive      = {J_EAAI},
  author       = {Sapna Singh Kshatri and Deepak Singh},
  doi          = {10.1016/j.engappai.2025.112066},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112066},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A systematic review on vision-based gaze estimation: Advance in computer vision and deep learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel framework for improving railway driver performance based on emotional intelligence and job-driven factors: An artificial neural network method. <em>EAAI</em>, <em>161</em>, 112065. (<a href='https://doi.org/10.1016/j.engappai.2025.112065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient transportation systems critically rely on human factors to ensure safety, reliability, and service quality. This study introduces a novel framework for evaluating and improving the performance of the Tehran Urban and Suburban Railway Company (TRS) drivers by focusing on the role of emotional intelligence (EI) and job-driven (JD) factors. The core of the proposed method is a two-stage hybrid approach: first, an Artificial Neural Network (ANN) is used to model driver performance using EI and JD factors as inputs and outputs, respectively; then, Data Envelopment Analysis (DEA) validates the results and benchmarks performance levels. Data were collected from 146 TRS drivers through a standardized questionnaire. Sensitivity analysis and statistical tests evaluated the impact of EI and JD factors on driver performance. Additionally, a SWOT (Strengths, Weaknesses, Opportunities, Threats) analysis translated the findings into practical recommendations for system improvement. The findings reveal high job satisfaction and low job stress levels among TRS drivers, highlighting the significant contribution of EI and JD factors. By combining data-driven prediction, performance benchmarking, and strategic analysis, this study introduces a novel, human-centered framework for driver Performance Evaluation (PE)—one that fills methodological gaps in the literature and supports enhancing safety, efficiency, and passenger satisfaction in railway systems.},
  archive      = {J_EAAI},
  author       = {Narges Hajloo and Behnaz Salimi and Mahdi Hamid and Masoud Rabbani},
  doi          = {10.1016/j.engappai.2025.112065},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112065},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel framework for improving railway driver performance based on emotional intelligence and job-driven factors: An artificial neural network method},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient fusion-based deep learning framework for land use and land cover image clustering. <em>EAAI</em>, <em>161</em>, 112061. (<a href='https://doi.org/10.1016/j.engappai.2025.112061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land use and land cover (LULC) analysis is vital for understanding spatial dynamics and informing environmental management, urban planning, and sustainable development. Traditional approaches, such as manual surveys and conventional image clustering methods, often face limitations in scalability and adaptability. This paper presents a novel deep learning framework that combines the Vision Transformer (ViT) and Variational Autoencoder (VAE) to extract complementary feature representations for LULC image clustering. The ViT tokenizes image patches to capture high-level semantic features, while the VAE models latent structures to integrate contextual and structural information. To further improve clustering performance, the framework incorporates Uniform Manifold Approximation and Projection (UMAP) for dimensionality reduction followed by k -means++ clustering, enabling a scalable and robust solution for diverse datasets. Experiments on multiple datasets, including the Urban Atlas LULC 2018 dataset and recent LULC maps of Japan and Vietnam, demonstrate the framework’s superior ability to capture complex LULC patterns compared to traditional methods. The datasets and source code will be made publicly available at https://github.com/ClarkDinh/LULCMiner . This framework has broad applications across geospatial and remote sensing engineering, civil and environmental engineering, agricultural planning, transportation, and urban development.},
  archive      = {J_EAAI},
  author       = {Tai Dinh and Dat Tran and Zdena Dobešová and Huynh Van Hong and Daniil Lisik and Rameesh Khan},
  doi          = {10.1016/j.engappai.2025.112061},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112061},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient fusion-based deep learning framework for land use and land cover image clustering},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing multi-objectives urban siting of hydrogen refueling dispenser using fuzzy NSGA-II: A case study in fez, morocco. <em>EAAI</em>, <em>161</em>, 112060. (<a href='https://doi.org/10.1016/j.engappai.2025.112060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To support the growing need for sustainable urban transport, it is essential to reduce the environmental impact of vehicles; this study focuses on optimizing hydromobility through the strategic integration of hydrogen dispensers (HDs) into existing locations, rather than deploying standalone hydrogen refueling stations (HRSs). This approach minimizes costs while enhancing accessibility, addressing the current limitations in hydrogen vehicle (HV) adoption. A novel method combining the non-dominated sorting genetic algorithm II (NSGA-II) with fuzzy logic and Pareto front analysis is proposed to identify optimal HD locations using a real case study of Fez city in Morocco. The results provide actionable strategies for implementing HDs in a way that balances efficiency, accessibility, and budget constraints. The study demonstrates how intelligent planning can support the transition to cleaner energy solutions in urban mobility.},
  archive      = {J_EAAI},
  author       = {Soukayna Abibou and Dounia El Bourakadi and Ali Yahyaouy and Hamid Gualous},
  doi          = {10.1016/j.engappai.2025.112060},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112060},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing multi-objectives urban siting of hydrogen refueling dispenser using fuzzy NSGA-II: A case study in fez, morocco},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic data enhancement using diffusion models for improved miscanthus identification and bioenergy extraction. <em>EAAI</em>, <em>161</em>, 112059. (<a href='https://doi.org/10.1016/j.engappai.2025.112059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Miscanthus, a high-yielding perennial grass pivotal for bioenergy production, requires precise species identification to optimize bioenergy extraction. However, limited annotated spectral datasets hinder robust classification model development. To address this challenge, the paper proposes a novel diffusion probabilistic model tailored for near-infrared spectral synthesis. Unlike conventional generative approaches, the proposed model integrates a bidirectional gated recurrent unit-based temporal encoder and one dimension convolutional neural networks within a diffusion framework, augmented by a spectral attention module to prioritize critical absorption bands. This architecture uniquely addresses the sequential dependencies and subtle biochemical variations inherent in near-infrared spectral, enabling high-fidelity generation of diverse synthetic data. The diffusion process is optimized through a hybrid loss function combining variational lower bound training with mean squared error for pixel-level fidelity and maximum mean discrepancy for distributional alignment. Evaluated on 517 near-infrared spectral samples across three Miscanthus species, the proposed model outperforms traditional variational autoencoders , generative adversarial networks, and standard diffusion models in terms of sample authenticity and diversity. Incorporating synthetic data enhanced the accuracy, precision, and recall of downstream classifiers by 10%–15%, with the convolutional neural networks attaining 87% accuracy using hybrid real-synthetic training data. Remarkably, even with 50% synthetic data substitution, classification accuracy remained robust at 75%, demonstrating the model’s efficacy in mitigating data scarcity and advancing precision agriculture for bioenergy optimization.},
  archive      = {J_EAAI},
  author       = {Xinyue Wang and Xiangdong Chen and Jun Jiang and Ronggao Gong and Biao Wang},
  doi          = {10.1016/j.engappai.2025.112059},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112059},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synthetic data enhancement using diffusion models for improved miscanthus identification and bioenergy extraction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-order feature learning with global–local attention for real-time X-ray security inspection. <em>EAAI</em>, <em>161</em>, 112058. (<a href='https://doi.org/10.1016/j.engappai.2025.112058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X-ray security inspection in high-throughput environments such as airports faces fundamental challenges stemming from the intrinsic complexity of baggage scanning. These challenges include feature entanglement from overlapping objects, visual distortions due to fixed imaging angles, inconsistent pseudo-color representations caused by varying X-ray absorption, and the difficulty of detecting prohibited items across multiple scales. To tackle these challenges, we introduce Multi-Order Gated Network (MoGNet), a lightweight transformer-based architecture that integrates three core innovations. First, a Multi-order Gated Aggregation Block designed for efficient multi-order feature extraction. Second, a Global–Local Self-Attention mechanism that enhances differentiation between foreground and background elements. Finally, a DynamicFusion module for adaptive integration of multi-scale features. Comprehensive evaluations on five challenging datasets establish our proposed framework, MoGNet, as the new state-of-the-art (SOTA). The model demonstrates superior performance, achieving mean Average Precision (mAP) scores at a 50% Intersection over Union (IoU) threshold (mAP 50 ) of 75.4%, 91.9%, 91.2%, 96.6%, and 80.0%, respectively. This high accuracy is maintained while operating at an efficient 64.1 Frames Per Second (FPS). These comprehensive experimental results demonstrate its remarkable capability to optimize the balance between computational efficiency and detection accuracy, establishing it as a preferable solution for real-time contraband detection in practical security screening.},
  archive      = {J_EAAI},
  author       = {Ling Guo and Yangbin Xu and Shouhong Chen},
  doi          = {10.1016/j.engappai.2025.112058},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112058},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-order feature learning with global–local attention for real-time X-ray security inspection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stress-dependent strength neural network model for predicting the true triaxial strength of rocks. <em>EAAI</em>, <em>161</em>, 112057. (<a href='https://doi.org/10.1016/j.engappai.2025.112057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the true triaxial strength of rocks is essential for safe underground engineering, yet existing empirical and data-driven models often fail to capture the nonlinear effects of the intermediate principal stress σ 2 . This study proposes a stress-dependent strength neural network (SDSNN) that integrates physically informed constraints, including monotonicity and boundary conditions, as well as an exponential adaptive weighting strategy to balance data and constraint losses. Cohesion and internal friction angle are used as input features, replacing conventional reliance on uniaxial strength. Compared with a purely data-driven neural network (DDNN) and a constraint-aware variant without adaptive weighting (SDSNN#0), SDSNN achieves significantly better predictive accuracy and robustness across test sets, representative rock types, and five-fold cross-validation. In particular, it maintains consistent strength trends and improved stability across six representative rocks with diverse mechanical properties. Importantly, the model maintains high performance even when trained only on low-to-mid σ 2 data and tested on high σ 2 conditions—demonstrating strong generalization under extrapolation. This capability has received relatively limited attention in data-driven models and is particularly valuable in practical scenarios where high- σ 2 test data are limited or difficult to obtain. Furthermore, ablation analysis demonstrates that removing physical constraints leads to a notable decrease in model accuracy, underscoring the importance of incorporating strength variation characteristics into the model. SDSNN shows particular advantage under boundary stress conditions and when facing noisy or sparse datasets, indicating its potential to serve as a robust and interpretable tool for true triaxial strength prediction in geotechnical applications.},
  archive      = {J_EAAI},
  author       = {Tianzhi Yao and Yunpeng Gao and Jianhai Zhang and Ru Zhang and Li Qian and Qijun Hu and Xianliang Wang and Feng Jiang},
  doi          = {10.1016/j.engappai.2025.112057},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112057},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A stress-dependent strength neural network model for predicting the true triaxial strength of rocks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source contrastive cluster center method for cross-domain bearing fault identification. <em>EAAI</em>, <em>161</em>, 112056. (<a href='https://doi.org/10.1016/j.engappai.2025.112056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the complexity and time-varying attributes of the exterior surroundings, rolling bearings commonly operate under variable working conditions at any time. Therefore, there is a multi-source domain adaptation problem that involves multiple source domains and a target domain. In this circumstance, identifying faults directly in a multi-source domain through a model built in a single source domain will also lead to limited model generalization ability, i.e., due to the incompleteness of the training sample size caused by the singularity of the domain quantity limited access to fault knowledge in a single source domain, the established model may be prone to over-fitting, thus whose generalization ability has been decreased under complex and variable working conditions to a certain extent. Hence, this paper has proposed a Multi-source Contrastive Cluster Center (MS3C) Method for addressing the aforementioned issues. Experimental findings on two datasets have suggested that MS3C has not only considered the domain shifts of the same classes between different source domains and the target domain but also adaptively aligned the feature distributions of the same classses in different source domains, therefore, MS3C has a higher identification rate, a better clustering and classification performance and a superior convergence.},
  archive      = {J_EAAI},
  author       = {Pengfei Chen and Lizhen Wu and Rongzhen Zhao and Kongyuan Wei and Yuqiao Zheng and Linfeng Deng and Yongfei Zhang and Mingkuan Shi and Zhuo Chen},
  doi          = {10.1016/j.engappai.2025.112056},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112056},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-source contrastive cluster center method for cross-domain bearing fault identification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced encoder–decoder network for temporomandibular joint segmentation in magnetic resonance images. <em>EAAI</em>, <em>161</em>, 112054. (<a href='https://doi.org/10.1016/j.engappai.2025.112054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of the condyle, articular disc, and articular eminence from magnetic resonance imaging (MRI) is essential for the diagnosis and treatment planning of temporomandibular joint (TMJ) disorders. However, current deep learning methods for TMJ segmentation face significant challenges: (1) anatomical structures of the TMJ exhibit complex inter-patient variability; (2) structural boundaries are often ambiguous; and (3) large inter-slice spacing in MRI makes it difficult to fully utilize spatial context, limiting the effectiveness of both three-dimensional and two-dimensional approaches. To address these challenges, we propose an edge-enhanced TransUNet-based encoder–decoder framework that effectively integrates local edge features and global contextual information to obtain accurate and robust TMJ segmentation. Specifically, a cross-slice attention transformer (CAT) is introduced to capture inter-slice dependencies, addressing the challenge of large slice spacing and enhancing the utilization of contextual information across slices. Moreover, a feature enhancement module (FEM) is designed to explicitly fuse edge information, facilitating accurate localization where boundaries are blurred or indistinct. In addition, an attention gate (AG) mechanism adaptively highlights salient anatomical structures and suppresses irrelevant background, improving the model’s overall focus and resistance to noise. Evaluated on the private TMJ MRI dataset, our method achieves Dice similarity coefficients (DSC) of 0.922, 0.834, and 0.837 for the condyle, articular disc, and articular eminence, respectively, outperforming baseline and comparison methods. Further validation on a public knee MRI dataset demonstrates the good generalizability of the proposed method. These results demonstrate robust and precise TMJ segmentation, supporting reliable automated analysis in clinical settings.},
  archive      = {J_EAAI},
  author       = {Yilin Hu and Yunan Zhang and Wei Tang and Jixiang Guo},
  doi          = {10.1016/j.engappai.2025.112054},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112054},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An enhanced encoder–decoder network for temporomandibular joint segmentation in magnetic resonance images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way decision method integrating probabilistic linguistic term sets and prospect theory in large-scale scenarios. <em>EAAI</em>, <em>161</em>, 112053. (<a href='https://doi.org/10.1016/j.engappai.2025.112053'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probability linguistic term sets (PLTSs), owing to their ability to effectively represent the uncertainty and complexity of decision information, have been widely adopted in large-scale multiattribute decision-making (MADM) scenarios. However, existing decision-making methods in the PLTS environment typically suffer from information loss in similarity computation, subjectivity in weight determination, and inadequate consideration of decision-makers’ behavioral psychology, which limits their applicability in real-world complex situations. To address these issues, this paper proposes an innovative hybrid three-way decision (TWD) method that integrates prospect theory with multiobjective optimization on the basis of the ratio analysis (MOORA) approach. Compared with existing studies, the main contributions of this paper include (1) an objective weight determination mechanism based on the information entropy of PLTSs, which improves the scientific validity and computational efficiency of weight allocation compared with subjective or complex traditional methods (2) a novel direct similarity degree based on the probability linguistic Jensen–Shannon (PLJS) divergence, which effectively overcomes the information loss caused by indirect distance measures and achieves accurate similarity characterization between PLTSs (3) a new conditional probability determination strategy utilizing θ -level similarity classes that enhances the dynamic adaptability and accuracy of conditional probability estimation and (4) the integration of prospect theory and the MOORA method within the TWD framework, enabling hierarchical classification of alternatives while fully reflecting decision-makers’ psychological and behavioral characteristics, thereby facilitating the classification and ranking of alternatives. Furthermore, through comparative analysis with large-scale real-world air quality assessment data and mainstream PLTS-based decision-making methods, the effectiveness and rationality of the proposed method are comprehensively verified, demonstrating its superiority, robustness, and practical application value.},
  archive      = {J_EAAI},
  author       = {Zhaxi Pahua and Haidong Zhang and Yizhu Cairang and Yanping He},
  doi          = {10.1016/j.engappai.2025.112053},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112053},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-way decision method integrating probabilistic linguistic term sets and prospect theory in large-scale scenarios},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive feature-level fusion of manifold and deep learning for robust multi-view face recognition. <em>EAAI</em>, <em>161</em>, 112052. (<a href='https://doi.org/10.1016/j.engappai.2025.112052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust face recognition across varying poses, lighting conditions, and viewpoints remains a significant challenge in engineering applications such as surveillance, authentication, and human–computer interaction. This paper presents Dynamic Manifold–Deep Learning Fusion (DM-DLF), an artificial intelligence (AI)-based framework that integrates manifold learning with deep neural networks using an adaptive feature-level weighting strategy. By combining global semantic features and local geometric structures, the proposed AI model enhances identity recognition under real-world multi-view scenarios. Experimental results show that DM-DLF surpasses recent transformer-based and graph-based models, achieving up to 94.00 % classification accuracy. The method also reduces prediction error and improves training efficiency. These findings confirm DM-DLF as a powerful AI solution for multi-view face recognition in engineering systems where labeled data is limited and view diversity is high.},
  archive      = {J_EAAI},
  author       = {Faraein Aeini},
  doi          = {10.1016/j.engappai.2025.112052},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112052},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive feature-level fusion of manifold and deep learning for robust multi-view face recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing long-term load forecasting with convolutional informer-based hybrid model. <em>EAAI</em>, <em>161</em>, 112051. (<a href='https://doi.org/10.1016/j.engappai.2025.112051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term load forecasting (LTLF) is essential for energy management but challenged by the complexity of non-stationary time series. The Informer model struggles to capture localized peak–valley patterns, while Variational Mode Decomposition (VMD) faces issues with feature complexity. This study proposes a hybrid framework integrating VMD, Informer, and a Convolutional Long Short-Term Memory (CNN-LSTM) module for accurate LTLF. VMD decomposes non-stationary load data into multi-scale intrinsic mode functions, refined through spectral and autocorrelation analyses to ensure robust feature extraction. The Informer employs sparse self-attention for efficient long-sequence modeling, with CNN-LSTM enhancing the decoder to capture localized temporal dynamics. Experiments on non-stationary load time series across multiple prediction horizons demonstrate that the proposed framework significantly improves forecasting accuracy and robustness compared to baseline models, including Informer and its derivatives. By excelling in complex load pattern prediction, the framework supports efficient grid scheduling and resource optimization in energy systems.},
  archive      = {J_EAAI},
  author       = {Bin Sun and Xudong Chen and Tao Shen and Liyao Ma},
  doi          = {10.1016/j.engappai.2025.112051},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112051},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing long-term load forecasting with convolutional informer-based hybrid model},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault diagnosis of high-voltage three-phase asynchronous motors using residual neural networks and bidirectional gated recurrent units. <em>EAAI</em>, <em>161</em>, 112049. (<a href='https://doi.org/10.1016/j.engappai.2025.112049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-voltage three-phase asynchronous motors are extensively used in industrial production; however, rotor bar breakage faults are characterized by strong concealment and severe consequences, making early and accurate diagnosis difficult with traditional methods. To address this issue, this paper proposes a deep learning model based on a Residual Neural Network (ResNet) and a Bidirectional Gated Recurrent Unit (Bi-GRU) for motor fault diagnosis. The proposed model integrates the spatial feature extraction advantages of ResNet with the temporal modeling capabilities of Bi-GRU, simultaneously capturing spatiotemporal information from voltage and current signals. The model was trained and tested on a large-scale dataset comprising 324,000 data points under nine distinct operating conditions. Experimental results demonstrate that the proposed method achieves over 99.83 % in key metrics such as accuracy, precision, recall, and F1-score, significantly outperforming traditional approaches and other comparative models. Additionally, it maintains stable performance under varying operating conditions, demonstrating strong robustness and generalization capability. Further ablation experiments also validated the effectiveness of each module within the proposed model. This study indicates that the application of deep learning in industrial motor fault diagnosis has promising prospects and practical value.},
  archive      = {J_EAAI},
  author       = {Huihui Yang and Yuxin Wu},
  doi          = {10.1016/j.engappai.2025.112049},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112049},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis of high-voltage three-phase asynchronous motors using residual neural networks and bidirectional gated recurrent units},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot image translation via query compensation and style enhancement. <em>EAAI</em>, <em>161</em>, 112048. (<a href='https://doi.org/10.1016/j.engappai.2025.112048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In zero-shot image translation methods based on diffusion models, two prevalent challenges are the loss of identity information and insufficient stylization. To address these issues, we propose a zero-shot image translation method. Specifically, we use the edit-friendly noise space for image inversion. By this way, the identity of the input image is largely preserved. Additionally, we introduce an identity compensation mechanism by injecting the source query vectors into the denoising process. Furthermore, to tackle the model’s insufficient stylization ability, we propose cross-attention style modulation (CSM) to transfer style information from the reference to the input image. Finally, to further enhance the style effect of the translated image, we design initial latent self-enhancement (ILS), style supplementation (SS), and style alignment (SA) strategies. Our zero-shot image translation method does not require training samples, optimization, or fine-tuning. We achieve this by manipulating the self-attention features of a pre-trained diffusion model in a manner analogous to cross-attention—by replacing the key and value vectors of the input image with those of the reference image during the denoising process. Extensive in-domain and cross-domain translation experiments demonstrate the effectiveness of our method across a wide range of object categories and show strong robustness to variations in object shape, size, posture and instance between the input and reference image. The proposed method achieves competitive performance in identity preservation, as measured by the mean Intersection over Union (mIoU), and attains the best style transfer in terms of Single Image Fréchet Inception Distance (SIFID). In addition, qualitative comparisons demonstrate that our approach significantly outperforms the baselines.},
  archive      = {J_EAAI},
  author       = {Heng Zhang and Yi-Jun Yang and Wei Zeng},
  doi          = {10.1016/j.engappai.2025.112048},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112048},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-shot image translation via query compensation and style enhancement},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Camouflaged object detection with boundary localization in complex backgrounds. <em>EAAI</em>, <em>161</em>, 112047. (<a href='https://doi.org/10.1016/j.engappai.2025.112047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary challenge of Camouflaged Object Detection (COD) lies in the high similarity between the target and the complex background, making it difficult for the human eye to distinguish them. Based on the phenomenon that human attention shifts between the target and the background when observing objects, we propose a network model named MENet. This model adopts a three-stage decoupled architecture of “localization-interaction-fusion.” In the localization stage, we utilize an attention mechanism-based backbone network (Pyramid Vision Transformer V2, abbreviated as PVT-V2) to generate multi-level features, which can initially locate the target area. In the interaction stage, we design a Contour-Aware Edge Module (CAEM) and an Area Decoder (AD) to capture the target edges and background information, respectively, thereby achieving precise localization of the target boundary and reducing interference from background noise. Furthermore, we developed a Boundary Guidance Module (BGM) that effectively injects boundary cues and relevant background information separately into the multi-level features, enhancing the model’s ability to detect target edges in complex backgrounds. In the fusion stage, we design two Feature Fusion Modules (FFM and KFFM) to effectively merge multi-level features with precise boundaries and de-noised features, thereby enhancing the prediction performance of camouflaged objects. Extensive experiments on three challenging benchmark datasets demonstrate that our MENet outperforms many existing state-of-the-art methods. Our method leverages artificial intelligence (AI) techniques to improve the accuracy of camouflaged object and pest detection in complex visual environments. Our code is publicly available at: https://github.com/yang19950966666/MENet .},
  archive      = {J_EAAI},
  author       = {Guangjian Zhang and Zhengming Yang and Yong Wang and Yuliang Chen and Duoqian Miao},
  doi          = {10.1016/j.engappai.2025.112047},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112047},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Camouflaged object detection with boundary localization in complex backgrounds},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A grid-based boundary sharpening clustering algorithm. <em>EAAI</em>, <em>161</em>, 112045. (<a href='https://doi.org/10.1016/j.engappai.2025.112045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the clustering problem for arbitrary shapes, in this paper, we propose a Grid-based Boundary Sharpening clustering algorithm called as “GBSharp”. This method is grounded in morphology and relies on two fundamental morphological operations: dilation and erosion. The main innovations of the proposed algorithm lie in two aspects. Firstly, we further introduce the concepts of inward dilation and bridge erosion based on the basic morphological operations to reduce the impact of the chain effect. Secondly, a unique indexing structure is designed specifically for non-empty cells in high dimensional space. In addition, to tackle the complex conditional judgments encountered in high-dimensional scenarios, we further utilize the inversion method for bridge-erosion operation. Experiments conducted on synthetic datasets and real-world datasets further validate the effectiveness and efficiency of the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Lin Ma and Qijing Yan and Mengxia Lv and Tiefeng Ma and Mingchang Cheng},
  doi          = {10.1016/j.engappai.2025.112045},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112045},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A grid-based boundary sharpening clustering algorithm},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advances in physics-informed neural networks for solving complex partial differential equations and their engineering applications: A systematic review. <em>EAAI</em>, <em>161</em>, 112044. (<a href='https://doi.org/10.1016/j.engappai.2025.112044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most physical and engineering problems can be described by partial differential equations (PDEs), which are typically solved using numerical methods such as the finite difference method and the finite element method. However, conventional numerical discretization approaches face significant challenges in terms of computational efficiency and convergence speed when dealing with complex nonlinear PDEs, such as high-dimensional nonlinear PDEs, stiff PDEs, PDEs with complex boundary conditions or irregular geometries, and multi-scale PDEs. Recently, physics-informed neural networks (PINNs) have emerged as a transformative methodology for solving complex PDEs by integrating physical laws intrinsically into deep learning architectures. While PINNs effectively overcome mesh dependency and dimensionality constraints inherent in traditional numerical methods, they still encounter persistent challenges related to training convergence and generalization robustness. This paper aims to present a comprehensive review of the state-of-the-art developments in PINNs for solving complex PDE problems. The core ideas, network architectures, and generic implementation frameworks, along with associated open-source Python libraries, are first introduced in detail. Furthermore, a systematic taxonomy of optimization techniques is provided, covering hyperparameter selection, adaptive sampling strategies, physics-constrained loss formulations, hybrid differentiation approaches, and architectural innovations. Subsequently, various coping strategies and research advancements of PINNs in addressing complex nonlinear PDE problems are thoroughly discussed. Real-world engineering applications are then reviewed across multiple domains, including cosmology and quantum mechanics, materials science and manufacturing, fluid mechanics, energy systems, biological and environmental sciences, and power and information technologies. Finally, this paper discusses the current challenges and limitations of PINNs in solving complex PDEs and outlines potential directions for future research. By addressing the current limitations and pursuing targeted improvements in architectures, training, interpretability and generalization, PINNs can become a powerful tool in engineering and scientific applications.},
  archive      = {J_EAAI},
  author       = {Jiangtao Guo and Hao Zhu and Yujie Yang and Chenrui Guo},
  doi          = {10.1016/j.engappai.2025.112044},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112044},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Advances in physics-informed neural networks for solving complex partial differential equations and their engineering applications: A systematic review},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DPMF-net: A dual-path perceptive multi-stage fusion network for skin lesion segmentation. <em>EAAI</em>, <em>161</em>, 112043. (<a href='https://doi.org/10.1016/j.engappai.2025.112043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of skin lesions in dermoscopic images is crucial for skin cancer detection and treatment. Despite progress in deep learning-based methods, challenges remain due to diverse skin lesion shapes, colors, and blurred boundaries. We propose a novel Dual-path Perceptive Multi-stage Fusion Network (DPMF-Net) for skin lesion segmentation. DPMF-Net integrates multiple feature refinement modules. It aims to gradually optimize lesion representations by leveraging the dual-path framework to perceive high-level contextual information. The Spatial Frequency Dual-path Cascaded Perception Module (SFDCP) synergizes spatial and frequency domains to model long-range dependencies and suppress noise, enhancing perception of low-contrast lesions. Subsequent to the SFDCP, the Spatial Channel Dual-path Parallel Perception Module (SCDPP) employs entropy-driven attention and multi-granularity convolutions in skip connections to dynamically select informative channels and extract lesion details across spatial scales. To verify the efficacy of our proposed DPMF-Net, extensive experimental assessments are carried out across four challenging datasets. The outcomes of these quantitative and qualitative experiments confirm that our approach significantly outperforms current state-of-the-art methods in terms of all evaluation metrics.},
  archive      = {J_EAAI},
  author       = {Yuling Huang and Yaoyao Ma and Jing Wang and Chao Xu and Zhiwei Fan and Di Wu},
  doi          = {10.1016/j.engappai.2025.112043},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112043},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DPMF-net: A dual-path perceptive multi-stage fusion network for skin lesion segmentation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradient surgery: A necessity for robust test-time adaptation for detecting casting defects. <em>EAAI</em>, <em>161</em>, 112039. (<a href='https://doi.org/10.1016/j.engappai.2025.112039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Casting defects pose a significant challenge in the manufacturing industry, leading to material waste, production inefficiencies, and compromised product quality. While deep learning models have shown promise in automating defect detection, their effectiveness is often constrained by domain shifts and variability in real-world data distributions. In this work, we propose Bayesian Test-Time Adaptation (BTTA), a novel framework designed to enhance the robustness and adaptability of machine learning models in such dynamic environments. Unlike traditional Test-Time Adaptation (TTA) methods, our approach employs gradient-guided diversification with Stein Variational Gradient Descent (SVGD) to explore diverse optimization paths. Experimental results on benchmark datasets, including CIFAR-10-C , Casting Defects , and GDXray , demonstrate significant performance improvements across key metrics. Notably, the framework achieves an average accuracy improvement of 2-3% under severe corruption levels and excels in cross-domain generalization, highlighting its ability to handle diverse and unseen defect categories. This dynamic adaptability not only addresses the limitations of static models but also offers a practical and cost-effective solution for real-time defect detection in industrial settings. Our study underscores the potential of BTTA to transform quality assurance processes, ensuring reliable performance across varying operational conditions without the need for extensive retraining or large annotated datasets. The codebase for BTTA is available on: https://github.com/afsharshamsi/GradSurgery .},
  archive      = {J_EAAI},
  author       = {Afshar Shamsi and Rejisa Becirovic and Hamid Alinejad-Rokny and Arash Mohammadi and Ahmadreza Argha},
  doi          = {10.1016/j.engappai.2025.112039},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112039},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Gradient surgery: A necessity for robust test-time adaptation for detecting casting defects},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing real-time detection transformer for small floating targets. <em>EAAI</em>, <em>161</em>, 112038. (<a href='https://doi.org/10.1016/j.engappai.2025.112038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing the challenge of detecting small floating target in complex water environments, where it is difficult to balance real-time performance and end-to-end capabilities, this study introduces a specialized model called the Enhancing Real-Time Detection Transformer (ERT-DETR). This model integrates a Dynamic Feature Pyramid Network (DFPNet) with a Micro-Attention Module (MAM) to achieve refined feature extraction and enhanced object recognition mechanisms. Additionally, it incorporates an Inner Intersection over Union (Inner-IoU) auxiliary bounding box loss function, which accelerates model convergence and improves bounding box accuracy. Experiments conducted on the Floating Object in Water Image Dataset (FloW-Img) demonstrate that the ERT-DETR model achieves a 92.6% Average Precision (AP) and 118.84 Frames Per Second (FPS), outperforming the baseline Real-Time Detection Transformer (RT-DETR) by 4.3% and 19.8%, respectively. The ERT-DETR model’s precision and real-time performance in dynamic water surface environments surpass those of the most advanced You Only Look Once (YOLO) and Detection Transformer (DETR) series detectors. This model is significant for enhancing small floating target detection capabilities in complex water environments and can be extended to applications in marine management, environmental monitoring, and vessel tracking.},
  archive      = {J_EAAI},
  author       = {Guobing Xie and Xinran Wu and Jiefeng Shi and Yixin Su and Binghua Shi},
  doi          = {10.1016/j.engappai.2025.112038},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112038},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing real-time detection transformer for small floating targets},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-contact weight intelligent estimation based on yak skeleton localization. <em>EAAI</em>, <em>161</em>, 112036. (<a href='https://doi.org/10.1016/j.engappai.2025.112036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weight estimation is a vital method for monitoring the growth and health of yaks, however, traditional techniques-such as relying on herders’ experience or using weighbridge-are labor-intensive, time-consuming and pose safety risks. Currently, many studies have shown that yak body size can be an effective indicator of weight. With the advancement of computer vision, non-contact weight estimation has become increasingly feasible for livestock. Yet, studies focusing on yak weight estimation, particularly in high-altitude plateau regions, remain limited. Herein, we propose a novel weight estimation approach based on deep learning and binocular vision technology to address this gap. The method involves four main steps: (1) yak image acquisition, (2) skeletal key point localization, (3) body size calculation (4) weight estimation using Gaussian process regression. To enhance practicality and mobility, we also developed two edge-intelligent devices: an intelligent inspection vehicle and a handheld detection unit, enabling convenient and non-invasive weight estimation. Our models are trained and tested on a yak dataset collected by our team on the Tibetan Plateau. Experimental results demonstrate the effectiveness of our approach, achieving an Mean Absolute Percentage Error (MAPE) of 0.12 percent, a Mean Absolute Error (MAE) of 25.4 kilograms (kg) and a Coefficient of determination ( R 2 ) value of 0.72. It not only provides a new technical solution for the yak industry but also provides innovative insights for advancing intelligent animal husbandry. The code and data can be accessed at https://github.com/FeiWang-swun/YakWeight .},
  archive      = {J_EAAI},
  author       = {Fei Wang and Xinghua Zou and Zhijiang Chen and Qi Tang and Tianshuo Li and Shuiying Wang and Lijun Yang and Dongming Tang},
  doi          = {10.1016/j.engappai.2025.112036},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112036},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Non-contact weight intelligent estimation based on yak skeleton localization},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of the performances of artificial intelligence bots using continuous intuitionistic fuzzy evaluation based on distance from average solution method. <em>EAAI</em>, <em>161</em>, 112033. (<a href='https://doi.org/10.1016/j.engappai.2025.112033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of artificial intelligence (AI) has introduced novel opportunities and challenges in various fields. In this study, we present a pioneering approach known as Continuous Intuitionistic Fuzzy (CINFU) Evaluation based on Distance from Average Solution (EDAS), an innovative extension of the EDAS method tailored to Continuous Intuitionistic Fuzzy Sets. This methodology is designed to compare the performance of AI tools. The capabilities of AI bots have been examined through their success rates in various tasks and uncertainty levels in decision-making processes. The study aims to evaluate the effectiveness of different models in decision-making processes by analyzing the performances of AI bots such as Chat Generative Pre-trained Transformer (ChatGPT), Bard, and Claude based on both objective measurements and fuzzy evaluation criteria. The comparison focuses on key performance criteria such as Bots Triggered, User Engagement, Message Click-Through Rate, Chat Handoff, User Retention, Bounce Rate & Dwell Time, Leads Captured, and Customer Satisfaction Score. Ultimately, the validity and robustness of the approach have been tested with sensitivity analysis.},
  archive      = {J_EAAI},
  author       = {Nurşah Alkan and Umut Aydın and Akın Menekşe and Cengiz Kahraman},
  doi          = {10.1016/j.engappai.2025.112033},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112033},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comparison of the performances of artificial intelligence bots using continuous intuitionistic fuzzy evaluation based on distance from average solution method},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A global linear attention incorporated video transformer for robust sintering condition recognition. <em>EAAI</em>, <em>161</em>, 112032. (<a href='https://doi.org/10.1016/j.engappai.2025.112032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust and accurate sintering condition recognition is a fundamental yet critical issue in the design of image-based intelligent combustion control systems. However, owing to the weak texture and fast changing characteristics of flame videos, capturing the condition indicator using existing gradient-based methods is challenging. To address this issue, we propose a global linear attention incorporated video transformer model for sintering condition recognition. First, to reduce the prediction error and uncertainty, the spatial-temporal features are extracted to describe the dynamic characteristics of the flame video streams based on the video shifted window (Swin) Transformer architecture. Next, to address the problem that the local attention strategy used in the Video Swin Transformer is insufficient for global flame feature extraction, we propose a Video Linear Attention block that obtains the global attention as a supplement. Extensive experiments conducted on a real-world rotary kiln sintering dataset demonstrate the effectiveness of our approach, achieving an overall accuracy of 97.76% and an F1-score of 95.30%. Compared to the Video Swin Transformer model, these results represent improvements of 2.00% in accuracy and 4.96% in F1-score, respectively. This research is particularly significant in the context of real-time identification of combustion process conditions, optimization of control parameters, and realization of more stable and efficient combustion process control.},
  archive      = {J_EAAI},
  author       = {Leyuan Wu and Junlin Wu and Dingxiang Wang and Qiang Fu},
  doi          = {10.1016/j.engappai.2025.112032},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112032},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A global linear attention incorporated video transformer for robust sintering condition recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Markerless gait analysis for parkinson’s disease diagnosis: A study on machine learning integration and features explainability. <em>EAAI</em>, <em>161</em>, 112031. (<a href='https://doi.org/10.1016/j.engappai.2025.112031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease is a common neurodegenerative disorder with progressive loss of dopaminergic and other subcortical neurons that significantly impair motor functions, necessitating accurate diagnostic and monitoring techniques. Researchers commonly use gait analysis to estimate gait parameters to classify diseases and their progression. Traditional gait analysis, while effective, typically requires expensive, specialized equipment and lacks the flexibility for widespread clinical use. Furthermore, many existing studies on markeless approaches do not use public datasets, giving comparable and benchmarking results. Additionally, these methods often do not incorporate explainability, leaving a gap in understanding which specific gait features most significantly impact diagnostic outcomes. To address this issue, we propose a novel system to support diagnosis and analysis of the gait of Parkinson’s disease. The two-step approach involves pose extraction with vision-based pose estimation and classification employing machine learning techniques based on the subject’s temporal, kinematic, and symmetric characteristics. The explainability technique used in this study shows the important role of features such as the knee angle, cadence, and double support duration in influencing diagnostic outcomes. The system shows promising results for non-invasive, low-cost Parkinson’s disease diagnostics, reaching an accuracy of 0.95, a sensitivity of 0.90, a specificity of 0.97, a Matthew’s Correlation Coefficient (MCC) of 0.88, an Area Under the Curve (AUC) of 0.99.},
  archive      = {J_EAAI},
  author       = {Cesare Davide Pace and Alessandro Marco De Nunzio and Claudio De Stefano and Francesco Fontanella and Mario Molinara},
  doi          = {10.1016/j.engappai.2025.112031},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112031},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Markerless gait analysis for parkinson’s disease diagnosis: A study on machine learning integration and features explainability},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Offshore wind power multi-step forecasting based on multi-scale attention mechanism fusion network. <em>EAAI</em>, <em>161</em>, 112026. (<a href='https://doi.org/10.1016/j.engappai.2025.112026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonlinear, unstable, and multi-scale characteristics of offshore wind power present significant challenges for grid scheduling and power forecasting. To address this issue, this paper proposes a multi-step forecasting hybrid model for offshore wind power based on the sequence-to-sequence (Seq2Seq) architecture, which is named Multi-scale, Denoising, Attention Fusion Network (mDAFNet). The model integrates a multi-level learnable wavelet decomposition network, frequency-domain interpolation denoising technique, and dual-attention mechanism, and improves forecasting performance through joint high- and low-frequency dual-branch predictions. The process begins by improving data quality through outlier cleaning and feature selection based on grey correlation analysis and mutual information. Subsequently, a multi-level learnable wavelet decomposition network is introduced to extract high- and low-frequency subsequences from the frequency domain and optimize parameters dynamically through backpropagation. To address the noise impact on high-frequency subsequences, frequency domain interpolation denoising technique is applied for noise reduction. Then, a sequence-to-sequence model based on the dual-attention mechanism is used to forecast the denoised high-frequency subsequences, while a Long Short-Term Memory (LSTM) neural network predicts the low-frequency subsequences. Finally, the dual-branch forecasting network enables joint modeling of high- and low-frequency subsequences. We conducted experiments on two offshore wind power datasets. The results indicate that, compared to baseline models, the proposed mDAFNet reduces Mean Absolute Error, Root Mean Square Error, and Mean Absolute Percentage Error by an average of 33.94 %, 36.62 %, and 39.84 %, respectively, while significantly improving forecasting accuracy and stability. This study provides a new approach and perspective for offshore wind power forecasting.},
  archive      = {J_EAAI},
  author       = {Yizhuang Xiong and Wenbo Wang},
  doi          = {10.1016/j.engappai.2025.112026},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112026},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Offshore wind power multi-step forecasting based on multi-scale attention mechanism fusion network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted multi-granularity fuzzy probabilistic rough set based on semi-overlapping function and its application in three-way decision. <em>EAAI</em>, <em>161</em>, 112023. (<a href='https://doi.org/10.1016/j.engappai.2025.112023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel model of fuzzy probabilistic rough sets and develops an interesting three-way decision (TWD) applicable to multi-attribute group decision-making and classification problems. First, we simultaneously consider the cut-levels of fuzzy relations and decision-making fuzzy sets, investigating a new fuzzy probabilistic rough set model. This model employs semi-overlapping functions as the range of the membership functions of the fuzzy set, enhancing interpretability since the semi-overlapping functions can act as the truth tables of fuzzy logic. Second, by assigning different weights to various granular fuzzy relations, we propose a weighted multi-granularity fuzzy probabilistic rough set model. It is proven that the proposed (weighted multi-granularity) fuzzy probabilistic rough set model encompasses many existing models as special cases, thereby providing a very broad framework for rough set theory. Third, by integrating the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) method with Bayesian theory, we develop a method for computing the threshold of fuzzy probabilistic rough sets and construct a new TWD. Sorting and classification rules and algorithms for TWD are provided. Finally, we perform parameter analysis and comparative experiments on nine public datasets to verify the effectiveness and rationality of our TWD. The experimental results demonstrate that our approach exhibits superior fault tolerance and noise reduction capabilities. Specifically, the introduction of semi-overlapping functions enhances our TWD model’s performance, with A c c u r a c y improving the most on the Heart dataset, reaching 9.37%, and the F 1 score increasing the most on the Heart and Plrx datasets, reaching 5.3%. In summary, this paper offers a novel solution for applying artificial intelligence in decision-making scenarios.},
  archive      = {J_EAAI},
  author       = {Xinru Li and Lingqiang Li and Chengzhao Jia},
  doi          = {10.1016/j.engappai.2025.112023},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112023},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Weighted multi-granularity fuzzy probabilistic rough set based on semi-overlapping function and its application in three-way decision},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-driven double deep Q-network with iterated greedy for intelligent scheduling optimization in reentrant hybrid flow shops. <em>EAAI</em>, <em>161</em>, 112012. (<a href='https://doi.org/10.1016/j.engappai.2025.112012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reentrant hybrid flow shop scheduling problem (RHFSP) poses significant challenges due to its complex structure and limited research on model accuracy, solution space exploration, and adaptive strategy selection. To address these gaps, this paper proposes a novel feature-driven double deep Q-network with iterated greedy (FD3QNIG) algorithm. First, a five-dimensional mixed-integer linear programming (MILP) model is developed to significantly improve modeling accuracy. Second, a feature-driven initialization strategy (FDNEH) enhances the quality of initial solutions, while an adaptive historical information-driven destruction and reconstruction strategy (AHDDR) effectively balances exploration and exploitation during the search process. Third, multi-scale local search strategies are employed, including the first application of comprehensive exploration-driven mandatory operations local search (CED_MOLS) to RHFSP, substantially deepening the search capability. Fourth, an adaptive strategy selection mechanism based on double deep Q-Network (DDQN_ASS) dynamically guides the algorithm toward more efficient decision-making. Extensive experiments on 285 benchmark instances demonstrate that FD3QNIG achieves a 53 %–94 % improvement in average relative percentage increase ( A R P I ) over state-of-the-art methods, confirming its effectiveness and robustness.},
  archive      = {J_EAAI},
  author       = {Chexiang Li and Yuyan Han and Yuting Wang and Yiping Liu and Biao Zhang and Leilei Meng},
  doi          = {10.1016/j.engappai.2025.112012},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112012},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-driven double deep Q-network with iterated greedy for intelligent scheduling optimization in reentrant hybrid flow shops},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semi-supervised framework for generating multi-dimensional taxonomies from asset maintenance documents. <em>EAAI</em>, <em>161</em>, 112010. (<a href='https://doi.org/10.1016/j.engappai.2025.112010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operation and maintenance of buildings generate large volumes of unstructured textual data, such as inspection reports and service requests. These records contain valuable insights that can support fault detection, cost tracking, and resource planning. However, existing classification approaches often rely on static, expert-defined labels that fail to reflect the complexity of real-world maintenance operations. This paper introduces a hybrid framework that combines sentence embedding, clustering, topic modeling, and network modularization to uncover recurring patterns in maintenance text. The extracted patterns are then reviewed and refined by facility management experts to develop a multi-dimensional taxonomy model tailored to operational needs. The methodology is applied to a case study involving over 30,000 work orders. The results demonstrate how the proposed system captures fine-grained details such as system type, failure mode, and required trade expertise. A proof-of-concept software tool, developed in collaboration with facility managers, showcases the practical value of the taxonomy in enabling data-driven decision-making, such as identifying cost drivers and recurring issues. Additionally, the resulting taxonomy models serve as effective prompts for zero-shot text classification, enabling large language models to classify new maintenance records without requiring retraining or labeled data. This approach provides a scalable and adaptable foundation for text classification systems in asset management.},
  archive      = {J_EAAI},
  author       = {Soroush Sobhkhiz and Tamer El-Diraby},
  doi          = {10.1016/j.engappai.2025.112010},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112010},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A semi-supervised framework for generating multi-dimensional taxonomies from asset maintenance documents},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive review of facial beauty prediction using deep learning techniques. <em>EAAI</em>, <em>161</em>, 112009. (<a href='https://doi.org/10.1016/j.engappai.2025.112009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial beauty prediction (FBP) is an emerging area of artificial intelligence (AI) that focuses on the development of models that analyze facial features to assess beauty, based on human perception. This task is particularly challenging due to the subjective nature of beauty and limited resources. Deep learning methods have proven their exceptional ability to capture complex features and are therefore well suited for FBP tasks. This paper reviews recent advances in FBP, focusing on deep learning techniques and benchmark datasets. A proposed taxonomy organizes the main methods according to their design and applications, and comparative analyzes highlight trends and the performance of different models. Finally, the study outlines future research directions to drive progress in this evolving field.},
  archive      = {J_EAAI},
  author       = {Djamel Eddine Boukhari and Fadi Dornaika and Ali Chemsa and Abdelmalik Taleb-Ahmed},
  doi          = {10.1016/j.engappai.2025.112009},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112009},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comprehensive review of facial beauty prediction using deep learning techniques},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum relevant minimum redundant multi-label feature selection using ant colony optimization. <em>EAAI</em>, <em>161</em>, 112007. (<a href='https://doi.org/10.1016/j.engappai.2025.112007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning tasks involve instances that may belong to multiple categories simultaneously, making feature selection particularly challenging in high-dimensional feature spaces. Existing multi-label feature selection methods often suffer from limitations such as high computational complexity, inadequate handling of feature redundancy, and insufficient modelling of label dependencies. To overcome these challenges, we propose a novel framework called Maximum Relevant Minimum Redundant Multi-Label Feature Selection (MR2MLFS), which integrates a two-layer graph representation with a modified Ant Colony Optimization (ACO) strategy. The first graph layer clusters correlated features using Louvain community detection, while the second constructs a meta-graph to model inter-cluster relationships. ACO then explores this structure, favouring the selection of highly relevant and non-redundant features. To reduce computational overhead, we introduce an information-theoretic metric that estimates both feature-label relevance and feature-feature redundancy, eliminating the need for repeated classifier training during the search. We evaluated the proposed method on ten benchmark multi-label datasets using several multi-label classifiers. Experimental results show that the proposed method outperforms six state-of-the-art methods across multiple evaluation metrics, achieving an average relative improvement of 5–12 % while reducing feature dimensionality by up to 80 %. These results confirm the method's robustness, efficiency, and effectiveness in multi-label feature selection.},
  archive      = {J_EAAI},
  author       = {Mohammad Hatami and Parham Moradi and Sadegh Sulaimany and Mahdi Jalili},
  doi          = {10.1016/j.engappai.2025.112007},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112007},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Maximum relevant minimum redundant multi-label feature selection using ant colony optimization},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage model for unified sentence- and document-level biomedical event extraction. <em>EAAI</em>, <em>161</em>, 112001. (<a href='https://doi.org/10.1016/j.engappai.2025.112001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical event extraction, a cornerstone of information extraction, has increasingly attracted attention within the biomedical research community. Moreover, it is a highly complex task, which not only deals with many sub-tasks but also involves nested events. Currently, the research on biomedical event extraction, whether pipelined model or joint method, needs to be processed for each sub-task. The process of processing each sub-task one by one lead to the degradation of event extraction performance. In addition, most studies focus on extracting sentence-level events and ignore cross-sentence event information. To solve these problems, we simplify the process of event extraction, reduce the processing steps, and combine the two sub-tasks of relation extraction and argument combination as one sub-task. In addition, we consider document-level event extraction, which not only extracts cross-sentence events but also considers broader context information. Experimental results indicate that our novel approach outperforms prior studies. Additionally, the document-level event extraction model attains the top performance on the BioNLP’11 test data and achieves near-leading performance on the BioNLP’13 test data.},
  archive      = {J_EAAI},
  author       = {Fangfang Su and Yue Zhang and Pengfei Jiao and Zhidong Zhao and Bobo Li and Fei Li and Donghong Ji},
  doi          = {10.1016/j.engappai.2025.112001},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112001},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two-stage model for unified sentence- and document-level biomedical event extraction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A position-aware sets based weakly supervised framework for whole-slide subtype classification. <em>EAAI</em>, <em>161</em>, 111998. (<a href='https://doi.org/10.1016/j.engappai.2025.111998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying cancer subtypes is essential for personalized treatment and accurate prognosis due to the varying sensitivities of subtypes to therapies. However, in cancer subtype classification tasks, normal slides are usually scarce or absent as negative samples, while subtype whole-slide images (WSIs) often contain extensive unannotated normal tissue regions. These regions introduce significant noise during feature fusion and subtype classification, leading to degraded performance of existing weakly supervised methods In this paper, we propose the Position-aware Sets based Weakly Supervised learning framework (PSWS), designed for cancer subtype classification using WSIs, with a two-stage structure to enhance model efficiency. Specifically, it first presents a novel patch organization approach, distinct from the bag concept of traditional Multiple Instance Learning (MIL), called position-aware sets, as basic units for learning. Then, PSWS automatically selects subtype-specific features based on enhanced histological features and mutual-patch relations, mitigating the negative impact of unannotated negative regions. In the experiments, the superior performance of PSWS over representative MILs is validated through subtype classification tasks on both public datasets and our internally constructed dataset. Furthermore, class probabilities of position-aware sets and attention region visualizations demonstrate its post-hoc interpretability, assisting pathologists in locating suspicious areas.},
  archive      = {J_EAAI},
  author       = {Jiuman Song and Bo Yu and Xiaomin Liu and Lele Cong and Zilong Zhou and Xianling Cong and Hongyan Sun and Shuchao Pang and Hechang Chen},
  doi          = {10.1016/j.engappai.2025.111998},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111998},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A position-aware sets based weakly supervised framework for whole-slide subtype classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Action understanding in low-light and pitch-dark conditions: A comprehensive survey. <em>EAAI</em>, <em>161</em>, 111996. (<a href='https://doi.org/10.1016/j.engappai.2025.111996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action understanding in low-light and dark environments (AULLD) is a critical and technically demanding challenge at the intersection of computer vision and engineering applications. This task focuses on interpreting human actions using motion cues under visually constrained conditions, such as poor illumination or complete darkness. Since 2010, machine learning and, more notably, deep learning have significantly advanced AULLD by enabling systems to extract and learn discriminative features from complex, low-visibility data. These techniques have resulted in state-of-the-art solutions, with recent methods achieving accuracies on various benchmark datasets of up to 97.10%, and a 73.20% top-1 accuracy on an infrared dataset. These solutions have had applications across domains such as healthcare monitoring, surveillance and security, human–computer interaction, and social computing. In this survey, we provide the first comprehensive overview of the progress of the research and topical developments in AULLD. We cover a broad range of elements, including the datasets, evaluation protocols, methods, challenges, and emerging research directions. To organize and evaluate the literature in a structured, integrated way, we introduce a novel taxonomic framework, grounded in four core dimensions: body representation, temporal representation, feature representation, and neural architectures. Employing this taxonomy, we perform an analysis of AULLD approaches, exploring their methodological foundations, system design considerations, performance outcomes, and inherent trade-offs. The survey concludes with an in-depth discussion of the existing challenges confronting AULLD, highlighting several promising research directions that hold potential for advancing the field and setting the stage for future innovations and improvements in AULLD.},
  archive      = {J_EAAI},
  author       = {Muhammad Munsif and Samee Ullah Khan and Noman Khan and Altaf Hussain and Sung Wook Baik},
  doi          = {10.1016/j.engappai.2025.111996},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111996},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Action understanding in low-light and pitch-dark conditions: A comprehensive survey},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer learning framework integrating attention mechanism and domain adaptation for low earth orbit satellite network traffic prediction. <em>EAAI</em>, <em>161</em>, 111992. (<a href='https://doi.org/10.1016/j.engappai.2025.111992'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction is a crucial prerequisite for planning and even network security in Low Earth Orbit (LEO) satellite networks (LSNs). This paper designed a transfer learning framework for LSN traffic prediction that leverages attention mechanism and domain adaptation. Firstly, by integrating five-dimensional data including global population distribution, local time coefficient, the Internet penetration rate of the country, daily data volume of a single Internet user, and global aeronautical traffic demand, a traffic model that could characterize the traffic situation of the area covered by LEO satellite within a specific time range was constructed. Considering the problem of insufficient online traffic data, knowledge was transferred from terrestrial network traffic (source domain) to satellite network traffic (target domain) by incorporating the Domain-Adversarial Neural Network (DANN) method to tackle the data distribution discrepancies between the source and target domains. Finally, by combining DANN with the attention mechanism, the domain-invariant features of the source domain and the target domain were extracted to predict satellite network traffic accurately. Experimental results show that compared to baseline models, the error of the proposed framework in terms of root mean square error measurement is reduced by 9.57% to 33.47% and 18.85% to 38.99% in the two simulated LSN traffic scenarios. Moreover, this framework has low computational complexity among other transfer learning models, which can lay a foundation for subsequent satellite traffic planning and network security.},
  archive      = {J_EAAI},
  author       = {Yan Zhang and Yong Wang and Qingsong Zhao and Yadi Zhai and Zhi Lin and Luda Zhao and Yihua Hu},
  doi          = {10.1016/j.engappai.2025.111992},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111992},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transfer learning framework integrating attention mechanism and domain adaptation for low earth orbit satellite network traffic prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skeleton-based multi-person action recognition towards real-world violence detection. <em>EAAI</em>, <em>161</em>, 111987. (<a href='https://doi.org/10.1016/j.engappai.2025.111987'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action recognition is crucial in intelligent systems like robotics, healthcare, and surveillance, gaining significant attention with the rise of AI in computer vision. This work presents the Multi-Skeleton Action Recognizer (MSAR), a comprehensive multi-stage process specifically designed to enhance the recognition and classification of violent activities involving multiple individuals. The approach aims to improve accuracy and robustness in real violence detection and classification leveraging skeletal data. The proposed MSAR pipeline consists of five main stages: Human detection, Human tracking, Skeleton extraction, Data pre-processing and Padding, and Action classification. Experimental results demonstrate the effectiveness of our multi-stage process, showing significant improvements in multi-person action recognition in violence detection. In the human detection stage, our integration of multiple detection models provides a comprehensive visual comparison of model performance, offering empirical insights into accuracy, computational efficiency, and processing speed. The fusion Bidirectional Long Short-Term Memory - Gated Recurrent Unit (BiLSTM-GRU) architecture designed for action classification integrating Deep Bidirectional Long Short-Term Memory (BiLSTM) and Gated Recurrent Unit (GRU) components, demonstrated maximum accuracy of 96.46% and an average accuracy of 91.18%. The proposed architecture is explored to potentially enhance the model’s ability to capture temporal dependencies in action sequences. Additionally, our proposed multi-stage pipeline for action recognition exemplifies a modular, systematic approach, where each stage functions as an independent module is expanded, optimized, replaced without affecting others. This modularity enhances the flexibility, adaptability, scalability of the pipeline, providing a solid foundation for future advancements across various tasks, application domains.},
  archive      = {J_EAAI},
  author       = {Minh-Trieu Truong and Van-Dung Hoang},
  doi          = {10.1016/j.engappai.2025.111987},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111987},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Skeleton-based multi-person action recognition towards real-world violence detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Malware attack and defense game in fractional-order internet of underwater things: Model-based and model-free approaches. <em>EAAI</em>, <em>161</em>, 111970. (<a href='https://doi.org/10.1016/j.engappai.2025.111970'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the Internet of Underwater Things (IoUT), its cybersecurity faces increasingly severe challenges, as malware attacks have become a common and highly destructive threat. However, most existing studies rely on integer-order models or static defense mechanisms, which fail to capture the memory and hereditary properties of underwater malware propagation and lack adaptability in dynamic adversarial environments. To address this issue, this paper constructs a fractional-order propagation model and introduces differential game theory to investigate the dynamic interactions between malware and system defense, aiming to derive the optimal dynamic strategies and the corresponding Nash equilibrium for both parties. Furthermore, two innovative artificial intelligence strategy learning approaches are proposed: a model-based method and a model-free method, designed to approximate the optimal control strategies in the game. Extensive comparative experiments and simulation results demonstrate the effectiveness of the proposed methods in strategy learning. We further discuss the practical applications of these methods in IoUT as well as their scalability to other domains.},
  archive      = {J_EAAI},
  author       = {Guiyun Liu and Zulong Peng and Tingting Tan and Xiaojing Zhong and Zhongwei Liang},
  doi          = {10.1016/j.engappai.2025.111970},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111970},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Malware attack and defense game in fractional-order internet of underwater things: Model-based and model-free approaches},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised graph contrastive learning for emotion recognition based on electroencephalogram signals. <em>EAAI</em>, <em>161</em>, 111969. (<a href='https://doi.org/10.1016/j.engappai.2025.111969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition plays a crucial role in affective computing, aiming to identify and interpret human emotions. Since electroencephalography (EEG) measures brain electrical activity associated with emotional processing, its use in emotion recognition has garnered significant attention. However, due to the complexity of EEG, capturing the low-dimensional manifold structure from a high-dimensional EEG signal remains a challenge. Moreover, even though EEG labeling is expensive and requires specialization, the development of emotion recognition models has predominantly relied on labeled EEG datasets. To address these issues, we propose a semi-supervised graph contrastive learning (SGCL) model for EEG-based emotion recognition, leveraging the abundance of unlabeled EEG data to generate clearer representations. The proposed SGCL extracts two frequency-domain features from the EEG signal, differential entropy (DE) and power spectral density (PSD), which are integrated through a symmetric similarity network fusion (SSNF) with graph contrastive learning (GCL) to improve the generalization and representation capability of the graph convolutional network (GCN) to complex EEG data in transductive learning tasks. Extensive experimental results on three public datasets reveal that the proposed SGCL consistently outperforms state-of-the-art models. Notably, on the Shanghai Jiao Tong University EEG Emotion dataset (SEED), SGCL achieves an average accuracy of 99.99% using only 3.5% of the data as labeled input, setting a new benchmark in both effectiveness and efficiency. Further analyses confirm our model learns highly discriminative representations and offers insightful explanations, demonstrating its potential for robust emotion recognition.},
  archive      = {J_EAAI},
  author       = {Dae Hyeon Kim and Young-Seok Choi},
  doi          = {10.1016/j.engappai.2025.111969},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111969},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised graph contrastive learning for emotion recognition based on electroencephalogram signals},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable automated wild-orchid identification combining deep neural networks and bayesian networks. <em>EAAI</em>, <em>161</em>, 111961. (<a href='https://doi.org/10.1016/j.engappai.2025.111961'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been shown repeatedly to be a successful method of obtaining accurate classifiers. This also applies to orchid identification from digital photographs. However, deep neural networks possess the major weakness of lack of explainability, missing the ability to explain the reasons behind a decision. Nevertheless, most current research regarding automated orchid identification applies this blackbox approach. By contrast, in this paper we propose a new method for trustworthy automated orchid identification combining two complementary methods: deep neural networks and feature-based Bayesian networks, where the Bayesian network is also utilized for providing an explanation of the generated solutions. We use other deep neural networks to extract flower characteristics, the features, from the images which are subsequently fed into the Bayesian network as uncertain evidence. When combining the deep neural network and the Bayesian network as an ensemble classifier, both reaching the same conclusion, an accuracy of 89.4% is achieved, the most trustworthy outcome. With a human-in-the-loop ensemble classifier, validation results are even better, yielding an accuracy of 98.1%. Our approach also exploits the taxonomic knowledge represented in the Bayesian network to provide an explanation of the solutions for every case, reinforcing further trust in the method. The result is an explainable user-in-the-loop ensemble classifier. Providing explainability can help build user trust in a system and may play a major role when it is used as a learning aid for new orchid enthusiasts. Finally, the proposed method may be also of value in many fields other than plant determination.},
  archive      = {J_EAAI},
  author       = {Diah Harnoni Apriyanti and Luuk J. Spreeuwers and Peter J.F. Lucas},
  doi          = {10.1016/j.engappai.2025.111961},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111961},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable automated wild-orchid identification combining deep neural networks and bayesian networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A safe multi-agent reinforcement learning algorithm using constraint update projection approach. <em>EAAI</em>, <em>161</em>, 111929. (<a href='https://doi.org/10.1016/j.engappai.2025.111929'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional reinforcement learning has a major limitation, which is that they optimize agent’s policy purely for maximizing rewards. It completely ignore safety considerations. However, in certain critical engineering fields, ensuring safety is of utmost importance, otherwise it can cause incalculable losses. Therefore, this paper proposes a safe Multi-Agent Constrained Update Projection(MACUP) algorithm, which can safely control agents to complete tasks. We solve this problem from the perspective of policy constraint optimization. Firstly, we derive the new bounds of multi-agent policy performance difference based on a tighter general policy performance difference. It contains generalized advantage estimates, and we utilize these bounds as surrogate functions concerning the objective and constraints. Secondly, to address the coordination issue among multiple agents, we employ a multi-agent sequential policy update framework. Finally, we use a projection method to optimize policies, which has low computational complexity and does not require convex approximation of the surrogate function for solving. It can help us reduce errors. Finally, we have validated our algorithm in two different multi-agent safety environments, and the results show that it is able to satisfy safety constraints while achieving higher rewards.},
  archive      = {J_EAAI},
  author       = {Yang Liu and Xiang Feng and Huiqun Yu},
  doi          = {10.1016/j.engappai.2025.111929},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111929},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A safe multi-agent reinforcement learning algorithm using constraint update projection approach},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-criteria group decision-making method using spherical fuzzy Z-numbers for smart technology revolution in municipal waste management. <em>EAAI</em>, <em>161</em>, 111928. (<a href='https://doi.org/10.1016/j.engappai.2025.111928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the new phenomenon of globalization and the fast growing cities, there is drastic pressure on the conventional methods of waste management hence the need for innovative management wastage that is proactive to the theme of environmental and economic challenge of the modern world. This paper aims at investigating the following research question: How has the introduction of smart technologies impacted waste management in the context of a mid-sized city that is in the cross-road of generating more wastes while at the same time, concerns over ecological attainability. They present a new type of Spherical Fuzzy Z-Number Sets in organizational environments dealing with multi criteria group decision making where it possess higher order of uncertainty than conventional fuzzy sets. For handling the multi facility nature of multi criteria group decision making in waste management, we propose the so-called Additive Ratio Assessment method when the attribute weights are unknown. To ensure that the criteria weights are determined objectively in this research, the CRITIC (CRiteria Importance Through Intercriteria Correlation) technique is used. The first part of the study provides a theoretical framework of spherical fuzzy Z-numbers concerning accuracy, scoring functions, and operations. Then we introduce this framework to actual multi criteria group decision making cases in municipal waste management to show that how Spherical Fuzzy Z-Number can facilitate decision-making processes by dealing with the vagueness and fuzziness of stakeholder preferences. The TODIM (Tomada de Decisao Iterativa Multicriterio) technique is used in this to validate and compare for efficiency of the proposed additive ratio assessment method. Besides, this research will not only enhance the theoretical aspect of fuzzy decision making but also present a feasible and effective framework for handling unsound and random decision making problems especially within the context of urban waste management.},
  archive      = {J_EAAI},
  author       = {Shahzaib Ashraf and Muhammad Naeem and Chiranjibe Jana and Maria Akram and Gerhard-Wilhelm Weber},
  doi          = {10.1016/j.engappai.2025.111928},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111928},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-criteria group decision-making method using spherical fuzzy Z-numbers for smart technology revolution in municipal waste management},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From image processing to artificial intelligence-driven tools: A comprehensive survey on the evolution of feature extraction methods in paintings. <em>EAAI</em>, <em>161</em>, 111794. (<a href='https://doi.org/10.1016/j.engappai.2025.111794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the computational process of converting qualitative elements of paintings, such as shape, color, texture, and line, into quantitative numerical values, which aid in identifying and extracting features from painting images. These identified features are then used to classify paintings based on artist, art style, genre, and art movements. This review employs a systematic literature review methodology, examining approximately 80 research papers to track trends in this field from 2015 to 2025. With the increasing presence of paintings in online media, museums, and galleries, artificial intelligence (AI) plays a significant role in interpreting these subjective elements. This review examines various image processing techniques in conjunction with AI implementations to extract the local and global features of a painting. These methods are combined with AI models, such as deep learning and computer vision algorithms, to improve feature extraction and provide a more thorough and accurate paintings analysis.},
  archive      = {J_EAAI},
  author       = {Rekha Sharma and Rishi Gupta and Aditya Sinha},
  doi          = {10.1016/j.engappai.2025.111794},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111794},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {From image processing to artificial intelligence-driven tools: A comprehensive survey on the evolution of feature extraction methods in paintings},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
