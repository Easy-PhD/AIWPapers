<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EAAI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eaai">EAAI - 512</h2>
<ul>
<li><details>
<summary>
(2025). Teach sample-specific knowledge: Separated distillation based on samples. <em>EAAI</em>, <em>162</em>, 112696. (<a href='https://doi.org/10.1016/j.engappai.2025.112696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in deep neural networks have revolutionized computer vision, enabling practical applications like classification and object detection. However, deploying these models on resource-constrained devices remains a critical challenge due to their high computational demands. Knowledge Distillation (KD) has emerged as an effective technique to address this issue by transferring knowledge from complex teacher models to lightweight student models, enhancing efficiency while maintaining high performance. Traditional logit-based KD methods use forward Kullback–Leibler divergence (FKLD) to transfer meaningful knowledge. However, FKLD typically exhibits a mode-averaging property, causing students to focus on non-target information, whether the teacher’s samples are correct or incorrect. Additionally, when handling uncertain samples, even teacher models may fail to classify them accurately, leading to incorrect predictions and confusing the students. To address these issues, we classify the dataset into two groups based on the teacher’s predictions: correct and incorrect samples. To ensure a more reliable transfer of knowledge from teacher to student for correct samples, we employ both forward Kullback–Leibler divergence (FKLD) and reverse Kullback–Leibler divergence (RKLD), which has mode-focusing properties. We also reduce temperature scaling for RKLD to enhance the focus on target information, ensuring that the student model prioritizes meaningful knowledge while minimizing the influence of non-target information. Conversely, for incorrect predictions, our method minimizes the teacher’s knowledge, encouraging students to rely more on the true labels by focusing on cross-entropy loss. Experimental results on both classification and object detection tasks demonstrate that our method, Teach Sample-Specific Knowledge (TSSK), outperforms state-of-the-art KD methods, making it ideal for deployment on-devices in real-world scenarios.},
  archive      = {J_EAAI},
  author       = {Seonghak Kim and Gyeongdo Ham and Suin Lee and Daeshik Kim},
  doi          = {10.1016/j.engappai.2025.112696},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112696},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Teach sample-specific knowledge: Separated distillation based on samples},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A context-adaptive and dual-dimensional collaboration method for infrared-visible image registration and fusion. <em>EAAI</em>, <em>162</em>, 112684. (<a href='https://doi.org/10.1016/j.engappai.2025.112684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image registration and fusion are tightly coupled tasks. However, in unregistered scenarios, prioritizing registration accuracy can compromise the integrity of complementary information, whereas enforcing fusion quality may disrupt geometric consistency. To address this, we propose a Context-Adaptive and Dual-Dimensional Collaboration Method for Infrared-Visible Image Registration and Fusion. Firstly, we design an adaptive context-aware channel fusion convolution module that simultaneously serves feature extraction for both registration and fusion tasks, perceiving contextual feature relationships to coordinate corresponding regions across modalities while dynamically generating task-adaptive feature representations. Secondly, we design a dual-dimensional dynamic collaboration module leveraging interactive mapping across spatial and channel dimensions to effectively fuse complementary cross-modal features while preserving detail and texture information. Finally, the registered and fused images are reconstructed by the spatial transformer network and lightweight decoder. Extensive tests on multiple datasets show that our method exhibits excellent performance in visual effects, quantitative metrics, and generalization ability, making it suitable for application scenarios such as security monitoring, fault detection, and target recognition.},
  archive      = {J_EAAI},
  author       = {Minghao Jiang and Shaoshu Gao and Xiaodong Zhang and Xingli Wang and Qing Hu and Weiming Wang},
  doi          = {10.1016/j.engappai.2025.112684},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112684},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A context-adaptive and dual-dimensional collaboration method for infrared-visible image registration and fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight vision mamba coding UNet for medical image segmentation. <em>EAAI</em>, <em>162</em>, 112676. (<a href='https://doi.org/10.1016/j.engappai.2025.112676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of medical images is vital for advancing research in medicine and supporting precise clinical diagnoses. Over the past few years, neural network-based methods have become a major focus of research and have been broadly adopted in medical image segmentation. However, mainstream methods like Transformer have excessive computational cost requirements, which makes them impractical for mobile medical applications. Therefore, this paper proposes a Lightweight Vision Mamba Coding UNet (LVMC-UNet), which integrates the Rotation-based Vision Mamba module (RVM) and Correlation Space Fusion module (CSF) in a lightweight manner. The RVM module processes the input images in parallel and introduces rotary positional encoding (RPE) on the Vision Mamba architecture to address the limitation of the Mamba module’s insufficient ability to capture local details. The CSF module integrates multi-stage and multi-scale feature maps and introduces blueprint separable convolutions (BSConvs) to enhance intra-kernel correlation. Comprehensive experiments on three datasets demonstrate that LVMC-UNet outperforms current lightweight segmentation methods and strikes a balance between segmentation accuracy and computational requirements.},
  archive      = {J_EAAI},
  author       = {Yuanyuan Li and Yifei Duan and Guanqiu Qi and Baisen Cong and Li Zhang and Zhiqin Zhu},
  doi          = {10.1016/j.engappai.2025.112676},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112676},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight vision mamba coding UNet for medical image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time design and implementation of intelligent drowsiness and fatigue recognition system for enhancing driver safety. <em>EAAI</em>, <em>162</em>, 112665. (<a href='https://doi.org/10.1016/j.engappai.2025.112665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the rise in personal vehicle usage for speed and convenience has increased road accidents, with driver fatigue as a major cause. Existing drowsiness detection systems suffer from high computational complexity and poor generalization across diverse conditions. To address these challenges, we propose an Intelligent Drowsiness and Fatigue Recognition (IDFR) System leveraging deep learning for real-time driver monitoring. Our system employs a customized Convolutional Neural Network (CNN) optimized for detecting eye states (open or closed) with high accuracy. A key feature is the use of the Eye Aspect Ratio (EAR) with a threshold of 0.2, empirically validated for precise drowsiness detection across varying lighting conditions and facial features. The system is trained on the Media Research Lab (MRL) Eye dataset, containing over 84,000 images, ensuring robust generalization across diverse demographics. The proposed IDFR system achieves 98.50 % accuracy, outperforming state-of-the-art deep learning models including Visual Geometry Group 16-layer network (VGG16), Visual Geometry Group 19-layer network (VGG19), Residual Network 152-layer (ResNet152), and Densely Connected Convolutional Network 201-layer (DenseNet201) in accuracy, precision, recall, and computational efficiency. By integrating transfer learning and fine-tuning techniques, we significantly reduce computational costs while maintaining high performance. The system was evaluated under challenging conditions, such as low lighting, high glare, and partial occlusion (e.g., sunglasses, shadows, and face coverings), ensuring robust detection accuracy. Our results demonstrate the IDFR system's potential for real-time in-vehicle deployment, providing immediate driver feedback and reducing accident risks. This work advances intelligent driver assistance technologies, enhancing road safety and future transportation systems.},
  archive      = {J_EAAI},
  author       = {Samy Abd El-Nabi and Khalil F. Ramadan and El-Sayed M. El-Rabaie and Ahmed Emam and Walid El-Shafai},
  doi          = {10.1016/j.engappai.2025.112665},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112665},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time design and implementation of intelligent drowsiness and fatigue recognition system for enhancing driver safety},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coupled fault diagnosis for centrifugal pumps through boruta-shap feature selection and rime-enhanced stacked denoised autoencoder. <em>EAAI</em>, <em>162</em>, 112659. (<a href='https://doi.org/10.1016/j.engappai.2025.112659'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the critical engineering challenges of diagnosing multi-condition cavitation and impeller erosion damage in deep sea centrifugal pumps, where traditional methods suffer from feature redundancy and poor generalization. An artificial intelligence (AI)-driven framework is proposed by integrating Boruta-Shap interpretable feature selection with a Rime-optimized Stacked Denoising Auto-Encoder (SDAE). Firstly, vibration signals undergo multi-domain feature extraction. The Boruta-Shap method quantifies feature interactions via Shapley values and shadow feature hypothesis testing, enabling physics-informed selection of cavitation energy indicators and impeller damage transient features, reducing feature dimensionality by approximately 70 %. Secondly, the Rime algorithm, inspired by ice-crystal growth dynamics, globally optimizes SDAE hyperparameters via balancing soft-rime exploration and hard-rime exploitation. Validated experimentally under variable conditions (0.8, 1.0 and 1.2 Q d ), the framework achieves 96 % testing accuracy, outperforming other diagnostic models, with reduced cross-condition misclassification. By bridging interpretable AI with multi-physics diagnostics, this work provides a replicable solution for predictive maintenance of energy infrastructure, advancing intelligent maintenance technologies for industrial systems facing complex hydrodynamic perturbations.},
  archive      = {J_EAAI},
  author       = {Kang Hu and Hui Sun and Wei Fan and Qiaorui Si and Yu Wu and Shouqi Yuan},
  doi          = {10.1016/j.engappai.2025.112659},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112659},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Coupled fault diagnosis for centrifugal pumps through boruta-shap feature selection and rime-enhanced stacked denoised autoencoder},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal interval prediction of carbon dioxide emissions from heavy construction machinery: A missing-data robust inverted-transformer model considering sensors failure in complex construction environment. <em>EAAI</em>, <em>162</em>, 112658. (<a href='https://doi.org/10.1016/j.engappai.2025.112658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of carbon dioxide (CO 2 ) emissions from heavy construction machinery in large-scale infrastructure projects presents a viable avenue for mitigating climate change. However, most current studies neglect the intricate operating conditions of such machinery. Moreover, in complex construction environments with high-frequency vibrations and heavy dust, sensor failures leading to random data loss significantly increase the difficulty of emission prediction. Especially when high-emission periods account for a small proportion, existing methods struggle to effectively capture CO 2 emission peaks. To address these challenges, this study proposes an improved Inverted-Transformer (iTransformer) multimodal interval prediction model for accurate CO 2 emission forecasting in heavy construction machinery under conditions of random sensor failures. The model incorporates a Mixture of Experts (MoE) mechanism within the iTransformer framework, which adaptively adjusts expert weights for missing modalities, thereby reducing prediction errors caused by random data loss. Additionally, to capture localized CO 2 emission peaks, this study introduces a Peak Capture Loss (PCL) function, which adjusts incremental emissions between adjacent time steps by supervising the differences between generated sequences, enabling the model to track abrupt emission variations. The Bootstrap method is also utilised to quantify and estimate uncertainty in the CO 2 emission Interval Prediction. Case studies reveal that the proposed model achieves high prediction accuracy (coefficient of determination ( R 2 ) = 0.99), especially across various data missing rates (5 %, 10 %, 15 %), with the average R 2 value increasing by approximately 6 %. This provides a novel approach for predicting emissions of heavy construction machinery in large-scale infrastructure projects.},
  archive      = {J_EAAI},
  author       = {Zhouquan Dong and Xiaoling Wang and Jun Zhang and Peng Yu and Zhijian Cai},
  doi          = {10.1016/j.engappai.2025.112658},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112658},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal interval prediction of carbon dioxide emissions from heavy construction machinery: A missing-data robust inverted-transformer model considering sensors failure in complex construction environment},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing wind power forecasting accuracy under extreme weather: Leveraging a dual-model approach with condition-based classification. <em>EAAI</em>, <em>162</em>, 112656. (<a href='https://doi.org/10.1016/j.engappai.2025.112656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind power forecasting is essential for grid stability, yet extreme weather events, exacerbated by climate change—pose challenges that current methods often overlook. In this study, we introduce a forecasting framework that accounts for extreme weather conditions to improve forecasting accuracy. First, we correct Numerical Weather Prediction (NWP) via temporal alignment and bias correction. Then, we address the differences in data distributions between typical and extreme weather conditions, while accounting for multivariate meteorological influences. We establish weather classification thresholds by integrating meteorological indicators (wind speed variation rate, precipitation, snowfall) with a data-driven sensitivity analysis, and optimize them via grid search to maximize the coefficient of determination ( R 2 ) while balancing false alarms and detection rates. Finally, due to the difference in distribution and data pattern, we implemented distinct forecasting models for each condition. A Convolutional Neural Network (CNN) models normal conditions by capturing temporal dependencies, while Light Gradient Boosting Machine (LightGBM) handles sparse extreme-weather samples. Compared to models that ignore extreme weather, our approach reduces Mean Absolute Error (MAE) by 21.13% and Root Mean Squared Error (RMSE) by 9.29%. Under extreme conditions, Mean Absolute Percentage Error (MAPE) is reduced by 32.76%, demonstrating enhanced robustness in handling extreme weather scenarios.},
  archive      = {J_EAAI},
  author       = {Weimin Yuan and Han Yang and Zhu Han and Yanru Zhang},
  doi          = {10.1016/j.engappai.2025.112656},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112656},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing wind power forecasting accuracy under extreme weather: Leveraging a dual-model approach with condition-based classification},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating multimodal biophysical features with hybrid deep learning for ribonucleic acid secondary structure prediction. <em>EAAI</em>, <em>162</em>, 112648. (<a href='https://doi.org/10.1016/j.engappai.2025.112648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The secondary structure of ribonucleic acid (RNA) is pivotal for elucidating its functional roles. However, existing deep learning models predominantly rely on single-feature representations, which restricts their capacity to sufficiently capture the intricate information embedded in RNA sequences. To solve this problem, we propose a novel RNA secondary structure prediction method based on multimodal feature fusion and hybrid deep learning. By integrating multiple features of RNA are modeled to achieve the synergistic effect of the chemical microenvironment, local physical constraints and long-range interactions. We conceptualize RNA structure as an image and treat various RNA features as distinct channels of that image. To facilitate the transformation from RNA sequences to RNA images, we design a hybrid neural network architecture. Specifically, the sequence feature extraction module first extracts features directly from the RNA sequence. These features are then passed to the image feature extraction module, which focuses on capturing effective structural information from the multichannel RNA image, thereby enhancing the accuracy of RNA secondary-structure prediction. Experimental results indicate that our method achieves state-of-the-art performance compared with recent deep learning methods across several benchmark datasets and demonstrates potential in drug discovery applications.},
  archive      = {J_EAAI},
  author       = {Xiao Wang and Yongfeng Zhang and Lixiang Yang and Rong Wang},
  doi          = {10.1016/j.engappai.2025.112648},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112648},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrating multimodal biophysical features with hybrid deep learning for ribonucleic acid secondary structure prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometry-informed multimodal fusion network for enhancing high-density spatial transcriptomics from histology images. <em>EAAI</em>, <em>162</em>, 112647. (<a href='https://doi.org/10.1016/j.engappai.2025.112647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial transcriptomics (ST) is a revolutionary technology that combines spatial information with gene expression analysis, opening up new perspectives for studying the spatial distribution of genes within tissues and their regulatory mechanisms. However, it is limited by the sparsity of sequencing spots and the high cost of ST technology, which hinders its widespread application in biomedical research. An alternative and more cost-effective strategy is to leverage deep learning methods to infer high-density gene expression profiles from histological images. To this end, we developed the HisHRST (Histology-based High-Resolution Spatial Transcriptomics) method based on an offline pathological image foundation model, aiming to accurately generate high-density ST data from histological images using a geometry-guided multimodal fusion network with spatial coordinates. This method employs a multi-head attention mechanism to incorporate spatial location information, thereby enhancing feature representation. We systematically evaluated HisHRST on seven ST datasets and compared its performance with five existing methods. Experimental results demonstrate that HisHRST can accurately predict gene expression profiles for unmeasured spots, refine gene expression patterns, and effectively preserve the original spatial structure of gene expression. Furthermore, this method facilitates the identification of biologically meaningful pathways, thereby advancing the understanding of key biological processes. All code and public datasets used in this paper are available at https://github.com/wenwenmin/HisHRST and https://zenodo.org/records/15129356 .},
  archive      = {J_EAAI},
  author       = {Zhiceng Shi and Shuailin Xue and Wenwen Min},
  doi          = {10.1016/j.engappai.2025.112647},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112647},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Geometry-informed multimodal fusion network for enhancing high-density spatial transcriptomics from histology images},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State-of-the-art of machine learning methods for fault detection and health monitoring of wind turbine system components: A comprehensive review. <em>EAAI</em>, <em>162</em>, 112645. (<a href='https://doi.org/10.1016/j.engappai.2025.112645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the world shifts from fossil fuels to sustainable energy sources, wind energy has become an increasingly important part of the global renewable energy mix. However, maintaining the efficient operation of wind turbines remains challenging. This review presents, discusses and extracts the major trends of advancements in artificial intelligence and their application in engineering solutions for diagnosing faults in wind turbine systems. It begins with an analysis of the benefits and limitations of different generator types used in wind power generation. Next, it identifies the most frequently failing components, including power converters, generators (with rotor), sensors, gearboxes and drivetrain. Furthermore, it provides an exhaustive overview of machine learning (ML) techniques, including advanced methodologies such as attention mechanisms and ensemble learning frameworks, for wind turbine fault detection and health monitoring. This review aims to show the current trends and future research directions of machine learning applications to improve the reliability, efficiency, and sustainability of wind turbine operations. It provides valuable insights for researchers, engineers, and decision-makers in the wind energy sector, helping them select suitable ML approaches and refine existing wind turbine operational strategies. It also enables us to measure the challenges that remain towards achieving highly efficient operation of wind turbines.},
  archive      = {J_EAAI},
  author       = {Abebe Wolie Yimam and Majid Vafaeipour and Maarten Messagie and Kinde Anlay Fante and Emiyamrew Minaye Molla and Tefera Mekonnen Azerefegn and Thierry Coosemans},
  doi          = {10.1016/j.engappai.2025.112645},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112645},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {State-of-the-art of machine learning methods for fault detection and health monitoring of wind turbine system components: A comprehensive review},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Removal of cationic dyes from aqueous solutions using agricultural waste: Modeling the biosorption process with semantic immune plasma programming. <em>EAAI</em>, <em>162</em>, 112640. (<a href='https://doi.org/10.1016/j.engappai.2025.112640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the use of celery stalks, a low-cost agricultural waste, as biosorbent for removing crystal violet (CV), a toxic cationic dye, from aqueous solutions. The biosorption process was experimentally examined under varying conditions of potential of hydrogen (pH), contact time, biosorbent dose, initial dye concentration, and temperature. To model the relationship between these input parameters and biosorption performance, we employed symbolic regression using four automatic programming (AP) methods: Genetic Programming (GP), Artificial Bee Colony Programming (ABCP), Immune Plasma Programming (IPP), and a newly proposed semantic IPP (sIPP), which introduces a semantic-based crossover operator. The novelty of the study lies in combining agricultural waste-based biosorption with interpretable Artificial Intelligence (AI), enabling both accurate prediction and transparent understanding of the system. Experimental results revealed the presence of chemisorption in the spontaneous and endothermic biosorption process, with a maximum biosorption efficiency of 90% and a biosorption capacity of 6.9 mg/g. Among the symbolic models, sIPP achieved the highest test accuracy ( R Test 2 = 0 . 99 for capacity, 0.98 for efficiency), while also generating the simplest trees (approximate mean values: 91 and 99 nodes). This confirms sIPP’s strength in balancing predictive accuracy with model transparency. The proposed framework demonstrates strong potential for sustainable and explainable modeling in environmental engineering applications.},
  archive      = {J_EAAI},
  author       = {Nurşah Kütük and Sibel Arslan},
  doi          = {10.1016/j.engappai.2025.112640},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112640},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Removal of cationic dyes from aqueous solutions using agricultural waste: Modeling the biosorption process with semantic immune plasma programming},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-enhanced fault hierarchical perception for dissolved gas analysis in power transformer. <em>EAAI</em>, <em>162</em>, 112639. (<a href='https://doi.org/10.1016/j.engappai.2025.112639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dissolved Gas Analysis (DGA) is a widely used technique for diagnosing power transformer faults by monitoring the gas content in transformer oil to identify potential issues. However, existing research often treats dissolved gas samples as loosely connected independent entities, failing to explicitly model the relationships between them. Moreover, the similarity between faults caused by different factors can sometimes be higher than that between faults caused by the same factor, highlighting the need for hierarchical modeling of fault relationships to improve diagnostic performance. To address these challenges, we propose a graph-enhanced fault hierarchical perception model for DGA. In this work, a K -Nearest Neighbors ( K NN) graph is constructed by calculating the similarity between DGA samples in the transformer oil to capture potential associations between samples. To further enhance the learning of sample representations, we generate two augmented views by randomly perturbing node features and edges to capture information about different local structures in the graph. Additionally, we introduce a consistency constraint to ensure that the prediction results from the two augmented views remain consistent. Furthermore, we design a hierarchical perception-based ranking strategy that ranks fault similarities at a fine-grained level, effectively utilizing hierarchical fault information to optimize the model. Extensive experimental results demonstrate that the proposed model achieves high accuracy and strong generalization performance in fault-type prediction.},
  archive      = {J_EAAI},
  author       = {Yingyue Zhang and Huifang Ma and Yuwei Gao and Shengjiang Peng and Ruijia Zhang},
  doi          = {10.1016/j.engappai.2025.112639},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112639},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph-enhanced fault hierarchical perception for dissolved gas analysis in power transformer},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Full autonomy in underwater robotics systems: A realistic prospect?. <em>EAAI</em>, <em>162</em>, 112638. (<a href='https://doi.org/10.1016/j.engappai.2025.112638'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous Underwater Systems (AUS) are transforming underwater exploration, environmental monitoring, and subsea operations by reducing reliance on human intervention. This review explores the advancements and challenges in achieving full operational autonomy in AUS, focusing on navigation, perception, communication, energy management, control systems, and decision-making frameworks. Current systems predominantly exhibit partial autonomy, performing pre-defined missions with limited adaptability. However, advancements in hybrid localisation techniques, multi-modal sensor fusion, and Artificial Intelligence (AI)-driven decision-making are pushing the boundaries of autonomy, enabling AUS to adapt dynamically to complex underwater environments. The integration of subsystems remains a central challenge. Navigation systems address positional drift through cooperative approaches, while perception systems enhance environmental understanding via sensor fusion. Communication technologies, although constrained by underwater limitations, are advancing through hybrid protocols that strike a balance between bandwidth and range. Energy management is evolving with innovations in battery technology, energy harvesting, and predictive resource allocation. Control systems, increasingly incorporating AI-based frameworks, translate mission commands into precise actions, bridging the gap between decision-making and physical execution. Decision-making frameworks synthesise inputs from all subsystems, enabling real-time prioritisation and adaptive behaviour. Despite significant progress, achieving full autonomy requires further innovation in subsystem integration, real-time processing, and environmental adaptability. This review emphasises the need for modular architectures and standardised protocols to ensure interoperability and scalability. The potential of fully autonomous underwater systems extends beyond technical achievements, offering profound implications for ocean exploration, resource sustainability, and environmental stewardship. The question posed – Full Autonomy in Underwater Systems: A Realistic Prospect? – is addressed with cautious optimism. While partial autonomy is well within reach, achieving full autonomy depends on sustained innovation across multiple domains. This manuscript provides a comprehensive roadmap for advancing AUS, laying the foundation for transformative advancements in one of Earth’s least understood frontiers.},
  archive      = {J_EAAI},
  author       = {Ali Rohan and Hamidreza Farhadi Tolie and Md Junayed Hasan and Somasundar Kannan},
  doi          = {10.1016/j.engappai.2025.112638},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112638},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Full autonomy in underwater robotics systems: A realistic prospect?},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and implementation of deep learning-based framework for multi-class fault diagnosis in complex chemical process systems. <em>EAAI</em>, <em>162</em>, 112630. (<a href='https://doi.org/10.1016/j.engappai.2025.112630'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis in modern chemical plants is increasingly challenging due to process complexity, nonlinearity, and high-risk operations, where undetected faults can cause severe safety and economic consequences. Conventional machine learning (ML) models suffer from reliance on handcrafted features, poor generalization in high-dimensional spaces, and limited labeled data, resulting in reduced diagnostic performance. To overcome these challenges, we propose a scalable deep learning (DL) framework for multi-class fault diagnosis in chemical processes. The framework employs convolutional neural networks (CNN), autoencoders (AE), and long short-term memory (LSTM) networks to automatically extract spatial and temporal features from multivariate process data. Validated on the Tennessee Eastman process (TEP) benchmark, CNN achieved the highest diagnostic performance, with 88 % accuracy, 91 % precision, and 89 % F1-score. AE also performed strongly, with 85 % accuracy and 82 % F1-score, while LSTM achieved 71 % accuracy and 75 % F1-score, all outperforming conventional machine learning models, which scored between 48 % and 52 % accuracy. Superior AUC scores (micro-average: 1.00; macro-average: 0.99) confirm the framework's robustness, including in detecting overlapping and rare faults. The proposed two-phase approach, offline training and real-time monitoring, offers a practical solution for improving fault diagnosis accuracy, adaptability, and early warning capabilities in industrial processes.},
  archive      = {J_EAAI},
  author       = {Remigius Nnadozie Ewuzie and Shivaneswar Gunasekaran and Zainal Ahmad and Norazwan Md Nor},
  doi          = {10.1016/j.engappai.2025.112630},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112630},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design and implementation of deep learning-based framework for multi-class fault diagnosis in complex chemical process systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network approach on forecasting the engine emission using biodiesel fuel from fish oil based on injection pressure and engine operating parameters. <em>EAAI</em>, <em>162</em>, 112628. (<a href='https://doi.org/10.1016/j.engappai.2025.112628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the influence of injection pressure on the performance and emission characteristics of a diesel engine fueled with biodiesel derived from basa fish oil blended with conventional diesel (B10, B20, and B30). Experiments were performed at injection pressures ranging from 400 to 800 bar, with 600 bar as the baseline, on an engine operating at 1400 revolutions per minute (rpm). The results indicated that reducing the injection pressure to 500 bar increased emissions of carbon monoxide (CO), hydrocarbons (HC), and smoke, while nitrogen oxides (NOx) emissions decreased. At 500 bar compared to 600 bar, CO, HC, and smoke rose by up to 23.4 %, 10.0 %, and 32.0 %, respectively, whereas NOx decreased by up to 9.1 %. Conversely, at 700 bar, CO, HC, and smoke emissions decreased by up to 20.3 %, 6.7 %, and 28.4 %, while NOx increased by up to 12.7 %. Furthermore, an exhaust emission prediction model was developed using an Artificial Neural Network (ANN) based on injection pressure and engine operating parameters. The ANN model achieved high predictive accuracy, with the coefficient of determination (R 2 ) exceeding 0.995 and root mean square error (RMSE) values as low as 0.49975 % for smoke. These findings demonstrate that injection pressure significantly affects emission trade-offs in diesel engines operating with biodiesel blends. In addition, the ANN model proves to be a reliable tool for predicting and controlling engine emissions, supporting the potential of biodiesel as a sustainable alternative fuel.},
  archive      = {J_EAAI},
  author       = {Nguyen Van Tuan and Nguyen Xuan Khoa and Nguyen Tuan Nghia},
  doi          = {10.1016/j.engappai.2025.112628},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112628},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A neural network approach on forecasting the engine emission using biodiesel fuel from fish oil based on injection pressure and engine operating parameters},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy decision-making method for unloading command at crushing stations based on deep learning and dynamic coal flow features slicing. <em>EAAI</em>, <em>162</em>, 112617. (<a href='https://doi.org/10.1016/j.engappai.2025.112617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contemporary world hosts numerous open-pit coal mines, as mining efficiency increases, the unloading process of the crushing station still relies on manual command. Adversely affected by the harsh production environment and the high-intensity fatigue of operators, incorrect unloading commands can lead to issues, such as blockages at the receiver bin discharge outlet and coal swelling in the crushing chamber, resulting in production accidents. To address this issue, this study analyzes the dynamic characteristics of the coal flow in the receiver bin, in addition, monitors the bin status in real time through the camera, combining a lightweight selective kernel network (Li-SKNet) with the average classification confidence from a small segment of consecutive video frames to assess the suitability of unloading conditions. By introducing a convolutional kernel attention mechanism, the model achieved a classification accuracy of 99.8 %, subsequently, in order to adapt to the changes in the working conditions of the crushing station, a segmented fuzzy function is proposed to further optimize the model inference results. Finally, an intelligent unloading command system for the crushing station is established, which has been put into production and operated stably for six months. In comparison to traditional manual commanding methods for unloading, the system has approximately demonstrated a 15 % increase in production efficiency.},
  archive      = {J_EAAI},
  author       = {Tongyu Cui and Yongtai Pan and Yankun Bi and Zhen Liu and Jiacheng Huang and Bingjia Liu},
  doi          = {10.1016/j.engappai.2025.112617},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112617},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fuzzy decision-making method for unloading command at crushing stations based on deep learning and dynamic coal flow features slicing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting the cyclic behavior and strength-weakening effect of saturated clays using artificial neural network. <em>EAAI</em>, <em>162</em>, 112616. (<a href='https://doi.org/10.1016/j.engappai.2025.112616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cyclic behavior of soft cohesive soils under shear loads is characterized by progressively increasing strain and by the growth of the pore pressure that can lead to an effective stress reduction and, eventually, to the sudden failure of the soil, both risks with evident engineering safety implications. Although this problem has received much attention in research, most present approaches can only predict some parameters of the clay performance separately, commonly leading to highly complex approaches requiring extensive training and expertise. The present research uses an Artificial Neural Network (ANN) and machine learning to predict the cyclic behavior of the soft clays in the investigated site, considering for the first time all the relevant parameters that characterize the problem. The proposed ANN includes 9 inputs, two hidden layers with 10 neurons each, and five outputs. Nine inputs include the vertical effective consolidation pressure, parameters from the monotonic shear test, and defined input variables from the cyclic simple shear test. As outputs, the net considers five different results, including the various parameters of the shear strain response for each cycle, the maximum number of cycles, and the pore pressure increase. The resulting ANN shows predictions with high accuracy, with R = 0.995, and individual errors below 10 % in most cases. No prior training or experience is required to use the ANN, and it can be confidently used as an alternative to other analytical and numerical approaches for analyzing clay cyclic behavior, as long as the input values fall within the defined ranges.},
  archive      = {J_EAAI},
  author       = {M.A. Millán and R. Galindo and A. Viana da Fonseca and H. Patiño},
  doi          = {10.1016/j.engappai.2025.112616},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112616},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting the cyclic behavior and strength-weakening effect of saturated clays using artificial neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic co-evolution with neural networks for evolutionary optimization. <em>EAAI</em>, <em>162</em>, 112614. (<a href='https://doi.org/10.1016/j.engappai.2025.112614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary computation (EC) algorithms, which simulate natural selection and genetic mechanisms, are widely applied to solve complex optimization and search problems. During the evolutionary process, EC algorithms inherently generate a wealth of evolutionary data. However, conventional EC algorithms often fail to effectively utilize this data, limiting their optimization effectiveness and overall performance. Neural networks, known for their powerful learning capabilities, excel in extracting features and recognizing patterns within large datasets. They can automatically identify complex relationships through their hierarchical architectures. Inspired by this, we propose a neural-synergized co-evolutionary optimization (NSCO) framework that integrates neural networks to learn from successfully evolved individuals during the EC process. This approach extracts valuable evolutionary knowledge to guide algorithms toward improved solutions and higher-quality data. Additionally, the enhanced data enables neural networks to derive richer evolutionary insights, creating a positive feedback loop that consistently improves performance. Notably, this framework operates without the need for additional expert knowledge, relying solely on the data generated by the algorithms themselves. To validate its effectiveness, we integrate this framework with 10 distinct EC algorithms and evaluate its performance using the CEC2014 benchmark suite. Results demonstrate significant enhancements in the algorithms’ performance.},
  archive      = {J_EAAI},
  author       = {Kun Bian and Juntao Zhang and Hong Han and You Zhou and Yifei Sun and Shi Cheng and Jun Zhou},
  doi          = {10.1016/j.engappai.2025.112614},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112614},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synergistic co-evolution with neural networks for evolutionary optimization},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of environmental emergency treatment technologies using the interval pythagorean neutrosophic set. <em>EAAI</em>, <em>162</em>, 112611. (<a href='https://doi.org/10.1016/j.engappai.2025.112611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the problem of environmental pollution is severe both domestically and internationally, hindering social development. Therefore, strengthening environmental protection and improving the ability to manage environmental emergencies are urgently needed. Based on this situation, this paper proposes an evaluation model for environmental emergency treatment techniques (EETTs) using the interval Pythagorean neutrosophic (IPN) set for the first time. First, the IPN is introduced, and the operating rules and fractional/exact functions of IPN numbers are defined. Second, to apply IPN numbers to multi-attribute decision-making, two types of aggregation operators (IPN weighted arithmetic average (IPNWAA) operator and IPN weighted geometric average (IPNWGA) operator) are proposed. Finally, the evaluation index system and model for EETTs are constructed, and the rationality of the model is verified through an example involving computer data processing. According to the evaluation results, enterprises can identify their strengths and weaknesses in coping with environmental emergency treatment and take corresponding corrective measures in time to improve their emergency treatment capabilities. Therefore, this study has important scientific value and practical significance.},
  archive      = {J_EAAI},
  author       = {Changxing Fan},
  doi          = {10.1016/j.engappai.2025.112611},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112611},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluation of environmental emergency treatment technologies using the interval pythagorean neutrosophic set},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic consensus-based decentralized method for multiple unmanned aerial vehicles cooperative target allocation. <em>EAAI</em>, <em>162</em>, 112609. (<a href='https://doi.org/10.1016/j.engappai.2025.112609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates multiple unmanned aerial vehicles dynamic target allocation problem with capability-requirement matching constraints. The objective is to achieve conflict-free allocation through distributed collaboration under a dynamic environment. To address this problem, we propose a decentralized method named Dynamic Consensus-Based Group Algorithm (DCBGA). This algorithm utilizes a rule-based method known as State-Event-Condition-Action (SECA) as the decision-making framework. In addition, this algorithm consists of iterations between two phases: target selection and conflict resolution. In the target selection phase, each unmanned aerial vehicle (UAV) selects targets in a market-based method and follows the principle of “capability-requirement matching”. In the conflict resolution phase, a consensus-based mechanism is designed so that each UAV communicates with its neighbors to generate a conflict-free allocation result. In the simulation section, this paper performs convergence analysis, sensitivity analysis, and optimization comparisons. The simulation results confirm both the convergence and robustness of the DCBGA. Furthermore, the comparison results demonstrate that the proposed algorithm exhibits better optimization performance than other advanced algorithms.},
  archive      = {J_EAAI},
  author       = {Han Wang and Xiaolong Liang and Jiaqiang Zhang and Aiwu Yang},
  doi          = {10.1016/j.engappai.2025.112609},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112609},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamic consensus-based decentralized method for multiple unmanned aerial vehicles cooperative target allocation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biological visual-cognition-inspired deep network for short-term significant wave height prediction. <em>EAAI</em>, <em>162</em>, 112607. (<a href='https://doi.org/10.1016/j.engappai.2025.112607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of Significant Wave Height (SWH) is essential to optimize wave energy conversion efficiency. However, ocean waves' stochastic and nonlinear characteristics make traditional models face the challenges of insufficient accuracy and limited interpretability. In this paper, we propose a deep network based on a biological visual cognitive mechanism, which significantly improves the short-term SWH prediction performance inspired by the functional principles of the human visual system's hierarchical perception, hemispheric collaboration and attentional decision-making mechanism. The model consists of three components: (1) a visual-spatial pyramid component, which gradually extracts local to global features through a multi-scale convolutional kernel; (2) a brain analysis component, which combines gated recurrent unit (GRU) and convolutional neural network (CNN) to capture spatiotemporal dependencies and enhance the stability through residual connectivity, respectively; and (3) an attention-driven prediction component, which dynamically filters the key features to improve the prediction accuracy. Experiments based on two real-world buoy sites show that the proposed method reduces the mean absolute percentage error (MAPE) to 5.56 % and 6.30 %, respectively. The energy capture error (ΔP) is reduced to 10.93 % and 13.02 %, respectively, and remains robust under extreme sea states. This work can effectively improve the prediction accuracy and operational reliability of industrial ocean energy systems under complex ocean conditions.},
  archive      = {J_EAAI},
  author       = {Liao Fang and Weimin Wu and Feifei Cao and Zhenguan Cao and Guodong Fan and Lin Cui and Frede Blaabjerg},
  doi          = {10.1016/j.engappai.2025.112607},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112607},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Biological visual-cognition-inspired deep network for short-term significant wave height prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-based video interpolation via complementary motion information. <em>EAAI</em>, <em>162</em>, 112606. (<a href='https://doi.org/10.1016/j.engappai.2025.112606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video frame interpolation, the task of synthesizing intermediate frames to increase temporal resolution, often struggles with complex scenarios when constrained by the assumption of linear motion The advent of event cameras has led to significant progress in addressing this issue. Event cameras, with microsecond-level temporal resolution, bridge the gap between frames by providing accurate motion cues. However, current event-based video frame interpolation methods often overlook that event data primarily offers high-confidence features at scene edges during multi-modal feature fusion, which may limit the contribution of event signals to optical flow estimation. To address this, we propose a novel end-to-end learning framework that explicitly leverages the complementary characteristics of event signals and frames. Our method synergistically fuses dense contextual information from frames with sparse but precise edge motion from events via a proposed Edge Guided Attention (EGA) module. The EGA employs a coarse-to-fine strategy, where event-based optical flow directly refines the frame-based motion estimation at each level of a pyramidal architecture. Additionally, we introduce an event-based visibility map, co-learned within our event-processing network, to adaptively mitigate occlusions during the warping process. Extensive experiments conducted on a diverse suite of six benchmarks, including four synthetic and two real-world datasets validate the effectiveness of this novel approach. A dedicated discussion of the method’s trade-offs and potential limitations is presented in the Limitations section.},
  archive      = {J_EAAI},
  author       = {Yuhan Liu and Linghui Fu and Hao Chen and Zhen Yang and Youfu Li and Yongjian Deng},
  doi          = {10.1016/j.engappai.2025.112606},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112606},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Event-based video interpolation via complementary motion information},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time dynamic coordinated optimization control with near-global optimal learning for connected plug-in hybrid electric vehicles. <em>EAAI</em>, <em>162</em>, 112602. (<a href='https://doi.org/10.1016/j.engappai.2025.112602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the application of connected technologies, such as vehicle-to-vehicle and vehicle-to-cloud communication in connected vehicles to obtain various traffic information, it is crucial to balance the optimality and computational burden of the energy management strategy for further improving the fuel economy of the connected plug-in hybrid electric vehicle. Another key factor affecting the improvement of fuel economy and control performance in connected plug-in hybrid electric vehicles is the fluctuation in driving torque resulting from the different response characteristics of the engine and motor during mode switching of the powertrain for the power distribution of the energy management strategy. To address these challenges, this paper proposes a novel real-time dynamic coordinated optimization control scheme that incorporates energy management at the upper layer and adaptive coordination at the lower layer for the connected plug-in hybrid electric vehicle in a vehicle-following scenario. Based on the offline optimal control rules extracted by the extreme learning machine, which possesses good generalization capabilities, the upper-layer guided model predictive control for energy management is implemented by applying the particle swarm optimization algorithm within variable horizons across different road sections. The bottom-layer adaptive fixed-time control scheme, equipped with a coordinated mechanism, is designed to address transient response deviations in the upper-layer results. The effectiveness and advantages of the proposed hierarchical scheme are validated through both the co-simulation platform and a hardware-in-loop test.},
  archive      = {J_EAAI},
  author       = {Jiaqi Xue and Chao Yang and Jiayi Fang and Xiao Zhang and Muyao Wang},
  doi          = {10.1016/j.engappai.2025.112602},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112602},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time dynamic coordinated optimization control with near-global optimal learning for connected plug-in hybrid electric vehicles},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multichannel framework for multitask learning fusion in modulation recognition tasks. <em>EAAI</em>, <em>162</em>, 112601. (<a href='https://doi.org/10.1016/j.engappai.2025.112601'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic modulation recognition is an essential process linking signal detection to signal demodulation, and it is a promising technology for improving spectrum usage efficiency in cognitive radio. With the advent of fifth generation mobile communication technology, wireless communication systems have had massive data throughput. As a result, integrating artificial intelligence techniques with modulation recognition has emerged as a key focus area in the communication sector. To enhance the precision of signal modulation recognition, this study proposes a multitask learning fusion multichannel network modulation recognition framework—Multitask Residual Convolution Long Short Memory-Transformer Deep Neural Network. The primary task network is a two stream network composed of Convolutional Neural Network module, Long Short-Term Memory module and Transformer-Encoder module, allowing for the simultaneous extraction of both time and frequency features from the signal. The auxiliary task network is composed of residual convolution module paired with Transformer-Encoder module, designed for extracting the power spectral density characteristics of straightforward signals. Ultimately, the features derived from both the primary task network and the auxiliary task network are combined. The auxiliary network enhances the primary task network’s ability to characterize features, thereby boosting the neural network’s overall versatility and precision. The experimental findings indicate that the proposed model achieved peak recognition accuracies of 99.73%, 93.9%, and 94.1% on the three datasets, respectively. Moreover, the recognition accuracy of the proposed model is better than the baseline model in the low Signal-to-Noise Ratio environment (-18 decibel ∼ 0 decibel).},
  archive      = {J_EAAI},
  author       = {Wenshi Xiao and Zhongqiang Luo and Mengxuan Lan},
  doi          = {10.1016/j.engappai.2025.112601},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112601},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multichannel framework for multitask learning fusion in modulation recognition tasks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficiency prediction of fluid machinery based on knowledge-aided ensemble learning. <em>EAAI</em>, <em>162</em>, 112600. (<a href='https://doi.org/10.1016/j.engappai.2025.112600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluid machinery is a type of high-energy-consumption equipment. Accurate prediction of energy efficiency enables the optimization of energy management and enhances equipment performance. However, factors such as equipment aging, sensor anomalies, and complex interferences pose challenges to accurately predicting energy efficiency solely through knowledge-based models or machine learning approaches. To address this issue, a fluid machinery energy efficiency prediction method based on knowledge-aided ensemble learning is proposed by integrating mechanistic knowledge and machine learning. During data repair, the physical characteristics of fluid machinery are used to identify condition anomalies, and a sliding window-based Local Outlier Factor (WLOF) algorithm is designed to identify other types of anomalies. Different types of anomalies are repaired using mechanistic knowledge and eXtreme Gradient Boosting (XGBoost), respectively. The preprocessed data is subsequently employed to train models for energy efficiency prediction. This method has been applied to predict the energy efficiency of fans in a large-scale steel plant. Compared with various energy efficiency prediction models, the application results show that the prediction based on Knowledge-WLOF-XGBoost exhibits higher accuracy and robustness than single physical models or machine learning models.},
  archive      = {J_EAAI},
  author       = {Weijian Kong and Rong Zhuo and Linfu Zheng},
  doi          = {10.1016/j.engappai.2025.112600},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112600},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Energy-efficiency prediction of fluid machinery based on knowledge-aided ensemble learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pretrained transformers for multimodal fake news detection: Explainability using SHapley additive exPlanations for contributions from text, image, and image captions. <em>EAAI</em>, <em>162</em>, 112590. (<a href='https://doi.org/10.1016/j.engappai.2025.112590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wide use of Online Social Networks (OSNs) for news consumption necessitates the identification and flagging of fake news to reduce its negative impacts. Existing research mostly emphasizes deep learning techniques that examine textual features or combinations of text and images for the detection of fake news. In this study, we propose two enhanced models for fake news detection. First, we present a multimodal framework that leverages Vision Transformer embeddings for image representation instead of traditional Convolutional Neural Network (CNN) features, which achieves significant improvements over baseline approaches. Second, we implemented an image caption-augmented multimodal model that integrates image captions as an additional modality alongside text and images. Caption embeddings act as semantic bridges that strengthen cross-modal alignment and contextual understanding. The experiments conducted on the FakeNewsNet and Fakeddit datasets show that the model incorporating image captions consistently surpasses the baseline BERT-VIT framework. It achieves improvements of up to +7.9% in accuracy, +11.5% in precision, and +5.3% in the F1-score, while still maintaining competitive levels of recall and Area Under the Curve (AUC). Statistical significance testing verifies the reliability of these enhancements. Additionally, a SHapley Additive exPlanations (SHAP)-based analysis highlights the contribution of each modality, which enhances the interpretability of the proposed framework.},
  archive      = {J_EAAI},
  author       = {Athira A.B. and S.D. Madhu Kumar and Anu Mary Chacko},
  doi          = {10.1016/j.engappai.2025.112590},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112590},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pretrained transformers for multimodal fake news detection: Explainability using SHapley additive exPlanations for contributions from text, image, and image captions},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the morphological quality of zizania latifolia shoot based on instance segmentation. <em>EAAI</em>, <em>162</em>, 112589. (<a href='https://doi.org/10.1016/j.engappai.2025.112589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The breeding of Zizania latifolia primarily relies on the cross-regional introduction of varieties and manual selection, which involves the assessment of morphological quality. Traditional methods are time-consuming and labor-intensive. This paper proposed a morphological assessment method based on instance segmentation. Assessment indicators, including enlargement degree, color, straightness, and slenderness, were defined according to national grading standards and expert knowledge to provide a comprehensive assessment framework. For the segmentation task, the irregular contours, similar internal regions, and indistinct boundaries pose significant challenges. Additionally, classification heavily relies on the spatial relationships. To solve these problems, this study proposed a sub-stem segmentation algorithm, which based on You Only Look Once Version 8 (YOLOv8). The Linear Deformable Convolution (LDConv) module was employed to recognize irregular sub-stems through learnable offsets. Next, the Efficient Multi-Scale Attention (EMA) mechanism was added to refine image features by emphasizing the interactions between channels and spatial dimensions. We also employed the Wise Intersection over Union Version 3 (WIoU v3) loss function, which evaluated the anchor box quality based on outlier degree. The proposed model outperformed YOLOv8 and other state-of-the-art models on the Zizania latifolia dataset, achieving Precision, Recall, and mean Average Precision (mAP) values of 95.3 %, 93.9 %, and 97.7 %. Additionally, our model achieved 35.7 % mAP on the Microsoft Common Objects in COntext (MS COCO) dataset. Based on the segmentation results, we extracted phenotypic parameters, such as height, width, and two-dimensional area. We determined the top-10 individuals with superior morphological quality among 65 varieties, providing robust support for Zizania latifolia breeding.},
  archive      = {J_EAAI},
  author       = {Chenmin Yang and Shanyong Wang and Tingting Lou and Ruiqi Song and Huanliang Xu and Zhaoyu Zhai},
  doi          = {10.1016/j.engappai.2025.112589},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112589},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Assessing the morphological quality of zizania latifolia shoot based on instance segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combined adaptive gaussian short-term fourier transform and mamba framework for stock price prediction. <em>EAAI</em>, <em>162</em>, 112588. (<a href='https://doi.org/10.1016/j.engappai.2025.112588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In financial investment, predicting stock prices precisely is challenging due to the inherent volatility and non-stationarity of market data. To address this, we propose a pioneering hybrid approach, introducing the Adaptive Gaussian Short-Time Fourier Transform (AG-STFT) in Mamba for the first time—it dynamically adjusts the window size based on frequency content to enhance the representation of non-stationary modes. We further present AGSMNet, a novel hybrid architecture fusing AG-STFT with the Mamba framework, which addresses the dual-domain modeling challenge (time + frequency) through an end-to-end deep learning solution leveraging both signal processing and structured state-space modeling techniques, enabling robust sequence modeling with enhanced temporal and spectral sensitivity. The AG-STFT dissects and represents temporal and spectral features of stock price movements, capturing dynamics often overlooked by traditional models, while Mamba — known for discerning complex patterns — enhances predictive capabilities. The model employs a Multiple Feature Extraction (MFE) module for shallow features and a Residual State-Space Group (RSSG) module for deep features, fed into a predictor module to predict next-day prices. Extensive experiments across ten major stock and index datasets demonstrate that AGSMNet consistently achieves the lowest MAE, MSE, and RMSE, and the highest R 2 values, outperforming leading models such as TimesNet, Autoformer, and MambaStock. These results confirm AGSMNet’s superior generalization, robustness across volatile markets, and practical effectiveness. It is applicable to non-stationary datasets, outperforms traditional, machine learning, and deep learning-based methods, and shows potential as a transformative tool for financial analysts and investors, with adaptability to other financial modeling areas promising advancements in predictive analytics.},
  archive      = {J_EAAI},
  author       = {Yuling Huang and Zhiyuan Pei and Jin Yan and Chujin Zhou and Xiaoping Lu},
  doi          = {10.1016/j.engappai.2025.112588},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112588},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combined adaptive gaussian short-term fourier transform and mamba framework for stock price prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Driver risk classification for transportation safety: A machine learning approach using psychological, physiological, and demographic factors with driving simulator. <em>EAAI</em>, <em>162</em>, 112585. (<a href='https://doi.org/10.1016/j.engappai.2025.112585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving behavior is a critical factor in ensuring road safety, particularly in commercial transportation sectors where hiring safe and reliable drivers is a priority. This study presents a machine learning-based framework for predicting driver behavior using multimodal assessments, including psychological, physiological, and demographic factors. We utilized a driving simulator equipped with biometric sensors to capture the physiological data of the driver, including heart rate, eye blink rate, pupil diameter, and point of gaze (POG), during driving sessions. The psychological attributes are collected through a self-report questionnaire. The questionnaire is structured to obtain information about nine psychological characteristics of the driver, including instrumental attitude, social anxiety, sensation seeking, premeditation, urgency, selfishness, aggressive mode, life satisfaction, and conscientiousness. In addition, some demographic attributes, such as age and gender, are also adopted to study their effect on driving behavior. Experiments were conducted on 80 participants, each driving for 10 min. Various machine learning models, along with a feature selection strategy, were used to find the relationship between the driver's modalities and his driving behavior. Results demonstrate that the k-nearest neighbors (KNN) model achieved the best performance, yielding an accuracy of 93.75 % and a False Negative Rate (FNR) of 0. Feature importance analysis revealed that gaze distraction, sensation seeking, conscientiousness, and gender are the best predictors of driving behavior. The findings suggest that our model can serve as a valuable decision-support tool for taxi companies and transportation agencies aiming to enhance driver selection processes by identifying drivers with lower accident risks.},
  archive      = {J_EAAI},
  author       = {Malek Masmoudi and Yasmin Shakrouf and Omar Hassan Omar and Amir Shikhli and Fatima Abdalla and Wadad Alketbi and Imad Alsyouf and Ali Cheaitou and Anwar Jarndal and Ali I. Siam},
  doi          = {10.1016/j.engappai.2025.112585},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112585},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Driver risk classification for transportation safety: A machine learning approach using psychological, physiological, and demographic factors with driving simulator},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A credibility and consistency-oriented stochastic aggregation framework for heterogeneous multi-attribute large-scale group decision making with several attribute sets. <em>EAAI</em>, <em>162</em>, 112584. (<a href='https://doi.org/10.1016/j.engappai.2025.112584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large-scale group decision making, experts usually provide their individual preferences on attribute values, as well as attribute sets. The coexistence of large-scale heterogeneous information poses a significant challenge to the credibility and consistency on decision making. To this issue, the paper proposes a credibility and consistency-oriented stochastic aggregation framework, including four primarily research points. Firstly, a simplified transformation method is developed to convert heterogeneous attribute values into individual attribute superiority-probability-based pairwise comparison matrix (IA-SPMs), which saves transformation cost as well as provides abundant references for credibility analysis. Secondly, the deviation-based credibility measures and the credibility-based weighting methods are proposed. Thirdly, a cluster-based aggregation operator is introduced by considering group consistent preferences on attributes selection to get the collective SPM (C-SPM). Fourthly, the ranking probability matrix (RPM) and the possibility ranking result are calculated based on the C-SPM. Using experiment and application analyses we illustrate that the proposed methods can enhance the credibility of decision outcomes, as well as the stability of the results. This research can provide technical support for effective fusion of heterogeneous information from multiple sources in the artificial intelligence (AI) era, and has broad application potential in large-scale democratic decision making and pre-evaluation engineering projects.},
  archive      = {J_EAAI},
  author       = {Weiwei Li and Pingtao Yi and Danning Zhang},
  doi          = {10.1016/j.engappai.2025.112584},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112584},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A credibility and consistency-oriented stochastic aggregation framework for heterogeneous multi-attribute large-scale group decision making with several attribute sets},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic machine learning with a cascaded framework for robust failure mode classification and capacity estimation of rectangular concrete-filled steel tube columns under axial compression. <em>EAAI</em>, <em>162</em>, 112581. (<a href='https://doi.org/10.1016/j.engappai.2025.112581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops an advanced probabilistic machine learning (ML) framework to predict failure modes and axial load-bearing capacity of rectangular concrete-filled steel tube (CFST) columns, addressing critical challenges of class imbalance and prediction uncertainty. Leveraging a comprehensive dataset of 597 experimental samples, a rigorous feature selection procedure is conducted to optimize the ML applications. Three ML models are developed and evaluated: a deterministic approach (Random Forest) and two probabilistic models (Gaussian Process and Natural Gradient Boosting, NGBoost). To address the issue of class imbalance in failure mode classification, a hybrid resampling strategy combining the Synthetic Minority Over-sampling Technique and Tomek Links method (SMOTE-Tomek) is implemented. Furthermore, A novel classification-regression cascaded framework is proposed, where failure modes are first classified, followed by category-specific regression for capacity prediction. Results demonstrate that SMOTE-Tomek significantly improves minority failure mode classification, increasing the average F1-scores by 8.1 % (for flexural failure) and 118.2 % (for combined failure). The cascaded framework outperforms direct regression in estimating capacity, achieving a 56 % higher coefficient of determination (R 2 ) and 15–30 % lower error metrics on average. NGBoost excels in both probabilistic failure mode prediction and uncertainty-aware capacity estimation, enabling reliability-based design and risk-informed decision-making for CFST structures in engineering practice.},
  archive      = {J_EAAI},
  author       = {Xueqi Zhong and Dade Lai and Qiyao Yu and Feiyu Liao},
  doi          = {10.1016/j.engappai.2025.112581},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112581},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probabilistic machine learning with a cascaded framework for robust failure mode classification and capacity estimation of rectangular concrete-filled steel tube columns under axial compression},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing precision tomato harvesting with feature sharing and intersection screening. <em>EAAI</em>, <em>162</em>, 112580. (<a href='https://doi.org/10.1016/j.engappai.2025.112580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tomato is a significant economic crop cultivated extensively worldwide. Rapid and accurate localization of picking points is fundamental to automating the tomato harvesting process. To address this, we develop a lightweight dual-task network built upon the YOLOv10 (You Only Look Once) architecture. The backbone integrates the ADown module for efficient downsampling, and utilizes a Dysample-based cross-scale feature fusion module (CCFM) in the detection neck, while the segmentation neck employs Simulated Annealing Adaptive Concatenation (SAAC) for feature fusion. Furthermore, the conditionally restricted Hungarian algorithm is employed to match ripe tomatoes with their corresponding corollas. Two localization techniques are proposed: local skeleton line fitting and boundary intersection screening. In local skeleton line fitting, the corolla detection box is expanded, and the stem mask within this region is used to extract the skeleton line and find the intersection point. Boundary intersection screening determines whether to directly compute the midpoint of intersecting lines or use skeleton line fitting, based on the number of intersections between the stem mask and the corolla box. The detection Precision and Recall of the proposed model are 0.970 and 0.983, respectively, while the IoU (Intersection over Union) and MIoU (Mean Intersection over Union) for segmentation are 0.962 and 0.980. The localization precision for picking points is 0.922, with a recognition rate of 0.988. Achieving an average processing time of only 55.89 ms per image, the proposed artificial intelligence application exhibits excellent efficiency and accuracy in real-world conditions, offering a promising foundation for further development of automated tomato harvesting systems.},
  archive      = {J_EAAI},
  author       = {Xueke An and Bin Dai and Zhaolei Yang and Hassan H.A. Mostafa and Wang Fangyan and Yuliang Yun},
  doi          = {10.1016/j.engappai.2025.112580},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112580},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing precision tomato harvesting with feature sharing and intersection screening},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting the compression index of expansive soils with hybrid machine learning approaches. <em>EAAI</em>, <em>162</em>, 112579. (<a href='https://doi.org/10.1016/j.engappai.2025.112579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expansive soils pose significant challenges for geo-infrastructure design, construction, and maintenance because of their moisture-induced volume changes. Despite extensive research on swelling behavior, the compression index ( C c ), an important indicator of soil compressibility has received relatively limited attention. C c is conventionally obtained from time-consuming and costly consolidation tests, while empirical equations derived from general clays may not provide reliable estimates for expansive soils. To address this gap, seven machine learning models based on five algorithms were developed to estimate the C c of expansive soils using soil properties readily obtained from conventional laboratory tests. A comprehensive dataset comprising 238 expansive soil samples, compiled from 60 years of published literature across various regions of the world, is employed to train and validate the proposed models. Among them, Model 2 based on Newton-Raphson-Based Optimizer optimized Extreme Gradient Boosting (NRBO-XGBoost) achieved the best performance, with a coefficient of determination ( R 2 ) of 0.903 and a root mean square error (RMSE) of 0.029 on the test set. Sensitivity analysis showed that the plasticity index was the most influential factor (31.1 %), followed by liquid limit (29.4 %), initial void ratio (25.3 %), and dry density (14.1 %), highlighting its primary influence on soil compressibility. Additionally, a simplified equation derived from the Multilayer Perceptron (MLP) designated as Model 4 is validated through three case studies. The settlement predictions deviated by 5–14 % from field measurements, offering a practical tool without the need for machine learning techniques. The findings provide useful guidance for developing rational design strategies for geo-infrastructures affected by expansive soils.},
  archive      = {J_EAAI},
  author       = {Aolin Zhang and Sai K. Vanapalli},
  doi          = {10.1016/j.engappai.2025.112579},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112579},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting the compression index of expansive soils with hybrid machine learning approaches},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-based pre-compensator design for piezoelectric actuators based on physics guided neural network and physics-precision balanced training. <em>EAAI</em>, <em>162</em>, 112576. (<a href='https://doi.org/10.1016/j.engappai.2025.112576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing model-based pre-compensators is crucial for achieving high-precision motion control in piezoelectric actuators (PEAs), which exhibit complex nonlinear behaviors. While data-based modeling methods offer a straightforward approach, they face challenges with poor extrapolation and high complexity. Incorporating the known physics of PEAs, which is more consistent with physical principles and computationally efficient, can help overcome these limitations. Based on the above knowledge, this paper embeds physical knowledge within a neural network, forming a novel Physics Guided Neural Network (PGNN) structure as a model-based PEA pre-compensator to achieve high motion precision. Training the PGNN is challenging due to potential competition between the physics component and the neural network. The flexible nature of the neural network can easily overshadow the physical information, leading to overfitting and rendering the PGNN model ineffective. To address this, a Physics-Precision Balanced Training (PPBT) method is proposed. In the PPBT method, the physical correctness and model precision of the PGNN are mathematically defined, and these two components are balanced through a nonlinear function within the training algorithm. Experimental results show that the proposed pre-compensator based on PGNN and PPBT outperforms physics-based approaches in precision and offers greater robustness than purely data-based methods. The peak-to-peak displacement error is reduced to less than 35 nm in open-loop control. Measured by Mean Absolute Error (MAE), this method reduces displacement errors by 89 % compared to no compensation, by 77 % compared to purely neural network-based compensation, and by 73 % compared to rate-dependent Prandtl-Ishlinskii operator-based compensation.},
  archive      = {J_EAAI},
  author       = {Qin Li and Zhiwei Ruan and Chenyang Ding},
  doi          = {10.1016/j.engappai.2025.112576},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112576},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Model-based pre-compensator design for piezoelectric actuators based on physics guided neural network and physics-precision balanced training},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end burst signal demodulation via adaptive masked deep learning framework. <em>EAAI</em>, <em>162</em>, 112569. (<a href='https://doi.org/10.1016/j.engappai.2025.112569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bit error rate (BER) directly determines the quality of wireless communication transmission. Traditional demodulators are limited in operating on burst signals and exhibit poor BER performance in low signal-to-noise ratio (SNR) conditions. For real-world burst signals, symbol-by-symbol approaches fail to capture inter-symbol dependencies, and existing end-to-end frameworks cannot handle the variable output lengths required for burst signals. To address this issue, we propose an end-to-end demodulation framework based on deep learning (DL), in which detection, recognition, channel compensation, and demodulation stages were trained as a unified system, enabling the entire signal burst to be demodulated in a single operation during inference. The framework's generalization and robustness are enhanced by a proposed masking mechanism and a denoising autoencoder (DAE), respectively. The former dynamically adjusts the output bitstream length while preventing gradient flow from redundant components, and the latter compensates for channel fading effects. We further introduce a dedicated end-to-end training strategy to optimize the adaptation between these modules. Experimental results on real-world Frequency Shift Keying (FSK), Minimum Shift Keying (MSK), Phase-Shift Keying (PSK), and Quadrature Amplitude Modulation (QAM) signals demonstrate that the proposed framework achieves superior demodulation accuracy for long-sequence burst signals. Compared to existing methods, the proposed framework enables parallel demodulation, and dynamically adapts the output bit stream in terms of varying message types and lengths.},
  archive      = {J_EAAI},
  author       = {Mingdi Li and Wenzhe Fan and Yanbin Li and Chunlei Xie and Yanan Duan},
  doi          = {10.1016/j.engappai.2025.112569},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112569},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {End-to-end burst signal demodulation via adaptive masked deep learning framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-head detector with point-driven transformer and semantic-spatial gating for liquid crystal display defects. <em>EAAI</em>, <em>162</em>, 112565. (<a href='https://doi.org/10.1016/j.engappai.2025.112565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unique structure of liquid crystal displays (LCDs) leads to defects with specific characteristics, posing a significant challenge to defect detection. These defects mainly include global slender line defects, numerous small defects, and other defects exhibiting significant variations in scale and visual complexity. To simultaneously detect slender defects and numerous small defects, we propose a novel dual-head detector (DHDet) that combines the strengths of transformer-based and convolutional neural network (CNN)-based approaches. The transformer-based line head leverages its global context modeling capability and exploits shape priors by representing line defects using discrete points. Additionally, a slender-object query selection module is introduced to generate line proposals composed of discrete points. These proposals with spatial cues provide effective initialization for the inputs of the transformer decoder. The CNN-based box head focuses on detecting prevalent small defects and other multi-scale objects. To enhance the detection of complex and large defects, we design a semantic-modulated spatial-coordinated gating module. Through semantic guidance and spatial correlations, this module adaptively gates and weights global context from the line head’s queries to optimize top-level features for the box head. Experiments on an industrial LCD defect detection dataset and two defect datasets of manufacturing domain demonstrate our detector’s superior performance in complex defect detection tasks. Our method outperforms other state-of-the-art methods on the LCD defect dataset, achieving 67.4% mean average precision (mAP) and 88.3% mAP at an intersection over union threshold of 0.5 (mAP 50 ). The code is available at .},
  archive      = {J_EAAI},
  author       = {Chaofan Zhou and Meiqin Liu and Senlin Zhang and Shanling Dong and Ronghao Zheng and Shaoyi Du},
  doi          = {10.1016/j.engappai.2025.112565},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112565},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-head detector with point-driven transformer and semantic-spatial gating for liquid crystal display defects},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated machine learning framework for the early diagnosis of hypertension disease. <em>EAAI</em>, <em>162</em>, 112564. (<a href='https://doi.org/10.1016/j.engappai.2025.112564'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypertension is a type of disease that occurs after a serious increase in blood pressure. Due to the rapid increase in the disease, efforts for its early diagnosis are increasing day by day. The use of artificial intelligence (AI) and machine learning (ML) methods in disease detection is of great importance, especially in early diagnosis. In this study, a framework for the diagnosis of hypertension is developed. Behavioral Risk Factor Surveillance System (BRFSS) and Hypertension Risk Prediction (HRP) datasets with clinical and demographic information were used to diagnose hypertension. The problem of class imbalance in the datasets was solved by Random OverSampling method. In particular, the relationship between the attributes and the target variable was analyzed with Consistency-Based Filter, Recursive Feature Elimination with Cross-Validation (RFECV), Least Absolute Shrinkage and Selection Operator (LASSO), Information gain, Relief and Correlation-based feature selection methods and the features selected for the diagnosis of hypertension disease were taken into consideration. In the experiments, Extremely Randomized Trees (Extra Trees), Adaptive Boosting (Adaboost) and Extreme Gradient Boosting (XGBoost) machine learning methods were used in five fold cross-validation. In both datasets, the most successful results were obtained with the XGBoost algorithm. Then, for this algorithm, Random Search, Grid Search, Bayes Search and Genetic Algorithm were used for model hypertuning. For the BRFSS dataset with 87.96 % accuracy and for the HRP dataset with 97.67 % accuracy were obtained. The results are obtained with evaluation metrics that the medical world considers in evaluations, and the proposed framework for hypertension disease detection provides valuable insights for healthcare applications.},
  archive      = {J_EAAI},
  author       = {Ayşe Eldem},
  doi          = {10.1016/j.engappai.2025.112564},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112564},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An integrated machine learning framework for the early diagnosis of hypertension disease},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An explainable deep learning approach for sleep staging in sleep apnea patients across all age subgroups from pulse oximetry signals. <em>EAAI</em>, <em>162</em>, 112562. (<a href='https://doi.org/10.1016/j.engappai.2025.112562'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-learning (DL) approaches have been developed using pulse rate (PR) and blood oxygen saturation (SpO 2 ) recordings from pulse oximetry to streamline sleep staging, particularly for obstructive sleep apnea (OSA) patients. However, lack of interpretability and validation across patients from a wide range of ages (children, adolescents, adults, and elderly OSA individuals) are two major concerns. In this study, a DL model based on the U-Net framework (POxi-SleepNet) was tailored to accurately perform 4-class sleep staging (wake, light sleep, deep sleep, and rapid-eye movement sleep) in OSA patients across all age subgroups using PR and SpO 2 signals. An explainable artificial intelligence (XAI) methodology based on semantic segmentation via gradient-weighted class activation mapping (Seg-Grad-CAM) was also applied to quantitatively interpret the time and frequency characteristics of pulse oximetry recordings that influence sleep stage classification. Overnight PR and SpO 2 signals from 17303 sleep studies from six datasets encompassing children, adolescents, adults, and elderly OSA individuals were used. POxi-SleepNet showed high performance for sleep staging in the six databases, with accuracies between 81.5 % and 84.5 % and Cohen's kappa values from 0.726 to 0.779. It also demonstrated greater generalizability than previous studies. XAI analysis showed the key contributions of mean and variability in PR and SpO 2 amplitude, as well as changes in their spectral content across specific frequency bands (0.004–0.020 Hz, 0.020–0.100 Hz, and 0.180–0.400 Hz), for sleep stage classification. These findings indicate that POxi-SleepNet could effectively automate sleep staging and assist in diagnosing OSA across all age groups in clinical settings.},
  archive      = {J_EAAI},
  author       = {Fernando Vaquerizo-Villar and Gonzalo C. Gutiérrez-Tobal and Daniel Álvarez and Adrián Martín-Montero and David Gozal and Roberto Hornero},
  doi          = {10.1016/j.engappai.2025.112562},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112562},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An explainable deep learning approach for sleep staging in sleep apnea patients across all age subgroups from pulse oximetry signals},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transient electrodynamic simulation of laser beam reflection on inclined surfaces using a generative adversarial network-based deep learning model. <em>EAAI</em>, <em>162</em>, 112561. (<a href='https://doi.org/10.1016/j.engappai.2025.112561'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In laser-material interactions, the temporal dynamics of beam reflection are crucial as they affect both laser absorption and material response. Currently, electrodynamic simulation is the most accurate method for calculating transient laser reflection and absorption patterns, but it is computationally very expensive. In this study, we present the first transient electrodynamic simulation model based on a generative adversarial network, with the time information embedded as color in the input image. The model accurately predicts reflection patterns of a laser beam on inclined surfaces using an input image containing geometric and time information of the domain. The finite-difference time-domain method was used to generate 16 data by changing the surface inclination angle from 0 o to 75 o . The model was based on a generator made by stacking a deep residual network and a discriminator. Although trained on limited data, the model predicted transient beam reflection patterns without overfitting, and the average structural similarity index measure and R-squared accuracy were 96.7 % and 98.0 %, respectively. Another deep learning model was developed to predict the laser beam absorptance from a laser beam reflection image. The ground truth absorptance values were obtained from the Fresnel equations, and the average R-squared accuracy was 99.8 %. Robustness evaluation was additionally performed to examine if the model can be used to predict reflection patterns from angled and curved surfaces. Reasonably accurate results were obtained when the angle difference was not greater than 3° for angled surfaces and the normalized curvature was 0.032 or less for curved surfaces.},
  archive      = {J_EAAI},
  author       = {Myeonggyun Son and Hyungson Ki},
  doi          = {10.1016/j.engappai.2025.112561},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112561},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transient electrodynamic simulation of laser beam reflection on inclined surfaces using a generative adversarial network-based deep learning model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanical properties prediction of bi-metal foam sandwiches using machine learning methods and elastic deformation behaviour. <em>EAAI</em>, <em>162</em>, 112560. (<a href='https://doi.org/10.1016/j.engappai.2025.112560'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal foam sandwiches are a kind of ultra-lightweight material made from a porous metal core bonded to two face sheets. Friction stir welding (FSW) is utilised in welding bimetal foam sandwiches. It is worth mentioning that the exact relation between mechanical properties and process parameters is challenging to determine. The innovation lies in the non-destructive estimation of mechanical properties (Young's modulus, ultimate tensile strength and fracture strain) through elastic deformation data and the novel application of artificial intelligence techniques optimised by genetic algorithms, eliminating dependency on input process parameters. After proper network training, three methods are employed to estimate these mechanical properties: a decision tree, a feedforward neural network and long-short term memory. These are chosen to investigate the influence of both machine/deep learning methods in predicting the mechanical properties of the FSW final product. Moreover, a genetic algorithm is employed to find the optimal hyperparameters of the three investigated prediction models to reach the highest accuracy. The results prove the efficiency of the proposed feedforward neural network in the estimation of Young's modulus and ultimate tensile strength for the bi-metal foam sandwiches with lower mean absolute error (MAE) and higher correlation coefficient compared to the decision tree (63.9 % lower MAE and 25.50 % higher correlation coefficient) and long-short term memory (77.50 % lower MAE and 25.05 % higher correlation coefficient). In addition, the proposed decision tree model accurately predicts the fracture strain with R-square and root mean square error as 0.61429 and 1.3862 × 10 −5 , respectively.},
  archive      = {J_EAAI},
  author       = {Mohammad Reza Chalak Qazani and Mohsen Dorudgar and Mehdi Moayyedian and Abdel-Hamid I. Mourad and Moosa Sajed and S.M. Hossein Seyedkashi and Siamak Pedrammehr},
  doi          = {10.1016/j.engappai.2025.112560},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112560},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mechanical properties prediction of bi-metal foam sandwiches using machine learning methods and elastic deformation behaviour},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal unified generalization and translation network for intelligent fault diagnosis under dynamic environments. <em>EAAI</em>, <em>162</em>, 112559. (<a href='https://doi.org/10.1016/j.engappai.2025.112559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal data fusion can generate reliable fault representations for intelligent fault diagnosis. However, simple data fusion strategies often introduce fault-irrelevant information, thereby reducing robustness against unknown domain shifts. Moreover, traditional methods generally lack adaptive mechanisms to address missing modalities, leading to considerable performance degradation under sensor failure conditions. To address these problems, this paper proposes a multimodal unified generalization and translation network. To learn invariant unified representations for resisting unknown data distribution shifts, information-enhanced concatenation first generates intra-domain and cross-domain representations. Subsequently, mutual information maximization is applied to remove fault-unrelated information from these representations. Finally, A hybrid ensemble diagnosis strategy fully leverages the interaction of multimodal information across different levels. In addition, semantic supervision investigates the relationships among different modalities and enables intermodal translation in the event of a sensor failure within the monitoring system. Extensive experimental results based on a public bearing dataset and a self-collected motor dataset indicate that the proposed method improves accuracy by 10.53 % and 8.47 % compared to the state-of-the-art methods, respectively. The code and datasets are available at https://github.com/CHAOZHAO-1/MUGTN .},
  archive      = {J_EAAI},
  author       = {Chao Zhao and Weiming Shen and Enrico Zio and Hui Ma},
  doi          = {10.1016/j.engappai.2025.112559},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112559},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal unified generalization and translation network for intelligent fault diagnosis under dynamic environments},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FabricMamba: A fabric surface defect detection system based on large kernel attention and visual state space. <em>EAAI</em>, <em>162</em>, 112558. (<a href='https://doi.org/10.1016/j.engappai.2025.112558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the textile manufacturing industry, fabric defect detection is essential for ensuring product quality. Traditional approaches based on Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) often encounter scalability issues, particularly due to the high computational complexity of the self-attention mechanism in ViTs. To address these limitations, this study introduces FabricMamba, a real-time defect detection framework built on the You Only Look Once version 8 (YOLOv8) CNN architecture. The model enhances detection precision and efficiency for complex fabric defects in high-resolution images while minimizing computational cost. YOLOv8 was selected as the base model due to its strong balance between accuracy and inference speed, which is critical in fast-paced textile production settings. FabricMamba extends YOLOv8 with several innovations: the Parallel Large Separable Kernel Attention (P-LSKA) mechanism for multi-scale perception, the Visual State Space Module (MVSS) for long-range dependency modeling, the lightweight DySample module for reduced resource usage, and Programmable Gradient Information (PGI) to optimize training without increasing inference complexity. Extensive evaluations were conducted using a proprietary industrial fabric defect dataset and two public benchmarks, TILDA Textile Texture Database and FDDS Object Detection Dataset. FabricMamba achieved a mean Average Precision (mAP) of 90.0 %, 97.7 %, and 39.1 % on the respective datasets, outperforming the YOLOv8 baseline by 1.8 %, 2.3 %, and 2.0 %. Compared to Mamba-YOLO, FabricMamba reduced model size and computational requirements by 36.7 % and 33.1 %, respectively, with recall improving by 2.9 %, 1.4 %, and 4.0 %. These results confirm the model effectiveness and practical potential for industrial fabric inspection tasks.},
  archive      = {J_EAAI},
  author       = {Nengsheng Bao and Jiajun Lin and Yuchen Fan and Runxuan Bao and Alessandro Simeone},
  doi          = {10.1016/j.engappai.2025.112558},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112558},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FabricMamba: A fabric surface defect detection system based on large kernel attention and visual state space},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing performance metrics with new distance and similarity measures using control parameters of linear diophantine fuzzy sets. <em>EAAI</em>, <em>162</em>, 112557. (<a href='https://doi.org/10.1016/j.engappai.2025.112557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control parameters (CPs) of linear Diophantine fuzzy sets (LDFSs) provide an innovative approach for information analysis in the multi-criteria decision making (MCDM), machine learning (ML), and computational intelligence (CI). The CPs give freedom to the decision-makers in evaluating feasible alternatives in measuring performance metrics. Previous fuzzy MCDM methods often meet strict limitations in handling real-world uncertainty and dynamic MCDM. To overcome these limitations, this study extends the Preference Ranking Organization Method for Enrichment of Evaluations (PROMETHEE-II) method to linear Diophantine fuzzy sets (LDFSs) for more flexible and robust MCDM approach. The proposed MCDM approach primarily evaluates performance metrics criterion, utilizing LDFSs which are robust extension of fuzzy sets (FSs), intuitionistic fuzzy sets (IFSs) as well as interval-valued intuitionistic fuzzy sets (IVIFSs). It helps decision makers to address uncertain information with membership degree (MD), non-membership degree (NMD), and CPs. For this objective, new LDFS based distance measures (DMs) and similarity measures (SMs) are developed for the construction of LDFS PROMETHEE-II technique. The proposed MCDM approach provides a structured and comprehensive framework for optimizing investment performance metrics. Its robustness is validated through sensitivity and comparative analyses.},
  archive      = {J_EAAI},
  author       = {Masooma Raza Hashmi and Muhammad Riaz and Arshid Mahmood and Muhammad Ajmaeen and Muhammad Aslam},
  doi          = {10.1016/j.engappai.2025.112557},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112557},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing performance metrics with new distance and similarity measures using control parameters of linear diophantine fuzzy sets},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic capsule network-based physical alert monitoring system for elderly people with disabilities. <em>EAAI</em>, <em>162</em>, 112556. (<a href='https://doi.org/10.1016/j.engappai.2025.112556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elderly disabled people have higher health risks due to reduced mobility, delayed emergency response, and poor real-time monitoring. Existing Internet of Things (IoT) based monitoring systems frequently have static thresholds, lack personalization, and struggle to capture complex physical and physiological fluctuations, resulting in false alerts and reduced reliability. We propose a Dynamic Capsule Network-Based Physical Alert Monitoring System (DyCN-PAM) for intelligent, real-time monitoring of elderly disabled people to overcome these constraints. Compiling accelerometer, gyroscope, and heart rate readings, and utilizing capsule routing to preserve spatiotemporal hierarchies, enables the system to detect falls, seizures, and fainting. Context-aware alerts utilize capsule confidence and heart rate baselines to distinguish between typical changes and catastrophic emergencies. The DyCN-PAM system outperforms benchmark models in terms of accuracy and robustness, achieving a 5.13 % increase in F1-score, a 28.6 % increase in precision, a 45.1 % reduction in false alarms, and a 26.3 % improvement in computational efficiency. The DyCN-PAM system enhances accuracy, precision, and efficiency, making it feasible to improve safety, independence, and quality of life for older individuals with disabilities. More real-world experiments are needed to prove its use.},
  archive      = {J_EAAI},
  author       = {Shujuan Feng and Hongying Zhu and Yangkai Wu and Ziheng Zeng and Ezzeddine Touti and Jinming Wang and Amar Jain},
  doi          = {10.1016/j.engappai.2025.112556},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112556},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamic capsule network-based physical alert monitoring system for elderly people with disabilities},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiple convolution and bilayer acceleration model for precise and efficient early urban fire detection in complex scenarios. <em>EAAI</em>, <em>162</em>, 112555. (<a href='https://doi.org/10.1016/j.engappai.2025.112555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI advancement enables earlier and more effective urban fire detection, crucial for slowing fire spread. However, hardware limitations make precise and efficient detection under limited resources a major challenge. Moreover, earlier detection of fire requires the identification of smoke, which further exacerbates the difficulty of detecting algorithms since smoke's inherent low-contrast visual properties produce feature blurring from the surrounding background. In this paper, we propose a novel multiple convolutions and bilayer accelerate (MCBA) model for effective early urban fire detection in terms of precision, lightweight and efficiency, which takes advantage of the mainstream You Only Look Once version 8 (YOLOv8) to training and testing the early fire detection model. In our MCBA model, three optimization techniques have been developed to balance lightweight and precision. First, it designs a new multi-convolution (MC) structure to reduce the size of the original backbone network by avoiding complex or skipping connections. Second, the model includes a novel design of a bilayer accelerate mechanism (BAM) at the neck to minimize the interference of redundant background information in multiple scenarios. Third, we provide a precision compensation strategy (PCS) at the neck to enhance the feature extraction and aggregation capabilities, enabling effective detection of small fire areas. The experiments demonstrate that our proposed MCBA model achieves higher performance in terms of precision and efficiency compared with 17 counterpart detection models. It exhibits superior performance with minimal parameter count and the lowest computational complexity among the compared methods. The model shows strong potential for deployment in early urban fire detection across a variety of real-world scenarios.},
  archive      = {J_EAAI},
  author       = {Pei Shi and Jun Lu and Yachen Xu and Quan Wang and Yonghong Zhang and Liang Kuang and Deji Chen and Guangyan Huang},
  doi          = {10.1016/j.engappai.2025.112555},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112555},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multiple convolution and bilayer acceleration model for precise and efficient early urban fire detection in complex scenarios},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning driven prediction of dynamic stress-strain response in limestone: Insights into transient mechanical behavior under complex loadings for shield tunneling. <em>EAAI</em>, <em>162</em>, 112554. (<a href='https://doi.org/10.1016/j.engappai.2025.112554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex geological conditions pose a serious challenge to improving the rock-breaking efficiency of shield cutter machines in subway tunnel constructions. This study develops a three-axis thermal-hydraulic-mechanical (THM) coupled dynamic impact system, which is integrated with a scaled shield cutter model to generate a unique dataset of stress wave propagation under multi-field coupling. A bidirectional long short-term memory (LSTM) neural network with an attention mechanism is proposed to establish a nonlinear time mapping relationship between stress waves. The determination coefficient ( R 2 ) exceeds 0.97, the symmetric mean absolute percentage error ( sMAPE ) is less than 10 %, and the average relative uncertainty ( ARU ) is less than 4 %, confirming its high accuracy and reliability. Based on predictions and test results, the new quantitative laws for the transient dynamics of limestone are further revealed. The results reveal that loading conditions do not alter the correlation trend between loading rate and dynamic parameters but significantly influence the degree of the loading rate's effect. Axial pressure dominates energy absorption with an energy contribution rate of 60 %. Confining pressure amplified the sensitivity of loading rate by 170 %, while THM coupling suppressed the dynamic deformation modulus by over 30 %. The accurate prediction of the nonlinear response of stress waves in limestone by the LSTM neural network establishes the connection between transient dynamic observation and rock fragmentation physics mechanism, providing support for quantifying energy absorption and conversion in the rock fragmentation process, and providing key strategies for optimizing shield machine performance in extreme environments.},
  archive      = {J_EAAI},
  author       = {Baoping Zou and Kejian Xia and Jingyuan Ma and Xu Long},
  doi          = {10.1016/j.engappai.2025.112554},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112554},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning driven prediction of dynamic stress-strain response in limestone: Insights into transient mechanical behavior under complex loadings for shield tunneling},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A continuous verification mechanism for ensuring client data forgetfulness in federated unlearning. <em>EAAI</em>, <em>162</em>, 112553. (<a href='https://doi.org/10.1016/j.engappai.2025.112553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Federated Learning (FL), it is sometimes necessary to unlearn client data through Federated Unlearning (FU) methods, which help protect user privacy and recover from data poisoning. One critical task is to check the consistency of FU methods and verify if certain clients’ data has been effectively unlearned. However, none of the current FU verification methods can be performed on clients who opt out of the FL process, failing to meet the universal demand in FL, such as the user’s “right to be forgotten” (RTBF). Specifically, after clients leave the FL cooperation, they can no longer verify whether the FL model unlearns their data as the FL continues training for several rounds. To address this, we introduce a continuous verification mechanism for FL clients called Backdoor Attack-based Forgetting Verification (BAFV). The BAFV method embeds a persistent mark for clients who propose to leave, allowing them to verify FU long after leaving the FL cooperation. Extensive experiments across diverse FU environments and datasets demonstrate that our method maintains the model’s accuracy and provides clients with a continuous verification mechanism to ensure their data is unlearned. Our combinatorial marking strategy and gradient-amplified persistence mechanism represent significant advancements beyond existing verification schemes. Our code of BAFV is publicly available at: https://github.com/FuduXing/newBAFV.git .},
  archive      = {J_EAAI},
  author       = {Fudu Xing and Jun Liu and Shanshan Chen and Tianlong Yu and Yang Yang},
  doi          = {10.1016/j.engappai.2025.112553},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112553},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A continuous verification mechanism for ensuring client data forgetfulness in federated unlearning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trajectory planning of redundant parallel mechanism considering motion accuracy based on reinforcement learning. <em>EAAI</em>, <em>162</em>, 112552. (<a href='https://doi.org/10.1016/j.engappai.2025.112552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The motion accuracy of the trajectory directly affects the reliability of parallel mechanisms in precision tasks such as micro-assembly. Thus, this paper investigates trajectory planning considering motion accuracy, and uses a (6+3)-degrees of freedom (DOF) kinematically redundant parallel mechanism (KRPM) as a case study. First, the kinematics of KRPM are analyzed, and an error model incorporating dimensional errors, driving input errors, and joint clearances is established. Then, based on the error model, the aggregate sensitivity index (ASI) and comprehensive error sensitivity (CES) are introduced to study the error properties of KRPM, along with a universal analysis process. Subsequently, reinforcement learning (RL) utilizing the twin delayed deep deterministic policy gradient (TD3) algorithm is employed to the trajectory planning of KRPM considering motion accuracy. Finally, numerical simulation is carried out based on three cases to verify the effectiveness of the proposed method, and experimental results further demonstrate its practical applicability.},
  archive      = {J_EAAI},
  author       = {Chen-dong Zeng and Zhi-cheng Qiu and Fen-hua Zhang and Xian-min Zhang},
  doi          = {10.1016/j.engappai.2025.112552},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112552},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Trajectory planning of redundant parallel mechanism considering motion accuracy based on reinforcement learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning-tuning hierarchical vehicle trajectory tracking framework based on improved kinematic model predictive control. <em>EAAI</em>, <em>162</em>, 112551. (<a href='https://doi.org/10.1016/j.engappai.2025.112551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory tracking is crucial in vehicle control, as it ensures stable driving along a predefined path. This paper proposes a deep reinforcement learning (DRL)-tuning hierarchical trajectory tracking framework, aiming to improve the tracking accuracy of traditional kinematic model predictive control (MPC) methods in uncertain environments. The proposed hierarchical vehicle trajectory tracking framework consists of two layers: the upper layer serves as a compensation layer for the vehicle side-slip angle (VSA), designed using bidirectional long short-term memory (BiLSTM); while the lower layer is the trajectory tracking layer, in which the improved kinematic MPC is enhanced by integrating the twin delayed deep deterministic policy gradient (TD3) algorithm with an external attention (EA) mechanism. The contribution in artificial intelligence is improving the TD3 algorithm with the EA mechanism, enhancing its ability to capture contextual information and improve adaptability. The contribution in engineering applications is implementing the EA-TD3-tuned hierarchical kinematic MPC framework in the field of vehicle trajectory tracking. With 95 % confidence, compared to traditional kinematic MPC controller, the proposed hierarchical vehicle trajectory tracking framework reduces the average lateral error by 33 % (confidence interval, CI: [0.0616, 0.0850]), the average heading angle error by 34 % (CI: [0.01173, 0.0157]), the average yaw rate variation by 31 % (CI: [0.0244, 0.0346]), and the average front wheel steering angle variation by 28 % (CI: [0.0244, 0.0346]).},
  archive      = {J_EAAI},
  author       = {Jiankun Peng and Xingyan Liu and Changcheng Wu and Dawei Pi and Jiaxuan Zhou},
  doi          = {10.1016/j.engappai.2025.112551},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112551},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement learning-tuning hierarchical vehicle trajectory tracking framework based on improved kinematic model predictive control},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel decomposition-prediction hybrid model improved by dual-channel cross-attention mechanism for short-term wind speed prediction. <em>EAAI</em>, <em>162</em>, 112550. (<a href='https://doi.org/10.1016/j.engappai.2025.112550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of wind energy is crucial for ensuring the safe operation and stability of power systems. To improve the accuracy and robustness of wind speed (WS) forecasting, a novel hybrid method based on mixture of experts (MoE), Transformer, temporal convolution network (TCN), multi-head attention (MA) mechanism, and improved by dual-channel cross-attention mechanism (DCCAM) is proposed. The wind speed data is decomposed by MoE into seasonal and trend components. The trend features are directly captured through a multi-head attention mechanism. An innovative Transformer-TCN framework associated with DCCAM is designed to handle the seasonal component, wherein the Transformer-TCN can make full use of long dependency modeling of Transformer and the local feature extraction of TCN, and DCCAM enables the information interchange and feature fusion, therefore realizing complementary advantages. Based on the proposed model, a series of experiments are conducted on multiple datasets. Ablation experiments confirm the effectiveness of the model and the role of each module in performance improvement. Experiments on seasonal datasets, including spring, summer, autumn, and winter, show that the proposed model can effectively adapt to variations in amplitude and volatility of wind speed sequences under different climatic conditions. Comparative experiments with six advanced hybrid models including decomposition and prediction modules, further demonstrate the superiority and stability of the proposed model.},
  archive      = {J_EAAI},
  author       = {Donghan Geng and Haiteng Cui and Leisen Lv and Jiamin Guo},
  doi          = {10.1016/j.engappai.2025.112550},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112550},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel decomposition-prediction hybrid model improved by dual-channel cross-attention mechanism for short-term wind speed prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysing sustainable industrial wastewater treatment technologies using circular fermatean fuzzy multi-attribute group decision making with decision experts’ confidence levels. <em>EAAI</em>, <em>162</em>, 112549. (<a href='https://doi.org/10.1016/j.engappai.2025.112549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of sustainable industrial wastewater treatment techniques is vital for preserving environmental integrity and protecting public health. Industrial processes often generate wastewater containing toxic compounds like metal contaminants, toxic chemicals, and complex organic compounds, posing serious risks to ecosystems and human well-being. This study proposes a robust multi-attribute group decision-making framework to assess five treatment alternatives across twelve sub-criteria. The evaluation model employs circular Fermatean fuzzy numbers to capture uncertainty and imprecision in expert judgements. To enhance the accuracy of data aggregation, four novel Schweizer–Sklar weighted aggregation operators are introduced, integrating varying confidence levels. Criteria weights are determined through a hybrid approach combining the subjective Ranking Comparison (RANCOM) method and the objective Opinion Weight Criteria Method (OWCM), ensuring balanced prioritization. Alternatives are ranked using the Alternative Ranking Order Method Accounting for Two-Step Normalization (AROMAN), a novel technique for improved discrimination and consistency. Results reveal that the membrane bioreactor as the most sustainable treatment with score 0.821, outperforming activated sludge process, by 25.34%. The lowest-ranked option is chemical coagulation and flocculation, scoring 0.622. Sensitivity analysis, performed by varying three parameters, shows reasonable stability with an average correlation value of 0.71. Comparative analysis shows an average Spearman’s rank correlation of 0.86, confirming reliability. The study recommends prioritizing membrane bioreactor adoption in industrial treatment plants to enhance efficiency and water reuse. By promoting effective treatment solutions, the study contributes to reducing industrial pollution, enhancing water reuse, and advancing environmental sustainability.},
  archive      = {J_EAAI},
  author       = {Prayosi Chatterjee and Mijanur Rahaman Seikh},
  doi          = {10.1016/j.engappai.2025.112549},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112549},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analysing sustainable industrial wastewater treatment technologies using circular fermatean fuzzy multi-attribute group decision making with decision experts’ confidence levels},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cost-effective nash-based allocation method for task distribution of multiple robots in distributed robotic networks. <em>EAAI</em>, <em>162</em>, 112548. (<a href='https://doi.org/10.1016/j.engappai.2025.112548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiency is paramount in distributed robotic networks (DRNs), where multiple autonomous robots collaborate to perform complex tasks. In this context, the identification of the most efficient path for robots, considering both distance and cost, plays a crucial role in the development of an effective matching algorithm for addressing multirobot task allocation (MRTA) challenges. The study introduces a new cost-efficient Nash-based game framework for task allocation in a distributed robotic network. The proposed model relies on a decentralized decision-making strategy, where each robot selects a single task that optimizes its execution time at a constant speed, thereby maximizing energy harvesting and minimizing energy consumption. In this context, each robot optimizes its choices for individual benefit while also considering the collective welfare, achieving the Nash equilibrium as a nearly optimal allocation strategy in DRNs. The proposed model is tested on various MRTA scenarios involving five robots, seven robots, ten robots, fifteen robots, and twenty robots with the same number of tasks. The proposed Nash-based decentralized model outperforms the Hungarian method by significantly reducing computational costs and complexity to O ( N ) , making it more efficient for large-scale problems.},
  archive      = {J_EAAI},
  author       = {Ali Hamidoğlu and Omer Melih Gul and Seifedine Nimer Kadry and Chiranjibe Jana and Ali Elghirani and Gokhan Koray Gultekin},
  doi          = {10.1016/j.engappai.2025.112548},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112548},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A cost-effective nash-based allocation method for task distribution of multiple robots in distributed robotic networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A digital twin-assisted algorithm for diagnosis of permanent magnet synchronous generator interturn short circuit fault and converter open circuit fault in wind power systems using pearson correlation coefficient. <em>EAAI</em>, <em>162</em>, 112547. (<a href='https://doi.org/10.1016/j.engappai.2025.112547'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interturn short-circuit faults (ISCFs) in permanent magnet synchronous generators (PMSGs) and open-circuit faults (OCFs) in the machine-side converters represent two critical reliability challenges in wind power systems. Conventional fault diagnosis approaches typically rely on dedicated models for each fault type for each fault type, leading to excessive system complexity and suboptimal computational efficiency. To overcome these limitations, this paper proposes a novel unified digital twin-assisted framework capable of simultaneous diagnosis of both PMSG ISCFs and converter OCFs within a single integrated architecture. The high-fidelity digital twin model based on one-dimensional convolutional neural networks is established to generate real-time reference value of current space vector (SV) for online fault detection, while Pearson correlation coefficient analysis enables accurate differentiation between ISCF and OCF. For ISCFs, the fault severity assessment is performed based on the deviation between reference and measured current SV, with the faulty phase identified using phase current root mean square (RMS) values. In the case of converter OCFs, the proposed method introduces a dual-stage identification process: single and dual insulated-gate bipolar transistor (IGBT) open faults are differentiated through severity estimation analysis, and the faulty IGBT is identified by evaluating the effective current interval ratio (ECIR) and normalized current average (NCA). The experimental results validate the effectiveness of the proposed method, and comparative analysis further demonstrates its superior performance in terms of parameter dependency and diagnostic efficacy.},
  archive      = {J_EAAI},
  author       = {Bin Sun and Ying Zhu and Zhinong Wei},
  doi          = {10.1016/j.engappai.2025.112547},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112547},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A digital twin-assisted algorithm for diagnosis of permanent magnet synchronous generator interturn short circuit fault and converter open circuit fault in wind power systems using pearson correlation coefficient},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight self-attention metric network for bird species recognition in intelligent bird repellent equipment. <em>EAAI</em>, <em>162</em>, 112546. (<a href='https://doi.org/10.1016/j.engappai.2025.112546'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bird damages to power transmission lines pose significant operational risks, and intelligent bird repellent equipment (IBRE) requires accurate species recognition for effective long-term repellent. We propose a novel lightweight self-attention metric network (LSAM-Net) for few-shot bird species recognition in the vicinity of power transmission lines, aiming to enhance the performance of IBRE. LSAM-Net integrates a simple attention mechanism (SimAM) to emphasize critical spatial and channel features, thereby enhancing the extraction of key semantic information from bird images. Additionally, a self-correlation representation (SCR) module is employed to capture local structural patterns, effectively mitigating the impact of pseudo-features and improving the network’s capacity to learn discriminative representations. To promote the utilization of local discriminative information in few-shot classification, LSAM-Net leverages earth mover’s distance (EMD) to compute structural similarity between images. For efficient deployment, we apply knowledge distillation to further reduce model complexity. Extensive experiments conducted on Bird-65, CUB200, 2011, miniImageNet, and Fewshot-CIFAR100 demonstrate that LSAM-Net achieves superior performance compared to state-of-the-art methods, while maintaining a compact architecture. On the Bird-65 and CUB200-2011 datasets, LSAM-Net requires only 4.75 and 1.18 giga floating-point operations (GFLOPs), and achieves inference speed improvements of 52.9 % and 48.9 %, respectively, over the self-attention metric network (SAM-Net). Further optimization with TensorRT yields additional reductions in inference time by 43.6 ms and 53.7 ms, respectively. These improvements significantly support species-specific repellent strategies, thereby enhancing the long-term effectiveness of IBRE systems.},
  archive      = {J_EAAI},
  author       = {Jiangjian Xie and Shanshan Xie and Baican Li and Yujie Zhong and Chunhe Hu and Junguo Zhang and Björn W. Schuller},
  doi          = {10.1016/j.engappai.2025.112546},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112546},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight self-attention metric network for bird species recognition in intelligent bird repellent equipment},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multimodal multi-scale fusion network for leak detection in marine piping systems. <em>EAAI</em>, <em>162</em>, 112545. (<a href='https://doi.org/10.1016/j.engappai.2025.112545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marine system monitoring data inherently exhibit multimodal characteristics, making artificial intelligence-driven correlation and fusion essential for improving fault feature recognition. However, existing intelligent diagnosis methods mostly focus on feature fusion within homogeneous data types, such as fusing multiple time-series signals or multiple image sets, while systematic exploration of joint representation learning across heterogeneous dimensions remains under-explored. This limitation constrains the recognition capability for complex failure modes. Meanwhile, the inherent differences in physical meanings and representations of multimodal data pose significant challenges in constructing effective correlations, often limiting the performance of mainstream machine learning based fault diagnosis approaches. The proposed method enhances the fault diagnosis capability of mainstream approaches through the fusion of multi-sensor data and visual data, with its core innovation residing in a multimodal fusion framework leveraging attention mechanisms to effectively integrate cross-dimensional representations of multivariate time-series data and imaging data. Compared to existing multimodal transformer techniques, this dual-strategy architecture enables the model to simultaneously capture shared systemic behaviors and modality-unique signatures, substantially elevating diagnosis precision. Experimental validation on real-world leak detection datasets demonstrates that the proposed model achieves F1-scores consistently surpassing 90 % across diverse marine monitoring scenarios, with quantitative evaluations further confirming its superior performance over conventional multivariate time-series diagnosis methods in establishing multimodal correlations, conclusively validating both technical excellence and engineering practicability.},
  archive      = {J_EAAI},
  author       = {Peng Zhang and Chaozhe Li and Shitao Peng and Bomu Tian and Si Luo and Yuewen Zhang and Taili Du},
  doi          = {10.1016/j.engappai.2025.112545},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112545},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multimodal multi-scale fusion network for leak detection in marine piping systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified rotating machinery health management framework leveraging large language models for diverse components, conditions, and tasks. <em>EAAI</em>, <em>162</em>, 112544. (<a href='https://doi.org/10.1016/j.engappai.2025.112544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the Rotating Machinery Large Language Model (RotLLM), a unified framework for rotating machinery health management that integrates deep learning with large language models (LLMs) to address diverse operational conditions, components, and health management tasks. RotLLM employs a novel Spectral Folding Network (SFN) to transform vibration spectrum into a unified feature space that preserves essential health state information. A dedicated projection layer then maps these features into the semantic domain of an LLM. The framework is trained using a three-stage strategy: first, pre-training the encoder on the Large-scale Multimodal Rotating Machinery (LMR) dataset, which comprises 237,298 vibration samples collected under hundreds of operating conditions; second, initializing the projection layer with textual health state labels; and finally, fine-tuning using parameter-efficient Low-Rank Adaptation (LoRA) with high-quality corpus for various health management tasks. Experimental evaluations demonstrate that RotLLM achieves state-of-the-art performance in fault classification, maintains strong robustness under noisy conditions, and delivers rapid multi-task inference with minimal computational overhead. The framework consistently outperforms conventional methods, enabling efficient, accurate, and context-aware health management for rotating machinery across diverse conditions and tasks. The dataset and source code are open-sourced ( https://github.com/SIA-IDE/RotLLM ), fostering collaboration, reproducibility, and broader adoption in industrial prognostics research.},
  archive      = {J_EAAI},
  author       = {Haotian Peng and Jie Gao and Jiawei Liu and Jinsong Du and Wei Wang},
  doi          = {10.1016/j.engappai.2025.112544},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112544},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A unified rotating machinery health management framework leveraging large language models for diverse components, conditions, and tasks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid neural network model for shale gas production prediction considering production plans and produced water. <em>EAAI</em>, <em>162</em>, 112543. (<a href='https://doi.org/10.1016/j.engappai.2025.112543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks have been widely applied to shale gas production prediction. However, current literature has two major flaws. Firstly, the delay issue can be observed in single-step prediction. Secondly, models that can be directly applied to newly developed wells are underresearched. This study presents a hybrid neural network combining fully connected (Dense) layers and long short-term memory (LSTM) layers to solve the two problems. In the proposed Dense-LSTM model, parameters regarding produced water and production plans are fed into the Dense layers while historical data is fed into the LSTM layers. The bottom-hole total flow rate converted from ground gas and water rates using volume factors is also included as an auxiliary parameter. The production plans made from the feature engineering can preserve the key information from shut-in periods while keeping a continuous prediction. The performance of the proposed model is demonstrated through ablation experiments and the comparison with popular decline curve models. For long-term prediction with window size w = 14 days, the proposed model’s mean cumulative error is 40.26% of that of vanilla LSTM at the end of the 3-year-long prediction interval. For window size w ′ = 100 days, the proposed model’s mean cumulative error is 77.93% of that of vanilla LSTM and 29.71% of that of the classic Arps model. The workflow of this study also sheds light on the construction of a universal prediction model for shale gas wells from different gas fields.},
  archive      = {J_EAAI},
  author       = {Yilun Dong and Youzhi Hao and Detang Lu},
  doi          = {10.1016/j.engappai.2025.112543},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112543},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid neural network model for shale gas production prediction considering production plans and produced water},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-source heterogeneous data fusion based fault diagnosis framework for manufacturing processes. <em>EAAI</em>, <em>162</em>, 112542. (<a href='https://doi.org/10.1016/j.engappai.2025.112542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis technologies are important means to ensure the production operation safety and product quality stability for manufacturing processes. After a fault occurs in the manufacturing processes, it may be characterized by high-frequency and high-dimensional structured time series data anomalies such as sensor data, or by unstructured data anomalies such as images. Traditionally, single structured sensor data is often used for constructing diagnosis models, the fault characteristics may not be adequately characterized, thus affecting the diagnosis performance. Therefore, in this paper, in order to make full use of multi-source data and obtain more comprehensive and accurate diagnosis results, a new multi-source heterogeneous data fusion based fault diagnosis framework is designed for manufacturing processes. Specifically, to solve the problem that the important information is ignored during data level fusion of multi-source data, an adaptive weight multi-source data fusion method is proposed. Furthermore, in response to the problem of feature redundancy in feature level fusion of heterogeneous data, a feature differentiation extraction and heterogeneous feature fusion method is proposed, of which a feature source discriminator is constructed for enhancing the complementarity of the extracted heterogeneous features, and feature concatenation is performed to improve the feature expression ability. Finally, the effectiveness and feasibility of the proposed framework is verified on actual datasets from the hot rolling process and the Tennessee Eastman process. Experimental results show that the proposed framework is both effective and feasible in fault diagnosis with multi-source heterogeneous data.},
  archive      = {J_EAAI},
  author       = {Liang Ma and Qikai Yang and Orestes Llanes-Santiago and Kaixiang Peng},
  doi          = {10.1016/j.engappai.2025.112542},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112542},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel multi-source heterogeneous data fusion based fault diagnosis framework for manufacturing processes},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reducing modal differences in zero-shot anomaly detection based on vision-language generation model. <em>EAAI</em>, <em>162</em>, 112541. (<a href='https://doi.org/10.1016/j.engappai.2025.112541'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot anomaly detection methods based on vision-language model rely on alignment between image and text. These methods ignore the inherent differences between different modalities, which is unfavorable for improving the alignment between modalities. This paper reduces modal differences between image and text by using guiding vision feature and text feature from the pre-trained vision-language generation model. The vision perception text embedding is constructed by adding guiding vision feature to the weight shared text prompt. The text perception vision embedding is extracted by a vision text fusion module. The fusion module is designed to promote the visual modality to perceive the textual information locally. Anomaly regions are detected by cosine similarity between cross-modal perception embeddings. Zero-shot anomaly detection performance is evaluated on five publicly available industrial anomaly detection datasets, and a real-world dataset about automotive plastic parts. Experimental results show that the proposed method achieves highly competitive anomaly detection performance on multiple evaluation metrics.},
  archive      = {J_EAAI},
  author       = {Yanan Song and Weiming Shen and Baisong Pan and Quanhui Wu and Dawei Gu},
  doi          = {10.1016/j.engappai.2025.112541},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112541},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reducing modal differences in zero-shot anomaly detection based on vision-language generation model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel short-term prediction method for distributed photovoltaic power generation considering extreme weather. <em>EAAI</em>, <em>162</em>, 112540. (<a href='https://doi.org/10.1016/j.engappai.2025.112540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed photovoltaic power plants are often impacted by various factors such as weather conditions and geographical locations, making it challenging to fully capture the spatial correlation characteristics among multiple photovoltaic plants. Furthermore, the failure to consider meteorological factors that influence photovoltaic output results in larger prediction errors during extreme weather events. To reduce prediction errors, this paper proposes a short-term photovoltaic forecasting method that considers meteorological factors, explores spatial correlations among photovoltaic plants, and captures temporal characteristics. Firstly, a Graph Attention Network is established to obtain spatial correlations between different plants while a Convolutional Neural Network is employed to extract feature information of meteorological factors. Then, the feature information from these two sources is integrated and input into a Long Short-Term Memory network, which is enhanced based on Spiking Neural P Systems to extract temporal characteristics of photovoltaic output and complete the prediction task. Finally, real-world power station datasets are utilized for validation and comparison with several typical photovoltaic prediction models. The results clearly show that the application of artificial intelligence in this proposed method can effectively improve the accuracy of distributed photovoltaic power forecasting, demonstrating the great potential of AI in the field of photovoltaic power prediction.},
  archive      = {J_EAAI},
  author       = {Xin Guan and Xiao Han and Jun Wang and Tao Wang},
  doi          = {10.1016/j.engappai.2025.112540},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112540},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel short-term prediction method for distributed photovoltaic power generation considering extreme weather},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An innovative method of multi-view face frontalization based on receptive field-enhanced conditional generative adversarial network. <em>EAAI</em>, <em>162</em>, 112539. (<a href='https://doi.org/10.1016/j.engappai.2025.112539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A series of theoretical and experimental investigations based on deep learning were conducted to enhance the accuracy and generalizability of face frontalization models. A series of theoretical investigations and experimental verifications based on deep learning are conducted to further enhance the face frontalization model's accuracy and generalizability. To address inadequate local feature extraction and the low realism in synthesized images, a receptive field-enhanced conditional generative adversarial network (RFC-GAN) is proposed to achieve multi-view face frontalization. RFC-GAN model integrates a novel configuration of multi-scale dilated convolutions in a multi-branch generator architecture to significantly expand the receptive field and improve feature extraction. The unique integration enhances the realism and detail of the generated images. Unlike conventional approaches that focus primarily on pixel-level accuracy, RFC-GAN introduces a perceptual loss component to enhance semantic content and structural integrity at the feature level. RFC-GAN has been experimentally validated on the Karolinska Directed Emotional Faces (KDEF) and Carnegie Mellon University Multiple Pose, Illumination, and Expression Face Database (CMU Multi-PIE). The generated facial expression images from RFC-GAN exhibit a higher degree of detailed texture reproduction in critical facial features such as the eyes, nose, and mouth. On the two datasets, the Peak Signal-to-Noise Ratio (PSNR) reaches 31.5185 for KDEF and 26.1851 for Multi-PIE, the Structural Similarity Index (SSIM) reaches 0.3604 for KDEF and 0.3965 for Multi-PIE, and the Learned Perceptual Image Patch Similarity (LPIPS) reaches 0.117 for KDEF and 0.408 for Multi-PIE, respectively. Compared to existing state-of-the-art methods, RFC-GAN exhibits marked improvements in these metrics, especially in detailed texture reproduction of critical facial features such as the eyes, nose, and mouth, establishing new benchmarks in face frontalization.},
  archive      = {J_EAAI},
  author       = {Yancong Zhou and Dongdong Wang},
  doi          = {10.1016/j.engappai.2025.112539},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112539},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An innovative method of multi-view face frontalization based on receptive field-enhanced conditional generative adversarial network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced air pollution spatiotemporal forecast model using frequency domain convolution and attention mechanism. <em>EAAI</em>, <em>162</em>, 112538. (<a href='https://doi.org/10.1016/j.engappai.2025.112538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of air pollution, which is crucial for public health and environmental management, often faces challenges in effectively capturing the complex and intertwined spatiotemporal dynamics of pollutants. Existing models frequently struggle to simultaneously account for broad periodic spatiotemporal dependencies as well as fine-grained local temporal patterns. This paper presents a novel deep learning architecture, the Fourier Convolutional Graph Transformer (FCGformer), specifically designed to overcome these limitations. FCGformer distinctively features a dual-module approach: a Global Module that constructs an integrated spatiotemporal graph and leverages Fourier transforms with frequency domain convolution to extract long-range dependencies and crucial periodicities; and a Local Module that employs inverse temporal embedding and self-attention to meticulously capture nuanced, short-term temporal variations. The key contribution of this work lies in the synergistic integration that enables FCGformer to effectively model complex pollutant behaviors, providing a more comprehensive understanding of both global contexts and local details. Extensive experiments demonstrate that FCGformer significantly outperforms state-of-the-art benchmark models in prediction accuracy, offering a promising advancement for improved air quality management.},
  archive      = {J_EAAI},
  author       = {Haiwei Yang and Ru Yang and Ling Ding and Shiqiang Du and Maozhen Li and Bo Zhang},
  doi          = {10.1016/j.engappai.2025.112538},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112538},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced air pollution spatiotemporal forecast model using frequency domain convolution and attention mechanism},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gate-guided spatial-channel reconstruction network: An efficient lightweight framework for steel surface defect detection. <em>EAAI</em>, <em>162</em>, 112537. (<a href='https://doi.org/10.1016/j.engappai.2025.112537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limitations in You Only Look Once version 8 (YOLOv8) for steel surface defect detection, including insufficient generalization of image enhancement, constrained feature representation capability in core modules, and poor adaptability of the loss function to scale variations and sample imbalance, this paper proposes the Gate-guided Spatial-channel Reconstruction Network, an efficient and lightweight improved network. Contrast-Limited Adaptive Histogram Equalization (CLAHE) is introduced to enhance local image details and contrast while reducing noise impact. The Gating Block and the Spatial-channel Reconstruction Block are designed to replace the original C2f (cross-stage partial bottleneck with two convolutions) module in YOLOv8, thereby enhancing feature representation capability and efficiency. The loss function is optimized using Wise-IoU (WIoU) and Slide Loss (SlideLoss) to improve convergence and robustness. The proposed network was evaluated on the Northeastern University Surface Defect Detection (NEU-DET) dataset (200 × 200 pixels) and the Chinese Academy of Sciences Defect Detection (GC10-DET) dataset (2048 × 1000 pixels). It demonstrated high detection accuracy, achieving the mean Average Precision at 50 % (mAP50) of 84.7 % and 79.4 %, respectively. Furthermore, the network maintains low complexity with only 3.6 million parameters and achieves a high detection speed of up to 154 frames per second (FPS). The Gate-guided Spatial-channel Reconstruction Network effectively detects surface defects on hot-rolled steel, achieving state-of-the-art detection accuracy. It successfully meets the requirements for precise and real-time steel surface defect detection under resource-constrained industrial conditions.},
  archive      = {J_EAAI},
  author       = {Wei Zhang},
  doi          = {10.1016/j.engappai.2025.112537},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112537},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Gate-guided spatial-channel reconstruction network: An efficient lightweight framework for steel surface defect detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor product-fault diagnosis-transformer based wind turbine blade fault prediction method. <em>EAAI</em>, <em>162</em>, 112535. (<a href='https://doi.org/10.1016/j.engappai.2025.112535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous iterative updating of wind turbine (WT) blade fault diagnosis (FD) technology, intelligent prediction methods based on supervisory control and data acquisition (SCADA) systems have gradually become advanced mainstream technology in the industry. However, despite the many advantages of SCADA data in fault prediction, its high-dimensional characteristics and highly unstable nature still pose significant challenges for practical applications. Accordingly, this study proposes an innovative WT blade fault prediction method based on tensor product dimensionality reduction and FD-Transformer (TP-FD-Transformer) methodology, which aims to effectively solve the problem of timely and accurate prediction of WT blade faults. The TP-FD-Transformer method combines the quantum dimensionality reduction technique with the FD-Transformer model to form a new framework for data processing and analysis. The TP-FD-Transformer method adopts the tensor product-relative position matrix composite dimensionality reduction technique, which effectively reduces the dimensionality and complexity of SCADA data while preserving its features. After data processing is completed, the TP-FD-Transformer method utilizes the FD-Transformer model for deep learning training. The FD-Transformer model has been improved for complex time series data and can effectively capture potential features in the data. The experiments under the open dataset show that the TP-FD-Transformer method demonstrates excellent prediction ability in the field of WT blade FD, with an accuracy rate of 93.65 %. The research findings verify that TP-FD-Transformer method provides a feasible solution for the intelligent diagnosis of WT blade faults, with broad application prospects and significant practical significance.},
  archive      = {J_EAAI},
  author       = {Linfei Yin and Yuhan Liu and Nannan Wang},
  doi          = {10.1016/j.engappai.2025.112535},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112535},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tensor product-fault diagnosis-transformer based wind turbine blade fault prediction method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid physics-based and data-driven method for the rotor angle prediction. <em>EAAI</em>, <em>162</em>, 112533. (<a href='https://doi.org/10.1016/j.engappai.2025.112533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods are widely employed for transient stability analysis in power systems. However, the prediction performance can be adversely affected by undesirable factors in the measured data. To alleviate the effect of the undesirable factors, a hybrid physics-based and data-driven prediction network of the rotor angle trajectory is proposed in this paper. The prediction model embeds the rotor equation to form a dynamic learning model that conforms to the actual physical law. The physical consistency of the prediction results is guaranteed. Meanwhile, a dynamic error derivative integral network incorporating the Runge–Kutta method is proposed to correct the final results. The accuracy of the prediction can be improved. Finally, it is tested in the IEEE 39-bus system and the East China Power Grid system. The test results show that the model significantly outperforms other comparative models. And the dependence on the quality of measured data can be alleviated effectively.},
  archive      = {J_EAAI},
  author       = {Lingzhe Zhang and Dong Huang and Huaiyuan Wang},
  doi          = {10.1016/j.engappai.2025.112533},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112533},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid physics-based and data-driven method for the rotor angle prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed machine learning for near real-time stress prediction on a structural component: Application for landing gears. <em>EAAI</em>, <em>162</em>, 112532. (<a href='https://doi.org/10.1016/j.engappai.2025.112532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightweight design constitutes a pivotal research and development objective for next-generation landing gear systems. Nevertheless, achieving reduced weight while maintaining structural safety and reliability presents considerable challenges. The establishment of a digital twin (DT) for structural health monitoring (SHM) offers a promising approach to address these concerns across the design, testing, and operational lifecycle of landing gears. In this study, we develop a physics-informed neural network (PINN) model for near real-time stress prediction on the drag strut of a nose landing gear (NLG), specifically for an A320-type aircraft, serving as a foundational component of a DT system. The proposed PINN framework directly outputs displacement fields while deriving stresses as secondary quantities, effectively incorporating the fundamental equations of linear elasticity into the loss function. Displacement boundary conditions, informed by finite element method (FEM) simulations, are integrated as penalty terms to enhance trainability and physical consistency. The training dataset is constructed using load cases statistically representative of actual landing gear operations, with high-fidelity FEM providing corresponding displacement and stress references. The model demonstrates strong predictive accuracy, with relative errors between 5% and 7% compared to FEM results, and significantly outperforms both pure stress-output PINNs and conventional deep neural networks (DNNs). Moreover, the trained PINN achieves inference times within seconds under time-varying loads, highlighting its capability for near real-time stress monitoring. This work underscores the potential of physics-informed machine learning for enhancing DT-enabled SHM systems in safety-critical aerospace structures.},
  archive      = {J_EAAI},
  author       = {Zixuan Zhu and Yifan Zhao and Agusmian Partogi Ompusunggu},
  doi          = {10.1016/j.engappai.2025.112532},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112532},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed machine learning for near real-time stress prediction on a structural component: Application for landing gears},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced forest fire detection via dynamic multiscale fusion and contextual partial cross features. <em>EAAI</em>, <em>162</em>, 112531. (<a href='https://doi.org/10.1016/j.engappai.2025.112531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely and accurate detection of forest fires, particularly in the early stages when smoke and small flames are present, is crucial for minimizing ecological damage and improving the effectiveness of emergency response. However, existing methods face challenges such as missing edge information, ineffective multi-scale feature fusion, and low accuracy when identifying small or distant targets in complex forest conditions. To address these issues, a novel detection framework is proposed, called the Dynamic Contextual Shallow Network (DCSNet). This framework enhances detection performance and real-time efficiency. The proposed method incorporates three key components: (1) the Contextual Partial Cross Feature Network (CPCFNet), which employs a reparameterized non-local attention mechanism and partial channel separation to strengthen contextual representation; (2) the Dynamic Multiscale Fusion Pyramid Network (DMFPN), which uses dynamic sampling and deformable convolution to fuse multi-scale features adaptively; and (3) the Shallow Feature Detection Layer (SFDL), which refines shallow features to improve the detection of small smoke and flame targets. Experimental evaluations on visible-light and infrared remote sensing datasets collected by unmanned aerial vehicles (UAVs) demonstrate the effectiveness of DCSNet. Specifically, DCSNet achieves an average mean average precision (mAP) at 50 % intersection over union (IoU) of 76.0 %, a frame rate of 283 frames per second (FPS), and an F1-score of 71.9 % on the visible-light dataset. On the infrared dataset, the framework achieves an mAP@50 of 77.5 %, an mAP@50:95 of 45.5 %, and an F1 score of 72.9 %. These results suggest that DCSNet provides high accuracy and robustness in the real-time detection of forest fires under diverse environmental conditions. The code and datasets are available at https://github.com/Lili-wang-del/DCSNet .},
  archive      = {J_EAAI},
  author       = {Lili Wang and Lei Guo and Haiyan Li and Bingbing He and Jundong Yang and Yaqun Huang},
  doi          = {10.1016/j.engappai.2025.112531},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112531},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced forest fire detection via dynamic multiscale fusion and contextual partial cross features},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced targeted attacks on graph neural networks via average gradient and perturbation optimization. <em>EAAI</em>, <em>162</em>, 112530. (<a href='https://doi.org/10.1016/j.engappai.2025.112530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) are vulnerable to adversarial attacks that cause performance degradation by adding small perturbations to the graph. Gradient-based attacks are among the most widely used methods and have demonstrated strong performance across various attack scenarios. However, most gradient attacks use greedy strategies to generate perturbations, which tend to fall into local optima, leading to underperformance of the attack. To address the above problem, we propose an attack (Average Gradient and Perturbation Optimization Attack, AGPOA) on GNNs, which consists of an average gradient calculation and a perturbation optimization module. In the average gradient calculation module, we compute the average of the gradient information over all moments to guide the attack to generate perturbed edges, which stabilizes the direction of the attack update and gets rid of undesirable local maxima. We use a perturbation optimization module to limit the attack budget and further improve performance. Furthermore, we demonstrate the theoretical superiority of AGPOA over traditional gradient-based attack methods through attack loss variance. The experimental results show that AGPOA improves the misclassification rate by 2%–8% compared to other state-of-the-art models in the node classification task.},
  archive      = {J_EAAI},
  author       = {Yang Chen and Bin Zhou and Haixing Zhao and Padarti Vijaya Kumar},
  doi          = {10.1016/j.engappai.2025.112530},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112530},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced targeted attacks on graph neural networks via average gradient and perturbation optimization},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-free safe deep reinforcement learning for grid-to-vehicle management considering grid constraints and transformer thermal stress. <em>EAAI</em>, <em>162</em>, 112529. (<a href='https://doi.org/10.1016/j.engappai.2025.112529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing penetration of Electric Vehicles (EVs) presents challenges to the distribution grid, due to more volatile power profiles and higher peak demand. One key research question is how to accommodate EVs with limited-capacity grid equipment, such as transformers and lines. However, uncertainties from the EV side and the complexity of grid equipment models challenge the performance of the control strategies implemented. Moreover, the thermal loading of the transformer is often neglected. In this work, we propose a fully model-free, safe Deep Reinforcement Learning (DRL)- based grid-to-vehicle management strategy to avoid electric and thermal overloading of the transformer and power grid constraint violation. The management strategy is based on Projection-based Constraint Policy Optimization (PCPO) and takes only the observable information from the grid and vehicles. The target is to maximize energy delivery to the EV fleet while considering safe constraints, such as transformer thermal loading, voltage magnitude limits, and line loading limits. We compared the proposed strategy with conventional DRL and other safe DRL methods and investigated its robustness against higher ambient temperatures. The results show that the proposed strategy can deliver 92 % energy and reduce violations of the grid and transformers, while the other benchmarks deliver less than 80 %. The robustness test demonstrates that the proposed strategy is effective in various temperature. Moreover, the proposed strategy can effectively reduce at most 90 % of the transformer aging incurred by the thermal stress, compared with the uncontrolled charging.},
  archive      = {J_EAAI},
  author       = {Zhewei Zhang and Rémy Rigo-Mariani and Nouredine Hadjsaid and Yan Xu},
  doi          = {10.1016/j.engappai.2025.112529},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112529},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Model-free safe deep reinforcement learning for grid-to-vehicle management considering grid constraints and transformer thermal stress},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probability forecasting for multivariate urban water demand using temporal convolutional network based on quantile regression and parzen window. <em>EAAI</em>, <em>162</em>, 112528. (<a href='https://doi.org/10.1016/j.engappai.2025.112528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probability prediction can provide more abundant information about uncertainties in future water demand, which is gaining increasing attention in building economical and reliable water resource management plans. However, most existing literature on water demand prediction focus on provide deterministic point prediction results. To overcome this problem, a novel hybrid probability forecasting model based on quantile regression temporal convolutional network and Parzen window is proposed for the probability density forecast of multivariate urban water demand. Firstly, to address the complex coupling relationship between water demand and multiple influencing factors, a random forest-based feature selection method is employed to eliminate the redundant variables. Then, a discrete wavelet transform is deployed to decompose the original series into a variety of characteristic subseries to reduce fluctuations of the original water demand series. Secondly, a quantile regression-based temporal convolutional neural network is employed to obtain the conditional quantiles of future water demand. Moreover, a probability density prediction method based on Parzen window estimation is developed to further obtain the distribution information of prediction uncertainty. Finally, a real-world multivariate dataset from a water plant in Suzhou, China, is used for comparison experiments with state-of-the-art models. The comparison results show that the proposed model has achieved an average improvement of 15.4 % and 53.3 % in interval prediction and probability density prediction, respectively. It shows that the proposed model is a reliable prediction model that can assist policymakers to optimize the management of urban water demand.},
  archive      = {J_EAAI},
  author       = {Jun Guo and Qingya Meng and Baigang Du and Hui Sun},
  doi          = {10.1016/j.engappai.2025.112528},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112528},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probability forecasting for multivariate urban water demand using temporal convolutional network based on quantile regression and parzen window},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex T-spherical fuzzy yager prioritized weighted aggregation for prioritizing waste management strategies: A case study from delhi. <em>EAAI</em>, <em>162</em>, 112527. (<a href='https://doi.org/10.1016/j.engappai.2025.112527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient waste management is crucial for addressing urban challenges in densely populated areas like Delhi. This study is motivated by a key research gap: the need for an advanced Multi-Criteria Decision-Making (MCDM) framework capable of handling both two-dimensional uncertainty and the prioritized nature of criteria in such complex problems. Our primary contribution is a novel framework integrating the flexibility of Complex T-Spherical Fuzzy Sets (CT-SFS) with Yager’s prioritized aggregation. Unlike traditional T-SFS, which are limited to a one-dimensional representation, CT-SFS incorporates both amplitude and phase information for Membership Degree (MD), Neutral Degree (ND), and Non-membership Degree (NMD), offering a nuanced model for expert evaluations. The framework introduces two innovative operators: the Complex T-Spherical Fuzzy Yager Prioritized Weighted Average (CT-SFYPWA) and the Complex T-Spherical Fuzzy Yager Prioritized Weighted Geometric (CT-SFYPWG). These operators uniquely incorporate Yager’s prioritized aggregation, allowing decision-makers to assign hierarchical importance to critical criteria, which is vital for effective resource allocation in urban waste management. The framework’s practical value is demonstrated through a detailed case study prioritizing waste management strategies in Delhi. Rigorous numerical analysis, sensitivity tests, and comparative evaluations confirm the framework’s robustness, adaptability, and distinct advantages over existing methods. Applying this framework to Delhi, we found that a holistic, integrated waste management system is the most promising strategy, outperforming capital-intensive projects like Waste-to-Energy. Our work offers a powerful, structured methodology for cities to make more nuanced, forward-looking decisions and advances MCDM theory by integrating prioritized aggregation within the CT-SFS environment.},
  archive      = {J_EAAI},
  author       = {Fathima Banu M. and S. Solaiappan and Subramanian Petchimuthu and Abrar Hussain},
  doi          = {10.1016/j.engappai.2025.112527},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112527},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complex T-spherical fuzzy yager prioritized weighted aggregation for prioritizing waste management strategies: A case study from delhi},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Critical nodes detection for complex networks via knowledge-guided evolutionary framework. <em>EAAI</em>, <em>162</em>, 112526. (<a href='https://doi.org/10.1016/j.engappai.2025.112526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Critical Node Problem (CNP) focuses on identifying critical nodes within complex networks. These nodes play a crucial role in maintaining connectivity, and their removal impacts network performance. Among CNP variants, CNP-1a — which minimizes pairwise connectivity after removing a limited number of nodes — has attracted significant research attention due to its NP-hard nature and applications in diverse fields like epidemic control and infrastructure resilience. While state-of-the-art methods leverage memetic algorithms and variable populations, they fundamentally rely on random initialization that often converges to local optima. This limitation arises because traditional methods fail to capture higher-order topological dependencies. To address this gap, we propose K2GA, a knowledge-guided genetic algorithm initialized by a graph attention network (GAT). The GAT embeds networks into low-dimensional spaces, assigning topology-aware attention weights to nodes that guide population initialization. K2GA then employs a hybrid genetic algorithm with a local search process to identify an optimal set of critical nodes. The local search process utilizes a cut node-based greedy strategy. Experiments on 26 real-world networks demonstrate that K2GA outperforms state-of-the-art methods in terms of the best, median, and average objective values, establishing new upper bounds for minimization in eight cases. This work pioneers a GAT-guided evolutionary search framework, offering a novel paradigm for solving CNP.},
  archive      = {J_EAAI},
  author       = {Chanjuan Liu and Shike Ge and Zhihan Chen and Wenbin Pei and Enqiang Zhu and Hisao Ishibuchi},
  doi          = {10.1016/j.engappai.2025.112526},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112526},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Critical nodes detection for complex networks via knowledge-guided evolutionary framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient framework for general long-horizon time series forecasting with mamba and diffusion probabilistic models. <em>EAAI</em>, <em>162</em>, 112525. (<a href='https://doi.org/10.1016/j.engappai.2025.112525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting plays an essential role in supporting critical decision-making processes in risk management and resource allocation in various fields, including finance, transportation, industrial systems, etc. Conventional models can effectively capture volatility and, are proficient in handling specific patterns, such as the AutoRegressive Integrated Moving Average model (ARIMA) and the Generalized AutoRegressive Conditional Heteroskedasticity model (GARCH). Nonetheless, these models meet many challenges, such as high dimensionality, non-stationarity, and nonlinearity inherent in real-world data. Although deep learning methodologies can provide better performance, they may still suffer from long-term errors and heightened computational expenses. A novel framework named Mamba Diffusion Probabilistic Models (MambaDiffTS) is proposed, which integrates Mamba’s state space model with a frequency-aware diffusion process grounded in Denoising Diffusion Probabilistic Models (DDPM). Mamba’s selective state transitions enable linear-time modeling of long-range dependencies; at the same time, frequency-aware spectral decomposition isolates trends and seasonality through Fourier regularization. Furthermore, the implementation of spectral energy-guided noise scheduling preserves temporal fidelity. Extensive experiments on diverse benchmarks-financial volatility, industrial IoT sensor data, and climate modeling-demonstrate MambaDiffTS’s superiority. Notably, on stock forecasting tasks, MambaDiffTS reduces Mean Squared Error (MSE) by approximately 18.6% compared to the best-performing baseline, and substantially outperforms diffusion models, all while maintaining linear computational complexity. The proposed MambaDiffTS facilitates scalable forecasting over extended horizons.},
  archive      = {J_EAAI},
  author       = {Wenjing Wang and Qilei Li and Ziwu Jiang and Deqian Fu and David Camacho},
  doi          = {10.1016/j.engappai.2025.112525},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112525},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient framework for general long-horizon time series forecasting with mamba and diffusion probabilistic models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selecting after sales provider of complex product based on game and matching framework. <em>EAAI</em>, <em>162</em>, 112524. (<a href='https://doi.org/10.1016/j.engappai.2025.112524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a strategic enabler of high-end manufacturing, the high-quality evolution of complex equipment is indispensable for any nation aspiring to industrial leadership. After sales service (AS) long relegated to a support function, which has emerged as a decisive determinant of product life-cycle value and, consequently, of this transformative journey. This study therefore investigates the technological innovation of AS for complex products through a Stackelberg game that captures the collaborative dynamics between an original equipment manufacturer (OEM) and an after-sales service provider (ASP). We derive the necessary and sufficient conditions under which an ASP finds participation economically viable, then embed these conditions into a multi-criteria matching framework that links ASP capabilities with spare-part requirements. Leveraging an entropy weighted DEMATEL (Decision-making Trial and Evaluation Laboratory) hybrid and we first quantify the causal salience of matching attributes and build a parsimonious evaluation index system. Next, by explicitly encoding bilateral attribute preferences, we formulate a two-sided matching model that identifies the Pareto-optimal ASP portfolio for any given product architecture. Finally, backward induction over the integrated game-matching structure yields a prescriptive tool that not only screens ASPs but also prescribes contractual levers to sustain long-term co-innovation. The proposed framework thus unifies strategic participation incentives with operational compatibility, offering OEMs a rigorous, implementable roadmap for selecting and governing after-sales partners in the era of servitized, high-stakes manufacturing.},
  archive      = {J_EAAI},
  author       = {Xin Huang and Xiaoyan Qi and Xiaojuan Xu},
  doi          = {10.1016/j.engappai.2025.112524},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112524},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Selecting after sales provider of complex product based on game and matching framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PLDs-CNN-ridge-ELM: Interpretable lightweight waste classification framework. <em>EAAI</em>, <em>162</em>, 112522. (<a href='https://doi.org/10.1016/j.engappai.2025.112522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accelerating global population growth and expanding economic activities have resulted in a notable increase in waste generation, necessitating accurate and efficient waste classification systems for sustainable waste management. This research presents a novel two-stage waste classification model leveraging a Lightweight Parallel Depth-wise Separable Convolutional Neural Network (PLDs-CNN), combined with a Ridge Regression Extreme Learning Machine (Ridge-ELM) classifier, using waste images as input. The proposed system efficiently classifies waste into four primary categories (hazardous, household, recyclable, and residual) in the first stage and further refines the classification into twelve subcategories in the second stage. Featuring a lightweight architecture of nine layers and about 1.09 million parameters, the PLDs-CNN model achieves high accuracy with substantially reduced computational overhead, outperforming many deeper networks. In the four-class classification stage, the system achieves an average accuracy of 99 %, with precision, recall, F1-score, and receiver operating characteristics (ROC)-area under the curve (AUC) values of 97.25 ± 0.02 %, 96 ± 0.03 %, 96.5 ± 0.01 %, and 99.28 %, respectively. In the twelve-class classification, the model continues to deliver superior results, with 96 % accuracy and equally strong precision, recall, and F1-score metrics. The system is supported by a real-time hardware architecture, featuring a user-centric Graphical User Interface (GUI), a webcam-enabled conveyor belt sorting mechanism, and a 2-axis pan-tilt system for automated waste sorting. Additionally, the model's interpretability is significantly improved through the integration of Shapley Additive Explanations (SHAP), which provides important perspectives into the decision-making process, increasing transparency and trustworthiness in real-world applications. The proposed framework not only surpasses conventional methods in both accuracy and computational efficiency but also emphasizes sustainability by facilitating cost-effective and scalable waste management solutions aimed at promoting recycling and resource reuse.},
  archive      = {J_EAAI},
  author       = {Mansura Naznine and Md. Nahiduzzaman and Md. Jawadul Karim and Md. Faysal Ahamed and Abdus Salam and Mohamed Arselene Ayari and Amith Khandakar and Azad Ashraf and Mominul Ahsan and Julfikar Haider},
  doi          = {10.1016/j.engappai.2025.112522},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112522},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PLDs-CNN-ridge-ELM: Interpretable lightweight waste classification framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable interval prediction of dam displacement based on variational autoencoder and improved temporal fusion transformer considering solar radiation effects. <em>EAAI</em>, <em>162</em>, 112520. (<a href='https://doi.org/10.1016/j.engappai.2025.112520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the safety of dams is critical to maintaining national economic development and social stability, requiring the implementation of accurate displacement prediction methods for early detection of structural anomalies and effective risk mitigation. However, existing statistical models primarily focus on point predictions, failing to quantify the uncertainty in displacement variations, and often neglect the critical environmental factor of solar radiation. To address these limitations, this study proposes a novel interpretable interval prediction framework that integrates solar radiation factors into an advanced hydrostatic-temperature-time (AHTT) model. A variational autoencoder (VAE) is employed to extract robust latent features from a large volume of measured temperature data, effectively reducing temperature-related noise. Subsequently, an improved temporal fusion transformer method is introduced to probabilistic dam displacement prediction. This method uses an enhanced quantile loss function based on the Huber loss to generate both point and interval predictions that dynamically reflect the prediction uncertainty. In addition, an interpretable multi-head attention module is incorporated to quantify the contribution of each environmental factor. Hyperparameter tuning of the improved temporal fusion transformer is further optimized using Bayesian optimization based on the tree-structured Parzen estimator (TPE), which improves prediction accuracy. Engineering case studies validate that the proposed model not only achieves the highest point prediction accuracy, but also provides narrower prediction intervals with the best coverage width criterion. Ablation experiments and interpretability analyses further confirm the significant impact of solar radiation on dam displacement, providing valuable insights for the development of dam displacement prediction models and risk-informed decision making.},
  archive      = {J_EAAI},
  author       = {Taiqi Lu and Hao Gu and Chongshi Gu and Chenfei Shao and Yiming Wang and Dongyang Yuan},
  doi          = {10.1016/j.engappai.2025.112520},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112520},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable interval prediction of dam displacement based on variational autoencoder and improved temporal fusion transformer considering solar radiation effects},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An undersampling method for software defect prediction based on hilbert curve mapping distance. <em>EAAI</em>, <em>162</em>, 112519. (<a href='https://doi.org/10.1016/j.engappai.2025.112519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class imbalance problem presents a significant challenge in software defect prediction. The undersampling method enhances prediction performance by eliminating non-defective instances, thereby enabling the model to focus more on defective instances. However, the effective selection of representative non-defective instances while preserving the overall data distribution remains a critical challenge. Inspired by the space-filling property of Hilbert curves, we propose the H ilbert C urve M apping D istance U ndersampling (HCMDU) method for software defect prediction. This method first maps instances to Hamming space to ensure that similar instances are positioned closer together in the space. Instance circular domains are then partitioned based on the Hamming distance between them, which facilitates the exploration of instance variability within a localized region. Finally, the Hilbert curve mapping distance is employed to further uncover the data distribution pattern within the instance circular domains. The experimental results demonstrate that HCMDU delivers outstanding performance across 16 randomly selected software defect datasets in both Random Forest (RF) and Classification and Regression Trees (CART). Moreover, the results are further corroborated by the Friedman ranking and Nemenyi post-hoc test, which indicate that HCMDU significantly improves the performance of software defect prediction.},
  archive      = {J_EAAI},
  author       = {Yu Tang and Ye Du and Ang Li and Ming-song Yang and Yan Xia},
  doi          = {10.1016/j.engappai.2025.112519},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112519},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An undersampling method for software defect prediction based on hilbert curve mapping distance},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised fault diagnosis method for rolling bearings based on federated universal domain adaptation. <em>EAAI</em>, <em>162</em>, 112518. (<a href='https://doi.org/10.1016/j.engappai.2025.112518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issues of low diagnostic model accuracy caused by non-sharing of rolling bearing private data, distribution differences, and label space discrepancies across multiple clients, as well as the challenges that certain clients face in obtaining labeled data, an unsupervised fault diagnosis method is proposed for rolling bearings based on federated universal domain adaptation (FUDA). First, privacy protection during the transmission process in federated learning is ensured by implementing random mapping at local clients. Second, the central server employs the proposed mixed radial basis kernel-maximum mean discrepancy (MR-MMD) method to further mitigate distributional disparities between the feature spaces of source and target clients. This achieves unsupervised features alignment between these features. Third, margin vectors are introduced to tackle label space disparities between source and target clients, enabling effective separation of unknown class samples in the dataset of the target client. Finally, a dynamic weighted loss fusion strategy is designed to adaptively optimize the weight ratios of different losses. This enhancement facilitates the learning efficiency of the model. Experimental validation on two datasets demonstrates that the proposed approach can achieve average accuracies of 95.6 % and 87.7 % for the respective datasets. Compared with other methods, it represents improvements of 6.5 % and 8.1 %, while training time is reduced by at least 27 %. These results validate the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Shouqiang Kang and Yulin Sun and Xinrui Li and Yujing Wang and Qingyan Wang and Xintao Liang},
  doi          = {10.1016/j.engappai.2025.112518},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112518},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised fault diagnosis method for rolling bearings based on federated universal domain adaptation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-scale feature extraction and fusion framework based on wavelet Kolmogorov–Arnold networks and parallel bi-directional gated recurrent units for electric load forecasting. <em>EAAI</em>, <em>162</em>, 112517. (<a href='https://doi.org/10.1016/j.engappai.2025.112517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term electric load forecasting remains challenged by the dual requirements of accuracy and robustness due to the combined effects of strong seasonality, multi-scale spikes, and stochastic disturbances. To address this, we propose a novel multi-scale forecasting framework, NP-WavKAN-Fusion, which integrates Neural Prophet for data decomposition and a Wavelet-based Kolmogorov–Arnold Network (WavKAN) with learnable wavelet kernels for multi-scale encoding. This fusion model utilizes a Bi-directional Gated Recurrent Unit (BiGRU) to capture long-term temporal dependencies and an adaptive feature fusion gate (AFF) to dynamically re-weight static and dynamic features for final load predictions. Extensive experiments on two public datasets from Australia and Morocco show that NP-WavKAN-Fusion consistently outperforms traditional models, reducing the mean absolute error by at least 30 %. For multi-step forecasting tasks, NP-WavKAN-Fusion maintains error inflation within 15 %, demonstrating superior performance compared to state-of-the-art long-sequence models such as Informer and PatchTST. The Diebold–Mariano test confirms that NP-WavKAN-Fusion yields statistically significant improvements, with 19 out of 20 comparisons showing lower errors. Ablation studies show that removing either the Neural Prophet component or the AFF significantly increases the forecasting error, validating the necessity of our layered denoising and fusion strategies. The proposed NP-WavKAN-Fusion framework demonstrates strong potential for real-world applications in electric load forecasting, offering robust performance under various temporal and non-stationary conditions.},
  archive      = {J_EAAI},
  author       = {Chunliang Mai and Lixin Zhang and Xuewei Chao and Xue Hu and Omar Behar},
  doi          = {10.1016/j.engappai.2025.112517},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112517},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-scale feature extraction and fusion framework based on wavelet Kolmogorov–Arnold networks and parallel bi-directional gated recurrent units for electric load forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resilient kernel-based unsupervised multi-view feature selection via compact binary hashing. <em>EAAI</em>, <em>162</em>, 112515. (<a href='https://doi.org/10.1016/j.engappai.2025.112515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view feature selection across diverse views identifying a compact subset of the most informative feature across various data views without relying on labeled information. While most of the solutions are limited to linear multi-view data or utilize weakly-supervised single-label learning to assist in feature selection, leading to the loss of valuable semantic information, especially when dealing with complex real-world multi-view datasets. To overcome these limitations, we introduce a novel Resilient Kernel-based Unsupervised Multi-view Feature Selection via compact Binary Hashing (RKUMBH), which aims to search a robust and consistent graph representation across views, leveraging binary hashing codes to guide feature selection. Specifically, we first standardize the dimensionality of multi-view data by using non-linear kernel mapping. Then, we explore consistent graph structures across different views by fusing individual similarity graph of each view under a self-representation guidance. Moreover, the low-rank constraints are used to preserve the primary structures and patterns embedding within the data, and an unsupervised hashing feature selection framework is conducted to generate reliable hashing codes across views. Additionally, we design a customized iterative optimization method to solve the unified model. Extensive experiments on six public multi-view datasets demonstrate that our proposed method obtains state-of-the-art results compared to existing works for both clustering and feature selection tasks.},
  archive      = {J_EAAI},
  author       = {Rongyao Hu and Mengmeng Zhan and Jiangzhang Gan and Li Li and Fei Ye and Tong Liu},
  doi          = {10.1016/j.engappai.2025.112515},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112515},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Resilient kernel-based unsupervised multi-view feature selection via compact binary hashing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering the geometry-dependent optical asymmetry of gold nanorods helical assemblies using artificial neural networks. <em>EAAI</em>, <em>162</em>, 112513. (<a href='https://doi.org/10.1016/j.engappai.2025.112513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optical asymmetry of gold nanorods (Au-NRs) helical assemblies is well-documented with a wide range of applications. Nevertheless, the geometry-dependent optical asymmetry within these assemblies has not been adequately explored and quantified. The present study proposes a novel approach to predict the optical asymmetry of Au-NRs helical assemblies based on geometric characteristics using artificial neural networks (ANN). The performance of the ANN termed 3 N H L 50 N N was significantly enhanced through the optimization of the hidden layer and node, resulting in an R 2 of the outcomes exceeding 0.998 and a reduction in computational time exceeding 99.99 %. In instances where the specific geometric characteristics are needed to attain a desired optical asymmetry, a retrieval of geometric characteristics of Au-NRs helical assemblies was additionally investigated using a traversing mechanism featured particle swarm optimization (PSO) algorithm. The results of the retrieval were obtained within 6 s and demonstrate a high degree of accuracy and reliability. The combination of the 3 N H L 50 N N and the PSO algorithm is capable of accurately predicting the optical asymmetry of Au-NRs helical assemblies and the retrieval of the geometry characteristics, thereby enabling the quantitative understanding of their overall geometry-dependent optical asymmetry.},
  archive      = {J_EAAI},
  author       = {Yang Liu and Yongguang Chen and Xiyang Wei and Jianhua Shang and Lina Zhao},
  doi          = {10.1016/j.engappai.2025.112513},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112513},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Uncovering the geometry-dependent optical asymmetry of gold nanorods helical assemblies using artificial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting worker loss of balance events from point cloud sequence using unsupervised motion-pose learning. <em>EAAI</em>, <em>162</em>, 112512. (<a href='https://doi.org/10.1016/j.engappai.2025.112512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workers' loss of balance (LB), such as slip and trip, may lead to severe injuries and even fatalities. Existing methods for detecting LB typically rely on wearable sensors and focus on specific body parts. This study introduces a novel, non-contact approach utilizing light detection and ranging (LiDAR) technology to detect LB events. By capturing full-body point cloud data, the proposed method extracts both static pose and dynamic motion features across multiple body sections and detects LB events through unsupervised learning. The high-dimensional point cloud sequence is transformed into interpretable gait features, enabling effective unsupervised learning through sequence reconstruction. A two-stream network and fusion strategy are also developed to combine pose and motion features for final LB detection. Experiments with various LB events demonstrate the method's effectiveness, achieving an F1 score of 0.98 and a recall of 0.98. Our analysis reveals that integrating features from multiple body parts and the fusion of pose and motion information significantly enhances detection performance. This study offers a promising alternative to traditional methods, providing effective, non-intrusive monitoring of worker safety in dynamic construction environments.},
  archive      = {J_EAAI},
  author       = {Mingyu Zhang and Lei Wang and Yinong Hu and Shuai Han and Jiawen Zhang and Heng Li},
  doi          = {10.1016/j.engappai.2025.112512},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112512},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting worker loss of balance events from point cloud sequence using unsupervised motion-pose learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human motion prediction using mixture-of-branch graph convolutional network. <em>EAAI</em>, <em>162</em>, 112511. (<a href='https://doi.org/10.1016/j.engappai.2025.112511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the same spatio-temporal feature extraction network to predict multiple types of human motions pose a challenge for the prediction model to achieve optimal performance. To address this issue and achieve differentiated training, we propose a novel Mixture-of-Branch Graph Convolutional Network model which simultaneously inserts human motion sequences into a multi-branch human motion prediction module and a branch weight allocation module. When generating the final prediction sequence, weights are assigned to the prediction results of each branch. Mixture-of-Branch Graph Convolutional Network employs loss values to control competition rather than cooperation among branches, effectively addressing the issue of mutual influence between sequences during network training. To the best of our knowledge, this marks the inaugural utilization of a Mixture-of-Branch network in the realm of human motion prediction. To optimize the efficiency of the multi-branch model and reduce prediction complexity, we introduce a spatio-temporal feature extraction method for the human skeleton that accommodates Euclidean geometric transformations. This method liberates the Mixture-of-Branch Graph Convolutional Network from the constraints of additional branches, allowing it to handle similar motion sequences under varying degrees of translation or rotation, where feature matrices may exhibit significant differences. The proposal of Mixture-of-Branch Graph Convolutional Network and its related experiments represent our contribution to the Artificial Intelligence field, with significant potential value in engineering applications as well. Mixture-of-Branch Graph Convolutional Network is tested on the Human3.6M, Carnegie Mellon University Motion Capture, and Three-Dimensional Human Pose in the Wild datasets, achieving high performance. Particularly noteworthy is the 7% overall performance improvement in Mean Per Joints Position Error prediction on the Carnegie Mellon University Motion Capture dataset.},
  archive      = {J_EAAI},
  author       = {Xianshan Li and Ang Gao and Xingxing Ning and Fengda Zhao},
  doi          = {10.1016/j.engappai.2025.112511},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112511},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Human motion prediction using mixture-of-branch graph convolutional network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid multivariate normal boundary intersection approach with post-optimization assisted by mixture design of experiments. <em>EAAI</em>, <em>162</em>, 112510. (<a href='https://doi.org/10.1016/j.engappai.2025.112510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a hybrid multiobjective optimization approach for identifying Pareto-optimal solutions by combining evaluation metrics. Using response surface models built from rotated factor scores, the algorithm analyzes the influence of weights on solutions through performance metrics, applying a weighted combination as a post-optimization strategy. The methodology introduces innovations such as the combination of independent functions, polynomial analysis to discover intermediate weights, and the use of prediction-based metrics. To illustrate application of the methodology, a case study was conducted on the turning process of tempered cylindrical steel bars, evaluating dimensions of reliability, quality, and economic performance. The best solution obtained included the following input variables: a cutting speed of 147.792 m per minute, a feed rate of 0.156 mm per revolution, and a depth of cut of 0.247 mm. The resulting output variables included a mean tool life of 46.316 min, mean time to failure of 47.164 min, a wear rate of 0.006 mm per minute, an average surface roughness of 0.746 μm, a total surface roughness of 3.406 μm, a process cost of 3.721 dollars, a return on investment of 0.187, and overall equipment effectiveness of 0.387. Comparisons were made with other optimization methods, revealing satisfactory performance based on key metrics. The methodology was also tested on benchmark functions to assess its robustness and adaptability to different scenarios. In addition, the method was implemented in an online quality monitoring system using the Random Forest machine learning algorithm, and results indicate that optimal conditions can be identified quickly and effectively.},
  archive      = {J_EAAI},
  author       = {Matheus Costa Pereira and Caio Tertuliano Ribeiro and Ronã Rinston Amaury Mendes and Paulo Henrique da Silva Campos and Anderson Paulo de Paiva},
  doi          = {10.1016/j.engappai.2025.112510},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112510},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid multivariate normal boundary intersection approach with post-optimization assisted by mixture design of experiments},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse design of particle shapes with target sphericity and packing fraction using variational autoencoders. <em>EAAI</em>, <em>162</em>, 112509. (<a href='https://doi.org/10.1016/j.engappai.2025.112509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sphericity and packing fraction are fundamental properties governing the behavior of granular materials in many engineering applications. Conventional methods for designing particles with these target properties usually suffer from limited accuracy, diversity, and interpretability due to complex relationships between particle shape and properties. To address this, we propose an inverse design framework based on deep learning. First, a rotation- and reflection-invariant variational autoencoder (VAE) parameterizes two-dimensional convex particle shapes into a low-dimensional latent space, enabling accurate reconstruction and capturing geometric interpretations such as sphericity and symmetry. Second, a conditional variational autoencoder (CVAE) facilitates inverse design by generating particle shapes corresponding to target sphericity or packing fraction, and also enables the coupling control of both properties. Trained on a dataset of over 1600 convex shapes, the framework demonstrates robustness and universality. The rotation- and reflection-invariant architecture consistently maps different orientations of the same shape to a unified representation, which enhances interpretability. The main contribution in artificial intelligence lies in developing invariant generative models that learn shape representations and enable property-driven shape generation. The engineering contribution is providing a precise and efficient tool for the inverse design of particle shapes with target properties, supporting the optimization of granular materials in engineering applications.},
  archive      = {J_EAAI},
  author       = {Yutong Qian and Shuixiang Li},
  doi          = {10.1016/j.engappai.2025.112509},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112509},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inverse design of particle shapes with target sphericity and packing fraction using variational autoencoders},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way dynamic clustering algorithms based on generalized neighborhood relations in incomplete hybrid information systems with applications in medical decision-making. <em>EAAI</em>, <em>162</em>, 112508. (<a href='https://doi.org/10.1016/j.engappai.2025.112508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addressing clinical challenges related to chronic diseases, the effective use of medical data in decision-making is often hindered by issues such as incompleteness, heterogeneity, and the need for continuous updates. To cope with these challenges, this study introduces a three-way dynamic clustering strategy built upon generalized neighborhood relations, aiming to enhance clustering robustness, strengthen the model’s ability to manage uncertainty, and support adaptability to dynamically evolving data. First, generalized neighborhood relations are constructed in incomplete hybrid information systems. An evaluation function is defined from two perspectives: the number of similar attributes between objects and the distance between objects, thereby optimizing similarity measurement and accurately characterizing the data structure. Second, three-way decision rules are introduced to effectively handle uncertainty in objects while maintaining classification accuracy, thereby improving the interpretability and adaptability of the clustering model. Furthermore, to accommodate the dynamic nature of medical data, a dynamic incremental clustering method based on neighborhood information is proposed to ensure that newly added patient data can be efficiently integrated into existing clusters, enhancing model real-time performance and computational efficiency. Experiments conducted on real clinical data from Chronic kidney disease (CKD) patients validate the proposed method. The results demonstrate that, compared to existing clustering algorithms, the proposed method outperforms in terms of F1-score and Rand Index evaluation metrics. It also exhibits higher applicability in patient classification, core and boundary domain partitioning, and dynamic data processing, providing effective support for precision stratified management of chronic disease patients and intelligent medical decision-making.},
  archive      = {J_EAAI},
  author       = {Haoran Sun and Bingzhen Sun and Xixuan Zhao and Qiang Bao and Xiaoli Chu},
  doi          = {10.1016/j.engappai.2025.112508},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112508},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-way dynamic clustering algorithms based on generalized neighborhood relations in incomplete hybrid information systems with applications in medical decision-making},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A three-stage segmentation framework for lung cancer lesion isolation in three-dimensional positron emission tomography images. <em>EAAI</em>, <em>162</em>, 112507. (<a href='https://doi.org/10.1016/j.engappai.2025.112507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background Positron emission tomography (PET) is a critical functional medical imaging modality for the early detection and diagnosis of cancers. PET imaging faces several challenges that hinder accurate interpretation including its inherently low spatial resolution, substantial variability in cancer lesions’ appearance, and difficulties distinguishing between the image background and benign lesions. Methods We propose a novel three-stage image segmentation framework to enhance the accuracy of lung cancer lesion identification and extraction from three-dimensional (3D) PET images. The first stage conducts a coarse segmentation using an encoder-decoder structure network to roughly position lesions. The second stage employs a multi-layer feature extraction network to learn the detailed characteristics of coarse segmentation results, mitigating false positives caused by localization inaccuracy. The last stage further refines the extracted features via dividing a sub-region of the lesion into foreground and background branches, reducing false positives caused by over-segmentation of edges. A novel lesion count loss function is introduced to guide the model to generate predictions during the training, ensuring that the predicted lesion counts align with the ground truth labels. Results The proposed method was evaluated on clinical 3D PET image datasets. Experimental results demonstrated a Dice Similarity Coefficient (DSC) of 85.35 %, Accuracy of 83.97 %, and Recall of 86.83 %. Compared to existing models applied to the same datasets, our method consistently achieved superior performance. Conclusion The proposed method significantly improves the segmentation performance of lung cancer lesions, implying that our method holds substantial potential for broader clinical application, even in low-resolution images.},
  archive      = {J_EAAI},
  author       = {Yusheng Wu and Qiang Lin and Jingjun Wei and Yongchun Cao and Zhengxing Man and Xiaodi Huang},
  doi          = {10.1016/j.engappai.2025.112507},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112507},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A three-stage segmentation framework for lung cancer lesion isolation in three-dimensional positron emission tomography images},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised visual assessment of railway track curvature via homography learning based on projective curvilinear geometry model. <em>EAAI</em>, <em>162</em>, 112506. (<a href='https://doi.org/10.1016/j.engappai.2025.112506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railway track curvature monitoring is crucial for ensuring operational safety and passenger comfort. As a robust complement to the single-point physical sensor approaches, vision-based methods have recently gained increasing adoption. However, existing approaches frequently neglect the systematic exploitation of railway ego-vision geometry in two critical aspects: (1) the rail-camera kinematic coupling that relates the rail appearance in camera’s view and the track curvature during curvilinear motion, and (2) the potential of self-supervised learning to overcome annotation scarcity in this domain. This geometric oversight limits their accuracy in real-world dynamic scenarios. To address these gaps, this study proposes a novel vision-based framework that systematically exploits the railway ego vision geometry. Our methodology comprises two key innovations: First, a projective curvilinear geometry model that mathematically relates the ground-planes-induced homography to actual track curvature, thereby establishing a mapping from curvature and its variation to rail imaging curves. Second, a self-supervised curvature prediction network trained using automatically generated labels from our geometric model, eliminating the need for manual curve annotations. The self-supervision is achieved through a cyclic consistency mechanism between predicted curvatures and reprojected image features. Experimental validation using real-world railway footage demonstrates significant improvements: Our method reduces the average root mean squared error by 23.31% compared to state-of-the-art vision-based curvature estimation methods. These results underscore the effectiveness of geometry-aware computer vision for railway geometry monitoring},
  archive      = {J_EAAI},
  author       = {Peng Tang and Zhibin Yu},
  doi          = {10.1016/j.engappai.2025.112506},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112506},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised visual assessment of railway track curvature via homography learning based on projective curvilinear geometry model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Saliency and correlation learning for co-salient object detection. <em>EAAI</em>, <em>162</em>, 112504. (<a href='https://doi.org/10.1016/j.engappai.2025.112504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-Salient object detection aims to identify common salient objects across a given group of images. However, accurately locating co-salient objects remains challenging due to the complexity of capturing the correlation representation of each group of images. To tackle this problem, we propose a saliency and correlation learning method for co-salient object detection. This method employs a saliency learning network and a correlation learning network to generate precise co-saliency maps of a group of images. Within the saliency learning network, a saliency feature grafting module is designed to refine object edges and achieve accurate detection of salient objects. Furthermore, the correlation learning network incorporates two modules, which are designed for extracting saliency correlation representation and deriving consensus correlation representation within a group of images, respectively. Guided by prior information obtained from saliency learning of images, our method significantly improves performance in co-salient object detection through correlation representation learning. Extensive experiments on all the latest benchmarks demonstrate that our method outperforms 11 state-of-the-art models, achieving a new level of technical excellence, with an average Structural Similarity Measure score of 0.845.},
  archive      = {J_EAAI},
  author       = {Ying Tong and Xiangfeng Luo and Liyan Ma and Shaorong Xie},
  doi          = {10.1016/j.engappai.2025.112504},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112504},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Saliency and correlation learning for co-salient object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated monitoring of mycobacterium population growth in time-lapse microscopy with deep learning pseudo-supervised algorithm. <em>EAAI</em>, <em>162</em>, 112503. (<a href='https://doi.org/10.1016/j.engappai.2025.112503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The understanding of bacteria evolution through time and the analysis of their interaction with the medium is a main step in biomedical research. Bacteria cause in humans different infectious diseases, such as tuberculosis. Tuberculosis is one of the leading causes of death worldwide, caused by Mycobacterium tuberculosis ( Mtb ). Observation of Mycobacteria under a microscope provides essential information for disease-fighting. Nevertheless, Mtb presents a very particular cell division pattern characterized by a high entanglement in which the frontier between dividing cells are almost indistinguishable to the human eye, which makes the manual analysis of cultures a very challenging task, resulting in extremely long processing times. In this paper, we propose a novel approach to automatically detect bacterial cells and infer the growth rate and growth speed over a time-lapse microscopy (TLM) sequence. This method leverages a semi-supervised Deep Learning approach with a lightweight U-Net for efficient and fast processing. To reduce efforts of database construction, we deploy and exploit a mix of manually and synthetically annotated databases of two different classes of Mycobacterium , i.e. Mtb and Mycobacterium smegmatis ( Msm ). The experiments demonstrated the efficiency of the detection of both bacterial reproduction rate and bacterial death in Mycobacterium species, with the Phase-contrast (PhC) microscopy channels as a unique input. Reaching a segmentation accuracy of 96.3%, recall of 78.2%, and precision of 85.5% on Mtb detection for the model trained with a mix of manually and synthetically annotated databases. The experiments validate as well the synthetic label generation technique, which provides more conscience and accurate results than the manually segmented techniques. The mask generation workflow opens new opportunities for the microbial AI development field. The system implemented may change the paradigm in preclinical anti-mycobacteria drug development for since enables the adoption of TLM, a technology that provides extremely valuable information on drug efficacy but is seldom leveraged due to the complex image processing it involves.},
  archive      = {J_EAAI},
  author       = {Lara Visuña and Javier Garcia-Blas and Santiago Ferrer-Bazaga and Patricio Lopez-Exposito and Jesus Carretero},
  doi          = {10.1016/j.engappai.2025.112503},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112503},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated monitoring of mycobacterium population growth in time-lapse microscopy with deep learning pseudo-supervised algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reducing the estimation bias and variance in reinforcement learning via maxmean and aitken value iteration. <em>EAAI</em>, <em>162</em>, 112502. (<a href='https://doi.org/10.1016/j.engappai.2025.112502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The value-based reinforcement leaning methods suffer from overestimation bias, because of the existence of max operator, resulting in suboptimal policies. Meanwhile, variance in value estimation will cause the instability of networks. Many algorithms have been presented to solve the mentioned, but these lack the theoretical analysis about the degree of estimation bias, and the trade-off between the estimation bias and variance. Motivated by the above, in this paper, we propose a novel method based on Maxmean and Aitken value iteration, named MMAVI. The Maxmean operation allows the average of multiple state–action values (Q values) to be used as the estimated target value to mitigate the bias and variance. The Aitken value iteration is used to update Q values and improve the convergence rate. Based on the proposed method, combined with Q-learning and deep Q-network, we design two novel algorithms to adapt to different environments. To understand the effect of MMAVI, we analyze it both theoretically and empirically. In theory, we derive the closed-form expressions of reducing bias and variance, and prove that the convergence rate of our proposed method is faster than the traditional methods with Bellman equation. In addition, the convergence of our algorithms is proved in a tabular setting. Finally, we demonstrate that our proposed algorithms outperform the state-of-the-art algorithms in several environments.},
  archive      = {J_EAAI},
  author       = {Fanghui Huang and Wenqi Han and Xiang Li and Xinyang Deng and Wen Jiang},
  doi          = {10.1016/j.engappai.2025.112502},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112502},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reducing the estimation bias and variance in reinforcement learning via maxmean and aitken value iteration},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid reinforcement learning in parameterized action space via fluctuates constraint. <em>EAAI</em>, <em>162</em>, 112499. (<a href='https://doi.org/10.1016/j.engappai.2025.112499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameterized actions in Reinforcement Learning (RL) are composed of discrete-continuous hybrid action parameters, which are widely employed in game scenarios. However, previous works have often concentrated on the network structure of RL algorithms to solve hybrid actions, neglecting the impact of fluctuations in action parameters for agent move trajectory. Due to the coupling between discrete and continuous actions, instability in discrete actions influences the selection of corresponding continuous parameters, resulting in the agent deviating from the optimal move path. In this paper, we propose a parameterized RL approach based on parameter fluctuation restriction (PFR) to address this problem, called CP-DQN. Our method effectively mitigated value fluctuation in action parameters by constraining the action parameter between adjacent time steps. Additionally, we have incorporated a supervision module to optimize the entire training process. To quantify the superiority of our approach in minimizing trajectory deviations for agents, we propose an indicator to measure the influence of parameter fluctuations on performance in hybrid action space. Our method is evaluated in three environments with hybrid action spaces, and the experiments demonstrate the superiority of our method compared to existing approaches.},
  archive      = {J_EAAI},
  author       = {Chengcheng Yan and Shujie Chen and Jiawei Xu and Xuejie Wang and Zheng Peng},
  doi          = {10.1016/j.engappai.2025.112499},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112499},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid reinforcement learning in parameterized action space via fluctuates constraint},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAVREN: A multilayered adaptive framework for deploying vision-language models on resource-constrained unmanned aerial vehicles for autonomous search and rescue. <em>EAAI</em>, <em>162</em>, 112498. (<a href='https://doi.org/10.1016/j.engappai.2025.112498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) have become indispensable in autonomous search and rescue (SAR) missions, where the ability to interpret complex visual scenes in real time is critical. When equipped with artificial intelligence (AI)-empowered Vision-Language Models (VLMs), UAVs can provide rich contextual insights, interpret their findings, and even suggest next steps, but their deployment on resource-constrained UAV platforms is vastly limited by high computational demands, energy constraints, and strict latency requirements. This paper introduces MAVREN, a m ultilayered a daptive scheduler for V LM execution in re source-constrained UAV n etworks for autonomous SAR operations. Evaluations conducted on NVIDIA Jetson Orin NX using state-of-the-art VLMs such as Large Language and Vision Assistant (LLaVA) 1.6 and Vision-Language Alignment (VILA) 7B demonstrate that MAVREN achieves up to 26.11% higher throughput , 23% lower energy consumption , 13.51% reduced latency , and a 7% gain in detection accuracy compared to baseline schedulers across indoor, outdoor, and multi-UAV SAR scenarios. This is achieved through the integration of a visual encoder for lightweight feature extraction, a block floating-point quantizer for precision-efficient representation, a bit-wise computation engine for fast arithmetic execution, and a branch-and-bound optimizer for dynamic central processing unit (CPU) scheduling. These tightly coupled components allow MAVREN to optimize the energy–latency–accuracy trade-off, making it a deployable solution for vision-language reasoning in real-world SAR missions. Our findings demonstrate MAVREN’s capability to deliver rapid, energy-efficient inference, advancing the deployment of computationally intensive VLMs on resource-constrained UAV platforms.},
  archive      = {J_EAAI},
  author       = {Md Tahmid Rashid and Md Jawad Siddique and Abdus Shaqur},
  doi          = {10.1016/j.engappai.2025.112498},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112498},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MAVREN: A multilayered adaptive framework for deploying vision-language models on resource-constrained unmanned aerial vehicles for autonomous search and rescue},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rapid prediction of structural deflection based on explainable machine learning. <em>EAAI</em>, <em>162</em>, 112497. (<a href='https://doi.org/10.1016/j.engappai.2025.112497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-pressure arched air-rib membrane structures (HP-ARMS) exhibit lightweight portability and modular installation. This study proposes an explainable machine learning (ML) framework for the prediction of blast-induced HP-ARMS deflection. Firstly, compare the simulation results with the experimental data to verify the numerical method accuracy. Subsequently, a database containing 500 samples was established through numerical modeling. The input features include 6 structural parameters (air-rib pressure (X1), air-rib diameter (X2), air-rib thickness (X3), air-rib width (X4), air-rib height (X5), and air-rib bottom consolidation method (X6)) and 4 external load parameters (soil cover depth (X7), lateral explosion distance (X8), explosion equivalent (X9), and charge burial depth (X10)). Use Six ML algorithms—Light Gradient Boosting Machine (LightGBM), Random Forest (RF), Adaptive Boosting (AdaBoost), K-Nearest Neighbors (KNN), Convolutional Neural Network (CNN), and Gradient Boosting (GB)— and use four evaluation metrics to assess the accuracy of the ML model. Finally, the SHapley Additive exPlans (SHAP) method was used for interpretable analysis. The results showed that the LightGBM model had the best prediction performance. Compared with LightGBM, the Random-LightGBM (R-LightGBM) model significantly improved performance after hyperparameter optimization, with Root Mean Square Error (RMSE) reduced by 2.75 %, Mean Absolute Percentage Error (MAPE) reduced by 8.16 %, Mean Absolute Error (MAE) reduced by 5.88 %, and R-Squared (R 2 ) increased by 0.01. The SHAP method indicates that the explosion equivalent (X9) and charge burial depth (X10) are the most important parameters.},
  archive      = {J_EAAI},
  author       = {Yongtao Mi and Yushuai Zhang and Yicun Chen and Chenxi Sun and Huiqi Ren},
  doi          = {10.1016/j.engappai.2025.112497},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112497},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Rapid prediction of structural deflection based on explainable machine learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A latent-coupled neural network for multiphysics long-term forecasting in reactor transients using sparse observations. <em>EAAI</em>, <em>162</em>, 112496. (<a href='https://doi.org/10.1016/j.engappai.2025.112496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex dynamical systems in safety-critical applications like nuclear reactors involve strongly coupled physical fields evolving over space and time. Accurate prediction of these fields is vital for safety monitoring but is challenged by limited sensor placement and unobservable variables ( e.g. , xenon and iodine concentrations). This paper proposes the S parse observation to H igh-dimensional coupled physical field P rediction Network (SHPNet), a deep learning framework that predicts and reconstructs multiple physical fields directly from sparse observations.SHPNet combines a three-branch autoencoder to extract shared latent representations with a neural operator that models temporal dynamics in latent space, enabling efficient long-term forecasting. Evaluated on H ua-long P ressurized R eactor (HPR1000) under varying power and burnup conditions, SHPNet outperforms traditional frameworks and end-to-end model , achieving higher accuracy, robustness to observation sparsity, and effective reconstruction of unobservable fields. These results demonstrate SHPNet’s potential as a practical tool for real-time monitoring of complex coupled systems.},
  archive      = {J_EAAI},
  author       = {Yu-Yan Xu and Jun Luo and Deng Pan and Wei Lu and Ting Liu and Guanghui Yuan and Minxiao Zhong and Qing Li and Helin Gong},
  doi          = {10.1016/j.engappai.2025.112496},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112496},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A latent-coupled neural network for multiphysics long-term forecasting in reactor transients using sparse observations},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ESIGCF: Extremely simplified but intent-enhanced graph collaborative filtering for recommendation. <em>EAAI</em>, <em>162</em>, 112495. (<a href='https://doi.org/10.1016/j.engappai.2025.112495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) and graph contrastive learning (GCL) have substantially advanced recommender systems by modeling high-order user–item interactions and leveraging self-supervised signals. However, many existing methods overemphasize user–user or item–item similarities and rely on complex intent modeling, leading to increased complexity and limited exposure to diverse items. To address these challenges, we propose ESIGCF ( E xtremely S implified but I ntent-enhanced G raph C ollaborative F iltering) — a lightweight yet effective recommendation framework. ESIGCF explicitly defines user intent as the inner product between user and item embedding vectors and comprises two primary modules: (i) an intent-enhanced GCN that uses hybrid normalization (combining mean- and symmetric-normalization) to capture fine-grained user–item preferences without additional intent parameters, and (ii) an intent-aware GCL that aligns user–item pairs and positive and generated negative items. Negative samples are generated via a non-linear activation of item embedding interactions, promoting exposure to varied candidates without data augmentation. Experiments on three public datasets (Alibaba-iFashion, Yelp2018, Amazon-Book) show that ESIGCF consistently outperforms state-of-the-art baselines. For instance, on Alibaba-iFashion, ESIGCF achieves Recall@20 of 0.1273 versus 0.1059 for the best intent-enhanced baseline (a 20.2% relative improvement). Comprehensive experiments confirm that ESIGCF effectively captures latent user intent, mitigates popularity bias, and enhances recommendation performance with reduced complexity. Our code is available at https://github.com/Yangzhi22/ESIGCF .},
  archive      = {J_EAAI},
  author       = {Zhi Yang and Ruizhang Huang and Yanping Chen and Chuan Lin and Yongbin Qin},
  doi          = {10.1016/j.engappai.2025.112495},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112495},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ESIGCF: Extremely simplified but intent-enhanced graph collaborative filtering for recommendation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing spatial–temporal information into deep learning via wind propagation theory to enhance wind power prediction. <em>EAAI</em>, <em>162</em>, 112494. (<a href='https://doi.org/10.1016/j.engappai.2025.112494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting wind power poses significant challenges because of the inherent randomness and intermittency of wind speed, thereby impeding effective wind power scheduling. This study proposes an improved deep learning model which leverages wind propagation theory to uncover spatial–temporal relationships among wind turbines to enhance the performance of wind power prediction. In addition, comprehensive theoretical and empirical analyses are conducted to justify the effectiveness of leveraging wind propagation theory for capturing spatio-temporal relationships among wind turbines. Moreover, spatio-temporal dependencies are modeled through a dual mechanism: multi-channel independent modeling for per-turbine temporal dynamics and wind propagation-based matrix computations for inter-turbine spatial relationships, which together significantly reduce computational complexity while preserving predictive performance. Data from 134 wind turbines and six comparison models were employed to validate the robustness and effectiveness of the proposed model. Empirical results indicate that the proposed model outperforms the baseline models, achieving an average improvement of 6.19% in Root Mean Square Error and 7.05% in Mean Absolute Error.},
  archive      = {J_EAAI},
  author       = {Maolin He and Jujie Wang},
  doi          = {10.1016/j.engappai.2025.112494},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112494},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fusing spatial–temporal information into deep learning via wind propagation theory to enhance wind power prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LIP-MC: Multi-constraint label independent prediction in label distribution learning. <em>EAAI</em>, <em>162</em>, 112493. (<a href='https://doi.org/10.1016/j.engappai.2025.112493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning can resolve label ambiguity precisely by determining how well each label describes an instance. Traditional label distribution learning algorithms frequently attempt to model the complex relationships between all labels. This not only adds complexity to the model but may also reduce prediction accuracy due to label conflicts. In this paper, we propose a novel label distribution learning algorithm based on Multi-Constraint Label Independent Prediction (LIP-MC), intended to promote the rationality and accuracy of prediction results by simplifying the prediction process and combining multiple constraints. Specifically, label independent prediction values are generated for each label through sparsity constraints and weight coefficient matrices. Subsequently, a novel transformation model is designed to combine all separate label predictions and produce the final label distribution. Furthermore, smoothness constraints and logarithmic similarity constraints were introduced to enhance the model’s performance and generalization ability. On fourteen real datasets, the experiment was carried out, and the comparison results against seven advanced algorithms under seven evaluation metrics confirmed that the proposed algorithm is superior.},
  archive      = {J_EAAI},
  author       = {Gui-Lin Li and Ruili Wu and Xiaorui Qian and Qiang Zhu and Heng-Ru Zhang},
  doi          = {10.1016/j.engappai.2025.112493},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112493},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LIP-MC: Multi-constraint label independent prediction in label distribution learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed dynamic bayesian networks for time-dependent reliability prediction of subsea wellhead sealing system with multi-states. <em>EAAI</em>, <em>162</em>, 112492. (<a href='https://doi.org/10.1016/j.engappai.2025.112492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Subsea Wellhead Sealing System (SWSS) is crucial for the safety of deepwater operating, yet its reliability assessment faces challenges from harsh environments and multi-factor interactions. This study developed a data-driven, physics-informed reliability assessment method combining Finite Element Analysis (FEA) and Dynamic Bayesian Networks (DBN). An FEA model is established based on metal sealing theory, and a data-driven reliability model is subsequently constructed through sampling analysis, with a numerical-to-state conversion method bridging FEA and DBN. The FEA-DBN approach offers two key advantages: eliminating expert scoring subjectivity through physics-based modeling and effectively capturing multi-factor interactions and time-dependent behaviors. Results show this method can precisely quantify the evolution of SWSS reliability throughout its service lifecycle, with the probability of failure increasing from 0.64 % to 3.38 % over a 30-year service life. Case studies demonstrate its effectiveness for deep-sea equipment assessment, particularly in operating environments where real-time monitoring proves challenging, thereby demonstrating significant engineering application value.},
  archive      = {J_EAAI},
  author       = {Shengnan Wu and Han Gong and Long Yu and Aibo Zhang and Laibin Zhang and Yiliu Liu},
  doi          = {10.1016/j.engappai.2025.112492},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112492},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed dynamic bayesian networks for time-dependent reliability prediction of subsea wellhead sealing system with multi-states},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constructing a robust short-text clustering model for contrastive learning based on optimized adaptive optimal transport for pseudo-label generation. <em>EAAI</em>, <em>162</em>, 112491. (<a href='https://doi.org/10.1016/j.engappai.2025.112491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-text data often suffers from noise and class imbalances, posing challenges for effective clustering. To address these issues, we propose a Short-Text Clustering Model based on Pseudo-Labels and Contrastive Learning (SCPCL). The model comprises two key components: (1) a pseudo-label acquisition module, which introduces the optimal transport theory into short-text clustering and adopts a dynamically adjusted prior distribution to enhance the clustering of minority classes; and (2) a contrastive learning module combining a supervised clustering network, an instance contrastive head, and an anchor network. These components ensure intraclass compactness, interclass separability, and robustness to noise. Experiments on six benchmark datasets showed that SCPCL achieves an average clustering accuracy improvement of 2.61%, with a maximum gain of 6.47% for long-tailed distributions. This model provides an effective solution for clustering complex short text data.},
  archive      = {J_EAAI},
  author       = {Jiahui Liu and Chun Yan and Wei Liu and Yi Ding},
  doi          = {10.1016/j.engappai.2025.112491},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112491},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Constructing a robust short-text clustering model for contrastive learning based on optimized adaptive optimal transport for pseudo-label generation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid semantic-structural graph neural network for fault knowledge graph completion in railway operational equipment. <em>EAAI</em>, <em>162</em>, 112490. (<a href='https://doi.org/10.1016/j.engappai.2025.112490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete fault knowledge graphs in railway operational equipment hinder effective fault diagnosis, prediction, and maintenance planning. This study addresses the challenge of completing fault knowledge graph by proposing a hybrid semantic-structural graph neural network (Hybrid S-GNN) that integrates both semantic and structural information for knowledge graph completion (KGC) in railway fault scenarios. The Hybrid S-GNN comprises four key modules: a semantic encoding module that enhances textual fault data representations through contextual enhancement and dynamic weight allocation; a structural encoding module that captures graph topology using multi-view structure encoding combining local aggregation, global path encoding, and relation-aware adjustment; a semantic-structural fusion module leveraging attention mechanisms to balance semantic and structural signals; and an optimization-prediction module employing margin-based ranking loss and context-aware negative sampling for accurate triple prediction. Experiments on real-world railway fault knowledge graphs demonstrate that Hybrid S-GNN achieves a Hits@10 of 80.5 % and mean reciprocal rank (MRR) of 0.640, outperforming state-of-the-art baselines by 5.8 % and 6.1 %, respectively. Ablation studies confirm the critical contributions of each module, validating the necessity of jointly modeling semantic and structural features. This work provides an effective solution to enhance railway fault knowledge graphs and paves the way for advanced fault management applications in railway operations.},
  archive      = {J_EAAI},
  author       = {Xiaorui Yang and Honghui Li and Yi Xu and Yunhao Deng and Yanhui Bai and Shufang Liu},
  doi          = {10.1016/j.engappai.2025.112490},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112490},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid semantic-structural graph neural network for fault knowledge graph completion in railway operational equipment},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing efficiency and accuracy: Extreme gradient boosting and neural networks for near real-time brain deformation prediction in sports collisions. <em>EAAI</em>, <em>162</em>, 112489. (<a href='https://doi.org/10.1016/j.engappai.2025.112489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid head motion during sports collisions can cause traumatic brain injury. Head motion can be measured with instrumented mouthguards and fed into finite element (FE) models to predict brain strain, a measure of brain deformation and injury. Due to the computational cost of FE models, deep neural networks have been developed for near real-time prediction. However, they are not used in pitch-side assessments due to their complexity and reliance on full kinematic data, which cannot be reliably transmitted in real-time. We propose an extreme gradient boosting (XGBoost) model with simple input of two kinematic features. Its accuracy and efficiency were compared with two deep learning models: a multilayer perceptron (MLP) using 20 features, and a convolutional neural network (CNN) using entire kinematics. All models were trained on 1701 rugby impacts collected with mouthguards and simulated using the Imperial brain FE model. The XGBoost model predicted strain in key brain regions, while the deep learning models predicted whole-brain strain distributions. All models showed reasonable accuracy in predicting regional strain, with R 2 values 0.764–0.851 for XGBoost, 0.721–0.876 for MLP, and 0.744–0.887 for CNN. XGBoost required orders of magnitude fewer floating-point operations, and it used simple input that can be calculated on mouthguards and reliably transmitted in real-time. This study suggests that different models can be used at different stages of brain injury assessment. We hope that the XGBoost model proposed here will lower the barriers for adopting brain strain combined with instrumented mouthguards for pitch-side assessments from elite to grassroot collision sports.},
  archive      = {J_EAAI},
  author       = {Emily Yik Kwan Chan and Xiancheng Yu and Chen Qin and Mazdak Ghajari},
  doi          = {10.1016/j.engappai.2025.112489},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112489},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Balancing efficiency and accuracy: Extreme gradient boosting and neural networks for near real-time brain deformation prediction in sports collisions},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards lensless image deblurring with prior-embedded implicit neural representations in the low-data regime. <em>EAAI</em>, <em>162</em>, 112488. (<a href='https://doi.org/10.1016/j.engappai.2025.112488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of computational imaging has witnessed a promising paradigm shift with the emergence of untrained neural networks, offering novel solutions to inverse computational imaging problems. While existing techniques have demonstrated impressive results, they often operate either in the high-data regime, leveraging Generative Adversarial Networks (GANs) as image priors, or through untrained iterative reconstruction in a data-agnostic manner. This paper delves into lensless image reconstruction, a subset of computational imaging that replaces traditional lenses with computation, enabling the development of ultra-thin and lightweight imaging systems. To the best of our knowledge, we are the first to leverage implicit neural representations for lensless image deblurring, achieving reconstructions without the requirement of prior training. We perform prior-embedded untrained iterative optimization to enhance reconstruction performance and speed up convergence, effectively bridging the gap between the no-data and high-data regimes. Through a comprehensive comparative analysis of various untrained and low-shot methods, including under-parameterized non-convolutional techniques and domain-restricted low-shot approaches, we demonstrate that our method outperforms these alternatives by a significant margin. This work paves the way for the development of resource-constrained compact imaging systems, which can be applied in fields such as biomedical microscopy and embedded vision in low-data scenarios.},
  archive      = {J_EAAI},
  author       = {Abeer Banerjee and Sanjay Singh},
  doi          = {10.1016/j.engappai.2025.112488},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112488},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards lensless image deblurring with prior-embedded implicit neural representations in the low-data regime},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive detection method for driver fatigue using facial multisource dynamic behavior fusion. <em>EAAI</em>, <em>162</em>, 112482. (<a href='https://doi.org/10.1016/j.engappai.2025.112482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving while fatigued is a leading cause of traffic accidents. This study proposed an adaptive detection model to recognize driver fatigue based on the dynamic facial behavior information of drivers. First, drivers’ facial fatigue features were extracted to establish a general feature space, including pupil movement, eye state, and fatigue expression parameters. A differentiated feature space was then built based on individual drivers, taking into account the homogeneity, regularity, and individual variances in drivers' facial behavior at various states. A complete adaptive fatigue feature space was built by integrating the general feature space and differentiated feature space. Finally, a driver adaptive fatigue discrimination model was constructed to classify the general and adaptive fatigue feature space to detect driver fatigue states adaptively. A driver fatigue detection dataset from real scenarios had been established to validate the performance of the proposed model. Experimental results demonstrated that the proposed method significantly improved the detection accuracy of driver fatigue. In terms of artificial intelligence, this study contributes a novel adaptive feature space construction method based on multimodal dynamic feature fusion for facial fatigue recognition; in engineering application, it develops an adaptive driver fatigue detection system grounded in multimodal dynamic behaviors, which provides real-time alerts upon detecting driver fatigue and ensures driving safety.},
  archive      = {J_EAAI},
  author       = {Guoxin Zhang and Fei Yang and Xin Fang and Lili Wang and Lei Zhao and Chaoning Yu},
  doi          = {10.1016/j.engappai.2025.112482},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112482},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive detection method for driver fatigue using facial multisource dynamic behavior fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermoeconomic optimization of climate-adaptive solar and wind multi-generation systems using artificial intelligence and thermal energy recovery. <em>EAAI</em>, <em>162</em>, 112481. (<a href='https://doi.org/10.1016/j.engappai.2025.112481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a hybrid multi-generation energy system designed to overcome solar intermittency while meeting the global demand for integrated delivery of electricity, water, cooling, and sustainable fuels in the transition to decarbonization. The engineering application integrates solar thermal and wind energy with a modified Brayton cycle, a Steam Rankine Cycle (SRC), and a Thermoelectric Generator (TEG) to simultaneously produce electricity, fresh water via Reverse Osmosis (RO), hydrogen and oxygen via Proton Exchange Membrane Electrolyzer (PEME), and cooling (via absorption chiller) within a unified optimization framework. The system was modeled using Engineering Equation Solver (EES) and optimized via Response Surface Methodology (RSM) based on 11 decision variables. To address the complexity of optimization, a second phase applied Artificial Intelligence (AI) techniques: Adaptive Boosting (AdaBoost) for predictive modelling and Particle Swarm Optimization (PSO) for global optimization. Under optimal conditions, the Response Surface Methodology yielded an exergy efficiency of 45.8 % with a cost rate of 576.76 United States Dollars per hour (USD/h), while AI reduced costs to 211.2 USD/h with a moderate efficiency trade-off. Simulation of the optimized configuration across eight diverse climates identified Quebec as most viable, generating 22,629.6 Megawatt-hours per year (MWh/year) of electricity and avoiding 4616.4 tons of Carbon Dioxide (CO 2 ) emissions annually. Integration of wind energy stabilizes solar variability, enhancing performance. AI contributes to optimizing complex interactions, nonlinear constraints, and multiple conflicting objectives. The methodology offers a scalable, generalizable framework for designing intelligent, climate-resilient infrastructures. Future research includes AI-enabled real-time control, experimental validation, and broader deployment strategies.},
  archive      = {J_EAAI},
  author       = {Ehsanolah Assareh and Nima Izadyar and Emad Tandis and Mehdi Khiadani and Amir shahavand and Neha Agarwal and Arian Gerami and Ahmed Rezk and Minkyu Kim and Reza Kord and Tahereh Pirhoushyaran and Mehdi Hosseinzadeh and Saleh Mobayen},
  doi          = {10.1016/j.engappai.2025.112481},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112481},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermoeconomic optimization of climate-adaptive solar and wind multi-generation systems using artificial intelligence and thermal energy recovery},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A mamba-quantum attention transformer-convolutional network for automated pest and disease detection. <em>EAAI</em>, <em>162</em>, 112480. (<a href='https://doi.org/10.1016/j.engappai.2025.112480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses critical challenges in apple leaf disease detection, where environmental interference (climate variations, lighting conditions, growth stages), symptom similarity across diseases, and phenotypic diversity within single diseases significantly impede accurate identification. To overcome these limitations, we propose the Mamba Quantum Attention Transformer-Graph Convolutional Network (MQAT-Transformer), a novel hybrid architecture that integrates quantum-enhanced attention mechanisms with dynamic graph learning. Firstly, the Mamba-Quantum X Attention mechanism (MQXA), inspired by quantum state modeling, optimizes visual feature extraction under complex environmental conditions. Secondly, the Dynamic Graph Convolution Feature Prioritization module (DGCF) adaptively resolves heterogeneous symptom manifestations by establishing multi-scale feature dependencies through learnable graph structures. This study conducted comprehensive experiments on the AppleLeaf9 Datasets (AppleLeaf9) proposed by Northwest A&F University, Apple disease leaf images Dataset (ADLI), and PlantVillage Dataset (PlantVillage) proposed by Pennsylvania State University. The results demonstrate that the proposed method achieves competitive performance across multiple evaluation metrics (e.g., accuracy, recall, and F1-score), confirming its generalization capability in cross-species scenarios. Finally, leveraging this network architecture, we developed a lightweight mobile application for farm leaf disease detection, offering a practical and user-friendly solution for crop health monitoring in agricultural settings.},
  archive      = {J_EAAI},
  author       = {Dong Tang and Zhihuan Liu and YiRui Zeng and Zhao Xu and Wendong Su},
  doi          = {10.1016/j.engappai.2025.112480},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112480},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A mamba-quantum attention transformer-convolutional network for automated pest and disease detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-driven prior learning-based deep unrolling for underwater image enhancement. <em>EAAI</em>, <em>162</em>, 112472. (<a href='https://doi.org/10.1016/j.engappai.2025.112472'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a physics-driven prior learning-based algorithm unrolling approach for underwater image enhancement that leverages the advantages of both model- and learning-based approaches while overcoming their limitations. Model-based algorithms are theoretically robust because of prior knowledge of the underlying physics but may degrade image quality due to modeling inaccuracies. On the other hand, learning-based algorithms exhibit better adaptivity but inferior interpretability due to their black-box models and neglect of domain knowledge. In this work, we first formulate underwater image enhancement as a joint optimization problem with physics-based underwater-related priors and two learnable regularizers to compensate for modeling inaccuracies. Then, we solve the problem by reformulating it as a set of subproblems, which are then solved iteratively. Finally, we unroll the iterative algorithm into a deep neural network comprising a series of blocks, in which the optimization variables and regularizers are updated using closed-form solutions and learned deep neural networks, respectively. Experimental results on several datasets demonstrate that the proposed algorithm outperforms state-of-the-art underwater image enhancement algorithms on both quantitative and qualitative comparisons. The source code and pretrained models will be available at https://github.com/thithuypham/BLUE-Net .},
  archive      = {J_EAAI},
  author       = {Thuy Thi Pham and Hansung Yu and Truong Thanh Nhat Mai and Chul Lee},
  doi          = {10.1016/j.engappai.2025.112472},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112472},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-driven prior learning-based deep unrolling for underwater image enhancement},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explore unicin milvus optimization-based scale invariant signal interference noise loss enabled cycle generative adversarial network for audio source separation. <em>EAAI</em>, <em>162</em>, 112470. (<a href='https://doi.org/10.1016/j.engappai.2025.112470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio Source Separation remains the major research area as noisy audio signals lack information connectivity among users. Despite the numerous important efforts for audio source separation, there are still some challenges limiting the overall performance. Specifically, the existing methods face difficulty in working with multiple input sources and ignore the spectrum information of the signals, resulting in subpar performance. Hence, the research proposes the Explore Unicin Milvus Optimization-based Scale Invariant Signal interference Noise loss enabled Cycle Generative Adversarial Network (ExUnMO-S2NC-GAN) for addressing the challenges in the existing methods. The proposed approach utilizes the Cycle Generative Adversarial Network (C-GAN) architecture to carry out the transformation and restoration while preserving the significant details, resulting in achieving the most relevant audio source as the outcome. Specifically, the proposed model exploits the Scale Invariant Signal interference noise (S2N) loss function, improving the robustness against invariant to the signal scale and deformations of the signal. Besides, the Explore Unicin Milvus Optimization (ExUnMO) algorithm, harnessing the unique traits of Red Kite and Harris Hawk, is used for fine-tuning the hyperparameters of C-GAN, leading to improved performance. Moreover, the feature extraction with the spectral parameters added more advantages to the research model to work on more specific inputs. Extensive experiments demonstrates that theproposed model obtained high-efficiency outcomes in comparison with the state-of-the-art methods, which is evaluated with the error metrics attaining the Mean Absolute Error (MAE) of 1.79, and Mean Absolute Percentage Error (MAPE) of 3.22, whereas the signal quality metrics such as Peak Signal-to-Noise Ratio (PSNR), Signal-to-Interference Ratio (SIR) and Signal-to-Artifacts Ratio (SAR) achieved the high values of 54.81 dB (dB), 39.33 dB, and 40.56 dB respectively.},
  archive      = {J_EAAI},
  author       = {Baishakhi Dutta and Chandrakant J Gaikwad},
  doi          = {10.1016/j.engappai.2025.112470},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112470},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explore unicin milvus optimization-based scale invariant signal interference noise loss enabled cycle generative adversarial network for audio source separation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep ensemble learning model for chinese spelling check. <em>EAAI</em>, <em>162</em>, 112469. (<a href='https://doi.org/10.1016/j.engappai.2025.112469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Chinese Spelling Check models are individual end-to-end models with different tendencies, which cannot fully cover all kinds of spelling errors and achieves advanced performance in every aspect. In this paper, a deep ensemble learning model for Chinese Spelling Check is designed, which captures the correct Chinese spelling answers proposed by most of the candidate ckeck models. Considering the phonological, visual and semantic characteristics of all candidate answers, it can even discover new correct answer which is not found by any of the candidate ckeck models. Specifically, in order to learn a hybrid representation of each input correction answer provided by each candidate ckeck model that includes phonological, visual, and semantic characteristics, a hybrid representation learner is designed and does not need to consider the compatibility of the candidate ckeck models. A deep ensemble correction network is designed to integrate all the hybrid representations and finds a final correction answer that considers all the useful information of all input correction answers. Moreover, based on the deep ensemble correction network, the deep ensemble learning model can be easily extended to involve new candidate ckeck models. Experimental results on the benchmark demonstrate that our proposed model largely outperforms any of its aggregated individual ckeck models.},
  archive      = {J_EAAI},
  author       = {Yaoyao Wu and Ruizhang Huang and Lina Ren and Ruina Bai},
  doi          = {10.1016/j.engappai.2025.112469},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112469},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep ensemble learning model for chinese spelling check},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient active flow control strategy for confined square cylinder wake using deep learning-based surrogate model and reinforcement learning. <em>EAAI</em>, <em>162</em>, 112468. (<a href='https://doi.org/10.1016/j.engappai.2025.112468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a deep learning surrogate model-based reinforcement learning (DL–MBRL) for active control of two-dimensional (2D) wake flow past a square cylinder confined between parallel walls using antiphase jets. In the training of this framework, a proximal policy optimisation (PPO) reinforcement learning agent alternates its interaction between a deep learning-based surrogate model (DL–SM) and a computational fluid dynamics (CFD) simulation to suppress wake vortex shedding, thereby significantly reducing computational costs. The DL–SM, built with a Transformer for temporal dynamics and a multiscale enhanced super-resolution generative adversarial network (MS–ESRGAN) for spatial reconstruction, is trained on 2D direct numerical simulation wake flow data to effectively and accurately emulate complex nonlinear flow behaviours. Compared to standard model-free reinforcement learning, the DL–MBRL approach reduces training time by about 50% while maintaining or improving wake stabilisation. Specifically, it achieves approximately a 98% reduction in shedding energy and a 95% reduction in the standard deviation of the lift coefficient, demonstrating strong suppression of vortex shedding. By leveraging the inherent stochasticity of DL–SM, DL–MBRL also addresses the nonzero mean lift coefficient issue observed in model-free methods, promoting more robust exploration. These results highlight the potential of the framework for extension to practical and industrial flow control problems.},
  archive      = {J_EAAI},
  author       = {Meng Zhang and Mustafa Z. Yousif and Minze Xu and Haifeng Zhou and Linqi Yu and Hee-Chang Lim},
  doi          = {10.1016/j.engappai.2025.112468},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112468},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient active flow control strategy for confined square cylinder wake using deep learning-based surrogate model and reinforcement learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vessel behavior recognition method for preventing vessel-bridge collisions via adaptive video analytics. <em>EAAI</em>, <em>162</em>, 112467. (<a href='https://doi.org/10.1016/j.engappai.2025.112467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a comprehensive end-to-end framework for recognizing vessel behaviors aimed at preventing vessel-bridge collisions in complex maritime environments. Current monitoring approaches that rely on Automatic Identification Systems or external tracking mechanisms often suffer from class imbalance, cross-domain variability, and limited capability to detect previously unseen high-risk behaviors. To address these challenges, the proposed framework directly analyzes video streams and introduces a standardized behavioral taxonomy, classifying vessel activities into eleven categories while incorporating temporal continuity and behavior transition modeling. A robust dataset construction pipeline is established, consisting of fixed-length frame sequences and mechanisms for cross-domain generalization. The framework integrates a spatio-temporal feature extraction module based on deformable convolution and multi-scale attention, coupled with a cross-instance mutual enhancement mechanism to capture domain-invariant representations. An open-set recognition strategy, grounded in class anchor clustering, enables accurate identification of previously unobserved high-risk behaviors. Furthermore, an adaptive frame sampling strategy dynamically adjusts sampling density around behavior transitions, enhancing recall and capturing infrequent events while minimizing computational cost. Extensive evaluations on both single-domain and multi-domain benchmark datasets, as well as real-world bridge video streams, demonstrate superior performance in terms of overall accuracy, F1-score, detection of rare behaviors, and recall compared with baseline methods. Ablation studies confirm the contribution of each component, and comparisons with open-set recognition methods underscore the practical utility of the proposed approach for anomaly detection. This framework provides a scalable, artificial intelligence-driven solution for vessel behavior recognition, anomaly detection, and cross-domain generalization, supporting intelligent monitoring and early warning in safety-critical maritime operations.},
  archive      = {J_EAAI},
  author       = {Woqin Luo and Daoxin Chen and Ye Xia and Dongming Feng},
  doi          = {10.1016/j.engappai.2025.112467},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112467},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vessel behavior recognition method for preventing vessel-bridge collisions via adaptive video analytics},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A secure architecture for intelligent internet of vehicle systems using advanced dimensionality reduction with deep ensemble models. <em>EAAI</em>, <em>162</em>, 112466. (<a href='https://doi.org/10.1016/j.engappai.2025.112466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An intelligent transportation system (ITS) is an idea that provides a safe, protected, and smarter travelling experience to drivers. This visionary strategy aims to enable vehicles, pedestrian smartphones, roadside transportation frameworks, and additional devices to communicate with each other to offer secure and convenient services. Vehicle-to-Infrastructure (V2I) and Vehicle-to-Vehicle (V2V) communication in ITS enables the exchange of data like speed, position, and heading between vehicles and nearby networks. This improves data flow among infrastructure and vehicles, promoting road safety, traffic efficiency, reduced emissions, and ITS development. Artificial intelligence (AI) now presents smart solutions for addressing these threats effectively. This paper presents a Secure Architecture for Intelligent Vehicle Systems Using Integrated Ensemble Model and Advanced Dimensionality Reduction (SAIVS-IEMADR) model. Initially, the data pre-processing is performed to transform and organize raw data into a suitable format. The feature selection (FS) process uses five methods: Consistency, Correlation Feature Selection (CFS), information theory (InfoGain), Relief for Features (Relief-F), and Fast-Correlation Based Filter (FCBF) to identify the most relevant and informative features. Finally, an ensemble model comprising the temporal convolutional network (TCN), deep belief network (DBN), and stacked sparse auto-encoder (SSAE) is employed for classification. The SAIVS-IEMADR approach was evaluated on the Network Security Laboratory – Knowledge Discovery in Databases (NSLKDD) and Canadian Institute for Canadian Institute for Cybersecurity Intrusion Detection System (CICIDS)-2017 datasets, achieving superior accuracy of 99.55 % and 99.32 % compared to existing methods.},
  archive      = {J_EAAI},
  author       = {Amal K. Alkhalifa and Mashael M. Asiri and Reham Al-Dayil and Ahmed Alsayat and Mashail N. Alkhomsan and Mohammed A. AlAqil and Shouki A. Ebad and Mohammed Mujib Alshahrani},
  doi          = {10.1016/j.engappai.2025.112466},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112466},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A secure architecture for intelligent internet of vehicle systems using advanced dimensionality reduction with deep ensemble models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A constitutive framework for non-isothermal plasticity through micro-mechanism informed artificial neural networks. <em>EAAI</em>, <em>162</em>, 112465. (<a href='https://doi.org/10.1016/j.engappai.2025.112465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-isothermal plastic deformation creates modeling challenges for constitutive model development. Current constitutive models challenge to capture the coupled microstructural changes that occur when temperature varies during processing. The Micro-Mechanism Informed Artificial Neural Network (MMIANN) framework was developed to address these limitations using artificial intelligence (AI) and machine learning (ML) techniques. The MMIANN framework combines physics-based evolution equations for key metallurgical processes—dislocation density, grain boundary migration, and precipitation kinetics—with neural network predictions. These micro-mechanisms operate as internal state variables that guide the network's material behavior predictions. The architecture uses parallel physics-based and neural pathways, blended through adaptive coefficients. Thermodynamic constraints maintain consistency through penalty-based enforcement of the Clausius-Duhem inequality. The model was trained and validated using experimental data from simultaneous cooling and tensile deformation of AA7075 aluminum alloy. The tests replicated industrial hot forming conditions with cooling rates from 25 to 75 °C per second (°C/s). This experimental approach captures the thermal-mechanical coupling that drives microstructural evolution in practice. MMIANN achieved correlation coefficients exceeding 0.96 for stress, temperature, and grain size predictions. The framework captures thermomechanical regimes. Processing maps generated by the AI model link process parameters to microstructural outcomes. The analysis reveals an optimal processing window (40–55 °C/s cooling, 0.15–0.25 strain ( ε )) and identifies three regimes where different strengthening mechanisms dominate. By integrating metallurgical science with machine learning, this framework provides a practical tool for non-isothermal manufacturing processes. The approach bridges microstructural understanding with process control for thermal-mechanical operations through the application of artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Yo-Lun Yang and Tsai-Fu Chung and Chia-Hung Liao and Liang-Yu Chen and Hsing-Yu Wu and Uthayakumar Marimuthu and Arumugaprabu Veerasimman and Sundarakannan Rajendran and Vigneshwaran Shanmugam},
  doi          = {10.1016/j.engappai.2025.112465},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112465},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A constitutive framework for non-isothermal plasticity through micro-mechanism informed artificial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learnable patchmatch and self-teaching for multi-frame depth estimation in monocular endoscopy. <em>EAAI</em>, <em>162</em>, 112463. (<a href='https://doi.org/10.1016/j.engappai.2025.112463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work delves into unsupervised monocular depth estimation in endoscopy, which leverages adjacent frames to establish supervisory signals during the training phase. For many clinical applications, e.g. , surgical navigation, temporally correlated frames are also available at test time. However, most existing monocular methods struggle to make effective use of temporal information during both training and inference, primarily due to the inherent challenges of endoscopic imagery, including low- or homogeneous-texture regions and brightness fluctuations between frames. To fully exploit the temporal information in endoscopic scenes, we propose a novel unsupervised multi-frame monocular depth estimation model. The proposed model integrates a learnable patchmatch module to adaptively increase the discriminative ability in regions with low or homogeneous textures, and enforces cross-teaching and self-teaching consistencies to provide efficacious regularizations towards brightness fluctuations. Furthermore, as a byproduct of the self-teaching paradigm, the proposed model is able to improve the depth predictions when more frames are input at test time. We conduct detailed experiments on multiple datasets, and the experimental results indicate that the proposed method exceeds prior state-of-the-art competitors. The source code and trained models will be publicly available at https://github.com/ShuweiShao/FrameDepth .},
  archive      = {J_EAAI},
  author       = {Shuwei Shao and Zhongcai Pei and Weihai Chen and Xingming Wu and Zhong Liu},
  doi          = {10.1016/j.engappai.2025.112463},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112463},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learnable patchmatch and self-teaching for multi-frame depth estimation in monocular endoscopy},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph induced semi-supervised orthogonal nonnegative matrix factorization with label and constraint propagation. <em>EAAI</em>, <em>162</em>, 112462. (<a href='https://doi.org/10.1016/j.engappai.2025.112462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a popular technology of artificial intelligence, nonnegative matrix factorization (NMF) aims at clustering and finding the differentially expressed features of each cluster. However, for complex high-dimensional sample data, it is still a challenge to design more appropriate NMF optimization models and develop more efficient algorithms to solve this model in view of enhanced theoretical properties and numerical performance. In this paper, a novel NMF optimization model with regularization is proposed such that the NMF is performed by a semi-supervised approach, as well as incorporating the strategies of hypergraph induced label propagation and constraint propagation. Specifically, different from existing NMF methods, the hypergraph structure underlying the data, together with the simple graph information, is employed to guide the pairwise constraint propagation in our built model. In recognition of sample similarity, a dataset-adaptive strategy is proposed to update the weight matrix of the graphs. By adding dual orthogonality on the factor matrices in the objective function, interpretability and feature independence of the built model are enhanced. Then, an algorithm is developed to efficiently solve this complicated model. Theoretically, it is proved that the developed algorithms are well defined and convergent. Numerically, extensive tests on the proposed model and algorithm are performed, which validate that they outperform the state-of-the-art ones in terms of different metrics of evaluating clustering performance when they are applied into solution of the problems from eight public datasets.},
  archive      = {J_EAAI},
  author       = {Jie Guo and Ting Li and Jialu Liu and Zhong Wan},
  doi          = {10.1016/j.engappai.2025.112462},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112462},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hypergraph induced semi-supervised orthogonal nonnegative matrix factorization with label and constraint propagation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel condition monitoring approach using hybrid lightweighted adaptive models for complex machinery. <em>EAAI</em>, <em>162</em>, 112461. (<a href='https://doi.org/10.1016/j.engappai.2025.112461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Condition monitoring of complex industrial systems is critical for ensuring operational reliability. Data-driven methods using artificial intelligence have advanced anomaly detection (AD) and fault diagnosis (FD), but existing approaches often treat them separately, focus on known faults, and struggle with previously unseen or rare conditions in multi-modal scenarios. This study proposes a novel condition monitoring framework that integrates AD and FD within a distributed architecture. Lightweight models—including kernel principal component analysis, support vector machines, and one-dimensional convolutional neural networks—enable efficient and scalable processing. A multilevel information fusion strategy ensures consistent detection and diagnosis while facilitating the isolation of previously unknown faults. Module test results demonstrate the effectiveness and robustness of the proposed feature extraction and adaptive modeling approaches. The overall test results for previously unknown faults vary across channels and modules. For samples with misalignment and inner blade wear, channel-level detection accuracy ranges from 0.007 to 0.989, with unknown recognition rates up to 0.933 and diagnosis probabilities from 0.508 to 0.933. For strong misalignment and fan-end inner race faults, nearly all channels achieve 100 % detection accuracy, with some diagnosis probabilities above 0.9, while unknown recognition remains minimal (mostly below 0.05). Importantly, the proposed framework integrates detection and diagnostic outputs across channels, effectively mapping previously unseen faults to similar known categories or to an unknown category. Overall, the proposed framework offers a referenced solution for condition monitoring of industrial systems like pumps, turbines, and compressors, and lays the foundation for future improvements incorporating domain knowledge and model-driven interpretability.},
  archive      = {J_EAAI},
  author       = {Yingqian Liu and Rongyong Zhang and Luigi Grossi and Zhipin Ye and Huairui Li and Rongsheng Zhu and Qiang Fu},
  doi          = {10.1016/j.engappai.2025.112461},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112461},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel condition monitoring approach using hybrid lightweighted adaptive models for complex machinery},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast and stable framework for generative adversarial imitation learning. <em>EAAI</em>, <em>162</em>, 112460. (<a href='https://doi.org/10.1016/j.engappai.2025.112460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying reinforcement learning to complex and high-dimensional tasks encounters challenges, including the formulation of suitable reward functions, achieving sample efficiency, and developing effective exploration strategies. Adversarial imitation learning techniques address these issues by employing generative adversarial networks (GANs) to capture temporal dependencies and mitigate compounding errors. These methods exhibit enhanced efficiency relative to behavioral cloning and require fewer expert samples. Nonetheless, their complex min-max problem results in sample inefficiency and struggles with challenges such as mode collapse and training instability. This paper provides a comprehensive approach that adeptly addresses these challenges. The proposed method's design comprises three main steps. First, it uses the off-policy Twin Delayed Deep Deterministic (TD3) algorithm to enhance sample efficiency and accelerate learning. In the second step, a novel reward function based on energy-based GANs and deep regret analytic GANs is developed, which alleviates mode collapse and enhances training stability. Finally, we suggest several improvements, including the use of a pre-trained discriminator and mixed batches, to achieve a faster and more stable algorithm. The evaluation findings on continuous control tasks demonstrate that our method not only matches state-of-the-art performance but also surpasses it in both sample efficiency and stability. It achieves convergence with far fewer iterations than the compared methods.},
  archive      = {J_EAAI},
  author       = {Fateme Shahabi-Nejad and Mohammad Mehdi Ebadzadeh},
  doi          = {10.1016/j.engappai.2025.112460},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112460},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fast and stable framework for generative adversarial imitation learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transfer learning method of collaborating random walk and adaptive instance normalization for inscription image denoising. <em>EAAI</em>, <em>162</em>, 112458. (<a href='https://doi.org/10.1016/j.engappai.2025.112458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mess noise hinders reading and understanding of inscriptions in images. For image restoration from noise-corrupted images, existing network-learning-based methods can construct an excellent model to generate noise patterns. However, the performance of such models is degraded owing to the lack of high-quality training data and the complex noise pattern in inscription images, e.g., mixed noise with multiple levels. Herein, we first propose a novel noise generation model that can produce more realistic synthetic noise images using the random walk algorithm. Then, we propose an explainable inscription image denoising network using a variational inference model, where the joint distribution of clean-noise image pairs is approximated in a dual adversarial manner. The proposed network exhibits improved generalizability and adaptability to different noise characteristics using an estimated noise map and adaptive instance normalization. Finally, we introduce a transfer learning scheme to migrate the network learned from the synthetic noise image domain to a real-inscription image domain with a limited number of real-inscription images. The proposed method outperforms state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Erhu Zhang and Yunjing Liu and Guangfeng Lin and Jinghong Duan},
  doi          = {10.1016/j.engappai.2025.112458},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112458},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A transfer learning method of collaborating random walk and adaptive instance normalization for inscription image denoising},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based time series forecasting for bearing remaining useful life: Recent advances, hybrid architectures, and targeted enhancements. <em>EAAI</em>, <em>162</em>, 112457. (<a href='https://doi.org/10.1016/j.engappai.2025.112457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a systematic review of deep learning(DL)-based time series forecasting hybrid model for bearing RUL prediction by evaluating these studies from 2020 to 2025, addressing the gap in analyzing cross-model collaboration strategies. Firstly, the general workflow and modeling framework for remaining useful life (RUL) prediction were introduced. Secondly, a comparative analysis of time dependence capture mechanisms -including Recurrent Neural Networks(RNN) and their variants and Temporal Convolutional Network(TCN), and Transformer-was conducted. The findings reveal a shift from local sequential modeling to globally contextualized frameworks, enhanced by self-supervised learning and multimodal fusion. These developments underscore the importance of aligning model selection with specific task objectives and balancing multiple dimensions to achieve optimal performance in complex industrial scenarios. Thirdly, to address common challenges in RUL prediction, such as noisy data, sparse features, high model complexity, and limited interpretability, this paper explores performance optimization strategies from the perspectives of data quality, architectural design, and decision transparency. Finally, a comprehensive review was made of the current challenges: unclear applicability of attention, limited interpretability, deployment difficulties under resource constraints, difficulties in real-time prediction, and weak generalization in a data-scarce environment. To address these issues, future research should explore more trustworthy attention evaluation, interpretable architectures, lightweight design, continuous iteration for real-time prediction, and leveraging embedding other models to complement the lack of generalization. Overall, this work provides a structured perspective to support the development of the next generation of intelligent prediction systems.},
  archive      = {J_EAAI},
  author       = {Zhenyu Tang and Dalian Yang and Linrong Tan and Liying Zeng},
  doi          = {10.1016/j.engappai.2025.112457},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112457},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning-based time series forecasting for bearing remaining useful life: Recent advances, hybrid architectures, and targeted enhancements},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite element-integrated neural network framework for spatial modal prediction in machine tool structures. <em>EAAI</em>, <em>162</em>, 112456. (<a href='https://doi.org/10.1016/j.engappai.2025.112456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of position-dependent structural dynamics in (CNC) machine tools is critical for ensuring machining precision, avoiding resonance, and enabling real-time health monitoring. This study proposes an integrated framework combining finite element analysis (FEA), experimental modal testing, and artificial neural networks (ANNs) to model and predict position-dependent dynamics across the machine workspace. A validated FEA model of a high-rigidity vertical machining centre is developed and correlated with experimental modal analysis using a PCB 086D20 impact hammer and tri-axial accelerometer. Natural frequencies and mode shapes are extracted and compared, showing deviation under 10 %, confirming model fidelity. To capture position-dependent dynamics, modal analysis was performed at 27 spatial locations, revealing significant frequency variation across planes, indicating localized compliance zones. A multilayer ANN is trained on the modal dataset to predict frequencies based on spatial coordinates, achieving R 2 values above 0.99. The proposed hybrid approach enables real-time estimation of structural dynamics, reducing the need for repeated testing and supporting intelligent control strategies in large-format CNC systems. This work contributes a predictive foundation for dynamic stability optimization, resonance avoidance, and digital twin development in precision machining applications.},
  archive      = {J_EAAI},
  author       = {Aman Ullah and Tzu-Chi Chan and Jun-Fa Huang and Shinn-Liang Chang},
  doi          = {10.1016/j.engappai.2025.112456},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112456},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Finite element-integrated neural network framework for spatial modal prediction in machine tool structures},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end go (Weiqi) game record reconstruction from live broadcast videos. <em>EAAI</em>, <em>162</em>, 112455. (<a href='https://doi.org/10.1016/j.engappai.2025.112455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual transcription of Go (Weiqi) game records from broadcast videos creates a major bottleneck for building training data in artificial intelligence (AI). We present an end-to-end system that reconstructs complete smart game format (SGF) records from professional tournament broadcasts. The pipeline integrates four modules: (i) video-to-frame sampling; (ii) a board detector based on a detection transformer (DETR), optimized with a size-aware loss to reliably localize both main and commentary boards; (iii) a stone classifier that uses knowledge distillation from a vision transformer (ViT) teacher to an efficient grid-based student for full-board inference; and (iv) a temporal reconstruction algorithm for occlusion recovery and move-sequence consistency. When evaluated under a zero-error-tolerance video-level protocol – where a video is counted correctly only if all sampled frames match the reference – the system achieves 82.56% accuracy on 86 real tournament videos (356 h). Component analyses reveal high board localization quality with mean average precision (mAP50-95) reaching 0.99; near-teacher board-state recognition with a 67 × speedup (377.5 frames per second, FPS) and F1 score 0.988; and a 70.23% reduction of occlusion-related misdetections. Compared with you only look once (YOLO) and faster region-based convolutional neural network (Faster R-CNN) baselines, our design improves small-board recall and end-to-end robustness in dual-board and occluded settings. The system outputs SGF records suitable for large-scale dataset construction, AI-assisted analysis, education, and digital preservation, and the approach can be generalized to other grid-structured board games with minor adaptations.},
  archive      = {J_EAAI},
  author       = {Chih-Lin Lin and Hsia-Hung Ou and Lung Hung Chen and Chih-En Kuo},
  doi          = {10.1016/j.engappai.2025.112455},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112455},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {End-to-end go (Weiqi) game record reconstruction from live broadcast videos},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting code paraphrased by large language models using coding style features. <em>EAAI</em>, <em>162</em>, 112454. (<a href='https://doi.org/10.1016/j.engappai.2025.112454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in large language models (LLMs) for code generation has raised serious concerns about intellectual property protection. Malicious users can exploit LLMs to produce paraphrased versions of proprietary code that closely resemble the original. While the potential for LLM-assisted code paraphrasing continues to grow, research on detecting it remains limited, underscoring an urgent need for a detection system. We respond to this need by proposing two tasks. The first task is to detect whether code generated by an LLM is a paraphrased version of original human-written code. The second task is to identify which LLM is used to paraphrase the original code. For these tasks, we construct a dataset consisting of pairs of human-written code and LLM-paraphrased code using various LLMs. We statistically confirm significant differences in the coding styles of human-written and LLM-paraphrased code, particularly in terms of naming consistency, code structure, and readability. Based on these findings, we develop a detection method that identifies paraphrase relationships between human-written and LLM-generated code, and discover which LLM is used for the paraphrasing. Our detection method outperforms the best baselines in two tasks, improving F1 scores by 2.64% and 15.17% while achieving speedups of 1,343x and 213x, respectively.},
  archive      = {J_EAAI},
  author       = {Shinwoo Park and Hyundong Jin and Jeong-won Cha and Yo-Sub Han},
  doi          = {10.1016/j.engappai.2025.112454},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112454},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting code paraphrased by large language models using coding style features},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative neural networks for inverse design: Integrating denoising autoencoder and surrogate model for partial design variable imputation. <em>EAAI</em>, <em>162</em>, 112453. (<a href='https://doi.org/10.1016/j.engappai.2025.112453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven inverse design is an engineering approach where target performance criteria are specified upfront, leading to the derivation of design solutions that meet these criteria. While recent research focuses on generating complete design solutions using generative models, these approaches struggle with partial design variables and constraints that predetermine certain variables. Additionally, generative models are data-intensive and prone to overfitting with limited datasets. To address these limitations, this paper proposes a Cooperative Neural Network architecture comprising two key components: the Imputation Model and the Surrogate Model. These components collaborate to optimize design solutions while adhering to predefined performance criteria. The framework’s effectiveness is demonstrated through a case study on Glass Run Channel (GRC) designs from a Korean automotive manufacturer. Results show the architecture proficiently imputes undetermined variables and ensures the designs meet desired performance metrics, achieving Mean Squared Error (MSE) reductions of up to 98 % and R-squared values of 0.997–0.999 in initial tests. It remains robust in diverse scenarios, achieving up to 95.65 % MSE reduction and R-squared values of 0.995–0.999 for cases with the most undetermined variables, and up to 94.68 % MSE reduction with R-squared values of 0.983–0.995 for the smallest training datasets. This framework reduces design cycle times and enhances engineering design efficiency, offering a robust solution to limitations in traditional methods reliant on physical prototyping and iterative testing.},
  archive      = {J_EAAI},
  author       = {Agung Nugraha and Hyerin Kwon and Gyeongho Park and Jihwan Lee},
  doi          = {10.1016/j.engappai.2025.112453},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112453},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cooperative neural networks for inverse design: Integrating denoising autoencoder and surrogate model for partial design variable imputation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge distillation via teacher-modeled sample relationships for skin cancer diagnosis. <em>EAAI</em>, <em>162</em>, 112452. (<a href='https://doi.org/10.1016/j.engappai.2025.112452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In skin cancer diagnosis, knowledge distillation can achieve model compression, which enables complex deep learning tasks to run efficiently on devices with limited resources. However, existing studies have largely overlooked explicit modeling of sample relationships during teacher model training, particularly in the context of class imbalance. Directly transferring such unrefined relational knowledge not only fails to address the bias toward majority classes but also leads to suboptimal performance for minority classes. To address this gap, we propose a novel approach that integrates a sample relationship module into the teacher model to learn relational knowledge under class imbalance, which is then transferred to the student model during distillation. Specifically, the teacher transfers two key types of knowledge: traditional logits and inter-sample relationships. During training, the student is optimized through two losses: a standard logit-matching loss to mimic classification knowledge, and relational consistency losses to enforce alignment between the student’s and teacher’s predicted inter-sample relationships to address class imbalance. We conducted extensive experiments on large-scale public skin lesion classification datasets, including ISIC2019 and HAM10000, and the results demonstrate that our method significantly outperforms current state-of-the-art approaches.},
  archive      = {J_EAAI},
  author       = {Peng Liu and Wenhua Qian and Shan Tang},
  doi          = {10.1016/j.engappai.2025.112452},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112452},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Knowledge distillation via teacher-modeled sample relationships for skin cancer diagnosis},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Region-based weighting-and-enhancement network with adaptive class weighting loss for postoperative inguinal hernia prediction. <em>EAAI</em>, <em>162</em>, 112451. (<a href='https://doi.org/10.1016/j.engappai.2025.112451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Postoperative inguinal hernia (PIH) is a common complication after radical prostatectomy, subsequently leading to multiple potential risks (e.g., cardiovascular and cerebrovascular accidents) and increased surgical costs due to re-surgical reparation. Magnetic resonance imaging (MRI) examination is a widely used procedure before radical prostatectomy, which can investigate the muscle structures of the abdominal wall (MSAW). Recently, clinical studies have indicated that clinical parameters (e.g., thickness and width of the external oblique muscle) of MSAW are strongly related to PIH. However, automated MRI-based PIH prediction based on deep neural networks has not been studied previously. Motivated by these observations, we propose a novel region-based weighting-and-enhancement network to predict PIH before radical prostatectomy based on MRI images automatically. Specifically, we employ the well-designed Region Weighting-and-Enhancement module to capture informative context representations through region weighting and regional context enhancement, by fully leveraging the potential of clinical MSAW priori. Additionally, this paper designs an effective adaptive class weighting loss to emphasize or suppress the samples with varying levels of significance to further boost the PIH prediction performance. The extensive experiments on a clinical MRI-PIH dataset and one publicly available MRI dataset manifest the superiority of our proposed methods over state-of-the-art deep neural networks and advanced loss methods.},
  archive      = {J_EAAI},
  author       = {Jiawei Zhang and Lisheng Wu and Qiang Fang and Weidong Yu and Zhengyu Hu and Fengyun Zhang and Cheng Yang and Xiaoqing Zhang},
  doi          = {10.1016/j.engappai.2025.112451},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112451},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Region-based weighting-and-enhancement network with adaptive class weighting loss for postoperative inguinal hernia prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting thermal transport of blood-based penta-hybrid nanofluid in fin geometries using deep neural networks and finite difference approach. <em>EAAI</em>, <em>162</em>, 112450. (<a href='https://doi.org/10.1016/j.engappai.2025.112450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nanofluids have garnered significant research interest due to their enhanced heat transfer and thermal characteristics. A novel hybrid nanofluid has exhibited exceptional thermal properties, combining five nanoparticles of uniform shapes with a base fluid, such as blood. This study investigates the influence of fin thickness, varying with length, considering the implications of internal heat production, convection, and thermal radiation processes in rectangular, convex, and triangular fin descriptions. Wet scenarios are interpreted to evaluate differences in thermal energy dynamics for fin shapes like Rectangular, Convex and Triangular. Darcy's model is employed to account for the material's porous nature. A finite difference scheme, implemented using Partial Differential Equation solver (PDSolve) in Maple (2024), provides graphical insights into fin effectiveness and thermal steady-state responses across various parameters. Incorporating Penta hybrid nanofluids enhances fin performance, with rectangular fins' Nusselt numbers (up to 1.936) proving more efficient, delivering faster thermal responses than triangular fins and convex fins. Further, using the Adam Optimisation algorithm, Convolutional Neural Networks were used to validate the current model. It was observed that these networks could accurately forecast the truth values, and the two findings matched, as indicated in Table 3 As a potential biological application, this research offers insight into optimising cooling systems for biomedical devices, such as heat exchangers in artificial organs.},
  archive      = {J_EAAI},
  author       = {Maddina Dinesh Kumar and Nehad Ali Shah and Dharmaiah Gurram and Se-Jin Yook},
  doi          = {10.1016/j.engappai.2025.112450},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112450},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting thermal transport of blood-based penta-hybrid nanofluid in fin geometries using deep neural networks and finite difference approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on the application of attention mechanism based multi-model fusion in food recommendation platforms. <em>EAAI</em>, <em>162</em>, 112449. (<a href='https://doi.org/10.1016/j.engappai.2025.112449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smartphone-based food ordering has greatly enhanced convenience in daily life, and the rise of recommendation systems has transformed the functionality and user experience of food delivery applications. Innovations in recommendation algorithms and models have significantly improved the efficiency of food, merchant, and advertisement recommendations on food platforms, leading to higher transaction rates and greater user satisfaction. To further enhance recommendation efficiency, this study introduces a novel multi-model fusion recommendation architecture based on the multi-head self-attention mechanism, utilizing a two-tier structure. The first-tier model (the attention-based homogeneous AutoInt model) acts as a teacher to guide the training of the second-tier Transformer model. This hierarchical approach integrates multiple models through knowledge distillation, significantly improving the accuracy of the recommendation system. The complexity and performance of the proposed architecture were analyzed and applied in a production environment. Testing on a private dataset reveals that the proposed multi-model fusion recommendation architecture significantly enhances recommendation performance across various food platform scenarios, achieving an accuracy of 0.7643, recall of 0.8262, and an F1 score of 0.7936. These results surpass the performance of current state-of-the-art models. Therefore, the proposed architecture is not only highly applicable to food recommendation systems but also has broad applicability in other fields such as retail and entertainment.},
  archive      = {J_EAAI},
  author       = {Linchao Zhang and Lei Hang},
  doi          = {10.1016/j.engappai.2025.112449},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112449},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on the application of attention mechanism based multi-model fusion in food recommendation platforms},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying fake reviews for refund purposes: Evaluating the effectiveness of a transfer-learning model against emerging large language models. <em>EAAI</em>, <em>162</em>, 112448. (<a href='https://doi.org/10.1016/j.engappai.2025.112448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Recently, dishonest sellers are using social platforms to advertise products that can be purchased for free through a refund mechanism, which is based on the writing of five-star fake reviews. The aim is to increase product visibility by influencing their ranking compared to similar products. This mechanism is leading to a significant distortion of e-commerce platforms, eroding trust among customers and sellers. Objective: In this paper, we address the problem of identifying fake reviews, aiming to provide an approach for mitigating fraudulent practices that compromise the integrity and transparency of e-commerce platforms. Methods: We propose a supervised model tailored for identifying fake reviews for refund purposes and compare its performance with some of the most recent generative models. Since, to the best of our knowledge, no datasets exist in the literature suitable for fake review identification in the process of Purchasing, Requesting reviews, and Refunding a product, we first proposed a new dataset of fake and genuine reviews from Amazon, collected with the help of a domain expert. Then, we defined five other new datasets containing reviews automatically generated by language models. To interact with these models, we designed new prompt approaches specifically tailored to our goal, which exploit the iterative refinement behind these models for improving classification results. Results: Experimental results demonstrated the effectiveness of the supervised model in detecting both types of fake reviews, outperforming state-of-the-art models with improvements ranging from 0.23 to 0.70 in terms of accuracy, precision, and recall.},
  archive      = {J_EAAI},
  author       = {Loredana Caruccio and Gaetano Cimino and Stefano Cirillo and Vincenzo Deufemia and Giuseppe Polese and Giandomenico Solimando},
  doi          = {10.1016/j.engappai.2025.112448},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112448},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identifying fake reviews for refund purposes: Evaluating the effectiveness of a transfer-learning model against emerging large language models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced multi-modal emotion recognition using the feature level fusion. <em>EAAI</em>, <em>162</em>, 112447. (<a href='https://doi.org/10.1016/j.engappai.2025.112447'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal human emotion recognition is a complex process of synthesizing information from various modalities to calculate emotion states. This field faces several challenges: (1) Acoustic is an essential component of emotion expression, but it often underperforms compared to visual and text in emotion recognition. (2) Capturing the feature interaction among different modalities is usually complex. (3) Processing high-definition videos can significantly reduce the efficiency of visual analysis. In this study, we presented a learning architecture designed to recognize human emotions effectively. For the first challenge, we implemented a multi-level acoustic encoder (MLAE) that enhances the extraction of acoustic information to improve the acoustic contribution in multi-modal emotion recognition. Facing the second challenge, we introduced the cross-attention block module, which adeptly captures the inter-modal interactions. To address the third challenge, we adopted the re-parameterized visual geometry group network (RepVGG) as the visual feature encoder, employing its multi-branch learning and single-branch reasoning structure to maintain high reasoning efficiency. Our model has demonstrated the state-of-the-art performance of the interactive emotional dyadic motion capture (IEMOCAP) dataset and the multi-modal opinion sentiment and emotion intensity of the Carnegie Mellon University (CMU-MOSEI) dataset.},
  archive      = {J_EAAI},
  author       = {Aziguli Wulamu and Yuheng Wu and Xin Liu and Yao Zhang and Jinghan Xu and Yang Zhang},
  doi          = {10.1016/j.engappai.2025.112447},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112447},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced multi-modal emotion recognition using the feature level fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep adaptive wavelet autoencoder with mutually independent empirical cumulative distribution for unsupervised motor anomaly detection. <em>EAAI</em>, <em>162</em>, 112446. (<a href='https://doi.org/10.1016/j.engappai.2025.112446'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {—Permanent magnet synchronous motors (PMSMs) are widely used in industrial applications but remain vulnerable to stator faults, such as inter-coil and inter-turn short circuits. Although recent deep learning-based fault detection methods have shown promise, they typically rely on large volumes of labelled fault data for training. To address this limitation, this paper proposes a novel unsupervised fault detection framework, termed Deep Adaptive Wavelet Autoencoder (DAWA) with Mutually Independent Empirical Cumulative Distribution (MIECD), specifically designed for PMSM fault detection. DAWA utilizes convolutional neural networks to learn adaptive wavelet filters through fast discrete wavelet transform, allowing for fully learnable, threshold-free extraction of fine-grained signal patterns. The resulting latent features are then mapped by MIECD into a mutually independent space via independent component analysis (ICA). Without assuming any prior data distribution, MIECD estimates empirical cumulative distributions (ECDs), computes tail probabilities across dimensions, and aggregates them into a unified anomaly score. Experimental results on motor vibration datasets demonstrate the effectiveness of the proposed method, showing average accuracy improvements of 15.85 % for Interturn and 15.16 % for Intercoil fault detection compared to conventional data-driven baselines across various operating conditions.},
  archive      = {J_EAAI},
  author       = {Pinze Ren and Ning Zhu and Dandan Peng and Liyuan Ren and Huan Wang},
  doi          = {10.1016/j.engappai.2025.112446},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112446},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep adaptive wavelet autoencoder with mutually independent empirical cumulative distribution for unsupervised motor anomaly detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic vision-based machine vibration sensing and fault diagnosis with signal alignment and feature clustering. <em>EAAI</em>, <em>162</em>, 112445. (<a href='https://doi.org/10.1016/j.engappai.2025.112445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, intelligent fault diagnosis methods for machines have been widely developed. The contact accelerometer has been popularly used with high measurement accuracy. However, in many industrial applications, non-contact sensors are often preferred due to practical constraints. The event camera is a novel bio-visual sensing technology for asynchronously capturing pixel-wise changes in brightness. It has various advantages including high measurement rate, exceptional resolution, wide dynamic range, etc., which thus has promising prospects in non-contact monitoring and fault diagnostic tasks. Despite these advantages, the high complexity of the dynamic vision data from the event cameras poses significant processing challenges, and the extraction of machine vibration information is of great difficulties. To address these challenges, this paper proposes a novel dynamic vision-based machine vibration sensing and fault diagnosis method. First, the dynamic vision data is reconstructed into event frame sequences. Next, a deep neural network is proposed to extract the micro-vibration information with feature clustering for enhancing model robustness. A signal alignment method is further proposed where the contact sensing data are used as a reference for optimizing model performance. Finally, the intelligent fault diagnosis is implemented with the estimated vibration data. Experimental validations are conducted with real rotating machine data, which demonstrate the promising applicability of the proposed method in non-contact machine vibration sensing and fault diagnosis.},
  archive      = {J_EAAI},
  author       = {Ruiyi Guang and Xiang Li and Yaguo Lei and Bin Yang and Naipeng Li},
  doi          = {10.1016/j.engappai.2025.112445},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112445},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic vision-based machine vibration sensing and fault diagnosis with signal alignment and feature clustering},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reliable degradation prediction method for proton exchange membrane fuel cells based on uncertainty bayesian self-attention. <em>EAAI</em>, <em>162</em>, 112444. (<a href='https://doi.org/10.1016/j.engappai.2025.112444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health state prediction of Proton Exchange Membrane Fuel Cells (PEMFCs) is a critical technology to ensure their long-term reliable operation. Prediction accuracy directly influences the effectiveness of maintenance strategies and risk management. However, existing PEMFC degradation prediction methods based on Recurrent Neural Networks (RNNs) or Transformer architectures mostly focus on point estimation while neglecting uncertainty quantification. This limitation makes it difficult to assess the confidence level of predictions in practical engineering applications, reducing the models' reliability in decision support. To address this issue, this paper proposes a novel Bayesian Patch Time Series Transformer (B-PatchTST) method. By deeply integrating Bayesian variational inference with time series patch modeling, the method enables probabilistic prediction of PEMFC degradation trajectories and disentangled analysis of uncertainty sources. Unlike traditional Bayesian Neural Networks (BNNs) that primarily apply Bayesian modeling to fully connected layers, B-PatchTST introduces a Bayesian Self-Attention Mechanism, which models epistemic uncertainty in three stages: patch embedding, uncertainty-aware self-attention computation, and adaptive regularization. This design significantly enhances the credibility of the model. Extensive experiments on the fuel cell datasets demonstrate the proposed method's outstanding performance. It achieves an average reduction of 36.31 % in root mean square error and an average compression of 83.39 % in the 95 % confidence interval, significantly outperforming existing methods. This approach offers a trustworthy basis for predictive maintenance in PEMFC systems, promoting a shift from “experience-based maintenance” to “reliable prognostics” in hydrogen energy applications.},
  archive      = {J_EAAI},
  author       = {Mengyu Liu and Zhe Cheng and Yu Yang and Niaoqing Hu and Guoji Shen and Yi Yang},
  doi          = {10.1016/j.engappai.2025.112444},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112444},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A reliable degradation prediction method for proton exchange membrane fuel cells based on uncertainty bayesian self-attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-data synergy enabling zero-shot composite fault diagnosis in sucker-rod pumping systems. <em>EAAI</em>, <em>162</em>, 112443. (<a href='https://doi.org/10.1016/j.engappai.2025.112443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-Shot Learning Accurate and comprehensive fault diagnosis is critical to ensuring production efficiency and extending equipment lifespan in oilfield operations. However, most existing diagnostic methods for sucker rod pumping systems are limited to single-fault identification, while the scarcity and high acquisition cost of compound fault samples hinder the application of supervised learning. To address these challenges, this paper proposes a zero-shot compound fault diagnosis framework that integrates domain knowledge with data-driven representations, enabling the identification of unseen fault using only single-fault samples. First, a unified semantic space is constructed by jointly embedding text-based fault descriptions and capsule-encoded load features. Then, a semantics-guided weakly supervised attribute composition strategy is introduced to enhance the completeness and discriminability of the semantic space. Finally, a bidirectional contrastive learning mechanism is established between visual encodings and semantic representations, and an adaptive multi-task loss weighting strategy is employed to optimize the overall framework efficiently. Experiments on real-world oilfield data demonstrate that the proposed method achieves an F1-score of 86.15 % under the zero-shot setting and 69.08 % under the generalized zero-shot setting, offering an effective and scalable solution for compound fault diagnosis in oil wells.},
  archive      = {J_EAAI},
  author       = {Xin-yan Wang and Li-ming Zhang and Kai Zhang and Cheng Cheng},
  doi          = {10.1016/j.engappai.2025.112443},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112443},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Knowledge-data synergy enabling zero-shot composite fault diagnosis in sucker-rod pumping systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge computing and server-based high-precision flood level classification system. <em>EAAI</em>, <em>162</em>, 112442. (<a href='https://doi.org/10.1016/j.engappai.2025.112442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban flooding and the resulting road water accumulation have become a significant threat to public transportation safety and the stability of municipal infrastructure. Traditional monitoring networks based on physical water level sensors suffer from low deployment density, high maintenance costs, and lagging response times. To address these shortcomings of traditional water accumulation monitoring systems, this study proposes an edge-computing intelligent monitoring system based on collaborative inference between the edge end (You Only Look Once version 5, YOLOv5) and the server end (Transform Vision Detection, TrVDet). A dual-modal perception architecture of “edge-end triggering and server-end precise analysis” has been constructed. At the edge end, the YOLOv5 model is deployed on embedded devices to achieve efficient preliminary screening of water accumulation, reducing dependence on the central server, lowering latency, and enhancing real-time response capabilities. On the server end, multi-object segmentation is performed on the detected water accumulation images, including roads, cars, motorcycles, and bicycles. Finally, a series of logical judgments is applied to determine the water accumulation level based on reference objects within the water. Since there is no publicly available dataset for target object recognition in flooded areas, we employed professional annotators to perform pixel-level labeling on the collected and organized flood data and constructed a multi-class target flood dataset (City Flood Segmentation, CityFloodSeg). Given the scarcity of moderate and severe water accumulation samples, we optimized the instance segmentation model TrVDet under the (A Visual Representation for Neon Genesis, EVA-02) framework and applied five data augmentation methods, including Mosaic and Flip, to expand the diversity of the dataset. Moreover, based on domain expert standards, we designed a logical judgment rule algorithm for model inference of water accumulation levels to classify the levels of water accumulation. Experimental results show that the server-end processing delay is stable within 0.4 s, capable of accurately judging different water accumulation risk levels. This provides centimeter-level real-time situational awareness for urban flood control decision-making and promotes the development of intelligent municipal infrastructure towards higher reliability and universality.},
  archive      = {J_EAAI},
  author       = {Ankang Lu and Runlong Cao and Yuanbin Wang and Wenjun Hu and Yuncan Gao and Zhifeng Hu and Ying Zang},
  doi          = {10.1016/j.engappai.2025.112442},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112442},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Edge computing and server-based high-precision flood level classification system},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WeedNet-X: A lightweight field weed detection algorithm. <em>EAAI</em>, <em>162</em>, 112441. (<a href='https://doi.org/10.1016/j.engappai.2025.112441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately distinguishing field weeds from crops and locating weed positions are critical prerequisites in automated weed control operations. However, weed detection and localization in unstructured field environments with complex lighting remains challenging. Firstly, data-driven deep learning based algorithms usually have a high dependence on a large number of training samples, and there are huge differences between field weeds and crops in different regions, growth cycles, and types. In addition, the conflict between hardware performance and computation cost makes it difficult for existing weed detection algorithms to maintain both detection accuracy and speed on low-performance platforms. All these problems increase the difficulty of detection. To solve the above problems, we first construct a medium-to-large weed dataset using an open-source agricultural image dataset and collect field data. Subsequently, we have proposed a lightweight weed detection algorithm using the ShuffleNetv2 network as the backbone network, with a multi-scale pyramid network, and the overall network algorithm is named WeedNet-X. The number of model parameters and the computational volume of the algorithm are only 0.57 million and 0.48 Giga floating point operations (GFLOPs), respectively. On the two constructed datasets, the mean Average Precision (mAP) of the algorithm can reach 86.31 % and 80.98 %, respectively, which are improved by 0.61 % and 3.10 % compared to the baseline model. Finally, the hardware and software systems for weed detection verify the excellence of the proposed algorithm in terms of practical performance.},
  archive      = {J_EAAI},
  author       = {Yong Li and Ao Ke and Zhiqiang Guo and Qingji Tan and Jingchao Yang},
  doi          = {10.1016/j.engappai.2025.112441},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112441},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {WeedNet-X: A lightweight field weed detection algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven robust intertwined wheat supply chain: Redesigning a viable network for long-term geopolitical conflicts. <em>EAAI</em>, <em>162</em>, 112440. (<a href='https://doi.org/10.1016/j.engappai.2025.112440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent human-made conflict in 2022 severely damaged Ukraine's infrastructure, causing significant instability in the food supply chain. This crisis was further exacerbated by trade bans imposed on another major global wheat exporter. Since wheat production and export are intrinsically linked, particularly in times of crisis, it is essential to adopt the concept of an intertwined supply chain. Accordingly, this study proposes an intertwined supply chain framework for the production and export of wheat during long-term disruptions. To enhance the viability of this intertwined system, the study introduces three key strategies. First, it addresses long-term disruptions and operational risks by employing redundancies and data-driven robust optimization techniques, where uncertainty sets are generated using a support vector clustering model. Second, the proposed supply chain accounts for freshwater resource limitations by integrating water resilience measures. Third, as the framework operates within a global context, it incorporates a comprehensive model that considers exchange rates, taxation, foreign demand points, and international trade responsibilities. To optimize these strategies, two multi-objective optimization models are developed and solved using an epsilon-constraint method. A cardinality-based measure is introduced to efficiently represent the Pareto front, offering decision-makers valuable insights into non-dominated solutions. The results are divided into analyses of wheat production, export, and their combined network. Individual analyses assess network setup, viability, and uncertainty control, while the integrated analysis examines sensitivity and interdependence. Overall, improving water use, managing risks, and designing a resilient, interconnected system can greatly strengthen the wheat supply chain during long-term crises.},
  archive      = {J_EAAI},
  author       = {Hani Gilani and Mehrdad Mohammadi and Tom Van Woensel and Hadi Sahebi},
  doi          = {10.1016/j.engappai.2025.112440},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112440},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven robust intertwined wheat supply chain: Redesigning a viable network for long-term geopolitical conflicts},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multitask learning-based fault detection approach for high impedance fault in resonant distribution networks. <em>EAAI</em>, <em>162</em>, 112439. (<a href='https://doi.org/10.1016/j.engappai.2025.112439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing high impedance faults (HIF) in resonant distribution networks remains a formidable challenge. This paper introduces a multitask learning-based approach integrated with a multitask fault detection network (MTFD-Net), employing three task-specific heads—classification, segmentation, and regression—to enable precise fault detection. MTFD-Net utilizes zero-sequence voltage data and a sliding time window to perform initial coarse classification, which allows the classification head to determine whether a permanent HIF has occurred. Upon detection, MTFD-Net proceeds to pinpoint potential fault moments through the outputs of the segmentation head. The regression head further refines these moments by predicting a reference moment and calculating the distance to each potential fault, effectively isolating the exact fault moment. An industrial prototype was developed and rigorously tested on a 10 kV system, where MTFD-Net demonstrated superior performance, achieving an accuracy of 0.976, an intersection over union of 0.984, and an absolute detection deviation of 5.20 ms. Operating efficiently with inference times ranging from 9.69 to 15.45 miliseconds on a Raspberry Pi 4B, MTFD-Net surpasses existing methods in accuracy, F1-score, sensitivity, specificity, and detection accuracy, providing a robust solution for HIF detection in resonant distribution networks.},
  archive      = {J_EAAI},
  author       = {Jian-Hong Gao and Mou-Fa Guo and Shuyue Lin and Duan-Yu Chen},
  doi          = {10.1016/j.engappai.2025.112439},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112439},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multitask learning-based fault detection approach for high impedance fault in resonant distribution networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Carbon trading price prediction with spikes: A novel hybrid model framework using heuristic multi-head attention convolutional bidirectional recurrent neural network. <em>EAAI</em>, <em>162</em>, 112438. (<a href='https://doi.org/10.1016/j.engappai.2025.112438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of carbon trading prices (CTPs) with spikes is crucial for developing carbon emission reduction policies and planning corporate investments. However, most existing CTP approaches usually focus on designing a cutting-edge model without considering spike prediction. Therefore, this paper presents a novel heuristic optimization-based hybrid model framework for CTP prediction with spikes. First, random forest is exploited to identify the relevant features of spikes and non-spikes for CTPs, and categorical boosting is employed to predict the spike occurrences of CTPs. Then, a novel hybrid model based on multiple linear regression, categorical boosting, and two dimensions convolutional neural network and bidirectional gated recurrent unit with multi-head regularized attention mechanism (2DCNN-BiGRU-MRA) is proposed to predict spikes and non-spikes for CTPs. In this model, multiple linear regression and categorical boosting are respectively applied to capture the linear and complex nonlinear features of the CTPs, in which their prediction results and deviations are integrated into the 2DCNN-BiGRU-MRA model as relevant features. The proposed 2DCNN-BiGRU-MRA can learn the spatiotemporal features and enhance representation capabilities by introducing 2DCNN, BiGRU, and MRA, thereby improving the accuracy of CTP prediction. In addition, to construct appropriate model hyperparameters of 2DCNN-BiGRU-MRA, the strength honey badger algorithm based on the adaptive momentum estimation is proposed to optimize the hyperparameters of 2DCNN-BiGRU-MRA. Finally, the proposed framework is tested on the actual data of European Union emissions trading and the carbon market in Hubei, China, and case studies have confirmed the superiority and achievable local interpretability of the proposed hybrid model framework.},
  archive      = {J_EAAI},
  author       = {Rongquan Zhang and Siqi Bu and Gangqiang Li and Min Zhou},
  doi          = {10.1016/j.engappai.2025.112438},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112438},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Carbon trading price prediction with spikes: A novel hybrid model framework using heuristic multi-head attention convolutional bidirectional recurrent neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inter-graph and intra-graph: Utilizing global financial markets and constituent stocks for stock index prediction. <em>EAAI</em>, <em>162</em>, 112437. (<a href='https://doi.org/10.1016/j.engappai.2025.112437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock index prediction is a significant yet difficult undertaking due to its incorporation of complex and diverse information. Following the implementation of Graph Neural Networks in financial data analysis, numerous researchers have focused on the node-level task of forecasting individual stock movements by analyzing the relationships between stocks. However, two key challenges remain: first, realizing different speeds of feature propagation among nodes in graph representation learning; second, predicting stock indices by extracting and aggregating fluctuations from constituent stocks through graph-level tasks remains unaddressed. To tackle these challenges, this paper proposes a novel spatio-temporal prediction framework combining both node-level and graph-level tasks. The framework includes two types of graphs: inter-graph and intra-graph, which combine information from the micro, meso, and macro dimensions. For the inter-graph at the node level, we introduce the Granger causality test as an innovative node filtering method, which realizes the propagation of features between nodes with different strengths and speeds in the process of graph representation learning. For the intra-graph at the graph level, we examine various graph pooling methods and pooling proportions of stock index constituents to enhance the interpretability of the results and to provide new theoretical insights for stock index prediction. In conclusion, we develop the Graph Representation Learning-based Long Short-Term Memory (GRL-LSTM) model for forecasting stock index movements, and demonstrate the superiority of our approach on four major Chinese stock markets.},
  archive      = {J_EAAI},
  author       = {Yong Shi and Yunong Wang and Jie Wu},
  doi          = {10.1016/j.engappai.2025.112437},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112437},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inter-graph and intra-graph: Utilizing global financial markets and constituent stocks for stock index prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel data-efficient double deep Q-network framework for intelligent financial portfolio management. <em>EAAI</em>, <em>162</em>, 112436. (<a href='https://doi.org/10.1016/j.engappai.2025.112436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigating the complexities of dynamic and uncertain financial markets demands intelligent systems capable of learning profitable strategies amidst risk and volatility. While Deep Q-Networks (DQN) offer a foundation for such systems, they often suffer from overestimation bias, training instability, and poor generalization in noisy financial environments. To address these challenges, this work introduces Portfolio Double Deep Q-Network (PDQN), a novel architecture inspired by recent advancements in reinforcement learning. PDQN enhances portfolio management by integrating Double Q-Learning to reduce overestimation, alongside Leaky ReLU activation, Xavier initialization, Huber loss, and dropout regularization to improve learning stability and generalization. Unlike prior methods that rely on large datasets and heavy computational infrastructure, PDQN achieves competitive—and often superior—performance using substantially less training data and lightweight infrastructure, making it well-suited for real-world, resource-constrained financial applications. Distinct from conventional approaches, PDQN uses separate networks to adapt portfolio decisions across varying market conditions. Empirical results across multiple market years show that PDQN often outperforms baseline strategies, including classic DQN and Buy-and-Hold, across key metrics such as Sharpe ratio, Sterling ratio, and cumulative return. PDQN—like all data-driven models—exhibits room for improvement under highly irregular or extreme financial scenarios. These observations suggest promising directions for future refinement and increased robustness, without detracting from the model's practical effectiveness and competitive edge.},
  archive      = {J_EAAI},
  author       = {Mahshad Alidousti and Morteza Khakzar Bafruei and Amir Hosein Afshar Sedigh},
  doi          = {10.1016/j.engappai.2025.112436},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112436},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel data-efficient double deep Q-network framework for intelligent financial portfolio management},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking few-shot wind speed prediction through a novel end-to-end transfer learning paradigm based on decomposition and gating information fusion. <em>EAAI</em>, <em>162</em>, 112435. (<a href='https://doi.org/10.1016/j.engappai.2025.112435'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind speed prediction is one of the key technologies for achieving intelligent and sustainable development in the engineering field. In the field of wind speed prediction, we are confronted with a challenging few-shot prediction problem. Specifically, due to the fact that some wind turbines in wind farms are newly established or there is data loss during the data collection process, these turbines only contain a small amount of wind speed data. This scarcity of data poses great difficulties for the prediction work, and traditional prediction methods often fail to achieve the desired prediction accuracy. In order to overcome the above difficulties, we propose an novel prediction paradigm of end-to-end transfer learning based on data decomposition and gated information fusion. We use the Fourier transform to find the source domain similar to the target domain to achieve feature alignment. Then, we pre-train the model on the source domain and transfer this model to the target domain, thus solving the problem of low prediction accuracy when directly predicting the target domain. In the first step, the data is decomposed and denoised by using the Variational Mode Decomposition. According to the sample entropy, the decomposed data is reorganized into three frequency components. Each component is input as an independent channel into the end-to-end prediction model. Firstly, the features of each channel are expanded to a high-dimensional space through the Multilayer Perceptron. Then, the gating mechanism is utilized to mix the features of the three channels into the features of one channel, thus achieving information fusion. Finally, the prediction result of the end-to-end model is output through the Gated Recurrent Unit. In the second step, the model pre-trained on the source domain is transferred to the small-sample target domain. The Dynamic Time Warping and cosine similarity are used to quantify the similarity of each channel between the two domains. The parameters of the channels with high similarity are locked, and at the same time, the parameters of other channels are fine-tuned to output the final prediction result. In addition, multiple sets of comparative experiments conducted using the wind speed data from wind farms in Queensland, Australia, have demonstrated the superiority of this prediction paradigm. Our strategy outperforms various baseline models in all three sets of data. Moreover, ablation experiments have proven the effectiveness of each component in this framework in improving prediction accuracy, opening up a new path for solving the difficult problem of few-shot prediction in practical engineering.},
  archive      = {J_EAAI},
  author       = {Xiaoyue Dong and Zhirui Tian},
  doi          = {10.1016/j.engappai.2025.112435},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112435},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unlocking few-shot wind speed prediction through a novel end-to-end transfer learning paradigm based on decomposition and gating information fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hyperparameter-fusion neural networks for deposition prediction. <em>EAAI</em>, <em>162</em>, 112434. (<a href='https://doi.org/10.1016/j.engappai.2025.112434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As integrated circuit manufacturing processes develop into the nanometer scale, precise control and prediction of the deposition process have become crucial. Nanoscale manufacturing imposes unprecedentedly high demands on film quality, uniformity, and consistency, presenting significant challenges to traditional control and prediction methodologies. This study proposes a novel approach that, for the first time, formulates the thin-film deposition process as a video prediction task, enabling the use of deep learning for morphological forecasting under varying process conditions, and introduces a novel hyperparameter-fusion neural network, referred to as DepositionNet (DepoNet). Unlike conventional video prediction models, DepoNet specifically accounts for the influence of deposition parameters on the entire simulation process. We have incorporated a novel Hyper Projector that allows the model to flexibly adapt to varying deposition conditions and material characteristics. Through comprehensive comparative experimental analyses, we demonstrate that DepoNet significantly outperforms existing deep-learning models and achieves a mean squared error of 17.34, representing a 3.67% improvement over the second best model and a 1,435 × speedup over physics-based methods, thereby validating its exceptional generalization capability. Extensive experiments reveal that the model maintains high performance even under conditions of limited training data, for instance, achieving a peak signal-to-noise ratio (PSNR) of 41.516 decibels (dB) when trained with only 20% of the available data.},
  archive      = {J_EAAI},
  author       = {Li Ding and Kun Pang and Junjie Li and Hua Shao and Nan Liu and Rui Chen and Zhiqiang Li and Zhenjie Yao and Ling Li},
  doi          = {10.1016/j.engappai.2025.112434},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112434},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hyperparameter-fusion neural networks for deposition prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming challenges in leveraging blockchain technology: Entropy-based q-rung orthopair fuzzy model for benchmarking application barriers. <em>EAAI</em>, <em>162</em>, 112433. (<a href='https://doi.org/10.1016/j.engappai.2025.112433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has emerged as a transformative solution across industries, delivering enhanced transparency, security, and operational efficiency. Nevertheless, its adoption remains hindered by significant challenges, especially in complex, data-intensive domains such as logistics. This study introduces a novel integration of the entropy-based q-rung orthopair fuzzy compromise ranking of alternatives from distance to ideal solution (CRADIS) approach to systematically evaluate and prioritize key barriers to blockchain adoption. The innovation of this work lies in applying q-rung orthopair fuzzy sets which are particularly capable of handling higher degrees of uncertainty and hesitancy, and then integrated with entropy for objective criterion weighting and CRADIS for robust decision-making. A real-world case study is presented, involving five critical barriers, lack of legal and regulatory frameworks, high implementation costs, technological scalability issues, data privacy and security concerns, and cultural resistance to change evaluated against eight decision criteria. The entropy weighting revealed regulatory clarity (0.168) and security (0.154) as the most influential factors, while the CRADIS ranking identified a lack of legal frameworks as the top barrier. This framework provides a transparent, data-driven method for decision-makers to identify and prioritize adoption challenges, particularly in uncertain and multi-faceted environments. By demonstrating the model’s applicability and precision, the study contributes to the emerging body of literature on blockchain integration and supports organizations in navigating the transition towards decentralized technologies.},
  archive      = {J_EAAI},
  author       = {Sana Shahab and Naoufel Kraiem and Ashit Kumar Dutta and Mohd Anjum and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.engappai.2025.112433},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112433},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Overcoming challenges in leveraging blockchain technology: Entropy-based q-rung orthopair fuzzy model for benchmarking application barriers},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual angle magnetic arc blow estimation in keyhole tungsten inert gas welding using high dynamic range imaging and a lightweight vision transformer network with coordinate attention and multiple auxiliary branches. <em>EAAI</em>, <em>162</em>, 112432. (<a href='https://doi.org/10.1016/j.engappai.2025.112432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high current Keyhole Tungsten Inert Gas (K-TIG) welding, magnetic arc blow frequently causes severe defects such as lack of fusion and undercut, which seriously affect weld formation quality. Conventional visual sensing systems are limited by dynamic range, making it difficult to capture arc morphology, while single angle descriptors fail to represent nonlinear deflection and lightweight convolutional models struggle with long range dependencies. To address these challenges, this study employs a High Dynamic Range (HDR, 120 decibel [dB]) imaging system to capture detailed arc variations and proposes a lightweight Vision Transformer (ViT) network with embedded Coordinate Attention (CA) and multiple auxiliary branches for real time angle estimation. A custom magnetic excitation system enables controllable arc blow simulation and consistent data acquisition. The method introduces a dual angle representation, namely the maximum curvature angle ( θ curv ) and the equivalent deviation angle ( θ eq ), to comprehensively describe arc geometry. The Artificial Intelligence (AI) framework integrates segmentation, keypoint localization, and regression tasks to improve accuracy and robustness. Trained on a self constructed HDR dataset containing 3,191 annotated images, model achieves a mean absolute error (MAE) of 1 . 12 ° , a root mean square error (RMSE) of 2 . 84 ° , a determination coefficient ( R 2 ) of 0.96, and a per frame inference latency of 12.96 ms (ms) on an NVIDIA RTX 2080Ti graphics processing unit (GPU). These results demonstrate that AI based methods combined with HDR imaging cannot only achieve accurate monitoring of welding arc states, but also provide potential support for closed loop control in all position welding applications.},
  archive      = {J_EAAI},
  author       = {Xiyin Chen and Xiaohu Zhang and Yonghua Shi and Yuxiang Huang and Junjie Pang},
  doi          = {10.1016/j.engappai.2025.112432},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112432},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual angle magnetic arc blow estimation in keyhole tungsten inert gas welding using high dynamic range imaging and a lightweight vision transformer network with coordinate attention and multiple auxiliary branches},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plug-and-play dynamic optimization for three-dimensional gaussian generation. <em>EAAI</em>, <em>162</em>, 112431. (<a href='https://doi.org/10.1016/j.engappai.2025.112431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Three-Dimensional (3D) asset generation have demonstrated remarkable progress in generation efficiency, enabling transformative applications across creative industries and mission-critical domains including autonomous systems. Current 3D asset generation primarily employs Score Distillation Sampling (SDS) to derive 3D priors from Two-Dimensional (2D) diffusion models. While this contribution ensures high generation quality, it is time-consuming. Recent methods have utilized 3D Gaussian Splatting for image rendering, which, despite enhancing generation speed, compromised on quality. Our method aims to balance the quality and speed of 3D asset generation by designing a plug-and-play optimization process that combines the strengths of both methods. We propose a rapid 3D Gaussian generation framework that begins with constructing a pipeline to generate multi-view images from text input using pre-trained generative models. Then our method utilizes 3D Gaussian Splatting for quick 3D asset initialization and subsequently performs detail optimization using Gaussian Filter and SDS-based 2D diffusion model optimizer. Additionally, we have optimized the loss function for 3D Gaussian Splatting and ensured the entire optimization process is plug-and-play, offering high generation quality and speed. Our method demonstrates strong adaptability in representative single-object 3D Gaussian generation tasks, indicating promising generalization potential. Achieving high-quality 3D generation on a single Graphics Processing Unit (GPU), our framework outperforms most popular optimization-based models in generation speed (5 × speedup +). Furthermore, when juxtaposed with the latest inference-based models, our optimization architecture offers a notable enhancement in generation quality (Contrastive Language-Image Pre-Training Score 33.8 vs. 27.3) within an acceptable amount of time.},
  archive      = {J_EAAI},
  author       = {Qixuan Li and Haoyang Li and Chao Wang and Yang Zhou and Yan Peng},
  doi          = {10.1016/j.engappai.2025.112431},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112431},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Plug-and-play dynamic optimization for three-dimensional gaussian generation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A diffusion model using semantic and sketch information for anomaly detection. <em>EAAI</em>, <em>162</em>, 112430. (<a href='https://doi.org/10.1016/j.engappai.2025.112430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In anomaly detection, methods that employ diffusion models for anomaly localization and reconstruction have demonstrated significant achievements. However, these methods face challenges such as the misclassification of multiple types of anomalies and the inability to effectively reconstruct large-scale anomalies due to the absence of semantic and sketch information from the original images. To tackle these challenges, we propose a framework, A Diffusion Model using Semantic and Sketch Information for Anomaly Detection (DSAD), which includes a semantic and sketch-guided network (SSG), a pre-trained autoencoder, and Stable Diffusion (SD). Initially, within SSG, we introduce a Semantic & Sketch Feature Fusion Module to enhance the model’s comprehension of the original images and present a Multi-scale Feature Fusion Module to maximize reconstruction accuracy. Subsequently, we connect SSG with the denoising network in SD in order to guide the network in reconstructing anomalous regions. Experiments on MVTec-AD dataset demonstrate the effectiveness of our approach which surpasses the state-of-the-art methods. The dataset and code are available at https://github.com/QinLi-STUDY/DSAD/tree/master .},
  archive      = {J_EAAI},
  author       = {Li Qin and Zhenyu Yin and Feiqing Zhang and Chunhe Song and Xiaoqiang Shi},
  doi          = {10.1016/j.engappai.2025.112430},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112430},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A diffusion model using semantic and sketch information for anomaly detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time spatiotemporal error compensation framework for face gear grinding. <em>EAAI</em>, <em>162</em>, 112429. (<a href='https://doi.org/10.1016/j.engappai.2025.112429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometric and thermal errors critically affect the precision of face gear grinding, yet current modeling approaches are computationally intensive and lack real-time adaptability. This study proposes a real-time spatiotemporal error compensation framework for face gear grinding. A closed-loop feedback mechanism is introduced to adaptively update compensation intensity based on residual error feedback, ensuring robustness and efficiency under fluctuating machining conditions. Moreover, a novel spatial-temporal thermal error model is developed by integrating Taylor-graph convolutional network and modified-long short term memory network to capture both node-level spatial fusion and long-term temporal dependencies. High-order terms in geometric error modeling are eliminated using a vector decomposition and truncation-based approach, significantly reducing computational complexity. Furthermore, a high-efficiency multi-source error-tooth flank mapping model is developed based on vector decomposition and truncation function methods, enabling accurate prediction with reduced computational cost. To identify dominant error contributors, an improved Morris-based sensitivity analysis method is integrated, distinguishing geometric and thermal errors affecting tooth flank deviation. Experimental results demonstrate sub-65 ms real-time response, 24.2 μm maximum error reduction, and robust adaptability under fluctuating machining conditions. Compared with recent gear-flank compensation studies, the proposed closed-loop framework achieves a 63.4 % reduction in maximum normal flank error under real machining and <65 ms response latency. This level is comparable to reported reductions based on grid-aggregated metrics in spiral bevel gears (76.82 % reduction of the sum of absolute grid errors), while additionally ensuring real-time, delay-aware execution. These findings validate the proposed system's potential for precision, real-time compensation in multi-axis manufacturing environments.},
  archive      = {J_EAAI},
  author       = {Jialan Liu and Chi Ma and Mingming Li and Jialong He and Giovanni Totis and Chunlei Hua and Gangwei Cui and Liang Wang and Ruijun Xue and Zhi Tan and Jun Yang and Kuo Liu and Yuansheng Zhou and Jianqiang Zhou and Xiaolei Deng and Shengbin Weng},
  doi          = {10.1016/j.engappai.2025.112429},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112429},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time spatiotemporal error compensation framework for face gear grinding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilayer perceptron-based offspring prediction model for constrained multi-objective optimization. <em>EAAI</em>, <em>162</em>, 112428. (<a href='https://doi.org/10.1016/j.engappai.2025.112428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems generally have both multiple constraint violations and conflicting objective functions. Some of them not only have sparse feasible regions, but also are difficult to converge. For these problems, the evolutionary operators used in traditional constrained multi-objective evolutionary algorithms (CMOEAs) are difficult to generate solutions with ideal quality. Therefore, this paper proposes a multilayer perceptron-based offspring prediction model for constrained multi-objective optimization (MOPCMO). Specifically, an evolutionary direction guidance strategy is designed that utilizes historical populations as training data to train a multilayer perceptron, which guides the evolution of the population by predicting and generating offspring, thereby improving the overall evolutionary efficiency of the algorithm. In addition, as the population iterates, evolutionary direction guidance strategy adaptively transforms the training data of multilayer perceptron. Finally, the multilayer perceptron is intermittently updated and uses an evolutionary direction guidance strategy to generate promising offspring, guiding the algorithm to achieve efficient search. Compared with seven state-of-the-art CMOEAs on 33 benchmark test problems and 8 engineering application problems, MOPCMO achieves excellent performance.},
  archive      = {J_EAAI},
  author       = {Qianlong Dang and Ruihuan Luo and Linlin Xie and Xiaochuan Gao and Weiting Bai},
  doi          = {10.1016/j.engappai.2025.112428},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112428},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multilayer perceptron-based offspring prediction model for constrained multi-objective optimization},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault diagnosis via multi-sensor fusion with auxiliary contrastive learning and phased fine-tuning. <em>EAAI</em>, <em>162</em>, 112427. (<a href='https://doi.org/10.1016/j.engappai.2025.112427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typically, deep learning-based fault diagnosis models fail to fully utilize the potential information in large amounts of normal state data and encounter difficulties when learning from limited fault samples. To address these challenges, this study proposes an auxiliary contrastive learning framework designed for multi-sensor data. The framework incorporates auxiliary classifiers after each sensor-specific branch to enhance feature representation, and enables model pretraining using only normal condition data. In addition, a phased fine-tuning strategy is developed, which combines full-model fine-tuning with lightweight adapter tuning to improve the adaptability of the fine-tuning process. A novel multi-sensor data augmentation technique is also introduced to enrich the contrastive learning tasks by generating structurally diverse negative samples. By enabling the effective utilization of normal condition data in model training, the proposed framework offers a new perspective for fault diagnosis applications. Experimental results on three benchmark datasets demonstrate that the proposed method significantly improves the generalization capability of the pre-trained model. Furthermore, the phased fine-tuning strategy exhibits high adaptability to the target tasks. Compared to other data fusion methods, the proposed auxiliary contrastive learning framework achieves notable performance advantages.},
  archive      = {J_EAAI},
  author       = {Yulin Jin and Xiaochuan Luo and Xiangwei Kong and Yulin Zhang},
  doi          = {10.1016/j.engappai.2025.112427},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112427},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis via multi-sensor fusion with auxiliary contrastive learning and phased fine-tuning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Damage and energy dissipation prediction and multi-objective optimization design of latticed concrete-filled steel tube column-composite box girder joints based on extreme gradient boosting. <em>EAAI</em>, <em>162</em>, 112426. (<a href='https://doi.org/10.1016/j.engappai.2025.112426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To optimize joint performance, a finite element (FE) model is developed based on low-cycle reciprocating load tests of latticed concrete-filled steel tubular (CFST) column-composite box girder joints. The FE-predicted hysteresis curves are compared with test results to verify model accuracy, and a data set is established accordingly. Extreme Gradient Boosting (XGBoost) algorithm is used for training and prediction, and compared with the traditional machine learning (ML) algorithm, the superiority of the XGBoost algorithm is manifested. The XGBoost algorithm is then used to predict the damage and energy values of the joint under more different parameter combinations, with the largest ratio of damage value to energy dissipation value selected as the optimal combination of the joints within the variation range of the six parameters. The results show that the FE model correlates well with the test results and can therefore be used to generate a data set. The prediction accuracy of XGBoost algorithm has high accuracy of more than 99 % in predicting damage and energy dissipation values and can thus be used for joint prediction research. Compared with other ML algorithms, XGBoost has the best prediction performance and superiority. Within the variation range of the six parameters, the ratio of damage value to energy dissipation value is the largest when the concrete strength, longitudinal bar diameter, concrete slab thickness, box girder strength, axial compression ratio, and transverse stiffener strength are respectively 30 Mega Pascal (MPa), 12 mm (mm), 90 mm, 390 MPa, 0.3, and 455 MPa.},
  archive      = {J_EAAI},
  author       = {Zhi Huang and Xin Deng and Juan Chen and Xiang Li and Lizhong Jiang and Yohchia Frank Chen and Yuner Huang and Lin Chen},
  doi          = {10.1016/j.engappai.2025.112426},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112426},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Damage and energy dissipation prediction and multi-objective optimization design of latticed concrete-filled steel tube column-composite box girder joints based on extreme gradient boosting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional feature fusion network design and performance optimisation for small target detection. <em>EAAI</em>, <em>162</em>, 112425. (<a href='https://doi.org/10.1016/j.engappai.2025.112425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the long distance of image acquisition, high imaging resolution, complex feature background, shooting angle, etc. The result is that there are few features available for small targets and they are easily interfered by background noise, which poses a challenge to the detection of small targets. To address the above problems, this paper proposes a target detection network (Convolution-based Small Target Detection Network, CSTDNet) with enhanced feature information, which integrates a multi-dimensional information fusion strategy for small target features. An all-round efficient feature fusion mudule (AeFusion) is introduced, which emphasises the fusion of multi-dimensional feature information, enhances the model's ability to focus on key information and suppress redundant information, and strengthens the ability to characterise local features and details, improving the effectiveness of the information and computational efficiency. In order to further enhance the location-awareness capability in cross-layer interaction, this paper introduces a novel decoupling head (Self-aware task decomposition for fine-grained feature sharing, STFS), which improves the accuracy of the small-target classification and localisation tasks through efficient detail sharing and task auto-alignment functions. And localisation tasks through efficient detail sharing and task auto-alignment. This study evaluates the effectiveness of the algorithm on five different scenarios containing small target datasets. Experimental results show that CSTDNet achieved improvements of 6.6 %, 5.8 %, 5.8 %, 5.5 %, and 5.6 % over the baseline model in terms of the mean average precision (mAP@0.5) metric on the Visdrone 2019, BDD100K, WiderPerson, SODA10M, and AppleDatas datasets, respectively, demonstrating stronger detection performance.},
  archive      = {J_EAAI},
  author       = {Xiaoyao Yang and Wenyang Zhao and Pengchao Sun and Wenda Zhao and Wenlong Yang},
  doi          = {10.1016/j.engappai.2025.112425},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112425},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-dimensional feature fusion network design and performance optimisation for small target detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDFNet: Feature-decision dual fusion network for intelligent fault diagnosis of rotating machinery under varying speed conditions. <em>EAAI</em>, <em>162</em>, 112423. (<a href='https://doi.org/10.1016/j.engappai.2025.112423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis is a critical technique for enhancing the reliability and security of rotating machinery. Existing diagnosis methods still have restricted generalization performance under speed variations owing to inadequate utilization of multisensor information. To address this problem, a novel feature-decision dual fusion network is proposed for fault diagnosis of rotating machinery under varying speed conditions. First, for each sensor, the frequency information learner is built to simultaneously extract global and local frequency domain features using global and local feature encoders. These features are then fused through a cross-attention mechanism to generate a sensor-specific initial classification decision. Subsequently, these individual sensor-wise decisions are fed into the decision dynamic ensemble to yield final fault diagnosis result. Moreover, an adaptive optimization strategy is designed to guide model learning generalizable features by flexibly adjusting the sensor loss weights during training. Finally, the effectiveness of the proposed method is validated on bearing and gearbox datasets. Experimental results demonstrate that the proposed method exhibits superior generalization and robustness for fault diagnosis under varying speed conditions.},
  archive      = {J_EAAI},
  author       = {Qi Deng and Zuoxiu Zhang and Xuyuan Tu and Zimuzhi Wang and Jun Wu},
  doi          = {10.1016/j.engappai.2025.112423},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112423},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FDFNet: Feature-decision dual fusion network for intelligent fault diagnosis of rotating machinery under varying speed conditions},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resource-efficient cross-subject emotion recognition from electroencephalogram via spiking domain discriminators. <em>EAAI</em>, <em>162</em>, 112422. (<a href='https://doi.org/10.1016/j.engappai.2025.112422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time emotion recognition poses a significant challenge in electroencephalogram (EEG) based emotion recognition, as it requires the immediate processing of EEG data. This necessity imposes substantial demands on the model’s resource consumption. To address this issue, this paper introduces a novel approach to EEG emotion recognition using a Cross Domain Spiking Convolutional Network (CDSCN), focusing on developments in the design of the spiking convolutional block. To address individual differences, the CDSCN incorporates Z-Score normalization at the feature level and introduces a spiking domain discriminator at the model level. These innovations aim to mitigate variations in data distribution across individuals and domains, thereby enhancing the model’s robustness and generalizability. Additionally, the CDSCN introduces a novel pooling fusion layer within the spiking convolutional block to optimize computational efficiency while preserving discriminative performance. Experimental evaluations on two publicly available datasets validate the effectiveness of the proposed CDSCN in achieving both accurate and generalized emotion recognition.},
  archive      = {J_EAAI},
  author       = {Dongdong Li and Shengyao Huang and Yujun Shen and Zhe Wang},
  doi          = {10.1016/j.engappai.2025.112422},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112422},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Resource-efficient cross-subject emotion recognition from electroencephalogram via spiking domain discriminators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight deep learning based solar cells defect detection using electroluminescence images. <em>EAAI</em>, <em>162</em>, 112421. (<a href='https://doi.org/10.1016/j.engappai.2025.112421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar cells are the fundamental core energy harvesting components in photovoltaic (PV) power generation stations. In view of the capability of detecting the invisible defects, the electroluminescence (EL) imaging is broadly used in the production lines of solar cells, based on which the deep learning technique is introduced to implement automatic defect detection and classification. However, the current deep learning models feature high complexity and require much computation resources, which are difficult to deploy in edge devices for real time applications. To tackle this issue, we proposed a novel lightweight and high-precision deep learning model named Cross Stage Partial Photovoltaic-You Only Look Once (CSPV-YOLO) based on the deep learning framework You Only Look Once v5 (YOLOv5) to enable the real-time solar cell defect detection. Firstly, a new module Cross Stage Partial C5 (CSPC5) is proposed to replace the initial C3 module in the YOLOv5 network to enhance the network accuracy in recognizing different types of defects. Secondly, a novel Spatial Pyramid Pooling with Cross Stage Partial (SPPFCSP) module is designed to replace the original Spatial Pyramid Pooling Fast (SPPF), which boosts the network feature extraction capabilities from defect targets at multiple scales and facilitates a more efficient integration of multiscale features. Finally, the original loss function of YOLOv5 is replaced by the Scylla intersection over union (SIoU) function to optimize the training model. The proposed models have been validated and intensively compared with many other state-of-the-art models on two public datasets. Firstly, results of experiments on the public Pascal Visual Object Classes (PASCAL VOC) 2007 datasets demonstrate that the proposed SPPFCSP block is obviously superior to other Spatial Pyramid Pooling blocks for the most state-of-the-art YOLO detectors, which can significantly improve the detection accuracy. The comparison results of experiments on the public Photovoltaic Electroluminescence Anomaly Detection Dataset (PVEL-AD) that includes 12-class defects obviously indicate that the proposed CSPV-YOLO model is better than many state-of-the-art models and achieves 91.5 % average precision (AP) and frames per second (FPS) of 177.8 on with only 2.2 million (M) parameters. Hence, it is suitable for the deployment on edge devices for real-time applications.},
  archive      = {J_EAAI},
  author       = {Zhicong Chen and Tianxiang Chen and Haoxin Zheng and Lijun Wu and Shuying Cheng and Peijie Lin},
  doi          = {10.1016/j.engappai.2025.112421},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112421},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightweight deep learning based solar cells defect detection using electroluminescence images},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple scattering-assisted data-driven full waveform inversion for pipeline blockage detection. <em>EAAI</em>, <em>162</em>, 112420. (<a href='https://doi.org/10.1016/j.engappai.2025.112420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockages in urban water supply systems (UWSS) cause operational inefficiencies and require timely detection and intervention. Hydraulic transients offer an efficient method for diagnosing UWSS. However, existing transient-based approaches face limitations: they either rely on gradient-descent optimization algorithms, which are prone to convergence issues due to noise, or they assume weak blockage-induced scattering that only applies to small blockages, thereby restricting their diagnostic scope. This study introduces a novel approach that leverages multiple scattering of transient wavefields to enhance full waveform inversion (FWI) for accurate pipeline blockage detection and profiling. Recognizing that blockage characteristics – such as length, size, and location – significantly alter the system’s transient response, we perturb these parameters to generate a comprehensive dataset using a numerical model. This dataset is used to train a machine learning (ML) model designed to associate multiple scattered wavefield patterns with specific blockage characteristics. The ML model performs full waveform inversion to predict spatial variations in pipeline area, thereby revealing detailed blockage profiles. We validate the effectiveness of our method through numerical simulations and experimental data, which account for multiply scattered wavefields influenced by visco-elastic and frictional damping effects. Specifically, we quantify prediction accuracy by reporting errors in key blockage parameters such as length and radial extent, which directly influence pipeline performance. Additionally, we assess the framework’s resilience to noise, a common challenge in practical applications. The proposed framework demonstrates that ML can effectively interpret complex scattered wavefield data related to pipeline defects, paving the way for advancements in diagnosing large-scale water networks.},
  archive      = {J_EAAI},
  author       = {Utban Ahmed and Muhammad Waqar and Fedi Zouari and Liyou Luo and Moez Louati and Jensen Li and Mohamed S. Ghidaoui},
  doi          = {10.1016/j.engappai.2025.112420},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112420},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple scattering-assisted data-driven full waveform inversion for pipeline blockage detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A streaming variable neural speech codec. <em>EAAI</em>, <em>162</em>, 112418. (<a href='https://doi.org/10.1016/j.engappai.2025.112418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a variable bit rate streaming neural speech codec designed for ultra-low bit rate scenarios, based on the SoundStream network framework. The codec employs the vector quantized variational auto-encoder (VQ-VAE) algorithm to capture the temporal structure and spectral characteristics of the speech signal, and constructs a latent space codebook to facilitate the effective mapping of feature vectors to discrete vectors. Based on the harmonic characteristics of speech signals and the inherent defects of single-scale discriminators, we introduce multi-period discriminators and multi-scale discriminators. The training process uses a balanced training strategy to ensure the balance between codebook utilization and training weights, and utilizes the Short-Time Fourier Transform (STFT) spectrum that can provide more accurate time–frequency resolution to compute the reconstruction loss. We introduce codebook loss to improve the utilization rate of the codebook and accelerate the convergence of the model. In the inference process, we use a quantizer selection strategy to achieve adaptive adjustment of variable bitrate. Objective and subjective experiments demonstrate that our proposed new neural speech codec outperforms traditional classical speech codecs and existing neural speech codecs in terms of reconstructed speech naturalness and quality while maintaining the low latency characteristic of neural speech codecs. With a multi-stimulus test with hidden reference and anchor (MUSHRA) score of 87, it is highly suitable for ultra-low bit rate speech compression applications such as satellite speech communication and narrowband instant messaging. The demo has been publicly released at https://svcodec.github.io/ .},
  archive      = {J_EAAI},
  author       = {Huaifeng Zhang and Pengfei Wu and Guigeng Li and Yuan An and Hao Zhang},
  doi          = {10.1016/j.engappai.2025.112418},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112418},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A streaming variable neural speech codec},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGP-DETR: An end-to-end object detection model for surface defect detection in light guide plates. <em>EAAI</em>, <em>162</em>, 112416. (<a href='https://doi.org/10.1016/j.engappai.2025.112416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose Light Guide Plate-DETR (LGP-DETR), an end-to-end object detection model tailored for identifying surface defects in light guide plates (LGPs). To address challenges such as low contrast, small target size, and complex backgrounds in industrial settings, LGP-DETR integrates three key components: Deformable Transformer Fusion Layer (DtransFusion), a deformable attention-based fusion module for capturing multi-scale features; Upsampling by Dynamic Sampling (DySample), a dynamic upsampling strategy for edge detail preservation; and OrthoC3, a channel attention module that suppresses background noise through orthogonal feature enhancement. We adopt FasterNet as a lightweight convolutional backbone to achieve a balance between accuracy and efficiency. Experimental results on a real-world LGP defect dataset demonstrate that LGP-DETR achieves a mean Average Precision (mAP) of 97.9 % and inference speed of 60 frames per second (FPS), significantly outperforming existing models. Furthermore, generalization tests on a fiberglass fabric defect dataset confirm the model's adaptability to different industrial domains. These findings validate the practical applicability and robustness of the proposed deep learning framework for industrial visual inspection.},
  archive      = {J_EAAI},
  author       = {Shuangning Liu and Cunling Liu and Junfeng Li},
  doi          = {10.1016/j.engappai.2025.112416},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112416},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LGP-DETR: An end-to-end object detection model for surface defect detection in light guide plates},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards efficient stream monitoring: A systematic approach for model selection and continuous improvement in tiny machine learning applications. <em>EAAI</em>, <em>162</em>, 112415. (<a href='https://doi.org/10.1016/j.engappai.2025.112415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring ephemeral stream flows is essential for ecological and hydrological studies. However, their intermittent nature and remote locations pose challenges for conventional monitoring methods, which often consume excessive energy to capture rare events. We address this with BODOQUE (Bimodal Observational Device for Optimizing Quantification of Ephemeral streams), a dual-mode system that leverages Tiny Machine Learning (TinyML) on low-power microcontrollers. The system remains in an energy-saving sensing state and activates high-precision measurements only when water flow is detected. We present a model selection methodology that balances detection accuracy with inference cost, enabling reliable operation within hardware constraints. To enhance adaptability in diverse environments, we developed a specialized component that facilitates dataset expansion through new field samples. This supports ongoing retraining to maintain model performance under changing conditions. A comprehensive evaluation using real-world data demonstrates that our system can achieve up to 97% annual energy savings compared to traditional continuous monitoring approaches.},
  archive      = {J_EAAI},
  author       = {Benjamín Arratia and Erika Rosas and Javier Prades and Salvador Peña-Haro and José M. Cecilia and Pietro Manzoni},
  doi          = {10.1016/j.engappai.2025.112415},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112415},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards efficient stream monitoring: A systematic approach for model selection and continuous improvement in tiny machine learning applications},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer architecture with illumination aware mechanisms for low-light image enhancement via retinex decomposition. <em>EAAI</em>, <em>162</em>, 112414. (<a href='https://doi.org/10.1016/j.engappai.2025.112414'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing low-light images is a complex task that involves not only restoring brightness but also preserving color fidelity and reducing noise interference. In this paper, we propose a novel Retinex-based Transformer Model with Illumination Aware Mechanisms (TIMRetinex-Net), which achieves physically interpretable modeling through a decomposition network guided by Retinex theory. To adapt to light variations in different regions, we randomly apply gamma transformations to several subregions of the illumination component and use a Color Estimation Module to capture the color global distribution of the natural scene in the reflection component. By modeling the color global distribution and repairing the degraded regions collaboratively, we alleviate the issue of being highly sensitive to data usage during training and improve the model’s ability to handle unknown scenes. The Illumination and Reflection Adjustment Transformer Network (IRAT-Net) produces enhanced images, achieving a balanced enhancement of detail and color. In addition, IRAT-Net incorporates an attention mechanism into the feature extraction layer and introduces the Illumination-Guided Information Aggregation Module to adaptively estimate lighting conditions. In the field of image processing, our method based on artificial intelligence was evaluated on five datasets and compared with twelve state-of-the-art methods. The results demonstrated strong alignment with the ground truth, with our method achieving superior performance in both subjective and objective assessments.},
  archive      = {J_EAAI},
  author       = {Zixuan Wang and Gang Liu and Hanlin Xu and Yao Qian and Rui Chang and Durga Prasad Bavirisetti},
  doi          = {10.1016/j.engappai.2025.112414},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112414},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer architecture with illumination aware mechanisms for low-light image enhancement via retinex decomposition},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient interactive segmentation of three-dimensional gaussians with optimal view selection. <em>EAAI</em>, <em>162</em>, 112413. (<a href='https://doi.org/10.1016/j.engappai.2025.112413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) scene representation has advanced rapidly in recent years, drawing the focus of more researchers. One of the main challenges for researchers is quickly and accurately segmenting 3D objects. Previous work has achieved excellent segmentation accuracy, but retraining requires a significant amount of time. Additionally, most methods fail to provide users with an efficient and convenient segmentation experience. To address these issues, we present Efficient Interactive Segmentation of 3D Gaussians (EISG), an efficient interactive segmentation method that eliminates the need for lengthy retraining. We first design an optimal view selection (OVS) method. This method uses 3D Gaussian entropy and image uncertainty to evaluate the quantity of view information. OVS helps users quickly select the optimal segmentation view, thereby enhancing interaction efficiency. Secondly, we use projection to find the target foreground rapidly and then segment the approximate objects using a clustering algorithm. Thirdly, we design a spatial-color background filter (SCBF) using the depth and color of 3D Gaussians. SCBF enables precise segmentation without needing retraining. Our method has been systematically tested on multiple datasets. Compared to other methods, the results demonstrate that EISG achieves ideal accuracy while significantly reducing processing time.},
  archive      = {J_EAAI},
  author       = {Yongtang Bao and Chengjie Tang and Yuze Wang and Yutong Qi and Ruijun Liu},
  doi          = {10.1016/j.engappai.2025.112413},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112413},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient interactive segmentation of three-dimensional gaussians with optimal view selection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial black-box attack and defense for convolutional neural network-based power quality disturbance classification. <em>EAAI</em>, <em>162</em>, 112411. (<a href='https://doi.org/10.1016/j.engappai.2025.112411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correctly identifying power quality disturbance (PQD) is crucial for the proper functioning of power systems. Deep learning (DL) techniques have been widely used for PQD classification due to their excellent performance. However, DL models are susceptible to adversarial attacks, posing a serious security threat to DL-based PQD classification systems. This issue has received limited attention in current research. In this study, we first utilize a convolutional neural network (CNN) to recognize various types of PQD signals. To evaluate model robustness, we introduce a black-box attack method for PQD classification based on the variance-tuning momentum iterative fast gradient sign method (VMI-FGSM). VMI-FGSM integrates a variance tuning method into the iterative process of the momentum iterative fast gradient sign method (MI-FGSM) , thereby producing more transferable adversarial PQD signals. To defend against such attacks, we propose a perturbation removal defense based on a generative adversarial network (PRD-GAN). This approach is capable of removing perturbations from adversarial PQD signals before they are recognized by the target classification model. Experiments demonstrate that VMI-FGSM produces adversarial perturbations that are nearly identical to those of the advanced MI-FGSM, but its adversarial examples are significantly more effective at misleading the target CNN model. Furthermore, the proposed PRD-GAN effectively reconstructs adversarial PQD signals into clean forms under various black-box attack intensities and outperforms the multi-level denoising autoencoder (ML-DAE) in defense performance due to its superior reconstruction capability.},
  archive      = {J_EAAI},
  author       = {Xiudong Zhang and Congmei Jiang and Mingbiao Yu and Xiankui Wen and Jing Zhang and Na Rong and Song Han},
  doi          = {10.1016/j.engappai.2025.112411},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112411},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adversarial black-box attack and defense for convolutional neural network-based power quality disturbance classification},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An intrusion detection system for critical infrastructures: Modbus approach. <em>EAAI</em>, <em>162</em>, 112410. (<a href='https://doi.org/10.1016/j.engappai.2025.112410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to develop an Intrusion Detection System (IDS) using deep learning and machine learning algorithms to detect cyber attacks in the network traffic of critical infrastructures using an artificial intelligence-based approach. The research investigates various machine learning algorithms, datasets, and performance evaluations to detect the security vulnerabilities commonly found in industrial networks. Implemented in Python, the system has been tested on hybrid dataset, demonstrating the performance of different algorithms in terms of accuracy, precision, and other metrics. From artificial intelligence perspective, this study contributes machine learning and deep learning in cybersecurity, showing how normal and ensemble models can effectively detect complex threats, with fewer features but more relevant. The research employs supervised learning techniques, leveraging labeled datasets to train models that can accurately classify network traffic as either normal or attack, ensuring high detection accuracy. From an engineering standpoint, the system’s Python implementation addresses the practical challenges of real-world deployment in industrial control systems (ICS) and facilitates integration with existing infrastructures. Additionally, the custom dataset and post-dissector code contribute to the field of industrial cybersecurity, providing engineers with tools for testing, validating, and optimizing IDS solutions. As cyber–physical systems are increasingly integrated into ICS, the proposed IDS provides a crucial layer of defense against cyber threats, safeguarding both the digital and physical components of critical infrastructure. The findings reveal that the proposed system exhibits high performance in terms of detection accuracy. The results show that the system provides an effective and reliable detection mechanism using artificial intelligence techniques.},
  archive      = {J_EAAI},
  author       = {Murat Varol and Murat İskefiyeli},
  doi          = {10.1016/j.engappai.2025.112410},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112410},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intrusion detection system for critical infrastructures: Modbus approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive resource management in dynamic Cyber–Physical systems using artificial intelligence. <em>EAAI</em>, <em>162</em>, 112409. (<a href='https://doi.org/10.1016/j.engappai.2025.112409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective resource management is crucial for the operation of dynamic Cyber–Physical Systems (CPS), yet traditional static or rule-based approaches often fail to handle their inherent complexity. This paper presents a novel Artificial Intelligence (AI)-driven framework for adaptive resource management, defined as the capability to autonomously adjust resource allocation by proactively forecasting future demands and dynamically optimizing decisions in real-time. The framework integrates a suite of AI techniques, including time-series models like Long Short-Term Memory (LSTM), chosen for their ability to capture complex temporal dependencies, for demand prediction. For resource allocation, it employs advanced actor–critic reinforcement learning (RL) algorithms like Proximal Policy Optimization (PPO) and Deep Deterministic Policy Gradient (DDPG), selected for their stability and efficiency in complex decision-making tasks. Performance was rigorously evaluated in a simulated dynamic environment. Experimental results demonstrate that combinations leveraging LSTM’s predictive accuracy with the robust optimization of PPO and DDPG achieve superior performance and stability. Specifically, the LSTM+DDPG and LSTM+PPO configurations yielded the highest average rewards (0.964 and 0.942, respectively), significantly outperforming the fixed-strategy baseline (0.497) and other AI pairings. Furthermore, the feasibility of training prediction models in a distributed manner via Federated Learning (FL) is successfully demonstrated. This research highlights that a synergistic integration of suitable AI predictors and advanced RL agents provides a powerful and resilient solution for resource management in dynamic CPS.},
  archive      = {J_EAAI},
  author       = {Xiaofei Zhao and Fangling Guo and Amin Huang and Jieqiong Ding and Chi Yan and Wei Yuan and Yunqi Su and Quanzhou Li and Qianggang Zhang},
  doi          = {10.1016/j.engappai.2025.112409},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112409},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive resource management in dynamic Cyber–Physical systems using artificial intelligence},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel prior knowledge-based and texture-enhanced network for few-shot industrial defect segmentation. <em>EAAI</em>, <em>162</em>, 112408. (<a href='https://doi.org/10.1016/j.engappai.2025.112408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based segmentation techniques have demonstrated significant potential in defect detection, which is vital for product quality. However, the existing models tend to specialize in detecting specific defect types, reducing their adaptability to a wider range of product defects, most existing methods rely on multi-scale or prototype learning to extract defect features, but still struggle with complex backgrounds, various interferences, and large intra-class variations. Additionally, the rarity of certain defects limits the availability of training samples. Herein, an innovative segmentation network, the Prior Knowledge-based and Texture-Enhanced Network (PTNet), is designed for few-shot industrial segmentation. The model is mainly composed of a self-guidance branch, a cross-guidance branch, and a texture enhancement module, enabling generalization across defect types with minimal labeled samples. Self-guidance extracts prior knowledge from the query image, while the cross-guidance branch extracts prior and prototype features from the masked support image. The texture information in the low-level features of the backbone is then enhanced by proposed texture enhancement module (TEM). Finally, the enhanced low-level texture information are fused with high-level semantic features, allowing the network to fully exploit both local details and global context before being decoded to restore the original image size. This enables the model to handle complex textures and generalize to unseen defect types. Extensive experimental results validate the effectiveness of the proposed modules. State-of-the-art performance is achieved in few-shot defect segmentation, with notable improvements in mean Intersection over Union (mIoU) of 46.05 % and 46.98 % under 1-shot and 5-shot conditions, respectively.},
  archive      = {J_EAAI},
  author       = {Xingyue Liu and Qian Wu and Yahui Cheng and Guojun Wen},
  doi          = {10.1016/j.engappai.2025.112408},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112408},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel prior knowledge-based and texture-enhanced network for few-shot industrial defect segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel reinforcement learning-based approach for optimal control: An application to multi-tank water systems. <em>EAAI</em>, <em>162</em>, 112407. (<a href='https://doi.org/10.1016/j.engappai.2025.112407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of control actions is a critical challenge in industrial systems, especially when dealing with complex and unknown dynamics. Data collected from the environment enables the application of reinforcement learning techniques, which let the controller learn a policy based on data. This work proposes a novel model-free reinforcement learning approach that consists of a value iteration algorithm based on separate policy evaluation and policy improvement phases to provide an accurate control policy estimation. The proposed approach addresses tracking control for quadruple-tank water systems while obtaining minor tracking errors and faster transient responses. The results from the case study reveal better accurate estimation of the value function, up to 86.13% mean improvement in tracking accuracy and faster responses compared to existing methods. Therefore, the proposed approach demonstrates advantages in optimizing control performance and stands as a promising control method for industrial applications.},
  archive      = {J_EAAI},
  author       = {Eva Masero and Giacomo Mussita and Alessio La Bella and Riccardo Scattolini},
  doi          = {10.1016/j.engappai.2025.112407},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112407},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel reinforcement learning-based approach for optimal control: An application to multi-tank water systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic weighted ensemble learning for ballast resistance estimation driven by vehicle-ground information fusion. <em>EAAI</em>, <em>162</em>, 112406. (<a href='https://doi.org/10.1016/j.engappai.2025.112406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health management of transmission parameters for railway signal equipment is a key link between intelligent operation and maintenance. As a core parameter of track circuits, ballast resistance significantly affects signal transmission. To accurately and reliably assess its health state, an ensemble learning algorithm (ELA) is introduced, tackling deviations of appraisal decision boundaries. Focusing on issues of complex weight calculation, model homogenization, and severe overfitting in ELA, an integration model based on an automatic weight allocation strategy (AWAS) is innovatively proposed, constructing a method for resistance estimations driven by information fusion, while maximizing its generalization ability. Firstly, for deterioration mechanism analysis of ballast resistance, a transmission state model for vehicle-ground collaboration is established, completing extractions of evolutionary rules. Secondly, the improved ELA leverages heterogeneous classifier optimization and automatic weighted soft voting, with its core ensemble strategy employing a secondary learner to map the fused datasets. Then, by means of data mining techniques, interpolation and denoising algorithms are applied to implement data preprocessing, facilitating the effective fusion of heterogeneous vehicle-ground information. Finally, based on occurrence of adverse conditions, an appropriate particle size is set to achieve state warning. The results indicate that the proposed AWAS for ballast resistance calculations can achieve 98.52 % testing accuracy and outperforms others.},
  archive      = {J_EAAI},
  author       = {Conghui Wang and Shiwu Yang and Chang Liu},
  doi          = {10.1016/j.engappai.2025.112406},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112406},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic weighted ensemble learning for ballast resistance estimation driven by vehicle-ground information fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Future of humanity in an artificial intelligence centric world. <em>EAAI</em>, <em>162</em>, 112405. (<a href='https://doi.org/10.1016/j.engappai.2025.112405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This scholarly article rigorously investigates the transformative and disruptive roles of artificial intelligence (AI) in influencing the trajectory of human society. By concentrating on three fundamental sectors—healthcare, finance, and education—it evaluates the ways in which AI augments operational efficiency, facilitates intricate decision-making processes, and introduces innovative capabilities such as personalized medicine and automated financial systems. Concurrently, the analysis underscores urgent ethical dilemmas, encompassing algorithmic bias, accountability deficiencies, data privacy vulnerabilities, and workforce displacement. Employing real-world examples such as Deepfakes, and Neuralink, the article contextualizes emerging challenges within a dynamic socio-technical framework. The research offers a cohesive conceptual model that amalgamates technical, ethical, and governance aspects of AI, while presenting policy recommendations designed to promote transparency, equity, and human-centered AI development. The study emphasizes the necessity for reliable AI systems that humans can trust. The conclusions accentuate the immediate necessity for robust regulatory frameworks and sector-specific ethical supervision to ensure that advancements in AI are harmonized with the well-being of society.},
  archive      = {J_EAAI},
  author       = {Sunil Baloda and Monika Sharma and Mukesh Kumar},
  doi          = {10.1016/j.engappai.2025.112405},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112405},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Future of humanity in an artificial intelligence centric world},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel federated deep learning for intrusion detection in smart grid cyber-physical systems. <em>EAAI</em>, <em>162</em>, 112404. (<a href='https://doi.org/10.1016/j.engappai.2025.112404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of sophisticated computational, communicative, and physical elements in Smart Grid Cyber-Physical Systems (SGCPS) has greatly improved the efficiency and reliability of power grids. However, this complexity introduces enhanced cybersecurity risks, evidenced by significant cyberattacks on the Ukrainian power grid during 2015 and 2016. Despite progress in Artificial Intelligence (AI)-driven security solutions for SGCPS, practical deployment of these technologies is often limited due to a lack of high-quality attack data and owners’ hesitance to distribute sensitive details. This paper introduces an innovative strategy to fortify SGCPS against diverse network threats via a comprehensive intrusion detection system. We present a deep learning model leveraging a temporal convolutional network with multi-feature integration, aimed at robust threat identification. We also propose a federated learning framework enabling various SGCPS to jointly develop an extensive intrusion detection model, ensuring data privacy. Moreover, we incorporate a gradient compression technique utilizing the Long Short Term Memory- β -Total Correlation Variational Autoencoder (LSTM- β -TCVAE) model to enhance and secure model parameters throughout the training phase. Thorough experimental validations confirm the efficacy of our method in recognizing multiple cyber threat types to SGCPS and its advantages over current methods.},
  archive      = {J_EAAI},
  author       = {Rong Xie and Bin Wang and Xin Xu},
  doi          = {10.1016/j.engappai.2025.112404},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112404},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel federated deep learning for intrusion detection in smart grid cyber-physical systems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tunnel-YOLO: An improved you only look once algorithm for real-time shield tunnel lining leakage detection. <em>EAAI</em>, <em>162</em>, 112403. (<a href='https://doi.org/10.1016/j.engappai.2025.112403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting crack leakages in shield tunnels is crucial for ensuring structural safety and extending service life, as traditional detection methods are limited by high subjectivity and low accuracy. To address these limitations, this paper proposes Tunnel-YOLO, an improved object detection algorithm based on You Only Look Once version 8 (YOLOv8). This algorithm replaces standard convolutional blocks with a novel Receptive Field Channel Attention Convolution (RFCAConv) module, which leverages dynamic receptive fields to enhance feature capture at different scales. We also introduce a C2f_SGE module, integrating the Spatial Group-wise Enhance (SGE) attention mechanism into the C2f (CSPNet with 2 convolutions) block to significantly improve feature extraction while suppressing background interference. Furthermore, an Edge Feature Enhancement Detection Head (EFE-Head) incorporates deconvolution layers to enhance fine-grained details for more precise boundary localization. To better accommodate the shape-sensitive detection task, our LeShape-IoU (Intersection over Union) loss function is designed to focus on the shape and scale characteristics of target bounding boxes. Experimental results on a public, real-world dataset demonstrate that Tunnel-YOLO significantly outperforms the baseline, increasing Recall, Precision, and mean Average Precision at 0.5 IoU (mAP50) by 15.7%, 10.3%, and 14.8%, respectively. Comparative analysis with other mainstream algorithms further validates the effectiveness and superiority of the proposed Tunnel-YOLO.},
  archive      = {J_EAAI},
  author       = {Ruijun Yang and Hao Zhang},
  doi          = {10.1016/j.engappai.2025.112403},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112403},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tunnel-YOLO: An improved you only look once algorithm for real-time shield tunnel lining leakage detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of data-driven predictive model and enhanced multiobjective optimization to improve the excavation performance of large-diameter slurry shields. <em>EAAI</em>, <em>162</em>, 112402. (<a href='https://doi.org/10.1016/j.engappai.2025.112402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety, efficiency and energy consumption are important aspects for evaluating the performance of large-diameter slurry shield, and improving the performance of shield is crucial for safe and efficient excavation. To this end, a data-driven hybrid method is developed to improve the excavation performance of large-diameter slurry shields by intelligence regulating shield parameters. This method combines Bayesian Optimization with categorical boosting (BO-CatBoost) and enhanced multiobjective evolutionary algorithm based on decomposition (EMOEA/D). The method uses surface settlement, penetration and specific energy as output targets and employs the expert knowledge to select the input parameters. Subsequently, the trained BO-CatBoost model is employed to fit the input-output relationship. On this basis, the multiobjective optimization process was performed using EMOEA/D, with the important parameters determined by Shapley Additive exPlanations as decision variables and the nonlinear relationship fitted by BO-CatBoost as the objective function. Finally, the technique for order preference similarity to ideal solution is applied to obtain optimal operational parameters, thereby enhancing the excavation performance of large-diameter slurry shield. The proposed method is applied to a Wuhan rail transit line to verify the effectiveness, and the result shows that: (1) Our method can accurately predict the three targets with goodness of fit ranging from 0.938 to 0.988, respectively. (2) The proposed method can effectively improve the excavation performance of the large-diameter slurry shield, and reaches 13.88 %, 5.21 %, and 10.88 %, respectively. (3) An adaptive decision-making system for setting operational parameters is constructed, which is valuable for formulating of operational control strategies for large-diameter slurry shields.},
  archive      = {J_EAAI},
  author       = {Feiming Su and Xianguo Wu and Tiejun Li and Yang Liu},
  doi          = {10.1016/j.engappai.2025.112402},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112402},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of data-driven predictive model and enhanced multiobjective optimization to improve the excavation performance of large-diameter slurry shields},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive active adaptive partial label learning under class distribution mismatch. <em>EAAI</em>, <em>162</em>, 112401. (<a href='https://doi.org/10.1016/j.engappai.2025.112401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial label learning is an important learning framework where each training sample is associated with a candidate label set and its ground-truth label is included in the candidate label set. Active partial label learning is a variation where training data consists of both labeled and unlabeled samples. However, there exists the problem of class distribution mismatch, wherein the unlabeled sample set contains many instances out of the target categories. In this paper, a contrastive active adaptive partial label learning method under class distribution mismatch which combines active partial label learning with contrastive coding is proposed. A novel active sample selection strategy is first established to use label propagation ability to measure the optimization ability of unlabeled samples to partially labeled samples. Furthermore, to solve the problem of class distribution mismatch, a joint query score based on contrastive coding is utilized to reduce the queries of unlabeled samples out of target categories. Finally, the above two indicators are combined adaptively to select the most valuable unlabeled samples in target categories for manual labeling and the selected samples will be added to the training sample set to train the new classifier. The effectiveness and efficiency of the method are evaluated by performing experiments on the datasets CIFAR10 and CIFAR100.},
  archive      = {J_EAAI},
  author       = {Aohan Zhang and Kezhen Dong and Hongying Zhang},
  doi          = {10.1016/j.engappai.2025.112401},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112401},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contrastive active adaptive partial label learning under class distribution mismatch},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A framework for photovoltaic power forecasting based on hybrid data reconstruction, neural network models fusion, and multi-objective optimization. <em>EAAI</em>, <em>162</em>, 112400. (<a href='https://doi.org/10.1016/j.engappai.2025.112400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intermittency of photovoltaic power seriously affects the safety and operation of the power grid. Accurate photovoltaic power forecasting is critical for a safe connection of large-scale solar energy to the grid. Despite the efforts of many researchers, current forecasting methodologies remain inadequate. To bridge this gap, leveraging the recent advancements in artificial intelligence algorithms, this work combines cutting-edge deep learning techniques and data preprocessing strategies to develop a forecasting system that comprehensively considers various influencing factors and integrates multiple deep learning neural networks. The framework enables deterministic forecasting and uncertainty analysis, providing reliable supporting information for accurate forecasting through hybrid decomposition data preprocessing and feature selection modules. Then, closed-form continuous-time (Cfc) neural networks are introduced as one of the core forecasting components. Theoretically, the validity of the combined model and the Pareto optimization process are proved. Practically, the multi-objective African vultures optimization (MoAvo) is employed to identify the Pareto optimal solution, integrate four models, and improve the model's adaptability to external environmental changes. The experimental results show that the average mean absolute percentage error (MAPE) of the designed combined system for 1–3 steps forecasting on the Yulara are 6.09 %, 8.15 %, and 10.03 %, respectively. The results demonstrate that the framework fully considers the influence of candidate variables on forecasting, offering significant advantages over comparison models.},
  archive      = {J_EAAI},
  author       = {Menggang Kou and Jianzhou Wang and Jingrui Li and Runze Li and Zhiwu Li},
  doi          = {10.1016/j.engappai.2025.112400},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112400},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A framework for photovoltaic power forecasting based on hybrid data reconstruction, neural network models fusion, and multi-objective optimization},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A binary particle swarm optimization with dual encoding mechanism for feature selection. <em>EAAI</em>, <em>162</em>, 112397. (<a href='https://doi.org/10.1016/j.engappai.2025.112397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a crucial machine learning preprocessing stage with numerous practical uses. Numerous algorithms are created to tackle the task. However, these algorithms still suffer from several challenges. This study introduces a novel binary particle swarm optimization with dual encoding mechanism, named DEBPSO, to solve feature selection problems. A new transfer function, called an inverse S-shaped function, and a Boolean encoding mechanism are employed to enhance the exploration performance of DEBPSO. In addition, to better balance exploration and exploitation, a new game mechanism is proposed to find the best solution. In order to verify the performance of DEBPSO, a comprehensive experimental is designed. The experimental results on 27 well-known datasets show that DEBPSO significantly outperforms the compared algorithms on 17, 14, 13, 17, 16, 21, 14, 23, 20 datasets in terms of classification error rate, highlighting its efficiency in reducing the classification error rate and irrelevant features.},
  archive      = {J_EAAI},
  author       = {Chong Zhou and Rumeng Liang and Qi Liu and Sirui Niu},
  doi          = {10.1016/j.engappai.2025.112397},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112397},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A binary particle swarm optimization with dual encoding mechanism for feature selection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel weight-optimized machine-learning hybrid model for daily river runoff prediction. <em>EAAI</em>, <em>162</em>, 112396. (<a href='https://doi.org/10.1016/j.engappai.2025.112396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The daily runoff process has been characterized as nonlinear and unsteady due to the impacts of watershed precipitation and evaporation, vegetation coverage rate, reservoir operations and other human activities. In recent years, machine-learning (ML) models have been widely applied in the daily runoff predictions, but the robustness and effectiveness of individual ML model is always limited. A novel weight optimization scheme has been introduced to ML models to obtain accurate predictions of daily river runoff. Variational modal decomposition method is adopted in the dataset preprocessing, and the runoff prediction performance of various classic ML models, including Genetic Algorithm-Back Propagation neural network (GA-BP), Long Short-Term Memory network (LSTM), Elman neural network (Elman) and Genetic Algorithm-Support Vector Machine (GA-SVM) are subsequently evaluated. A particle swarm optimization (PSO) based weight optimization strategy is proposed to combine different types of ML models, thus more accurate and robust results could be obtained. The ten-fold cross-validation method has been adopted and the performance of the optimized hybrid models are further evaluated for different schemes. A case study at Hankou hydrological station demonstrates that root mean square error (RMSE) and mean absolute percentage error (MAPE) is improved by 35.7 %, 75.8 % respectively for the optimized hybrid model. The present study shares useful insights to the comprehensive optimization of various ML models in the intelligent management of water resources.},
  archive      = {J_EAAI},
  author       = {Zhonglian Jiang and Jianglong Ying and Zhen Yu and Xiao Chu and Chengqiang Yu},
  doi          = {10.1016/j.engappai.2025.112396},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112396},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel weight-optimized machine-learning hybrid model for daily river runoff prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent assessment of habitat quality based on multiple machine learning fusion methods. <em>EAAI</em>, <em>162</em>, 112395. (<a href='https://doi.org/10.1016/j.engappai.2025.112395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating habitat quality can help balance the relationship between economic development and biodiversity conservation, and it serves as a foundation for constructing an ecological security pattern. However, research on the intelligent construction of habitat quality is limited. This study develops a comprehensive framework to assess habitat quality based on optimized machine learning methods. The findings of the research are as follows: (1) From the perspective of human-machine interactive interpretation, ensemble learning is used to enhance the performance of basic classifiers, resulting in a classification map with high precision and recall. (2) The particle swarm optimization (PSO) algorithm can improve the goodness of fit of the Extreme Gradient Boosting (XGBoost) inversion model by 4–5 %. (3) The habitat quality inversion method based on XGBoost-PSO has high credibility and application value, with its texture structure being the result of both expert experience and image information interaction. (4) The model demonstrates certain application potential in downscaling; under the seven-band perspective, the blue and near-infrared bands are the most important, while in the four-band perspective, green and near-infrared bands take precedence.},
  archive      = {J_EAAI},
  author       = {Kui Yang and Dongge Cui and Chengrui Wang and Qi Tang and Linguang Miao},
  doi          = {10.1016/j.engappai.2025.112395},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112395},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent assessment of habitat quality based on multiple machine learning fusion methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical semantics guided multi-scale correlation network for alignment-free red-green-blue and thermal salient object detection. <em>EAAI</em>, <em>162</em>, 112394. (<a href='https://doi.org/10.1016/j.engappai.2025.112394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGBT (red-green-blue and thermal) salient object detection (SOD) aims to identify and highlight the most visually salient objects in an image by leveraging the complementary information from both RGB and thermal (TIR) modalities. It is particularly effective for 24/7 intelligent surveillance and autonomous perception in smart city security and traffic monitoring, especially under low light and adverse weather. However, existing methods primarily rely on manually aligned datasets, which are limited in handling the challenges posed by unaligned multi-modal data in real-world applications. Furthermore, these methods usually extract complementary information from both modalities using fixed-size windows (Liuet al., 2022, Wanget al., 2024b). However, such fixed-size windows are not effective in dealing with unaligned multi-modal images due to spatial inconsistencies. Additionally, existing methods often use single-layer high-level feature to represent semantic information, which fails to fully exploit the complementary benefits of multi-level features, thereby reducing the effectiveness of semantic guidance. To address these challenges, we propose a Hierarchical Semantics guided Multi-scale correlation Network (HSMNet) for alignment-free RGBT SOD. A Hierarchical Semantic Fusion Module (HSFM) dynamically assigns weights to features from multiple levels, enabling adaptive fusion of multi-level semantic information. A Multi-scale Asymmetric Correlation Module (MACM) employs windows of various sizes to capture asymmetric correlations between unaligned multi-modal data, enhancing cross-modal complementary information extraction even when data are not perfectly aligned. We conduct extensive experiments on unaligned, weakly aligned and aligned RGBT SOD datasets, with results demonstrating that our method outperforms state-of-the-art algorithms, achieving superior accuracy and robustness in both unaligned and weakly aligned RGBT SOD scenarios.},
  archive      = {J_EAAI},
  author       = {Chengmei Han and Lei Liu and Kunpeng Wang and Fei Xie and Bing Wei},
  doi          = {10.1016/j.engappai.2025.112394},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112394},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical semantics guided multi-scale correlation network for alignment-free red-green-blue and thermal salient object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear dynamic modeling of turbojet engines using combined convolutional and long short-term memory networks. <em>EAAI</em>, <em>162</em>, 112393. (<a href='https://doi.org/10.1016/j.engappai.2025.112393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Turbojet engines are widely used in small-scale aerial vehicles, but their nonlinear and time-varying dynamics present significant challenges for accurate modeling and control. Traditional system identification methods often struggle to capture these complex behaviors, particularly under limited data conditions. This study proposes a novel hybrid neural network architecture that combines convolutional neural networks and long short-term memory units. The model is specifically designed for small-sample scenarios, enabling robust learning and precise engine speed prediction from real input-output sequences. The input vector comprises the current engine speed, the next-step pulse-width modulation command, and its increment, enhancing the model’s responsiveness and reducing phase-lag effects. The proposed model is trained and evaluated on a real-world dataset containing 38,257 samples, with 80 % used for training and 20 % for testing. Its predictive performance is assessed using step input responses and three evaluation metrics: mean absolute error, root mean square error, and Pearson correlation coefficient. Experimental results demonstrate that the proposed hybrid architecture outperforms other recurrent models in capturing transient dynamics and accurately reproducing real engine behavior. These findings highlight the model’s effectiveness in modeling nonlinear engine dynamics and its potential as a data-efficient alternative to traditional identification techniques for small-scale turbojet applications.},
  archive      = {J_EAAI},
  author       = {Chen Lei and Dong Wei and Su Hang and Chi Yutian and Tian Congling and Gao Yongzhuo and Wu Dongmei and Dong Hui},
  doi          = {10.1016/j.engappai.2025.112393},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112393},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear dynamic modeling of turbojet engines using combined convolutional and long short-term memory networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scientific machine learning for generic compact model parameter extraction of nanoscale transistors. <em>EAAI</em>, <em>162</em>, 112392. (<a href='https://doi.org/10.1016/j.engappai.2025.112392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a framework to automate modelcard extraction of industry-standard compact models. This framework presents a Scientific Machine Learning (ScML) approach capable of inverse modeling. It integrates a random forest model with an artificial neural network to produce efficient and precise regression results. This new method is used for parameter extraction in the standard compact models of the semiconductor device industry. Modeling of a multi-gate Field Effective Transistor (FET) with an industry-standard compact model like Berkeley Short-channel Insulated-Gate Field-Effect Transistor Model – Common Multi-Gate (BSIM-CMG) is taken as an example to illustrate and describe the framework and highlight its key advantages. Proposed framework is useful in numerous aspects; it holds vital principles of physics, avoids depending on massive datasets, and has a sparse architecture while avoiding accuracy trade-offs. The framework is tested on production-level experimental devices to evaluate the real-world performance. This framework significantly reduces the time and cost of parameter extraction for the Process Design Kits (PDKs) development. Therefore, this is of immediate importance for fabrication and Electronic Design Automation (EDA) industries.},
  archive      = {J_EAAI},
  author       = {Kumar Sheelvardhan and Surila Guglani and Abhilash Dubey and Shashank Dubey and Sindhu Ramaswamy and Vaidy Subramanian and Kassandra Anderson and Glenn Workman and Sourajeet Roy and Avirup Dasgupta},
  doi          = {10.1016/j.engappai.2025.112392},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112392},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scientific machine learning for generic compact model parameter extraction of nanoscale transistors},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed graph neural network for 3D spatiotemporal structural response modeling of flexible pavements. <em>EAAI</em>, <em>162</em>, 112391. (<a href='https://doi.org/10.1016/j.engappai.2025.112391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying pavement damage is crucial for roadway agencies' maintenance planning. This study proposed a Physics-informed Graph Neural Network-based Pavement Simulator (PhyGPS) to predict three-dimensional (3D) asphalt concrete pavement responses, building upon an established data-driven Graph Neural Network-based Pavement Simulator (GPS) model. The key innovation lies in integrating knowledge graphs and mechanics equations to create a physics loss function, distinguishing it from its data-driven counterpart. The physics loss function comprises strain-displacement and stress loss components derived from 3D strain-displacement relations and stress equilibrium principles. A thorough 3D finite element (FE) pavement database supported the model development. The 3D FE pavement data was transformed into graph format where nodes and edges represent 3D FE pavement models’ nodes and node connections, respectively. Performance evaluation employed two case studies: “OneStep” for assessing short-term predictive capabilities and “Rollout” for examining long-term prediction accuracy under practical conditions. Results demonstrated that the physics-informed GPS model showed superior long-term predictive capability and robustness while maintaining excellent short-term accuracy compared to the data-driven model. Both models achieve rollout time under 8 s per FE simulation case, a dramatic improvement over the 12-h runtime of traditional 3D FE pavement models. The PhyGPS model successfully integrates physics principles, spatial relationships between structural components, temporal correlations in structural data, and complex material properties, offering an accurate, robust, and computationally efficient solution for predicting 3D pavement responses.},
  archive      = {J_EAAI},
  author       = {Fangyu Liu and Imad L. Al-Qadi},
  doi          = {10.1016/j.engappai.2025.112391},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112391},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed graph neural network for 3D spatiotemporal structural response modeling of flexible pavements},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Health state estimation of retired batteries based on physical constraints. <em>EAAI</em>, <em>162</em>, 112390. (<a href='https://doi.org/10.1016/j.engappai.2025.112390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing use of retired lithium-ion batteries, accurately monitoring their health status has become increasingly important. This study proposed a method to estimate the health of retired batteries by embedding their capacity degradation characteristics directly into the loss function of a Bidirectional Long Short-Term Memory (BiLSTM) network, combined with a Physically Informed Neural Network (PINN) model. The model is developed by incorporating the dynamics of the solid electrolyte interface (SEI) membrane, which evolves as the lithium-ion poles of the retired battery move. By combining these dynamics with the governing equations of motion, a partial differential equation (PDE) is derived. This approach integrates physical constraints, data-driven learning, and PDEs into a composite loss function. The proposed method is validated on two different datasets under varying operating temperatures. The results show that the PINN-BiLSTM model achieves a Root Mean Square Percentage Error (RMSPE) of 0.024, representing a 9.67 % improvement over the PINN-LSTM. This adaptive PINN method offers highly accurate health state predictions across temperature variations, thus supporting the sustainable use of retired batteries in secondary applications and helping to mitigate energy scarcity.},
  archive      = {J_EAAI},
  author       = {Fei Xia and Qianwen Dong and Lin Xia and Zhenyi An and Ziyang Xia and Chunyang Gong},
  doi          = {10.1016/j.engappai.2025.112390},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112390},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Health state estimation of retired batteries based on physical constraints},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive cybersecurity in bio-medical modules: A dynamic programming neural network-based protection for markov-chain fabricated data attacks. <em>EAAI</em>, <em>162</em>, 112389. (<a href='https://doi.org/10.1016/j.engappai.2025.112389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advances in communication technologies, remote monitoring and control of drug delivery are becoming prevalent in bio-medical engineering. In a chemotherapy system, the measurement signals can be wirelessly transferred to the control center by communication networks. Nevertheless, the avenues of communication might be jeopardized by false data injection (FDI), which poses significant risks to the security and stability of biomedical systems. In this work, a defense mechanism is developed to tackle the effect of FDI threats in the networked chemotherapy system. In particular, the effect of FDI attacks on the chemotherapy system is modeled by the Markov chain process. The proposed defense mechanism is designed in two parts: i ) a data-driven sliding mode observer (DDSMO) is utilized to identify the occurrence of cyber attacks in the tumor signals measured by the bio-sensor, and ii ) a mitigation scheme based on a dynamic rejection compensator (DRC) to compensate for the impact of cyber threats. In the mitigation phase, a goal representation heuristic dynamic programming (GrHDP) is adopted to adaptively adjust the parameters of DRC and to dynamically handle the cyber threats. The designed mitigation mechanism not only regulates the cancerous cells against cyber threats but also minimizes the side effects of drug delivery by regulating the output of normal cell and immune cell. Compared to prevalent methodologies, the proposed approach yields significant performance, including a 60.23 % improvement over the without protection, 37.48 % over the DDSMO-based model predictive controller (MPC), 35.95 % over the reinforcement learning (RL) based Kalman filter, and 70.44 % over the proportional integral (PI) based Kalman filter.},
  archive      = {J_EAAI},
  author       = {Mostafa Taheri and Juliang Yin and Zahra Rasooli Berardehi},
  doi          = {10.1016/j.engappai.2025.112389},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112389},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive cybersecurity in bio-medical modules: A dynamic programming neural network-based protection for markov-chain fabricated data attacks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted multi-source domain unsupervised adaptive network for rotating machinery fault diagnosis based on dual adversarial. <em>EAAI</em>, <em>162</em>, 112386. (<a href='https://doi.org/10.1016/j.engappai.2025.112386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-domain adaptive methods are becoming a growing focus of fault diagnosis, which can provide enhanced data support for models using the feature information from various source domains. As a most commonly used method, unsupervised multi-domain adaptive methods (UMA) can eliminate the requirement for the label of the target domain samples. However, the neglect of contributions from different source domains to the target domain and insufficient utilization of diagnostic information from multiple source domains are the widely limitation of UMA. Therefore, a dual-adversarial weighted multi-source domain unsupervised adaptive network (DAWMUN) is proposed to utilize diagnostic information from multi-source domains and consider the contribution of different source domains. Firstly, the shared feature extractor and dual adversarial training with the domain adversarial modules between multi-source domains and source-target domains are used to enhance domain confusion between multi-source and target domains (MSTD). Secondly, based on Multiple Kernel Maximum Mean Discrepancy (MK-MMD), a novel weighting mechanism and the corresponding training framework are constructed to effectively reduce negative transfer. Finally, a novel weighted classifier is proposed to merge the outputs of multiple classifiers and synthesize the impact of each source domain. The performance of the DAWMUN is validated using a rotating machinery dataset across various transfer tasks under different rotational speed and load conditions. The experimental results demonstrate that the diagnostic accuracy using the proposed DAWMUN is superior to existing SSDA and MSDA methods, with the average accuracies of 98.53 % and 98.23 % across six tasks in two separate experimental setups. The comparison to the existing methods results that the DAWMUN still demonstrates superior performance with improvements of 2.54 % and 2.86 %, respectively.},
  archive      = {J_EAAI},
  author       = {Wenqi Wang and Zongzhen Zhang and Jinrui Wang and Baokun Han and Huaiqian Bao and Zhikang Fan and Rongkang Ge},
  doi          = {10.1016/j.engappai.2025.112386},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112386},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Weighted multi-source domain unsupervised adaptive network for rotating machinery fault diagnosis based on dual adversarial},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Twin-stream network: Enhancing wave prediction by capturing spatiotemporal information. <em>EAAI</em>, <em>162</em>, 112385. (<a href='https://doi.org/10.1016/j.engappai.2025.112385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wave prediction is a critical challenge in ocean and coastal engineering, particularly for understanding and mitigating the effects of sea waves on structures such as ships, offshore platforms, and coastal defenses. A novel machine learning model, Twin-Stream Network (TSNet), is proposed to enhance wave prediction accuracy by leveraging temporal and spatial dependencies in historical data. The TSNet model along with other baseline models are evaluated, in both single-point and multi-point forecasting tasks, by various performance metrics across different datasets including one-dimensional-linear, one-dimensional-nonlinear, two-dimensional-linear and two-dimensional-nonlinear water waves. The comprehensive comparative analysis demonstrates that the TSNet model outperforms others, especially in the multi-point forecasting task. This study provides a valuable insight into the effectiveness of machine learning approaches and highlights the potential of the accuracy improvement for wave prediction.},
  archive      = {J_EAAI},
  author       = {Junhao Xu and Zhongying Feng and Zhan Wang and Kun Zheng and Ruipeng Li},
  doi          = {10.1016/j.engappai.2025.112385},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112385},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Twin-stream network: Enhancing wave prediction by capturing spatiotemporal information},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clean-sample guided cross-modal retrieval with adaptive weighted contrastive learning. <em>EAAI</em>, <em>162</em>, 112383. (<a href='https://doi.org/10.1016/j.engappai.2025.112383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal retrieval enables efficient integration of information by linking different data modalities, such as images and text. As data volumes increase rapidly, the need for effective cross-modal interaction grows. Cross-modal hashing is favored for its low storage requirements and fast retrieval speed, but many existing methods depend on accurately labeled data, which can be subjective and expensive to obtain. To address this limitation, we propose Clean-guided Adaptive Weighted Contrastive Hashing (CAWCH), a novel framework designed to improve robustness against noisy labels. CAWCH incorporates two main components: a Gaussian Mixture Model (GMM)-based noise purifier that identifies reliable and noisy samples by modeling sample loss, and a contrastive learning strategy that selectively chooses positive samples and adaptively assigns weights based on multi-label similarity, considering both intra- and inter-modal relationships. Extensive experiments demonstrate that CAWCH significantly outperforms existing methods under noisy label conditions, highlighting its effectiveness and potential for real-world cross-modal retrieval applications.},
  archive      = {J_EAAI},
  author       = {Shuni Jiang and Zhixin Li},
  doi          = {10.1016/j.engappai.2025.112383},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112383},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Clean-sample guided cross-modal retrieval with adaptive weighted contrastive learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Denoising of the magnetic flux leakage signal using dynamic feature fusion and a multi-scale autoencoder network. <em>EAAI</em>, <em>162</em>, 112382. (<a href='https://doi.org/10.1016/j.engappai.2025.112382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic flux leakage (MFL) signal denoising is essential for the nondestructive inspection of oil and gas pipelines, where complex noise interference can severely degrade defect quantification accuracy. Traditional approaches such as mean filtering and wavelet transform offer limited suppression of multi-type mixed noise and often distort critical features, including defect peaks and valleys. Even deep learning–based MFL denoising methods struggle in scenarios with substantial signal-noise overlap due to inadequate feature extraction and limited adaptability.This work presents an advanced denoising framework that combines dynamic feature fusion with a multi-scale autoencoder network. The framework jointly exploits time- and frequency-domain signal components, employing an adaptive weighting mechanism for dynamic feature fusion. Parallel convolutional branches extract multi-scale features, improving the capture of both global structures and fine-grained details, while a Squeeze-and-Excitation (SE) channel attention mechanism enhances defect-sensitive features and suppresses noise. Extensive experiments demonstrate that the proposed model outperforms mean filtering, wavelet denoising, and a baseline autoencoder, achieving notable gains in signal-to-noise ratio (SNR), mean squared error (MSE), and signal similarity. Beyond superior noise suppression, the method preserves critical defect characteristics, providing a robust and reliable foundation for precise defect quantification in pipeline MFL inspection.},
  archive      = {J_EAAI},
  author       = {Lushuai Xu and Shaohua Dong and Haotian Wei and Feng Li and Pengkun Zhang and Cong Zuo and Mingxing Guo and Penghui Liao},
  doi          = {10.1016/j.engappai.2025.112382},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112382},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Denoising of the magnetic flux leakage signal using dynamic feature fusion and a multi-scale autoencoder network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimisation approach guided by crack variation mechanism in the informer prediction model. <em>EAAI</em>, <em>162</em>, 112381. (<a href='https://doi.org/10.1016/j.engappai.2025.112381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring (SHM) faces a fundamental challenge in reconciling predictive performance with physical interpretability for infrastructure diagnostics. Conventional deep learning (DL) approaches neglect essential mechanisms governing crack width variation—including thermal gradients, hysteretic responses, and phase-shifted correlations—limiting their reliability in real-world applications. To bridge this gap, we propose a mechanism-guided optimization (MGO) framework that integrates domain knowledge into the Informer architecture through physics-informed enhancements: auto-correlation modeling for capturing temperature-crack hysteresis, static gated fusion for multi-feature integration, and adaptive elastic net regularization for feature selection. Validated on cable-stayed bridge monitoring data, our framework achieves significant mean absolute error reductions (MAE) (5 %–60 %) and root mean square error reductions (RMSE) (10 %–55 %) versus baseline Informer across all cracks and prediction horizons, with diebold-mariano (DM) tests confirming statistical superiority in most cases. Crucially, it demonstrates superior precision relative to six state-of-the-art benchmarks across all evaluation scenarios. The ordinary least squares (OLS)-enhanced variant further delivers volatility reduction, while sensor failure tests establish quantifiable robustness benchmarks through MAE progression from 0.013 mm to 0.391 mm. This work establishes an interpretable, physics-grounded paradigm that explicitly links environmental drivers to structural degradation.},
  archive      = {J_EAAI},
  author       = {Xujia Liu and Youliang Ding and Fei Xu and Yichao Xu and Kang Yang},
  doi          = {10.1016/j.engappai.2025.112381},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112381},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimisation approach guided by crack variation mechanism in the informer prediction model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight segmentation model based on segment anything model for tongue image segmentation. <em>EAAI</em>, <em>162</em>, 112379. (<a href='https://doi.org/10.1016/j.engappai.2025.112379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tongue image segmentation plays a crucial role in intelligent of diagnosis of Traditional Chinese Medicine. Accurate, efficient, and lightweight tongue segmentation significantly improves both the quality and practical applicability of intelligent disease diagnosis models. To address this challenge, we propose TongueSAM_Lite, a lightweight and fully automated tongue image segmentation model. Based on the Segment Anything Model. Our approach employs knowledge distillation and parameter-efficient fine-tuning to develop a novel lightweight image encoder, high-parameter modules in the Vision Transformer are partially replaced with lightweight image modules, which facilitate the transfer of its feature extraction capabilities while accelerating inference speed and reducing computational resource requirements. Additionally, to eliminate manual annotation of tongue region bounding boxes, we integrate a YOLOX-based automatic Box-prompt generator, enabling end-to-end fully automated prompting and segmentation of tongue images. To validate our approach, various experiments were conducted in three datasets. The results show that compared to the original large-scale model of the Segment Anything Model, TongueSAM_Lite reduces the size of the model by 42.7% and shortens the inference time to 45.43% while retaining the near-complete segmentation accuracy of few-shot learning. TongueSAM_Lite achieves Mean Intersection over Union scores of 96.48%, 98.36%, and 97.53% in the three datasets, respectively, outperforming state-of-the-art segmentation methods. Further validation confirms that the YOLOX-based prompt encoder yields optimal performance for the generation of tongue image bounding boxes. Our proposed approach provides new research insights to advance tongue diagnosis technology of Traditional Chinese Medicine. All codes in this article are available at https://github.com/ruanqunsheng/TongueSAM_Lite .},
  archive      = {J_EAAI},
  author       = {Qunsheng Ruan and Shan Cao and Zhirong Luo},
  doi          = {10.1016/j.engappai.2025.112379},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112379},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight segmentation model based on segment anything model for tongue image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring cross-branch information for semi-supervised remote sensing object detection. <em>EAAI</em>, <em>162</em>, 112378. (<a href='https://doi.org/10.1016/j.engappai.2025.112378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised object detection (SSOD) provides a promising solution to mitigate the annotation costs in remote sensing applications. Mainstream teacher-student based SSOD methods leverage unlabeled images through pseudo labeling, and their effectiveness is fundamentally limited by the inevitable noise in pseudo labels, particularly for remote sensing (RS) scenarios with complex backgrounds and dense, multi-scale and oriented objects. Current methods primarily focus on reducing pseudo label noise through category, scale and Intersection over Union information mining, as well as designing fine-grained confidence thresholding strategies. However, the inherent discrepancy between classification and localization reliability is neglected. In this study, with analyzing the characteristic discrepancies between the classification and localization branches, We propose artificial intelligence (AI) methodological innovation method named cross-branch information incorporation method (i.e., CBI-SSOD) to utilize these discrepancies to assist the training of the classification branch, and thus improve the performance of SSOD methods. Specifically, our method present two key AI innovations. Firstly, we propose a pretext task to extract cross-branch information, which can improve the classification ability by reinforce the consistent predictions between the classification branch and the pretext task. Besides, we propose a pseudo label reassignment approach to adjust the soft classification pseudo labels, and thus suppress pseudo label noise and improve the detection performance. Extensive experiments on Dataset for Object Detection in Aerial Images (DOTAv1.0) and DOTAv1.5 datasets validate the effectiveness and superiority of our method, and demonstrate the practical engineering impact of our method on RS applications and interpretation systems.},
  archive      = {J_EAAI},
  author       = {Shitian He and Huanxin Zou and Yingqian Wang and Xu Cao and Hao Chen and Ning Jing},
  doi          = {10.1016/j.engappai.2025.112378},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112378},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring cross-branch information for semi-supervised remote sensing object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm. <em>EAAI</em>, <em>162</em>, 112376. (<a href='https://doi.org/10.1016/j.engappai.2025.112376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, global climate warming has led to a significant increase in both the frequency and intensity of tropical cyclones (TCs). The development of TCs is often accompanied by frequent lightning activities. The risk of lightning strikes to high offshore wind turbines is substantially elevated. This study evaluates the lightning risk faced by offshore wind farms influenced by tropical cyclones. Firstly, TC paths are analyzed in both spatial and temporal dimensions by linking them with lightning data to examine the distribution of TC-related lightning, and the lightning strike characteristics of offshore wind turbines are investigated. Secondly, a Bayesian Optimization (BO)-based eXtreme Gradient Boosting (XGBoost) model for lightning risk assessment is proposed, incorporating characteristics of TC lightning and offshore wind farms as input variables. The proposed BO-XGBoost model outperforms XGBoost, Bidirectional Long Short-Term Memory (Bi-LSTM), Support Vector Machine (SVM) and Neural Network (NN), achieving a precision of 98.9 % and a recall of 98.9 % on the test set. Additionally, SHapley Additive exPlanations (SHAP) value analysis indicates that TC lightning characteristics and offshore wind farm characteristics significantly impact the model output, enhancing the accuracy of the model. The assessment outcomes provide a theoretical basis for future offshore wind farm planning and guidance for lightning protection measures in offshore wind farms.},
  archive      = {J_EAAI},
  author       = {Qibin Zhou and Kehan Chen and Xiaoyan Bian and Shangjie Chen and Gaopeng Lu},
  doi          = {10.1016/j.engappai.2025.112376},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112376},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond trial-and-error: Predicting user abandonment after a moderation intervention. <em>EAAI</em>, <em>162</em>, 112375. (<a href='https://doi.org/10.1016/j.engappai.2025.112375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current content moderation follows a reactive, trial-and-error approach, where interventions are applied and their effects are only measured post-hoc. In contrast, we introduce a proactive, predictive approach that enables moderators to anticipate the impact of their actions before implementation. We propose and tackle the new task of predicting user abandonment following a moderation intervention. We study the reactions of 16,540 users to a massive ban of online communities on Reddit, training a set of binary classifiers to identify those users who would abandon the platform after the intervention—a problem of great practical relevance. We leverage a dataset of 13.8 million posts to compute a large and diverse set of 142 features, which convey information about the activity, toxicity, relations, and writing style of the users. We obtain promising results, with the best-performing model achieving micro F1-score = 0 . 914 . Our model shows robust generalizability when applied to users from previously unseen communities. Furthermore, we identify activity features as the most informative predictors, followed by relational and toxicity features, while writing style features exhibit limited utility. Theoretically, our results demonstrate the feasibility of adopting a predictive machine learning approach to estimate the effects of moderation interventions. Practically, this work marks a fundamental shift from reactive to predictive moderation, equipping platform administrators with intelligent tools to strategically plan interventions, minimize unintended consequences, and optimize user engagement.},
  archive      = {J_EAAI},
  author       = {Benedetta Tessa and Lorenzo Cima and Amaury Trujillo and Marco Avvenuti and Stefano Cresci},
  doi          = {10.1016/j.engappai.2025.112375},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112375},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Beyond trial-and-error: Predicting user abandonment after a moderation intervention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sampling interval-adaptive transformer for industrial time sequence modeling with heterogeneou s sampling rates in quality prediction. <em>EAAI</em>, <em>162</em>, 112374. (<a href='https://doi.org/10.1016/j.engappai.2025.112374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The industrial data sequences frequently exhibit irregular sampling frequencies, which pose a number of difficulties for data analysis and modeling. The traditional dynamic models like Recurrent Neural Network (RNN) and Transformer are difficult to model such data sequences. The main reason is that these models assume that data sampling frequency should be constant. To this end, a Sampling Interval-Adaptive Transformer (SIA-Trans) is proposed in this paper to adaptively model the temporal information for heterogeneous sampling sequences in industrial processes. The SIA-Trans uses the sampling interval and position embedding block to address the problem of unequal time intervals and rectify the temporal correlations in time series. Then, the interval-aware self-attention net is designed for dynamic data relationship modeling, taking the processed data through the self-attention mechanism. Finally, the predicted output is obtained after the point-wise feed-forward layer. The proposed SIA-Trans is validated on a real-world hydrocracking process to predict the content of hydrocarbon mixture with five carbon atoms (C5) hydrocarbons in light naphtha, as well as the final boiling point of jet fuel.},
  archive      = {J_EAAI},
  author       = {Zijian Xu and Nuo Xu and Kai Wang and Xiaofeng Yuan and Yalin Wang and Chunhua Yang and Weihua Gui and Shuqiao Cheng and Lingjian Ye},
  doi          = {10.1016/j.engappai.2025.112374},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112374},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A sampling interval-adaptive transformer for industrial time sequence modeling with heterogeneou s sampling rates in quality prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection. <em>EAAI</em>, <em>162</em>, 112373. (<a href='https://doi.org/10.1016/j.engappai.2025.112373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of face forgery technology, many forged faces threaten information security. Although existing face forgery detection methods obtain better detection performance on intra-dataset evaluation, the generalization of cross-dataset detection and the robustness against image post-processing operations still need to be improved. To address these issues, we propose a multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection. Specifically, a two-branch architecture is designed to extract spatial and frequency features. To realize the interaction and communication of spatial and frequency information, the cross-modality interaction module is designed to explore the inter-modality correlation by applying across self-attention. Subsequently, a multi-scale feature enhancement module is introduced in the spatial branch to enhance the texture and semantic information of spatial features, improving the robustness of tackling image post-processing operations. In addition, to exploit the complementary relationship between the spatial and frequency features, an adaptive fusion module is designed to establish forged feature dependencies by leveraging spatial self-attention, while learning discriminative feature representations by fusing spatial and frequency features in an adaptive weighted manner. Extensive experimental results on four public datasets demonstrate that the proposed method outperforms other state-of-the-art methods for intra-dataset, cross-dataset, and perturbed dataset evaluations.},
  archive      = {J_EAAI},
  author       = {Chunyin Shi and Chengyou Wang and Xiao Zhou and Zhiliang Qin},
  doi          = {10.1016/j.engappai.2025.112373},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112373},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-modality complementary learning network with cross-modality interaction and adaptive fusion for face forgery detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive neural network tracking control for unknown high-order nonlinear systems: A constructive approximation set based approach. <em>EAAI</em>, <em>162</em>, 112371. (<a href='https://doi.org/10.1016/j.engappai.2025.112371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the problem of adaptive neural network (NN) tracking control for unknown high-order nonlinear systems, with a focus on accurately constructing NN approximation sets. To guarantee the local approximation capabilities of NNs, it is crucial that their input signals remain within corresponding compact sets. However, the unknown functions and powers in high-order nonlinear systems make it difficult to determine these sets accurately. To solve this, we introduce a novel adaptive NN tracking control strategy that integrates signal substitution technique, barrier functions (BFs), and NNs. Specifically, the signal substitution technique converts the original system states into state error variables, along with the desired reference signal and its time derivatives, which serve as part of the NN input. BFs are employed to constrain the state errors, while NNs approximate the transformed unknown system functions. This approach enables precise calculation of bounds for the NN weight estimators, ensuring that the NN approximation sets are constructed. Unlike existing methods, our approach not only proves the existence of NN approximation sets but also provides a constructive design strategy, significantly enhancing the approximation accuracy for unknown nonlinear functions. Simulation results demonstrate the effectiveness and advantages of the proposed method.},
  archive      = {J_EAAI},
  author       = {Yu-Fa Liu and Yong-Hua Liu and Jin-Wa Wu and Jie Tao and Ming Lin and Chun-Yi Su and Renquan Lu},
  doi          = {10.1016/j.engappai.2025.112371},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112371},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive neural network tracking control for unknown high-order nonlinear systems: A constructive approximation set based approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic correlation graph convolution network with embedded temporal correlation extraction for stock price forecasting. <em>EAAI</em>, <em>162</em>, 112370. (<a href='https://doi.org/10.1016/j.engappai.2025.112370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock price forecasting has become a significant and complex research area within financial technology. The dynamic correlations among stocks and the inherent noise in price volatility present considerable challenges in accurately forecasting stock prices and enhancing investment returns. This paper introduces a novel Dynamic Correlation Graph Convolution Network (DyCGCN) with embedded temporal correlation extraction. First, we propose a dual-scale dynamic graph generation method to capture the topological relationships among stocks. Second, we develop a dynamic correlation-temporal convolution module that extracts high-level temporal correlations. Third, we introduce a prospect theory-guided multi-strategy loss function that accommodates the diverse risk preferences of investors. Furthermore, we present a joint regression-classification learning method to extract and leverage stock trend information. Experiments conducted on four real-world datasets demonstrate the superiority of DyCGCN, achieving an average 24.7% reduction in prediction error and a 10.5% improvement in predictive accuracy over baseline models, underscoring its strong potential for practical stock price forecasting.},
  archive      = {J_EAAI},
  author       = {Fang He and Wei Yin and Yilun Jin and Zhengyang Chen},
  doi          = {10.1016/j.engappai.2025.112370},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112370},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic correlation graph convolution network with embedded temporal correlation extraction for stock price forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm. <em>EAAI</em>, <em>162</em>, 112368. (<a href='https://doi.org/10.1016/j.engappai.2025.112368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the convergence of mobile communication, sensing, and computational networks in sixth-generation technology, the integration of sensing and communication with unmanned aerial vehicles (UAVs) is promising. This paper focuses on the contribution of artificial intelligence in optimizing the deployment of UAV swarms for multi-objective target detection applications in sixth-generation networks. Specifically, the artificial intelligence contribution lies in the development of an improved multi-objective particle swarm optimization (IMOPSO) algorithm for solving a complex multi-objective deployment problem. The problem aims to simultaneously optimize communication rate, sensing quality, and energy consumption in the deployment of UAV swarms. To address this, the proposed IMOPSO incorporates chaotic initialization, Lévy flight mutation, dynamic mutation rate, and an elimination mechanism based on opposition-based learning. These innovations are designed to enhance the algorithm’s ability to explore the solution space effectively, overcome premature convergence to local solutions, and improve solution quality. In terms of engineering applications, the IMOPSO is applied to the deployment of UAV swarms for target detection, demonstrating its ability to enhance communication and sensing performance while reducing energy consumption in practical scenarios. Through extensive simulations, we show that the IMOPSO outperforms traditional optimization methods and other baseline algorithms, achieving superior results across all optimization objectives. Specifically, the IMOPSO achieves approximately 5% higher transmission data rate, 9% better sensing quality, and 19% lower energy consumption compared to baseline algorithms across multiple test scenarios. Furthermore, the solutions obtained are not only closer to the optimal front but also more concentrated, indicating higher-quality results.},
  archive      = {J_EAAI},
  author       = {Hongjuan Li and Haiyuan Chen and Miao Wang and Jiahui Li and Hui Kang and Yuzhuo Guan and Xu Lin},
  doi          = {10.1016/j.engappai.2025.112368},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112368},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive semi-supervised learning for specific emitter identification: An iterative clustering and pseudo-label refinement approach. <em>EAAI</em>, <em>162</em>, 112361. (<a href='https://doi.org/10.1016/j.engappai.2025.112361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specific Emitter Identification (SEI) distinguishes radio-frequency (RF) devices by exploiting hardware-induced signal fingerprints, thereby strengthening wireless-layer security. Existing deep learning-based SEI methods depend heavily on labeled data and fixed confidence thresholds for pseudo-labeling, which limits their effectiveness under label scarcity or open-set conditions. To overcome these issues, we propose a progressive semi-supervised learning (ProSSL) method for SEI that combines iterative clustering with contrastive learning to generate adaptive pseudo-labels. ProSSL introduces an “uncertain” class and employs a dual-constraint selector—prediction stability and class diversity—to suppress noisy pseudo-labels and ensure robust propagation. Experiments on the public real-world long range(LoRa) RF-fingerprint dataset show that ProSSL gains 2.90%–6.01% absolute accuracy over state-of-the-art baselines, reaching 96.48% accuracy with 90% labels and 59.88% with only 5% labels. While on the public automatic dependent surveillance-broadcast(ADS-B) Top-10 dataset, ProSSL achieves 84.40% accuracy with 5% labeled data and 99.40% accuracy with 90%labeled data, again outperforming all competing methods. Open-set evaluations further demonstrate that overall accuracy rises from 18.81% when only two classes are known to 62.25% when eight classes are known, confirming strong generalization to unseen emitters and validating ProSSL’s robustness and practicality in realistic wireless environments.},
  archive      = {J_EAAI},
  author       = {Yiting Gao and Ke Wang and Hao Huang and Jiao Wang and Jiaxu Liu and Yao Zheng and Jianqing Li},
  doi          = {10.1016/j.engappai.2025.112361},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112361},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Progressive semi-supervised learning for specific emitter identification: An iterative clustering and pseudo-label refinement approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing scene text image super-resolution via gradient-based graph attention network. <em>EAAI</em>, <em>162</em>, 112360. (<a href='https://doi.org/10.1016/j.engappai.2025.112360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene text image super-resolution is crucial for enhancing text recognition in low-resolution real-world images. Existing methods usually overlook the structured and repetitive layout of text, which can serve as powerful prior knowledge for guiding reconstruction. In this work, we propose a novel framework that incorporates gradient-based graph attention to explicitly model patch-level text layout. The architecture combines a non-local group-wise attention module, a cascaded channel attention module, and a gradient-guided graph attention module to capture both global and local structural dependencies. This design enables more accurate restoration of text contours and layout consistency. Extensive experiments on the benchmark dataset demonstrate that our method achieves superior performance in both image quality and recognition accuracy, outperforming state-of-the-art methods. The code is available at: https://github.com/cvzxy/TSANv2 .},
  archive      = {J_EAAI},
  author       = {Xiangyuan Zhu and Xuchong Liu and Kehua Guo and Wei Zhao},
  doi          = {10.1016/j.engappai.2025.112360},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112360},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing scene text image super-resolution via gradient-based graph attention network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A consistency regularization-based approach integrating anatomical structural relationships and organ category representations for multi-organ segmentation in pigs. <em>EAAI</em>, <em>162</em>, 112359. (<a href='https://doi.org/10.1016/j.engappai.2025.112359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern biomedical research and livestock management, accurate multi-organ segmentation in pigs is essential for breeding programs. However, current methods face challenges due to low imaging contrast, size disparities, and organ shape variability. Additionally, the manual annotation of computed tomography (CT) scans is labor-intensive and costly, limiting available labeled samples. To address these issues, we propose a consistency regularization-based network guided by anatomical structural relationships and global organ category representations, specifically designed for multi-organ segmentation using a limited number of annotated CT scan samples from pigs. Specifically, we designed the SpatialLink Gated Recurrent Unit (GRU) module to extract anatomical structural information and capture dynamic spatial relationships between organs, thereby minimizing segmentation biases caused by organ shape variations. Moreover, we developed the Organ Category Coding module and Guidance module, which integrate consistency regularization and attention mechanisms, enabling the network to accurately extract global organ category representations during the decoding phase, even with a small number of labeled samples, significantly improving segmentation consistency across organs of different sizes. Additionally, We are the first to apply the Visual State Space block to multi-organ segmentation in pigs, using it to extract contextual information. Experiments on 60 pigs demonstrate that our method achieves state-of-the-art results, with significant improvements in segmentation accuracy for the gallbladder and bladder, including a 9.8% and 4.2% Dice score increase, respectively, and a 12.4% and 6.2% boost in Jaccard scores compared to compared with a selection of published methods.},
  archive      = {J_EAAI},
  author       = {Xiang Pan and Hang Fan and Jianlan Wang and Yan Fu and Wei Chu and Weipeng Tai and Jing Gu and Jianming Ni},
  doi          = {10.1016/j.engappai.2025.112359},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112359},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A consistency regularization-based approach integrating anatomical structural relationships and organ category representations for multi-organ segmentation in pigs},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable chest X-ray localization using principal component-based feature selection in deep learning. <em>EAAI</em>, <em>162</em>, 112358. (<a href='https://doi.org/10.1016/j.engappai.2025.112358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification and localization of diseases in chest X-ray (CXR) images are crucial for early diagnosis and timely medical intervention. Traditional localization techniques like Class Activation Mapping (CAM), depend on Global Average Pooling (GAP) layers, restricting their flexibility, while gradient-based methods like Grad-CAM involve computational overhead and limited interpretability. To address these limitations, this study introduces a novel Principal Component Analysis (PCA)-based localization method that eliminates reliance on GAP layers and gradient computations. Utilizing publicly available Kaggle datasets, namely the COVID-19 Radiography Dataset and Tuberculosis (TB) Chest X-ray Database. The proposed approach employs PCA to compress high-dimensional convolutional feature maps extracted from the pretrained VGG16 model into a lower-dimensional, spatially meaningful representation. This enables rapid, interpretable heatmap generation highlighting precise abnormal regions. Experimental results demonstrate that the proposed method achieved an average training loss of 0 . 0835 ± 0 . 1830 and validation loss of 0 . 1385 ± 0 . 0741 across 5-fold cross-validation. In addition, it achieved an impressive accuracy of 97.5%, sensitivity of 98.2%, specificity of 99.4%, a Dice Similarity Coefficient (DSC) of 97.5%, and an Intersection-over-Union (IoU) of 95.1%. Compared to CAM, and Grad-CAM, PCA-based localization significantly reduces inference time, enhances interpretability, and provides robust multi-class localization performance suitable for clinical deployment.},
  archive      = {J_EAAI},
  author       = {Diwakar Diwakar and Deepa Raj},
  doi          = {10.1016/j.engappai.2025.112358},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112358},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable chest X-ray localization using principal component-based feature selection in deep learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast simulation for scattering muography applications using generative adversarial neural networks. <em>EAAI</em>, <em>162</em>, 112357. (<a href='https://doi.org/10.1016/j.engappai.2025.112357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Muography is an emergent non-destructive testing technique that uses cosmic muons to probe the interior of objects and structures. This technique can be employed to perform preventive maintenance of critical equipment in the industry in order to test the structural integrity of the facility. Several muography imaging algorithms based on machine learning methods are being developed in the recent years. These algorithms make exhaustive use of simulated data, usually using packages such as GEANT4 (GEometry ANd Tracking), that exhaustively simulate the detector, to produce training samples. This work presents a faster alternative for the generation of simulated samples based on generative adversarial neural networks. A speed up factor of 80 is observed with this system without any significant degradation of the quality of the simulation.},
  archive      = {J_EAAI},
  author       = {Rubén López Ruiz and Celia Fernández Madrazo and Sergio Sánchez Cruz and Lara Lloret Iglesias and Pablo Martínez Ruiz del Árbol},
  doi          = {10.1016/j.engappai.2025.112357},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112357},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast simulation for scattering muography applications using generative adversarial neural networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on lightweight network for real-time detection of steel structure corrosion based on knowledge distillation. <em>EAAI</em>, <em>162</em>, 112356. (<a href='https://doi.org/10.1016/j.engappai.2025.112356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular and real-time monitoring of corrosion is crucial for ensuring structural safety and extending the service life of infrastructure. With the continuous development of advanced structural health monitoring technologies, intelligent corrosion detection has become an inevitable trend. This study addresses the issues of low accuracy, incomplete detail processing, and missed or false detections in complex scenarios in steel structure corrosion detection, as well as the challenges of high complexity and insufficient real-time performance in deep learning models. We propose a high-performance, lightweight, real-time corrosion detection model, Real-Time Detection Transformer for Corrosion (RT-DETR-Corrosion), based on knowledge distillation. By incorporating lightweight optimization on the RT-DETR-R18 baseline model and a hybrid knowledge distillation approach, the model significantly improves real-time performance and detection accuracy, meeting the application requirements for efficiency and precision in steel structure corrosion detection. Experimental results show that the model exhibits excellent optimization effects in terms of localization accuracy, classification accuracy, and position regression error on both the training and validation sets, while also demonstrating strong generalization ability. In extreme weather conditions (such as rain, fog, snow, and strong light) and complex scenarios (such as occlusion, blur, and low-light environments), the model maintains stable Precision, Recall, and mAP metrics, validating its reliability and applicability in diverse real-world engineering environments. Moreover, visualized heatmap analysis of detection results for different scenarios further confirms the model's precise attention to corrosion regions and its generalization ability, providing essential technical support for steel structure corrosion risk assessment and intelligent monitoring, with significant potential for engineering applications.},
  archive      = {J_EAAI},
  author       = {Jia Hou and Wei Chen and Zhen Duan and Hang Li and Mingyu Yu},
  doi          = {10.1016/j.engappai.2025.112356},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112356},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on lightweight network for real-time detection of steel structure corrosion based on knowledge distillation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Function structures of information measures for n-polygonal interval-valued intuitionistic fuzzy sets and their application in location selection strategy. <em>EAAI</em>, <em>162</em>, 112355. (<a href='https://doi.org/10.1016/j.engappai.2025.112355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interval-valued intuitionistic fuzzy set (IVIFS) represents an organic integration of interval-valued fuzzy sets and intuitionistic fuzzy sets, but it fails to meet the requirements of linearity and closure in arithmetic operations, rendering its computations relatively intricate. Consequently, this paper employs an interval partitioning strategy to mitigate the complexity of arithmetic operations, thereby constructing a novel fuzzy set structure characterized by efficient piecewise linear approximation capabilities. Furthermore, the paper presents the structural form of arithmetic operations for the IVIFS with piecewise linear approximation and demonstrates the simplicity of these operations by an numerical example. In addition, we extend the findings on information measures for polygonal interval-valued intuitionistic fuzzy set pertaining to abstract functions that fulfill particular criteria. Furthermore, we delve into the transformation relationships among these information measures, from which a range of structural formats for information measures can be deduced based on functional expressions and transformation relationships. Finally, similarity measures are applied to company site selection. The validity, practicality and stability of proposed measures have been proven through sensitivity analysis and comparative analysis.},
  archive      = {J_EAAI},
  author       = {Le Fu and Chunfeng Suo},
  doi          = {10.1016/j.engappai.2025.112355},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112355},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Function structures of information measures for n-polygonal interval-valued intuitionistic fuzzy sets and their application in location selection strategy},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-dimensional refined composite multi-scale revised ensemble dispersion entropy and its application to fault diagnosis of rolling bearing. <em>EAAI</em>, <em>162</em>, 112354. (<a href='https://doi.org/10.1016/j.engappai.2025.112354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-dimensional ensemble dispersion entropy (EDE 1D ) can effectively characterize the nonlinear dynamic characteristics of one-dimensional time series, but the complexity of two-dimensional space is not reflected, and only single-scale features can be captured. Firstly, to comprehensively capture the feature information of two-dimensional space, the symmetrized dot pattern (SDP) is introduced to overcome the shortcomings of the ordinary images lack of physical meaning and the time-frequency distribution methods exhibit incomplete information representation, etc. Simultaneously, the amplitude and frequency information are intuitively expressed by a two-dimensional mirror snowflake symmetrized image (MSSI 2D ). Secondly, to overcome the shortcomings of single-scale and traditional coarse-graining, a two-dimensional refined composite multi-scale coarse-graining method is proposed, which improves the accuracy of feature extraction and reduces the calculation deviation. After that, a new feature extraction method namely two-dimensional refined composite multi-scale revised ensemble dispersion entropy (RCMREDE 2D ) is proposed, whose parameter stability and performance are explored through simulation analysis. The results demonstrate that the RCMREDE 2D exhibits excellent stability and anti-noise interference ability. Based on the advantages of RCMREDE 2D , a novel fault diagnosis method for rolling bearings is developed by integrating RCMREDE 2D and a firefly algorithm optimized support vector machine (FA-SVM) multi-fault classifier for pattern recognition. The proposed method is further validated through two measured bearing data sets and five comparative methods, and the results indicate that the RCMREDE 2D and FA-SVM achieve the highest recognition accuracy while demonstrating superior stability.},
  archive      = {J_EAAI},
  author       = {Wenqing Ding and Jinde Zheng and Haiyang Pan and Jian Cheng and Jinyu Tong},
  doi          = {10.1016/j.engappai.2025.112354},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112354},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-dimensional refined composite multi-scale revised ensemble dispersion entropy and its application to fault diagnosis of rolling bearing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse and robust elastic net support vector machine with bounded concave loss for large-scale problems. <em>EAAI</em>, <em>162</em>, 112352. (<a href='https://doi.org/10.1016/j.engappai.2025.112352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The elastic net support vector machine is an extensively employed method for addressing a range of classification tasks. Nevertheless, a significant drawback of the elastic net support vector machine is its high computational cost when dealing with large-scale classification problems. To address this drawback, we first introduce an innovative non-convex elastic net support vector machine model that employs our newly created bounded concave loss function, which effectively attains both sparsity and robustness. Based on proximal stationary point, we have effectively constructed an innovative optimality theory tailored for our newly created elastic net support vector machine model. By leveraging the innovative optimality theory, we have successfully developed a new and exceptionally effective algorithm designed to enhance computational efficiency through the division of the entire dataset into two distinct categories: working sets and non-working sets. During each learning cycle, the parameters associated with the non-working set remain unchanged. In contrast, the parameters related to the working set are subject to updates. Consequently, our new algorithm facilitates quicker modifications on smaller datasets, improving runtime efficiency and lowering computational complexity. Numerical experiments have demonstrated significant efficiency, particularly regarding computational speed, the number of support vectors, and classification accuracy, surpassing eleven other leading solvers.},
  archive      = {J_EAAI},
  author       = {Huajun Wang and Wenqian Li},
  doi          = {10.1016/j.engappai.2025.112352},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112352},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sparse and robust elastic net support vector machine with bounded concave loss for large-scale problems},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of speaker verification: Methods, network architectures, tasks and challenges. <em>EAAI</em>, <em>162</em>, 112351. (<a href='https://doi.org/10.1016/j.engappai.2025.112351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speaker verification is an important branch of biometric recognition, with wide applications in identity authentication, audio monitoring, and other fields. In recent years, deep learning and meta-learning have made remarkable advancements in the field of speaker verification. Therefore, it is necessary to update existing reviews of speaker verification to reflect the latest research developments. We review literature from the past decade to provide a timely and comprehensive survey of the field. First, we outline the concept and system process of speaker verification. Then, we analyze the speech preprocessing process and common acoustic features used in the systems. Next, we present an overview of speaker modeling approaches, covering traditional probabilistic methods, deep learning-based speaker methods, and meta-learning-based speaker methods, focusing on the latter two methods. We provide an in-depth analysis and summary of the characteristics and the latest network architectures of these methods, focusing on the development of Transformer and large-scale pre-trained Transformer. Furthermore, we introduce the datasets and evaluation metrics used in speaker verification systems, focusing on a detailed and fair comparison of the performance of text-dependent and text-independent speaker verification systems. Finally, we explore the challenges faced by speaker verification systems and discuss future research opportunities.},
  archive      = {J_EAAI},
  author       = {Weijie Wang and Hong Zhao and Yikun Yang and Yongjuan Yang},
  doi          = {10.1016/j.engappai.2025.112351},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112351},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of speaker verification: Methods, network architectures, tasks and challenges},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-cost and sparsity for continual semantic segmentation. <em>EAAI</em>, <em>162</em>, 112350. (<a href='https://doi.org/10.1016/j.engappai.2025.112350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have contributed to significant progress in semantic segmentation tasks. However, deep neural networks exhibit a critical drop in performance due to catastrophic forgetting when they are required to learn new tasks incrementally. The more plastic the network is, the easier it can learn new tasks. Whereas, for continual semantic segmentation, it is more reliable to preserve the knowledge it has learned from previous tasks. Here, gated 0-1 Bernoulli variable is used as a regularization method to optimize performance by enhancing network sparsity. Then, the special case of gated 0-1 Bernoulli variable is applied in the replay-based method of continual semantic segmentation. Specifically, when the value of the sub-network sampling rate reaches 0.5, the network reaches the strongest stability. Finally, the gated 0-1 Bernoulli variable improves the network’s performance in complex scenarios and reduces cost under similar performance. Experimental results indicate that in using 100% samples for incremental training, the Mean Intersection over Union(mIoU) of the old classes improves by up to 4.6% and 5.5% compared to the baseline at the end of the overall training in continual semantic segmentation scenarios 10-1 and 10-2. Furthermore, in using 60% samples for incremental training, the performance for the old tasks only drops by less than a percentage, while the time cost to complete the full setup decreases by 22%.},
  archive      = {J_EAAI},
  author       = {Qing Ji and Bin Li and Shaobo Li and Hongchao An and Jing Yang},
  doi          = {10.1016/j.engappai.2025.112350},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112350},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Low-cost and sparsity for continual semantic segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Promoting sustainability-oriented brand activist campaigns: A spherical fuzzy decision support framework for evaluating activist advertising videos. <em>EAAI</em>, <em>162</em>, 112349. (<a href='https://doi.org/10.1016/j.engappai.2025.112349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activist video advertisements represent a strategic form of brand communication in which companies express their stance on social or environmental issues through emotionally driven storytelling and slogan-based narratives. Despite their growing prevalence, there is a notable lack of systematic and quantitative methods for evaluating their performance or comparing their effectiveness across competing brands. This research addresses that gap by proposing a comprehensive decision support system (DSS) designed to assess the performance of activist video advertisements in a structured and reproducible manner. The study introduces a novel hybrid multi-criteria decision-making (MCDM) framework: the spherical cubic fuzzy (SCF)–Aczel-Alsina–ranking comparison (RANCOM)–method based on the removal effects of criteria (MEREC)–deviation-based pairwise assessment ratio technique (DEPART). This methodology integrates subjective weights obtained via SCF–RANCOM and objective weights derived through SCF–MEREC, with both sets of weights combined using SCF-based aggregation operators that incorporate Aczel-Alsina t-norm and t-conorm functions. Performance rankings are then generated using the SCF–DEPART method. To demonstrate the model's applicability, a real-world case study involving eight sustainability-oriented activist video advertisements released in Türkiye was conducted. Evaluations were based on input from ten domain experts across eleven criteria. The analysis identified “convincingness and credibility” as the most critical factor, with “The Voice of Nature” campaign achieving the highest performance rating. The model's robustness was confirmed through scenario-based sensitivity analyses, and its consistency was validated by benchmarking against thirteen alternative MCDM approaches. The findings offer meaningful implications for both academic research and advertising practice.},
  archive      = {J_EAAI},
  author       = {Galip Cihan Yalçın and Karahan Kara and Gülcan Işık and Esra Serdar Tekeli and Vladimir Simic and Abdullah Ballı and Dragan Pamucar},
  doi          = {10.1016/j.engappai.2025.112349},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112349},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Promoting sustainability-oriented brand activist campaigns: A spherical fuzzy decision support framework for evaluating activist advertising videos},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated clustering with mutual knowledge distillation for traffic flow prediction. <em>EAAI</em>, <em>162</em>, 112347. (<a href='https://doi.org/10.1016/j.engappai.2025.112347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction plays a critical role in intelligent transportation systems. Conventional traffic flow prediction methods primarily rely on centralized training, which poses a risk of privacy leakage. Federated learning, a privacy-preserving framework to machine learning, enables distributed participants to jointly train a shared model without sharing local private data. However, traffic flow is typically collected from different devices and contains different temporal patterns, leading to non-independent and identically distributed. To address these challenges, we propose a traffic flow prediction method based on federated clustering with mutual knowledge distillation. We first perform temporal decomposition on the traffic flow data and use mutual learning with adaptive distillation loss to facilitate mutual knowledge transfer among local models during training. Then, we apply spectral clustering to cluster clients based on the cosine similarity of model parameters at the server and design a global model aggregation method to improve the performance of federated learning. Finally, the proposed method is evaluated on two real-world traffic datasets, and the experiment results show significant improvements over traditional federated learning approaches and also outperform federated mutual learning. The results demonstrate that the proposed method effectively captures temporal information and mitigates the effect of non-independent and identically distributed issues.},
  archive      = {J_EAAI},
  author       = {Yao Lin and Shengwu Xiong},
  doi          = {10.1016/j.engappai.2025.112347},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112347},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Federated clustering with mutual knowledge distillation for traffic flow prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantifying hybrid failure mode in cyclic-loaded reinforced concrete shear walls: Integrating unsupervised and supervised learning techniques. <em>EAAI</em>, <em>162</em>, 112346. (<a href='https://doi.org/10.1016/j.engappai.2025.112346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to identify failure types in Reinforced Concrete Shear Walls (RCSWs) by quantifying the contributions of shear and flexural modes in the force-deformation response of the walls. The supporting research database includes images, cyclic curve backbones, and geometric and mechanical characteristics of 253 RCSWs. Initially, the database is manually classified into shear, flexure, and shear-flexure failure modes based on observations of surface damage and the cyclic response of the wall. Subsequently, unsupervised clustering and supervised learning algorithms are employed to probabilistically quantify and predict the participation of flexural and shear modes in the overall seismic response of the walls, respectively. The unsupervised model, utilizing the K-means algorithm, identifies the primary failure modes of the walls, achieving over 90 % concordance with manual expert labeling. Based on the results of unsupervised clustering, a hybridity index is proposed to demonstrate the contributions of shear and flexure failure modes to the overall seismic response. Supervised learning is then used to predict hybridity indices from wall characteristics, with the Extremely Randomized Trees (Extra Trees) model achieving the best results based on a balanced evaluation of multiple performance metrics. SHapley Additive exPlanations (SHAP), a tool for exploring model sensitivity, highlights the aspect ratio as the key influencing factor on failure mode, in accordance with relevant structural engineering codes and standards. Implementation of the proposed framework in exploring the behaviors of four unseen case studies reveals a significant correlation between the predicted hybridity indices and observed damage, consistent with existing guidelines.},
  archive      = {J_EAAI},
  author       = {Pouya Ebrahimi and Amir Hossein Asjodi and Kiarash M. Dolatshahi},
  doi          = {10.1016/j.engappai.2025.112346},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112346},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantifying hybrid failure mode in cyclic-loaded reinforced concrete shear walls: Integrating unsupervised and supervised learning techniques},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-path multiple attention-guided feature interaction network for camouflaged object detection. <em>EAAI</em>, <em>162</em>, 112345. (<a href='https://doi.org/10.1016/j.engappai.2025.112345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Camouflaged Object Detection (COD) methods rely on features from a pre-trained backbone with a single-encoder structure, leading to initial features biased towards global or local preferences. This affects subsequent feature modeling and degrades COD performance. Some studies use modular or auxiliary flow structures to balance feature preferences but often focus only on interactions between hierarchical features or information flows, ignoring potential redundancy or noise within aggregated features. Therefore, we propose a novel dual-path multiple attention-guided feature interaction network (DMAFI-Net) for COD, which contains four main components: global and local features interaction module (GLFI), intra-feature interaction module (IFI), multi-scale feature enhancement module (MFE), and two decoders including neighbor connection decoder based feature aggregation (NFA) and refine decoder. Specifically, the GLFI is designed to implement the interaction and combination of global and local features, and the combined features will be sent to IFI to mine intra-feature information. Besides, the MFE is introduced to further enrich the extracted features obtained in the IFI. In the feature decoding stage, the NFA module utilizes neighbor connection decoder to fuse multi-scale features and ultimately generates a coarse prediction. Finally, the refine decoder leverages multiple attention modules to refine the initial prediction with the combined features as auxiliary cues and obtain the final camouflaged map. Extensive experiments on four COD benchmark datasets demonstrate the superiority of the proposed framework when compared to 24 state-of-the-art (SOTA) methods in terms of five widely used evaluation metrics. Furthermore, the ablation studies show the effectiveness of main components of our DMAFI-Net.},
  archive      = {J_EAAI},
  author       = {Anzhi Wang and Jintao Wu and Shuang Zhao and Yun Liu},
  doi          = {10.1016/j.engappai.2025.112345},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112345},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-path multiple attention-guided feature interaction network for camouflaged object detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TFCTL: Time–Frequency calibrated transfer learning for cross domain depression detection. <em>EAAI</em>, <em>162</em>, 112344. (<a href='https://doi.org/10.1016/j.engappai.2025.112344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the application of speech-based depression detection systems expands, differences in cross-domain data distribution pose significant challenges. This paper proposes the framework of Time–Frequency Calibrated Transfer Learning (TFCTL). This framework first introduces Frequency-Delay Neural Network (FDNN), inspired by Time-Delay Neural Network (TDNN), extending the concept of temporal feature extraction using sliding windows and weight sharing from the time domain to the frequency domain. A multi-level information aggregation module then integrates features of varying abstraction levels from both time-delay and frequency-delay neural networks, balancing global and local speech information. Finally, TFCTL uses transfer learning to calibrate the distribution of the aggregated time–frequency embedding vectors, uncovering commonalities of depression features across different domains. Cross-speaker and cross-corpus experiments were conducted using the Chinese Multimodal Depression Corpus (CMDC) and the Distress Analysis Interview Corpus Wizard-of-Oz (DAIC-WOZ). In cross-speaker scenarios, TFCTL achieved F1 scores of 0.7324 on DAIC and 0.9660 on CMDC, outperforming other methods. In cross-corpus scenarios, TFCTL achieved F1 scores of 0.6743 on DAIC and 0.6879 on CMDC, demonstrating its robustness in addressing domain mismatch issues. The source code used in the paper is available at https://anonymous.4open.science/r/TFCTL-A545/ .},
  archive      = {J_EAAI},
  author       = {Dongdong Li and Li Ding and Zuo Yang and Zhe Wang and Ke Zhao},
  doi          = {10.1016/j.engappai.2025.112344},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112344},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TFCTL: Time–Frequency calibrated transfer learning for cross domain depression detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mutual information guided invertible image hiding network. <em>EAAI</em>, <em>162</em>, 112343. (<a href='https://doi.org/10.1016/j.engappai.2025.112343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image hiding techniques are commonly used for secure communication, copyright protection, and visual privacy. Invertible neural network (INN) have emerged as a promising approach for image steganography, enabling the concealment and recovery of secret images through forward and backward mappings within the network. However, existing methods often face limitations in the accuracy of recovered images due to challenges in estimating the lost information during the forward process. To address this issue, we propose a Mutual Information Guided Invertible Image Hiding Network (MIGIIHNet), which leverages mutual information estimation between the lost information and the stego image in the forward process to guide the backward mapping for reconstruction. Specifically, we propose a lightweight INN with a channel attention feature aggregation module (CAFAM), integrating a channel attention mechanism to optimize the multi-scale aggregation of both low-level and high-level features in a single forward pass. Also, an association learning module (ALM) is designed to model the mutual information between the stego image and the lost information during the forward hiding process. Then, the mutual information is utilized to reconstruct the secret image with high accuracy. Extensive experimental results show that MIGIIHNet outperforms existing state-of-the-art methods in terms of invisibility, security, and recovery accuracy, while maintaining low computational complexity.},
  archive      = {J_EAAI},
  author       = {Kehan Zhang and Fen Xiao and Jingwen Cai and Xieping Gao},
  doi          = {10.1016/j.engappai.2025.112343},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112343},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mutual information guided invertible image hiding network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-tailed detection and classification of wafer defects from scanning electron microscope images robust to diverse image backgrounds and defect scales. <em>EAAI</em>, <em>162</em>, 112342. (<a href='https://doi.org/10.1016/j.engappai.2025.112342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semiconductor engineering, high yield of wafers relies on accurate detection and classification of wafer defects. The dataset for detecting wafer defects presents three primary challenges: (i) different background types, (ii) variable image or defect scales, and (iii) imbalanced data with a long-tailed distribution of defect types. These challenges create significant limitations for traditional classification techniques. To address these issues, we propose a stratified framework called Wafer Detection and Classification (WaferDC), designed specifically for detecting and classifying wafer defects from scanning electron microscope (SEM) images. Our framework achieves high defect detection performance on SEM wafer images by utilizing a multi-cluster memory bank, which effectively handles the challenges of (i) variable background types and (ii) differing image or defect scales. Building on this robust detection, we propose Segmentation and Mix (SegMix), a novel defect augmentation technique based on anomaly heatmaps, which enhances the reliability of defect detection and classification in a (iii) long-tailed imbalanced environment. Finally, we pass defect-classified images through a parameter-efficient fine-tuning (PEFT)-based classifier (Shiet al., 2023) utilizing a vision transformer (ViT) architecture, further improving overall defect detection and classification performance. We rigorously tested WaferDC on a proprietary SEM wafer dataset and the public Describable Textures Dataset-Synthetic (DTD-Synthetic) and Magnetic Tile Defect (MTD) datasets. The results confirm the effectiveness of our method in improving defect detection and classification in wafer manufacturing. Our code is available at https://github.com/SpatialAILab/WaferDC .},
  archive      = {J_EAAI},
  author       = {Taekyeong Park and Yongho Son and Sanghyuk Moon and Seungju Han and Je Hyeong Hong},
  doi          = {10.1016/j.engappai.2025.112342},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112342},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long-tailed detection and classification of wafer defects from scanning electron microscope images robust to diverse image backgrounds and defect scales},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast trajectory planner with a reinforcement learning-based controller for robotic manipulators. <em>EAAI</em>, <em>162</em>, 112341. (<a href='https://doi.org/10.1016/j.engappai.2025.112341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating obstacle-free trajectories for robotic manipulators in unstructured and cluttered environments remains a significant challenge. Existing motion planning methods often require additional computational effort to generate the final trajectory by solving kinematic or dynamic equations. This paper highlights the strong potential of model-free reinforcement learning methods over model-based approaches for obstacle-free trajectory planning in joint space. We propose a fast trajectory planning system for manipulators that combines vision-based path planning in task space with reinforcement learning-based obstacle avoidance in joint space. We divide the framework into two key components. The first introduces an innovative vision-based trajectory planner in task space, leveraging the large-scale fast segment anything (FSA) model in conjunction with basis spline (B-spline)-optimized kinodynamic path searching. The second component enhances the proximal policy optimization (PPO) algorithm by integrating action ensembles (AE) and policy feedback (PF), which greatly improve precision and stability in goal-reaching and obstacle avoidance within joint space. These proximal policy optimization (PPO) enhancements increase the algorithm’s adaptability across diverse robotic tasks, ensuring consistent execution of commands from the first component by the manipulator, while also enhancing both obstacle avoidance efficiency and reaching accuracy. The experimental results demonstrated the effectiveness of proximal policy optimization (PPO) enhancements, as well as simulation-to-simulation (Sim-to-Sim) and simulation-to-reality (Sim-to-Real) transfer, in improving model robustness and planner efficiency in complex scenarios. These enhancements allowed the robot to perform obstacle avoidance and real-time trajectory planning in obstructed environments. https://sites.google.com/view/ftp4rm/home},
  archive      = {J_EAAI},
  author       = {Yongliang Wang and Hamidreza Kasaei},
  doi          = {10.1016/j.engappai.2025.112341},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112341},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast trajectory planner with a reinforcement learning-based controller for robotic manipulators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-level location-routing problem with time windows for mixed-load recycling of heterogeneous batteries: A transformer-based improved deep reinforcement learning algorithm. <em>EAAI</em>, <em>162</em>, 112340. (<a href='https://doi.org/10.1016/j.engappai.2025.112340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the urgency, timeliness and uncertainty of power batteries recycling, we extend a novel network model for retired battery recycling systems, bi-level capacitated location-routing problem with time windows for heterogeneous battery mixed-load (CLRPTW-HBM). Firstly, the expected interval and linear weighting methods are used to transform and process the lower-level multi-objective function that contains fuzzy variables. Secondly, a Transformer-based improved deep reinforcement learning algorithm (Transformer-IDRL) is proposed. (1) The bi-level CLRPTW-HBM is modeled as Markov decision process, and a policy network model with dual-layer encoder-decoder structure is designed based on Transformer architecture. (2) Randomly generate instance data, and the asynchronous advantage Actor-Critic with adaptive dynamic parameter tuning strategy is employed for training. (3) The action sampling strategy based on roulette reverse selection mechanism, and local search strategy incorporating problem characteristics are introduced to improve solution quality. Finally, extensive experiments are conducted on benchmark datasets and actual cases, and the results demonstrate superior performance of Transformer-IDRL, with an average Gap of 0.22 % and 0.19 %, a 5.30 % reduction in recycling cost, and a 6.06 % reduction in battery exposure risk. These satisfactory results highlight the feasibility and efficiency of the proposed model and method. Additionally, sensitivity analysis of model parameters shows that under different decision-maker preferences and vehicle loading capacity, the sensitivity range of path cost is [5.77 %, 39.85 %] and [16.04 %, 35.54 %], while that of exposure risk is [1.40 %, 3.39 %] and [1.35 %, 5.54 %], indicating that parameter variations significant influence the layout of recycling network and overall path cost. Therefore, decision-makers should flexibly adjust key parameters to balance economic benefits and sustainable development in battery recycling.},
  archive      = {J_EAAI},
  author       = {Mengna Zhao and Shiping Chen},
  doi          = {10.1016/j.engappai.2025.112340},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112340},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bi-level location-routing problem with time windows for mixed-load recycling of heterogeneous batteries: A transformer-based improved deep reinforcement learning algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instantaneous power prediction for industrial robots using tree-based machine learning methods. <em>EAAI</em>, <em>162</em>, 112339. (<a href='https://doi.org/10.1016/j.engappai.2025.112339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a tree-based machine learning methodology for instantaneous power prediction designed, tested and validated using data from an articulated industrial robot. The proposed methodology for instantaneous power prediction materializes through a generic system architecture with functionalities consisting of data acquisition, time alignment of data samples, storage, model learning, instantaneous power prediction and integration in time to evaluate energy consumption at robot operation level. This methodology is designed to evaluate offsite energy consumption of robotized workstations for different layouts characterized by relative position of the robot with respect to the serviced and fly-by points. This is important both for offline virtual commissioning of robotized workstations (determine layout) and for online operation for maintenance purposes (determine energy spikes different from normal model). The analyzed operation is the linear motion of the robot Tool Control Point in Cartesian space, characterized by the complexity of the kinematic model: each joint operates in coordinated motion, adjusting its velocity and acceleration continuously to ensure a straight path with constant speed. A custom Internet of things (IoT) device enables synchronized energy and motion data logging for robots, ensuring consistent values for sampled trajectories. Justification for the usage of tree-based methods and experimental results are provided.},
  archive      = {J_EAAI},
  author       = {Ionuţ Lenţoiu and Silviu Răileanu and Theodor Borangiu and Mihnea Constantinescu and Octavian Morariu},
  doi          = {10.1016/j.engappai.2025.112339},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112339},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Instantaneous power prediction for industrial robots using tree-based machine learning methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward sustainable wastewater treatment: Transformer ensembles and multitask learning for energy consumption and quality management. <em>EAAI</em>, <em>162</em>, 112338. (<a href='https://doi.org/10.1016/j.engappai.2025.112338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wastewater treatment plants (WWTPs) are among the most energy-intensive components of urban infrastructure and bear strict regulatory responsibilities for wastewater quality. These dual challenges, minimizing energy consumption and maintaining environmental compliance, are deeply interrelated and must be managed simultaneously to achieve sustainable plant operation. This study proposes a framework that comprises two customized components. The first component employs a voting ensemble model based on transformer architecture to predict energy consumption. It processes heterogeneous feature domains — including hydraulic, wastewater, and climatic variables — through parallel attention-driven streams. The outputs from these streams are then aggregated using a weighted voting mechanism to produce the final prediction. Second, a multitask Bidirectional Gated Recurrent Unit (Bi-GRU) forecasts wastewater quality indicators concurrently (ammonia, Biochemical Oxygen Demand (BOD), and Chemical Oxygen Demand (COD)), capturing shared temporal dependencies and reducing model complexity. A hybrid preprocessing strategy is applied, incorporating domain-aware outlier detection (z-score and Interquartile Range (IQR)), K-Nearest Neighbors (KNN) Imputation, and feature selection using Extreme Gradient Boosting (XGBoost). Experimental results showed that. The voting ensemble model achieved the best results for energy consumption prediction with 31.61 of Root Mean Squared Error (RMSE). The multitask Bi-GRU achieved the best results for wastewater quality indicators with RMSE at 6.1689, 48.0323, and 88.2214 for ammonia, BOD, and COD, respectively. This work is among the first to integrate transformer ensembles and multitask learning in a unified WWTP forecasting system. Simultaneously addressing energy efficiency and water quality assurance, this offers a practical, scalable, and intelligent decision-support tool for sustainable wastewater management.},
  archive      = {J_EAAI},
  author       = {Hager Saleh and Sherif Mostafa and Shaker El-Sappagh and Abdulaziz AlMohimeed and Michael McCann and Saeed Hamood Alsamhi and Niall O’Brolchain and John G. Breslin and Marwa E. Saleh},
  doi          = {10.1016/j.engappai.2025.112338},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112338},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Toward sustainable wastewater treatment: Transformer ensembles and multitask learning for energy consumption and quality management},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complete information extraction for monocular depth estimation using a dual framework. <em>EAAI</em>, <em>162</em>, 112337. (<a href='https://doi.org/10.1016/j.engappai.2025.112337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to address the problem of efficient extraction of complete multi-scale information for supervised monocular depth estimation. Most of the existing depth estimation methods are based on Convolutional Neural Network (CNN). By gradually exploring the contextual and semantic features, they have achieved good results in scene depth estimation. However, with the expansion of the receptive field, global information limited by the local induction bias is gradually suppressed, resulting in the performance cannot be further improved. Recently, Transformer-based methods have been widely used to model the global correlation between features. Nevertheless, since the Transformer networks are not spatially aware enough, they usually lose local details and have no clear mechanism for reusing features when processing images. The Transformer networks perform self-attention mechanism at each location and cannot directly obtain information from other locations for features. Therefore, we propose a novel dual framework called as Transformer-CNN, which includes the Transformer-branch and the CNN-branch for monocular depth estimation. Specifically, the Transformer-branch is able to model the global contextual information and the CNN-branch can capture local spatial relationships in images. However, simply fusing these two independent branches may result in insufficient feature aggregation. To this end, we design a Parallel Feature Interaction Module (PFIM), which contains a Self-Attention Module (SAM) and a Cross-Attention Module (CAM), so as to highlight features from the Transformer-branch and the CNN-branch respectively and extract complementary information between the two branches. Meanwhile, in order to make full use of the low-level features with low quality in the scene, we propose a Low-level Information Acquisition Module (LIAM) to capture texture-related information and preserve texture details in the CNN-branch. Finally, to address the lack of multi-scale contextual information in Vision Transformer (ViT), we introduce a Wide Area Multi-scale Decoder (WAMD), which incorporates the multi-scale feature representations into the decoder part via a Wide Area Attention (WAA). Extensive experiments on benchmark datasets collected in the outdoor and indoor environments demonstrate the competitive results of the proposed method, compared with the state-of-the-art monocular depth estimation methods.},
  archive      = {J_EAAI},
  author       = {Bin Li and Dazheng Zhou and Xianjie Gao and Mingliang Zhang},
  doi          = {10.1016/j.engappai.2025.112337},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112337},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complete information extraction for monocular depth estimation using a dual framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards non-visual bowel cancer diagnosis: A certainty-aware data-driven method of lesion characterisation using a vibrating capsule. <em>EAAI</em>, <em>162</em>, 112336. (<a href='https://doi.org/10.1016/j.engappai.2025.112336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in miniaturised, dynamically actuated robots have opened new pathways for non-visual, in-situ disease diagnosis. This study explores a novel method for early bowel cancer detection using a self-propelled robotic capsule that navigates the bowel and detects lesions based on variations in tissue stiffness. The approach capitalises on the sensitivity of the capsule’s dynamic responses to surrounding tissue properties. A dual-phase machine learning framework is proposed. The first phase uses regression models including multilayer perceptron (MLP), support vector regression (SVR), and Gaussian process regression (GPR) to predict tissue stiffness from displacement signal features. The second phase uses a Gaussian mixture model (GMM) to cluster the predicted stiffness values into different categories. Unlike our previous work, this study emphasises the robustness of the models under varying data conditions using both accuracy and reliability-oriented metrics. Based on our studies, MLP provided the most reliable regression results for simulated data and downstream clustering, though GPR performed better on experimental datasets. SVR consistently underperformed, especially on experimental data. The GMM achieved over 89% clustering accuracy across both simulated and experimental datasets, with improved results when predictions from more accurate regression models are used as the inputs. This work demonstrates a promising step toward dynamic, in-situ lesion characterisation and highlights the potential for integrating lesion biomechanics into future endoscopic diagnosis.},
  archive      = {J_EAAI},
  author       = {Kenneth Omokhagbo Afebu and Yang Liu and Evangelos Papatheou and Shyam Prasad},
  doi          = {10.1016/j.engappai.2025.112336},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112336},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards non-visual bowel cancer diagnosis: A certainty-aware data-driven method of lesion characterisation using a vibrating capsule},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models. <em>EAAI</em>, <em>162</em>, 112335. (<a href='https://doi.org/10.1016/j.engappai.2025.112335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Artificial Intelligence (AI)-based weather forecasting is growing rapidly, with continuous progress in model development, techniques, and performance improvements. This paper provides a comprehensive overview of AI-based weather forecasting models, focusing on their current status, challenges, and directions for further development. A review of more than 40 models, primarily proposed after 2015, underscores the importance of critically examining various aspects of AI-based forecasting. Unlike previous reviews that targeted only a limited number of models or features, this study addresses a complete set of aspects and analyzes existing challenges from multiple perspectives. These aspects include the Machine Learning (ML) and Deep Learning (DL) methods used, datasets, predictand parameters, overfitting, and capability for forecasting extreme weather, lead time, spatiotemporal scale, performance criteria, overfitting, data assimilation, data-driven models, and the analysis of state-of-the-art (SOTA) models such as FengWu, ClimaX, Pangu-Weather, FourCastNet, GraphCast, GenCast, and Artificial Intelligence Forecasting System (AIFS) from various viewpoints. The review also discusses current challenges, including limited historical data and data quality, small-scale weather forecasting, model explainability, uncertainty, extreme weather prediction, physical constraints, temporal adaptation, and generalization, and outlines potential future directions.},
  archive      = {J_EAAI},
  author       = {Saeid Haji-Aghajany and Witold Rohm and Piotr Lipinski and Maciej Kryza},
  doi          = {10.1016/j.engappai.2025.112335},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112335},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural model of the adaptive tuned particle impact damper. <em>EAAI</em>, <em>162</em>, 112334. (<a href='https://doi.org/10.1016/j.engappai.2025.112334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a novel approach for the modeling of the Adaptive Tuned Particle Impact Damper (ATPID) using Multilayer Perceptron (MLP). The main motivation was the recognition that such an approach can support the development of novel neural modeling and the optimal determination of damper parameters in terms of mechanical vibration attenuation. The training data were obtained using a theoretical model validated experimentally. The optimally selected MLP was compared with other regression models using 10 different metrics. A hyperparameter tuning of the determined neural network architecture was conducted based on the input parameters such as excitation amplitude, grain mass, and ATPID damper height. The analyses show that the proposed neural network could quickly and accurately estimate the system’s vibration amplitude and efficiently predict the optimal damper height. The ability to effectively determine the correct optimal height is crucial for ATPID damper control. The high efficiency in predicting the system’s vibration amplitude allows for the replacement of the theoretical model with applied time-consuming contact forces. The MLP accurately estimated vibration amplitudes with 1%–10% error for interpolated data and up to 15% for extrapolated cases. The issue raised is particularly important from the perspective of real-time damper control. It was found that computing a single case using the artificial neural network is more than ten times faster compared to the theoretical model. Therefore, the proposed ATPID damper model based on a neural network forms the basis for further considerations and scientific research to finally propose a control algorithm in the future.},
  archive      = {J_EAAI},
  author       = {Mateusz Żurawski and Karolina Grabska and Robert Zalewski and Adam Kulawik},
  doi          = {10.1016/j.engappai.2025.112334},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112334},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural model of the adaptive tuned particle impact damper},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive hybrid machine reading comprehension framework for multimodal emotion-cause pair extraction in conversations. <em>EAAI</em>, <em>162</em>, 112333. (<a href='https://doi.org/10.1016/j.engappai.2025.112333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal emotion-cause pair extraction in conversations (MECPEC) has gradually evolved into an emerging task aimed at discovering deeper causal relationships between emotions and their corresponding causes in conversational contexts. It has widespread application in fields such as human–computer interaction, social media analysis, customer feedback management, and empathetic companion, among others. However, the challenges posed by the oversimplified multimodal feature fusion mechanism and the failure to account for the relative positional relationship between emotions and causes still hinder the performance of MECPEC. In this study, we propose an adaptive hybrid machine reading comprehension (AHMRC) framework to extract potential emotion-cause pairs inherent in conversations. The MECPEC task is first transformed into a two-round hybrid machine reading comprehension task that sequentially enforces the global emotion query and the local cause query with the goal of exploring the relative position constraint specific to conversations. Subsequently, an adaptive multimodal attention module is designed by incorporating features extracted from text, video, and audio modalities, and adaptively fusing them according to their contributions. Extensive experiments were carried out on the benchmark datasets to demonstrate the effectiveness of the proposed AHMRC framework in comparison to other state-of-the-art methods in the literature.},
  archive      = {J_EAAI},
  author       = {Guorui Li and Xufeng Duan and Cong Wang and Sancheng Peng},
  doi          = {10.1016/j.engappai.2025.112333},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112333},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive hybrid machine reading comprehension framework for multimodal emotion-cause pair extraction in conversations},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analytical and machine learning approaches for three-dimensional orthotropic functionally graded cylindrical structure in steady heat conduction. <em>EAAI</em>, <em>162</em>, 112332. (<a href='https://doi.org/10.1016/j.engappai.2025.112332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theoretical and computational modelling of heat conduction in a functionally graded cylinder has been rigorously investigated in prior studies, owing to its critical significance in high-stakes engineering applications such as nuclear reactor design, aerospace structural systems, and pressure vessel technology. Despite this extensive body of work, the majority of these studies have mostly focused on simplified two-dimensional models, frequently presuming idealized thermal parameters such as isotropic thermal conductivity, constant convection coefficients, and spatially uniform ambient temperatures. These simplifications overlook the crucial role of spatially varying thermal characteristics and three-dimensional (3D) temperature distributions, which are essential for accurately simulating the complex heat conduction behaviors found in real-world engineering. Unlike prior research, this study presents an analytical solution for heat conduction under non-homogeneous generalized Robin boundary conditions, capturing 3D thermal conductivity inhomogeneities along three orthogonal directions using Sturm-Liouville theory and finite integral transforms. However, while such analytical methods are highly accurate for simpler geometries, they often encounter significant challenges when extended to scenarios involving complex material gradients and irregular domains. A gradient-enhanced physics-informed neural network (g-PINN) framework is proposed to tackle these challenges, utilizing neural networks that incorporate physical laws and gradient information to enhance its applicability to complex configurations. This combined approach presents a novel framework that integrates classical theory with machine learning, facilitating precise modelling of thermal phenomena in functionally graded cylinders. The findings indicate that both the analytical and machine learning approaches (g-PINN) align closely with presented solutions, precisely capturing the energy equation and more complex boundary conditions.},
  archive      = {J_EAAI},
  author       = {Palash Das and Md Ashraful Islam and Dipayan Mondal},
  doi          = {10.1016/j.engappai.2025.112332},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112332},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analytical and machine learning approaches for three-dimensional orthotropic functionally graded cylindrical structure in steady heat conduction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust spurious drug–drug interaction detection via chi-square-guided bidirectional attention mechanism. <em>EAAI</em>, <em>162</em>, 112331. (<a href='https://doi.org/10.1016/j.engappai.2025.112331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spurious drug–drug interactions arising from experimental biases can compromise treatment safety and hinder effective clinical decision-making for patients. However, current molecular representation learning methods still face significant challenges in addressing this problem. First, most graph neural network-based approaches consider only single-direction interactive semantic extraction between drug molecules, failing to capture more granular relationships between drugs fully. Moreover, during training, they are vulnerable to noise from negative sampling and cannot sufficiently leverage the complete drug–drug interaction annotations, resulting in reduced robustness and accuracy in downstream tasks. To this end, we propose a robust spurious DDI detection framework that employs chi-square-guided bidirectional attention to capture fine-grained and bidirectional interaction patterns. First, considering their mutual information flow, a two-way cross-attention mechanism is introduced for a more granular extraction of cross-drug molecular interaction semantic representations through bidirectionally perceiving interactive features between drugs. Second, on the basis of robust minimum covariance determinant theory, we propose a chi-square distribution-based spurious detection method to approximate the correctly annotated drug–drug interactive feature space to a chi-square distribution for a complete feature representation. Extensive experiments on benchmark datasets further validate our method’s effectiveness over state-of-the-art methods, particularly in noisy interference scenarios. Our code is available at https://github.com/AlexCostra/cd .},
  archive      = {J_EAAI},
  author       = {Wei-Yu Shi and Yi-Jia Zhang and Jin-Zhong Ning},
  doi          = {10.1016/j.engappai.2025.112331},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112331},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust spurious drug–drug interaction detection via chi-square-guided bidirectional attention mechanism},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning. <em>EAAI</em>, <em>162</em>, 112330. (<a href='https://doi.org/10.1016/j.engappai.2025.112330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The textual adversarial attack aims to fool existing models into making erroneous predictions by adding strategic perturbations to normal data without affecting the user’s understanding. Recently, methods based on Pre-trained Language Models (PLMs) and Large Language Models (LLMs) have shown promising performance in various Natural Language Processing (NLP) downstream tasks. However, due to significant deviations between the original and perturbed texts, these methods struggle to achieve satisfactory results in defending against textual adversarial attacks, especially in Chinese, which has unique syntactic structures. To address this issue, we propose a domain adaptation method for defending against Chinese textual adversarial attacks through a prompt-tuning model, which effectively mitigates the discrepancy between different domains. Specifically, the original and perturbed texts are treated as the source and target domains, respectively, with the textual adversarial defense task framed as a cross-domain classification problem. The soft prompt-tuning model trained in the source domain is iteratively adapted to uncover the true label information in the target domain. The graph attention network is incorporated to integrate Chinese syntactic structure information with semantic features. Through a voting mechanism on predicted labels generated by the iterative model, soft prompt-tuning is further optimized for cross-domain classification tasks. Extensive experimental results demonstrate the superior effectiveness of our method in Chinese textual adversarial defense tasks compared to baseline methods, including the state-of-the-art fine-tuning approaches for PLMs and LLMs.},
  archive      = {J_EAAI},
  author       = {Yi Zhu and Zhenglong Li and Yun Li and Yunhao Yuan and Jipeng Qiang},
  doi          = {10.1016/j.engappai.2025.112330},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112330},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel high-accuracy graph neural network-based rumor detection method. <em>EAAI</em>, <em>162</em>, 112329. (<a href='https://doi.org/10.1016/j.engappai.2025.112329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumors spreading on social media platforms result in potential damages. A precise rumor detection mechanism can help form a healthy public opinion environment. In recent years, deep learning-based rumor detection methods, especially graph model-based ones, have risen and reached promising performance. However, there are several defects in existing methods, which limit models from efficiently utilizing the propagation structure. In this paper, we propose a novel rumor detection model, which has high accuracy and reaches state-of-the-art performance. First, we design a powerful comprehensive rumor feature extractor that explicitly overcomes the restriction of previous Graph Neural Networks-based models. Then, by introducing Kernel Subtree features, our model acquires the capability to learn crucial local features from important nodes. Comparative experiments performed on two real-world social media platforms demonstrate that our work reaches state-of-the-art performance, which outperforms the best baseline with 1.6% and 1.9% in accuracy respectively.},
  archive      = {J_EAAI},
  author       = {Xi Xiao and Zeming Wu and Chengzong Cai and Tian Bian and Guangwu Hu and Qing Li and Cheng Huang},
  doi          = {10.1016/j.engappai.2025.112329},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112329},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel high-accuracy graph neural network-based rumor detection method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Committee of multi-scale nonlinear learning frameworks for accurate stock price forecasting. <em>EAAI</em>, <em>162</em>, 112325. (<a href='https://doi.org/10.1016/j.engappai.2025.112325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dependable stock price predictions are vital for optimizing economic policies and investment strategies in both national and corporate settings. However, the intrinsic volatility and intricacy of stock prices pose considerable challenges. Thus, this paper introduces a novel Committee of Multi-scale Nonlinear Learning Frameworks (CoML) that employs a three-stage model: decomposition, reconstruction, and prediction. First, a complete ensemble empirical mode decomposition with adaptive noise is adopted to decompose the original stock prices into multiple intrinsic mode functions. Secondly, a fine-to-coarse algorithm is applied to reconstruct the intrinsic mode functions, so as to effectively extract short-term fluctuations and long-term trends. Finally, an ensemble of nonlinear models including bidirectional long short-term memory (BiLSTM), support vector regression (SVR) and multi-layer perceptron (MLP) is used to learn and forecast features extracted to obtain high performance. Experimental results indicate that the model performs exceptionally well in both emerging and developed markets highlighting the innovative capabilities of CoML in highly complex and volatile financial markets. The proposed model is further validated using Model Confidence Set and the results indicate that the model is statistically significant.},
  archive      = {J_EAAI},
  author       = {Qian He and Yanhui Liang and Yu Lin and Dazhi Pan and Yuying Yue},
  doi          = {10.1016/j.engappai.2025.112325},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112325},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Committee of multi-scale nonlinear learning frameworks for accurate stock price forecasting},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning robust brain tumor segmentation under label corruption and data scarcity. <em>EAAI</em>, <em>162</em>, 112322. (<a href='https://doi.org/10.1016/j.engappai.2025.112322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models for medical image segmentation often struggle with performance issues when datasets are affected by label noise or annotation errors, commonly introduced during manual process or lack of proficiency. These noisy annotations disrupt the loss function, leading to "partially incorrect" gradients that impair the model's learning and overall performance. Additionally, the limited availability of scanned data for training often makes it challenging to develop a robust model. A common approach to address this issue is to leverage similar large annotated datasets. However, differences in dataset distributions can also lead to inconsistencies, introducing erroneous gradients during training and further impacting model performance. To address these challenges, we propose MGR-DAS (Meta-Gradient Reweighting via Direction-Aware Similarity), a novel meta-learning-based approach that can automatically evaluate the reliability of training samples during training using a small, clean subset easily curated from the noisy dataset. Our method quantifies reliability by measuring the cosine similarity between the gradients of noisy training samples and those of the clean subset. Samples with higher gradient alignment are assigned greater weights during training, effectively reducing the impact of noisy labels and improving model robustness. We evaluate our method using three standard metrics for medical image segmentation: the Dice Similarity Coefficient (DSC), the 95th percentile Hausdorff Distance (HD95), and Intersection over Union (IoU). The proposed MGR-DAS achieved an overall 2.4 % improvement in the DSC on the brain tumor segmentation (BraTS, 2021) dataset. Remarkably, even with only 10 clean annotations used in the reweighting algorithm, our method yielded a 28.7 % gain in DSC. In real-world, data-scarce scenarios, our proposed MGR-DAS also improved the overall DSC score by 2.6 % on BraTS pediatric (BraTS-PEDs) and by 1.0 % on BraTS-Africa, demonstrating strong generalizability and robustness. Experimental results confirm that the proposed method reliably identifies noisy data, prioritizes clean data through adaptive weighting, and outperforms existing fine-tuning, curriculum learning techniques, and other meta-learning frameworks commonly employed in classification tasks.},
  archive      = {J_EAAI},
  author       = {Abdulkhalek Al-Fakih and Abbas Mohamed Rezk and Abdullah Shazly and Kanghyun Ryu and Mohammed A. Al-masni},
  doi          = {10.1016/j.engappai.2025.112322},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112322},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning robust brain tumor segmentation under label corruption and data scarcity},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection. <em>EAAI</em>, <em>162</em>, 112321. (<a href='https://doi.org/10.1016/j.engappai.2025.112321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slow Feature Analysis (SFA) has shown considerable success in the field of industrial process fault detection. Nonetheless, due to its unsupervised nature, SFA relies solely on the normal training data and overlooks the incorporation of prior process knowledge, which consequently diminishes its efficacy in early fault detection. To mitigate this limitation, this paper introduces the concept of Zero-Shot Learning (ZSL) and proposes an improved SFA approach, referred to as ZSL-SFA. This novel method leverages fault semantic representations as auxiliary knowledge to enhance fault detection sensitivity in industrial process monitoring. The ZSL-SFA framework implements a dual-model collaborative monitoring system: (1) a primary SFA model is developed using normal operational data to capture the dynamic characteristics of the process; and (2) a semantic encoding mechanism, grounded in expert knowledge, is devised to build the auxiliary model, where a probabilistic attribute learner adaptively extracts semantic information from fault attribute descriptions, facilitating effective fault knowledge transfer through similarity analysis. The monitoring outcomes from both the primary and auxiliary models are integrated using a Bayesian fusion strategy, culminating in a comprehensive ZSL-SFA monitoring system. The main advantage of this method is its ability to fully exploit prior process knowledge to enhance the basic SFA model without the need for additional labeled fault samples. Experimental validations on the Tennessee-Eastman process simulation platform are performed to indicate that the proposed ZSL-SFA method surpasses the basic SFA method in terms of fault detection performance.},
  archive      = {J_EAAI},
  author       = {Wenjie Yang and Xiaogang Deng and Lumeng Huang and Yuping Cao},
  doi          = {10.1016/j.engappai.2025.112321},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112321},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale embedding with guided attention for medical image analysis. <em>EAAI</em>, <em>162</em>, 112319. (<a href='https://doi.org/10.1016/j.engappai.2025.112319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate classification of medical images is pivotal for enhancing diagnostic accuracy and optimizing treatment strategies. Traditional methods encounter challenges in delineating clear inter-class boundaries within high-dimensional feature spaces affected by class overlap. This study introduces a Multi-Scale Embedding with Guided Attention (MSEGA) framework based on deep learning autoencoders that integrates innovative guided attention learning mechanisms without explicit target mask supervision for tumor detection and classification. The framework incorporates Multi-scale Feature Extraction Blocks and Depthwise Separable Convolution Blocks to comprehensively capture image features. Through Channel Attention and Spatial Attention mechanisms, the MSEGA method prioritizes critical tumor regions across scales. We also propose a novel interpretable embedding learning loss function to optimize image embeddings, highlighting crucial regions and refining category distinctions. Empirical evaluations on two brain tumor Magnetic Resonance Imaging (MRI) datasets demonstrate our approach surpasses conventional methods including Convolutional Neural Networks and Vision Transformers in classification accuracy and generalizability. These results underscore the framework’s potential as a versatile artificial intelligence-powered tool in medical image analysis.},
  archive      = {J_EAAI},
  author       = {Zeyan Li and Yifei Peng and Yizun Lin},
  doi          = {10.1016/j.engappai.2025.112319},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112319},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale embedding with guided attention for medical image analysis},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction. <em>EAAI</em>, <em>162</em>, 112318. (<a href='https://doi.org/10.1016/j.engappai.2025.112318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {T-cell receptor sequences (TCR-seq) are closely related to cancers, and in particular, cancer-related TCR-seq are crucial in cancer diagnosis and treatment. Current prediction methods for cancer-related TCR-seq often focus solely on the sequence structure, neglecting its spatial structure. Therefore, we propose a multimodal deep learning method based on parallel and residual structures (MDPR) for the detection of cancer-related TCR-seq. MDPR can effectively integrate the spatial and sequence structure of TCR-seq for accurately identifying cancer-related sequences. First, we introduce a TCR-seq encoding method based on atomic three-dimensional spatial coordinates, allowing for more effective extraction of the spatial structural features of TCR-seq. Second, we use high-dimensional word vectors instead of the amino acid feature vectors traditionally used by other researchers. Third, we pretrain the spatial feature extraction module and then conduct joint training with the sequence feature extraction module. This approach allows the model to better consider the relationship between the two modalities, thereby improving prediction accuracy. Finally, MDPR achieved an area under the curve (AUC) of 0.971 after ten rounds of three-fold cross-validation on the dataset. The AUC of MDPR is 5% higher than that of the previous best method. In short, we propose an artificial intelligence method called MDPR, and apply it to the biomedical field. MDPR can be obtained from https://github.com/biomg/MDPR .},
  archive      = {J_EAAI},
  author       = {Junjiang Liu and Shusen Zhou and Mujun Zang and Chanjuan Liu and Tong Liu and Qingjun Wang},
  doi          = {10.1016/j.engappai.2025.112318},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112318},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering. <em>EAAI</em>, <em>162</em>, 112317. (<a href='https://doi.org/10.1016/j.engappai.2025.112317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is a significant application for wearable devices, which primarily identifies current human activities by analyzing sequential sensor data. The real-time data recording of wearable devices enables the collection of vast amount of unlabeled data. Utilizing this data for self-supervised contrastive pre-training of HAR models presents a feasible solution to the decline in recognition performance due to limited labeled data. However, traditional contrastive learning frameworks are primarily designed based on positive and negative sample pairs in the image domain. The relatively simple sequence data of HAR is prone to generating incorrect negative pairs, thus pre-training HAR models solely in this manner is unsatisfactory. Given the phenomena described above, this paper proposes an Instance Prediction and Clustering Self-supervised Contrastive Learning Framework (IPCSC) for HAR, considering the characteristics of human activity data. IPCSC circumvents negative sample pairs, instead extracting contrastive information at the instance perspective by prediction tasks among various augmented views of samples and integrating clustering concepts for contrastive learning from a holistic perspective. The primary objective is to enable the model to discern critical information within human activity data and distinguishable features between different activities, thereby improving the model’s pre-training efficacy and enhancing its downstream activity recognition performance. Numerous experimental analyses demonstrate that IPCSC outperforms other self-supervised methods, achieving an average F1-Score performance improvement of 5.65%, 4.11%, and 7.99% over supervised baselines on the UCI-HAR, MobiAct, and MotionSense datasets, respectively, with only 1% of the labeled data.},
  archive      = {J_EAAI},
  author       = {Zhixuan Yang and Kewen Li and Zongchao Huang and Zhifeng Xu and Xinyuan Zhu and Yuan Xiao},
  doi          = {10.1016/j.engappai.2025.112317},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112317},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised method for learning path-augmented knowledge graph embedding. <em>EAAI</em>, <em>162</em>, 112315. (<a href='https://doi.org/10.1016/j.engappai.2025.112315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) consist of factual triples that describe relations between entities in the real world. Knowledge graph embedding (KGE) aims to map entities and relations into constantly low-dimensional vectors, which is important for lots of downstream tasks (e.g., KG completion and information retrieval). Current KGE methods primarily rely on explicit structural patterns, neglecting latent contextual semantics behind those structures and resulting in sub-optimal performance. While some methods incorporate additional data (e.g., textual descriptions), such dependencies limit applicability due to additional data requirements. Furthermore, most KGE models suffer from limited supervision with sparse labeled triples, restricting their capacity to learn comprehensive semantic features. Inspired by the simple but effective self-supervised language model word2vec, one interesting question is: Can KGE be performed as a simple self-supervised language model ? To achieve this, we innovatively propose a self-supervised KGE framework that learns entity and relation embeddings by adapting word2vec’s skip-gram objective to path sequences extracted from KGs. Our framework employs separate embedding spaces for entities and relations with an entity-relation mapping mechanism for effective interaction between the two embedding spaces. Further, to enhance the training efficiency, we introduce a markov chain-based negative sampling strategy, which generates semantically meaningful negative samples by preserving the structural contexts along KG paths. Our framework, which is the first attempt to follow the context-based self-supervised idea of language models to conduct KGE tasks, addresses the constraints of label-dependent supervised KGE techniques and obviates the requirement for external information, while simultaneously enabling effective extraction of the implicit contextual semantics inherent in triple structures. Experiments on two widely-used KGE datasets show state-of-the-art performance, demonstrating our framework’s ability to learn semantically rich representations solely from graph structure.},
  archive      = {J_EAAI},
  author       = {Tong Shen and Fu Zhang and Jingwei Cheng},
  doi          = {10.1016/j.engappai.2025.112315},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112315},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A self-supervised method for learning path-augmented knowledge graph embedding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion. <em>EAAI</em>, <em>162</em>, 112313. (<a href='https://doi.org/10.1016/j.engappai.2025.112313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence-based single-cell RNA sequencing (scRNA-seq) technology is widely used in cell type identification and disease research, but its data often contain a large number of missing values and zero values due to technical limitations and biological differences. These zero values not only affect downstream analysis, but also make it difficult to distinguish technical zero values from biological zero values. Therefore, this paper proposes a scRNA-seq data interpolation method (sc-MKNMF) based on non-negative matrix factorization and multi-kernel similarity network fusion for the first time. This method improves the accuracy of cell clustering by accurately filling some zero values. First, sc-MKNMF uses gene-cell dual-level analysis to distinguish technical zero values from biological zero values, and then calculates the similarity network of multi-kernel fusion of genes and cells respectively. Then, this method uses non-negative matrix factorization combined with similarity network to construct the objective function, and introduces sparse regularization terms to ensure the similarity between genes and cells and improve stability. In addition, sc-MKNMF is also equipped with an efficient optimization algorithm to promote its convergence by continuously updating the objective function. Finally, the verification and comparative experiments on 12 scRNA-seq datasets show that the sc-MKNMF method outperforms other advanced data interpolation methods. In addition, the extension of sc-MKNMF to the two tasks of cell trajectory inference and differentially expressed gene analysis showed significant improvement and excellent versatility.},
  archive      = {J_EAAI},
  author       = {Pei Liu and Cheng Chen and Hao Liu and Jin Gu and Xinya Chen and Ying Su and Zhiyuan Cheng and Xiaoyi Lv and Chen Chen},
  doi          = {10.1016/j.engappai.2025.112313},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112313},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention. <em>EAAI</em>, <em>162</em>, 112311. (<a href='https://doi.org/10.1016/j.engappai.2025.112311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cercospora leaf spot (CLS) is a widespread disease that seriously threatens beet yield and sugar quality. Timely detection enables farmers to take early control measures and reduce economic losses. Although artificial intelligence (AI)-based methods are replacing manual inspection in agriculture, CLS detection in complex field environments remains highly challenging due to subtle early-stage symptoms and severe occlusions caused by overlapping leaves and weeds. To address these challenges, this paper presents Cercospora Leaf Spot–You Only Look Once (CLS–YOLO), an enhanced detection model built upon You Only Look Once version 11 (YOLOv11), incorporating novel modules specifically designed for accurate CLS detection under challenging field conditions. To improve the detection of weak and early-stage symptoms, we design the Multi-Scale Large Kernel Decomposition (MSLKD) module, which enhances feature extraction for subtle lesions. Furthermore, we develop the Spatial-Channel Interaction Attention (SCIA) module to mitigate detection errors arising from occlusion and fragmented disease patterns by refining multi-scale feature representations. Experimental results demonstrate CLS–YOLO achieves superior performance, reaching an mAP@0.5 of 73.6% ± 0.2% and an mAP@0.5:0.95 of 40.6% ± 0.3% over five independent runs, outperforming twelve mainstream object detection algorithms while maintaining lightweight efficiency. To validate generalization capability across scenarios, crops, and diseases, we conducted comparative experiments on two public crop disease datasets, where our method achieved superior overall performance. In summary, this study provides an effective AI-driven solution for precise crop disease detection, contributing to the practical advancement of intelligent agriculture.},
  archive      = {J_EAAI},
  author       = {Hualong Dong and Yi Lu and Yurong Qian and Xuefei Ning and Ting Chen and Ke Tang},
  doi          = {10.1016/j.engappai.2025.112311},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112311},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ElecBench: A large language model benchmark in electric power domain. <em>EAAI</em>, <em>162</em>, 112310. (<a href='https://doi.org/10.1016/j.engappai.2025.112310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have made substantial advancements in the field of natural language processing, necessitating the development of new benchmarks to accurately track their progress. In this paper, we introduce ElecBench, the first benchmark specifically designed for the electric power domain. ElecBench comprises 24 datasets spanning different scenarios, covering general electric power knowledge and four specific business applications, with a total of 34,030 data entries. Furthermore, we evaluate the performance of a series of open-source Chinese LLMs on ElecBench. Our experiments demonstrate that ElecBench serves as an effective benchmark for electric power scenarios and highlight that existing LLMs require further optimization to gain domain-specific knowledge and achieve better performance.},
  archive      = {J_EAAI},
  author       = {Sai Zhang and Qiaochu Huang and Qiang Zhang and Xiao Liang and Weiwei Liu and Kunlun Gao and Fei Zhou and Congcong Shi},
  doi          = {10.1016/j.engappai.2025.112310},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112310},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ElecBench: A large language model benchmark in electric power domain},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based trajectory tracking optimal control for underactuated unmanned surface vehicles under asymmetric input saturation. <em>EAAI</em>, <em>162</em>, 112307. (<a href='https://doi.org/10.1016/j.engappai.2025.112307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For underactuated unmanned surface vehicles (USVs) under asymmetric input saturation caused by thrust-limit characteristics, as well as unknown dynamics and ocean environmental disturbances, a trajectory tracking optimal control (TTOC) scheme is proposed using the reinforcement learning (RL) method. Through coordinate transformations and mathematical derivation, an underactuated USV motion model is transformed into the standard affine nonlinear form. To address the asymmetric input saturation of underactuated USVs, a new inverse hyperbolic tangent-type penalty function is designed for control inputs, relaxing the assumption of input saturation limits being symmetric. Based on RL methods and adaptive neural networks (NNs), an actor-critic NN framework is developed, with weight update laws designed for NNs. This framework learns the TTOC law for underactuated USVs through the online interaction of actor and critic NNs while adapting to unknown dynamics and disturbances. In particular, a robustifying term is designed and added to the output of an actor NN to compensate for the adverse effects of a lumped residual term, which enhances the robustness of the TTOC law and thereby achieves asymptotic regulation of trajectory tracking errors. Theoretical analyses and simulation results indicate that the proposed TTOC scheme enables underactuated USVs to asymptotically track the desired trajectory.},
  archive      = {J_EAAI},
  author       = {Ziping Wei and Jialu Du},
  doi          = {10.1016/j.engappai.2025.112307},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112307},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning-based trajectory tracking optimal control for underactuated unmanned surface vehicles under asymmetric input saturation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-enhanced edge-INverse attention network for skin lesion segmentation. <em>EAAI</em>, <em>162</em>, 112306. (<a href='https://doi.org/10.1016/j.engappai.2025.112306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer, particularly melanoma, is one of the most aggressive and deadly forms of cancer with its incidence rising globally. Early detection is crucial for improving survival rates, but the traditional dermatoscopy method is a highly time-consuming and subjective process. To resolve this issue, we propose a novel Feature-Enhanced Edge-INverse attention network (FEEINnet) model that helps to segment the skin lesion region more accurately. FEEINnet consists of three sub-networks: Feature Enhanced Mechanism (FEM) learns and extracts the fine-grained enhanced features from informative channels, the Edge Attention Mechanism (EAM) helps to precisely identify the edges of the lesion region and the INverse Attention Mechanism (INAM) generates inverse attention maps which emphasize the less confident or ambiguous regions thereby increasing the segmentation accuracy iteratively. These three sub-networks collectively help to improve feature extraction, enhance boundary detection, and refine segmentation maps, even in challenging scenarios with varying lesion sizes, shapes and pigmentation. FEEINnet consistently outperforms existing models, achieving a F1-score of 95.55%, 95.53%, and 94.52%; Intersection over Union (IoU) of 92.76%, 92.43%, and 91.34%; and Structural Similarity Index Measure (SSIM) of 94.63%, 93.51%, and 91.85% on the Human Against Machine 10000 (HAM10000), Pedro Hispano Hospital ( P H 2 ), and International Skin Imaging Collaboration 2018 (ISIC2018) datasets, respectively. The obtained results demonstrate that the proposed model has a greater ability to segment complex skin lesions more accurately.},
  archive      = {J_EAAI},
  author       = {Shivamm Warambhey and Aravindkumar Sekar},
  doi          = {10.1016/j.engappai.2025.112306},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112306},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-enhanced edge-INverse attention network for skin lesion segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method. <em>EAAI</em>, <em>162</em>, 112305. (<a href='https://doi.org/10.1016/j.engappai.2025.112305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault-free functioning of Heating, Ventilation, and Air Conditioning (HVAC) systems is essential for reducing energy waste in modern-day buildings. Hence, data-driven approaches for HVAC fault detection have gained popularity. Faults become more severe with time. Fault detection reveals the presence of an anomaly, but it does not convey how critical the fault severity is. Fault severity indication provides this essential context, enabling urgent resource allocation to more severe faults, adding practical significance. However, faults being rare, obtaining substantial data at different severity levels to train supervised Machine Learning models is a realistic challenge. Therefore, we propose a method for estimating fault severity in an unsupervised setting. We define a robust Severity Indicator (SI) that reflects the shift in the severity levels of a fault. First, we define a healthy domain boundary for fault-free data using One-Class Support Vector Machines. SI scores are then computed using a novel adaptive feature weighing algorithm that assigns weights to individual features, adaptively, for every fault. We focus on detecting the shift in severity, rather than quantifying it. The study of the robustness of SI for different faults in HVAC subsystems, chillers, and air handling units (AHUs) yields consistently promising results. Our comparative analysis shows that our method outperforms the unweighted approach and existing state-of-the-art techniques for fault severity estimation. Notably, our method excels in detecting low-severity faults, addressing a common limitation in current methods.},
  archive      = {J_EAAI},
  author       = {Ramnath V. Prabhu Bam and Rajesh S. Prabhu Gaonkar and Clint Pazhayidam George},
  doi          = {10.1016/j.engappai.2025.112305},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112305},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient anchor-free model for ore particle size detection. <em>EAAI</em>, <em>162</em>, 112304. (<a href='https://doi.org/10.1016/j.engappai.2025.112304'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection of ore size is crucial in mineral processing, directly impacting equipment efficiency and product quality. However, traditional anchor-based models often struggle with the irregular shapes and varying scales of ore particles, resulting in limited performance. To overcome these challenges, an anchor-free detection framework was proposed. It incorporates a cross-stage partial bottleneck and a spatial pyramid pooling cross-stage partial connections (SPPCSCP-DualConv), both enhanced with dual convolution, to improve feature extraction and multi-scale fusion. In the backbone, the dual convolution module combines group convolution with heterogeneous convolution to improve feature diversity. The SPPCSCP-DualConv module further enhances feature representation in complex backgrounds. Additionally, a simplified path aggregation network (simPANet) feature fusion module is employed in the neck to refine the integration of multi-scale features. The proposed model was trained using a combination of binary cross-entropy, complete intersection over union (IoU), and distribution focal loss to optimize detection accuracy. The proposed model achieved a mean average precision of 86.80 % at an IoU threshold of .5 and 78.50 % across IoU thresholds from .5 to .95, surpassing existing methods while maintaining a lightweight architecture with only 10.10 million parameters and 89.45 giga floating point operations per second. Ablation studies confirmed the effectiveness of the simPANet and SPPCSPC-DualConv modules in enhancing feature representation. Generalization tests across mining sites with similar distributions demonstrated strong performance, although limitations remain for exceptionally large ore blocks due to dataset bias. The proposed model significantly improved the accuracy and efficiency of ore particle size detection, providing reliable real-time insights to improve grinding control and mineral processing operations.},
  archive      = {J_EAAI},
  author       = {Kanghui Zhang and Qingkai Wang and Guobin Zou and Jiawei Yang and Tao Song and Yang Liu and Daoxi Liu},
  doi          = {10.1016/j.engappai.2025.112304},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112304},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient anchor-free model for ore particle size detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning. <em>EAAI</em>, <em>162</em>, 112301. (<a href='https://doi.org/10.1016/j.engappai.2025.112301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failures in propulsion components, such as propellers, can critically affect flight safety; thus, early failure detection, preferably before flight, is essential. Traditional fault-diagnosis methods typically rely on additional sensors or operational data, which may not be available or practical in all situations. This study addresses these challenges by introducing motor-electric-signal-based fault diagnosis that is independent of airframe configuration and can detect faults, even when the aircraft is not in operation. However, difficulties arise owing to poor class variance in motor-electric-signal data and the challenge of obtaining fault data. To overcome these issues, a semi-supervised learning model based on a modified variational autoencoder-generative adversarial network (VAE-GAN) is proposed, which predicts faults using only normal motor-electric-signal data. Additionally, a new preprocessing method and patch-based ensemble inference technique are introduced to improve the poor class-variance characteristics of the data, thereby enhancing the prediction performance. This work demonstrates that propeller faults can be successfully diagnosed using motor-electric signals without the need for additional sensors or fault-data acquisition.},
  archive      = {J_EAAI},
  author       = {Sanga Lee and Dohyeong Kim and Minkyun Noh and Shinkyu Jeong and Jikang Kong and Youngjun Yoo},
  doi          = {10.1016/j.engappai.2025.112301},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112301},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight wood defect segmentation network via multi-dimension boundary perception and guidance. <em>EAAI</em>, <em>162</em>, 112300. (<a href='https://doi.org/10.1016/j.engappai.2025.112300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wood surface defect segmentation is extremely critical for defect refinement and quality control of wooden products. However, it is a challenging task to develop an efficient method with current algorithms due to the complicated characteristics of wood defects with obscure boundary, intraclass difference and interclass similarity. To address these issues, a lightweight network via multi-dimension boundary perception and guidance is proposed for precise segmentation of wood defects. At first, based on the Segformer, a boundary prediction branch is added to enrich detailed boundary information in the encoder, and supervised by the Gaussian signal and cosine similarity, to balance the effect of the boundary gradient information. Then, a double-flow enhancing module is designed to integrate the adjacent level features, by embedding two enhancing paths, to adaptively generate discriminative information of the defects. Finally, a binary segmentation head following the predicted map is introduced to strengthen the penalty for the false prediction results of the boundary. Experimental results demonstrate the proposed method outperforms the state-of-the-arts on our wood surface defect dataset, as well as on three public datasets.},
  archive      = {J_EAAI},
  author       = {Yuhang Zhu and Ye Lin and Zhezhuang Xu and Dan Chen and Kunxin Zheng and Yazhou Yuan},
  doi          = {10.1016/j.engappai.2025.112300},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112300},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight wood defect segmentation network via multi-dimension boundary perception and guidance},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse view tomographic reconstruction of elongated objects using learned primal-dual networks. <em>EAAI</em>, <em>162</em>, 112295. (<a href='https://doi.org/10.1016/j.engappai.2025.112295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the wood industry, logs are commonly quality screened by discrete X-ray scans on a moving conveyor belt from a few source positions. Typically, the measurements are obtained in a single two-dimensional (2D) plane (a “slice”) by a sequential scanning geometry. The data from each slice alone does not carry sufficient information for a three-dimensional tomographic reconstruction in which biological features of interest in the log are well preserved. In the present work, we propose a learned iterative reconstruction method based on the Learned Primal-Dual neural network, suited for sequential scanning geometries. Our method accumulates information between neighbouring slices, instead of only accounting for single slices during reconstruction. Evaluations were performed by training U-Nets on segmentation of knots (branches), which are crucial features in wood processing. Our quantitative and qualitative evaluations show that with as few as five source positions our method yields reconstructions of logs that are sufficiently accurate to identify biological features like knots (branches), heartwood and sapwood.},
  archive      = {J_EAAI},
  author       = {Buda Bajić and Johannes A.J. Huber and Benedikt Neyses and Linus Olofsson and Ozan Öktem},
  doi          = {10.1016/j.engappai.2025.112295},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112295},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sparse view tomographic reconstruction of elongated objects using learned primal-dual networks},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue. <em>EAAI</em>, <em>162</em>, 112292. (<a href='https://doi.org/10.1016/j.engappai.2025.112292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid flow shop scheduling problem (HFSP) is a prominent challenge in advanced manufacturing systems. Existing research often overlooks the impact of workers in production shops or treats worker fatigue as a static parameter, failing to capture its nonlinear accumulation and recovery effects on processing efficiency. However, with the advent of Industry 5.0, there has been a growing emphasis on the critical role of human factors in production scheduling. As a result, designing an effective algorithm for HFSP that considers human factors has become a prominent research focus. In this paper, an extended distributed heterogeneous hybrid flow shop scheduling problem with the dynamic effects of worker fatigue (DHHFSP-WF) is investigated. To address this problem, a Deep Q-Network-based multi-objective optimization algorithm (DQNMOEA) is designed to minimize makespan, total energy consumption (TEC), and total worker idle time (WIT). In DQNMOEA, a four-dimensional vector encoding scheme considering worker allocation represents solution, and a reconstruction strategy ensures initial population quality and diversity. Moreover, an improved order crossover, two-point crossover, and a segment-based recombination mutation method are proposed to enhance the global search performance of the algorithm. Then, a problem-specific local search strategy is designed for each layer of the vector, allowing the Deep Q-Network (DQN)-based adaptive decision-making mechanism to perform local perturbations on the current non-dominated solutions in the most suitable dimensions. Finally, seven algorithms are adopted to make a comparison on 36 sets of instances, the experimental results indicate that DQNMOEA exhibits competitive performance in solving DHHFSP-WF.},
  archive      = {J_EAAI},
  author       = {Jianlin Zhang and Longbin Ma and Wu Zhao and Jie Cao and Zuohan Chen and Tianpeng Xu},
  doi          = {10.1016/j.engappai.2025.112292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An angle-enhanced deep learning framework for thermal defect diagnosis in overhead transmission line composite insulators. <em>EAAI</em>, <em>162</em>, 112285. (<a href='https://doi.org/10.1016/j.engappai.2025.112285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to long-term outdoor exposure, composite insulators are susceptible to degradation and abnormal temperature rise, making Unmanned Aerial Vehicle (UAV)-based infrared inspections essential for effective monitoring. However, traditional manual interpretation of these images is inefficient and subjective. To improve detection automation and accuracy, we propose an intelligent detection method for composite insulators in infrared images based on an improved You Only Look Once version 11 (YOLOv11) model. The proposed approach introduces Oriented Bounding Boxes (OBBs) for annotation and designs an Angle-Enhanced Probabilistic Intersection over Union (AE-ProbIoU) loss function to enhance the model's ability to detect rotated objects. Experimental results demonstrate that the proposed Angle-Enhanced You Only Look Once (AE-YOLO) model achieves a mAP50:95 of 94.0 % and an angle prediction accuracy of 94.3 %. In addition, a temperature extraction module based on the OBBs is developed to accurately derive the temperature profile of the insulator core rod. This method significantly enhances the intelligence level of infrared image analysis for composite insulators and provides technical support for condition assessment and fault prediction in power transmission lines.},
  archive      = {J_EAAI},
  author       = {Xinzhe Yu and Zhenan Zhou and Yu Deng and Kun Zhang and Chen Gu and Zheyuan Liu and Songsong Zhou},
  doi          = {10.1016/j.engappai.2025.112285},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112285},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An angle-enhanced deep learning framework for thermal defect diagnosis in overhead transmission line composite insulators},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian bidirectional long short-term memory-based kinematics-dynamics fusion for fault-tolerant vehicle state estimation under yaw rate sensor failures. <em>EAAI</em>, <em>162</em>, 112283. (<a href='https://doi.org/10.1016/j.engappai.2025.112283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate estimation of vehicle states is a fundamental component of vehicle stability control systems. To address the issue of inaccurate estimation of vehicle state parameters resulting from yaw rate sensor failures, this study proposes a three-mode collaborative fault-tolerant state estimation method based on Bayesian Bidirectional Long Short-Term Memory (BiLSTM) kinematics-dynamics fusion. First, the kinematics-based method is established using the kinematics model. Second, the dynamics-based method is designed by integrating the Unscented Kalman Filter (UKF) with the dynamics model. Subsequently, a BiLSTM network fusion model based on Bayesian optimization is presented. The model utilizes estimates from kinematic and kinetic methods as a priori inputs and combines the bidirectional information capturing capability of BiLSTM with hyperparameter tuning from Bayesian optimization. The results indicate that when the yaw rate sensor fails, the proposed method achieves an average Root Mean Square Error (RMSE) of 0.0276 km per hour (km/h) for longitudinal speed, 0.0008 radian (rad) for side slip angle, and 0.0072 radian per second (rad/s) for yaw rate across all scenarios. This performance demonstrates a superiority over various maneuvers. This paper combines kinematics, dynamics, and deep learning to provide a reliable solution for fault-tolerant estimation of vehicle states.},
  archive      = {J_EAAI},
  author       = {Min Gao and Jiaqi Li and Wei Wang and Renguang Wang and Jin Luo and Jing Li},
  doi          = {10.1016/j.engappai.2025.112283},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112283},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bayesian bidirectional long short-term memory-based kinematics-dynamics fusion for fault-tolerant vehicle state estimation under yaw rate sensor failures},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate. <em>EAAI</em>, <em>162</em>, 112279. (<a href='https://doi.org/10.1016/j.engappai.2025.112279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary program diffing, or simply binary diffing, is a type of program analysis technique that quantifies the similarity between two binary programs to derive their differences. In particular, binary diffing is an essential technique for uncovering vulnerabilities and potential attack vectors in industrial control systems, where patch deployment is complicated by closed and restricted environments. Studies on binary diffing can be broadly categorized into dynamic analysis-based, static analysis-based, and neural network-based approaches. Each category of existing studies has its shortcomings, including limited coverage, low accuracy, and issues with on-demand learning. In this paper, we propose the binary diffing with sampling-and-aggregate, a hierarchical binary diffing model that generates inductive code representations based on graph sampling-and-aggregate. Our model sequentially produces instruction-level embedding, block-level embedding, and function-level embedding from the inter-procedural control flow graph of a given program, and then performs hierarchical code diffing based on these embeddings. We formally define the detailed models and present the algorithm of hierarchical binary diffing. Additionally, we conduct a thorough analysis of this algorithm, deriving several advantages. We implemented a prototype and evaluated it on a large-scale dataset in a cross-version, cross-optimization, and obfuscation settings. Our prototype showed F1-scores up to 0.96 and 0.968 in cross-version setting for function and basic block diffing, respectively. Also, our method demonstrated its robustness over several binary obfuscations. In conclusion, our proposal, which generates basic block- and function-level embedding by considering the control flow, has solid advantages on binary diffing and shows the robustness on the binary tampering.},
  archive      = {J_EAAI},
  author       = {Seungho Jeon and Kijong Koo and Daesung Moon and Jung Taek Seo},
  doi          = {10.1016/j.engappai.2025.112279},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112279},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network. <em>EAAI</em>, <em>162</em>, 112278. (<a href='https://doi.org/10.1016/j.engappai.2025.112278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Excavator arms are integral to the mining and construction industries, where real-time excavation load prediction is a critical element for the advancement of automated excavation technology. This study presents a novel Physics-guided Neural Network (PGNN) designed to predict the excavating force of hydraulic cylinders used in earthwork excavation. The PGNN model synergizes the physical load model of excavators with a Gated Recurrent Unit (GRU) neural network and is optimized using the Hyperband algorithm to attain both high-speed and precise forecasting. Through comparative experiments, the study validates the PGNN model's ability to achieve optimal response speed and precision in predicting excavation loads. Additionally, the predictive performance of the PGNN model is assessed via a Hardware-in-the-loop (HIL) test, conducted within the context of an actual excavation experiment. This research introduces a promising approach that seamlessly integrates physics-based modeling with machine learning techniques, facilitating real-time load forecasting for excavators. The findings pave the way for more efficient and precise excavation processes, with implications for the broader fields of mining and construction automation.},
  archive      = {J_EAAI},
  author       = {Jinshi Chen and Yue Yu and Dongyang Huo and Han Zhang and Jingyan Wang},
  doi          = {10.1016/j.engappai.2025.112278},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112278},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plug-and-play fine grained neural cognitive diagnosis framework. <em>EAAI</em>, <em>162</em>, 112276. (<a href='https://doi.org/10.1016/j.engappai.2025.112276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive diagnosis (CD) is a core task in intelligent education, which accurately assesses students’ mastery of specific knowledge concepts (KCs) by analyzing their answer records. However, existing methods mainly rely on explicit interaction data and use diagnostic models for automatic knowledge proficiency inference. These methods lack systematic optimization for fine-grained knowledge level representation, making it difficult to fully reflect students’ true learning status. To address this, this paper introduces a Plug-and-Play F ine Grained N eural C ognitive D iagnosis Framework (FNCD) with Knowledge-Level Constraint Awareness . The framework combines a knowledge proficiency evaluation module with students’ answer records and a Q-matrix to statically assess knowledge mastery. It uses a student similarity construction method based on random grouping to reveal latent learning pattern associations. Additionally, it employs a multi-scale relational learning strategy and a Top-k attention-enhanced graph network mechanism to dynamically adjust the student similarity relationship network, accurately modeling the complex learning relationships between students. Ultimately, a joint training mechanism is used to optimize the outputs of each module, significantly improving the rationality, interpretability, and accuracy of CD. The experimental results demonstrate that FNCD, as an artificial intelligence-driven plug-and-play module, can be effectively integrated into existing CD models to enhance the modeling of fine-grained knowledge mastery and improve diagnostic accuracy, showcasing the application potential of artificial intelligence in personalized education.},
  archive      = {J_EAAI},
  author       = {Xinjie Sun and Qi Liu and Kai Zhang and Weiyin Gong and Shuanghong Shen and Fei Wang and Yan Zhuang and Meikai Bao and Shijin Wang and Yuling Ma and Enhong Chen},
  doi          = {10.1016/j.engappai.2025.112276},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112276},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Plug-and-play fine grained neural cognitive diagnosis framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open-vocabulary object detection via neighboring region attention alignment. <em>EAAI</em>, <em>162</em>, 112270. (<a href='https://doi.org/10.1016/j.engappai.2025.112270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nature of diversity in real-world environments necessitates neural network models to expand from closed category settings to accommodate novel emerging categories. In this paper, we study open-vocabulary object detection (OVD), which facilitates the detection of novel object classes under the supervision of only base annotations and open-vocabulary knowledge. However, we find that the inadequacy of distilled information from the detector head during the alignment process inevitably constrains the performance of recent distillation-based OVD strategies. To this end, we propose Neighboring Region Attention Alignment (NRAA), which performs alignment within the attention mechanism to boost the open-vocabulary inference. Specifically, for a given proposal region, we randomly explore the neighboring boxes to capture the surrounding contextual vocabulary knowledge. Then, a set of regional token features, encompassing both the proposal and neighboring regions, utilize our proposed Neighboring Region Attention (NRA) to extract interaction information. Finally, this information is seamlessly provided to the distillation procedure to assist the alignment between the detector and the pre-trained vision-language models (VLMs). Extensive experiments validate that our proposed model exhibits superior performance on open-vocabulary benchmarks.},
  archive      = {J_EAAI},
  author       = {Sunyuan Qiang and Xianfei Li and Yanyan Liang and Wenlong Liao and Tao He and Pai Peng},
  doi          = {10.1016/j.engappai.2025.112270},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112270},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Open-vocabulary object detection via neighboring region attention alignment},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A time and frequency convolutional autoencoder for anomaly detection in industrial robots based on inertial measurement unit error calibration. <em>EAAI</em>, <em>162</em>, 112269. (<a href='https://doi.org/10.1016/j.engappai.2025.112269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of industrial robots, ensuring operational reliability and Long-Term Autonomy hinges on the accurate detection of anomalies. However, this sample difference due to noise, joint random errors and sensor errors increases the challenge of robot anomaly detection. To address this problem, an unsupervised deep learning method based on inertial measurement unit (IMU) error calibration is proposed. Firstly, the attitude signals acquired by the IMU from the end of the robot were calibrated using Kalman filtering. The three dimensional (3D) free acceleration was corrected based on the calibrated attitude signal and the calibrated 3D free acceleration signal was used as a signal sample. Secondly, a time and frequency convolutional autoencoder model (TFCAE) is proposed. And the distribution of the different component signals is fitted by stacking multiple encoder modules and 3D-TFCAE is used for 3D free acceleration signal reconstruction model. Then, the error sphere radius is calculated based on the reconstruction error of the 3D free acceleration signal. And the error sphere radius is used as the anomaly detection threshold to realize the robust detection of different types of anomalies. The model was evaluated on a constructed anomaly dataset. This study contributes an innovative 3D-TFCAE architecture, integrating Kalman filtering with time-frequency feature fusion, markedly enhancing anomaly detection in complex signal environments. Experimental findings reveal that 3D-TFCAE significantly outperforms 18 baseline models, improving detection accuracy by about 20 %–40 %, offering an effective solution for high-precision anomaly detection in industrial robots. The code for this project is available at https://github.com/LJlong977/3DTFCAE .},
  archive      = {J_EAAI},
  author       = {Jianlong Li and Xiaoqin Liu and Xing Wu and Dongxiao Wang and Kai Xu and Yashan Li},
  doi          = {10.1016/j.engappai.2025.112269},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112269},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A time and frequency convolutional autoencoder for anomaly detection in industrial robots based on inertial measurement unit error calibration},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight citrus detection and counting method based on deep learning model. <em>EAAI</em>, <em>162</em>, 112268. (<a href='https://doi.org/10.1016/j.engappai.2025.112268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picking robots have become an important development direction of smart agriculture, and the accurate detection, counting and lightweight deployment of fruits are the technical basis for realizing robot picking. However, due to complex weather conditions and the possible mutual occlusion between branches and citrus, it is challenging to accurately detect and count citrus in orchards. This study proposes a lightweight small target detection model for detecting and counting citrus, and deploys it on the citrus detection platform. The model first introduces FasterNet Block into the cross-stage partial feature fusion module of the backbone network to reduce the number of parameters and calculations while improving the detection accuracy of the network. Secondly, a multi-scale attention mechanism is added to the backbone network to enhance the feature extraction ability of the network. Finally, a bounding box loss function based on a dynamic non-monotonic focusing mechanism is used to increase the model convergence speed and further improve the model accuracy. Experimental results show that the model has an accuracy of 92.7%, an average precision of 91.7%, and a model size of only 5.37 megabytes. The lightweight model is applied to the citrus detection platform. Based on this application, a citrus counting method is proposed, which obtains a mean absolute error (MAE) of 0.92, a root mean square error (RMSE) of 1.28, a determination coefficient ( R 2 ) of 0.98, and a frame rate of 80.6 per second, which meets the requirements of real-time citrus detection and counting. This provides technical support for the subsequent deployment and counting research of picking robots.},
  archive      = {J_EAAI},
  author       = {Jiqing Chen and Mingchang Zhang and Bin Lu and Quan Chen and Zhiwu Jiang and Peilin Li and Jingyao Gai},
  doi          = {10.1016/j.engappai.2025.112268},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112268},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight citrus detection and counting method based on deep learning model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medical image fusion for high-level analysis: A mutual enhancement framework for unaligned photoacoustic tomography and magnetic resonance imaging. <em>EAAI</em>, <em>162</em>, 112259. (<a href='https://doi.org/10.1016/j.engappai.2025.112259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoacoustic tomography (PAT) offers optical contrast, whereas magnetic resonance imaging (MRI) excels in imaging soft tissue and organ anatomy. The fusion of PAT with MRI holds promising application prospects due to their complementary advantages. Existing image fusion has made considerable progress in pre-registered images, yet spatial deformations are difficult to avoid in medical imaging scenarios. More importantly, current algorithms focus on visual quality and statistical metrics, thus overlooking the requirements of high-level tasks. To address these challenges, we propose an unsupervised fusion model, termed PAMRFuse+, which integrates image generation and registration. Specifically, a cross-modal style transfer network is introduced to simplify cross-modal registration to single-modal registration. Subsequently, a multi-level registration network is employed to predict displacement vector fields. Furthermore, a dual-branch feature decomposition fusion network is proposed to address the challenges of cross-modal feature modeling and decomposition by integrating modality-specific and modality-shared features. PAMRFuse+ achieves satisfactory results in registering and fusing unaligned PAT–MRI datasets. Moreover, for the first time, we evaluate the performance of medical image fusion with multi-organ instance segmentation. Extensive experimental demonstrations reveal the advantages of PAMRFuse+ in improving the performance of medical image analysis tasks.},
  archive      = {J_EAAI},
  author       = {Yutian Zhong and Jinchuan He and Zhichao Liang and Shuangyang Zhang and Qianjin Feng and Lijun Lu and Li Qi},
  doi          = {10.1016/j.engappai.2025.112259},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112259},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Medical image fusion for high-level analysis: A mutual enhancement framework for unaligned photoacoustic tomography and magnetic resonance imaging},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Max–Min pooling and squeeze excitation lightweight bidirectional mamba for image classification. <em>EAAI</em>, <em>162</em>, 112246. (<a href='https://doi.org/10.1016/j.engappai.2025.112246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address challenges stemming from the quadratic computational complexity, slow execution speed, and high memory consumption of Transformer models, we propose a novel image classification method: Max–Min Pooling and Squeeze Excitation Lightweight Bidirectional Mamba(MMPSELMamba). The core artificial intelligence innovations include: (1) We design a max–min pooling mechanism that synergistically preserves high-activation foreground features through max-pooling and low-intensity contextual details via min-pooling. This approach addresses the information loss problem in conventional single-mode pooling methods; (2) Inspired by squeeze-enhanced Axial Transformer(SeaFormer), we design an axial squeeze excitation module that compresses redundant features along both vertical and horizontal dimensions while enhancing discriminative feature refinement; (3) Building upon recent advances in sequence modeling, we replace self-attention with a bidirectional Mamba architecture based on state space models (SSM), achieving linear complexity in the model of long-range dependencies; (4) Our novel multi-scale integration unit combines upsampling, concatenation, and downsampling operations to optimize feature fusion while minimizing computational overhead. For engineering applications, MMPSELMamba is specifically designed for resource-constrained environments such as edge devices and mobile vision systems. By integrating depthwise separable convolutions and lightweight SSM operations, it achieves a 36% parameter reduction and a 16% lower computational load compared to SeaFormer, while maintaining competitive accuracy. Experiments on public datasets validate its deployment potential in real-world scenarios like autonomous drones and embedded surveillance. Confusion matrices and heatmap visualizations further confirm the superior performance of the MMPSELMamba method. Our code can be gained from: https://github.com/yalemitter/MMPSELMamba-main .},
  archive      = {J_EAAI},
  author       = {Senlin Chi and Zhiwen Wang and Lianyuan Jang and Mengsi Gong},
  doi          = {10.1016/j.engappai.2025.112246},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112246},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Max–Min pooling and squeeze excitation lightweight bidirectional mamba for image classification},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes. <em>EAAI</em>, <em>162</em>, 112245. (<a href='https://doi.org/10.1016/j.engappai.2025.112245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate seismic risk assessment of railway embankments is critical for risk mitigation, seismic design, and emergency planning. However, conventional methods often suffer from computational inefficiency and complexity. This study proposes a novel machine learning (ML) framework to rapidly and accurately evaluate probabilistic seismic demand and risk for railway embankments. Latin hypercube sampling is utilised to generate representative soil parameter samples to construct numerical models for simulating dynamic responses under near-fault pulse-like ground motions. The peak permanent settlement (PPS) of the embankment surface is used as the key performance metric. Multiple ML models, including decision trees, random forests (RFs), extreme gradient boosting (XGBoost), artificial neural networks (ANNs), and a stacked ML model that integrates RFs, XGBoost, and ANNs, are trained and compared. The stacked ML model outperforms the other models and achieves the highest predictive accuracy for the PPS. SHapley Additive exPlanations are used to identify the velocity spectrum intensity (VSI) and the internal friction angle of the embankment as the most influential factors. Seismic fragility and risk curves are subsequently developed. The VSI and a power-law seismic hazard function are combined to estimate the annual exceedance probabilities for three seismic design criteria levels. The proposed ML framework significantly enhances the efficiency of seismic risk analysis while maintaining high precision, thereby providing a transformative approach for the seismic assessment of railway embankments.},
  archive      = {J_EAAI},
  author       = {Pan Si and Liang Tang and Shuang Tian and Xianzhang Ling and Yanfang Liu},
  doi          = {10.1016/j.engappai.2025.112245},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112245},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantization-based deep diversified ensemble for medical image segmentation. <em>EAAI</em>, <em>162</em>, 112242. (<a href='https://doi.org/10.1016/j.engappai.2025.112242'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in fully convolutional networks (FCNs) have significantly improved medical image segmentation. Ensemble methods are often used to further enhance performance, with diversity among learners being a critical factor. However, many current approaches focus on diversifying training samples or predictions while overlooking the diversity of internal multi-scale features. This oversight can lead to high correlations among features across different learners, limiting overall effectiveness. Additionally, traditional quantization methods aim to minimize accuracy loss by maintaining a rigid quantization process. This rigidity can eliminate the randomness introduced by quantization, further reducing ensemble diversity and effectiveness. In this paper, we propose a novel approach called Quantization-based Deep Diversified Ensemble (QDD-Ens) for medical image segmentation. Our method enhances the diversity of internal features among ensemble learners through two mechanisms: deep diversified loss, which focuses on feature diversity rather than segmentation accuracy, and deep diversified quantization, which preserves beneficial randomness in quantization process. Furthermore, QDD-Ens facilitates a deeper form of ensemble learning by employing a meta-learner to integrate diversified features at multiple resolution levels from various base learners, which are diversified by two above diversify enhancement mechanisms. Extensive experiments on five public medical image segmentation datasets show that our method significantly improves segmentation accuracy and outperforms existing ensemble techniques. The source code is publicly available to support future research. ( https://github.com/JerRuy/QDD-Ens )},
  archive      = {J_EAAI},
  author       = {Jiawei Zhang and Jialin Wang and Qi Wang and Yanchun Zhang and Weihong Han and Yangyang Mei and Yiyu Shi and Jian Zhuang and Meiping Huang and Xiaowei Xu},
  doi          = {10.1016/j.engappai.2025.112242},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112242},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantization-based deep diversified ensemble for medical image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning methods comparison by using statistical tests in solar energy forecasting based on weather features. <em>EAAI</em>, <em>162</em>, 112239. (<a href='https://doi.org/10.1016/j.engappai.2025.112239'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Climate change necessitates precise solar forecasting due to its weather-dependent intermittency. Key parameters - temperature, visibility, altitude, pressure, and wind speed - were analyzed using non-parametric tests. We prioritized short-term weather patterns over random data splitting for enhanced accuracy.Non-parametric tests, such as the Kolmogorov-Smirnov test, were used to assess data normality and select highly correlated features. Principal Component Analysis (PCA) reduces dataset dimensionality while preserving critical trends. Various machine learning approaches were evaluated, including: weighted linear regression (both with and without dimensionality reduction), boosted regression trees, and deep learning architectures-comprising both fundamental models (Convolutional Neural Networks [CNNs] and Recurrent Neural Networks [RNNs]) and advanced hybrid architectures (Temporal Convolutional Networks (TCN) Convolutional Neural Network-Long Short-Term Memory network (CNN-LSTM). All models were optimized through systematic hyperparameter tuning to enhance predictive performance, reduce computational complexity, and improve learning convergence rates. Special attention was given to addressing vanishing gradient problems in deep neural network implementations. Results show TCN outperform other deep learning models, achieving lower training and testing errors with fewer parameters and reduced time complexity. CNN-LSTM models, designed for spatial-sequence prediction, perform well but require more parameters and computational time. The lowest test and training errors belong to CNN-LSTM and TCN, with approximately 9 % and 2 % lower than the maximum amount, respectively. A trade-off between model complexity, error rates, and computational efficiency must be considered when selecting the optimal approach. Since relevant weather features vary by location, the proposed methodology serves as an adaptable algorithm for solar energy prediction in diverse geographical regions.},
  archive      = {J_EAAI},
  author       = {Mohammadreza pourmir and Seyedeh Mohadeseh Miri},
  doi          = {10.1016/j.engappai.2025.112239},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112239},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning methods comparison by using statistical tests in solar energy forecasting based on weather features},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events. <em>EAAI</em>, <em>162</em>, 112236. (<a href='https://doi.org/10.1016/j.engappai.2025.112236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic Principal Component Analysis (PPCA) is widely used in process monitoring. However, its underlying assumption that data follows a Gaussian distribution limits its effectiveness in handling Low Probability Events (LPEs), which often deviate from this assumption. To address this challenge, we propose a novel method called Sparse Filtering-based Improved Mixed-Gaussian Probabilistic Principal Component Analysis (SFIMPPCA) for enhanced LPEs detection. First, a Sparse Filtering (SF) preprocessing technique with an incremental structure is employed to extract the most discriminative features. Second, to address the distortion caused by LPEs, a dynamic ratio correction mechanism based on statistical variability is introduced, followed by a newly designed Mixed-Gaussian Probabilistic Principal Component Analysis (MPPCA). Third, a Bayesian Optimization Algorithm (BOA) is applied to automatically adjust control limits, enhancing the accuracy and reliability of fault detection. The effectiveness of the proposed method is validated using the Tennessee Eastman (TE) process and the Tin Chemical Process (TCP). Experimental results demonstrate that the proposed method significantly improves performance under LPEs conditions, achieving a 10%–12% improvement in most cases.},
  archive      = {J_EAAI},
  author       = {Chuangyan Yang and Jiande Wu and Peng Li and Xun Lang and Mingxi Ai and Hancheng Wang},
  doi          = {10.1016/j.engappai.2025.112236},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112236},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic graph neural network with historic-sequential information representation. <em>EAAI</em>, <em>162</em>, 112234. (<a href='https://doi.org/10.1016/j.engappai.2025.112234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s interconnected world, networks, whether social, technological, or biological, are constantly evolving, with relationships forming, shifting, and dissolving over time. Traditional models struggle to capture this fluidity, treating networks as static snapshots rather than living systems. While existing research has made strides in analyzing either spatial–temporal patterns or temporal sequences separately, these approaches often fall short in scalability and fail to unify discrete and continuous-time perspectives. To bridge this gap, we introduce DyGHS (Dynamic Graph Historical-Sequential), an innovative framework that harnesses dynamic graph neural networks to model how nodes, edges, and their historical interactions evolve together. By seamlessly integrating discrete-time and continuous-time graph representations, DyGHS not only captures the richness of real-world networks but also efficiently predicts future connections and node behaviors. Our experiments reveal that combining continuous-time Fourier transform (CTFT) with graph neural networks significantly boosts prediction accuracy, outperforming current methods in tasks like link prediction and node classification. This advancement opens new doors for understanding and anticipating the ever-changing tapestry of networked systems.},
  archive      = {J_EAAI},
  author       = {Adam Abakar Hamid and Anping Zhao and Alladoumbaye Ngueilbaye},
  doi          = {10.1016/j.engappai.2025.112234},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112234},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic graph neural network with historic-sequential information representation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation. <em>EAAI</em>, <em>162</em>, 112219. (<a href='https://doi.org/10.1016/j.engappai.2025.112219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain gaps can often cause dramatic performance deterioration when applying medical image segmentation models trained on the source domain to the target domain. Although unsupervised domain adaptation methods can address the domain gap challenge to some extent, their reliance on accessing source images largely hampers their practical applicability, as source data are often inaccessible due to privacy concerns. Moreover, the low-quality characteristic of medical images can further degrade the domain adaptation performance of segmentation models. To address these issues, we propose the Masked-AutoEncoder-guided Diffusion (MAE-Diff) framework for source-free domain adaptive medical image segmentation. MAE-Diff mainly consists of a Masked AutoEncoder (MAE) Module for effective feature extraction and domain adaptation, and a Diffusion Module for effective segmentation of low-quality medical images. On source images, the MAE encoder is trained to extract image-specific features, and the Diffusion Module is trained to generate segmentation maps following a gradual denoising strategy, under the guidance of features extracted by the MAE encoder. Training on the target domain involves only fine-tuning MAE (trained on the source images) with target images, allowing MAE-Diff to adapt to the target domain distribution. Inference on target images can then be made by the source-based Diffusion Module, under the guidance of features extracted by the MAE encoder fine-tuned on the target images. Extensive experiments on three datasets demonstrate the effectiveness of the proposed framework for source-free domain-adaptive medical image segmentation. The code of MAE-Diff is available at https://github.com/xuss804/MAEDiff .},
  archive      = {J_EAAI},
  author       = {Shanshan Xu and Le Xu and Yeqing Yang and Lixia Tian},
  doi          = {10.1016/j.engappai.2025.112219},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112219},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hierarchical reinforcement learning framework with imitation learning and bayesian Actor–Critic for distributed unmanned underwater vehicle encirclement in dynamic maritime environments. <em>EAAI</em>, <em>162</em>, 112214. (<a href='https://doi.org/10.1016/j.engappai.2025.112214'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of Unmanned Underwater Vehicles (UUVs) has introduced potential threats to critical infrastructure, with existing methods facing challenges in multi-agent collaboration and dynamic environment adaptation. To address these challenges, we propose HRL-IL-BAC—a Hierarchical Reinforcement Learning framework equipped with an Imitation-Learning (IL) high-level policy and a Bayesian Actor–Critic (BAC) low-level controller. The framework decomposes the encirclement mission into four sequential phases: submergence, interception, encirclement, and standoff tracking. At the high level, multi-agent collaboration and long-horizon autonomous decision-making are orchestrated by the IL-guided policy, whereby strategy convergence is accelerated and phase selection is rendered more precise. At the low level, environmental and model uncertainties are explicitly modeled by the BAC controller, so that adaptability and control accuracy are markedly boosted under dynamic ocean conditions. Validation through simulations and physical experiments demonstrates that the HRL-IL-BAC framework achieves 23.6% faster encirclement efficiency and 52.0% enhanced system stability compared to conventional methods, while maintaining superior adaptability to dynamic maritime conditions. This work provides an innovative and effective solution for underwater defense and marine security, offering new insights into multi-agent systems for complex maritime operations.},
  archive      = {J_EAAI},
  author       = {Hanbin Zhang and Wenchuan Zang and Peng Yao and Jiangli Cao and Dalei Song},
  doi          = {10.1016/j.engappai.2025.112214},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112214},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hierarchical reinforcement learning framework with imitation learning and bayesian Actor–Critic for distributed unmanned underwater vehicle encirclement in dynamic maritime environments},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule. <em>EAAI</em>, <em>162</em>, 112199. (<a href='https://doi.org/10.1016/j.engappai.2025.112199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first-order Takagi–Sugeno–Kang (TSK) fuzzy classifiers are famous for their high computational efficiency and strong interpretability, but they often struggle to learn from complex and large-scale datasets, and perform not very well compared to higher-order TSK fuzzy classifiers. To address this issue, in this paper we propose a novel Dynamic-Static Siamese TSK Fuzzy classifier with Inductive-Reflection Deep Fuzzy rule. It aims to enhance the model’s self-learning capabilities by utilizing Siamese network to integrate deep fuzzy knowledge and fine-grained knowledge without the need for a teacher model. The innovations of this study are as follows: (1) The deep fuzzy rules in the proposed classifier are enriched with an “Inductive-Reflection” process, which reduces constraints on traditional basic fuzzy rule and aligns rule acquisition more closely with general human thinking manners; (2) The proposed method includes a mechanism for self-learning and improvement from both deep and fine-grained fuzzy knowledge, eliminating the complexity of retraining a new teacher model; (3) An adaptive learning function is developed to effectively adjust the learning process, adapting to tasks with different complexities. Extensive experiments results on benchmark datasets, as well as two real-world datasets, demonstrate the effectiveness of the proposed classifier in terms of classification accuracy and weighted F1-score.},
  archive      = {J_EAAI},
  author       = {Xiongtao Zhang and Qihuan Shi and Yunliang Jiang and Qing Shen and Jungang Lou and Ruiqin Wang},
  doi          = {10.1016/j.engappai.2025.112199},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112199},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing anomaly detection with few-shot fine-tuned long text-to-image models. <em>EAAI</em>, <em>162</em>, 112174. (<a href='https://doi.org/10.1016/j.engappai.2025.112174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial anomaly detection plays a crucial role in the industrial manufacturing field. Currently, utilizing generated data to improve the performance of the anomaly detection model is an effective approach. However, most existing methods often rely on mask-guided synthesis, where the distribution of the generated defects is limited by masks that are typically random or learned by a model. In addition, the scarcity of real anomalous samples makes it difficult for generative models to capture genuine defect patterns and align with the real anomaly distribution. To tackle these issues, we propose DefectGen, the first long-text-guided few-shot text-to-image data generation pipeline for industrial anomaly detection. To improve distribution alignment under limited anomaly samples, DefectGen incorporates a Prompt Generation and Variation Module, which uses MLLMs (Multimodal Large Language Models) to expand few-shot image–text pairs into diverse and semantically rich prompts, and DoKr (Weight- D ecomposed L o w-Rank Adaptation with Kr onecker product), a lightweight fine-tuning strategy with structured low-rank adaptation. To ensure the quality of synthetic data, DefectGen further introduces the Real-Guided Clustering Filter, which selects high-quality generated samples by comparing their features with those of real anomalies. Experiments on the MVTec AD(MVTec AnomalyDetection) dataset show that DefectGen generates more diverse and realistic synthetic anomalies and achieves a 5.58% average improvement in anomaly classification accuracy compared to state-of-the-art methods. Code and data are available at: https://anonymous.4open.science/r/DefectGen-CD04/ .},
  archive      = {J_EAAI},
  author       = {Jiachen Liu and Jiajia An and Junbin Lu and Zhuoqin Yang and Jinbao Wang and Ping Lu and Yuying Wang and Linlin Shen},
  doi          = {10.1016/j.engappai.2025.112174},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112174},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing anomaly detection with few-shot fine-tuned long text-to-image models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A database of dentition images of indian breed cattle and estimation of cattle’s age using deep learning algorithms. <em>EAAI</em>, <em>162</em>, 112172. (<a href='https://doi.org/10.1016/j.engappai.2025.112172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate age estimation in livestock is crucial in agricultural management, influencing breeding, healthcare, and production planning. The primary method entails visually inspecting the teeth, a procedure susceptible to human fallibility. Recent deep learning (DL) algorithms are highly efficient in automating age prediction based on dentition images, offering faster and more accurate results. To our knowledge, no dataset exists for Indian livestock, hindering DL algorithm development for teeth segmentation and age estimation. Therefore, we created a database of dentition images for Indian livestock, covering an age range of 1 to 15 years, using 2,883 subjects. In this research, we employed a hybrid model based on You Only Look Once version 8 (YOLOv8) for instance segmentation of raw dentition images. Segmentation achieved 73.59% mean Average Precision (mAP) 50 and 56.44% mAP50–90, indicating strong performance in varying localization thresholds. These segmented images were then used in various DL algorithms, including convolutional neural network (CNN)-based transformers and vision transformers (ViTs), to develop DL models for age estimation. We conducted three age estimation experiments with increasing granularity: four age groups (4-year intervals), seven age groups (2-year intervals), and fifteen age groups (1-year intervals). InceptionV3 achieved the highest accuracy in the first two experiments with 73.72% and 62.41%, respectively. In the third experiment, MobileNet performed best with an accuracy of 43.87%. Our results demonstrate the effectiveness of these intricate DL models in enhancing livestock age estimation, making the process more streamlined and reliable. The study may assist farmers in making informed and efficient agricultural management decisions.},
  archive      = {J_EAAI},
  author       = {Chinmay Vijay Patil and Ankit Ashokrao Bhurane and Preeti Ghasad and Vipin Kamble and Manish Sharma and Anand Singh and Nareshkumar Nandeshwar and Ru-San Tan and Rajendra Acharya},
  doi          = {10.1016/j.engappai.2025.112172},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112172},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A database of dentition images of indian breed cattle and estimation of cattle’s age using deep learning algorithms},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed fine-tuning for physics discovery from random and sparse data. <em>EAAI</em>, <em>162</em>, 112132. (<a href='https://doi.org/10.1016/j.engappai.2025.112132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although significant advances have been made in both numerical methods and machine learning approaches for solving differential equations across various scientific sectors, these methods often rely on complete information about the differential equations, including precise parameter values, which are not easily obtainable in real-world scenarios. To address this challenge, data-driven methods for discovering differential equations have gained growing popularity in recent years. However, many existing approaches demand unrealistic prerequisites, such as extensive high-fidelity data or carefully designed low-fidelity data and functions. In this paper, we propose a novel method: P hysics- I nformed F ine- T uning ( PIFT ) to discover the unknown parameters in differential equations when only randomly distributed sparse data points are available. PIFT consists of three stages; (i) generating low fidelity data from prior knowledge under realistic settings, (ii) pre-training a single neural network with the generated low fidelity data, and (iii) fine-tuning the pre-trained model using physics-informed loss function. PIFT is evaluated on seven scientific problems including five ordinary differential equations and two partial differential equations. We also demonstrate the robustness and generalizability of PIFT to out-of-distribution tasks. PIFT exhibits high accuracy and robustness in discovering unknown parameters of differential equations from randomly distributed sparse data points.},
  archive      = {J_EAAI},
  author       = {Yong Jin Jeong and Taesup Moon},
  doi          = {10.1016/j.engappai.2025.112132},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112132},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed fine-tuning for physics discovery from random and sparse data},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep Q-learning with feature extraction and prioritized experience replay for edge node overload in edge computing. <em>EAAI</em>, <em>162</em>, 112124. (<a href='https://doi.org/10.1016/j.engappai.2025.112124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keeping track of the edge nodes’ status information is crucial, which is the condition of their available compute capacity as measured by their Age-of-Information. In Internet of Things-oriented edge computing systems, the computational and software-defined infrastructure resources are heterogeneous and subject to rapid change. Edge computing systems often face dynamic workloads and limited computational resources, leading to frequent node overload scenarios. These overloads degrade system responsiveness and service availability, especially in latency-sensitive applications. The scheduling of computation tasks would consider both current resource availability and predicted overload risks. An intelligent, adaptive method that learns optimal task allocation under resource constraints has the potential to boost the operational efficiency of Internet of Things-oriented edge computing systems. Addressing edge node overload is critical for the sustainable and scalable deployment of edge-based infrastructures. This research designs a resource-overloaded detection model specifically for diverse workloads in edge computing systems. The proposed Deep Reinforcement Learning model explores two significant challenges: the selection of pertinent feature sets from the workload resource utilization storage, and their classification of overload and detection of fatal failure of edge computing nodes. We propose a Deep-Q Network with a prioritized experience replay framework for edge node resource overload. The framework relies on feature learning using Linear Discriminant Analysis and Deep Q Network with a prioritized experience replay to efficiently indicate the overload status of edge nodes and reward the system with actions that enhance edge resources allocation. Deep-Q Network is well-suited for sequential decision-making in dynamic environments, while prioritized experience replay improves sample efficiency by focusing on updating on high-priority transitions with larger temporal-difference errors. Features are learned automatically from the edge node resource profiling data generated on a real edge-based container infrastructure. Linear Discriminant Analysis reduces the high-dimensional state space by emphasizing the most discriminative features for scheduling decisions. The infrastructure executes an intelligent inference of containerized applications considered as resource-intensive applications. When the feature extraction is added to the proposed deep reinforcement learning model, the overload classifier’s performance is improved. Comparing the model with selection to the one without it, the total accuracy and F1-score were improved by 1.3% and 1.4%, respectively.},
  archive      = {J_EAAI},
  author       = {Lionel Nkenyereye and Boon Giin Lee and Wan-Young Chung},
  doi          = {10.1016/j.engappai.2025.112124},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112124},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep Q-learning with feature extraction and prioritized experience replay for edge node overload in edge computing},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STEval: A framework for evaluating spatio-temporal crime prediction models. <em>EAAI</em>, <em>162</em>, 112123. (<a href='https://doi.org/10.1016/j.engappai.2025.112123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-Temporal predictive models are crucial for forecasting where and when crimes will occur, aiding public security organizations in resource allocation and crime prevention. Despite numerous literature proposals, a lack of standardized evaluation criteria hinders comparability and reliability. To address this, we propose STEval, a comprehensive and flexible evaluation framework for spatio-temporal predictive models. STEval consists of four modules: data preparation, spatial structure definition, model training, and model evaluation. The framework’s robustness was demonstrated using a 40-million-record crime dataset from Minas Gerais State (Brazil) across five experimental scenarios, including variations in temporal granularity, spatial resolution, and distribution shifts. Results demonstrate that no single model is universally superior, and the most appropriate model depends on the specific application context. For instance, Spatio-Temporal Kernel Density Estimation (STKDE) consistently achieved high Hit Rates (HR), often exceeding 0.98 in fine spatial resolutions (e.g., 100-square meters grid) for violent crimes, while Spatial-Temporal Autoregressive Integrated Moving Average (STARIMA) demonstrated strong performance in temporal granularity tests, reaching HRs of up to 0.65 for theft predictions. Conversely, Extra Tree Regressor, though exhibiting significantly lower HRs (e.g., as low as 0.02 in some spatial tests), consistently provided the fastest execution times, often under 5 s, contrasting with STKDE’s execution times that could extend to thousands of seconds in dense spatial grids. The framework’s detailed analysis provides important insights for informed model selection and optimization, revealing each model’s strengths and limitations, and providing a robust foundation for future advancements in spatio-temporal crime prediction research, leveraging Machine Learning (ML) techniques.},
  archive      = {J_EAAI},
  author       = {Gabriel Amarante and Matheus Pimenta and Yan Andrade and Matheus Senna and Rainer Menezes and Antônio Hot Faria and Marcelo Vilas-Boas and Frederico Martins de Paula Neto and João Paulo da Silva and Everton Renato de Sousa and Jamicel da Silva and Wagner Meira Jr. and George Teodoro and Leonardo Rocha and Renato Ferreira},
  doi          = {10.1016/j.engappai.2025.112123},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112123},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {STEval: A framework for evaluating spatio-temporal crime prediction models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology. <em>EAAI</em>, <em>162</em>, 112113. (<a href='https://doi.org/10.1016/j.engappai.2025.112113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is a network of interconnected devices that collect, monitor, analyze, and exchange data. This technology plays a crucial role in the smart city infrastructure by seamlessly interconnecting various nodes. The extensive application and recognition of IoT across multiple city domains, such as healthcare, transportation, energy, education, and agriculture, bring significant challenges, with security among the most pressing. Traditional hardware technologies like Complementary Metal Oxide Semiconductor (CMOS) and Very Large Scale Integration (VLSI) suffer from limitations such as high power consumption and insufficient scalability, which hinder secure and sustainable IoT deployment. Such limitations have prompted the need to seek other technologies that would serve the dual purpose of providing security as well as energy. Quantum-based technologies can become adequate candidates offering promising solutions to make IoT devices and sustainable systems more secured. Quantum-dot Cellular Automata (QCA) has been proposed as a nanotechnology with the potential of consuming ultra-low powers, less area, and high-speed operation. QCA enhances security through sustainable computing objectives by minimizing energy usage. To improve the future security and efficiency of IoT hardware, this paper suggests a QCA-based Arithmetic Logic Unit (ALU). This ALU can generate more than 12 logical and arithmetic operations. Designed together with the majority gates, XOR gates, multiplexers, and full adders, the ALU is simulated using the QCA-Designer 2.0.3. Simulated results indicate improvements in the number of cells and reduced occupied area relative to the earlier designs. These results indicate the potential of QCA technology in enabling secure, energy-efficient, and compact computing architecture applicable in the future IoT.},
  archive      = {J_EAAI},
  author       = {Maryam Zaker and Seyed Sajad Ahmadpour and Nima Jafari Navimipour and Muhammad Zohaib and Neeraj Kumar Misra and Sankit Kassa and Ahmad Habibizad Navin and Arash Heidari and Mehdi Hosseinzadeh and Omar I. Alsaleh},
  doi          = {10.1016/j.engappai.2025.112113},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112113},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prescribed-time convergence noise-tolerant zeroing neural network for multi-robot position management and coordination. <em>EAAI</em>, <em>162</em>, 112072. (<a href='https://doi.org/10.1016/j.engappai.2025.112072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A zeroing neural network (ZNN) model with prescribed-time convergence and noise tolerance is constructed for the first time to address multi-robot position planning (MPP) tasks. Unlike traditional ZNN models, which converge within finite, fixed, or predefined times, this model ensures that system errors converge precisely within the predefined time T p . Furthermore, it significantly enhances noise tolerance while maintaining excellent convergence performance. Through rigorous mathematical analysis and detailed numerical simulations, the proposed model demonstrates exceptional convergence and robustness, even under noise disturbances. In a noise-free environment, the convergence time accuracy (CTA) of this model when solving the MPP task reach over 90%, which is approximately 30% higher than traditional predefined-time convergence neural networks.},
  archive      = {J_EAAI},
  author       = {Tinglei Wang and Yufei Wang and Cheng Hua and Xinwei Cao and Bolin Liao and Shuai Li},
  doi          = {10.1016/j.engappai.2025.112072},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112072},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prescribed-time convergence noise-tolerant zeroing neural network for multi-robot position management and coordination},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inland waterway object detection in multi-environment: Dataset and approach. <em>EAAI</em>, <em>162</em>, 111994. (<a href='https://doi.org/10.1016/j.engappai.2025.111994'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has advanced intelligent ship visual perception, but the scarcity of dedicated inland waterway vessels dataset limits system adaptability in complex environments. Narrow waterways, variable weather, and urban interference challenge the robustness of existing object detection systems. To address these issues, this paper constructs the Multi-environment Inland Waterway Vessels Dataset (MEIWVD), comprising 32,478 high-quality images from diverse Yangtze River basin scenarios, including sunny, rainy, foggy, and artificially lit conditions. The diversity and multi-scale characteristics of MEIWVD establish it as a rigorous benchmark for vessel detection. To leverage the characteristics of the MEIWVD, this paper proposes a scene-guided image enhancement module for multi-environment scenarios, which adaptively enhances water surface images based on environmental conditions to improve detector performance in complex scenarios. Additionally, a parameter-limited dilated convolution is introduced to enhance the representation of salient features of inland waterway vessels by leveraging their geometric characteristics. Finally, a multi-scale dilated residual fusion method is proposed to effectively integrate multi-scale features and improve the detection of multi-scale objects. Comprehensive statistical analysis and experiments on the MEIWVD demonstrate that it poses higher demands on object detection algorithms compared to existing water surface datasets, owing to its diverse and challenging scenarios. The proposed methods, including scene-guided image enhancement, parameter-limited dilated convolution, and multi-scale dilated residual fusion, advance research in multi-environment dataset, achieving a mean average precision over intersection over union thresholds from 0.5 to 0.95 of 81.6 % on the MEIWVD, outperforming state-of-the-art object detection algorithms.},
  archive      = {J_EAAI},
  author       = {Shanshan Wang and Haixiang Xu and Hui Feng and Xiaoqian Wang and Pei Song and Sijie Liu and Jianhua He},
  doi          = {10.1016/j.engappai.2025.111994},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111994},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inland waterway object detection in multi-environment: Dataset and approach},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GhostPointNet: A deep learning-based method for ghost point noise detection in four-dimensional (4D) millimeter-wave radar point clouds of underground mine. <em>EAAI</em>, <em>161</em>, 112380. (<a href='https://doi.org/10.1016/j.engappai.2025.112380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high dust concentration, multi-metal supports, and narrow winding tunnels in underground mines collectively lead to frequent ghost point noise in four-dimensional (4D) millimeter-wave radar point clouds, posing serious challenges for mining perception and localization. To address this, we propose a deep learning algorithm, named GhostPointNet, for 4D millimeter-wave radar ghost point detection in underground mining environments. From an artificial intelligence perspective, this model thoroughly considers the multi-modal features of 4D millimeter-wave radar and the environmental complexity of underground mines. It incorporates multi-parameterized spatial information inputs in both Cartesian and Spherical coordinates, coupled with “Double T-Net” adaptive alignment correction, while integrating non-spatial information such as radar power and Doppler data to achieve multi-modal representation and end-to-end discrimination between ghost points and real points. Experimental validation shows that GhostPointNet achieves excellent performance in underground mining scenarios with 92.45 % accuracy and 95.84 % F1-score, outperforming traditional filtering, clustering, and machine learning algorithms. From an engineering application perspective, GhostPointNet is specifically designed for ghost noise detection in underground mines. Even in complex scenarios such as mine tunnel intersections and turns, it preserves critical structural points. Its end-to-end neural network simplifies post-processing procedures, enhances operational efficiency, and provides stable and reliable perceptual support for subsequent tasks such as autonomous mine locomotive navigation and three-dimensional (3D) structure reconstruction. Experimental results demonstrate that this method surpasses baseline approaches in ghost point detection, real point preservation, and generalization capability, providing significant support for improving underground mining safety and efficiency.},
  archive      = {J_EAAI},
  author       = {Hu Liu and Zhenghua Zhang and Jing Yang and Jörg Benndorf and Xiaofei Wang and Jiaqi Dong and Zitao Lin and Guoliang Chen},
  doi          = {10.1016/j.engappai.2025.112380},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112380},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GhostPointNet: A deep learning-based method for ghost point noise detection in four-dimensional (4D) millimeter-wave radar point clouds of underground mine},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid ensemble learning for predicting peak deviatoric stress in soil-rock mixtures from triaxial test data. <em>EAAI</em>, <em>161</em>, 112377. (<a href='https://doi.org/10.1016/j.engappai.2025.112377'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peak deviatoric stress ( q f ) is an important mechanical property index of soil-rock mixtures (SRM). However, determining it through experiments is a challenging and time-consuming task. This study presents a weighted averaging ensemble model for predicting the q f of SRM. 585 sets of consolidated drained triaxial test data for SRM were collected to construct the proposed models. Firstly, taking the extreme gradient boosting (XGBoost) as an example, the accuracy of the models established with different input parameter combinations was tested to determine the optimal inputs. Then, five artificial intelligence models were used to train the dataset, and the Bayesian optimization method was adopted for hyperparameter adjustment. Based on the prediction results, two base models (i.e. XGBoost and random forest (RF)) with good performance were selected from these five models, and a novel weighted averaging ensemble model was developed to predict the q f of SRM. The coefficient of determination (R 2 ), root mean squared error (RMSE) and mean absolute error (MAE) values of the ensemble model were 0.990, 220.0 kPa (kPa) and 118.4 kPa, respectively, for all datasets, indicating that this model has great potential in predicting the q f of SRM. In addition, the robustness, parameter patterns and the SHapley Additive exPlanations (SHAP) analysis of the ensemble model were also conducted in this study. The results of this study can be applied to rapid analysis of mechanical parameters for SRM in engineering, and are of great significance for geotechnical engineering design and disaster prevention.},
  archive      = {J_EAAI},
  author       = {Ruiliang Zhang and Xinhua Xue},
  doi          = {10.1016/j.engappai.2025.112377},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112377},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid ensemble learning for predicting peak deviatoric stress in soil-rock mixtures from triaxial test data},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph attention neural network for advancing medical imaging by enhancing segmentation and classification. <em>EAAI</em>, <em>161</em>, 112372. (<a href='https://doi.org/10.1016/j.engappai.2025.112372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor classification and segmentation using Magnetic Resonance Imaging (MRI) scans remain challenging due to limited spatial relationships and the inability of conventional models, such as Convolutional Neural Networks (CNNs), to effectively capture structural dependencies. To address these limitations, this study introduces GANN-Med (Graph Attention Neural Network for Medical Imaging), a novel framework designed to improve the accuracy and reliability of brain tumor detection, segmentation, and classification. The framework utilizes the publicly available Brain Tumor MRI dataset and applies preprocessing followed by wavelet transform to extract both spatial and frequency features, generating wavelet-based node embeddings that represent fine textures and overall tumor structure. These features are modeled as a graph and processed through a U-Net (U-shaped Convolutional Network) architecture integrated with Graph Attention Networks (GATs), enabling adaptive attention to be directed to critical tumor regions. The segmented tumor regions are then classified using GraphSAGE (Graph Sample and Aggregation) with a pooling aggregator, which supports inductive neighborhood learning while preserving topological consistency. Unlike existing models such as mResU-Net (Modified Residual U-Net) and LG-GNN (Local-Global Graph Neural Network), GANN-Med uniquely combines wavelet-based multi-resolution graph embeddings with attention mechanisms in a unified architecture. Experimental results demonstrate a significant performance boost, including an 18.47 % increase in Dice Similarity Coefficient (DSC), notable improvements in Jaccard Index and sensitivity, a 21.04 % reduction in false positives, and an overall classification accuracy of 93.2 %, with a balanced accuracy of 91.8 % across glioma, meningioma, pituitary, and no tumor classes. Additionally, the model achieves minimal training and validation losses of 43.2 % and 41.6 %, respectively, highlighting its potential to minimize misdiagnosis and contribute to more accurate, early-stage clinical decision-making in neuro-oncology.},
  archive      = {J_EAAI},
  author       = {Meshari D. Alanazi and Khaled Kaaniche and Mohammed Albekairi and Turki M. Alanazi and Munid Alanazi and Ghulam Abbas},
  doi          = {10.1016/j.engappai.2025.112372},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112372},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph attention neural network for advancing medical imaging by enhancing segmentation and classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy scheduling in distributed heterogeneous printed circuit board assembly lines: Feedback assisted neighborhood-based search coupling with rapid evaluations. <em>EAAI</em>, <em>161</em>, 112353. (<a href='https://doi.org/10.1016/j.engappai.2025.112353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Printed Circuit Board (PCB) production involves multiple heterogeneous and highly automated assembly lines running concurrently. These assembly lines involve complex processes with uncertain and fuzzy production times, presenting significant challenges for scheduling. Moreover, PCB production is notably affected by carryover sequence-dependent setup times (CSDST) and the need for product grouping, further complicating the scheduling process. To address these challenges, this paper formulates the scheduling problem as a fuzzy distributed heterogeneous flowshop group scheduling problem with carryover sequence-dependent setup times (FDHFGSP/CSDST). A novel and effective feedback-assisted population-based neighborhood search (FPBNS) algorithm, coupling with rapid evaluation of neighboring solutions, is proposed to solve this problem. The feedback strategy operates on two main levels: evaluating population quality and adjusting the search process. Additionally, an integrated heuristic method is employed to generate a high-quality and diverse initial population. To further enhance solution quality, a collaborative operation is designed to improve interaction between solutions. This comprehensive algorithm significantly enhances its adaptability in PCB manufacturing, providing an efficient solution to the complex scheduling challenges of real-world production environments. Comprehensive and systematic experiments were conducted to evaluate the effectiveness of the proposed algorithm and related methods, demonstrating its superior performance in solving the complex scheduling problem in PCB manufacturing.},
  archive      = {J_EAAI},
  author       = {Zhen-duo Han and Biao Zhang and Chao Lu and Lei-lei Meng and Wen-qiang Zou},
  doi          = {10.1016/j.engappai.2025.112353},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112353},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy scheduling in distributed heterogeneous printed circuit board assembly lines: Feedback assisted neighborhood-based search coupling with rapid evaluations},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A high-precision acupoint recognition and localization model for acupuncture robot end-effectors. <em>EAAI</em>, <em>161</em>, 112348. (<a href='https://doi.org/10.1016/j.engappai.2025.112348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate acupoint recognition is fundamental to therapeutic efficacy of acupuncture robots, presenting a crucial challenge in medical robotics: high-precision, real-time localization of sparse features on deformable skin surfaces. To address this, we propose the Acupoint Recognition Network (ACU-Net) for reliable acupoint identification to guide robotic acupuncture. From an artificial intelligence (AI) perspective, the core contribution of ACU-Net lies in its novel modules. The Convolutional Dilatation with Residual and Split (CDRS) module uses dilated convolution to expand the receptive field and overcomes the sparsity of acupoint features by capturing both anatomical contexts and subtle local gradients. The Cross-Scale Feature Fusion (CSFF) architecture integrates spatial and semantic information more effectively than standard Feature Pyramid Network (FPN). Formulated as a keypoint regression task, the network is jointly optimized using a weighted Object Keypoint Similarity (OKS)-based loss function. Evaluated on a physician-annotated, large-scale chest acupoint dataset, ACU-Net has achieved a mean Average Precision (AP 50-95 (B)) of 94.1 % for acupoint bounding boxes and 99.5 % for acupoint points (AP 50-95 (P)), outperforming mainstream Convolutional Neural Networks (CNNs) and Transformer models. Its average prediction error (0.282 cm) on volunteers represents a 30.9 % reduction compared to the second-best model of Real-Time Multi-person Pose Estimation (RTMPose). Robustness test on an independent forearm dataset confirmed its precision. Attention visualization showed strong focus on acupoint regions. Testing on chest acupoint under adverse imaging conditions of low illumination and information loss demonstrated its reliability with zero missed detection. This work significantly advances the development of acupuncture robotics for intelligent diagnosis and treatment.},
  archive      = {J_EAAI},
  author       = {Ailing Tan and Hao Mu and Wei Ma and Yu'e Lv and Haoyu Wang and Yong Zhao},
  doi          = {10.1016/j.engappai.2025.112348},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112348},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A high-precision acupoint recognition and localization model for acupuncture robot end-effectors},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Eviformer: An uncertainty fault diagnosis framework guided by evidential deep learning. <em>EAAI</em>, <em>161</em>, 112328. (<a href='https://doi.org/10.1016/j.engappai.2025.112328'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unpredictable signals are commonly encountered during equipment operation, and existing deep learning-based fault diagnosis methods often fail to accurately evaluate the uncertainty of diagnostic results, limiting the model's capacity to respond to unexpected signals. To address this challenge, this study introduces a modified Transformer model based on deep evidential learning—Eviformer. The proposed model first employs a Swin-Transformer (ST)-based distribution projector, which preserves the advantages of ST in extracting features from vibration signals and simultaneously projects these signals directly into a Dirichlet distribution with second-order probabilities. Furthermore, by incorporating novel evidence correction terms and a constraint factor to reconstruct the evidence constraint loss, more precise uncertainty quantification in diagnostic predictions is achieved. Using a gear-bearing vibration dataset, comparative experiments were conducted across various scenarios, including out-of-distribution gear faults, faults in unmonitored components, noise interference, and variable speed conditions. The results demonstrate that the proposed method can promptly issue uncertainty-based warnings when encountering vibration signals that significantly differ from the training set distribution, thereby offering essential support for maintenance decisions.},
  archive      = {J_EAAI},
  author       = {Jingjie Luo and Fucai Li and Xiaolei Xu and Wenqiang Zhao and Dongqing Zhang},
  doi          = {10.1016/j.engappai.2025.112328},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112328},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Eviformer: An uncertainty fault diagnosis framework guided by evidential deep learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale spatiotemporal feature fusion for super-resolution video reconstruction in dynamic scenes. <em>EAAI</em>, <em>161</em>, 112327. (<a href='https://doi.org/10.1016/j.engappai.2025.112327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-quality geospatial video reconstruction is vital for applications such as urban surveillance and disaster assessment. However, existing methods often suffer from motion blur and visual artifacts due to hardware limitations and dynamic environments with rapid motion, frequent background changes, and lighting variations. To address these challenges, we propose a novel video super-resolution method called Multi-Scale Spatiotemporal Feature Fusion for Video Super-Resolution. This approach leverages artificial intelligence techniques to extract rich spatiotemporal features using a multi-scale deformable convolutional pyramid with parallel branches. It integrates contextual residual learning and optical flow estimation to capture spatial details and compensate for missing temporal information. A hybrid spatiotemporal attention mechanism adaptively fuses key features across frames through dynamic weighting, suppressing background interference and enhancing target-region representation. The framework includes an explicit motion compensation module for precise frame alignment, followed by upsampling to generate high-resolution frames with improved perceptual quality. A multi-task joint loss function optimizes structural fidelity, motion consistency, and visual realism. Experimental results on the University of Alberta Detection and Tracking dataset and Video for Super-Resolution benchmark show the method achieves a peak signal-to-noise ratio of 30.62 dB and a structural similarity index of 0.92, surpassing state-of-the-art methods by up to 4.28 dB and improving perceptual metrics such as Learned Perceptual Image Patch Similarity and Flip Loss in Perception. Ablation studies confirm each module's contribution. The model runs efficiently at 24.8 ms per frame, demonstrating potential for real-time applications. This approach offers a robust and efficient solution for high-resolution geospatial video reconstruction.},
  archive      = {J_EAAI},
  author       = {mengqin Yang and yanhui Wang and yang Yang and chunhua Peng},
  doi          = {10.1016/j.engappai.2025.112327},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112327},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale spatiotemporal feature fusion for super-resolution video reconstruction in dynamic scenes},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable framework based on integrated sensor fusion and deep learning to estimate stability in high-speed micromilling of thin-walled titanium alloy. <em>EAAI</em>, <em>161</em>, 112326. (<a href='https://doi.org/10.1016/j.engappai.2025.112326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel deep learning (DL) framework based on multi-sensor fusion based on vibration and audio signals with transfer learning has been developed and validated for chatter onset prediction in micromilling of thin-walled titanium (TC4) alloys. The DL framework has been trained and validated with individual sensor data, labelled using machined surface micrographs and cutting tool condition. A total of 879,840 spectrograms has been generated for training via signal segmentation and augmentation methods that yielded a validation accuracy of 89 % during training phase. The trained DL model has been tested on the unlabelled fused signal data to make the DL model adapt to the unseen patterns in the signals recorded during real-time machining. The proposed DL framework based on fused signals outperformed individual sensor-based detection methods by demonstrating an increment of 33 % in accuracy, with a mean absolute error of 0.027416 and R 2 of 0.987. Ablation studies confirm that fusing signals enhances the DL model's performance, yielding a 21 % and 29 % improvement in precision and recall, respectively. The optimal fusion strategy reduced chatter misclassification, with one instance of misclassification. The proposed framework presents a robust, explainable DL approach that can be readily used for adaptive control of cutting conditions in different manufacturing processes. The industry readiness of the DL model has been demonstrated by testing the pretrained model on turning process. The DL model shows 95.31 % prediction accuracy with only three misclassifications out of sixty-four test conditions.},
  archive      = {J_EAAI},
  author       = {Sethurao Gururaja and Kundan K. Singh},
  doi          = {10.1016/j.engappai.2025.112326},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112326},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable framework based on integrated sensor fusion and deep learning to estimate stability in high-speed micromilling of thin-walled titanium alloy},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Liquid metal microfluidic cooling system for high-efficiency thermal management via learning-based genetic algorithm. <em>EAAI</em>, <em>161</em>, 112324. (<a href='https://doi.org/10.1016/j.engappai.2025.112324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High heat flux density is a critical factor that limits the performance and reliability of miniaturized, high-power microelectronic systems. This study proposes a liquid metal (LM)-based microfluidic cooling system optimized through a data-driven computational framework based on an enhanced Genetic Algorithm (LC-GA), aiming to deliver an efficient thermal management solution for high-density integrated systems. By integrating LM near-junction cooling with microchannel heat dissipation in a silicon substrate, we developed a heterogeneous three-dimensional interconnect cooling architecture capable of optimizing thermal performance through algorithm-guided parameter tuning. To validate the proposed method, four distinct microchannel configurations were designed, fabricated, and experimentally tested. LM was introduced into the channels to conduct both experimental cooling tests and thermal performance simulations on a simulated heat source. The results demonstrate that this LM-based microfluidic cooling system, optimized through computational parameter determination, can effectively dissipate heat from chips with power consumption up to 800 W while maintaining stable thermal performance. Additionally, a response surface methodology combined with enhanced LC-GA was utilized for multi-factor sensitivity analysis and multi-objective optimization, enabling automatic determination of optimal design and operating parameters to balance thermal resistance and pressure drop. The optimized configuration reduced the maximum chip temperature to approximately 357.54 K, lowered the system pressure requirement, and improved the Performance Evaluation Criterion (PEC) to 2.327. This work provides a data-driven optimization approach that supports the development of high-performance integrated microsystems through algorithm-assisted thermal design.},
  archive      = {J_EAAI},
  author       = {Yucheng Wang and Antong Bi and Kaiyu Chen and Shenxin Yu and Wanping Gao and Wenyi Zhang and Yuwan Wu and Zhiqiang Li and Shaoxi Wang},
  doi          = {10.1016/j.engappai.2025.112324},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112324},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Liquid metal microfluidic cooling system for high-efficiency thermal management via learning-based genetic algorithm},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HoloFluoNet: Live cell imaging intelligence based on fused holography and fluorescence for virtual staining, cell segmentation, classification, and viability analysis. <em>EAAI</em>, <em>161</em>, 112323. (<a href='https://doi.org/10.1016/j.engappai.2025.112323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluorescence microscopy enables detailed visualization of subcellular structures but is limited by phototoxicity, photobleaching, and labor-intensive labeling. In contrast, digital holographic microscopy (DHM) offers label-free, quantitative phase imaging but lacks biochemical specificity. To integrate the strengths of both modalities, we propose HoloFluoNet, a deep learning-based framework that generates virtual fluorescence information from phase images acquired by DHM. Using a dual-mode imaging system, we simultaneously captured phase and fluorescence images of live cancer cells. The fluorescence data were used to construct biologically grounded supervision signals, including nuclei masks and multi-class cell viability labels. From a single-phase image, HoloFluoNet predicts a virtual nuclei mask, a distance map for boundary refinement, and a viability mask. The architecture incorporates multi-scale feature extractor, and attention mechanisms, optimized with novel inclusion and exclusion loss functions. Post-processing using the watershed algorithm ensures accurate segmentation of overlapping cells. The final registered image provides label-free virtual staining for nuclei localization, viability assessment, and class-specific morphological profiling. HoloFluoNet achieved a Dice score of 0.8685 and an Aggregated Jaccard Index (AJI) of 0.7883, outperforming conventional deep learning models such as U-Net, Fully Convolutional Network (FCN), Pyramid Scene Parsing Network (PSPNet), and DeepLab v3+. These improvements were statistically validated using one-way analysis of variance (p < 0.01). Ablation experiments confirmed the complementary roles of architectural modules and novel loss functions, while robustness tests under noisy and low-quality conditions revealed high stability to low contrast and moderate noise. With an inference speed of 0.123 s per image, the model enables real-time cellular analysis. By bridging structural and molecular imaging, HoloFluoNet provides an efficient, label-free alternative to fluorescence microscopy, with promising applications in artificial intelligence (AI)-assisted drug screening, cancer research, and live-cell monitoring.},
  archive      = {J_EAAI},
  author       = {Seonghwan Park and Jaeseong Lee and Jaewoo Park and Inkyu Moon},
  doi          = {10.1016/j.engappai.2025.112323},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112323},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HoloFluoNet: Live cell imaging intelligence based on fused holography and fluorescence for virtual staining, cell segmentation, classification, and viability analysis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Method for ensuring quasi-maximum stability of a system with interval deviations by a robust controller parametric synthesis. <em>EAAI</em>, <em>161</em>, 112320. (<a href='https://doi.org/10.1016/j.engappai.2025.112320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that ensuring reliable stability of automatic control systems with interval and stochastic parameter deviations is critical for aviation and other critical areas. Therefore, this article proposes a method for synthesizing Proportional-Integral-Derivative controller parameters based on the coefficient approach to stability analysis (through the characteristic polynomial neighboring coefficients ratios) with an extension to interval uncertainties and the stability quasi-maximum degree integration into the multi-criteria optimization Non-Dominated Sorting Genetic Algorithm II. Scientific contribution and novelty lie in combining analytical sufficient stability conditions (including verification by Kharitonov polynomials and dominant polynomial analysis) with multi-objective optimization taking into account parameter errors and energy costs, which allows obtaining stable and economical Proportional-Integral-Derivative settings for discrete two-channel systems. The results are confirmed by numerical experiments on a helicopter turboshaft engine two-channel control system model with real on-board data. It is shown that the optimal parameter vector provides overshoot of ≈1.43 % and transient process time of ≈1.12 s and maintains stability with local changes in coefficients (±3 … 7 %) and in Monte-Carlo tests. At the same time, a comparative analysis with traditional and neural network controllers showed the proposed approach's advantage in key metrics.},
  archive      = {J_EAAI},
  author       = {Denys Baranovskyi and Serhii Vladov and Valerii Sokurenko and Oleksandr Muzychuk and Victoria Vysotska and Maryna Bulakh},
  doi          = {10.1016/j.engappai.2025.112320},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112320},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Method for ensuring quasi-maximum stability of a system with interval deviations by a robust controller parametric synthesis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust deep learning model selection with data augmentation for automatic detection of tessellated fundus images and explainable artificial intelligence based interpretation. <em>EAAI</em>, <em>161</em>, 112316. (<a href='https://doi.org/10.1016/j.engappai.2025.112316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust deep learning system for automatically classifying retinal fundus images into two classes—normal and tessellated—is presented in this study. Visual Geometry Group – 16 is used as the base model, taking advantage of transfer learning to develop an efficient framework for fundus image classification. The approach uses nine different model architectures and makes use of a dataset of 352 fundus images that was increased to 4865 samples using sophisticated data augmentation techniques. Of these, Model_8 performed the best, achieving a loss of 0.129 % and an impressive accuracy of 99.39 %. The suggested approach ensures higher performance and dependability by combining rigorous data augmentation, efficient preprocessing, and model fine-tuning techniques. Furthermore, Explainable Artificial Intelligence was used to improve the interpretability of the model and visualize important aspects such as features or imposed pathologies in fundus images more clearly. The study offers promising support to ophthalmologists by offering precise automated diagnoses for the early identification and treatment of retinal disorders.},
  archive      = {J_EAAI},
  author       = {Kachi Anvesh and Shanmugasundaram Hariharan and Bharati M. Reshmi and Qiang Xu and Joan Lu and Vinay Kukreja and Murugaperumal Krishnamoorthy},
  doi          = {10.1016/j.engappai.2025.112316},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112316},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust deep learning model selection with data augmentation for automatic detection of tessellated fundus images and explainable artificial intelligence based interpretation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Camera-invariance correlation learning and inter-domain-specific distinct representation for person re-identification. <em>EAAI</em>, <em>161</em>, 112314. (<a href='https://doi.org/10.1016/j.engappai.2025.112314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) in person re-identification (ReID) experiences performance degradation due to two primary factors: (1) the information changes across cameras among intra-domain identity samples within the source and target domains; and (2) the inter-domain gap when applied to an unexplored image domain, which makes it a challenging task. The majority of current methodologies predominantly address the inter-domain gap while overlooking the impact of the intra-domain issue. To overcome this limitation, this paper proposes an effective invariance representation ReID (IR-ReID) network that encompasses camera-invariance correlation learning (CICL) and Transformer-based, inter-domain-specific discriminative representation (IDSR), supported by curriculum learning, with the aim of concurrently addressing both of these pivotal issues. Specifically, a CICL module is designed to explore intra-domain distinct features of an individual captured by multiple cameras across the source and target domains. Secondly, an IDSR module is proposed to address the inter-domain gap issue. Thirdly, a curriculum learning-driven strategy is introduced for sample training, systematically guiding our network in learning samples progressively, ranging from easy to difficult instances. Meanwhile, a cluster-based constraint loss is presented to further optimize the clustering results. Finally, extensive experiments are conducted on three well-known datasets, which demonstrate the effectiveness and superiority of our proposed approach in comparison to the prevailing state-of-the-art methodologies.},
  archive      = {J_EAAI},
  author       = {Shangdong Zhu and Yunzhou Zhang and Peng Duan},
  doi          = {10.1016/j.engappai.2025.112314},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112314},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Camera-invariance correlation learning and inter-domain-specific distinct representation for person re-identification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applications of machine vision technology for conveyor belt deviation detection: A review and roadmap. <em>EAAI</em>, <em>161</em>, 112312. (<a href='https://doi.org/10.1016/j.engappai.2025.112312'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conveyor belt deviation is a frequent challenge in product transportation filed, and failure to promptly detect and rectify this anomaly not only significantly reduces transport efficiency but also poses a risk of serious safety accidents, leading to enormous economic losses. Traditional contact-based deviation detection technologies, with their inherent limitations of high costs and complicated maintenance, have struggled to meet the practical demands of long-distance conveyor belt inspection. In this context, non-contact machine vision technology has emerged as a prominent solution in the field of conveyor belt deviation detection, thanks to its notable advantages of a simple hardware structure and round-the-clock operational capability. Recently, with the rapid development of artificial intelligence theories, this research field has accumulated a series of effective solutions that have been proven through machine vision practical applications. This paper delves into the technical principles of the existing solutions, systematically summarizes them and objectively evaluates their strengths and weaknesses in practical applications. Based on this foundation, this paper also provides an insight on the future development trends of intelligent monitoring for conveyor belt deviation, aiming to offer valuable reference and guidance to technicians in related fields.},
  archive      = {J_EAAI},
  author       = {Jiaming Han and Ting Fang and Wensheng Liu and Chenxiao Zhang and Molin Zhu and Jibin Xu and Jie Ji and Xianhua He and Zhang Wang and Min Tang and Chong Dong and Long Ma and Xinlong Yang},
  doi          = {10.1016/j.engappai.2025.112312},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112312},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Applications of machine vision technology for conveyor belt deviation detection: A review and roadmap},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic aperture radar target recognition with limited training data based on frequency-domain-assisted dual-stream attention hierarchical deformable convolutional networks. <em>EAAI</em>, <em>161</em>, 112309. (<a href='https://doi.org/10.1016/j.engappai.2025.112309'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of synthetic aperture radar (SAR) automatic target recognition (ATR), the recognition performance of deep learning methods is often constrained by sample scarcity. To address this issue, this paper proposes a frequency-domain-assisted dual-stream attention hierarchical deformable convolutional network (DAHDF-Net). A frequency-domain-assisted dataset construction method is designed to extend the representational diversity of the sample feature space. Then, a parallel input architecture of frequency-space dual-stream features is constructed, and the adaptive dynamic fusion of frequency-domain stream features with spatial-domain stream features is realized by using a channel attention module in the frequency-domain stream. To enhance the expressiveness of the network on the basis of modulated deformation convolution, a hierarchical residual (H-residual) module is designed. Moreover, a triple hybrid loss is proposed to address the issues of high deformation, which makes classification difficult, and the fuzzy decision boundaries between categories. Experiments were conducted on the moving and stationary target acquisition and recognition (MSTAR) dataset and the FUSAR-Ship dataset. Among them, DAHDF-Net achieves recognition accuracies of 99.75 % and 97.48 % on all training sets and 10-way 25-shot under standard operating condition (SOC) of MSTAR, which demonstrated superior recognition accuracy compared to current state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Shanliang Yuan and Hongyuan Gao and Xiaoyuan Gu and Jingya Ma},
  doi          = {10.1016/j.engappai.2025.112309},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112309},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synthetic aperture radar target recognition with limited training data based on frequency-domain-assisted dual-stream attention hierarchical deformable convolutional networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale distance similarity entropy: A novel complexity measurement for gearbox fault diagnosis. <em>EAAI</em>, <em>161</em>, 112308. (<a href='https://doi.org/10.1016/j.engappai.2025.112308'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entropy-based methods have gained increasing attention in fault diagnosis due to their capability in quantifying the intrinsic complexity and dynamic behavior of time series signals. Vibration signals from gearboxes are typically nonlinear, nonstationary, and transient, often spanning multiple time scales, thus requiring robust multi-scale analysis for accurate condition assessment. However, existing multi-scale entropy methods, prone to missing local variations and vulnerable to noise, often yield incomplete features and low diagnostic accuracy with high computational costs. To overcome these challenges, this paper proposes a novel complexity measurement method termed multi-scale distance similarity entropy, which integrates distance similarity entropy with a multi-scale coarse-graining process. By computing element-wise distances and mapping them through a Gaussian kernel function, multi-scale distance similarity entropy captures subtle nonlinear variations in vibration signals while effectively suppressing noise interference. It estimates the similarity distribution between adjacent vectors, enabling sensitive tracking of dynamic complexity changes in mechanical vibration data. Experimental validation on two gearbox datasets encompassing both single and compound faults demonstrates that multi-scale distance similarity entropy achieves superior classification accuracies of 98.63 % and 97.14 %, respectively. The method also shows strong robustness under random impulse noise and low signal-to-noise ratio conditions, along with high computational efficiency, particularly in small-sample scenarios. These characteristics make it highly suitable for online real-time fault diagnosis in complex and noise contaminated industrial environments involving diverse and compound fault patterns.},
  archive      = {J_EAAI},
  author       = {Tao Wang and Shin Yee Khoo and Zhi Chao Ong and Pei Yi Siow and Teng Wang},
  doi          = {10.1016/j.engappai.2025.112308},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112308},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale distance similarity entropy: A novel complexity measurement for gearbox fault diagnosis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JSSM-DTA: Joint sequence-structure modeling with multi-scale transformers for explainable drug-target affinity prediction. <em>EAAI</em>, <em>161</em>, 112303. (<a href='https://doi.org/10.1016/j.engappai.2025.112303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-Target Affinity (DTA) prediction is a pivotal task in drug discovery, aiming to quantify the strength of interactions between drug molecules and their biological targets, such as proteins. Despite significant advancements in deep learning-based methods, several challenges persist. Scale mismatches obstruct functional group-specific representations, leading to suboptimal feature extraction and loss of critical interaction patterns. Additionally, the inability to fully exploit molecular graph structures weakens hierarchical dependency modeling, while ineffective feature fusion hampers the integration of heterogeneous molecular representations, restricting the capture of intricate drug-target interaction dynamics. To address these challenges, this work introduces JSSM-DTA, a novel Joint Sequence-Structure Modeling framework that integrates Multi-Scale Transformers with intermodal feature attention to enhance DTA prediction. JSSM-DTA formulates a unified representation space through the Adaptive Convolutional Transformer (ACT) and the Multi-Scale Diffusion Transformer (MSDT), where ACT refines sequential feature extraction by capturing intricate local dependencies and long-range contextual relationships, while MSDT preserves hierarchical learning, optimizing both global topological organization and fine-grained interactions. Additionally, the Factorized Inter-layer Interaction Module constructs joint embeddings by seamlessly integrating heterogeneous representations, enabling robust feature fusion. The proposed model was evaluated on Davis, KIBA, Metz and BindingDB datasets, demonstrating superior predictive accuracy over state-of-the-art methods. Explainability analysis reveals key molecular substructures and binding interactions, enhancing transparency in decision-making and establishing JSSM-DTA as a benchmark for both accuracy and interpretability in DTA prediction.},
  archive      = {J_EAAI},
  author       = {Uma E. and Mala T.},
  doi          = {10.1016/j.engappai.2025.112303},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112303},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {JSSM-DTA: Joint sequence-structure modeling with multi-scale transformers for explainable drug-target affinity prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyclic translations between pathomics and genomics improve automatic cancer diagnosis from whole slide images. <em>EAAI</em>, <em>161</em>, 112302. (<a href='https://doi.org/10.1016/j.engappai.2025.112302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incorporating genomic characterization into histopathological image modeling brings substantial value to enhancing diagnostic accuracy and supporting the development of targeted and effective treatment strategies. However, prevailing multi-modal integration methods often assume the availability of both pathomics and genomics data in both training and testing phases, overlooking the challenge of data absence due to prohibitive costs. In this paper, we propose a multi-modal cyclic feature generation network (MCFGN) that facilitates cyclic translations between pathomics and genomics to acquire a unified representation of multi-modal data. This approach enables the use of pathological images alone as input to generate joint representations during the testing phase. First, we utilize a general-purpose, self-supervised vision encoder to embed histological image patches as distinctive visual tokens. Next, we hierarchically aggregate patch-level tokens to region-level and slide-level, generating improved whole slide image (WSI) representations. We build self-supervised Masked Autoencoders (MAE) to initialize the hierarchical aggregator. Finally, to incorporate genomic characterization into the learning process, we develop a novel cross-modal cyclic feature generation module to create an intermediate joint representation of pathological and genetic features for patient diagnosis. Evaluations have been conducted on two public datasets from The Cancer Genome Atlas Breast Invasive Carcinoma (TCGA-BRCA) and Non-Small Cell Lung Cancer (TCGA-NSCLC) for various diagnostic tasks, including cancer subtyping and biomarker status prediction. Experiments indicate that our MCFGN model improves predictive performance in cancer diagnosis using histological slides, yielding an 8.7% improvement in area under the curve (AUC) for the cancer subtyping task and a 14.1% gain for biomarker prediction.},
  archive      = {J_EAAI},
  author       = {Xinyu Hao and Hongming Xu and Xiaofeng Wang and Tong Wang and Timo Hamalainen and Fengyu Cong},
  doi          = {10.1016/j.engappai.2025.112302},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112302},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cyclic translations between pathomics and genomics improve automatic cancer diagnosis from whole slide images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multimodal industrial anomaly detection method based on mask training and teacher–student joint memory. <em>EAAI</em>, <em>161</em>, 112299. (<a href='https://doi.org/10.1016/j.engappai.2025.112299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the teacher–student framework has been applied to both single-modality detection and multimodal detection, which realizes anomaly detection based on the feature difference between the teacher model and the student model. However, current multimodal teacher–student models use the same teacher model to extract two-dimensional (2D) image and three-dimensional (3D) point cloud features. The point cloud features extracted by the teacher model pre-trained on images are not the optimal feature representation. To further improve the performance of the teacher–student framework on the multimodal anomaly detection task, this paper proposes M ultimodal T eacher- S tudent J oint M emory ( MTSJM ). MTSJM constructs a teacher–student joint memory bank for each modality, the feature distance between the test sample and the memory bank is used as the anomaly indicator. This distance reflects the feature differences between the test sample and the normal sample at multiple levels, including the teacher–teacher, teacher–student, and student–student levels. Then, this paper proposes a mask-based student model training method. While ensuring that the student learns the feature of normal regions, mask training increases the feature difference of non-normal regions between the student and the teacher. On the MVTec 3D Anomaly Detection (MVTec 3D-AD) dataset, the proposed MTSJM achieves effective anomaly detection performance, reaching 95.7% mean Image-level Area Under the Receiver Operator Curve (I-AUROC) and 97.2% mean Area Under the Per-Region Overlap (AUPRO). In addition, MTSJM achieves 99.3% I-AUROC and 99.6% Pixel-level AUROC (P-AUROC) on a real-world vehicle stamping part task, which further illustrates the applicability of MTSJM on the multimodal anomaly detection task.},
  archive      = {J_EAAI},
  author       = {Yi Liu and Changsheng Zhang and Xingjun Dong and Yufei Yang},
  doi          = {10.1016/j.engappai.2025.112299},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112299},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multimodal industrial anomaly detection method based on mask training and teacher–student joint memory},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuse MetaFormer with convolutional neural networks for three-dimensional model classification. <em>EAAI</em>, <em>161</em>, 112298. (<a href='https://doi.org/10.1016/j.engappai.2025.112298'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimedia technology is widely applied to artificial intelligence and it is key to the performance of artificial intelligence systems, such as computer-aided design system, virtual reality system, the augmented reality system, medical image processing system, and game development system. With the development of multimedia technology, the number of three-dimensional (3D) models in network or database is becoming larger and larger. It is important to classify 3D models. In order to improve accuracy of three-dimensional model classification, a method of 3D model classification fusing MetaFormer with CNN (Convolutional Neural Networks) is proposed. 3D model is projected into two-dimensional (2D) views through the fixed-view projection, and representative views are selected by the clustering algorithm. Points sampled randomly from representative view are used to calculate its shape descriptors. View feature is extracted from representative view by MetaFormer. Shape feature is extracted from shape descriptors of representative view by Convolutional Neural Networks. View feature and shape feature of representative view are fused. At the same time, majority voting algorithm is used to determine category of 3D model based on the fusion of view features and shape features. Experiments are conducted on ModelNet10 dataset. Experimental results show that the proposed method achieves better results than others.},
  archive      = {J_EAAI},
  author       = {Xueyao Gao and Haomin Wu and Chunxiang Zhang and Yongzeng Xue},
  doi          = {10.1016/j.engappai.2025.112298},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112298},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuse MetaFormer with convolutional neural networks for three-dimensional model classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent design of broadband metasurface based on spectrum prediction neural network and transition simulated annealing algorithm. <em>EAAI</em>, <em>161</em>, 112297. (<a href='https://doi.org/10.1016/j.engappai.2025.112297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, metasurfaces have demonstrated considerable potential for application across various fields, including wireless communication, Internet of Things, holographic imaging, and radar systems. With the rapid development of artificial intelligence and its application in other disciplines, metasurface design based on artificial intelligence techniques, particularly deep learning, has attracted widespread attention. In this paper, we propose a novel scheme that integrates deep neural networks with an enhanced simulated annealing algorithm to achieve intelligent design of broadband metasurfaces. Firstly, we construct and train a neural network capable of accurately predicting the amplitude and phase responses of an isotropic metasurface structure, achieving a Mean Absolute Error of 1.36° on the test set. Subsequently, we develop a novel simulated annealing algorithm that is integrated with the prediction neural network to form an intelligent optimization framework. This approach can effectively search for the solution space to accurately achieve arbitrary target phase response, with a very low Mean Squared Error calculated on the test set. Furthermore, we validate the effectiveness of the proposed model and algorithm through a practical application that demonstrates broadband dispersion characteristics within the frequency range of 9–11 Gigahertz (GHz). Additionally, the prediction model can employ transfer learning strategy to adapt to various operating frequency bands, significantly enhancing its generalization capabilities. The proposed intelligent design methodology introduces a novel pathway for rapidly designing metasurface in complex application scenarios, serving as a valuable reference for the engineering design of devices in electronics, optics, and wireless communication.},
  archive      = {J_EAAI},
  author       = {Yin Zhang and Yuxin Dai and Yiyu Fan and Jun Yu},
  doi          = {10.1016/j.engappai.2025.112297},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112297},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent design of broadband metasurface based on spectrum prediction neural network and transition simulated annealing algorithm},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Industrial fabric defect-generative adversarial network (IFD-GAN): High-fidelity fabric cross-scale defect samples synthesis method for enhancing automated recognition performance. <em>EAAI</em>, <em>161</em>, 112296. (<a href='https://doi.org/10.1016/j.engappai.2025.112296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {—High-quality defect samples and datasets are the cornerstone for enhancing the performance of deep learning detection algorithms for fabric defects. Constraints, such as the complexity of fabric textures, the diversity and sporadic occurrence of defects, the insufficient scale, and the significant class imbalance of datasets, impede improvements in detection accuracy and generalization of detection models, thereby limiting industrial application. To address the issues above, a two-stage generative model for fabric defect images called Industrial Fabric Defect-Generative Adversarial Network (IFD-GAN), based on contrastive learning mutual information mechanism, was introduced. The Pixel-level Defect-Background Stripper (DBS) was devised for precise localization, and the Longitude-Latitude Self-Attention Mechanism (LLSA) was proposed to efficiently focus on defect foreground details, facilitating decoupling and efficient extraction of defect features. The combination of the two, along with the structural similarity loss function, collectively regulates the coordination and consistency between defect and background textures. An industrial-grade fabric defect dataset was collected for IFD-GAN training and generative testing. The model's effectiveness in generating defect images was evaluated based on dimensions such as fidelity and diversity. IFD-GAN is used to enhance this dataset, and the system compared the performance of advanced object detection models trained on the datasets before and after the enhancement. Extensive experimental results show that IFD-GAN can accomplish high-fidelity generation of high-resolution cross-scale fabric defect images in an unsupervised environment, significantly contributing to the creation of more balanced and diverse large-scale industrial fabric defect datasets and the enhancement of defect detection networks in precision, robustness, and generalizability.},
  archive      = {J_EAAI},
  author       = {Shun Xu and Sheng Cheng and Shuyang Jin and Xudong Hu and Weitao Wu and Zhong Xiang},
  doi          = {10.1016/j.engappai.2025.112296},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112296},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Industrial fabric defect-generative adversarial network (IFD-GAN): High-fidelity fabric cross-scale defect samples synthesis method for enhancing automated recognition performance},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample-efficient planning-control framework for autonomous underwater vehicle docking using lightweight cross Q-learning. <em>EAAI</em>, <em>161</em>, 112293. (<a href='https://doi.org/10.1016/j.engappai.2025.112293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous Underwater Vehicles (AUVs) are essential for long-duration missions in underwater sensor networks, but their operation is constrained by limited onboard energy and low-bandwidth communication. Docking stations are deployed to support energy replenishment and data transfer, requiring AUVs to autonomously plan return trajectories and achieve precise docking. Traditional motion planning and control methods for AUV docking often decouple global motion planning from local control or rely on accurate dynamics models, while existing deep reinforcement learning (DRL) approaches frequently neglect sample efficiency. This work presents a novel DRL framework that tightly integrates motion planning and control while emphasizing sample efficiency to enable reliable and efficient AUV docking. The docking task is formulated as an Markov Decision Process (MDP), in which a structured reward function is defined to guide the agent towards goal-directed behavior in an interpretable and sample-efficient manner. A lightweight Cross Q-Learning (CrossQ-Lite) algorithm is developed by removing target networks and incorporating batch normalization, achieving stable learning with approximately 92.8% fewer parameters while maintaining comparable performance. Simulation results demonstrate that, under the proposed MDP formulation, CrossQ-Lite achieves a minimum of 1 . 39 × higher sample efficiency and improved training stability compared to state-of-the-art DRL baselines. The trained model reliably completes AUV docking tasks, providing a practical and high-performance solution for autonomous underwater sensor networks.},
  archive      = {J_EAAI},
  author       = {Kaixin Zhang and Yuelong Xu and Minghao Zhao and Yu Jiang},
  doi          = {10.1016/j.engappai.2025.112293},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112293},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sample-efficient planning-control framework for autonomous underwater vehicle docking using lightweight cross Q-learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault diagnosis of wind turbine based on dual-channel feature aggregation network with attentional mechanism. <em>EAAI</em>, <em>161</em>, 112291. (<a href='https://doi.org/10.1016/j.engappai.2025.112291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind turbines are subjected to alternating stresses and shock loads during operation, and the collected vibration signals are nonlinear, non-stationary and contain noise, resulting in subtle fault features that are difficult to extract. In order to extract discriminative features from vibration signals under variable speed operating conditions, a dual-channel feature aggregation network (DCNet) with attention mechanism is developed in this paper. First, a Parallel Patch-Aware Convolutional Module (PPCM) is constructed to extract feature information of different scales and levels from Time–Frequency Representations (TFR). Specifically, convolutional operations are performed in both the spatial and frequency domains, endowing it with local–global capturing capabilities and efficiency. Then, to improve the network operation rate, Haar Wavelet Downsampling (HWD) is embedded into the DCNet architecture. The core idea is to reduce the spatial resolution of features through Haar wavelet transform while preserving as many discriminative features as possible. Additionally, Channel Prior Convolutional Attention (CPCA) is introduced to enable DCNet to focus on more critical feature parts by dynamically allocating channel and spatial attention weights, thereby suppressing redundant feature interference. Finally, in the Deep Feature Fusion Module (DFFM), a cross-attention mechanism is adopted for global interaction, fusing features from different channels to achieve feature enhancement. To obtain good diagnostic results under variable speed conditions, we apply a label smoothing algorithm to assist model training. The experimental results show that the proposed model has high diagnostic accuracy, can generalize effectively, and it still maintains high diagnostic accuracy under noise and variable speed working conditions.},
  archive      = {J_EAAI},
  author       = {Haiyu Guo and Xingzheng Guo and Xiaoguang Zhang and Fanfan Lu and Chuang Liang},
  doi          = {10.1016/j.engappai.2025.112291},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112291},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis of wind turbine based on dual-channel feature aggregation network with attentional mechanism},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new deep learning framework for intelligent aerial monitoring of power transmission line insulators. <em>EAAI</em>, <em>161</em>, 112290. (<a href='https://doi.org/10.1016/j.engappai.2025.112290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transmission line insulators are critical components for maintaining the integrity and efficiency of power transmission lines. Monitoring the health, performance, and efficiency of this network has always been of interest since the past. Traditional and field inspection methods are often tedious, costly, and prone to human error. In order to monitor the condition of transmission lines and overcome traditional challenges, this study proposes an intelligent monitoring framework using unmanned aerial vehicle (UAV) imaging and advanced deep learning models to identify and classify insulator defects. The dataset used in this study consists of 870 original images, 600 healthy images, 140 damaged images, and 130 images of flashover insulators collected from UAV flights and online sources. To increase the diversity of the training data, a data augmentation technique was used, increasing the number of images to 1952 samples and dividing the data into 80 % training sets and 20 % test sets. While the current evaluation is performed on this dataset, real-world experiments will be considered in future studies to further validate the model. In this approach, three scenarios were considered to evaluate and detect these errors. The first scenario used an independent convolutional neural network (CNN) for feature extraction and classification, achieving an accuracy of 82.54 %. The second scenario combined CNN with transfer learning (TL) techniques to improve feature representation, achieving an accuracy of 95.99 %. Scenario Three integrated a hybrid CNN model with a long short-term memory network, achieving an average accuracy of 99.67 % in fault detection and classification. The results demonstrate the superiority and robustness of the proposed hybrid model, providing a reliable and cost-effective solution for transmission line insulator monitoring. This study highlights the significant potential of combining UAV imagery with deep learning algorithms, reassuring the audience of the effectiveness of the proposed solution.},
  archive      = {J_EAAI},
  author       = {Reza Rahimi Nejadbougar and Ebadat Ghanbari Parmehr and Alireza Afary and Samira Mavaddati},
  doi          = {10.1016/j.engappai.2025.112290},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112290},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new deep learning framework for intelligent aerial monitoring of power transmission line insulators},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal generative network based on deep long short-term memory autoencoder for hand skeleton data sequences reconstruction and recognition. <em>EAAI</em>, <em>161</em>, 112289. (<a href='https://doi.org/10.1016/j.engappai.2025.112289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks attract the highest research focus in the developing field of Hand Gesture Recognition (HGR). Nevertheless, these approaches presented a challenging task in adapting to time-series data. In skeleton-based HGR, extracting spatial–temporal information remains a challenge. In recent times, recurrent neural networks have exhibited exceptional performance in detecting desired hand gestures by processing of varied length time-series data. Although they outperform traditional methods when huge training data is accessible, their effectiveness significantly diminishes when data availability is constrained. In this study, we introduce an unsupervised data augmentation network known as the Spatial-Temporal Generative Network (STGN), which reconstructs both the spatial and temporal information of the input sequences by leveraging a Deep Long Short-Term Memory Auto-Encoder (DLSTM-AE) network. Consequently, the DLSTM-AE combined with different Long Short-Term Memory (LSTM) network variations, forming an integrated network that can be trained end-to-end for HGR. Through experimentation conducted on the LeapGestureDB dataset (Leap Motion-based Gesture Dataset) and RIT dataset (Rochester Institute of Technology Hand Gesture Dataset), we prove that data reconstruction using STGN had a prominent effect on improving the accuracy of recognizing time-series based hand gestures. For all experiments, the best recognition results are achieved in the augmented dataset. Accuracies were improved on all tested LSTM networks from 2 to 10%. For reproducible research, the code is available at: https://github.com/AMEURsafa/STGN .},
  archive      = {J_EAAI},
  author       = {Safa Ameur and Mohamed Ali Mahjoub and Anouar Ben Khalifa},
  doi          = {10.1016/j.engappai.2025.112289},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112289},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spatial-temporal generative network based on deep long short-term memory autoencoder for hand skeleton data sequences reconstruction and recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural dynamic fluid reconstruction technique for four-dimensional imaging of combustion flame based on deep learning. <em>EAAI</em>, <em>161</em>, 112288. (<a href='https://doi.org/10.1016/j.engappai.2025.112288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional optical diagnostic techniques based on the principles of tomographic imaging enable the acquisition of rich three-dimensional information in experimental flow fields through reconstruction calculations. However, for tasks involving the reconstruction of three-dimensional flow fields at high temporal resolutions, existing methods incur high computational costs, low reconstruction efficiency, and struggle to achieve high spatiotemporal resolution measurements. This paper proposes the Neural Dynamic Fluid Reconstruction Technique (NDFRT) based on deep learning. NDFRT incorporates the time dimension into the reconstruction scope to achieve the four-dimensional reconstruction of dynamic flow fields using neural networks. NDFRT has the following technical advantages: (1) ultra-high spatiotemporal reconstruction resolution; (2) good computational efficiency, with the reconstruction parameter scale only half that of traditional voxel-based methods; (3) the ability to perform three-dimensional frame prediction of dynamic fluids. We validated the proposed method using numerical simulation and experimental jet flame reconstruction and compared it with the traditional algebraic reconstruction technique (ART). Experimental results demonstrate that NDFRT outperforms traditional ART methods in terms of computational efficiency, reconstruction resolution, and reconstruction accuracy.},
  archive      = {J_EAAI},
  author       = {Fuhao Zhang and Zhiyin Ma and Can Gao and Gang Xun and Qingchun Lei and Xuesong Li},
  doi          = {10.1016/j.engappai.2025.112288},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112288},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural dynamic fluid reconstruction technique for four-dimensional imaging of combustion flame based on deep learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BeltDiff: Diffusion-based self-labeled generation system for conveyor belt damage detection. <em>EAAI</em>, <em>161</em>, 112287. (<a href='https://doi.org/10.1016/j.engappai.2025.112287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The damages of conveyor belt are abnormal occurrence of industrial production line, generally resulting in serious economic losses. While utilizing deep-learning-based methods in belt damage detection task, models training is challenging due to the prevalent scarcity of both numbers and diversity in dataset, leading to the restricted performance and limited accuracy in practical applications. To address this issue, we propose a novel self-labeled generation system based on diffusion model, for creating effective and large-scale conveyor belt detection datasets. Specifically, the training of our system is divided into three stages for progressive task decomposition and interpretable user control. Among the generation process, we focus on the textual prompt alignment and shape guidance to generate more reasonable and high-quality damaged belt images. Meanwhile, larger scale datasets are created via our method on two scenes, including base scene with limited samples, and brand new scenes with no damaged samples, which compose 9636 and 7500 images respectively. By evaluating the quality of damaged images, and the relations between generated and real images, our method demonstrates its effectiveness on generating damaged belt image pairs with annotations. Further, for verifying the validity of our generative datasets, we implement numerous experiments of 4 types of popular detection models training on different settings. The results demonstrate that our datasets support effective accuracy improvement, comparing with the base datasets and the classic augmented datasets, specifically increased by up to 14.4% in the brand new scenes with no damaged samples.},
  archive      = {J_EAAI},
  author       = {Peixian Zhuang and Yuanxiu Cai and Xi Liu and Xianchao Zheng and Fuheng Xiao and Jiangyun Li},
  doi          = {10.1016/j.engappai.2025.112287},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112287},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {BeltDiff: Diffusion-based self-labeled generation system for conveyor belt damage detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust deep learning based model for denoising phonocardiogram signals in clinical environments. <em>EAAI</em>, <em>161</em>, 112286. (<a href='https://doi.org/10.1016/j.engappai.2025.112286'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A cardiac auscultation, being a very popular first line cardiovascular diseases screening method, typically produces phonocardiogram signals contaminated by background sounds, e.g., speech and movement of other patients and doctors/nurses, phone ringing and door knocking/opening/closing, and internal physiological body noises, e.g., lung sounds, muscle contraction and motion artifacts, as it is usually done in a noisy environment and it is not possible to suppress all the internal physiological body noises. So, a quality of the recording is finally decreased. Moreover, this can strongly affect a subsequent analysis/classification of the captured recording and can also lead to its incorrect classification. In this paper, we propose a novel deep convolutional architecture that integrates the bidirectional long short-term memory layers with the transformer blocks involving multi-head attention mechanism, which is particularly designed for denoising phonocardiogram signals. The performance of the proposed artificial intelligence-based approach is evaluated through synthetic data generated by using one public phonocardiogram dataset and two public real-world hospital ambient/respiratory sound databases as well as by deploying two public and renowned real-world clinical environment datasets containing phonocardiogram signals contaminated by various environmental and physiological noises recorded during the clinical auscultations. The deployed complex evaluation strategy assures a higher robustness and generalizability of the proposed approach. As also a result of that, the proposed model outperforms the current state-of-the-art approaches and provides the significant improvements in all the assessed signal quality and noise suppression metrics and over all the involved benchmark datasets. Finally, it should be noted here that the model achieved an average estimated SNR of 14.984 dB and 11.924 dB for the PASCAL and CirCor22 dataset respectively, which represent the renowned real-world clinical environment datasets.},
  archive      = {J_EAAI},
  author       = {Maros Jakubec and Eva Lieskovska and Peter Pocta},
  doi          = {10.1016/j.engappai.2025.112286},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112286},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust deep learning based model for denoising phonocardiogram signals in clinical environments},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based end-to-end point restoration network for filtering temporarily-static objects from point cloud. <em>EAAI</em>, <em>161</em>, 112284. (<a href='https://doi.org/10.1016/j.engappai.2025.112284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precision of map-based localization systems is pivotal for advanced navigation and autonomous vehicle technologies. This study addresses the challenge of dynamic environments where temporarily-static objects, such as vehicles, introduce occlusion and temporal alterations to the mapping landscape, leading to inaccuracies in mapping and localization. We propose a transformer-based deep learning model that removes temporarily-static objects and refines occluded areas in raw point cloud data, thereby enhancing both mapping and localization. Our method leverages a transformer-based point restoration network trained on a novel dataset that does not require human-driven manual annotation and predicts point clouds free of temporarily-static objects. The approach was validated through experiments demonstrating improved qualitative and quantitative results. The results display the importance of our method by removing temporarily-static objects and refining occluded areas. The proposed method achieves a 26.4 % reduction in Chamfer Distance L1 (CD-L1), 33.1 % reduction in Chamfer Distance L2 (CD-L2), and a 30.2 % relative improvement in the harmonic mean of precision and recall (F-Score) over the baseline network, demonstrating significantly enhanced model for filtering. This research contributes to artificial intelligence (AI)-enabled autonomous navigation by offering a systematic solution to a common problem in dynamic environments, setting a new filtering technology for mapping systems.},
  archive      = {J_EAAI},
  author       = {Sabir Hossain and Xianke Lin},
  doi          = {10.1016/j.engappai.2025.112284},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112284},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer-based end-to-end point restoration network for filtering temporarily-static objects from point cloud},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-view gait recognition based on discriminative global–local feature representation and learning. <em>EAAI</em>, <em>161</em>, 112282. (<a href='https://doi.org/10.1016/j.engappai.2025.112282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance of gait recognition can be heavily influenced by deformation of walking silhouettes due to variations of view angle. Cross-view gait recognition is still one of the most challenging problems in pattern recognition community. In this paper, we propose a new cross-view gait recognition algorithm by discriminative global–local feature representation and learning. First, we design cross-view convolutional neural network for learning global gait feature representations underlying binary walking silhouettes sequences. Second, we propose to extract local gait features by partial spatial–temporal sequence and local feature extractors, which can represent the motion characteristics and temporal changes of different human body parts. Both global and local features in our proposed method are extracted from different gait representations to provide spatial–temporal information from diverse aspects, and they are fused on feature level to further reduce the sensitivity to variations of view angle and improve the performance of gait recognition. Finally, we introduce deep metric learning framework and propose a robust, effective, and view-related loss function, named view triplet loss function, to learn discriminative gait features. Compared with triplet loss, the proposed loss function explores hierarchical relationship of the variations of view angles, which achieves better intra-subject compactness and inter-subject separability. Experimental results on CASIA-B, OULP and OUMVLP gait datasets demonstrate the feasibility and advantage of our proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Muqing Deng and Yi Zou and Zhi Zeng and Xiaoreng Feng and Yanjiao Wang and Yuan Liu},
  doi          = {10.1016/j.engappai.2025.112282},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112282},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cross-view gait recognition based on discriminative global–local feature representation and learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel clustering-ensemble learning model for day-ahead photovoltaic power forecasting. <em>EAAI</em>, <em>161</em>, 112281. (<a href='https://doi.org/10.1016/j.engappai.2025.112281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate day-ahead photovoltaic power forecasting (PPF) is essential for grid scheduling and transaction planning. However, time series prediction models based on historical meteorological and photovoltaic power data often struggle to capture long-term dependencies. Existing research typically employs multivariate regression models to establish mapping relationships between numerical weather prediction (NWP) and photovoltaic power data, yet still exhibits deficiencies in weather pattern recognition and consideration of temporal patterns. Therefore, this paper proposes a novel clustering-ensemble learning model to enhance predictive performance. In the proposed deep time-series clustering algorithm, key features from NWP data are extracted for clustering, addressing the inefficiencies of traditional clustering methods in handling high-dimensional data. A weighted Warp-Euclidean distance is proposed to capture sequence trend homogeneity and spatial similarity, overcoming the limitations of Euclidean distance in time-series data. The ensemble learning model combines the advantages of two gradient boosting tree models to handle nonlinear features and high-dimensional data, while introducing lag features to enhance temporal dynamic learning capability. This approach enhances the stability and mitigates the limitations associated with relying primarily on weather-related features. This study utilizes NWP and measured photovoltaic data from two stations in Hebei Province, China. Results demonstrate superior performance compared to other clustering algorithms and prediction models in day-ahead PPF tasks, achieving R 2 scores of 0.952 and 0.943 on two public photovoltaic datasets, representing improvements of 0.020 and 0.017 over optimal benchmark models. The proposed framework provides theoretical guidance for the stable operation of grid-connected photovoltaic systems.},
  archive      = {J_EAAI},
  author       = {Feifei Yang and Xueqian Fu and Zhengshuo Li and Dawei Qiu and Hamed Badihi},
  doi          = {10.1016/j.engappai.2025.112281},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112281},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel clustering-ensemble learning model for day-ahead photovoltaic power forecasting},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence-based phonocardiogram signal classification using segment-specific multi-domain features for cardiovascular and arterial disease. <em>EAAI</em>, <em>161</em>, 112280. (<a href='https://doi.org/10.1016/j.engappai.2025.112280'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart diseases are the leading cause of death globally, and early diagnosis coupled with timely treatment can save lives. The human heart produces sounds that reflect the functions of its valves and chambers, with murmurs often indicating abnormal heart behavior. The phonocardiogram (PCG) analysis offers a quick, easy, and affordable diagnostic method for detecting such conditions. The PhysioNet/2016 dataset, containing annotated heart sound recordings, has advanced automated heart sound classification research. Despite the dataset encompassing nine classes of heart diseases, it has primarily been used for binary classification tasks. Multi-class classification is challenging due to overlapping acoustic features among certain heart conditions and signal variability. To address these issues, we implemented segment specific feature extraction across six domains — time, frequency, amplitude, wavelet, spectrum, signal processing — and evaluated various machine learning classifiers. Our findings revealed that the Random Forest classifier outperformed others, leading us to integrate it into our model. On the testing dataset, it attained 94% accuracy, 93% sensitivity and 93% specificity for binary classification Our model achieved 89% accuracy, 80% sensitivity and 98% specificity for nine-class classification including both valve diseases and artery-related conditions.},
  archive      = {J_EAAI},
  author       = {Syeda Sana Bukhari and Shahab U. Ansari and Khurram Khan Jadoon and Raja Hashim Ali},
  doi          = {10.1016/j.engappai.2025.112280},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112280},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial intelligence-based phonocardiogram signal classification using segment-specific multi-domain features for cardiovascular and arterial disease},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic forecasting of non-ferrous metal prices based on outlier treatment algorithms, quantile regression based deep learning and two-phase multi-objective optimization. <em>EAAI</em>, <em>161</em>, 112277. (<a href='https://doi.org/10.1016/j.engappai.2025.112277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of non-ferrous metal prices plays a crucial role in helping enterprises optimize production, control costs, and manage risks, as well as in enabling countries and industries to formulate resource strategies, ensure economic security, and promote sustainable development. However, existing research still has limitations in outlier detection, uncertainty analysis, and model optimization, making it difficult to meet the forecasting needs in complex market environments. To fill these gaps, this study proposes a novel combined probabilistic forecasting framework for non-ferrous metal prices. First, this study utilizes outlier treatment algorithms to achieve robust outlier detection and correction. Second, multiple quantile regression-based deep learning models are established for probabilistic forecasting. Subsequently, a two-phase multi-objective optimization strategy is proposed. Specifically, the first phase is designed to optimize the upper quantile half-interval and lower quantile half-interval of each quantile regression-based deep learning model, while the second phase is used to optimize the combined weights of the aforementioned single model to synergistically enhance interval reliability and prediction accuracy. Finally, silver and aluminum futures prices are used as illustrative case studies. The experimental results show that the proposed model outperforms the benchmark method in terms of interval coverage and prediction accuracy. This study provides a scientific basis and reference for industrial production optimization, investment decision-making and resource management planning.},
  archive      = {J_EAAI},
  author       = {Pei Du and Fangrui Gui and Lijie Shan and Qianyi Xing and Jianzhou Wang},
  doi          = {10.1016/j.engappai.2025.112277},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112277},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probabilistic forecasting of non-ferrous metal prices based on outlier treatment algorithms, quantile regression based deep learning and two-phase multi-objective optimization},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying nonlinear roll damping and restoring parameters via physics-informed neural network. <em>EAAI</em>, <em>161</em>, 112275. (<a href='https://doi.org/10.1016/j.engappai.2025.112275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To effectively characterize a ship’s roll motion, developing a robust dynamic model that incorporates accurate damping and restoring parameters is essential. Given that only limited free-decay measurements have been measured, an efficient physics-informed neural network-based approach has been developed to simultaneously determine the nonlinear damping and restoring parameters associated with ship rolling. Rather than relying on a large dataset to train a neural network for parameter identification, the proposed method incorporates the physical equations of roll motion into the residual networks, ensuring that the identified parameters adhere to their physical interpretation. Three numerical cases, encompassing computational fluid dynamics (CFD) analyses, and laboratory experiments, are presented to show the superior performance of the developed method. Key findings indicate that the proposed method effectively identifies the investigated parameters with high precision while maintaining consistent performance across various initial roll angle conditions. Compared to traditional methods, the proposed approach offers significant advantages, including reduced reliance on large datasets, automated parameter identification without manual tuning, and the ability to incorporate physical constraints directly into the learning process. These features make the method particularly suitable for real-world applications where data is sparse or costly to obtain.},
  archive      = {J_EAAI},
  author       = {Shuai Cong and Jinwei Sun and Qianying Cao and Changhong Zhi and Shixuan Liu},
  doi          = {10.1016/j.engappai.2025.112275},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112275},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identifying nonlinear roll damping and restoring parameters via physics-informed neural network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection in offshore open radio access network using long short-term memory models on a novel artificial intelligence-driven cloud-native data platform. <em>EAAI</em>, <em>161</em>, 112274. (<a href='https://doi.org/10.1016/j.engappai.2025.112274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Radio Access Network (RAN) is a critical component of modern telecommunications infrastructure, currently evolving towards disaggregated and open architectures. These advancements are pivotal for integrating intelligent, data-driven applications aimed at enhancing network reliability and operational autonomy through the introduction of cognitive capabilities, as exemplified by the emerging Open Radio Access Network (O-RAN) standards. Despite its potential, the nascent nature of O-RAN technology presents challenges, primarily due to the absence of mature operational standards. This complicates the management of data and intelligent applications, particularly when integrating with traditional network management and operational support systems. Divergent vendor-specific design approaches further hinder migration and limit solution reusability. These challenges are compounded by a skills gap in telecommunications business-oriented engineering, which remains a key barrier to effective O-RAN deployment and intelligent application development. To address these challenges, Boldyn Networks developed a novel cloud-native data analytics platform, specifically designed to support scalable Artificial Intelligence (AI) integration within O-RAN deployments. This platform underwent rigorous testing in real-world scenarios, and applied advanced AI techniques to improve operational efficiency and customer experience. Implementation involved adopting Development Operations (DevOps) practices, leveraging data lakehouse architectures tailored for AI applications, and employing sophisticated data engineering strategies. The platform successfully addresses connectivity challenges inherent in real-world offshore wind farm deployments using Long Short-Term Memory (LSTM) models for anomaly detection in network connectivity. After integrating the LSTM models into the network control, more than 90 percent of connectivity issues were reduced in runtime. This marks a step toward autonomous, self-organizing, and self-healing networks.},
  archive      = {J_EAAI},
  author       = {Abdelrahim Ahmad and Peizheng Li and Robert Piechocki and Rui Inacio},
  doi          = {10.1016/j.engappai.2025.112274},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112274},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Anomaly detection in offshore open radio access network using long short-term memory models on a novel artificial intelligence-driven cloud-native data platform},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural design through reinforcement learning. <em>EAAI</em>, <em>161</em>, 112273. (<a href='https://doi.org/10.1016/j.engappai.2025.112273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Structural Optimization gym (SOgym), a novel open-source Reinforcement Learning (RL) environment designed to advance machine learning in Topology Optimization (TO). SOgym enables RL agents to generate physically viable and structurally robust designs by integrating the physics of TO into the reward function. To enhance scalability, SOgym leverages feature-mapping methods as a mesh-independent interface between the environment and the agent, allowing efficient interaction with the design variables regardless of mesh resolution. Baseline results use a model-free Proximal Policy Optimization agent and a model-based DreamerV3 agent. Three observation space configurations were tested. The Topology Optimization game ( TopOpt game) inspired configuration, an interactive educational tool for designing structures to minimize compliance under volume constraints, performed best in terms of performance and sample efficiency. The 100 million parameter DreamerV3 model (DreamerV3-100M) produced structures with compliance values approximately 54 % higher than those from traditional optimization methods and a 0 % disconnection rate, an improvement over supervised learning approaches that often struggle with disconnected load paths. When comparing the learning rates of the agents to those of engineering students from the TopOpt game experiment, the DreamerV3-100M model shows a learning rate approximately four orders of magnitude lower, an impressive feat for a policy trained from scratch through trial and error. These results suggest RL's potential to solve continuous TO problems and its capacity to explore and learn from diverse design solutions. SOgym provides a platform for developing RL agents for structural design challenges and is publicly available to support research in the field.},
  archive      = {J_EAAI},
  author       = {Thomas Rochefort-Beaudoin and Aurelian Vadean and Niels Aage and Sofiane Achiche},
  doi          = {10.1016/j.engappai.2025.112273},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112273},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Structural design through reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-channel selection for epileptic seizure identification through a custom machine learning model. <em>EAAI</em>, <em>161</em>, 112272. (<a href='https://doi.org/10.1016/j.engappai.2025.112272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy affects millions of people worldwide, triggering undesirable motor and sensory events that drastically impair the quality of life of those affected. Detecting this condition through a monitoring system can be extremely useful in identifying epileptic seizures without relying exclusively on a specialist. Our goal is to identify these seizures using personalized supervised machine learning models – eXtreme Gradient Boosting – for each patient, employing only one electroencephalogram input channel. Our methodology explores the relationship between the selected input channel and the topographic location of epileptic seizures modeled for the patient. The results revealed notable accuracy performances for the three patients investigated: 100%, 99%, and 88%, after applying the proposed time filter that checks for the presence/absence of a seizure every 3 s. Furthermore, it was possible to observe that the results are consistent with the affected area in each patient, demonstrating the effectiveness of the method in selecting the single channel. This approach demonstrates the feasibility of detecting convulsive seizures using only one input channel and underscores the need to extend the methodology to more patients.},
  archive      = {J_EAAI},
  author       = {Jusciaane Chacon Vieira and Ignacio Sanchez-Gendriz and Luiz Affonso Guedes},
  doi          = {10.1016/j.engappai.2025.112272},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112272},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Single-channel selection for epileptic seizure identification through a custom machine learning model},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IMobileTransformer: A fusion-based lightweight model for rice disease identification. <em>EAAI</em>, <em>161</em>, 112271. (<a href='https://doi.org/10.1016/j.engappai.2025.112271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rice blast, sheath blight, leaf scald, bacterial leaf blight, and brown spot severely threaten rice yield. To address the limitations of current deep learning methods in rice disease recognition, particularly their insufficient integration of local and global features, this study proposes an Improved MobileTransformer (IMobileTransformer) model. The proposed architecture synergistically combines MobileNet’s strengths in local feature extraction and lightweight architecture with Transformer’s superior capability in global information processing. Specifically, the model is designed with three functional branches: a) a MobileNet branch utilizing inverted residual structure with depthwise separable convolution layers to reduce parameters and computational complexity, b) a Transformer branch modified from Swin-Transformer architecture, where the Multilayer Perceptron (MLP) layer is enhanced by splitting input feature channels through an Inception-based structure to maintain global feature extraction efficiency while minimizing computational overhead, and c) a feature fusion branch that concatenates reshaped outputs from both branches through channel-wise stacking, enabling effective integration of local and global representations. Experimental results show that compared to classical models such as MobileNetV3-Large, EfficientNet-B0, Vision Transformer Base/16 (ViT-B/16), Shifted Window Transformer (Swin-Transformer), Tiny Vision Transformer (TinyViT), Mobile Vision Transformer (MobileViT), LocalViT-S, IMobileTransformer achieves a recognition accuracy of 99.62% for rice diseases, with improvements of 1.71%, 0.91%, 38.09%, 4.17%, 1.99%, 1.5% and 0.42%, respectively, providing an effective solution for rice disease recognition.},
  archive      = {J_EAAI},
  author       = {Yang Lu and Haoyang Zhou and Peng Wang and Erzhi Wang and Gongfa Li and Tongjian Yu},
  doi          = {10.1016/j.engappai.2025.112271},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112271},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IMobileTransformer: A fusion-based lightweight model for rice disease identification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized and safe medication recommendation based on convolutional neural network and transformer architecture. <em>EAAI</em>, <em>161</em>, 112267. (<a href='https://doi.org/10.1016/j.engappai.2025.112267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the accumulation of electronic health records (EHRs), artificial intelligence (AI) based medical services such as medication recommendation (MR) has aroused widespread concern. However, existing drug recommendation models suffer from inadequate patient representation and adverse drug–drug interactions (DDIs). To address these challenges, we propose an AI-based personalized and safe medication recommendation method based on convolutional neural network and transformer architecture (CT-PASMR). Specifically, convolutional neural network (CNN) and transformer are combined in parallel (CAT) to model local relationships in a patient’s single visit and long-term dependencies in sequential EHR data, respectively. Subsequently, graph attention networks (GATs) are deployed to capture drug co-occurrences and adverse DDIs with various weights, generating safe drug representations. Moreover, a joint loss function is introduced to balance accuracy and safety in CT-PASMR. Finally, the experimental results on MIMIC (Medical Information Mart for Intensive Care)-III and MIMIC-IV datasets demonstrate that CT-PASMR achieves competitive performance on seven evaluation metrics such as DDI rate, Jaccard index and F1 score, compared with nine state-of-the-art (SOTA) baseline models. Ultimately, ablation studies and further analysis confirm the efficacy of CATs and GATs in providing personalized and safe medication recommendations. Code, qualitative results, and trained weights will be available at the link: https://github.com/gefengru/CT-PASMR .},
  archive      = {J_EAAI},
  author       = {Fengru Ge and Xiaomei Yu and Xue Li and Xingxu Fan and Yanjie Zhao},
  doi          = {10.1016/j.engappai.2025.112267},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112267},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Personalized and safe medication recommendation based on convolutional neural network and transformer architecture},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning with similarity enhancement for dimensionality reduction. <em>EAAI</em>, <em>161</em>, 112266. (<a href='https://doi.org/10.1016/j.engappai.2025.112266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensionality reduction aims to reduce the number of dimensions while preserving crucial information. As a self-supervised learning approach, contrastive learning provides a novel perspective for dimensionality reduction. However, most contrastive learning methods focus on optimizing similarity, which have limitations in reducing feature redundancy. Moreover, the dependence on negative pairs introduces computational overhead. To address these problems, we propose Contrastive Learning with Similarity Enhancement for Dimensionality Reduction (CLSDR), which integrates neighborhood embedding into the contrastive learning framework. Specifically, CLSDR uses k -nearest neighbors sampling to construct positive pairs. We design a multi-level loss function that captures the diversity of data while maintaining the consistency of local and global features. In addition, we propose a nonlinear similarity optimization mechanism based on logarithmic smoothing, which adjusts the gradient of similarity loss, improving the stability during the training process. Experimental results demonstrate that CLSDR significantly outperforms several state-of-the-art methods. Especially, on the Street View House Numbers dataset, CLSDR achieves 66.7% and 62.3% Top-1 accuracy with two classifiers in 64-dimensional embedding space, which have 10.6% and 38.4% improvement over the best competing approach. Thus, CLSDR exhibits strong robustness and scalability across different dimensions.},
  archive      = {J_EAAI},
  author       = {Qi Yang and Changpeng Wang and Linlin Feng and Lizhen Ji and Jiangshe Zhang},
  doi          = {10.1016/j.engappai.2025.112266},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112266},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contrastive learning with similarity enhancement for dimensionality reduction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-modal approach for detecting drivers’ distraction using bio-signal and vision sensor fusion in driver monitoring systems. <em>EAAI</em>, <em>161</em>, 112265. (<a href='https://doi.org/10.1016/j.engappai.2025.112265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to a report by the World Health Organization (WHO), approximately 1.3 million people lose their lives annually owing to traffic accidents. The majority of road traffic accidents stem from driver negligence. Recently, there has been a growing interest in utilizing deep learning and machine learning technologies to enhance the safety and efficiency of road traffic, with the aim of addressing issues arising from driver inattentiveness. Most studies focus on detecting abnormal driver behavior using driving sensors or driver images; however, they often overlook physiological factors such as the driver's bio-signals. Considering that the driver's state, including fatigue, stress, and concentration, can significantly affect driving safety, it is crucial to build models that consider biometric information. Therefore, this study proposes a multi-modal transformer model called Bio-Vision Transformer (BiViT) that comprehensively considers both driver bio-signals and images. The BiViT model uses a vision transformer to extract features from driver images and employs a time-series transformer to capture features from the driver's bio-signals. In addition, the interactions between the extracted features are modeled, and the joint fusion method is employed as the feature-fusion approach. To validate the proposed model, performance comparisons and analyses were conducted using commonly used models in image analysis. The experimental results demonstrated that the proposed BiViT model exhibited high performance, with an accuracy of 0.91 and a harmonic mean of precision and recall (F1-score) of 0.91, surpassing the performance of the comparison models.},
  archive      = {J_EAAI},
  author       = {Byeongjoon Noh and Myeongseok Park and Yechan Han and Jaeyun Kim},
  doi          = {10.1016/j.engappai.2025.112265},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112265},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-modal approach for detecting drivers’ distraction using bio-signal and vision sensor fusion in driver monitoring systems},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural network with generative adversarial training for node classification on class imbalanced data. <em>EAAI</em>, <em>161</em>, 112264. (<a href='https://doi.org/10.1016/j.engappai.2025.112264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Node classification in class-imbalanced graph data remains a critical challenge, as traditional graph neural networks (GNNs) either assume class-balanced graph structures or inadequately address class imbalance. This often results in predictive bias, where majority classes are favored while minority classes are underrepresented. To overcome this limitation, this study introduces a novel graph neural network with generative adversarial training (GNN-GAN), where the GNN extracts latent features from input node attributes balanced through data synthesis using a conditional generative adversarial network (GAN) and data fusion strategy. The GNN and GAN are trained synchronously to ensure GAN synthesizes samples that match real data distribution, while GNN adjusts to the quality of synthesized data in a timely manner. A data fusion strategy combines synthetic and real samples to mitigate class imbalance and maintain classification accuracy. Experiments on several benchmark graph datasets demonstrate that the GNN-GAN consistently outperforms state-of-the-art baselines. A comprehensive ablative study further validates the advantages of the synchronized training procedure, offering insights into the model's robustness across graph datasets with varying structures and imbalance ratios.},
  archive      = {J_EAAI},
  author       = {Xiaoqi Zhou and Peixin Shi},
  doi          = {10.1016/j.engappai.2025.112264},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112264},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph neural network with generative adversarial training for node classification on class imbalanced data},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-based feature absorption approach for improving lightweight object detectors in adverse weather conditions. <em>EAAI</em>, <em>161</em>, 112263. (<a href='https://doi.org/10.1016/j.engappai.2025.112263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although cutting-edge lightweight detectors have achieved desirable performance in favorable weather conditions, they again failed to accurately identify objects within low-quality scenes captured in inclement environments, especially during rainy nighttime. These detectors face difficulties learning beneficial information for detection because objects are obscured by rain and low-light conditions. To address the aforementioned challenges, we introduce an innovative and effective Diffusion-based Feature Absorption Learning (Diff-FAL) approach, to reinforce the performance of lightweight detection models in nighttime with rain interference. By developing an unsupervised training strategy based on the diffusion model, the proposed approach assists lightweight detectors absorb useful features from degraded images. To this end, our Diff-FAL framework comprises three distinct subnetworks: a Feature Optimization (FO) subnetwork, a Feature Mutation (FM) subnetwork, and a Lightweight Detection (LD) subnetwork. The FO subnetwork is designed to produce sharp, detailed features from rainy night images and the FM subnetwork is developed to transfer those features to the LD subnetwork. Comprehensive experiments on various datasets confirmed the superiority of our model, outperforming the compared method by up to 28.01% and 30.16% in accuracy on two published datasets: the rainy nighttime (RNT) and real rainy images (rRain) datasets, respectively, while maintaining high-speed performance during inference.},
  archive      = {J_EAAI},
  author       = {Quoc-Viet Hoang and Trung-Hieu Le},
  doi          = {10.1016/j.engappai.2025.112263},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112263},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Diffusion-based feature absorption approach for improving lightweight object detectors in adverse weather conditions},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-modal model for removal of crack image shadow based on language prior information. <em>EAAI</em>, <em>161</em>, 112262. (<a href='https://doi.org/10.1016/j.engappai.2025.112262'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-vision based crack detection highly depends on the quality of images and it remains to be a challenging task due to the effects of shadow. The utilization of deep learning algorithm, guided by prior information, has been demonstrated effective in the removal of shadows. However, it has limitations in handling images with shadowed cracks. A deep learning method incorporating language prior information and a multi-modal model is proposed in this study to improve the removal of shadow effects in restoring the crack images. Natural language processing (NLP) is used to extract the language prior information from image text description to enhance the crack recognition, and OTSU method is used to obtain the image prior information. A novel multi-modal model, named as the Text-based Shadow Removal Network (TSRNet), for the removal of shadow in crack image, is proposed to have better crack restoration capability. Bayesian optimization approach is also employed to optimize the network architecture improving the prediction precision of TSRNet. The proposed framework for shadow removal is verified using an open-source shadowed concrete crack image dataset and a new dataset from experiment. Results indicate that the language prior information can enhance the TSRNet model with better performances of shadow removal for real-world crack images compared with other existing models.},
  archive      = {J_EAAI},
  author       = {Gang Liu and Xuming Li and Qingshan Yang and S.S. Law and Changjun Deng},
  doi          = {10.1016/j.engappai.2025.112262},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112262},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-modal model for removal of crack image shadow based on language prior information},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development and implementation of a hybrid visual prediction algorithm for robotic smart tomato harvesting. <em>EAAI</em>, <em>161</em>, 112261. (<a href='https://doi.org/10.1016/j.engappai.2025.112261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces new algorithms designed specifically for smart tomato harvesting, which combines predictions from two independently trained YOLOv8 (You Only Look Once version 8) models, each specialized on different datasets to detect tomatoes and classify their ripeness stages—ripe, unripe, and semi-ripe—while also computing their center points. To enhance detection accuracy under varying field conditions, multiple fusion strategies were developed, including a hybrid algorithm that integrates union and confidence-weighted summation methods. The Hybrid Algorithm achieved the best performance, surpassing the original models and other fusion techniques. It attained F1 scores of 0.697 and 0.694 at confidence thresholds of 0.5 and 0.9, respectively, compared to the original models' F1 scores of 0.670 and 0.648 at confidence 0.5, and 0.481 and 0.497 at confidence 0.9. This corresponds to an improvement of 4.0 % and 7.6 % at confidence 0.5, and 44.3 % and 39.6 % at confidence 0.9, demonstrating the hybrid algorithm's stability and superiority, particularly at higher thresholds. Furthermore, the system utilizes a high-resolution RGB (Red, Green, Blue) camera for real-time image capture, enhancing model performance in complex agricultural environments. This study validates the effectiveness of confidence-based fusion in developing robust and accurate vision systems for precision agriculture.},
  archive      = {J_EAAI},
  author       = {Giuseppe Carbone and Angad Singh Gurtatta and Dmitry Malyshev},
  doi          = {10.1016/j.engappai.2025.112261},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112261},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development and implementation of a hybrid visual prediction algorithm for robotic smart tomato harvesting},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal multi-level feature representation learning for flow pattern identification of oil-water two-phase flow. <em>EAAI</em>, <em>161</em>, 112260. (<a href='https://doi.org/10.1016/j.engappai.2025.112260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the difficulty of the traditional experimental methods in real-time monitoring and identification of the flow process, this paper introduces a novel flow pattern identification method of the vertical oil-water two-phase flow based on multi-modal multi-level feature representation. The one-dimensional electromagnetic signals are encoded into two-dimensional feature spaces to explore their structural complexity, evolutionary probability laws and nonlinear characteristics in multimodal domain, thereby generating a multi-modal representation of the electromagnetic signals. Subsequently, a multi-modal multi-level feature fusion network is developed for flow pattern identification network, which flexibly leverages effective information across different modalities and levels, thereby enhancing the identifying accuracy. Experimental results demonstrate that the proposed method achieves high accuracy on the constructed multi-modal dataset, proving its feasibility and effectiveness in identifying the flow pattern of the oil-water two-phase flow in vertical pipes.},
  archive      = {J_EAAI},
  author       = {Weihang Kong and Yaohan Chi and He Liu and Hongbao Tang and He Li},
  doi          = {10.1016/j.engappai.2025.112260},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112260},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-modal multi-level feature representation learning for flow pattern identification of oil-water two-phase flow},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Defining and evaluating decision and composite risk in language models applied to natural language inference. <em>EAAI</em>, <em>161</em>, 112253. (<a href='https://doi.org/10.1016/j.engappai.2025.112253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite their impressive performance, large language models (LLMs) are known to pose important risks. One such set of risks arises from misplaced confidence, whether over-confidence or under-confidence, that the models have in their inference. While the former is well studied, the latter is not, leading to an asymmetry in understanding the comprehensive risk of the model based on misplaced confidence. In this paper, we address this asymmetry by defining two types of risk (decision and composite risk), and proposing an experimental framework consisting of a two-level inference architecture and appropriate metrics for measuring such risks in both discriminative and generative LLMs. The first level relies on a decision rule that determines whether the underlying language model should abstain from inference. The second level (which applies if the model does not abstain) is the model’s inference. This framework has direct implications for error-sensitive LLM-based engineering applications where reliable decision-making is critical, such as healthcare and finance. Through detailed experiments on four natural language commonsense reasoning datasets using both an open-source ensemble-based transformer model and a generative LLM, we demonstrate the practical utility of our evaluation framework. Our results show that the framework can get an LLM to confidently respond to an extra 20.1% of low-risk inference tasks that other methods might misclassify as high-risk, and skip 19.8% of high-risk tasks, which would have been answered incorrectly.},
  archive      = {J_EAAI},
  author       = {Ke Shen and Mayank Kejriwal},
  doi          = {10.1016/j.engappai.2025.112253},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112253},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Defining and evaluating decision and composite risk in language models applied to natural language inference},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced machine learning techniques for predicting wear performance in graphene oxide particulate interpenetrating polymer network composites. <em>EAAI</em>, <em>161</em>, 112252. (<a href='https://doi.org/10.1016/j.engappai.2025.112252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research investigates the wear behavior of hybrid polymeric composites made from synthetic glass and natural cotton fibers, reinforced with varying proportions of Graphene Oxide (GO) (0 %, 1 %, 3 %, 5 %, 7 %, 9 %). The effect of fiber arrangement and Graphene Oxide (GO) incorporation on wear rate and Coefficient of Friction (CoF) was evaluated using the Pin-On-Disk method, with analysis based on Taguchi's L 32 Orthogonal Array. The optimal parameters were found at 6 min, 5 % GO, 300 revolutions per minute (rpm) speed, 20 mm (mm) track diameter, and 10 N (N) load, achieving a minimum wear rate of 0.612 × 10 −4 cubic millimeters per newton-meter (mm 3 /N-m) and a CoF of 0.151. Predictive modeling was performed to predict the wear rate and coefficient of friction using supervised machine learning algorithms, including Linear Regression, Decision Tree, and Random Forest, to forecast material behavior. Performance evaluation using Confusion Matrix, Distribution Analysis, and various metrics showed that the Decision Tree model excelled, achieving near-perfect predictive power with a Mean Squared Error (MSE) of 0 and an R-squared value of 0.9999. The model demonstrated 100 % accuracy, with precision, recall, and F1-scores all equal to 1. This research demonstrates the effectiveness of combining natural and synthetic fibers with GO, along with the predictive power of machine learning in optimizing material properties.},
  archive      = {J_EAAI},
  author       = {Eastus Russel and S. Madhu and Judy S and Edwin Geo Varuvel and G.B. Santhi and G. Suresh and Femilda Josephin J.S and Mohammed F. Albeshr and Farzad Kiani},
  doi          = {10.1016/j.engappai.2025.112252},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112252},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Advanced machine learning techniques for predicting wear performance in graphene oxide particulate interpenetrating polymer network composites},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Health state evaluation and analysis of equipment considering multi-scale data fusion. <em>EAAI</em>, <em>161</em>, 112251. (<a href='https://doi.org/10.1016/j.engappai.2025.112251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current researches of health state evaluation of equipment have increasingly emphasized the integration of data and knowledge to improve evaluation accuracy and interpretability, which leads to the emergence of hybrid information-based methods as a research hotspot. However, there are issues with redundant health indicators, multi-scale data with different features and measurement units, and interpretability measures in the evaluation. In this paper, an interpretable health state evaluation and analysis method of equipment is proposed based on trustworthy evidential reasoning rule (TERR). To deal with redundancy in health indicators, a multi-scale data analysis model is proposed based on the clustering analysis and Kruskal-Wallis test. It can select the optimal health indicators that effectively preserve the original evaluation information while reducing the model complexity. To integrate the selected indicators with uncertainty, a TERR-based multi-scale data fusion model is proposed, where the evidence weight, reliability, and trustworthiness are simultaneously considered. Also, an interpretable parameter optimization model is constructed to alleviate the uncertainty in initial evidential parameters. To study the interpretability of TERR, two sensitivity analysis methods are proposed, and the performance coefficient matrix of the model output to the perturbation is derived mathematically. This shows how the interpretability of TERR is enhanced and which external parameter has the greatest impact on outputs. Finally, a case study of health state evaluation of laser inertial measurement unit (LIMU) validates the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Shuai-Wen Tang and Jiang Jiang and Jian-Bin Sun and Zhuo-Ting Yu},
  doi          = {10.1016/j.engappai.2025.112251},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112251},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Health state evaluation and analysis of equipment considering multi-scale data fusion},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unmanned surface vehicle autonomous racing and obstacle avoidance with robust adversarial deep reinforcement learning. <em>EAAI</em>, <em>161</em>, 112250. (<a href='https://doi.org/10.1016/j.engappai.2025.112250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an autonomous racing control method for Unmanned Surface Vehicles (USVs) based on robust adversarial deep reinforcement learning (ADRL) algorithm, which leverages the strengths of both deep reinforcement learning and adversarial training. Adversarial obstacles and various tracks are employed to train a policy, so the proposed method can enhance the robustness and generalization of autonomous USV racing while ensuring effective obstacle avoidance. A simulation environment for USV racing was developed to conduct the experiments with Unity3D. The performance of the proposed method in handling diverse track scenarios and obstacle avoidance is demonstrated through simulations. Quantitative results show that ADRL achieves dramatic improvements over baseline DRL methods: collision rates are reduced by 99.85%, task completion rates are improved by 73.75%, and navigation time efficiency is enhanced by approximately 3% while maintaining superior safety performance.},
  archive      = {J_EAAI},
  author       = {Jingyu Liu and Yuanda Wang and Changyin Sun},
  doi          = {10.1016/j.engappai.2025.112250},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112250},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unmanned surface vehicle autonomous racing and obstacle avoidance with robust adversarial deep reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale constitutive modeling of anisotropic plasticity: Coupling the visco-plastic self-consistent model with the recurrent neural network and its implementation in finite element analysis. <em>EAAI</em>, <em>161</em>, 112249. (<a href='https://doi.org/10.1016/j.engappai.2025.112249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anisotropic and nonlinear strain-path-dependent nature of metal plasticity poses a major challenge for accurate constitutive modeling in finite element (FE) analysis. Traditional macroscale models are easily implemented but lack accuracy, while crystal plasticity (CP) models offer high fidelity at the cost of computational efficiency. To bridge this gap, we propose a deep neural network smart constitutive (DNNSC) framework that combines the visco-plastic self-consistent (VPSC) model with a gated recurrent unit (GRU) network. A VPSC model calibrated on pure aluminum generated 14,000 strain-paths for training GRU-based network. The optimized model has a prediction accuracy of up to 96 % on unknown strain-paths. Subsequently, the DNNSC model was implemented into the FE analysis through Fortran programming, and a benchmark simulation for thin sheet stamping was successfully performed. The simulation results demonstrated that the DNNSC model significantly improved prediction performance compared to conventional macroscale constitutive models. Especially, the ear height and plate thickness were accurately predicted with an accuracy of 91.85 % and 95.84 %, compared to only 68.85 % and 86.59 % achieved by the Yld model. Meanwhile, the simulation time was reduced to approximately one-tenth that of the fully coupled CP model, because the latter required calculating and homogenizing the mechanical responses of hundreds of grains at each integration point during the simulation. The DNNSC framework bridges the gap between CP models and FE simulations of plastic forming and breaks down the barrier between modeling and practical application. Furthermore, this framework can be extended to other materials by re-calibrating VPSC parameters and fine-tuning DNN parameters.},
  archive      = {J_EAAI},
  author       = {Ziwei Zhou and Liang Cheng and Huaidong Song and Haijing Guo and Ruolin Li and Lingyan Sun and Bin Tang},
  doi          = {10.1016/j.engappai.2025.112249},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112249},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiscale constitutive modeling of anisotropic plasticity: Coupling the visco-plastic self-consistent model with the recurrent neural network and its implementation in finite element analysis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An online reinforcement learning method to improve control adaptability in robot-aided rehabilitation. <em>EAAI</em>, <em>161</em>, 112248. (<a href='https://doi.org/10.1016/j.engappai.2025.112248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rehabilitation robotics enables consistent and personalized therapy but still relies on complex, expert-driven tuning of control parameters. To address this, a reinforcement learning strategy based on Q-learning is proposed to autonomously adapt key parameters during upper-limb rehabilitation, without requiring prior task-specific knowledge. A systematic evaluation is conducted across combinations of control parameters (radial stiffness and execution time), performance-based reward functions (pointing accuracy and movement smoothness), and exploration strategies ( ɛ - greedy and Upper Confidence Bound). The Q-learning agent selects discrete actions (increase, decrease, or maintain the current value) for each control parameter, enabling real-time adaptation based on observed performance. The method is validated using a Kuka robotic arm in experiments involving 16 right-handed healthy subjects (13 males, 3 females) and 8 right-handed individuals simulating impaired motor behavior (5 males, 3 females). Motion signals are acquired through internal robot sensors, while a wearable physiological monitoring system define the Q-learning agent state. Reward improvement and exploration ratio are analyzed as key performance indicators and statistically compared across all tested conditions using the Mann–Whitney test. The results demonstrate that the proposed algorithm effectively adjusts control parameters online, with performance influenced by the reward function, exploration strategy, and selected control actions. Reward improvements of 0 . 11 ± 0 . 09 ( ɛ - greedy , reward based on pointing ability) and 0 . 13 ± 0 . 11 (reward based on smoothness, Upper Confidence Bound strategy) were observed in healthy subjects, indicating enhancements in pointing accuracy and movement smoothness. In simulated pathological cases, improvements of 0 . 08 ± 0 . 13 and 0 . 06 ± 0 . 16 were observed, respectively.},
  archive      = {J_EAAI},
  author       = {Rita Molle and Christian Tamantini and Clemente Lauretti and Emilio Maria Romano and Loredana Zollo},
  doi          = {10.1016/j.engappai.2025.112248},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112248},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An online reinforcement learning method to improve control adaptability in robot-aided rehabilitation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast prediction and compensation of curing deformation behaviours of composite parts with complex geometry based on neural operator on riemannian manifolds. <em>EAAI</em>, <em>161</em>, 112247. (<a href='https://doi.org/10.1016/j.engappai.2025.112247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling the curing deformation of composite parts is becoming increasingly challenging with the ever-increasing performance requirements of aerospace equipment. Mould surface compensation, which adjusts the mould surface to minimise the discrepancy between the cured part geometry and the nominal part geometry, has become a primary deformation control way in engineering. The existing mirror compensation methods focus on the deformation dominated by spring-in and are challenging for complex deformation modes. Surrogate model-based shape optimisation provides a feasible idea, but establishing a surrogate model to predict curing deformation fields on complex part geometries remains a challenge. Therefore, this study explores a novel neural operator-driven framework for fast curing deformation prediction and compensation. A clustering-based deformation field segmentation method is proposed to manipulate the mould surface morphing using limited design variables. The neural operator on Riemannian manifolds is introduced for the first time to establish the surrogate model between the mould surface and the curing deformation fields on complex part geometries. To control the global error distribution of the composite part, two error metrics are designed to optimise the mould surface by genetic algorithm. The verification results show that the proposed framework exhibits significant potential in predicting and compensating for the curing deformation field of composite parts with complex geometry.},
  archive      = {J_EAAI},
  author       = {Lu Chen and Yingguang Li and Jingyan Su and Weiwei Xu and Lin Hu and Gengxiang Chen and Xu Liu and Xiaozhong Hao},
  doi          = {10.1016/j.engappai.2025.112247},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112247},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast prediction and compensation of curing deformation behaviours of composite parts with complex geometry based on neural operator on riemannian manifolds},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced detection of acute leukemia: A hybrid machine learning framework with adaptive weight-optimized level set evolution. <em>EAAI</em>, <em>161</em>, 112244. (<a href='https://doi.org/10.1016/j.engappai.2025.112244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, a novel, multistage framework is developed for the automated detection of Acute Lymphoblastic Leukemia (ALL) and Acute Myeloid Leukemia (AML), addressing challenges due to the inclusion of overlapping cells, noise, and unwanted cells. It integrates an Adaptive Weight-Optimized Level Set Evolution (AWOLSE) scheme to ensures precise and accurate segmentation, coupled with a marker-controlled watershed algorithm to improve performance in regions of cell overlap and contact. It ensures more reliable cell boundary delineation. For classification, a hybrid model combining the strengths of Random Forest (RF) and Support Vector Machine (SVM) is employed that delivering superior performance by leveraging the complementary advantages of these classifiers. Furthermore, feature extraction with the Gray Level Co-occurrence Matrix (GLCM), followed by feature selection with Principal Component Analysis (PCA), aids in the identification of relevant features. The suggested methodology beats its competitors, providing the best ALL identification results on the Acute Lymphoblastic Leukemia Image Database (ALLIDB), with 99.07% accuracy, 97.96% recall, 100.00% specificity, and 100.00% precision. Similarly, on the American Society of Hematology (ASH) database, the technique achieves superior AML identification results with 96.25% accuracy, 95.00% recall, 97.50% specificity, and 97.44% precision.},
  archive      = {J_EAAI},
  author       = {Pradeep Kumar Das and Adyasha Sahu and Sukadev Meher and Rutuparna Panda and Ajith Abraham},
  doi          = {10.1016/j.engappai.2025.112244},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112244},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced detection of acute leukemia: A hybrid machine learning framework with adaptive weight-optimized level set evolution},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based secure tracking control for nonlinear interconnected systems: An event-triggered solution approach. <em>EAAI</em>, <em>161</em>, 112243. (<a href='https://doi.org/10.1016/j.engappai.2025.112243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a secure tracking control method for nonlinear interconnected systems based on reinforcement learning, addressing both security constraints and mismatched conditions in such systems. By utilizing system augmentation techniques, the tracking control problem is reformulated into a stabilization problem for the augmented system, simplifying the original control task. Drawing inspiration from the Chinese philosophical principle, we further transform the problem into a zero-sum game framework. Moreover, a control barrier function (CBF) is incorporated into a cost function to ensure that system trajectories remain within a predefined safe region. An event-triggered mechanism is introduced, and an event-based safety Hamilton–Jacobi–Isaacs (HJI) equation is established. An adaptive single evaluation network is designed, leveraging experience replay techniques to solve the HJI equation. Finally, the Lyapunov method is employed to prove the uniform ultimate boundedness of both the tracking error and the weight error. The effectiveness of the proposed method is validated through numerical examples.},
  archive      = {J_EAAI},
  author       = {Chunbin Qin and Suyang Hou and Mingyu Pang and Zhongwei Wang and Dehua Zhang},
  doi          = {10.1016/j.engappai.2025.112243},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112243},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning-based secure tracking control for nonlinear interconnected systems: An event-triggered solution approach},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A quantized subtraction-convolution network for industrial lightweight edge interpretable diagnosis. <em>EAAI</em>, <em>161</em>, 112241. (<a href='https://doi.org/10.1016/j.engappai.2025.112241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addressing the prevalent challenges of delayed fault diagnosis, deployment complexity of advanced deep learning models on low-cost edge devices, and limited model interpretability, this study proposed an edge-cloud collaborative interpretable diagnosis based on quantized subtraction-convolution network. Firstly, an interpretable quantized subtraction-convolution network with lightweight three-layer structure is designed. Inspired by the adaptive spectral subtraction, a learnable sparse pulse kernel is designed to extract the fault feature as the subtraction layer. Subsequently, the convolution and classification layers are then integrated to produce interpretable results for efficient identification. To facilitate deployment and updates on edge devices, the quantized subtraction-convolution network is decomposed into a lightweight edge architecture and corresponding parameters. It can be deployed on edge devices, and an edge-cloud collaborative framework addresses its training and compression. Considering the sparse characteristics of quantized subtraction-convolution network, a sparse pulse quantization strategy and quantization-aware training technique were developed to compress the model parameters. Finally, a low-cost edge fault diagnosis node prototype with quantized subtraction-convolution network is designed for real-time edge fault diagnosis. Experiments shown that the proposed method achieved average accuracy of 99.88 percent with compression ratio of 9.5. The memory usage, floating-point operations per second, and average power consumption are respectively only 54 kilo binary byte, 0.053 mega binary byte, and 6.67 mJ. Actual gear edge diagnosis experiments confirmed the effectiveness, which can implement model inference in 0.045 s at the edge fault diagnosis node. It is anticipated that the proposed method will find extensive application in the industrial edge interpretable diagnosis.},
  archive      = {J_EAAI},
  author       = {Qihang Wu and Jun Luo and Wenbin Huang and Xiaoxi Ding},
  doi          = {10.1016/j.engappai.2025.112241},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112241},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A quantized subtraction-convolution network for industrial lightweight edge interpretable diagnosis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight multi-level feature integration transformer for image super-resolution. <em>EAAI</em>, <em>161</em>, 112240. (<a href='https://doi.org/10.1016/j.engappai.2025.112240'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based methods have attracted significant attention in the field of image super-resolution. However, existing approaches typically concentrate on a single level of information for image reconstruction, and neglect the critical role of multi-level information in feature representation, resulting in the low utilization of the potential capabilities of Transformer. To address this limitation, we propose a novel Transformer model, named as Multi-Level Differential Window Attention Transformer (MLDAT), designed for multi-level information fusion. Specifically, our approach introduces a self-attention module based on differential windows to comprehensively extract and integrate feature information across varying window sizes. Additionally, we introduce a High-order Global Attention Module (HGAB) to combine the second-order attention with global self-attention, which facilitates the establishment of relationships between local features and the overall global feature context within an image while complementing local window information. Extensive experimental results demonstrate that our model can significantly improve the performance of image super-resolution , and achieves the better results compared with existing methods.},
  archive      = {J_EAAI},
  author       = {Shuheng Wang and Ziao Gong and Mengda Li and Shen Wu and Yilin He},
  doi          = {10.1016/j.engappai.2025.112240},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112240},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightweight multi-level feature integration transformer for image super-resolution},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional object detection for autonomous driving via deep learning: A review. <em>EAAI</em>, <em>161</em>, 112238. (<a href='https://doi.org/10.1016/j.engappai.2025.112238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of autonomous driving technology, there is an increasing demand for highly accurate and real-time vehicle perception systems. From an artificial intelligence (AI) perspective, three-dimensional (3D) object detection benefits from recent progress in deep neural networks, convolutional neural networks (CNNs), and transformer architectures, which provide powerful tools for feature extraction, spatial reasoning, and multi-modal data fusion. These AI techniques enable robust, uncertainty-aware predictions by effectively modeling complex sensor data. From an engineering standpoint, 3D object detectors serve as critical components in autonomous driving systems by translating AI-derived insights into real-time, high-accuracy vehicle perception. This paper reviews the research progress of deep learning-based 3D object detection algorithms in autonomous driving. First, commonly used data acquisition sensors are systematically categorized, and the most widely adopted 3D detection datasets and evaluation metrics are introduced; the standard 3D bounding-box representation and core network architectures are also explained. Second, algorithms are classified according to input data type: 1) single-modal methods, including vision-based, 3D data dimensionality reduction, point cloud-based, transformer-based, mamba-based, and hybrid point cloud approaches; 2) multi-modal methods, subdivided into serial fusion and parallel fusion strategies within network pipelines. The characteristics, contributions, and limitations of each category are summarized, and representative algorithms are compared across datasets to identify research trends. Finally, current challenges, such as sparse data handling, domain shifts, and real-time constraints, are examined, and prospective directions for future development are proposed.},
  archive      = {J_EAAI},
  author       = {Jiaqi Cai and Yiquan Wu},
  doi          = {10.1016/j.engappai.2025.112238},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112238},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-dimensional object detection for autonomous driving via deep learning: A review},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unscented kalman filter neural network with double-layer decomposition algorithm applied to the prediction of current efficiency in aluminum electrolysis processes. <em>EAAI</em>, <em>161</em>, 112237. (<a href='https://doi.org/10.1016/j.engappai.2025.112237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive modeling in predictive optimization control technology can effectively reduce energy consumption and improve production efficiency in the electrolytic aluminum process (EAP). Among the various modeling approaches, artificial neural networks (ANN) have been widely adopted in the EAP due to their strong capability to capture nonlinear relationships inherent in complex industrial systems. However, conventional ANN heavily rely on historical data to achieve optimal models, which limits their accuracy and generalization performance under strong disturbances and time-varying conditions. To address these problems, this article proposes a novel dynamic prediction model of unscented Kalman filter neural network with double-layer decomposition (UKFNN-DD), building upon the foundation of Kalman filter neural network (KFNN). First, singular value decomposition (SVD) is adopted to compute the square root of covariance matrices, enhancing the numerical robustness of the prediction algorithm and overcoming the shortcomings of traditional Cholesky decomposition. Furthermore, a dual-layer KFNN strategy is introduced to overcome the absence of one-step-ahead prediction in conventional state-space formulations. By applying a two-stage correction to the state variables using measurement data, the proposed method improves the adaptability of the model to external environmental variations. Finally, the prediction error of the state variables is optimized using a gradient descent algorithm, which improves the stability and reliability of the model’s prediction performance. Experimental results demonstrate that the proposed method significantly outperforms baseline methods, achieving a 4.38-fold reduction in mean absolute error (MAE) and a 77.29-fold reduction in the sum of squared errors (SSE), thereby verifying its superiority in dynamic prediction for aluminum electrolysis.},
  archive      = {J_EAAI},
  author       = {Xiaoyan Fang and Xihong Fei and Zhenyi Xu and Lei Su and Jing Wang},
  doi          = {10.1016/j.engappai.2025.112237},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112237},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unscented kalman filter neural network with double-layer decomposition algorithm applied to the prediction of current efficiency in aluminum electrolysis processes},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature super-resolution-based method for small-scale target detection and segmentation in side-scan sonar. <em>EAAI</em>, <em>161</em>, 112235. (<a href='https://doi.org/10.1016/j.engappai.2025.112235'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of side-scan sonar in underwater target detection plays a significant role in marine engineering construction and ocean resource exploration. However, existing methods for small object detection often suffer from limited accuracy and robustness. To address this issue, we propose a feature super-resolution-based approach for detecting and segmenting small targets in side-scan sonar images. During network training, a feature super-resolution branch is first constructed. Both low-level and high-level features from the backbone of the You Only Look Once (YOLO) network are fed into this branch. After processing through an encoder-decoder architecture, a super-resolved feature map is reconstructed, and the network is optimized via backpropagation to enhance the ability to extract features of small targets. Furthermore, an exponential decay strategy is adopted to define the loss weights of different branches, establishing a branch-aware training mechanism to improve training effectiveness. During inference, the super-resolution branch is discarded to balance detection accuracy and inference efficiency. Experimental results demonstrate that the proposed method achieves superior performance in detecting and segmenting small-scale targets in side-scan sonar imagery, achieving state-of-the-art results on two public side-scan sonar small object datasets. Additionally, this approach can be extended as a training strategy for side-scan sonar target detection and segmentation networks. The source code is available at https://github.com/Yang-Code984/FSR_Sonar .},
  archive      = {J_EAAI},
  author       = {Zhiwei Yang and Jianhu Zhao and Xi Zhao and Chao Huang},
  doi          = {10.1016/j.engappai.2025.112235},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112235},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature super-resolution-based method for small-scale target detection and segmentation in side-scan sonar},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven prediction of thermal and flow fields in magnetized boger-micropolar tri-hybrid nanofluids via deep artificial neural networks. <em>EAAI</em>, <em>161</em>, 112232. (<a href='https://doi.org/10.1016/j.engappai.2025.112232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a deep learning framework for predicting the thermal and flow behavior of Boger micropolar tri-hybrid nanofluids under magnetized axial squeezing flow between two parallel disks. The fluid comprises gold, silver, and diamond nanoparticles dispersed in a water-based solution, forming a high-performance ternary hybrid heat transfer medium. A fully connected artificial neural network with three hidden layers (32–16–8 neurons) and hyperbolic tangent activation functions was trained on synthetic data generated using a boundary value problem solver. The model predicts four key physical quantities: axial velocity, streamwise velocity, microrotation, and temperature profile. Quantitative evaluation reveals excellent agreement between machine learning predictions and numerical benchmarks, with mean absolute errors consistently below 0.02 and coefficients of determination exceeding 0.99 across all outputs. Sensitivity analysis reveals the impact of the solvent fraction and vortex viscosity parameters on flow penetration and thermal stratification near the boundaries. This work introduces a novel combination of Boger–micropolar fluid dynamics, magnetohydrodynamic squeezing flow, and tri-hybrid nanoparticles into a unified ANN (Artificial Neural Networks) based surrogate, enabling accurate multi-output prediction of strongly coupled nonlinear fields. The proposed approach offers a scalable machine learning model for real-time optimization of nanofluid-based thermal management systems in engineering applications.},
  archive      = {J_EAAI},
  author       = {Mohammad Jalili and Hesam Ehsani and Ali Mirzagoli Ganji and Amirali Shateri and Mehdi mahboobtosi and Yuping Wu and Payam Jalili and Bahram Jalili and Davood Domiri Ganji},
  doi          = {10.1016/j.engappai.2025.112232},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112232},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven prediction of thermal and flow fields in magnetized boger-micropolar tri-hybrid nanofluids via deep artificial neural networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable knowledge recommendation for product innovation concept design based on knowledge graph and multi-task learning. <em>EAAI</em>, <em>161</em>, 112231. (<a href='https://doi.org/10.1016/j.engappai.2025.112231'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of product innovation concept design, by enhancing the transparency of the knowledge recommendation process and providing designers with explainable recommendation results, decision-making time can be reduced, and design efficiency can be improved. Existing explainable knowledge recommendation methods can generate textual explanation information, but they often overlook the dynamic nature of the design process, which negatively affects the accuracy of the recommendations. To address this issue, the current study proposes a knowledge recommendation method for product innovation concept design based on knowledge graph (KG) and multi-task learning. Specifically, a TransD-based model is first constructed to perform the knowledge graph embedding (KGE) task. Then, KGE and Gated Recurrent Unit (GRU) are used to obtain dynamic knowledge demands across different temporal scales from the historical interactions of designers to enhance recommendation accuracy. A multi-task learning framework is subsequently introduced to enable feature sharing between the two tasks, improving the generalization and effectiveness of the model. Finally, an explanation strategy is designed by combining embedded knowledge and paths to provide optimal explainability information. Experimental results demonstrate that, compared with other state-of-the-art knowledge recommendation algorithms, the proposed method not only offers explainable recommendation results but also achieves higher accuracy, making it more suitable for real-world recommendation scenarios.},
  archive      = {J_EAAI},
  author       = {Yida Hong and Wenqiang Li and Hai Xiang and Chuanxiao Li and Changfu Wan},
  doi          = {10.1016/j.engappai.2025.112231},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112231},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable knowledge recommendation for product innovation concept design based on knowledge graph and multi-task learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards reproducible machine learning-based process monitoring and quality prediction research for additive manufacturing. <em>EAAI</em>, <em>161</em>, 112223. (<a href='https://doi.org/10.1016/j.engappai.2025.112223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive manufacturing (AM) is increasingly adopted across industries for its ability to support design flexibility, rapid prototyping, and mass customization. Machine learning (ML)-based cyber-physical systems (CPSs) have been extensively developed to improve the print quality of AM. However, the reproducibility of these systems has not been thoroughly investigated due to a lack of formal evaluation methods. Reproducibility, a critical component of trustworthy artificial intelligence, is achieved when an independent team can replicate the findings or artifacts of a study using a different experimental setup and achieve comparable performance. In many publications, critical information necessary for reproduction is often missing due to a lack of comprehensive AM and ML domain knowledge, resulting in systems that fail to replicate the reported performance. Integrating AM and ML domain knowledge, this paper proposes a reproducibility investigation pipeline and a reproducibility checklist for ML-based AM process monitoring and quality prediction systems. Based on the CRoss Industry Standard Process (CRISP) methodology, the pipeline guides researchers through the key steps required to reproduce a study, while the checklist systematically extracts information relevant to reproducibility from the publication. We validated the proposed approach through two case studies: reproducing a fused filament fabrication warping detection system and a laser powder bed fusion melt pool area prediction model. Both case studies confirmed that the pipeline and checklist successfully identified missing information, improved reproducibility, and enhanced the performance of reproduced systems. Based on the proposed checklist and leveraging large language models, a reproducibility survey was conducted to assess the current reproducibility status within this research domain.},
  archive      = {J_EAAI},
  author       = {Jiarui Xie and Mutahar Safdar and Andrei Mircea and Bi Cheng Zhao and Yan Lu and Hyunwoong Ko and Zhuo Yang and Yaoyao Fiona Zhao},
  doi          = {10.1016/j.engappai.2025.112223},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112223},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards reproducible machine learning-based process monitoring and quality prediction research for additive manufacturing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Degradation-based predictive energy management for intelligent fuel cell hybrid electric vehicles with a novel deep reinforcement learning architecture. <em>EAAI</em>, <em>161</em>, 112222. (<a href='https://doi.org/10.1016/j.engappai.2025.112222'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The degradation of fuel cell systems (FCS) affects the energy management performance of fuel cell hybrid electric vehicles (FCHEVs), especially in the case of severe degradation. This study develops a novel predictive energy management architecture, which consists of the Extended Long Short-Term Memory (xLSTM) and Soft Actor-Critic (SAC). Specifically, the speed predictor is built using xLSTM network and leverages the speed and position information of the preceding and following vehicles. In order to provide a reliable basis for energy management in degradation scenarios, an FCS degradation model is developed, which enables the dynamic mapping of output efficiency curves under varying state-of-health (SOH) conditions. Sequentially, a SAC-based agent is employed as the energy management strategy (EMS), which innovatively takes full account of the impact of the FCS SOH on energy allocation, achieving proactive degradation-aware energy allocation. Simulation results demonstrate that the developed xLSTM architecture achieves a 71 % improvement in speed prediction accuracy compared to Transformer-based models within the Next Generation Simulation validated scenario. Moreover, at SOH = 90 %, the newly designed EMS reduces operational costs by 8.7 % and 10.7 % compared to conventional methods under the New European Driving Cycle and Worldwide Harmonized Light Vehicles Test Procedure, while decreasing FCS degradation costs by 17 % and 51 %, respectively. The innovative approach not only elevates energy efficiency but also prolongs FCS operational longevity via intelligent SOH-aware, which establishes a new paradigm for lifecycle-optimized energy management in FCHEVs.},
  archive      = {J_EAAI},
  author       = {Zhigen Nie and Zhuangfeng Shi and Yufeng Lian and Hao Song},
  doi          = {10.1016/j.engappai.2025.112222},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112222},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Degradation-based predictive energy management for intelligent fuel cell hybrid electric vehicles with a novel deep reinforcement learning architecture},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Observer based fault tolerant control design for saturated nonlinear systems with full state constraints via a novel event-triggered mechanism. <em>EAAI</em>, <em>161</em>, 112221. (<a href='https://doi.org/10.1016/j.engappai.2025.112221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety plays a crucial role in many promising applications as they must comply with stringent safety regulations while staying within physical limits. Therefore, safety fault-tolerant systems with saturated nonlinearities and input constraints are investigated in this paper. An event-triggered safety fault tolerant control (FTC) method based on adaptive dynamic programming (ADP) is proposed. The constrained state is modeled using a smooth mapping function, thus transforming the original system into an unconstrained framework. A fault observer is designed for unknown actuator faults occurring in the system. When an unknown fault occurs in the system, the actuator is compensated in real time according to the fault. The optimal safety value function is approximated by constructing a single critic neural network (NN). Then, a novel event-triggered mechanism is proposed, which allows the algorithm to obtain the optimal control law without constructing the event-triggered Hamilton–Jacobi–Bellman (HJB) equation. In addition, by adjusting the size of the parameter τ under the event triggered condition, different demands on the number of event triggers are realized, which in turn ensures the efficient use of resources while leading to the trade-off of optimal control. This paper also incorporates an empirical playback technique in the design of the critic’s update law to address the challenges associated with continuous incentive requirements. It is theoretically proven that all signals of the system are consistent with the limit bounds, thus ensuring the stability of the system.},
  archive      = {J_EAAI},
  author       = {Chunbin Qin and Mingyu Pang and Zhongwei Wang and Suyang Hou and Dehua Zhang},
  doi          = {10.1016/j.engappai.2025.112221},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112221},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Observer based fault tolerant control design for saturated nonlinear systems with full state constraints via a novel event-triggered mechanism},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cybersecurity enhancement using conditional generative adversarial network with transformer-based conditional variational autoencoder. <em>EAAI</em>, <em>161</em>, 112220. (<a href='https://doi.org/10.1016/j.engappai.2025.112220'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since, Artificial Intelligence is highly developing and concatenating into several domains, cybersecurity is an important field of delivering both the advantages and disadvantages. In addition to this, Artificial Intelligence is applied in a wide variety of applications like healthcare sector, content creation and entertainment and financial industries. Therefore, this work finds the efficiency of Artificial Intelligence -oriented cybersecurity metrics in succeeding the digital environment over elevating cyber threats. Here, the developed models consist of two different stages while implementing the model. In the first stage, the essential dataset is assembled from the benchmark data source. These datasets are assembled by using Generative Artificial Intelligence (Gen Artificial Intelligence networks). Consequently, the raw data is given as an input to Conditional Hybrid Network for cybersecurity enhancement. Further, the Transformer-based Conditional Variational Autoencoders with Spatial-temporal Attention are designed for feature extraction that is subjected to the Conditional Generative Adversarial Network for classifying the cyber attacks. Henceforth, the developed network is evaluated and designed with multiple measures. Comparing baseline models, the suggested network obtains higher performance for developing security over cyber networks.},
  archive      = {J_EAAI},
  author       = {Prithvipal Singh and Sandeep Singh and Gurupdesh Singh and Amritpal Singh},
  doi          = {10.1016/j.engappai.2025.112220},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112220},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cybersecurity enhancement using conditional generative adversarial network with transformer-based conditional variational autoencoder},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modal transfer enhanced deep learning for structural dynamic response with sparse spatial data. <em>EAAI</em>, <em>161</em>, 112218. (<a href='https://doi.org/10.1016/j.engappai.2025.112218'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse spatial data in structural health monitoring (SHM) presents significant challenges due to large spatial gaps and high uncertainty, which hinder the generalization ability and performance of traditional data-driven methods that rely on dense sensor networks. To address this issue, this paper proposes a novel modal transfer-enhanced deep learning (MT-DL) model for the reconstruction and prediction of structural dynamic responses. The core idea is to integrate physical modal information (mode shapes) into the deep learning framework via transfer learning. This integration enables the model to capture the spatial correlation among structural nodes, even under extremely limited data conditions. The MT-DL model is initially validated on a simply supported beam with varying stiffness, where it demonstrates significantly higher reconstruction accuracy compared to both conventional deep learning (DL) approaches and the graph convolutional network (GCN) model under sparse sensor conditions. To demonstrate the model's robustness and generalizability, it is further applied to the dynamic response reconstruction of a continuous beam subjected to moving loads, a plate with complex boundary conditions under impact loading, and a slender flexible riser undergoing vortex-induced vibration (VIV). The results show that the proposed MT-DL model, by incorporating physical principles into data-driven learning, not only enhances prediction accuracy with minimal data but also offers improved physical interpretability. This approach provides a promising solution for structural monitoring in scenarios where dense sensor instrumentation is impractical or cost-prohibitive.},
  archive      = {J_EAAI},
  author       = {Yangyang Liao and Yajuan Xie and Hesheng Tang and Zihan Xia and Songtao Xue},
  doi          = {10.1016/j.engappai.2025.112218},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112218},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A modal transfer enhanced deep learning for structural dynamic response with sparse spatial data},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep learning pipeline for coronary artery analysis in X-ray angiography. <em>EAAI</em>, <em>161</em>, 112217. (<a href='https://doi.org/10.1016/j.engappai.2025.112217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X- ray angiography is a primary and essential assistive method for the accurate diagnosis of coronary blockage. Segmentation of coronary arteries and analysis of coronary artery blockage are the two primary tasks performed by cardiologists. We have proposed Coronary Artery Segmentation, Blockage Detection, and Measurement (CASBloDaM) a state-of-the-art pipeline integrated deep learning framework with conventional image processing techniques to achieve accurate coronary artery analysis in X-ray angiographic images. A new private dataset of 214 X-ray angiographic images is prepared for training, validation, and testing of the model by manual pixel annotation. The UNet3+ deep learning model is trained on X-ray angiographic images for accurate artery segmentation while multiple image processing techniques are developed to perform blockage detection and measurement. The model shows excellent performance in artery segmentation and the dice score of 0.989, accuracy of 0.985, specificity of 0.913 and sensitivity of 0.847 is achieved during the testing which is superior when compared against the previous reported works. An accuracy of 0.853, 0.882 and 0.725 are achieved by the proposed catheter detection, sub-artery removal and blockage detection algorithms respectively when evaluated for 150 test images. The proposed methodology achieved a Mean Square Error (MSE) of 28.66 and an R-square of 0.81 for blockage percentage estimation, and an MSE of 69.91 with an R-square of 0.99 for blockage location, compared to manual calculations. The novelty of the present work is the end-to-end integrated framework which can accurately perform coronary artery analysis in X-ray angiographic images and propose its clinical usage.},
  archive      = {J_EAAI},
  author       = {Karan V. Padariya and Abhishek Raval and Pranay Soni and Harsh Kapadia},
  doi          = {10.1016/j.engappai.2025.112217},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112217},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel deep learning pipeline for coronary artery analysis in X-ray angiography},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-teacher knowledge distillation-based framework for long-term respiratory monitoring and prediction with a novel flexible wearable sensor in healthcare engineering. <em>EAAI</em>, <em>161</em>, 112216. (<a href='https://doi.org/10.1016/j.engappai.2025.112216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Respiratory monitoring plays a critical role in early health warnings and preventive care, offering significant potential for advancements in healthcare engineering. Wearable respiratory monitoring devices, known for their compact design, portability, and real-time capabilities, face challenges such as limited long-term comfort, environmental interference, and signal inaccuracies. In this study, we propose a novel wearable respiratory monitoring framework, RAMP, which integrates an innovative artificial muscle-based flexible sensor system with advanced deep learning modules. The system is designed to reconstruct and analyze respiratory data across various human activities and predict long-term respiratory function. Utilizing a multi-teacher knowledge distillation mechanism, the framework optimizes a student model for enhanced prediction accuracy. Experimental results demonstrate the mean absolute percentage error (MAPE) of 7.28 and mean absolute error (MAE) of 11.92, highlighting the feasibility and effectiveness of system. This work advances the development of portable health monitoring devices and provides a robust foundation for long-term respiratory activity assessment and forecasting, contributing to the broader field of healthcare engineering and personalized medicine.},
  archive      = {J_EAAI},
  author       = {Ke Li and Qing Wang and Haoke Liu and Mingke Wang and Suiyuan Zhu and Xiang Wang and Jing Qin},
  doi          = {10.1016/j.engappai.2025.112216},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112216},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-teacher knowledge distillation-based framework for long-term respiratory monitoring and prediction with a novel flexible wearable sensor in healthcare engineering},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic mask network based on spiking neural convolutional model for missing modality brain tumor segmentation. <em>EAAI</em>, <em>161</em>, 112215. (<a href='https://doi.org/10.1016/j.engappai.2025.112215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor segmentation is a medical image processing task aimed at accurately locating and isolating tumor regions from brain scan images (e.g., Magnetic Resonance Imaging, MRI) in order to help doctors in diagnosis, treatment planning and surgical navigation. Automatic brain tumor segmentation is extremely challenging due to incomplete feature representation in the case of missing modalities and insufficient inter-modal information interaction. To this end, this paper proposes a novel dynamic threshold mask Transformer network for the missing modality brain tumor segmentation task, which is designed based on the nonlinear spiking neural convolutional model. The network consists of four independent encoders and a shared decoder to extract the features of each modality and perform shared representation learning. Among them, the dynamic threshold mask Transformer introduces learnable embedding vectors, generates dynamic masks on top of static masks to achieve fine-grained feature filtering, and enhances the ability of inter-modal information interaction. The adaptive gating weighting module and the channel cross spiking neural P attention module fuse modal features layer by layer in both spatial and channel dimensions to strengthen the modeling capability of local and global features. We conducted extensive comparative experiments on different missing modal cases in the BraTS2020 and BraTS2018 datasets. The experimental results show that the method effectively improves the robustness of missing modalities and the performance of brain tumor segmentation while maintaining the computational efficiency, and has good generalization ability and practicality.},
  archive      = {J_EAAI},
  author       = {Junjie Li and Rui Cai and Bing Li and Hong Peng},
  doi          = {10.1016/j.engappai.2025.112215},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112215},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic mask network based on spiking neural convolutional model for missing modality brain tumor segmentation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing accuracy in fall detection and prediction for elderly individuals using ensemble wavelet neural network and maximal overlap discrete wavelet transform. <em>EAAI</em>, <em>161</em>, 112213. (<a href='https://doi.org/10.1016/j.engappai.2025.112213'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Falls are the second-largest risk factor for the health of the elderly. Various researchers have proposed approaches for monitoring health and falls using only the Internet of Things (IoT) and sensors. However, relying on a single sensor limits accuracy in fall risk prediction. Data from multiple sensors can be used to classify human posture through learning-based algorithms stemming from machine learning. Recently, posture-detecting sensors have become increasingly popular, with InvenSense's Inertial Measurement Unit 9250 (IMU 9250) being a notable example for detecting elderly motion and transmitting data to a computer. This paper proposes the Ensemble Wavelet Network Framework (EWNNET) for fall prediction and detection using the Maximal Overlap Discrete Wavelet Transform (MODWT). The inertial measurement unit (IMU) dataset, containing real-time posture data from seven sensors, is split into 80 % for training and 20 % for testing. The EWNNET approach is compared with other machine-learning methods for fall detection, showing improved accuracy, sensitivity, precision, F-score, and specificity, with a 96.7 % classification success rate.},
  archive      = {J_EAAI},
  author       = {Safa Hussein Mohammed and Yangyu Fan and Guoyun Lv and Shiya Liu},
  doi          = {10.1016/j.engappai.2025.112213},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112213},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing accuracy in fall detection and prediction for elderly individuals using ensemble wavelet neural network and maximal overlap discrete wavelet transform},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leakage localization methodology based on dynamic pressure signal for subsea pipeline. <em>EAAI</em>, <em>161</em>, 112212. (<a href='https://doi.org/10.1016/j.engappai.2025.112212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leakage is one of the most critical failure forms of subsea pipeline. The accurate leakage localization is of great significance to ensure the safe and reliable transportation of subsea pipeline. Leakage locations are considered to be discretely distributed along the subsea pipeline. However, an overabundance of nodes in leakage localization model is caused by excessive discretization. The performance of a leakage localization model with much localization points is poor. Furthermore, the data collected in site usually contains a lot of noise which reduce the effectiveness of leakage localization. A leakage localization methodology based on dynamic pressure signal for subsea pipeline is proposed in this paper. A noise reduction model based on variational mode decomposition (VMD) algorithm combined with power spectral density (PSD) is established to reduce noise of leakage signal. An improved K-means grouping model is developed to mining data for inherent similarity and cluster leakage characteristic. It improves robustness of the leakage localization model. A radial basis function (RBF) neural network leakage localization model optimized by the pelican optimization algorithm (POA) is used to identify the location of leakage. A leakage experiment is used to study performance of this methodology. The localization accuracy of the proposed leakage localization methodology is more than 90 %, the localization error is less than 16 cm. After neural network combined with improved grouping model, average leakage localization accuracy increased by 15.65 %, average absolute error decreased 8.64 cm. The proposed methodology provides an effective tool for leakage localization of critical equipment in subsea production system.},
  archive      = {J_EAAI},
  author       = {Guowei Ji and Baoping Cai and Xuelin Liu and Yi Jiang and Yixin Zhao and Qingping Li and Lei Gao and Kaizheng Wu},
  doi          = {10.1016/j.engappai.2025.112212},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112212},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leakage localization methodology based on dynamic pressure signal for subsea pipeline},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing entity and relation extraction with dynamic hard negative augmentation framework. <em>EAAI</em>, <em>161</em>, 112211. (<a href='https://doi.org/10.1016/j.engappai.2025.112211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity and relation extraction, a fundamental task in information extraction, plays a crucial role in modeling unstructured text by identifying meaningful entities and their semantic relationships. While existing methods have shown effectiveness, they still face challenges in accurately identifying entity boundaries and extracting complex relationships. These challenges primarily arise from current contrastive learning approaches, which uniformly handle all negative samples in boundary detection and relation extraction without emphasizing the learning of hard negative samples. Additionally, the scarcity of hard negative samples limits the exploration of the state space near the anchors. To tackle these challenges, we introduce Dynamic Hard Negative Augmentation, an innovative framework designed to strategically explore and generate hard negative samples, thereby enhancing the learning of challenging cases through adaptive contrastive learning. During the negative sample augmentation process, we employ adversarial training to explore underrepresented areas of hard negative samples, generating a comprehensive coverage of the hard negative sample space to effectively explore the state space. We further introduce a dynamic enhancement mechanism that continuously optimizes the proportion of hard negative samples during training, ensuring targeted learning of these challenging cases.},
  archive      = {J_EAAI},
  author       = {Qibin Li and Shengyuan Bai and Nai Zhou and Nianmin Yao},
  doi          = {10.1016/j.engappai.2025.112211},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112211},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing entity and relation extraction with dynamic hard negative augmentation framework},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NashDQNSleep: Nash-based deep Q-network adaptive sleep scheduling for energy efficiency and age of information optimization in industrial internet of things. <em>EAAI</em>, <em>161</em>, 112210. (<a href='https://doi.org/10.1016/j.engappai.2025.112210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fresh and timely data is essential for the sustainable operation of Industrial Internet of Things (IIoT) systems, which support real-time monitoring and decision-making tasks. Sensor nodes typically need to remain active for long durations to maintain data freshness, resulting in high energy consumption. Traditional sleep scheduling methods often trade off energy savings with data freshness, and many rely on centralized sink-node coordination, which can create communication bottlenecks and increase energy use. This paper introduces NashDQNSleep , a novel decentralized sleep scheduling algorithm that uniquely combines game-theoretic modeling with deep reinforcement learning to address these challenges. Unlike conventional DQN approaches that optimize node behavior independently or centrally, NashDQNSleep formulates the scheduling problem as a general-sum stochastic game and uses Deep Q-Networks (DQNs) to compute Nash equilibria. This enables sensor nodes to make autonomous, yet strategically coordinated decisions based on peer-to-peer information exchange, achieving a stable and efficient balance between energy consumption and data freshness without centralized control. Extensive simulations on diverse IIoT network topologies demonstrate that NashDQNSleep improves energy efficiency by up to 35%, reduces Age of Information (AoI) by 40%, and increases successful data transmissions by 15%–20% compared to state-of-the-art decentralized and centralized methods. These results establish NashDQNSleep as an effective, scalable, and practical solution for reliable and sustainable IIoT operations.},
  archive      = {J_EAAI},
  author       = {Partha Sarathi Banerjee and Soumyapriya Goswami and Debashis De},
  doi          = {10.1016/j.engappai.2025.112210},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112210},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {NashDQNSleep: Nash-based deep Q-network adaptive sleep scheduling for energy efficiency and age of information optimization in industrial internet of things},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel contrastive learning framework for multi-parameter optimization in 3D printing. <em>EAAI</em>, <em>161</em>, 112209. (<a href='https://doi.org/10.1016/j.engappai.2025.112209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive manufacturing (3D printing) revolutionizes prototyping and production through unparalleled material efficiency. However, part quality remains highly sensitive to parameter variations, where subtle deviations induce defects, material waste, and process instability. Traditional quality control methods – reliant on rule-based heuristics or manual inspections – fail to address complex multi-parameter interactions and fine-grained anomalies, limiting industrial scalability. This article focuses on an important issue in 3D printing: How can we develop a robust, automated framework to simultaneously detect and classify subtle multi-parameter anomalies in 3D printing, overcoming the limitations of manual and single-defect-focused approaches? We propose a supervised contrastive learning framework integrating Vision Transformers (ViT) to learn discriminative feature representations for multi-parameter optimization. By maximizing intra-class similarity and inter-class separation, our model captures nuanced variations across printing scenarios. The ViT architecture processes real-time printing images, while contrastive loss ensures compact feature clusters for “Low”, “Optimal”, and “High” parameter classes. Experimental evaluations on open-source datasets demonstrate our framework achieves 8.45% accuracy, outperforming conventional CNNs by 10.11%. Real-world validation shows robust performance across critical parameters: flow rate (86.5% accuracy in nominal ranges), feed rate (87% accuracy), and extrusion temperature (90% accuracy at optimal settings). The ViT’s self-attention mechanism enables precise detection of localized anomalies, such as under-extrusion and layer misalignment.},
  archive      = {J_EAAI},
  author       = {Jieyang Peng and Simon Kreuzwieser and Dongkun Wang and Andreas Kimmig and Zhi Fan and Jianing Li and Jivka Ovtcharova},
  doi          = {10.1016/j.engappai.2025.112209},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112209},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel contrastive learning framework for multi-parameter optimization in 3D printing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight model based on multi-scale feature fusion for ultrasonic welding surface defect detection. <em>EAAI</em>, <em>161</em>, 112208. (<a href='https://doi.org/10.1016/j.engappai.2025.112208'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasonic welding technology is crucial in industrial and medical fields, relying on precise surface defect detection for quality assurance. Traditional methods suffer from low accuracy, efficiency, high costs, and complex implementation. Additionally, current neural networks for ultrasonic surface defect detection struggle to balance parameter optimization with detection accuracy. To solve this problem, we proposed a lightweight model based on multi-scale feature fusion for the Ultrasonic Weld Surface Defect Detection Network (UWSDNet). First, the feature extraction module with reparameterization technology (FRT) and application of efficient multi-scale attention (EMA) are proposed to alleviate network redundant parameters and computational overhead brought by welding background. Secondly, the multi-core feature enhancement module (MCM) is introduced. It enhances multi-scale object detection with fewer parameters to cope with the actual edge deployment of ultrasonic welding. Finally, the lightweight asymmetric detection head (LADH) and contextual and spatial feature calibration network (CSFCN) are introduced into the network. To improve the multi-core dimensional feature capture capability, to solve the problem of large size span of ultrasonic welding surface defects. Experimental evaluations on a self-built ultrasonic welding wire harness defect dataset show that UWSDNet achieves the mean average precision (mAP) of 88.9%, the precision of 95.6% with parameters of 12.7M. In addition, UWSDNet achieves excellent performance on the publicly available NEU-DET dataset, demonstrating strong generalization and application potential in industrial defect detection.},
  archive      = {J_EAAI},
  author       = {Rui Liu and Lun Zhao and Yu Ren and Zhonghua Shen and Liya Li and Jianfeng Luo and Zeshan Abbas},
  doi          = {10.1016/j.engappai.2025.112208},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112208},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight model based on multi-scale feature fusion for ultrasonic welding surface defect detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial neural network solution for magnetohydrodynamic ternary hybrid second-grade nanofluid in rotating jeffery-hamel flow under heat generation: Entropy generation analyses. <em>EAAI</em>, <em>161</em>, 112207. (<a href='https://doi.org/10.1016/j.engappai.2025.112207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research-work examines entropy generation in Magnetohydrodynamic (MHD) ternary hybrid nanofluid under rotating Jeffery-Hamel flow with heat generation alongside thermal radiation. Using appropriate similar transformation equations, the original partial differential equations (PDEs) are converted into nonlinear ordinary differential equations (ODEs), while Artificial Neural Networks (ANNs), which highly extensively used as universal function approximators, is considered in this investigation. In fact, to provide efficient solutions for the nonlinear transformed problem of the magnetohydrodynamic ternary hybrid second-grade nanofluid in rotating Jeffery-Hamel flow, solvers consider log-sigmoid, radial basis and tan-sigmoid activation functions, optimized with an interior point method to generate optimal weights of each considered ANN model. The model relies on assumptions of incompressible steady flow together with negligible viscous energy loss and usage of Rosseland radiation approximation. The predictions made through the Artificial Neural Network (ANN) match numerical benchmarks successfully thus demonstrating better accuracy when modeling velocity, temperature and entropy profiles. The research data indicates that systems attaining better thermal qualities operate effectively under elevated nanoparticle levels and radiation conditions which provides fundamental knowledge to enhance thermal system design. The results from the proposed schemes match numerical solutions precisely thus showing their high accuracy for evaluating ternary hybrid nanofluid flow and heat behavior. Results show that the velocity and temperature profiles of the Magnetohydrodynamic (MHD) ternary hybrid nanofluid reveal significant improvements at higher thermal volume fractions of nanoparticles. The rate of flow increases, perhaps because inertial forces prevail over viscous forces, thereby improving flow dynamics. With higher Radiation numbers associated with higher permeability, the local temperature gradients decrease promoting heat transfer rates within the fluid.},
  archive      = {J_EAAI},
  author       = {Nouar Ahcene and Amar Dib and Farhan Lafta Rashid and Kezzar Mohamed and Mohamed Rafik Sari and Manal Elzain and Hamiden Abd El-Wahed Khalifa},
  doi          = {10.1016/j.engappai.2025.112207},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112207},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial neural network solution for magnetohydrodynamic ternary hybrid second-grade nanofluid in rotating jeffery-hamel flow under heat generation: Entropy generation analyses},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent compound fault decoupling of rolling bearing based on parallel capsule network. <em>EAAI</em>, <em>161</em>, 112206. (<a href='https://doi.org/10.1016/j.engappai.2025.112206'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complex working environment of rolling bearings, various components such as inner ring, outer ring, rolling element and cage in bearing may interact with each other, leading to a compound fault formed by a variety of single fault coupling. Most methods generally regard compound faults as single faults, ignoring the interaction between single faults, which is not conducive to decoupling compound faults into multiple single faults and formulating maintenance plans. Moreover, the capsule network requires stacking multiple capsule layers to enhance performance, which significantly increases model parameters and consumes substantial memory resources. Therefore, a compound fault intelligent decoupling method based on parallel capsule network combining dynamic routing and attention routing is proposed in this study. Firstly, the Omni-Scale block is added to the feature extraction part, which can cover different sizes of receptive fields to enhance the feature extraction ability of the network. Secondly, an attention routing module is proposed, which realize the transmission of information from low-level capsules to high-level capsules by calculating the correlation between the same layers. Finally, the parallel capsule decoupling layer is constructed by using dynamic routing and attention routing. This method is especially suitable for practical engineering scenarios where compound bearing fault samples are limited and computational resources are constrained, providing a lightweight and effective solution for intelligent fault diagnosis. Experimental results show that the proposed method significantly reduces model complexity while maintaining high diagnostic performance under small-sample conditions, with the ablation study further confirming the meaningful contribution of each core module.},
  archive      = {J_EAAI},
  author       = {Renwang Song and Chenyu Jiao and Hui Shi and Linying Chen},
  doi          = {10.1016/j.engappai.2025.112206},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112206},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent compound fault decoupling of rolling bearing based on parallel capsule network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning-based strategic bidding in electricity markets via variational autoencoder-assisted competitor behavior learning. <em>EAAI</em>, <em>161</em>, 112205. (<a href='https://doi.org/10.1016/j.engappai.2025.112205'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a deregulated electricity market, self-interested producers have incentives to offer strategically for maximizing their own profits. While deep reinforcement learning (DRL) has shown great potential for solving such strategic bidding problems, existing methods typically oversimplify strategic action spaces and neglect the influence of competitors' offering behaviors. To bridge these gaps, this paper proposes a novel DRL-based framework to model and solve the strategic bidding problem of an individual producer by jointly considering price-quantity offering actions and the dynamic behaviors of market competitors. First, a bilevel optimization model is formulated to incorporate offering actions on price-quantity pairs. Then, a data-driven framework that combines a variational autoencoder with a density-based clustering method is proposed to learn and capture competitors' offering behaviors. Finally, an imitation learning-integrated DRL algorithm is developed to improve learning stability and solution quality for strategic bidding with price-quantity actions and competitors' offering behaviors. Case studies on the IEEE-30 bus system show that the proposed framework obtains a 28.12 k$ (24.25 %) increase in average profit compared to the existing approach, demonstrating its effectiveness and adaptability under dynamic market conditions.},
  archive      = {J_EAAI},
  author       = {Fei Hu and Yong Zhao and Yaowen Yu and Yuanzheng Li},
  doi          = {10.1016/j.engappai.2025.112205},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112205},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement learning-based strategic bidding in electricity markets via variational autoencoder-assisted competitor behavior learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep-supervised framework utilizing edge features and global texture features for distortion rectification in fisheye images. <em>EAAI</em>, <em>161</em>, 112204. (<a href='https://doi.org/10.1016/j.engappai.2025.112204'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fisheye cameras, with their ultra-wide field of view, are increasingly deployed in urban environments. However, the severe radial distortion inherent in fisheye imagery presents formidable challenges for downstream computer vision tasks, including object recognition, motion estimation, and semantic segmentation. To address this issue, a deeply supervised framework for distortion rectification that leverages edge features and global texture information (DR-EGT) is proposed, which uniquely integrates edge-aware structural features with global texture information under a unified deep supervision strategy. Unlike conventional approaches that rely solely on texture priors or geometric assumptions, DR-EGT introduces a hierarchical supervision mechanism that simultaneously leverages low-level edge contours and high-level texture semantics to guide the distortion correction process. This joint supervision enables the network to learn the distortion flow field of the entire image, which facilitates the reconstruction of geometrically accurate and perceptually sharp undistorted images. On the Places2 dataset, DR-EGT outperforms existing advanced methods, achieving a 12.12 % increase in PSNR (Peak Signal-to-Noise Ratio), 7.44 % improvement in SSIM (Structural Similarity Index Measure), 16.42 % reduction in MAE (Mean Absolute Error), and a 78.17 % gain in FID (Fréchet Inception Distance), demonstrating its superior reconstruction fidelity and perceptual quality. The results demonstrate the ability of DR-EGT not only correct complex fisheye distortion but also suppress post-correction artifacts and visual degradation.},
  archive      = {J_EAAI},
  author       = {Yicheng Chen and Shuang Li and Yuhuan Gu and Chang Feng and Changhai Zhai},
  doi          = {10.1016/j.engappai.2025.112204},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112204},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep-supervised framework utilizing edge features and global texture features for distortion rectification in fisheye images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectrum prior-based and visibility fusion method for underwater image enhancement. <em>EAAI</em>, <em>161</em>, 112203. (<a href='https://doi.org/10.1016/j.engappai.2025.112203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When light propagates in water, it undergoes scattering and absorption phenomena, which typically result in haze, high blur, low contrast and color distortion, making it extremely challenging to obtain high-quality images. To address these issues, many existing methods target image enhancement by correcting specific aspects such as color shift or contrast. However, challenges like poor visibility and low-light conditions are often overlooked. In this paper, we proposed a spectrum prior-based and visibility fusion method (SPV) to enhance underwater images in terms of color, contrast, and visibility. Unlike existing methods, SPV complements the advantages of both physical and non-physical models, comprehensively addressing the problems of reduced visual visibility, color distortion, and low contrast caused by low-light environments, thereby significantly improving the overall image quality. We proposed a dehazing module based on spectral information priors, which reliably restores image quality under complex water conditions. Additionally, we introduced a color correction module based on human color perception and employed morphological operations, effectively solving the issues of color shift and unclear contours in underwater images. Furthermore, we proposed a visibility enhancement module based on the fuzzy c-means clustering method to improve image contrast and visibility, particularly under low-light conditions. Finally, through a detail enhancement fusion module, we simultaneously addressed problems related to color shift, low contrast, and low visibility. SPV showed excellent performance in application tests including feature point matching, geometric rotation estimation, and edge detection. Comparative experiments on four real underwater datasets against 14 advanced enhancement methods demonstrated promising results.},
  archive      = {J_EAAI},
  author       = {Qifeng Liu and Xin Yan and Lu Shen and Qiang Li},
  doi          = {10.1016/j.engappai.2025.112203},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112203},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spectrum prior-based and visibility fusion method for underwater image enhancement},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated multi-criteria decision-making approach with unknown weight information under probabilistic dual-hesitant pythagorean fuzzy environment and its application to supplier selection. <em>EAAI</em>, <em>161</em>, 112202. (<a href='https://doi.org/10.1016/j.engappai.2025.112202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preference ranking organization method for enrichment evaluation (PROMETHEE) has been proved to be one of the most effective techniques to rank alternatives of multi-criteria decision-making (MCDM) problems. However, the existing PROMETHEE cannot accurately adjust the representation range of uncertain information. Besides, the weight determination in PROMETHEE heavily relies on the decision matrix of alternatives on the criteria. Moreover, the information aggregation in PROMETHEE models lacks consideration of the interrelationship among criteria. To address the aforementioned shortcomings, this paper introduces a novel MCDM method that integrates the best-worst method (BWM) and PROMETHEE to help the decision-maker (DM) select the optimum alternative under the probabilistic dual-hesitant Pythagorean fuzzy (PDHPF) environment. Firstly, we extend PROMETHEE method to PDHPF scenario, which not only helps the DM depict subjective evaluations, but also provides the DM with a laxer constraint to present decision information. Secondly, the PDHPF power weighted Hamy mean operator (PDHPFPWHM) is utilized to aggregate the preference information of PROMETHEE. Additionally, the BWM method is utilized and extended to the PDHPF environment for acquiring optimal weights of criteria. The high efficiency and consistency of BWM are well-suited for the complex PDHPF environment. Finally, the method is applied to a semiconductor supplier selection case to demonstrate the validity, superiority, and feasibility of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Huzhi Xue and Haihua Xie and Butian Zhao and Jun Wang},
  doi          = {10.1016/j.engappai.2025.112202},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112202},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An integrated multi-criteria decision-making approach with unknown weight information under probabilistic dual-hesitant pythagorean fuzzy environment and its application to supplier selection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach for understanding the parking demand for internal access roads in hub car parks. <em>EAAI</em>, <em>161</em>, 112201. (<a href='https://doi.org/10.1016/j.engappai.2025.112201'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hubs serve as pivotal nodes within urban transport networks, and the car parks associated with these hubs constitute an integral component. The prevalent practice in China of utilizing internal access roads within car parks for passenger pick-up by online car-hailing vehicles has engendered a novel category of parking demand. However, this development presents a significant challenge to the efficient operation of hub car parks. A thorough analysis and comprehension of the parking demand for internal access roads is essential in devising suitable management strategies to enhance parking efficiency. Initially, this study categorizes the parking demand for internal access roads into three distinct groups, applying parking duration and the number of entries as classification criteria. Subsequently, considering the number of train frequencies, the categorized parking demands are forecasted independently utilizing the Long Short-Term Memory (LSTM) model, complemented by the Shapley Additive exPlanations (SHAP) method for model interpretation. Ultimately, Vector Autoregression (VAR) is employed to investigate the interaction mechanism between the parking demand for parking spaces and the parking demand for internal access roads. The findings indicate that optimal predictive performance is attained when employing a time interval of 15 min and an input step size of 4. Competition between the parking demand for internal access roads and the parking demand for parking spaces primarily occurs within respective categories, underscoring the need for external interventions when these demands are imbalanced.},
  archive      = {J_EAAI},
  author       = {Qianyi Hu and Weidong Liu and Chenyu Yan and Chu Zhang and Jun Chen and Changyin Dong},
  doi          = {10.1016/j.engappai.2025.112201},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112201},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel approach for understanding the parking demand for internal access roads in hub car parks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning for disease-specific prediction of high-cost patients. <em>EAAI</em>, <em>161</em>, 112200. (<a href='https://doi.org/10.1016/j.engappai.2025.112200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-cost patients incur disproportionately high medical expenses, and identifying them proactively is crucial for effective healthcare management. While previous research has focused on identifying high-cost patients based on overall expenditure, there has been a lack of studies analyzing them in the context of specific diseases. This study addressed this gap by leveraging data from the National Health Insurance Service (NHIS) of South Korea, spanning 2015 to 2019, to develop predictive models for identifying these patients. We trained models using data from 880,000 individuals to predict high-cost patients in 2019 using resource-efficient machine learning algorithms such as Extreme Gradient Boosting (XGBoost), Random Forest (RF), and Neural Networks (NN) that minimize computational overhead, with undersampling techniques applied to handle data imbalance. We focused on the six major disease categories that account for the highest medical expenditures in South Korea: diseases of the musculoskeletal system (DMS), circulatory system (DCS), eye and ear (DEA-DEM), digestive system (DDS), genitourinary system (DGS), and respiratory system (DRS). We discovered that disease-specific analyses revealed important predictive factors that were not apparent in aggregate analyses. For example, hemoglobin levels emerged as crucial predictors for DCS, while body mass index (BMI) proved essential for DMS prediction. These findings enhance our understanding of the factors contributing to high medical costs and provide a foundational framework for healthcare providers and policymakers to develop more targeted and effective health management strategies.},
  archive      = {J_EAAI},
  author       = {Inwoo Tae and Hyeongwoo Kong and Junghye Lee and Yongjae Lee},
  doi          = {10.1016/j.engappai.2025.112200},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112200},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning for disease-specific prediction of high-cost patients},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing mean conditional value-at-risk portfolios through deep neural network stock prediction. <em>EAAI</em>, <em>161</em>, 112198. (<a href='https://doi.org/10.1016/j.engappai.2025.112198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio optimization is essential in financial decision-making, requiring a balance between risk minimization and return maximization. Effective stock selection significantly influences portfolio performance. Traditional methods often struggle to effectively integrate advanced risk assessment techniques with stock selection. To enhance portfolio diversification and improve risk-adjusted returns, this study integrates deep learning-based stock selection with the mean conditional Value-at-Risk (MCVaR) model and entropy constraints to enhance portfolio diversification and risk-adjusted returns. Various deep neural networks, including Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), Multi-Layer Perceptrons (MLP), and Radial Basis Function Neural Networks (RBFN), are employed to rank stocks based on risk and return characteristics. The top-ranked stocks with the lowest risk are selected for portfolio construction. The entropy constraint is introduced to prevent excessive weight concentration, ensuring a well-diversified portfolio. Historical datasets from the Bombay Stock Exchange (BSE), India, B3 Stock Exchange, Brazil, and Shanghai Stock Exchange, China, are used for validation, with performance assessed on an out-of-sample dataset. Additionally, the efficacy of the suggested approach is evaluated by contrasting it with other machine learning and conventional portfolio optimization techniques. Experimental results demonstrate that the LSTM+MCVaR model with entropy constraint consistently outperforms other deep learning and conventional optimization methods, achieving superior cumulative returns and Sharpe ratios. The findings highlight the potential of combining LSTM forecasting with MCVaR optimization and entropy regularization for robust, diversified portfolio construction.},
  archive      = {J_EAAI},
  author       = {Jyotirmayee Behera and Pankaj Kumar},
  doi          = {10.1016/j.engappai.2025.112198},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112198},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing mean conditional value-at-risk portfolios through deep neural network stock prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and analysis of an unbiased intelligent recommendation system for all-rounders in cricket based on multiple criteria decision making. <em>EAAI</em>, <em>161</em>, 112197. (<a href='https://doi.org/10.1016/j.engappai.2025.112197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing and analyzing an unbiased intelligent all-rounder recommendation system in cricket is a critical and complex decision-making task, where performance prediction itself is a crucial issue. The majority of existing works on cricket focus on batsmen, bowlers, and teams. However, performance analyses of all-rounders are hardly found. Hence, the motivation of this paper is to propose an artificial intelligence (AI)-based method for assessing the performance of all-rounders utilizing various multiple-criteria decision-making (MCDM) techniques. With this goal in mind, effective attributes are considered for evaluating all-rounder bowling and batting performances. Case studies using a set of 20 all-rounders have been taken from the recent International Cricket Council (ICC) all-rounders list to determine their ranking. The performance of various MCDM techniques is investigated using ICC rankings, with the Spearman Rank Correlation Coefficient applied to the One Day International (ODI) format. The results indicate that the Criteria Importance Through Intercriteria Correlation (CRITIC)-VlseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR) method yields quite promising insights, achieving a higher correlation with ICC rankings (Spearman Rank Correlation: 0.794) and hence can be used as an intelligent AI-based all-rounder recommendation system. Finally, we have also conducted a sensitivity analysis on the ranking outcomes of all-rounders to examine the utility and robustness of our proposed MCDM approach. The proposed approach is beneficial for team selectors, analysts, and fantasy sports platforms, offering a fairer and more reliable ranking of all-rounders.},
  archive      = {J_EAAI},
  author       = {Nayan Ranjan Das and Imon Mukherjee and Goutam Paul},
  doi          = {10.1016/j.engappai.2025.112197},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112197},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design and analysis of an unbiased intelligent recommendation system for all-rounders in cricket based on multiple criteria decision making},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic analysis-based recommender system using sequential clustering and convolutional neural network. <em>EAAI</em>, <em>161</em>, 112196. (<a href='https://doi.org/10.1016/j.engappai.2025.112196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of user preferences and generation of personalized recommendations remain as critical challenges in intelligent recommendation systems. In this study, we propose a novel recommendation model that transforms the rating prediction problem into a single-label multiclass classification task. The model integrates three key components: (1) ordered clustering information derived from user review text similarity, (2) rating rank similarity reflecting users’ behavioral tendencies, and (3) a convolutional neural network (CNN) to extract semantic representations from user textual data. First, user review embeddings are clustered to capture high-level semantic preferences, where cluster indices are utilized as ordered categorical features. Second, rating rank similarity features are constructed by comparing the relative ranking of items rated by similar users. These features are fused and fed into a CNN model, which outputs a predicted rating class (e.g., 1–5 stars) for each unobserved item, treated as a single-label classification target. To generate final Top-N recommendations, we further incorporate user-specific rating habits and item popularity to re-rank the classification outputs. The experimental results on public benchmark datasets indicate that our model substantially improves the prediction accuracy and recommendation quality compared with existing baselines. The proposed method offers a robust and interpretable approach to bridging textual review semantics, user behavior, and deep learning for rating-aware personalized recommendation.},
  archive      = {J_EAAI},
  author       = {Yanjun Xu and Chunqi Tian and Wei Wang and Lizhi Bai},
  doi          = {10.1016/j.engappai.2025.112196},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112196},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semantic analysis-based recommender system using sequential clustering and convolutional neural network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ranking-oriented cross-modal hashing. <em>EAAI</em>, <em>161</em>, 112195. (<a href='https://doi.org/10.1016/j.engappai.2025.112195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep cross-modal hashing has become a mainstream solution for multimedia retrieval. Most methods utilize pair-wise or multi-wise loss as proxies for ranking consistency, focusing primarily on local relational patterns. However, these schemes are not well aligned with global ranking metrics, which consider the relative order among all candidate items. This misalignment may push semantically similar items down the list. Additionally, such methods heavily rely on the selection of negative samples, which can cause training instability and require careful tuning. To address this problem, we propose a novel Ranking-Oriented Cross-Modal Hashing (ROCMH) framework, which performs global ranking optimization based on a vision-language model. Specifically, we design a differentiable ranking-oriented objective, called cross-modal ranking alignment loss. It smoothly simulates discrete ranking and naturally models ranking relations in candidate lists, thereby promoting more consistent cross-modal ranking. Meanwhile, considering the perceptual gap between visual and textual, we suggest a nanoparam training strategy with modality-aware prompts. This strategy greatly reduces the number of trainable parameters while ensuring that each modality provides unique signals for semantic information learning. Extensive experiments on three public datasets demonstrate that the method achieves superior retrieval performance and reduces the number of trainable parameters to less than 0.2% of the vision-language model. The source code is available: https://github.com/QinLab-WFU/ROCMH .},
  archive      = {J_EAAI},
  author       = {Yadong Huo and Qibing Qin and Wenfeng Zhang and Lei Huang},
  doi          = {10.1016/j.engappai.2025.112195},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112195},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ranking-oriented cross-modal hashing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Matching quality-guided model-free satellite pose estimation. <em>EAAI</em>, <em>161</em>, 112194. (<a href='https://doi.org/10.1016/j.engappai.2025.112194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of learning-based techniques and large-scale public datasets, satellite pose estimation has seen significant progress for the past several years. However, most of current methods still rely on a known three-dimensional (3D) model of the object for the pose estimation, limiting its generalization and wide application. To this end, we propose a model-free pose estimation method, which takes as input only a set of images. The proposed method consists of two stages, i.e. the reconstruction stage and pose estimation stage, of which the former reconstructs a 3D model from the input images and the pose is estimated via two-dimensional (2D)-3D feature matching by the latter. More importantly, a matching quality guidance strategy is introduced to further improve the robustness to in-plane rotation during feature matching. Additionally, since no known 3D model is assumed, our method generalizes well to novel objects without retraining. We provide evaluation results on datasets of several satellites with different structures, which demonstrate impressive performances without known models against current methods.},
  archive      = {J_EAAI},
  author       = {Zhaoshuai Qi and Yating Liu and Yanning Zhang},
  doi          = {10.1016/j.engappai.2025.112194},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112194},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Matching quality-guided model-free satellite pose estimation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prebuilt spatiotemporal index: An exploration of efficient real-time data storage in intelligent transportation systems. <em>EAAI</em>, <em>161</em>, 112193. (<a href='https://doi.org/10.1016/j.engappai.2025.112193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread deployment of Internet of Things (IoT) devices in Intelligent Transportation Systems (ITS), real-time spatiotemporal data has grown rapidly. Hybrid data-bases have emerged as the mainstream solution for managing such data. The LSM R*-tree, which integrates Log-Structured Merge-trees (LSM-trees) for time-series ingestion and R*-trees for spatial queries, is now a widely used spatiotemporal index. However, storage schemes based on LSM R*-tree structures involve real-time index construction, leading to significant overhead and write latency. To address these challenges, this paper proposes a prebuilt index-based data storage workflow that shifts index construction ahead of data writing. This approach allows the database to directly apply the prebuilt index at write time, thereby minimizing real-time construction costs and enhancing write performance. To support index prebuild, we propose a lightweight embedding scheme, Index2Vec, specifically designed for R*-tree structures. Based on this, we extend the Transformer architecture and develop the R*-tree Prediction Network for ITS (RTPN4ITS), which achieves efficient inference on resource-constrained edge devices. Experimental results show that the prebuilt R*-tree index improves query efficiency by up to 90% over time-index-only schemes and enhances write performance by nearly 50% compared to real-time indexing. The proposed RTPN4ITS model achieves robust accuracy across varying traffic densities, reaching 85% accuracy in dense conditions. Moreover, the Index2Vec embedding enhances the Transformer’s structural awareness. In summary, this paper proposes an efficient prebuilt indexing strategy and lightweight embedding-based model for real-time spatiotemporal data management in ITS.},
  archive      = {J_EAAI},
  author       = {Yiran Shao and Kangshuai Zhang and Yong Zhou and Zhenwu Chen and Yang Yang and Lei Peng},
  doi          = {10.1016/j.engappai.2025.112193},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112193},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prebuilt spatiotemporal index: An exploration of efficient real-time data storage in intelligent transportation systems},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An error complementarity-based iterative learning approach via categorical boosting for student performance prediction. <em>EAAI</em>, <em>161</em>, 112192. (<a href='https://doi.org/10.1016/j.engappai.2025.112192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting student performance is important in achieving academic success and student development in many educational applications (e.g., academic early warning and early interventions). To accurately predict student performance, we propose an error complementarity-based iterative learning approach for student performance prediction. Our goal is to improve the prediction performance by iteratively reducing the prediction error. Specifically, in model construction, we first select the most important features to train the target estimator. Then, we obtain the errors between the target and predicted values. These errors are used to train the error estimator using the remaining features. Similarly, we iteratively train the model to learn from the errors until the desired conditions are met. In model prediction, we predict the testing sample using the target estimator to obtain the predicted value. Next, we predict the error for the next iteration using the corresponding error estimator. This process is repeated, and the final prediction is obtained by adding the predicted value and the error values. The extensive experiments from different educational datasets show that by using our error complementarity-based iterative learning approach, the proposed model outperforms the competing models for prediction accuracy. Furthermore, statistical testing conducted over 20-run experiments confirms the significant advantage of our proposed model. This suggests the iterative learning is effective for predicting student performance.},
  archive      = {J_EAAI},
  author       = {Zongwen Fan and Jin Gou and Cheng Wang},
  doi          = {10.1016/j.engappai.2025.112192},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112192},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An error complementarity-based iterative learning approach via categorical boosting for student performance prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated cross-device cluster dynamic time planning warping algorithm in the industrial internet of things. <em>EAAI</em>, <em>161</em>, 112191. (<a href='https://doi.org/10.1016/j.engappai.2025.112191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Production lines and heterogeneous devices generate diverse time-series data in the Industrial Internet of Things (IIoT). This diversity necessitates frequent updates of local models when using federated learning (FL). FL has become widespread in the IIoT, these continual model updates can hinder timely information exchange among cross-industry devices. They constrain the system's ability to handle high concurrency in read and write operations. Therefore, we propose a federated cross-device cluster dynamic time planning warping (Fed-cDTW) tailored for the IIoT. We incorporate each device's historical behavior data by constructing a functional characteristic distance matrix. We design a symmetric time warping lower bound function to measure the similarity among multi-source time-series data. This approach enables an adaptive, dynamically organized industrial device cluster. Meanwhile, we employ the federated dynamic (FedD) dual-weight optimization within the device cluster to enhance the models' generalization and robustness. The experimental results evaluated the performance of the proposed method. We compare our method with baselines, Fed-cDTW improves classification accuracy by 0.8 percentage points (pp), 1.7 pp, 9.6 pp, 14.4 pp, and 49.5 pp. Convergence is accelerated by 0.04, 0.05, 0.35, 0.42, and 0.46. Total communication cost is reduced by 40 megabytes (MB), 56 MB, 84 MB, 120 MB, and 168 MB.},
  archive      = {J_EAAI},
  author       = {Yifan Zhao and Shibao Sun and Pengcheng Zhao and Yatong Wang and Jianfeng Liu},
  doi          = {10.1016/j.engappai.2025.112191},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112191},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Federated cross-device cluster dynamic time planning warping algorithm in the industrial internet of things},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based prediction of compressive strength in sustainable self-compacting concrete. <em>EAAI</em>, <em>161</em>, 112190. (<a href='https://doi.org/10.1016/j.engappai.2025.112190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance and durability of conventional concrete (CC) is significantly influenced by supplementary cementitious materials (SCMs) and recycled coarse aggregate (RCA). Thus, the intrusion of enrich SCMs with RCA in the cementitious matrix delivers utmost properties. This research focuses on the use SCMs and RCA in the self-compacting concrete (SCC) system and their sustainability in the development of concrete resources. Standard experimental methods for forecasting the compressive strength (CS) of SCC have constraints in terms of efficiency, time consumption, and cost. Thus, its prediction is crucial without the need for laborious experimental procedures. This work employs and evaluates a multiplicity of machine learning (ML) models to predict the CS of the cementitious matrix to tackle these issues. Thus, considered a more effective and cost-saving solution in comparison with traditional approaches. Therefore, ML approaches like, gene expression programming (GEP), decision trees (DT), and support vector regression (SVR) were employed. The performance of the model is evaluated by employing the coefficient of determination (R 2 ), statistics, and uncertainty analysis. Individual Conditional Expectation (ICE), and Partial Dependence Plot (PDP) are used to analyze the effect of parameters on strength. The findings suggest that GEP performs best achieving superior R 2 > 0.90 for the training, validation, and test data sets with a lower error. While, the uncertainty analysis shows that all modeled values lie below the threshold value. The ICE and PDP graphs confirms that cement, age, and water-cement ratio have highly relation to outcomes. The RCA replacement ratio is more important than the CA one, and SCMs play an essential role in the development of concrete compressive strength, although not as much as cement. In addition, SP depicts major contribution to SCC. Moreover, graphical user interface (GUI) is also developed to help users/researcher that will facilitate them to estimate the strength of SCC in practical applications.},
  archive      = {J_EAAI},
  author       = {Jingguo Gou and Athar Zaman and Furqan Farooq},
  doi          = {10.1016/j.engappai.2025.112190},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112190},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning-based prediction of compressive strength in sustainable self-compacting concrete},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust fuzzy twin support vector machine with kernel-target alignment for binary classification. <em>EAAI</em>, <em>161</em>, 112189. (<a href='https://doi.org/10.1016/j.engappai.2025.112189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many algorithms similar to the twin version of the support vector machine and their variants have shown better results in the binary classification of nonlinear data points. But in the presence of outlier and noise, these algorithms exhibit low generalization efficiency. To alleviate this challenge, recently proposed, kernel-target alignment based fuzzy least square twin bounded support vector machine (KTA-FLSTBSVM) used fuzzy membership values and is solved using least squares. Inspired by this strategy, for further improvement, we propose a novel approach called decision support kernel-target alignment based fuzzy least square twin bounded support vector machine (DS-KFIFTBSVM). DS-KFIFTBSVM considers the kernelized fuzzy membership values with the regularized twin support vector machine and solves for linear and nonlinear data points using a functional iterative approach. In DS-KFIFTBSVM, the solution is obtained by solving a linearly convergent iterative scheme rather than solving quadratic programming problems. The proposed DS-KFIFTBSVM offers better generalization efficiency, which has been evaluated using both linear and Gaussian kernels, mostly on artificially developed and publicly accessible datasets with diverse dimensionalities. In terms of various performance evaluation metrics, including specificity, precision, false positive rate, rate of misclassification error, F_score, and geometric mean in linear and non-linear cases, DS-KFIFTBSVM outperforms various baseline approaches. It shows the highest accuracy in various datasets, including 98.1884 % for musk dataset (linear kernel) and 100 % for the glass dataset (Gaussian kernel). Further statistical analysis confirms its classification efficiency.},
  archive      = {J_EAAI},
  author       = {Deepak Gupta and Barenya Bikash Hazarika and Umesh Gupta and Witold Pedrycz},
  doi          = {10.1016/j.engappai.2025.112189},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112189},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust fuzzy twin support vector machine with kernel-target alignment for binary classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive assessment of pore-scale segmentation techniques for image-based multiphase flow characterization in porous media. <em>EAAI</em>, <em>161</em>, 112188. (<a href='https://doi.org/10.1016/j.engappai.2025.112188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation of multiphase fluid flow behavior based on pore-scale imaging is significantly influenced by the accuracy of the segmentation techniques. This study sheds light on the influence of various traditional and Artificial Intelligence (AI) algorithms on the major static, dynamic, volumetric, and topological properties of the porous media. The traditional methods include the Gaussian Mixture Model (GMM), Multi-Otsu’s thresholding (MOT), and Random Walk (RW), and the AI-based techniques include Trainable Weka (TW), as well as seven deep convolutional autoencoder architectures. The assessment was carried out by comparing the calculated phase fraction, contact angle, capillary pressure, effective permeability, and topology for multiphase flow images of Bentheimer sandstone. The results revealed that combining Residual Networks (ResNet) and UNet structures (UResNet) marginally performs better based on the statistical metrics. Compared to ground-truth watershed images, applying other approaches except TW yielded acceptable static and volumetric parameters. The main discrepancies were in contact angles, capillary pressure, and phase topology. These discrepancies also influenced calculated effective permeabilities, yielding unrealistic trends. UResNet provided the best accuracy, considering the watershed the ground truth. MOT and RW showed similar performance, while GMM performed inconsistently throughout the analysis and TW produced acceptable results for certain fractional flows. The segmentation approaches affected topological features most, whereas properties such as phase fractions were less affected. The inconsistent behavior and effectiveness of used algorithms indicate that the analysis of multiphase images necessitates a meticulous choice of segmentation techniques, emphasizing AI-based algorithms that ensure consistency across all evaluations.},
  archive      = {J_EAAI},
  author       = {Javad Siavashi and Mohammad Sharifi},
  doi          = {10.1016/j.engappai.2025.112188},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112188},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comprehensive assessment of pore-scale segmentation techniques for image-based multiphase flow characterization in porous media},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Land use and land cover change detection from multisource satellite imagery – A hybrid convolutional neural network approach. <em>EAAI</em>, <em>161</em>, 112187. (<a href='https://doi.org/10.1016/j.engappai.2025.112187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing and satellite imagery analysis enable us to observe and understand environmental changes over time. However, such an endeavor can be complex and time-consuming. To overcome this challenge, we propose a framework for leveraging Google Earth Engine (GEE) to analyze Earth's surface changes over time. Our framework starts by assessing land cover changes using satellite imagery, evaluating the effectiveness of vegetation indices in classification, and generating accurate land cover maps for a specific region. We examine the validity of this framework on the area near Rio Do Sul, located in the Santa Catarina district of Brazil, to classify and recognize the alteration in land use and land cover (LULC) from 2019 to 2023. In this effort, we develop a pre-trained Convolutional Neural Network (CNN) for feature extraction from the Landsat 8, Sentinel-1, and Sentinel-2 images and then link those into the random forest (RF) algorithm for spatial morphology and temporal change logic to map the long-term annual time series and detect changes in the region at hand. The novelty of this study arises from developing a CNN-RF hybrid model and implementing a data preprocessing pipeline, which includes progressive techniques for cloud masking and radiometric calibration, to ensure higher accuracy and reliability in land use and land cover classification. This CNN-RF hybrid model successfully traced the increasing and decreasing rate in the built-up area, water bodies, forest, fallow land, plantations, and grassland with an overall accuracy of 96.39 % and 94.15 % for 2019 and 2023, respectively.},
  archive      = {J_EAAI},
  author       = {M.S. Babitha and A. Diana Andrushia and N. Anand and M.Z. Naser and Y. Pari},
  doi          = {10.1016/j.engappai.2025.112187},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112187},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Land use and land cover change detection from multisource satellite imagery – A hybrid convolutional neural network approach},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safety monitoring digital twin-based centralized model consolidation mechanism using dynamic node selection for multi-worker safety prediction. <em>EAAI</em>, <em>161</em>, 112186. (<a href='https://doi.org/10.1016/j.engappai.2025.112186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction industry remains one of the most hazardous sectors, requiring innovative solutions to safeguard workers, especially in complex, dynamic outdoor environments. Digital Twin (DT) technology offers promising capabilities for real-time safety monitoring through virtual replicas of physical systems. However, existing DT frameworks rarely integrate comprehensive safety monitoring via a centralized model consolidation mechanism, such as Federated Learning (FL), which is explicitly tailored for multi-worker scenarios. Addressing this challenge, this paper proposes a FL-based Safety Monitoring Digital Twin (SMDT) framework designed to enhance multi-worker safety in resource-constrained settings. This enables real-time safety monitoring and control by representing on-site workers as virtual objects within a synchronized DT environment. A dynamic node selection mechanism based on client performance is employed to optimize global model convergence in FL. To validate the proposed approach, an edge computing-based experimental testbed using actual Raspberry Pi devices was implemented, using real-world construction safety data including worker status, weather conditions, and building structural parameters. Experimental results demonstrate the effectiveness of the proposed framework in significantly improving safety predictions and real-time monitoring efficiency. This research establishes a foundational work towards safer construction sites through intelligent, synchronized safety monitoring systems.},
  archive      = {J_EAAI},
  author       = {Sa Jim Soe Moe and Atif Rizwan and Anam Nawaz Khan and Rongxu Xu and Do Hyeun Kim},
  doi          = {10.1016/j.engappai.2025.112186},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112186},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Safety monitoring digital twin-based centralized model consolidation mechanism using dynamic node selection for multi-worker safety prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Universal entity linking. <em>EAAI</em>, <em>161</em>, 112185. (<a href='https://doi.org/10.1016/j.engappai.2025.112185'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity linking is a process of connecting mentions of entities in a document to corresponding entries in a knowledge base. Traditional models for entity linking often require specific fine-tuning to work with knowledge bases other than those they were originally pretrained on, which limits their flexibility and scalability. Building on the concept of entity profile generation, we propose a novel approach that enables entity linking across various knowledge bases without the need for such fine-tuning. Our pipeline leverages a fine-tuned Large Language Model, a generic embedding model, and a vector store to achieve high precision on the TweekiGold and Reuters-128 datasets. Additionally, it demonstrates strong retrieval rates across the TweekiGold , Reuters-128 , and ISTEX-1000 Wikidata entity linking datasets. We also illustrate the applicability of our method to other knowledge bases, using the Agrovoc knowledge base as an example. This solution offers a more versatile and scalable approach to entity linking.},
  archive      = {J_EAAI},
  author       = {Adam Aron Rynkiewicz and Raul Palma and Piotr Formanowicz},
  doi          = {10.1016/j.engappai.2025.112185},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112185},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Universal entity linking},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A search method for fractured-vuggy reservoir inter-well connectivity path based on multi-modal multi-agent. <em>EAAI</em>, <em>161</em>, 112184. (<a href='https://doi.org/10.1016/j.engappai.2025.112184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex geological structure of carbonate reservoirs and the intricate fracture-vuggy configurations obscure inter-well connectivity, making its evaluation challenging. Conventional studies primarily rely on seismic static data to delineate fracture-vuggy reservoirs, but the limited recognition accuracy hampers the precise characterization of inter-well connectivity and the spatial configuration of fractures and vugs. To address this, this study constructs a 3D (Three-Dimensional) search environment and use multi-modal static and dynamic data and proposes a multi-agent connected channel search model based on deep reinforcement learning. The model treats multiphase fluid as an agent and incorporates Swin Transformer (Shift Window Transformer) to extract large-scale fracture features from seismic data, providing global prior information for path search. A Graph Attention Network is established based on dynamic response relationships to extract spatial geological features, while a multi-head self-attention mechanism captures real-time fluid interactions in various directions. The model fuses multi-modal features, including seismic attributes and production data, to generate decisions and automatically search for inter-well connectivity channels. Experiments were conducted using the WE1 and WE5 well groups from the fault-controlled karst reservoirs in the Tahe oilfield, with results compared against tracer tests. The findings demonstrate that the proposed model's automatic search paths closely align with seismic data and tracer test results, effectively capturing the spatial distribution of fractures and vugs across different scales. This validates the model's effectiveness in evaluating inter-well connectivity in complex carbonate reservoirs.},
  archive      = {J_EAAI},
  author       = {Wenbin Jiang and Dongmei Zhang and Hong Cao and Xiaofeng Wang},
  doi          = {10.1016/j.engappai.2025.112184},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112184},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A search method for fractured-vuggy reservoir inter-well connectivity path based on multi-modal multi-agent},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continuous spatio temporal prompts for visual tracking. <em>EAAI</em>, <em>161</em>, 112183. (<a href='https://doi.org/10.1016/j.engappai.2025.112183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, visual single-object tracking methods utilize online template updates to combine temporal information. However, these methods rely on confidence scores to evaluate the reliability of the current template, which may result in a template not being updated for an extended period. Moreover, advanced trackers select bounding boxes based solely on the similarity between the template and the search area, which can lead to tracking drift when encountering deformable or similar targets. To alleviate these limitations, we propose a Spatio Temporal Prompt Tracker (STPTrack), which utilizes the prior information about small changes of object state between successive frames. Different from previous tracking methods that mainly rely on templates and similarity scores, STPTrack transfers the object position and shape information of the previous frame to the current frame as continuous spatio temporal prompt for the first time, and realizes the efficient fusion of spatio temporal information through the prompt encoder and the fusion decoder module. Specifically, it encodes the bounding box coordinates or mask information of the previous frame and the response points of the current frame as prompt features, and then combines prompt tokens with search tokens through the fusion decoder to provide the potential location of the object for the search feature map. Our STPTrack sets a new state-of-the-art performance on six tracking benchmark datasets.},
  archive      = {J_EAAI},
  author       = {Meng Sun and Xiaotao Liu and Yifan Li and Hongyu Wang and Dian Yuan and Jing Liu},
  doi          = {10.1016/j.engappai.2025.112183},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112183},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Continuous spatio temporal prompts for visual tracking},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Length-aware center loss for sequence to sequence thai scene text recognition. <em>EAAI</em>, <em>161</em>, 112182. (<a href='https://doi.org/10.1016/j.engappai.2025.112182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thai scene text recognition is a challenging task because Thai can be written in both horizontal and vertical directions, allowing characters to be stacked vertically. To address this issue, our previous work combined vertically stacked characters to create new characters. However, this strategy introduced many similar characters. In this paper, we further investigate this problem and propose the Length-aware Center Loss (LC) for Thai scene text recognition. The original center loss was designed for single object recognition tasks. When applied to multi-label tasks like text recognition, center loss is only effective when the lengths of the labels and prediction results are consistent. This can lead to an extreme case where all images receive incorrect predicted text lengths to minimize loss, severely interfering with the recognition process. Therefore, we propose the Length-aware Center Loss for text recognition. We also design the Length Supervision Module (LSM) and the Feature Clustering Module (FCM) to work alongside the LC loss. LSM predicts text length to provide additional supervision signals, while FCM aims to improve recognition performance by minimizing the distance between the features of corresponding class centers. Since there is no publicly available Thai scene text dataset, we have collected a new dataset containing more than 170,000 samples. Extensive experiments conducted on this dataset show that our method achieves superior performance in both string-level and character-level accuracy compared to other methods.},
  archive      = {J_EAAI},
  author       = {Hongjian Zhan and Chun Li and Bing Yin and Yue Lu},
  doi          = {10.1016/j.engappai.2025.112182},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112182},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Length-aware center loss for sequence to sequence thai scene text recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-based vision-language model for zero-shot anomaly detection in medical images. <em>EAAI</em>, <em>161</em>, 112181. (<a href='https://doi.org/10.1016/j.engappai.2025.112181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of diagnostic technology, the ability to detect pathological areas such as tumors and polyps has significantly improved. This progress provides medical imaging specialists with more precise visual information to support anomaly identification, diagnosis, treatment planning, and patient monitoring. However, existing unsupervised and semi-supervised anomaly detection methods struggle with data privacy constraints, limited annotated medical datasets, and challenges in generalization. Zero-Shot Anomaly Detection (ZSAD), which enables the detection of unseen categories without requiring class-specific training, has emerged as a promising solution by leveraging the vision-language alignment capabilities of Vision-Language Models (VLMs), such as Contrastive Language-Image Pretraining (CLIP). Despite recent progress, ZSAD remains hindered by high noise levels, sparse targets, and poor adaptability in complex medical imaging scenarios. To address these issues, we propose a novel framework: DiffusionCLIP, a diffusion-based VLM for zero-shot anomaly detection in two-dimensional medical images. Specifically, DiffusionCLIP integrates diffusion models into the VLM to progressively denoise multi-level features extracted from the CLIP visual encoder, enhancing feature robustness and discriminability. A multi-level feature fusion strategy is designed to aggregate multi-scale representations from different depths of the visual encoder, ensuring complementary semantic alignment across layers. In addition, a dynamically modulated weight loss function is introduced to adaptively balance the learning of hard and easy samples, further improving model generalization. Extensive experiments on multiple benchmark medical imaging datasets, demonstrate that the proposed method significantly outperforms existing zero-shot anomaly detection approaches in terms of accuracy, robustness, and generalization.},
  archive      = {J_EAAI},
  author       = {Yanhui Chen and Hongkang Tao and Zan Yang and Yunkang Cao and Chen Jiang and Longhua Hu and Pengwen Xiong and Haobo Qiu},
  doi          = {10.1016/j.engappai.2025.112181},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112181},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Diffusion-based vision-language model for zero-shot anomaly detection in medical images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surface roughness prediction in turning processes for grey cast iron: A hybrid machine learning approach integrating infrared thermography. <em>EAAI</em>, <em>161</em>, 112180. (<a href='https://doi.org/10.1016/j.engappai.2025.112180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workpiece surface quality is a critical control parameter in machining processes, influencing functional performance, dimensional precision, and wear resistance. However, accurately predicting surface roughness is complex, often limited by the computational demands of traditional high-precision methods and the reliance of existing models solely on cutting parameters, hindering real-time monitoring. This research introduces a hybrid Artificial Neural Network (ANN) methodology specifically developed for predicting surface roughness of grey cast iron GG-25 workpieces machined in turning processes, a material previously unstudied in this context. The methodology integrates real-time infrared thermal measurements from multiple defined regions of interest (ROIs) within the tool-workpiece contact zone, along with cutting parameters. Experimental results demonstrated that feed rate (f) is the most significant cutting parameter (effect = 0.43) affecting surface quality, followed by its combination with cutting speed (V c ) (effect = −0.25) and cutting speed (effect = 0.18). Correlation and non-linear regression analyses revealed complex, often exponential relationships between temperature and surface roughness, showing temperature an upward trend as machining progressed. The developed ANN achieves a correlation coefficient (R) value of 0.99 both when predicting the roughness arithmetic mean deviation (Ra) parameter in training conditions and when using data from experiments not used in training (validations data). Moreover, the model reaches a correlation coefficient value of 0.85 (test data) under cutting conditions different from those used in experiments, demonstrating robustness, significantly outperforming Support Vector Regression (SVR). This model represents a highly potential tool for real-time online inspection.},
  archive      = {J_EAAI},
  author       = {Sergio Aguado and Marcos Pueo and Raquel Acero and Ana Cristina Majarena and Jorge Santolaria},
  doi          = {10.1016/j.engappai.2025.112180},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112180},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Surface roughness prediction in turning processes for grey cast iron: A hybrid machine learning approach integrating infrared thermography},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Legendre multiwavelet-based feature attention guidance lightweight network for accurate steel surface defect classification. <em>EAAI</em>, <em>161</em>, 112179. (<a href='https://doi.org/10.1016/j.engappai.2025.112179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steel surface defects can significantly affect the quality and appearance of industrial products such as aerospace, construction application fields, and so on. Due to the multi-scale morphology, low contrast, and random positions of the defects, achieving a favorable balance between detection accuracy and speed remains challenging in practical applications. To address these challenges, this paper combines Legendre multiwavelet (LW) with feature attention guidance (FAG) mechanism to devise a novel high-accuracy lightweight network (LWFAG-LNet) for surface defect classification. More precisely, LW bases with rich regularities are first utilized to match complex geometric characteristics across multi-wavelet and multi-scale resolution levels. Subsequently, the FAG module effectively fuses shallow high-resolution detailed features with deep low-resolution contextual features, significantly reducing the depth of the convolutional neural network (CNN). To the third step, a lightweight CNN module with four convolutional blocks is designed to further extract deep features while preserving the most valuable defect information. The proposed model achieves the highest recognition accuracy with a simple structure and a compact parameter configuration. Extensive experiments are conducted on the Northeastern University-Classification (NEU-CLS), Xsteel surface defect dataset (X-SDD), and Kungliga Tekniska Högskolan Royal Institute of Technology Textures under varying Illumination, Pose and Scale (KTH-TIPS) dataset to verify the model's effectiveness and generalization capability. The results reach classification accuracies of 99.80 %, 98.49 %, and 99.06 %, outperforming existing models by about 1.45 %, 3.45 %, and 2.04 %, respectively. In summary, the proposed LWFAG module can be flexibly applied to various lightweight network frameworks, demonstrating great potential for real-time surface defect detection.},
  archive      = {J_EAAI},
  author       = {Xiaoyang Zheng and Weishuo Liu and Yan Huang},
  doi          = {10.1016/j.engappai.2025.112179},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112179},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Legendre multiwavelet-based feature attention guidance lightweight network for accurate steel surface defect classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting object hue bin in the CIECAM02 uniform color space using a multi-layer perceptron for optimal spectrum generation. <em>EAAI</em>, <em>161</em>, 112178. (<a href='https://doi.org/10.1016/j.engappai.2025.112178'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an innovative enhancement to an existing multi-channel light-emitting diode luminaire by integrating artificial intelligence and image analysis capabilities. The system captures an image of the object to be illuminated using a custom-developed Android application. The dominant color in the image is first identified, and then a multi-layer perceptron neural network classifies it into one of 16 hue bins within a uniform color appearance model. This classification process enables the luminaire to select a predefined spectrum designed to enhance the visual appeal of the illuminated object. To ensure robust hue bin classification, we developed a rich dataset with 7920 samples, collected using eleven smartphones under ten distinct light sources. Using this diverse dataset, thirteen multi-layer perceptron neural networks with varying input features were trained and compared, achieving hue classification accuracies, precision, and recall all ranging from 95 % to 99 % on the test set. One of the trained multi-layer perceptron networks was integrated into the Android application, with an inference time of 90 μs on a mid-range smartphone, demonstrating the practical application of artificial intelligence for on-demand hue analysis and lighting optimization. This advancement not only enhances the luminaire's functionality but also enriches the user experience by providing intelligent, on-demand lighting solutions tailored to the object's dominant color.},
  archive      = {J_EAAI},
  author       = {Esmat Kishani Farahani and Kaveh Ahmadian Tazehmahaleh},
  doi          = {10.1016/j.engappai.2025.112178},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112178},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting object hue bin in the CIECAM02 uniform color space using a multi-layer perceptron for optimal spectrum generation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized zero-shot fault diagnosis method for chillers based on cross-modal information compression. <em>EAAI</em>, <em>161</em>, 112177. (<a href='https://doi.org/10.1016/j.engappai.2025.112177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical chiller fault diagnosis applications, target fault training data is often inaccessible, which poses significant challenges to the effectiveness of data-driven diagnostic approaches. Generalized zero-shot fault diagnosis (GZSFD) aims to detect and classify all fault types without relying on fault samples from all categories during training. GZSFD models are trained exclusively on data from seen faults—those with available historical data—making them prone to bias toward these seen classes during inference. However, existing methods fail to exploit the fine-grained semantics of fault attributes, resulting in suboptimal performance when addressing feature bias toward seen classes. In this article, an innovative GZSFD framework for chillers based on cross-modal information compression is proposed to overcome this difficulty. This method constructs a cross-modal feature fusion attention (CmFFA) and information compression module, and integrates them into a variational autoencoder with generative adversarial network (VAEGAN), and establishes a CmFFA-VAEGAN network to synthesize high-quality unseen fault samples. Specifically, the CmFFA module effectively aligns local regions of the virtual samples with key words in the textual attributes, enabling the model to attend to fine-grained semantic information and robustly fuse features from different modalities. This facilitates the generation of virtual samples that more accurately reflect the characteristics of the target modality. In addition, an information bottleneck (IB) layer is introduced at the output of the generator to compress redundant information within the fused features, retaining only the key information most relevant to the data augmentation task. This design enhances cross-modal consistency between the synthesized samples and their corresponding attributes, while alleviating the feature shift of unseen class samples toward seen categories. Extensive experiments are designed and executed on the chiller dataset. Experimental results demonstrate that the proposed framework effectively mitigates the bias of synthesized unseen fault samples toward seen categories, leading to a significant improvement in diagnostic accuracy.},
  archive      = {J_EAAI},
  author       = {Kexin Jiang and Xuejin Gao and Huayun Han and Huihui Gao and Yongsheng Qi and Xi Zhang and Liang Zhao},
  doi          = {10.1016/j.engappai.2025.112177},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112177},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generalized zero-shot fault diagnosis method for chillers based on cross-modal information compression},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing rotation you only look once version 8 for accurate detection of arbitrarily-oriented and multi-scale construction material in complex environment. <em>EAAI</em>, <em>161</em>, 112176. (<a href='https://doi.org/10.1016/j.engappai.2025.112176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Construction material detection is integral to effective material management. While deep learning-based methods have advanced automatic detection, challenges such as arbitrarily oriented objects, similar features, large object scale variations, and noise interference still limit accuracy. This study proposes an enhanced detection method based on improved rotation you only look once version 8, incorporating three key innovations. First, the large selective kernel network employs a spatial selection mechanism to dynamically adjust the network's receptive field, capturing key features and contextual information of various materials in complex construction scenarios. This enhances object detection performance in feature-similar environments. Second, the poly kernel inception network combines non-dilated multi-scale convolutions to extract dense texture features from differently sized objects, while using contextual anchor attention to capture long-range information for small objects. These components work together to improve multi-scale object detection. Third, the rectangular self-calibration module uses horizontal and vertical pooling to model rectangular attention regions, capturing axial global context. Its shape self-calibration function adjusts these regions to better fit arbitrarily oriented construction materials, enhancing focus on objects while suppressing noise interference. Experimental results show a mean average precision of 0.871–2.7 % higher than the baseline model and surpassing other state-of-the-art methods—while maintaining real-time detection speed at 28.3 frames per second. The proposed method improves material detection accuracy in complex construction environments, enabling refined material management on-site. This supports material entry and exit tracking, on-site usage monitoring, inventory management, and procurement planning, while also strengthening lean control of construction progress and costs.},
  archive      = {J_EAAI},
  author       = {Yujie Lu and Yuanjun Nong and Dayu Zhu and Shuo Wang},
  doi          = {10.1016/j.engappai.2025.112176},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112176},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing rotation you only look once version 8 for accurate detection of arbitrarily-oriented and multi-scale construction material in complex environment},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-term forecasting of monthly reservoir inflow using deep and machine-learning-based algorithms. <em>EAAI</em>, <em>161</em>, 112175. (<a href='https://doi.org/10.1016/j.engappai.2025.112175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study provides a method for dynamic flow forecasting to detect how to move between periods with high and low-flow peaks. In other words, the model continues by gaining a deep insight into the long-term stable changes of the time series. Four-time horizons (5, 10, 15 and 20 years) were chosen to forecast the streamflow. These time horizons represent the ability of this method to detect the continuation of its movement in the short, medium, and long term. In this study, a dynamic and recurrent cycle is used to forecast river streamflow based on long-short-term memory (LSTM) and artificial neural network (ANN) models. The 12-month time delay of precipitation and streamflow of the Zayanderud river from 1970 to 2019 was used as input variables for training and validation of the models. In each stage of the forecasting process, 1 year (12 months) is forecasted and used as input for the next stage. The results show that the ANN model performs better in shorter time horizons and the LSTM model in longer time horizons, respectively. The best performance of the ANN model occurs in the 10-year forecast (Mean Absolute Percentage Error (MAPE) = 44.3, Nash–Sutcliffe efficiency coefficient (NSCE) = 0.58, Root Mean Square Error (RMSE) = 43.75) and the best performance of the LSTM model occurs in the 15-year forecast (MAPE = 48.9, NSCE = 0.54, RMSE = 47.12). Finally, the selected period is used to forecast the streamflow in future periods when observational data are not available.},
  archive      = {J_EAAI},
  author       = {Bahram Ghenaati and Mohammad Reza Nikoo and Mohammad G. Zamani},
  doi          = {10.1016/j.engappai.2025.112175},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112175},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long-term forecasting of monthly reservoir inflow using deep and machine-learning-based algorithms},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characteristics detection of surface agglomerated abrasive on electroplated diamond wire: A measurement method based on semantic segmentation. <em>EAAI</em>, <em>161</em>, 112173. (<a href='https://doi.org/10.1016/j.engappai.2025.112173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroplated Diamond Wire (EDW) serves as the primary tool for cutting semiconductor materials. Abrasive agglomeration on its surface induces sudden fluctuations in sawing force, exacerbates material surface damage, and shortens tool lifespan. However, existing testing methods primarily focus on abrasive counts while generally lacking effective means to quantify key characteristics of agglomerated abrasives (e.g., density, maximum size, and number of abrasives contained), leading to substantial limitations in the EDW quality assessment system. To address this critical gap, this study proposes a U-shape Network (UNet)-based semantic segmentation model for EDW surface abrasive grain segmentation, termed Electroplated Diamond Wire U-shape Network (EDW-UNet). By integrating Atrous Spatial Pyramid Pooling (ASPP) and Mamba-like Linear Attention (MLLA), EDW-UNet enhances the detection of multi-scale targets and the accuracy of complex boundary segmentation, enabling precise segmentation of both single and agglomerated abrasives on EDW surfaces. Experimental results demonstrate that EDW-UNet achieves a mean Intersection over Union of 0.917 and a mean Pixel Accuracy of 0.961 on the test set, outperforming the baseline UNet and other mainstream models, with an inference speed of up to 12.82 frames per second. For the first time, a feature extraction algorithm developed from the segmentation results enables measurement of key parameters, including the density, maximum size, and number of abrasives contained in agglomerates. This study not only addresses the technical gap in quantitative detection of agglomerated abrasive features but also provides a novel high-precision, quantitative standard for optimizing EDW manufacturing processes and assessing product quality, thereby enhancing the cutting efficiency and yield of semiconductor materials. The code is available at: https://github.com/huangwenbin123/EDW-UNet .},
  archive      = {J_EAAI},
  author       = {Wenbin Huang and Yufei Gao and Shengtan Hu and Dameng Cheng},
  doi          = {10.1016/j.engappai.2025.112173},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112173},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Characteristics detection of surface agglomerated abrasive on electroplated diamond wire: A measurement method based on semantic segmentation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk-response coupling in underground structures under liquefiable soil conditions: A causality-informed dynamic bayesian network integrated framework. <em>EAAI</em>, <em>161</em>, 112171. (<a href='https://doi.org/10.1016/j.engappai.2025.112171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underground structures in liquefiable soils face complex seismic risks that can trigger cascading failures. This study proposes a Granger causality-informed Dynamic Bayesian network (G-DBN) framework to capture the temporal propagation of seismic risk in such systems. Firstly, a system risk assessment model integrates multiple performance indicators through Cloud Model (CM) to quantify overall risk levels, considering uncertainties associated with soil liquefaction and structural responses. Subsequently, a structural dynamic risk inference model is established using Dynamic Bayesian network (DBN), combining Granger Causality (GC) analysis with engineering-informed relationships to define the network structure. The input features include key structural state variables such as tunnel cross-section convergence ( T 4 ), tunnel uplift displacement ( T 6 ), station uplift displacement ( S 5 ), and inter-story drift angle ( S 6 ), and the aggregated structural risk indicator serves as the target variable. This framework enables the temporal propagation of risk across interconnected structural nodes, and elucidates the mechanisms by which liquefiable soil deformations and structural responses interact within the soil-structure system. Results showed that the risk characteristic value (Expectation , E x ) decreased from 29.12 % (percentage) to 5.21 % as the Peak Ground Acceleration (PGA, expressed in units of gravitational acceleration g) increased from 0.1 g to 0.7 g. The proposed G-DBN model demonstrates robust predictive capabilities, achieving coefficient of determination ( R 2 ) values exceeding 0.95 across multiple seismic intensity conditions. Additionally, tunnel cross-section convergence ( T 4 ) was identified as the most critical factor affecting risk propagation in the coupled underground systems. By integrating holistic risk quantification with dynamic propagation analysis, this study offers a robust tool for understanding dynamic risk evolution and supports decision-making for seismic resilience of underground infrastructure in liquefiable soils.},
  archive      = {J_EAAI},
  author       = {Heqi Kong and Xiaohua Bao and Jun Shen and Xiangcou Zheng and Xiangsheng Chen},
  doi          = {10.1016/j.engappai.2025.112171},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112171},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Risk-response coupling in underground structures under liquefiable soil conditions: A causality-informed dynamic bayesian network integrated framework},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural operator-enabled forward and inverse modeling of laser-induced surface acoustic waves and applications in nondestructive evaluation. <em>EAAI</em>, <em>161</em>, 112170. (<a href='https://doi.org/10.1016/j.engappai.2025.112170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser-induced surface acoustic wave (SAW)-driven nondestructive evaluation offers high-resolution, non-contact characterization of subsurface microstructures. However, its practical application is often limited by the high computational costs associated with traditional numerical simulation methods. Recently, machine learning has emerged as an attractive alternative to accelerate these simulations. In this paper, we develop a neural operator-enabled framework for both forward and inverse modeling of laser-induced SAW propagation. A general dataset with randomly generated subsurface structures is used to evaluate and quantify the model's performance in both wave propagation and subsurface inversion problems. Three potential applications are then investigated: subsurface crack localization, multilayer structure characterization and polycrystalline grain imaging. The results demonstrate that the neural operator-enabled model achieves satisfactory accuracy even in the presence of noise and source waveform variations, underscoring its potential as an efficient and accurate surrogate model for practical nondestructive evaluation using laser-induced SAWs.},
  archive      = {J_EAAI},
  author       = {Zaiwei Liu and Zhongqing Su},
  doi          = {10.1016/j.engappai.2025.112170},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112170},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural operator-enabled forward and inverse modeling of laser-induced surface acoustic waves and applications in nondestructive evaluation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective double Q-learning-based hyper-heuristic algorithm for aluminum production and transportation integrated scheduling problem. <em>EAAI</em>, <em>161</em>, 112169. (<a href='https://doi.org/10.1016/j.engappai.2025.112169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cooperative process of electrolytic aluminum production and aluminum liquid distribution is a typical distributed integrated scheduling problem. The aluminum production and transportation integrated scheduling problem (APTISP) is a strong coupling problem that is studied with the optimal objectives of total completion time and total energy consumption. A mathematical model is constructed for the APTISP. A multi-objective double Q-learning-based hyper-heuristic (MDQHH) algorithm is designed to solve the APTISP. In the MDQHH algorithm, a heuristic rule-based initialization operation is designed to generate the initial population of the APTISP. Nine problem-specific low-level perturbation heuristics are constructed to explore the APTISP solution space. A dynamically adjustable ε -greedy strategy is designed to select the low-level perturbation heuristics, and ε gradually decreases as the learning process progresses. Two Q-tables are utilized alternately to select actions and update the Q-values based on the current solution in each iteration. The experimental results show that the MDQHH algorithm outperforms several state-of-the-art comparison algorithms in addressing the performance of APTISP.},
  archive      = {J_EAAI},
  author       = {Fuqing Zhao and Ting Yang and Tianpeng Xu and Jianlin Zhang},
  doi          = {10.1016/j.engappai.2025.112169},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112169},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-objective double Q-learning-based hyper-heuristic algorithm for aluminum production and transportation integrated scheduling problem},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable multi-agent reinforcement learning for factory-wide dynamic scheduling in semiconductor manufacturing. <em>EAAI</em>, <em>161</em>, 112168. (<a href='https://doi.org/10.1016/j.engappai.2025.112168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time dynamic scheduling in modern manufacturing is highly complex due to frequent disturbances and intricate operational constraints. While reinforcement learning (RL) has shown promise, existing approaches often rely on extensive dispatching rules and struggle to scale to factory-wide settings. This study introduces a scalable multi-agent RL (MARL) framework with a leader–follower structure, enabling decentralized agents to handle sub-problems while maintaining global coordination through abstract goals. To further enhance robustness, a limited rule-based conversion algorithm is proposed to mitigate performance degradation from poor agent decisions. Our experimental results demonstrate that the proposed model outperforms the state-of-the-art deep RL-based scheduling methods in various aspects. Additionally, the proposed model provides the most robust scheduling performance to demand changes. Overall, the proposed MARL-based scheduling model presents a promising solution to the real-time scheduling problem, with potential applications in various manufacturing industries.},
  archive      = {J_EAAI},
  author       = {Jaeyeon Jang and Diego Klabjan and Han Liu and Nital S. Patel and Xiuqi Li and Balakrishnan Ananthanarayanan and Husam Dauod and Tzung-Han Juang},
  doi          = {10.1016/j.engappai.2025.112168},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112168},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scalable multi-agent reinforcement learning for factory-wide dynamic scheduling in semiconductor manufacturing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on global path planning algorithm based on indoor map partition preprocessing. <em>EAAI</em>, <em>161</em>, 112167. (<a href='https://doi.org/10.1016/j.engappai.2025.112167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robots utilize Simultaneous Localization and Mapping (SLAM) technology to generate environmental maps and determine their locations within these environments. Subsequently, they employ path planning algorithms to complete navigation tasks. Although existing path planning algorithms are relatively mature, they still exhibit inefficiencies in complex indoor environments. To address this issue, this paper introduces an Indoor Map Partitioning Preprocessing (IMPP) algorithm, which identifies and segments irregularly shaped, complex rooms to accelerate the path planning process. The method initially utilizes the Robot Operating System (ROS) to construct an indoor map dataset and subsequently applies an image segmentation model to identify and enclose rooms. By combining image processing techniques with path planning algorithms, this method can obtain room index information and successfully exclude irrelevant areas from the path planning process. Ultimately, the IMPP algorithm is integrated with a variety of global path planning algorithms. Experimental results demonstrate that in complex indoor environments, this method significantly surpasses existing partitioning methods in terms of room recognition accuracy. Moreover, it decreases the number of expansion points in global path planning algorithms, significantly enhancing processing speed and efficiency.},
  archive      = {J_EAAI},
  author       = {Jifan Yang and Xiaoling Li and Xiaoyang Liu and Xunding Pan and Lei Wang},
  doi          = {10.1016/j.engappai.2025.112167},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112167},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on global path planning algorithm based on indoor map partition preprocessing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ensemble transfer learning strategy for short-term electricity load forecasting of data-sparse buildings. <em>EAAI</em>, <em>161</em>, 112166. (<a href='https://doi.org/10.1016/j.engappai.2025.112166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The “data silos” caused by the lack of available historical or shared information is an important reason affecting forecasting performance of building’s short-term power demand, thus limits the flexibility of demand response of building group. Knowledge’s transfer learning (TL) from similar domains has been proved an efficient tool to enhance target prediction’s performance. To improve data-sparse building’s energy forecasting accuracy and robustness simultaneously, an ensemble strategy based on different TL models is proposed in this study. Firstly, a two-stage similar data selection method is proposed for source domain construction. The multi-kernel maximum mean discrepancy (MK-MMD) is used for selecting similar buildings to the target one; the nearest neighbor search (NNS) method is adopted for picking the most helpful data from the similar buildings to form the dataset of source domain. To determine the optimal number of source domains for transfer learning, an objective function is also formulated. Then, two effective TL models, i.e., instance-based TL (IBTL) and model-based TL (MBTL) are both built as sub models. On this basis, a parallel ensemble framework is designed with model weights adjusted by multiple linear regression. For case study, a public data set containing 1,449 buildings is treated as candidate source domain set for knowledge transfer, and two educational buildings with sparse historical data are treated as target buildings for hourly electricity load forecasting. Forecasting results show that compared with the previous reported TL models, the proposed ensemble strategy always achieves the best performance in two cases and the prediction accuracies are improved by 41.8% and 29.3% (MAPE) respectively. The impact of source domain number and target data amount on prediction performance are also analyzed and discussed in details.},
  archive      = {J_EAAI},
  author       = {Xingqiao Liu and Borui Wei and Wenping Xue and Xiaoying Li and Kangji Li},
  doi          = {10.1016/j.engappai.2025.112166},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112166},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An ensemble transfer learning strategy for short-term electricity load forecasting of data-sparse buildings},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent multispectral image recognition by using credibility-based square root cubature kalman filters and broad particle swarm learning. <em>EAAI</em>, <em>161</em>, 112165. (<a href='https://doi.org/10.1016/j.engappai.2025.112165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes intelligent multispectral image recognition by using credibility-based Square Root Cubature Kalman Filters (SRCKF) and broad particle swarm learning to address the issue of low recognition accuracy in multispectral target detection using Kalman filtering. This method initially enhances the estimation accuracy of SRCKF by integrating credibility theory. Secondly, the regression parameters of a Broad Learning System (BLS) are tuned with Particle Swarm Optimization (PSO), forming a PSO-BLS network that offers fast, lightweight feature learning. The PSO-BLS acts as an regressor that compensates residual errors produced by the credibility-based SRCKF, thereby refining the overall filtering precision. Subsequently, a particle swarm-optimized broad learning neural network is employed to rectify the SRCKF results from a compensatory standpoint, thereby enhancing the system’s filtering precision. Ultimately, the adaptive search window generated by Camshift(Continuously adaptive Mean shift) can be employed as an input for the credibility SRCKF, thereby facilitating the acquisition of more reliable real-time observation data. Finally, in the experimental part, the proposed algorithm is validated by the MNIST(Modified National Institute of Standards and Technology) dataset , CIFAR-10(Canadian Institute For Advanced Research) dataset, GTOT(Grayscale-Thermal Object Tracking) dataset and OTB2015(Object Tracking Benckmark 2015) dataset respectively for its generalization ability and robustness in static classification tasks and the effectiveness of dynamic target detection and tracking in real lighting scenes, Occlusion and motion blur scenes, while the performance is more advantageous than some mainstream algorithms.},
  archive      = {J_EAAI},
  author       = {Quanbo Ge and Zijian Xue and Hao Wang and Yuanliang Wang},
  doi          = {10.1016/j.engappai.2025.112165},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112165},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent multispectral image recognition by using credibility-based square root cubature kalman filters and broad particle swarm learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accidents analysis of mining industry through semantic text representation and dimensionality reduction: An integrated clustering framework. <em>EAAI</em>, <em>161</em>, 112164. (<a href='https://doi.org/10.1016/j.engappai.2025.112164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant improvements in worker health and safety in recent decades, the mining industry still experiences fatal and non-fatal accidents. This underscores the critical need for a more nuanced understanding of accident causation patterns through accident data analysis. While conventional analytical approaches have yielded valuable insights, the extensive information embedded within text-based accident narratives remains underutilized. To address this gap, this study presents an artificial intelligence (AI)-based framework that integrates transformer-based natural language processing, nonlinear dimensionality reduction, and unsupervised machine learning to analyze and cluster accident narratives from the U.S. mining industry. Specifically, this study uses Sentence-BERT (SBERT), a sentence embedding model based on Bidirectional Encoder Representations from Transformers (BERT), to extract the high-dimensional semantical representation of accident narratives. These embeddings are then mapped to a low-dimensional space using the Uniform Manifold Approximation and Projection (UMAP) technique, followed by clustering with the k-means algorithm and subsequent hazard-focused cluster analysis. The primary contribution to AI lies in demonstrating the effectiveness of combining modern sentence embedding techniques with dimensionality reduction and clustering for the semantic analysis of safety-related narratives. From an engineering standpoint, this framework enables the identification of latent accident patterns that can inform hazard detection and guide safety interventions in the mining industry. The resulting clusters reveal diverse accident patterns across mining operations. In clusters associated with underground mining, a high proportion of incidents (ranging from 84 to 98 %) involved no equipment, with distinct injury patterns: torso injuries (67 %) from over-exertion, lower extremity injuries (58 %) from slips/falls, and upper extremity injuries from over-exertion (95 %) and material handling (85 %). Equipment-related clusters revealed strong associations with drilling tools (92 %), loaders (98 %), and bolting equipment (96 %). Clusters associated with strip/quarry/open pit operations exhibited a high frequency of vehicle-related accidents (98 % transportation, 99 % loaders), often resulting in multiple body part injuries. Milling operation clusters show 52–97 % no-equipment accidents, with injury patterns similar to those in underground mining. Additionally, noise-induced hearing loss (96–97 %) was observed in clusters spanning all mining operation types. These findings offer actionable insights for safety professionals and support data-driven, targeted interventions in the mining industry.},
  archive      = {J_EAAI},
  author       = {Abid Ali Khan Danish and Snehamoy Chatterjee and Kumar Vaibhav Raj and Rennie Kaunda and Hugh Miller and Aref Majdara},
  doi          = {10.1016/j.engappai.2025.112164},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112164},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Accidents analysis of mining industry through semantic text representation and dimensionality reduction: An integrated clustering framework},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight and improved you only look once model using GhostWise convolution and attention mechanism for accurate plant disease detection. <em>EAAI</em>, <em>161</em>, 112163. (<a href='https://doi.org/10.1016/j.engappai.2025.112163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence enables early plant disease detection to support food security, yet achieving high accuracy with low computational cost on multi-class datasets remains challenging. To bridge this gap and solve the problem, we propose an improved version of the “You Only Look Once version 8 nano” (YOLOv8n) model that integrates a convolutional block attention module and custom coarse-to-fine modules into the baseline YOLOv8n architecture. To improve both efficiency and detection performance, the proposed model incorporates a combination of Ghost module and Depthwise convolution for lightweight feature extraction. Additionally, the attention modules emphasize important spatial and channel-wise features, helping the model focus better on critical information. The performance of the proposed model is compared with YOLO models including YOLOv5n, YOLOv5s, YOLOv7, YOLOv8n, and YOLOv8s. The experimental results show that the improved model outperforms the benchmark YOLO models. In addition, the improved model achieves mean Average Precision at Intersection over Union threshold of 0.5 ( mAP@0.5 ) 0.742, representing an improvement of 3.37 % over the baseline YOLOv8n. For the metric mean Average Precision at thresholds from 0.5 to 0.95 ( mAP@0.5:0.95 ), the improved model shows an improvement of 5.13 % over YOLOv8n. The precision measure reveals an improvement of 8.99 % and F1 score of 0.6856 outperforms YOLOv8n by 5.85 %. In addition, generalization experiments are conducted using commonly preferred plant disease datasets. These results validate the robustness, accuracy and stability of the improved model in effectively detecting plant leaf diseases.},
  archive      = {J_EAAI},
  author       = {Bunyamin Dikici and Mehmet Fatih Bekciogullari and Hakan Acikgoz and Serkan Ozbay},
  doi          = {10.1016/j.engappai.2025.112163},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112163},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight and improved you only look once model using GhostWise convolution and attention mechanism for accurate plant disease detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid optimization approach for syngas-fueled gas turbines: Integrating inverse problem solving and machine learning techniques. <em>EAAI</em>, <em>161</em>, 112162. (<a href='https://doi.org/10.1016/j.engappai.2025.112162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the efficiency of gas turbines powered by syngas derived from gasification, combining a detailed thermodynamic model with a hybrid optimization approach that integrates inverse problem solving via the Levenberg-Marquardt (LM) algorithm and supervised machine learning using Gradient Boosted Trees (GBT). The LM method is used to estimate turbine and compressor performance parameters based on efficiency maps extracted through a custom image processing routine. These maps are applied to calibrate isentropic efficiencies and define the system's operational boundaries. The resulting performance curves enhance the accuracy of the thermodynamic cycle model. To identify optimal operating conditions that maximize thermal efficiency and minimize entropy generation, the inverse problem formulation is integrated with the GBT model, enabling data-driven optimization based on simulated system behavior. All modeling and simulations are conducted in Wolfram Mathematica version 14.0, while verification is performed with the commercial software Gasturb version 14.0, using syngas composition data available in the literature. As a case study to demonstrate the method's applicability, syngas obtained from sewage sludge gasification is analyzed. The findings after optimization indicated an average thermal efficiency of 40 % when using syngas. The analysis revealed that the fuel mass flow rate contributes approximately 45 % to the efficiency gains and more than 70 % to the exergy reduction, while the excess air ratio contributes around 50 % to the cycle's efficiency. The study demonstrates the value of integrating LM-based modeling and GBT optimization, indicating significant potential for enhancing the performance of syngas-fueled turbines. Moreover, it highlights syngas from sewage sludge as a promising sustainable energy source.},
  archive      = {J_EAAI},
  author       = {Hiago David Zogbi Silva Oliveira and Vítor Caldeira de Andrada Bastos and York Castillo Santiago and Isabela Florindo Pinheiro},
  doi          = {10.1016/j.engappai.2025.112162},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112162},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid optimization approach for syngas-fueled gas turbines: Integrating inverse problem solving and machine learning techniques},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-wavelet adaptive basis network for long-term time series forecasting. <em>EAAI</em>, <em>161</em>, 112161. (<a href='https://doi.org/10.1016/j.engappai.2025.112161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based models have demonstrated remarkable efficacy in long-term time series forecasting. Nevertheless, their fixed-scale feature extraction and static spectral processing limit adaptability to inherent multi-scale temporal dependencies. Additionally, conventional self-attention mechanisms struggle to effectively model hierarchical temporal structures. To address these limitations, we propose the Frequency-Wavelet Adaptive Basis Network (FWBNet), a novel framework that integrates three synergistic components including a Multi-scale Adaptive Basis Module (MS-ABM) for multi-resolution feature extraction, a Dual-Stream Wavelet Cross-Attention (DWCA) system with learnable wavelet transformations, and a computationally efficient Frequency-domain Multi-Layer Perceptron bottleneck (FreMLP bottleneck) for selective spectral processing. The MS-ABM innovatively integrates multi-scale features of time series through an adaptive basis function selection mechanism, dynamically fusing characteristics at different scales to form hierarchical representations. These multi-dimensional representations are then processed by the DWCA system, which establishes an efficient modeling framework for cross-scale temporal dependencies by combining bi-directional attention with learnable wavelet transforms. Building upon this foundation, the FreMLP bottleneck layer strategically performs selective feature optimization in the frequency domain, extracting key frequency information through spectral sparsification techniques to form an end-to-end multi-scale temporal feature learning pipeline. Experimental evaluations on six benchmark datasets demonstrate that FWBNet significantly outperforms state-of-the-art models, achieving mean squared error (MSE) reductions of 14% for multivariate and 21% for univariate predictions. This study presents a comprehensive framework for effective multi-scale temporal information integration in complex time series forecasting applications.},
  archive      = {J_EAAI},
  author       = {Qiang Lai and Yang You},
  doi          = {10.1016/j.engappai.2025.112161},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112161},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Frequency-wavelet adaptive basis network for long-term time series forecasting},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balanced sample repository for knowledge distillation in data-free image classification scenario. <em>EAAI</em>, <em>161</em>, 112160. (<a href='https://doi.org/10.1016/j.engappai.2025.112160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address strict data security and privacy requirements in the field of knowledge distillation for image classification, generative network-based data-free knowledge distillation produces fake images for training student models to perform image classification tasks. However, we discover that the datasets consisting of those fake images often suffer from imbalances, such as unclear class margins, uneven intra-class distribution, and skewed label distribution, impeding classification accuracy. To this end, this paper proposes the balanced sample repository method for data-free knowledge distillation in the context of image classification, comprising three components: dynamic pseudo-supervised loss weight (DLW), biased label generator (BLG), and intra-class homogeneity operator (IHO). Specifically, DLW adjusts the pseudo-supervised loss weight to maintain distinct class margins, BLG uses the roulette algorithm to balance label distribution, and IHO employs local outlier factors to remove outliers and homogenize intra-class distributions. The fake images generated by the generative network are initially stored in the sample repository, and those three components achieve a balanced dataset by influencing this sample repository. The experiments conducted across five recognized image classification datasets demonstrate that the proposed method achieves competitive results and produces more balanced samples.},
  archive      = {J_EAAI},
  author       = {Yafeng Sun and Xingwang Wang and Junhong Huang and Shilin Chen},
  doi          = {10.1016/j.engappai.2025.112160},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112160},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Balanced sample repository for knowledge distillation in data-free image classification scenario},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight detection model for green navel oranges in natural environments. <em>EAAI</em>, <em>161</em>, 112157. (<a href='https://doi.org/10.1016/j.engappai.2025.112157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In natural environments, the detection of green navel oranges in the unstructured plantings of Gannan navel oranges presents challenges, including low model accuracy and excessive parameter size. This paper integrates existing technologies to propose a lightweight green tangerine detection model based on You Only Look Once version 5s (YOLOv5s). The aim is to improve the accuracy of green tangerine identification and detection in natural environments through model improvements. Firstly, the original YOLOv5 network model is optimized by replacing the original CSPDarknet53 (Cross Stage Partial Darknet53) backbone network with MobileNetV3 in order to reduce model parameters. Concurrently, the Squeeze-and-Excitation (SE) module in the network is substituted with the Convolutional Block Attention Module (CBAM), resulting in a lightweight network. Secondly, CBAM is integrated into the C3 network (cross-stage partial bottleneck with three convolutional layers) in the neck region to enhance the model's ability to extract green navel orange features after lightweighting. Finally, improve the loss function of the model to reduce the positioning error of the model for low-quality targets. The experimental results demonstrate that the enhanced model attains a 3.6 % enhancement in precision, 2.3 % in recall, and 2.1 % in mean Average Precision (mAP) in comparison with the original YOLOv5 model. The model's size is 3.9 megabytes (MB), representing a reduction of 72.9 % from the original 14.4 MB. Research shows that our method provides an efficient and accurate solution for identifying green navel orange targets in complex environments, with potential application value in agricultural automation for orchard management and monitoring.},
  archive      = {J_EAAI},
  author       = {Dongyuan Zhang and Qiusheng Li and Xindi Yuan},
  doi          = {10.1016/j.engappai.2025.112157},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112157},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight detection model for green navel oranges in natural environments},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient real-time instance segmentation of garment for intelligent robot tie-dye based on you only look once version 11 network. <em>EAAI</em>, <em>161</em>, 112156. (<a href='https://doi.org/10.1016/j.engappai.2025.112156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tie-dye, as an intangible cultural heritage with a long history, has gained global popularity due to its unique artistic value and versatile craftsmanship. However, its reliance on manual operation leads to low production efficiency and inconsistent quality. To address this, we propose an improved You Only Look Once version-11 (YOLOv11) instance segmentation model, Garment-YOLO, to efficiently segment the garment regions of robotic tie-dye by artificial intelligence technology. First, the C3k2_DynamicMixFormer (C3k2_DMF) module introduces dynamic kernel weight selection mechanism and multi-scale fusion to effectively balance local details and global information. Meanwhile, the Dual-Cross Recalibration Feature Pyramid Network (DCR-FPN) is proposed to enhance the detail preservation of edge region by selectively aggregating semantic and boundary information. Furthermore, the Superior-Head replaces depthwise convolution (DWConv) with part convolution (PConv), significantly reducing model complexity while maintaining performance. Experimental results demonstrate that Garment-YOLO achieves 167.4 frames per second (FPS) and maintains an optimal trade-off between inference speed and segmentation accuracy, reaching 91.9 % mean average precision (mAP)50–95 (Box), 91.5 % mAP50-95 (Mask). To further validate its practical performance, we conducted a 72-h production-line comparison, showing that compared to the baseline, we increase the product qualification rate by 24.6 %, reduce dye waste by 19.4 %, and increase the total production by 52.5 % compared to manual tie-dye. This study not only provides a feasible solution for the intelligent transformation of traditional tie-dye but also contributes to the preservation and development of this intangible cultural heritage. The code will be released on GitHub ( https://github.com/fudifu123/GARMENT-YOLO ). A video that intuitively introduces our research ( https://www.bilibili.com/video/BV13MgczAEkB ).},
  archive      = {J_EAAI},
  author       = {Difei Feng and Qihong Zhou and Lei Xiao and Kunfeng Ge and Hangzhou Ma and Li Zhou},
  doi          = {10.1016/j.engappai.2025.112156},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112156},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient real-time instance segmentation of garment for intelligent robot tie-dye based on you only look once version 11 network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep patch network with spatiotemporal meta-parameter learning for soft sensor modeling of industrial processes. <em>EAAI</em>, <em>161</em>, 112155. (<a href='https://doi.org/10.1016/j.engappai.2025.112155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft sensing techniques have been widely employed in industrial processes to predict hardly measurable quality variables using easily measurable process variables. Effective modeling strategies for representing spatiotemporal features are highly desired in soft sensing applications for dynamic industrial processes. Deep networks, such as graph convolutional network and gated recurrent unit, are frequently employed to capture the spatial or temporal characteristics of sequential data. Nevertheless, effectively modeling and utilizing spatiotemporal heterogeneity remains a challenging problem. Thereby, a p atch network with spatiotemporal m eta- p arameter l earning (PMPL) is proposed in this paper, which presents an uniform framework of modeling spatiotemporal heterogeneous feature representations for soft sensing. In PMPL, a patching strategy is utilized to segment times series into sub-series-level patches, allowing the retention of local semantic information while capturing long-term dependencies. Next, a novel spatiotemporal meta-parameter learning approach is proposed to generate specific parameters for a spatial encoder, temporal encoder and spatiotemporal decoder through establishing corresponding embedding layers. In this way, the spatial, temporal and spatiotemporal dependencies within the process data can be adaptively captured and comprehensively refined from a uniform perspective. Extensive experiments are conducted based on two real production processes, which illustrate the feasibility and efficacy of the proposed model.},
  archive      = {J_EAAI},
  author       = {Xudong Shi and Kangping Du and Weili Xiong and Humberto Morales and Adriana Amicarelli},
  doi          = {10.1016/j.engappai.2025.112155},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112155},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep patch network with spatiotemporal meta-parameter learning for soft sensor modeling of industrial processes},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep bioinspired evolutionary stacking algorithm for unpaired multimodal cell classification calibration. <em>EAAI</em>, <em>161</em>, 112153. (<a href='https://doi.org/10.1016/j.engappai.2025.112153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-modality deep learning approaches for cell image classification exhibit inherent limitations in informational diversity when processing cross-institutional datasets acquired under varied imaging protocols. In contrast, multimodal cell imaging has emerged as a promising alternative for addressing data heterogeneity through comprehensive information integration. This study introduces a novel multimodal alternate training decision-making architecture based on a stacking algorithm for unpaired multimodal cell classification calibration. The method leverages deep bioinspired evolutionary networks combined with kernel-based support vector machines. Specifically, deep base classifiers incorporating multimodal concepts are derived from heterogeneous cell datasets. Each base classifier employs a bioinspired strategy to perform alternate training between two evolutionary densely connected attention networks. To mitigate class imbalance, where diseased cells are significantly outnumbered by normal cells, we incorporate a Shannon entropy loss term. Finally, multiple kernel-based support vector machines serve as meta classifiers, transforming high-level multimodal concepts into a separable feature space for robust decision-making. Experimental results demonstrate the superiority of our approach over existing algorithms for unpaired multimodal cell image classification. Our findings emphasize the importance of alternate training intra-modality classifiers and inter-modality fusion calibration for accurate and reliable medical image classification. All source code for this work will be publicly available on GitHub.},
  archive      = {J_EAAI},
  author       = {Lili Zhao and Di Xu and Xueping Tan and Jinzhao Yang and Weiping Ding and Hengde Zhu and Lichi Zhang and Qian Wang},
  doi          = {10.1016/j.engappai.2025.112153},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112153},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep bioinspired evolutionary stacking algorithm for unpaired multimodal cell classification calibration},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal-frequency joint hierarchical transformer with dynamic windows for speech emotion recognition. <em>EAAI</em>, <em>161</em>, 112152. (<a href='https://doi.org/10.1016/j.engappai.2025.112152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech Emotion Recognition (SER) aims to identify the emotional state of a speaker from speech signals, serving as a critical prerequisite for achieving natural human–computer interaction. In speech signals, emotional information is inherently distributed across diverse frequency bands and temporal scales, with emotional cues in distinct regions exhibiting varying levels of heterogeneity or interdependence. Existing Transformer-based methods face limitations in precisely localizing salient temporal-frequency regions and modeling their inter-regional relationships. To address these challenges, a temporal-frequency joint hierarchical Transformer with dynamic window mechanisms, abbreviated as TF-DWFormer, is proposed to capture critical emotional cues and their contextual dependencies across temporal-frequency dimensions. It operates through several principal phases: Firstly, a feature reconstruction module is designed to extract temporal, frequency, and temporal-frequency representations of emotional speech. Secondly, a high-low frequency-based emotion-aware partitioning strategy is designed to achieve the division of emotional regions. Thirdly, a local window within a hierarchical Transformer analyzes static intra-region correlations to capture fine-grained emotional patterns, while a dynamic window adaptively models temporal evolution across regions, learning dynamic inter-region relationships. Lastly, a dual-cross-attention mechanism is employed to synergize comprehensive emotion representation from different domains. Our evaluation experiments demonstrate that the proposed TF-DWFormer method achieves recognition accuracies of 73.68%, 91.67%, 92.59%, 74.42%, and 50.54% on the datasets IEMOCAP, CASIA, EMODB, eNTERFACE05, and MELD, respectively, outperforming existing SER methods. These results confirm the capability of TF-DWFormer to precisely localize salient regions, robustly model inter-region dependencies, and effectively fuse multi-domain information, providing a promising solution for advancing SER technology.},
  archive      = {J_EAAI},
  author       = {Yonghong Fan and Heming Huang and Huiyun Zhang and Ziqi Zhou},
  doi          = {10.1016/j.engappai.2025.112152},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112152},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Temporal-frequency joint hierarchical transformer with dynamic windows for speech emotion recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional reconstruction and fracture segmentation based on X-ray and computed tomography paired dataset. <em>EAAI</em>, <em>161</em>, 112151. (<a href='https://doi.org/10.1016/j.engappai.2025.112151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some orthopedic surgeries, the use of three-dimensional (3D) computed tomography (CT) scanning technology is not feasible due to scene limitations, leaving doctors to rely on two-dimensional (2D) X-ray images for real-time diagnosis. However, X-ray images lack 3D information, making accurate diagnosis challenging. Developing an algorithm to convert 2D X-ray images into 3D CT images, while simultaneously combining high-quality 3D reconstruction with precise fracture segmentation, offers a promising solution to the problem. In this study, we propose a novel artificial intelligence (AI)-driven framework named 3D reconstruction and segment anything model (3DRecSAM). The reconstruction image enhancer (RIE) is designed to achieve high-precision 3D reconstruction and provide high-quality feature initialization for fracture segmentation. Meanwhile, the mamba segment anything model (MSAM), based on the segment anything model (SAM) architecture, is developed for accurate fracture segmentation. We introduce a Kolmogorov–Arnold network (KAN)-based attention fusion module (KAF), which facilitates the joint optimization of the RIE reconstruction network and the MSAM segmentation network. Furthermore, the selective scanning mamba with KAN (SKM) is incorporated to enhance feature extraction for both RIE and MSAM. Mamba efficiently captures long-range dependencies and sequential patterns, while KAN’s learnable activation functions facilitate adaptive feature fusion and non-linear representation. To train and evaluate 3DRecSAM, we introduce the real X-ray and CT paired dataset (XCPData), which is publicly available on GitHub: https://github.com/YuanGao1201/XCPData .},
  archive      = {J_EAAI},
  author       = {Yuan Gao and Yuan Zhou and Da Chen and Jiachen Li and Mingle Zhou and Gang Li and Yunbo Gu and Jean-Louis Coatrieux and Yang Chen},
  doi          = {10.1016/j.engappai.2025.112151},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112151},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-dimensional reconstruction and fracture segmentation based on X-ray and computed tomography paired dataset},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised domain adaptation for lithology classification using dynamic entropy-based prototype learning. <em>EAAI</em>, <em>161</em>, 112150. (<a href='https://doi.org/10.1016/j.engappai.2025.112150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lithology classification plays a crucial role in geological exploration and resource evaluation. However, the significant distribution discrepancies between source and target domains, coupled with the unavailability of source domain data, pose substantial challenges to traditional domain adaptation methods. To address these challenges, we propose an innovative framework, Unsupervised Domain Adaptive Dynamic Entropy Prototype Learning (UDADEPL), which leverages a source-free unsupervised domain adaptation strategy for lithology classification. The UDADEPL framework consists of a frozen source pre-trained model and a trainable target model, incorporating a dynamic entropy-based prototype learning matrix for reliable sample selection and centroid-based pseudo-label learning for iterative optimization. Additionally, an information maximization loss and source domain regularization loss are integrated into a curriculum learning strategy to balance feature extraction and domain adaptation. This approach enables the model to effectively handle complex lithological boundaries and class imbalances in the target domain. Extensive experiments on datasets from the Tarim Oilfield and Hugoton–Panoma field demonstrate the superiority of UDADEPL over traditional machine learning and advanced deep learning models. UDADEPL achieves superior classification accuracy, outperforming the best baseline models, especially in cross-domain adaptation and complex lithology identification.},
  archive      = {J_EAAI},
  author       = {Hengxiao Li and Yahui Liu and Lu Liu},
  doi          = {10.1016/j.engappai.2025.112150},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112150},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised domain adaptation for lithology classification using dynamic entropy-based prototype learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transforming physics-informed machine learning to convex optimization. <em>EAAI</em>, <em>161</em>, 112149. (<a href='https://doi.org/10.1016/j.engappai.2025.112149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Machine Learning (PIML) offers a powerful paradigm of integrating data with physical laws to address important problems in engineering, such as parameter estimation, inferring hidden physics, equation discovery, and state prediction. However, PIML, such as Physics-Informed Neural Networks (PINNs), still lack the necessary accuracy, stability, and interpretability when applying in practical engineering due to many serious optimization challenges including the spectral bias, non-convex optimization, multi-objective optimization, and non-smooth optimization. In this study, we propose the Convex-PIML based on convex optimization and basis functions widely used in well-established numerical solvers to overcome all these limitations. The linear combination of B-splines is utilized to approximate the data, promoting the convexity of the loss function. By dividing variables into blocks and replacing the non-convex loss terms with convex approximations, the problem is further converted into a sequence of successively refined approximated convex optimization problems. This conversion known as Block Successive Convex Approximation (BSCA) allows the use of well-established convex optimization algorithms, obtaining solutions effectively and efficiently. Furthermore, an adaptive knot optimization method is introduced to mitigate the spectral bias issue of PIML, further improving the performance. The proposed fully adaptive framework by combining the adaptive knot optimization and BSCA is tested in scenarios with distinct types of physical prior. The results indicate that optimization problems are effectively solved in these scenarios, highlighting the potential of the framework for broad applications. Note that the Convex-PIML is also flexible since many other basis functions can also be incorporated to handle different systems.},
  archive      = {J_EAAI},
  author       = {Letian Yi and Siyuan Yang and Ying Cui and Zhilu Lai},
  doi          = {10.1016/j.engappai.2025.112149},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112149},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transforming physics-informed machine learning to convex optimization},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time fuzzy tracking control for networked suspension systems under gilbert-elliott fading channels. <em>EAAI</em>, <em>161</em>, 112148. (<a href='https://doi.org/10.1016/j.engappai.2025.112148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the finite-time ℓ 2 − ℓ ∞ fuzzy tracking control problem for networked suspension systems operating under Gilbert-Elliott fading channels. Firstly, the suspension system is established based on interval type-2 fuzzy rules to effectively describe the nonlinearity and uncertainty inherent in the model. Secondly, the Gilbert-Elliott model is employed to characterize the random switching behavior of channel states (good channel and fading channel) under real-world conditions. The timely identification of the current channel state is achieved through a mode detection method. To address channel fading and communication constraints, a novel mode-dependent controller is proposed. Simultaneously, we aim to minimize unnecessary and redundant communication. The hybrid scheduling strategy of the FlexRay protocol is utilized to transmit the measurement output data to the observer, and a saturation function is introduced in the observer to minimize the impact of outliers. Subsequently, the design conditions for stochastic finite-time boundedness and ℓ 2 − ℓ ∞ performance of the augmented system is proposed. Finally, simulation results demonstrate that the proposed algorithm is practically viable in dealing with complex environments, such as Gilbert-Elliott fading channels, outliers, and communication constraints.},
  archive      = {J_EAAI},
  author       = {Li-Juan Cai and Xiao-Heng Chang and Xin-Yue Zhao},
  doi          = {10.1016/j.engappai.2025.112148},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112148},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Finite-time fuzzy tracking control for networked suspension systems under gilbert-elliott fading channels},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RT-FedFlow: An efficient framework for real-time traffic signal optimization using federated multi-agent reinforcement learning. <em>EAAI</em>, <em>161</em>, 112147. (<a href='https://doi.org/10.1016/j.engappai.2025.112147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of Traffic Signal Control (TSC) is a critical component of the Intelligent Transportation System (ITS) in smart cities, aiming to eliminate traffic congestion and improve urban mobility. However, traditional approaches to TSC often rely on centralized data processing, limiting scalability and adaptability to real-time traffic dynamics while raising concerns about data privacy, communication, and computation. To address these challenges, this paper proposes the RT-FedFlow, a novel federated multi-agent reinforcement-learning (FMARL) framework for real-time traffic signal optimization. The framework employs enhanced FMARL techniques to enable decentralized collaboration among multiple traffic signal agents, optimizing traffic flow while seamlessly balancing local adaptability and global coordination. Federated model aggregation enables agents to collaboratively learn a global policy while preserving local data privacy, with each reinforcement learning (RL) agent independently optimizing its policy. Next, an advanced reward mechanism is designed to minimize congestion and reduce waiting times. Moreover, a hierarchical communication and coordination strategy is adopted to facilitate efficient local interaction among agents and global model aggregation to improve overall system performance. In addition, the framework enables real-time optimization and prioritization of emergency vehicles through a dedicated preemption module. Compared to existing TSC models, RT-FedFlow significantly improves traffic signal coordination and response times by dynamically adapting to complex, real-time traffic conditions. The proposed RT-FedFlow framework is implemented and evaluated using the SUMO simulator. Extensive simulation results demonstrate that RT-FedFlow outperforms all benchmark models, achieving a 15.49 % reduction in average inference time, a 3.07 % reduction in average queue length, a 13.04 % reduction in average intersection delay, a 0.20 % improvement in fuel consumption, and a 5.35 % emergency vehicle clearance time.},
  archive      = {J_EAAI},
  author       = {Ayaz Akbar and Syed Sajid Ullah and Abdul Malik and Saeed Mian Qaisar},
  doi          = {10.1016/j.engappai.2025.112147},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112147},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RT-FedFlow: An efficient framework for real-time traffic signal optimization using federated multi-agent reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid data-driven model for state of health estimation of lithium-ion battery with capacity recovery. <em>EAAI</em>, <em>161</em>, 112146. (<a href='https://doi.org/10.1016/j.engappai.2025.112146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The failure of lithium-ion batteries has attracted the attention of researchers. Monitoring the degradation process through sensor-based state-of-health (SOH) assessment enables early detection of anomalies and facilitates timely interventions to prevent catastrophic failures. During battery degradation, the phenomenon of capacity recovery makes it complicated to accurately evaluate the SOH. However, existing works usually neglect this phenomenon. In this paper, we propose a hybrid model focusing on capacity recovery. The model consists of four modules: a feature extraction module, a data decomposition module, a global trend assessment module, and a local fluctuation assessment module. Specifically, in the feature extraction module, a convolutional neural network extracts features from the input data that effectively characterize the capacity degradation process. The data decomposition module applies empirical mode decomposition (EMD) to separate local fluctuations caused by capacity recovery from the global degradation trend. These components are then input into their respective assessment modules. Additionally, the local fluctuation assessment module incorporates an attention mechanism that adaptively identifies the similarity between extracted features and health states, thereby enhancing the evaluation of local fluctuations. The proposed model is validated using the NASA (National Aeronautics and Space Administration) battery dataset, demonstrating its effectiveness in addressing the challenges of SOH prediction under capacity recovery conditions.},
  archive      = {J_EAAI},
  author       = {Yu Lin and Luo Zhou and Jianhai Yan and Shuguang He},
  doi          = {10.1016/j.engappai.2025.112146},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112146},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid data-driven model for state of health estimation of lithium-ion battery with capacity recovery},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel localization algorithm integrated with sensor fusion for position estimation of mobile robot in the road following and roundabout environment. <em>EAAI</em>, <em>161</em>, 112145. (<a href='https://doi.org/10.1016/j.engappai.2025.112145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel Artificial Intelligence algorithm based autonomous mobile robot localization in road environments is presented in this paper. The sensor fusion data, employing camera and odometry, are used to build the local maps for road environment. The localization of the robot is performed using a novel Artificial Intelligence algorithm, called Priori-Posteriori-Laser-Simulator, to find the position and heading-angle of robot along movement in two phases, namely priori and posteriori stages as 1st phase and Kalman filter in 2nd phase. In the priori stage, the path of the robot is planned in the built-map using Laser Simulator through generating a series of points as lines to drive the robot in the middle of the road environments. In the posteriori-stage, the position and robot heading angle are measured using sensor fusion system and the laser-simulator updates the position accordingly through a comparison between the planned and actual positions. The Kalman filter is used in 2nd phase to remove noise and enhance to enhance the localization accuracy. The proposed algorithm has been tested in indoor and outdoor road environments to show its effectiveness and performance for localizing robot in such environments. It is also compared with fuzzy-logic, adaptive H-infinity filter, fuzzy logic with Kalman filter and Oriented-Rotated Binary Simultaneous Localization and Mapping 2 algorithms on localizing robot at road environment. Results show the capability of the proposed algorithm to enable the robot to move effectively in road environments, recognize the features of road terrains and localize the robot during autonomous navigation in road environments.},
  archive      = {J_EAAI},
  author       = {Mohammed A.H. Ali and Nukman Yusoff and Bushroa Abd Razak and Sherzod Turaev and Rawad Abdulghafor and Aisha Muhammad},
  doi          = {10.1016/j.engappai.2025.112145},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112145},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel localization algorithm integrated with sensor fusion for position estimation of mobile robot in the road following and roundabout environment},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electroencephalography-based emotion recognition using a dual-stream multi-scale spatiotemporal convolutional capsule network. <em>EAAI</em>, <em>161</em>, 112144. (<a href='https://doi.org/10.1016/j.engappai.2025.112144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, emotion recognition using electroencephalogram (EEG) signals has gained significant attention. However, shallow convolutional neural networks used in EEG emotion recognition are ineffective at capturing spatial relationships between features, adversely affecting model performance. To solve this problem, this study proposes a dual-stream multi-scale spatiotemporal convolutional capsule network aimed at improving EEG-based emotion recognition. The novelty of our approach is the dual-stream multi-scale spatiotemporal design, which enables parallel extraction and fusion of temporal and spatial EEG features at multiple scales, offering a richer and more discriminative representation for emotion recognition. Specifically, a dual-stream feature construction module is developed to extract multi-scale temporal and spatial features from raw EEG signals. A hybrid spatiotemporal attention mechanism enhances feature fusion, while a capsule-based classifier improves recognition accuracy by modeling relationships between local and global features. Experimental results using subject-dependent 10-fold cross-validation show average accuracies of 97.72%, 97.56%, and 97.82% for valence, arousal, and dominance on the Dataset for Emotion Analysis using Physiological signals(DEAP), with average F1 scores of 97.83%, 97.51%, and 97.68%. For the Dataset for Emotion Analysis using Physiological signals(DREAMER 1 ), the average accuracies are 96.48%, 96.32%, and 96.35%, with corresponding F1 scores of 96.23%, 95.74%, and 95.66%. The proposed method outperforms existing state-of-the-art approaches on both datasets, reducing the number of parameters by 58.07% and decreasing inference time by approximately 50.86% and 33.39%, compared to Residual Network 18. Additionally, in the subject-independent leave-one-subject-out cross-validation, the proposed method demonstrated results that significantly outperformed the baseline model across both datasets. Experiments show that the proposed method enhances spatiotemporal feature extraction and improves emotion recognition accuracy. This method reduces computational resource consumption and enhances recognition accuracy, thereby facilitating efficient algorithm development and deployment for real-time emotion monitoring and related applications.},
  archive      = {J_EAAI},
  author       = {Han Cai and Pengfei Lu and Xiaofang Wang and Yuxing Wang},
  doi          = {10.1016/j.engappai.2025.112144},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112144},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Electroencephalography-based emotion recognition using a dual-stream multi-scale spatiotemporal convolutional capsule network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse structural design with generative and probabilistic autoencoders and diffusion models. <em>EAAI</em>, <em>161</em>, 112143. (<a href='https://doi.org/10.1016/j.engappai.2025.112143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional structural design is a forward trial-and-error process. Designers need to iterate through different design solutions and conduct structural analysis until the design meets the codes and standards. This study proposes and investigates a generative machine learning (ML) framework for inverse design of continuous beam systems. Three generative ML models, including conditional variational autoencoder (CVAE), conditional autoencoder with maximum likelihood estimation (CAE-MLE), and denoising diffusion models (DDMs) are trained and fine-tuned on the CBeamXP (Continuous Beam Cross-section Predictors) dataset with 1,000,000 beam sections to generate the cross sectional properties. Research results show that CAE-MLE achieves the highest generation accuracy and robustness, while CVAE offers more variability through latent space sampling. DDMs provide controllable generation variability via a stochasticity parameter in the inverse diffusion process. The proposed framework enables efficient generation of multiple design solutions and can potentially accelerate the conceptual design workflows in structural engineering. This work also demonstrated the feasibility toward artificial intelligence (AI)-assisted structural design using generative approaches and tabular datasets.},
  archive      = {J_EAAI},
  author       = {Bozhou Zhuang and Adrien Gallet and Danny Smyl},
  doi          = {10.1016/j.engappai.2025.112143},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112143},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inverse structural design with generative and probabilistic autoencoders and diffusion models},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective generative design framework and realization for quasi-serial manipulator: Considering kinematic and dynamic performance. <em>EAAI</em>, <em>161</em>, 112142. (<a href='https://doi.org/10.1016/j.engappai.2025.112142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a framework for optimizing the linkage mechanism of a quasi-serial manipulator for target tasks. The process is illustrated through a case study of a two-degree-of-freedom (2-DOF) linkage mechanism, which significantly influences the workspace of the quasi-serial manipulator. First, a diverse set of quasi-serial mechanisms is generated with workspaces that satisfy the target task and is converted into three-dimensional computer-aided design (3D CAD) models. Then, kinematic and dynamic analyses are conducted to compute workspace and payload torque labels for surrogate model training. Adaptive sampling is employed to identify an appropriate amount of training data for accurate prediction, while ensemble models are utilized to enhance robustness. After model training, a multi-objective optimization problem is formulated under the mechanical and dynamic constraints of the manipulator. The design objective is to recommend quasi-serial mechanisms with optimized kinematic (workspace) and dynamic (payload torque) performance that fulfill the target task. To explore the underlying physics of the Pareto solutions obtained via the Non-Dominated Sorting Genetic Algorithm (NSGA-II), various data mining techniques are applied to extract design rules that offer practical guidance. Finally, a detailed manipulator is realized using 3D-printed parts with topology optimization, and its performance is verified through a payload test. These results demonstrate the potential of the proposed framework for broader mechanism applications and its capability to support practical design decisions through design rule extraction.},
  archive      = {J_EAAI},
  author       = {Sumin Lee and Sunwoong Yang and Namwoo Kang},
  doi          = {10.1016/j.engappai.2025.112142},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112142},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective generative design framework and realization for quasi-serial manipulator: Considering kinematic and dynamic performance},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain and deep learning-enabled IoT device-to-device authentication approach for smart cities using 5th generation technology. <em>EAAI</em>, <em>161</em>, 112141. (<a href='https://doi.org/10.1016/j.engappai.2025.112141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As smart cities evolve, the increasing number of Internet of Things (IoT) devices requires secure authentication mechanisms for device-to-device (D2D) communication, especially within 5G networks. To address security challenges in D2D communication, Blockchain (BC) technology is utilized. Existing methods face issues like single-point failure attacks, high implementation costs, and data privacy concerns. This work aims to develop a secure and efficient authentication model leveraging BC technology and a Deep Q Network (DQN) for key generation to enhance IoT security in smart city applications. A novel authentication model, Deep Q Network-SecAuth (DQN-SecAuth), is proposed for secure D2D communication using BC. The model involves key entities such as the Registration Authority Center (RAC), blockchain, and IoT devices. The authentication process includes six stages: setup, registration, key generation, authentication, new device addition, and formal verification. In the key generation stage, the secret key is generated using a Deep Learning (DL) model named DQN. The proposed model also incorporates encryption, hash functions, Chebyshev polynomials, and XOR operations to ensure security. The DQN-SecAuth model achieved a minimum computational time of 9.525 s and memory usage of 42.897 megabytes (Mb), consensus delay of 0.420 s, energy consumption of 0.715 J, latency of 0.469 s, power consumption of 0.270 kW-hour (kWh), and throughput of 0.804 megabits per second (Mbps). The key novelty of this work is the use of a DQN for adaptive key generation, integrated into a BC-based authentication framework. This combination enhances security, reduces computational overhead, and outperforms traditional static key-generation and authentication methods in smart city IoT environments.},
  archive      = {J_EAAI},
  author       = {K. Prabhu Chandran and Bhuvaneswari P and Sivasankaran V and Vimala S},
  doi          = {10.1016/j.engappai.2025.112141},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112141},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Blockchain and deep learning-enabled IoT device-to-device authentication approach for smart cities using 5th generation technology},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergency medical facility site selection in drone-based relief operations using an enhanced T-spherical fuzzy frank combined compromise solution method. <em>EAAI</em>, <em>161</em>, 112140. (<a href='https://doi.org/10.1016/j.engappai.2025.112140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) play a vital role in disaster response operations, emphasizing the need for efficient site selection for emergency medical facilities (EMFs). This study presents a structured framework for evaluating candidate sites and identifying critical criteria for establishing EMFs in drone-based relief operations. It proposes a novel T-spherical fuzzy (T-SF) multi-criteria group decision-making framework for EMF site selection. The framework integrates the T-SF-Entropy method and a hybrid subjective–objective weighting scheme that combines stepwise weight assessment ratio analysis and the method based on the removal effects of criteria. This integration enables a more reliable aggregation of expert opinions. The framework applies T-SF Frank aggregation operators in the modified combined compromise solution method to rank potential sites under multi-disaster conditions. A real-world case study evaluates alternative sites using the critical criteria and demonstrates the practical utility of the proposed model in the field of emergency engineering logistics. Quantitative analysis shows that the “urban logistics hub” achieves the highest compromise index due to its advantages in proximity, infrastructure, and supply chain access. Sensitivity analysis confirms that variations in parameters do not affect the stability of rankings. This study uses artificial intelligence to support intelligent decision-making in disaster response. It provides an effective engineering application that optimizes UAV-based healthcare deployment, enhances resource allocation, and improves the speed and accuracy of emergency medical responses.},
  archive      = {J_EAAI},
  author       = {Rajdip Mahajan and Saptadeep Biswas and Vladimir Simic and Dragan Pamucar and Abhijit Baidya and Uttam Kumar Bera},
  doi          = {10.1016/j.engappai.2025.112140},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112140},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Emergency medical facility site selection in drone-based relief operations using an enhanced T-spherical fuzzy frank combined compromise solution method},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature description attention: Channel-independent local–global fusion for multi-scale feature representation. <em>EAAI</em>, <em>161</em>, 112139. (<a href='https://doi.org/10.1016/j.engappai.2025.112139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent deep convolutional networks, attention mechanisms rely heavily on global information to generate attention weights, but few methods can effectively recalibrate global features based on local object characteristics. To address this gap, we introduce a masked-averaging strategy that adaptively selects regions of interest from the feature map, allowing local features to encode and reflect global information. By combining these local descriptors with global averages and maximums into a multi-scale Bag-of-Visual-Words (BoVW), our method jointly captures salient point, local region, and global context, resulting in richer and more discriminative feature representations. Additionally, we propose Feature Batch Normalization (FBN) to facilitate cross-channel interactions, further enhancing the performance of attention modules. In terms of engineering applications, to overcome the limitations of traditional channel-dependent attention under model compression and pruning, we design a channel-independent feature recalibration mechanism based on one-dimensional depthwise convolution, termed Feature Description Attention (FDA). It leverages the properties of BoVW and FBN to provide a flexible and lightweight attention module with minimal computational overhead and robust performance under quantization and pruning. Our method demonstrates consistent gains across three vision tasks: classification accuracy improves by 0.72–1.68%, object detection performance increases by 1.8–3.0% mean average precision, and segmentation accuracy rises by 1.9%. These results across different benchmarks confirm the effectiveness and generalizability of our approach. FDA offers a scalable, hardware-friendly solution for modern vision applications, especially valuable in resource-constrained settings such as mobile deployment, autonomous systems, and medical image analysis.},
  archive      = {J_EAAI},
  author       = {Yuanyang Zhu and Guangjie Han and Hongbo Zhu and Fan Zhang},
  doi          = {10.1016/j.engappai.2025.112139},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112139},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature description attention: Channel-independent local–global fusion for multi-scale feature representation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving robustness of transformers for power quality disturbance classification via optimized relevance maps. <em>EAAI</em>, <em>161</em>, 112138. (<a href='https://doi.org/10.1016/j.engappai.2025.112138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power quality disturbances (PQDs) are a critical area of research in the power systems domain. The growing complexity of modern power systems increases the variability of PQDs that may occur, making it challenging to manage power quality using traditional methods, and motivates the inclusion of machine learning models. However, these models are vulnerable to adversarial attacks. The predominant defense approach is adversarial training, which increases robustness at the price of significant increase in computational complexity of the training process, and can often lead to reduced accuracy on non-adversarial examples. In this light, this paper introduces a distinct approach to increase the robustness of Transformer-based PQD classifiers by leveraging their intrinsic explainability derived from the self-attention mechanism. By incorporating the resulting explainable features in the form of relevance maps into the loss function during the fine-tuning stage, we guide the model to focus on salient disturbance features. This method enhances the robustness against adversarial attacks, without compromising accuracy, and avoids the additional computational overhead associated with adversarial training. Experimental results show that when no adversarial attack is applied, the fine-tuning stage increases the PQD classification accuracy from 97.62% to 99.26%, thus overcoming the accuracy-robustness trade-off. Furthermore, the Transformer with the proposed fine-tuning stage is more adversarial robust than a state-of-the-art deep Convolutional neural network (DeepCNN) PQD classifier. The proposed Transformer maintains accuracy and F1 scores slightly above 88%, whereas fo DeepCNN both scores are slightly below 66.60%, thus highlighting the effectiveness of our approach.},
  archive      = {J_EAAI},
  author       = {Itamar Kapuza and Elinor Ginzburg-Ganz and Ram Machlev and Yoash Levron},
  doi          = {10.1016/j.engappai.2025.112138},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112138},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving robustness of transformers for power quality disturbance classification via optimized relevance maps},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive epipolar geometry for robust light field super-resolution. <em>EAAI</em>, <em>161</em>, 112137. (<a href='https://doi.org/10.1016/j.engappai.2025.112137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light field technology captures both spatial and angular information, densely sampled high-resolution light field images contain abundant 3-dimensional geometric information, enabling widespread applications in various industrial fields. However, existing methods for joint spatial and angular super-resolution of light field images face significant challenges when reconstructing scenes with large disparities and significant occlusions. To address this issue, we propose a geometric information enhancement module that enables efficient extraction and preservation of geometric information, and then we propose a non-disparity-based, one-stage approach that allows for the direct reconstruction of densely sampled high-resolution light field images from sparsely sampled low-resolution counterparts. Specifically, we decompose the original 4-dimensional light field image into three distinct 2-dimensional representations: spatial, angular, and epipolar plane image. Among these representations, the epipolar plane image contains abundant geometric information, which inspires us to propose a more efficient feature extractor. In addition, we introduce a progressive feature fusion strategy that better preserves geometric information extracted from epipolar plane images. Finally, to avoid errors introduced by warping operations that complicate the process of enhancing geometric information, we introduce a spatial-angular integrated upsampling module. Extensive experimental results on public datasets demonstrate that our proposed method significantly outperforms state-of-the-art approaches both quantitatively and qualitatively. Specifically, on the Occlusions dataset, our method achieved significant improvement in performance while reducing inference time by approximately 80% compared to the current best method. This efficiency gain is particularly beneficial for practical applications of the artificial intelligence algorithm.},
  archive      = {J_EAAI},
  author       = {Hao Zhang and Hao Sheng and Rongshan Chen and Da Yang and Ruixuan Cong and Zhenglong Cui and Xuefei Huang and Guanqun Su},
  doi          = {10.1016/j.engappai.2025.112137},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112137},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Progressive epipolar geometry for robust light field super-resolution},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring knee joint moment prediction models for landing task with various model architecture: Leveraging inertial measurement unit sensors data and subject-specific attributes. <em>EAAI</em>, <em>161</em>, 112136. (<a href='https://doi.org/10.1016/j.engappai.2025.112136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a comparative evaluation of deep learning models for predicting Three-Dimensional (3D) knee joint moments during landing tasks using Inertial Measurement Unit (IMU) data. We assess a range of architectures, from simple feedforward networks to complex Three-Dimensional Convolutional Neural Networks (3D-CNN), to balance predictive accuracy with computational cost. The 3D-CNN model achieved the highest performance, with relative Root Mean Squared Error (rRMSE) values of 6.08 % for the knee abduction moment, 5.3 % for the external rotation moment, and 4.9 % for the flexion moment. We further explored the effect of adding subject-specific features, which yielded modest performance gains. While these features provided some improvement, model performance primarily depended on sensor data, reinforcing the need to integrate both biomechanical and Artificial Intelligence-driven insights. From an engineering application perspective, our findings guide researchers and clinicians in selecting the most suitable model and sensor placement based on both accuracy and computational complexity. Specifically, we highlight thigh-mounted IMU as the most effective placement for capturing landing dynamics. These insights support the practical deployment of knee joint moment prediction systems in real-world settings, such as gyms or training centers, where compact sensors and limited computational resources are essential.},
  archive      = {J_EAAI},
  author       = {Tommy Sugiarto and Yi-Jia Lin and Ya-Wen Tu and Hsiao-Liang Tsai and Lin-Fen Hsieh and Chi-Tien Sun and Patrik Kutilek and Wei-Chun Hsu},
  doi          = {10.1016/j.engappai.2025.112136},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112136},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring knee joint moment prediction models for landing task with various model architecture: Leveraging inertial measurement unit sensors data and subject-specific attributes},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key region semantic information augmented transformer for image captioning. <em>EAAI</em>, <em>161</em>, 112135. (<a href='https://doi.org/10.1016/j.engappai.2025.112135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing image captioning models often face difficulties in capturing inter-object relationships and generating description that comprehensively understands the entire image content, either relying on object detectors that overlook contextual information or depending on grid features that fail to adequately model spatial interactions. This paper proposes two solutions to these challenges. The first is the introduction of a module for mining semantic information from key regions. Based on the spatial proximity and high co-occurrence between objects, this module identifies the public region covered by these objects as a key region, mines their semantic information, and incorporates it into the modeling process, which compensates for the limitations of grid features. Second, we improve the standard Transformer decoder’s architecture by innovatively introducing an adaptive gating mechanism that dynamically adjusts the alignment between textual and visual features, enhancing the model’s overall comprehension of the image. To validate our approach, we applied these modules to the Transformer framework and proposed a novel method for image captioning, called Key region Semantic information Augmented Transformer (KSAT) for Image Captioning. Extensive experiments on benchmark datasets show that the proposed method outperforms many models. Specifically, our method achieves a score of 139.6% on the offline test, and 138.4% on the official online test server on the Consensus-based Image Description Evaluation (CIDEr) metric. In qualitative evaluation, our method also outperforms other methods at generating captions for complex scenes. Overall, these results confirm the validity of our method and advance the field of artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Fuyun Deng and Wei Li and Zhixin Li},
  doi          = {10.1016/j.engappai.2025.112135},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112135},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Key region semantic information augmented transformer for image captioning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced neural-network-based iterative learning control considering iterative uncertainties for piezoelectric actuated micro-positioning platform. <em>EAAI</em>, <em>161</em>, 112134. (<a href='https://doi.org/10.1016/j.engappai.2025.112134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research aims to developing a new enhanced data-driven sliding-mode iterative learning control (E-DDSILC) strategy for piezoelectric actuated micro-positioning (PAMP) platforms. For the first time, the analysis demonstrating that errors converge to 0 in E-DDSILC is successfully extended from strictly repetitive systems to systems with non-strictly repetitive initial conditions. This generalization expands the practical application range of E-DDSILC. Simultaneously, iterative uncertainties are considered, which are the major factor affecting the performance of iterative learning control. To address these uncertainties, a diagonal recurrent neural network is employed to fit and compensate for them within a dynamic linearization model, thereby further enhancing the tracking accuracy and practicability of E-DDSILC. Finally, Several experiments are performed on a PAMP platform to compare the developed E-DDSILC method with both classical DDSILC and traditional E-DDSILC schemes. Comparative experimental results prove the superiority of the developed controller.},
  archive      = {J_EAAI},
  author       = {Miaolei Zhou and Yulong Sun and Xiuyu Zhang and Wei Gao and Chun-Yi Su},
  doi          = {10.1016/j.engappai.2025.112134},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112134},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced neural-network-based iterative learning control considering iterative uncertainties for piezoelectric actuated micro-positioning platform},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-driven multi-stage stochastic optimization for sustainable humanitarian supply chain using machine learning algorithms. <em>EAAI</em>, <em>161</em>, 112133. (<a href='https://doi.org/10.1016/j.engappai.2025.112133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The frequency and severity of natural disasters have intensified, resulting in significant human, financial, and emotional consequences. Earthquakes, in particular, have caused severe economic losses, deaths, and homelessness among millions. This study is designed to establish a comprehensive plan for managing pre- and post-disaster phases, including preparations, responses, and recovery efforts. It introduces a Multi-Stage Stochastic Programming (MSSP) model for sustainable humanitarian relief operations, optimizing location, allocation, and inventory management. The first and third stages concentrate on minimizing environmental impacts, while the second stage centers on enhancing social welfare. Simultaneously, economic cost reduction is consistently pursued in all three stages. The model's primary advantages include optimized inventory management to avoid shortages and flexible logistics strategies for timely and cost-effective delivery of relief items. Additionally, it ensures continuous aid, addressing both short-term and long-term needs to improve disaster management effectiveness and resilience. The multi-objective model is solved using Augmented Epsilon-Constraint (AEC). Furthermore, this paper employs Multi-Criteria Decision-Making (MCDM) methods to rank suppliers, leveraging Machine Learning (ML) algorithms to enhance ranking precision, thereby leading to a more responsive Supply Chain (SC). A real-world case study is then provided to illustrate the applicability and validity of the proposed model. Focusing on achieving balanced sustainability across all three stages, ensuring seamless logistics for all humanitarian supplies and affected individuals, and addressing uncertainties, the model determines the optimal quantities of all relief items to store. Through comprehensive analysis, the results provide key insights into the importance of MSSP in disaster management plans, enhancing understanding of the model's effectiveness.},
  archive      = {J_EAAI},
  author       = {Farnaz Ansari and Ali Bozorgi-Amiri and Hossein Shakibaei},
  doi          = {10.1016/j.engappai.2025.112133},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112133},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A data-driven multi-stage stochastic optimization for sustainable humanitarian supply chain using machine learning algorithms},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A theme music generation model based on hybrid variational autoencoders and conditional generative adversarial networks. <em>EAAI</em>, <em>161</em>, 112131. (<a href='https://doi.org/10.1016/j.engappai.2025.112131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The musical theme is the core melodic element that runs through a work. It is the main source of recognizable features and the basis of the overall structure of the score. However, existing music generation systems often face problems with missing thematic features and monotonous structure. These systems find it difficult to capture the complex thematic changes and long-term dependencies in music, resulting in a lack of dynamic changes, artistic expression in phrasing, and structural coherence in the generated results. In this paper, we propose a thematic music generation model based on a generative adversarial network, named Thematic Music Conditional Generative Adversarial Network (TM-CGAN), which solves these challenges through three key innovations. First, we propose a thematic fusion degree calculation module based on multi-dimensional feature metrics to overcome the theoretical limitations of existing methods, which lack explicit modeling of thematic features. Subsequently, we construct a two-dimensional image representation learning framework that preserves Musical Instrument Digital Interface (MIDI) symbolic sequences and employs convolutional neural networks (CNNs) to effectively model the multi-dimensional feature dependencies inherent in musical structures. Finally, we design a hybrid variational autoencoder-conditional generative adversarial network architecture that processes latent space modeling of thematic features through variational inference mechanisms while simultaneously optimizing generation quality through adversarial training. We conducted comprehensive experiments across three diverse MIDI music datasets to validate our approach. The experimental results demonstrate that TM-CGAN significantly outperforms state-of-the-art baseline models on multiple evaluation metrics, including generated music quality, theme representativeness, and structural integrity.},
  archive      = {J_EAAI},
  author       = {Fangzhu Jin and Peng Li and Xiaojun Wu},
  doi          = {10.1016/j.engappai.2025.112131},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112131},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A theme music generation model based on hybrid variational autoencoders and conditional generative adversarial networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Malicious detection and trust calculation using residual recurrent neural network for trust with quality of service-aware multicast routing in mobile ad-hoc network system. <em>EAAI</em>, <em>161</em>, 112130. (<a href='https://doi.org/10.1016/j.engappai.2025.112130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Mobile Ad-hoc Network is a collection of mobile nodes without any proper infrastructure. In this work, a novel trust and Quality of Service-aware multicast routing technique for Mobile Ad-hoc Network is introduced. The key scope of this research paper is to evaluate the trust with Quality of Service -aware multicast routing process in Mobile Ad-hoc Network by detecting malicious nodes. For performing the optimal routing without any suspicious attacks initially the malicious node detection is performed by Residual Recurrent Neural Network. Further, if the Mobile Ad-hoc Network model is normal and free from malicious nodes, then the true value is calculated by utilizing the outcome of malicious node detection. If the node is free from malicious then, the trust value becomes high or else the trust value becomes low. Once, the trust calculation is completed the optimal routing is performed in the Mobile Ad-hoc Network with the support of the Enhanced Artificial Rabbits Optimization algorithm. Moreover, different constraints like hop count, throughput, Packet Delivery Ratio, delay, and energy consumption are derived. Further, different experiments are evaluated to prove the effectiveness of the implemented model against several baseline technique. Hence, the developed model accomplishes superior efficiency in detecting the malicious and performs the multicast routing in the Mobile Ad-hoc Network.},
  archive      = {J_EAAI},
  author       = {Sanjaya Kumar Sarangi and Rasmita Lenka and Janmejaya Mishra and Ritarani Sahu and Arabinda Nanda},
  doi          = {10.1016/j.engappai.2025.112130},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112130},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Malicious detection and trust calculation using residual recurrent neural network for trust with quality of service-aware multicast routing in mobile ad-hoc network system},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy management system scheduling optimization based on an improved generative adversarial network deep reinforcement learning algorithm. <em>EAAI</em>, <em>161</em>, 112129. (<a href='https://doi.org/10.1016/j.engappai.2025.112129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Households, as electricity consumers, play a critical role in achieving the carbon peak and carbon neutrality goals. The development of smart grids provides technical support for the efficient integration and distribution of renewable energy, gradually extending to household users. This has led to higher demands for the stability of electricity supply to address the growing electricity demand and the uncertainties associated with renewable energy. To address this, this paper proposes an improved generative adversarial network and an enhanced deep reinforcement learning algorithm to improve the scheduling capability of the energy management system. First, we introduce an improved wasserstein generative adversarial network that combines stochastic differential equations and autocorrelation penalty terms with the generator. The experimental results demonstrate that the proposed method can generate high-quality time series data. The generated data were used to train our scheduling model, effectively enhancing its generalization capability. Secondly, We introduced the Minmax mechanism to address Q-value estimation bias by utilizing multiple Q-networks. This mechanism first divides the target Q-values into several groups, selects the maximum value from each group, and then takes the minimum among these maxima as the final target Q-value. We applied this mechanism to improve deep reinforcement learning algorithms based on multi-Q-value evaluation. Comparison experiments show that this improvement significantly enhances the algorithm’s performance, outperforming traditional algorithms in terms of convergence, volatility, and final rewards. The energy management system demonstrates stronger adaptability when handling uncertainties arising from renewable energy variations, ensuring reliable power supply and achieving balanced energy management.},
  archive      = {J_EAAI},
  author       = {Weipeng Chao and Yuanbo Shi and Yushuai Li and Meng Liu and Xiaoling Leng},
  doi          = {10.1016/j.engappai.2025.112129},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112129},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Energy management system scheduling optimization based on an improved generative adversarial network deep reinforcement learning algorithm},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep ensemble learning and error correction method for remaining useful life prediction of rolling bearings. <em>EAAI</em>, <em>161</em>, 112128. (<a href='https://doi.org/10.1016/j.engappai.2025.112128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearings are critical components of rotating machinery, and the prediction of their remaining useful life (RUL) is important for system reliability and operating efficiency. A novel RUL prediction method based on deep ensemble learning and error correction is here proposed. Firstly, the moving average filter (MAF) is applied to preprocess vibration signals for removing outliers and noise. Then, time-domain features are extracted from the processed vibration signals, and optimized to obtain imperative feature signals. Subsequently, a deep ensemble learning model is built with gated recurrent unit (GRU), bidirectional GRU (BiGRU), long short-term memory (LSTM) and bidirectional LSTM (BiLSTM) as base learners, and the overall performance of the prediction model is enhanced by introducing an error correction strategy. The MAF method is also used to smooth the trend of the RUL prediction outcomes. Finally, the proposed method is applied to two full-lifecycle rolling bearing datasets: the Prognostics and Health Management 2012 (PHM2012) dataset and the Intelligent Maintenance System (IMS) dataset. It is evaluated using mean square error (MSE), mean absolute error (MAE), and the R-square coefficient of determination (R 2 ). The test results demonstrate that the method achieves highly accurate RUL predictions: on the PHM2012 dataset, the MSE, MAE, and R 2 reach 0.000380, 0.013695, and 0.994716, respectively; on the IMS bearing dataset, the corresponding values are 0.001056, 0.015403, and 0.978346. In addition, the method outperforms traditional single models (GRU, BiGRU, LSTM, BiLSTM) as well as the Transformer model in both cases, with R 2 improvements over the Transformer of 0.011065 and 0.008744, respectively. These results highlight the superior generalization capability and robustness of the proposed method, making it applicable to industrial environments requiring reliable RUL prediction.},
  archive      = {J_EAAI},
  author       = {Wenzhe Yin and Hong Xia and Enrico Zio and Xueying Huang},
  doi          = {10.1016/j.engappai.2025.112128},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112128},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep ensemble learning and error correction method for remaining useful life prediction of rolling bearings},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maritime supply chain optimization using robust adversarial reinforcement learning. <em>EAAI</em>, <em>161</em>, 112127. (<a href='https://doi.org/10.1016/j.engappai.2025.112127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores novel strategies for analyzing and managing port productivity in a multi-stage supply chain network by integrating synchronization and reinforcement learning (RL) techniques. Current port management systems face issues with nonlinearity, high interdependency, and vulnerability to market disruptions, which might destabilize port operations. To tackle these issues, seaport operations are examined in four stages of implementation: the terminal operator, inland carrier, inland terminal operator, and consignee. Brownian motion is applied to characterize stochastic disruptions in volatile markets, and the port performance under market disruptions is analyzed using nonlinear data analytics. The dynamical analysis reveals that port management systems exhibit highly coupled nonlinear dynamics with a tendency towards instability. The complex nature of maritime port logistics requires innovative strategies to analyze container handling volumes, optimize the strategic planning of port management, and improve overall efficiency. A novel optimal policy for port operations is realized by integrating a deep deterministic policy gradient into robust adversarial deep learning. A deep reinforcement learning algorithm is employed to learn adaptively from historical port-related data and real-time container handling feedback, enabling intelligent strategies to make informed decisions and dynamically adjust policies in response to stochastic disruptions or changing market conditions. Quantitative results demonstrate that the proposed strategy achieves up to 97.78 % operating efficiency despite disturbances, and the adversarial attacks are shown to decrease port productivity by up to 77.78 % in scenarios without robust deep learning support. This study contributes to the growing field of intelligent port operations by paving the way for more adaptive and smart solutions in the maritime supply chain network.},
  archive      = {J_EAAI},
  author       = {Truong Ngoc Cuong and Sam-Sang You and Le Ngoc Bao Long and Hwan-Seong Kim and Duy Anh Nguyen and Nguyen Duy Tan},
  doi          = {10.1016/j.engappai.2025.112127},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112127},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Maritime supply chain optimization using robust adversarial reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Employing dual-path structure and soft attention mechanism to enhance recognition and classification of wild medicinal licorice in xinjiang. <em>EAAI</em>, <em>161</em>, 112126. (<a href='https://doi.org/10.1016/j.engappai.2025.112126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Licorice is highly valued in traditional Chinese medicine for its anti-inflammatory, antiviral, and immunomodulatory properties, and is widely used in the pharmaceutical, food, and cosmetic industries. Xinjiang, the largest licorice-producing region in China, faces severe overharvesting of wild licorice due to increasing market demand, threatens natural populations and fragile ecosystems. Accurate identification and classification of licorice species are crucial for environmental protection and sustainable resource utilization, as traditional methods relying on experience are inefficient, subjective, and prone to errors. This study builds on the Inception-Residual Network-Version 2 (Inception-ResNet-V2) architecture and proposes an advanced licorice recognition model called Inception-ResNet-V2-Soft Attention, Dual-path Structure, and Focal Loss (IRV2-SDF). The IRV2-SDF model integrates a soft attention mechanism that focuses on key regions, a dual-path structure for multi-scale feature extraction, and a focal loss function to address class imbalance. It aims to improve the identification and classification of three wild licorice species ( Glycyrrhiza glabra , Glycyrrhiza inflata , and Glycyrrhiza uralensis ) and associated weeds in complex environments. Trained on 3,653 images collected from Xinjiang, the model achieves an average recognition accuracy of 91.79%, surpassing traditional models, with accuracy improvements of 4.27%, 2.08%, 2.76%, and 6.36% for G. glabra , G. inflata , G. uralensis , and weeds, respectively. By effectively reducing background noise and enhancing detection capabilities, the model overcomes the limitations of traditional methods and provides a robust solution for wild licorice recognition. This research offers a technical foundation for licorice conservation and sustainable utilization and can serve as a reference for identifying other medicinal plants in complex environments.},
  archive      = {J_EAAI},
  author       = {Yuan Qin and Jianguo Dai and Guoshun Zhang and Miaomiao Xu and Jing Yang and Jinglong Liu},
  doi          = {10.1016/j.engappai.2025.112126},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112126},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Employing dual-path structure and soft attention mechanism to enhance recognition and classification of wild medicinal licorice in xinjiang},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time cooperative target tracking in cluttered environments using multiple drone swarms with adaptive fuzzy emotional learning. <em>EAAI</em>, <em>161</em>, 112125. (<a href='https://doi.org/10.1016/j.engappai.2025.112125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a real-time adaptive trajectory prediction framework for cooperative unmanned aerial vehicle (UAV) swarms engaged in dynamic target tracking within cluttered environments. The proposed system introduces a novel artificial intelligence (AI)-based control architecture combining fuzzy inference, neuro-emotional learning, and distributed multi-agent coordination. At the core of the approach is a Bidirectional Fuzzy Brain Emotional Learning Prediction (BFBEL-P) model, which integrates fuzzy logic and an online adaptive neural structure to enable trajectory forecasting without pre-training or prior knowledge of the environment. From an engineering perspective, this AI model is deployed in UAV swarm navigation, where robust decision-making, predictive coordination, and obstacle avoidance are essential for target interception missions. In contrast to conventional prediction methods, such as curve fitting, nonlinear model predictive control (MPC), and deep learning-based Long Short-Term Memory (LSTM) networks, the BFBEL-P framework offers fast convergence, low computational cost, and high adaptability. The system incorporates multi-threaded data fusion across the swarm to achieve consensus-driven predictions and maintain situational awareness, even under sensor failures or occlusions. Simulation results show that BFBEL-P improves short-term prediction accuracy by 82.2%, reduces prediction time by 15%, and achieves a 100% tracking success rate across benchmark scenarios. These results establish BFBEL-P as a reliable AI technique for distributed control in real-world UAV swarm applications, offering a promising tool for search-and-rescue, surveillance, and defense operations.},
  archive      = {J_EAAI},
  author       = {Lucas William Page and Vu Phi Tran and Duy Luan Nguyen},
  doi          = {10.1016/j.engappai.2025.112125},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112125},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time cooperative target tracking in cluttered environments using multiple drone swarms with adaptive fuzzy emotional learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical multi-scale matched masked autoencoder for industrial multi-rate time series modeling. <em>EAAI</em>, <em>161</em>, 112122. (<a href='https://doi.org/10.1016/j.engappai.2025.112122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical industrial processes, due to sensor hardware limitations, the sampling rates of different variables often vary, leading to multi-rate time series (MRTS) data. However, the distribution of multi-scale dynamics in MRTS data typically follows a step-like pattern, with intricate scale transitions from fine to coarse and complex scale-consistent dependencies across rates. Additionally, the inherent characteristics of MRTS data often result in label scarcity. Both factors present significant challenges for MRTS modeling. To address these issues, we propose a novel self-supervised learning strategy, called H ierarchical M ulti-Scale M atched M asked A utoencoder (H3MAE). Specifically, we design a scale-matching input fusion mechanism where each layer is hierarchically aligned to a specific scale, with the scale-matching integration from two sources, effectively capturing the multi-scale dynamics and cross-rate scale-consistent dependencies in MRTS data. Besides, we introduce a novel auxiliary task that imputes masked positions in the encoded representation space at each layer, aiming to achieve MRTS representation learning and mitigate label scarcity. Furthermore, we propose a unique encoder-imputer structure in each layer to enable multi-scale self-supervised learning while generating temporally aligned features satisfying the input requirements of the next layer. Experimental results on three benchmark datasets and two industrial multi-rate tasks demonstrate that our framework yields better performance in MRTS modeling. The code is publicly available at https://github.com/monolithycq/H3MAE .},
  archive      = {J_EAAI},
  author       = {Changqing Yuan and Yongfang Xie and Shiwen Xie and Jie Wang},
  doi          = {10.1016/j.engappai.2025.112122},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112122},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical multi-scale matched masked autoencoder for industrial multi-rate time series modeling},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised feature selection via latent feature representation and modified graph embedding. <em>EAAI</em>, <em>161</em>, 112121. (<a href='https://doi.org/10.1016/j.engappai.2025.112121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data in practical applications are correlated not only between samples but also between high-dimensional features. Latent representations can effectively represent such correlations. Existing latent representation methods mainly consider inter-instance relationships and rely on constructing similarity graphs. However, the interconnection information obtained by latent representations is redundant due to the noise and irrelevance of the raw data. Therefore, to address the above issues, this paper proposes an unsupervised feature selection by latent feature representation and modified graph (LFRMG, for short) embedding. First, a latent feature representation norm for learning self-representation structure is designed to explore the interconnections among features. Mining feature relationships via self-representation can solve the redundancy caused by fixed similarity graph relationships. Second, the latent feature representation is combined with modified graph regularization to achieve good feature interconnections while maintaining local data information. In addition, the l 2 , 0 -norm is utilized to select the full-row sparse projection of salient features to avoid the drawbacks of sparsity limitation and parameter tunability. A scheme for solving the closed form of l 2 , 0 is constructed. Finally, the presented approach is superior to many state-of-the-art unsupervised methods through comprehensive experiments on nine existing datasets.},
  archive      = {J_EAAI},
  author       = {Jialing Yan and Gang Hu and Guo Wei},
  doi          = {10.1016/j.engappai.2025.112121},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112121},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised feature selection via latent feature representation and modified graph embedding},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coarse-to-fine dual-branch network for ship target recognition in complex environments. <em>EAAI</em>, <em>161</em>, 112120. (<a href='https://doi.org/10.1016/j.engappai.2025.112120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harsh sea conditions and the complex and variable positions of ships significantly impact the capacity of imaging devices to capture high-quality ship images, making ship target recognition challenging in the application of artificial intelligence. Many scholars have recently proposed cascaded recognition models to address this issue. Following this method, in this paper, we propose a novel method for ship target recognition in complex environments called the coarse-to-fine dual-branch (CFDB) network. The CFDB model designs a dual-branch network from coarse to fine to lock the target area fine features and then uses peer-to-peer communication to extract and exchange learning of the target region’s final discriminative contour features, assisting in predicting ship classes in the complex environment. The proposed method is evaluated on the constructed complex in background ships (CIB-ships) dataset and the publicly available Marine Argos Recognition Ships (MAR-ships) and Game-of-Ships datasets. Compared with the suboptimal method, the proposed CFDB network exhibits improvements of 2.11%, 1.33%, and 1.24% accuracy on the CIB-ships, MAR-ships, and Game-of-ships datasets, respectively. The results demonstrate that the proposed method provides useful ideas for the dynamic monitoring of ships in real environments. Our code will be published at https://github.com/yangt1013/CFDB-master .},
  archive      = {J_EAAI},
  author       = {Yang Tian and Hao Meng},
  doi          = {10.1016/j.engappai.2025.112120},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112120},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Coarse-to-fine dual-branch network for ship target recognition in complex environments},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-scale sparse channel transformer network for image reconstruction of astronomical bright source contamination. <em>EAAI</em>, <em>161</em>, 112119. (<a href='https://doi.org/10.1016/j.engappai.2025.112119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bright source contamination has long been a challenging issue in the field of image processing, particularly in applications such as astronomical observations, satellite imaging, and nighttime surveillance. To address this issue, this paper proposes a novel Multi-Scale Sparse Channel Transformer Network (MSCformer) aimed at achieving high-quality image reconstruction under the influence of bright source contamination. The network integrates a Top-k Sparse Attention mechanism with a Channel Attention module, enabling selective focus on the most informative features and adaptive weight allocation across channels. Additionally, a Multi-Scale Dual-Gate Feedforward Network is designed to further enhance the expression of valuable features while suppressing redundant information. Experimental results demonstrate that the proposed method exhibits outstanding performance in practical applications on the Sloan Digital Sky Survey (SDSS) photometric image dataset. Compared to existing state-of-the-art techniques, MSCformer achieves significant performance improvements, with a Peak Signal-to-Noise Ratio (PSNR) of 45.093 decibel(dB), a Structural Similarity Index Measure(SSIM) of 0.978, and a Pixel Average Absolute Error (PAAE) of 0.675. This not only significantly enhances the removal of bright source contamination in the field of astronomy but also provides important reference value for subsequent research in related domains.},
  archive      = {J_EAAI},
  author       = {Yajuan Zhang and Congcong Shen and Xia Jiang and Bo Qiu and Ali Luo and Fuji Ren and Yuanlu Chen},
  doi          = {10.1016/j.engappai.2025.112119},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112119},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-scale sparse channel transformer network for image reconstruction of astronomical bright source contamination},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Seismic damage assessment of reinforced concrete frame structures based on transfer-residual networks. <em>EAAI</em>, <em>161</em>, 112118. (<a href='https://doi.org/10.1016/j.engappai.2025.112118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post-earthquake building damage assessment is a critical research focus in civil engineering due to its vital role in guiding timely and informed rescue operations. This study proposes a rapid seismic damage assessment method for reinforced concrete frame structures based on transfer-residual networks. The methodology involves pre-training a base model on a large dataset generated from computationally efficient simplified model simulations, followed by transfer learning on a smaller, high-fidelity dataset derived from refined finite element model simulations. This approach significantly enhances prediction accuracy while reducing computational costs for seismic damage assessment in new building structures. Optimization of model parameters was performed to find the optimal residual network, which achieves an accuracy of 91.2 % with a remarkable 32-fold speedup over conventional nonlinear time-history analysis methods. Moreover, the transfer-residual network enhances accuracy by 10 % compared to training from scratch. The results conclusively demonstrate the feasibility of utilizing large datasets from simplified models to improve the training accuracy of refined models with limited data, providing a valuable reference for advancing transfer learning-based frameworks in seismic damage assessment of buildings.},
  archive      = {J_EAAI},
  author       = {Chen Xiong and Zhijie Luo and Jie Zheng and Linlin Xie and Liu Mei and Lixiao Li and Wujian Long},
  doi          = {10.1016/j.engappai.2025.112118},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112118},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Seismic damage assessment of reinforced concrete frame structures based on transfer-residual networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-enabled performance-based design of three-dimensional printed engineered cementitious composites. <em>EAAI</em>, <em>161</em>, 112117. (<a href='https://doi.org/10.1016/j.engappai.2025.112117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The superior tensile ductility of engineered cementitious composites (ECC) offers a promising solution to the challenge of integrating conventional steel reinforcement in three-dimensional (3D) concrete printing (3DCP). However, the widespread adoption of 3D printed ECC (3DP-ECC) is hindered by the reliance on trial-and-error design process. The complex material component and inherent anisotropy of 3DP-ECC pose challenges for accurate property prediction and inverse design. This paper introduces a performance-based design strategy for 3DP-ECC, leveraging machine learning (ML) and multi-objective optimization. The anisotropic-mechanical properties including compressive strength and flexural strength were experimentally and statistically investigated; further, ML prediction models conbined with multi-objective optimization algorithm were developed to inversely design 3DP-ECC for specific mechanical performance requirements, while reducing carbon footprint and material cost. Specifically, an extensive database was assembled, followed by grey relational analysis (GRA) to identify the parametric sensitivity of the mechanical properties of 3DP-ECC. Three representative ML techniques were employed, with the back-propagation artificial neural network (BPANN) demonstrating superior predictive accuracy. Model interpretability analyses uncovered the importance of input parameters and their influence on predicted outcomes. Lastly, non-dominated Sorting Genetic Algorithm II (NSGA-II) integrated with the BPANN models was applied to perform the inverse design of 3DP-ECC, showing good effectiveness and accuracy. This work offers an efficient and viable avenue for performance-based design for 3DP-ECC, along with the potential to develop low-carbon cost-effective 3DP-ECC.},
  archive      = {J_EAAI},
  author       = {Wenguang Chen and Long Liang and Junhong Ye and Lingfei Liu and Neven Ukrainczyk and Liqiang Yin and Jiangtao Yu and Kequan Yu},
  doi          = {10.1016/j.engappai.2025.112117},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112117},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning-enabled performance-based design of three-dimensional printed engineered cementitious composites},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized text-to-image generation with large language and vision assistant enhanced training. <em>EAAI</em>, <em>161</em>, 112116. (<a href='https://doi.org/10.1016/j.engappai.2025.112116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized image generation aims to synthesize images of a specific identity. The identity, denoted as V ∗ , refers to an entity with distinctive visual attributes, such as a dog-shaped backpack. However, existing methods like DreamBooth and Custom Diffusion often struggle to generate images of V ∗ that accurately match the input prompts. In this work, we analyze two key issues underlying this limitation: (1) the overbinding problem , where the prompt tokens used to represent V ∗ unintentionally bind to irrelevant visual details from the reference image during training; and (2) the low language prior problem , where insufficient use of pre-trained language prior limits the model’s ability to faithfully generate all the prompt words. To overcome these challenges, we propose LLaVA-Booth, a novel personalization method for diverse, identity-preserving image generation, based on Large Language and Vision Assistant (LLaVA) enhanced training. Our method alleviates the overbinding problem by disentangling background information and solves the low language prior problem by enriching the language context. Additionally, we introduce two auxiliary objectives: (1) an identity (ID) binding loss to strengthen the identity binding and (2) a prior preservation loss to prevent language drift and encourage generation diversity. Experiments demonstrate that LLaVA-Booth effectively mitigates overbinding and enhances language priors to improve prompt fidelity, then generates diverse, high-quality, and identity-preserving images of V ∗ .},
  archive      = {J_EAAI},
  author       = {Junsheng Luan and Zhanjie Zhang and Wei Xing and Lei Zhao},
  doi          = {10.1016/j.engappai.2025.112116},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112116},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Personalized text-to-image generation with large language and vision assistant enhanced training},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-view new energy vehicle form generation design method combining kansei imagery and deep learning. <em>EAAI</em>, <em>161</em>, 112115. (<a href='https://doi.org/10.1016/j.engappai.2025.112115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the competitive landscape of new energy vehicles, exterior design has become a crucial differentiator amid functional homogenization. User preferences are central to shaping vehicle appearance, yet most perceptual design methods rely on a single viewpoint, limiting insights into complex preference patterns. This study proposes a multi-perspective mapping approach that integrates Kansei engineering with deep learning. Firstly, user core imagery is collected and mined through big data. Secondly, Kernels Network (KNet) semantic segmentation model, Residual Networks (ResNet) tri-view (front/side/rear) score prediction model and fully connected network (FCN) feature fusion model are integrated to construct a multi-view feature mapping system. Finally, the optimal combination of morphological elements is explored based on the Elite Genetic Algorithm (EGA), and the scheme is validated through generative artificial intelligence (AI) workflow. The experimental results demonstrate that, employing “Cool” as a case study, the three-view scheme and the combination scheme devised by this research process exhibit substantial superiority over the majority of the samples. Under identical parameters, the scheme with decision constraints surpasses the randomly generated scheme in terms of perceptual scores and stability. The performance of the test set and the experimental results collectively substantiate the model’s validity. This workflow—covering preference extraction, morphological decomposition, AI-driven generation, and validation—provides a scalable framework for new energy vehicle exterior design. It also demonstrates novel applications of Kansei engineering in multi-view fusion and generative form design.},
  archive      = {J_EAAI},
  author       = {Zihao Wang and Le Xi and Yifan Ding and Wenjie Fang and Kaiming Wang and Hongliang Zuo},
  doi          = {10.1016/j.engappai.2025.112115},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112115},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-view new energy vehicle form generation design method combining kansei imagery and deep learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable remaining useful life uncertainty prediction method for rolling bearing. <em>EAAI</em>, <em>161</em>, 112114. (<a href='https://doi.org/10.1016/j.engappai.2025.112114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearing remaining useful life prediction is the core technology of equipment maintenance. Although deep learning-based prediction methods have made significant breakthroughs, the problems of insufficient model explainability and prediction result uncertainty quantification have seriously constrained the credibility of maintenance decisions. Therefore, this research combines prediction uncertainty quantification with model explanation to propose an explainable uncertainty prediction method. The method includes multi-dimensional feature extraction, remaining useful life uncertainty prediction, and Shapley additive explanations interpreter. For feature extraction, multi-dimensional feature vectors are constructed as network inputs by extracting time-domain features and frequency-domain features. Then, the remaining useful life prediction interval for the rolling bearing is compressed by the proposed gated temporal quantile network. Finally, the prediction model is explained using the Shapley additive explanations interpreter. The multi-case validation results based on the Xi'an Jiaotong University and Changxing Sumyoung Technology Co., Ltd. (XJTU-SY) and Intelligent Maintenance Systems (IMS) rolling bearing full life cycle datasets show that the proposed model has an average interval coverage of 93.96 % and an average interval width of 9.92 %, which indicates that the model maintains high accuracy and robustness in different cases. The nonlinear mapping relationship between the prediction results and the features is clarified by analyzing the Shapley values. Finally, the Shapley values are used to rank the importance of the features to locate the position that may cause rolling bearing performance degradation, which provides credible decision support for the development of the predictive maintenance strategy.},
  archive      = {J_EAAI},
  author       = {Ting Zhang and Honglei Wang},
  doi          = {10.1016/j.engappai.2025.112114},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112114},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable remaining useful life uncertainty prediction method for rolling bearing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based estimation of sound transmission loss in single and double-layered rectangular functionally graded plates. <em>EAAI</em>, <em>161</em>, 112112. (<a href='https://doi.org/10.1016/j.engappai.2025.112112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a robust machine learning (ML) framework for predicting sound transmission loss (STL) in temperature-dependent functionally graded (FG) single- and double-layered plates, combining analytical modeling and data-driven approaches. The FG plates are modeled with material properties varying along the thickness via a power-law distribution, incorporating nonlinear temperature effects. A high-fidelity analytical solution is derived using first-order shear deformation theory (FSDT) and acoustic velocity potential, with governing equations formulated via Hamilton's principle and solved using the weighted residual method. To enable ML training, a large-scale parametric study generates 189,000 data points, covering variations in plate geometry, temperature, acoustic cavity depth, gradient index, and incident wave angles. ML algorithms are trained on this data to predict STL, with the extreme gradient boosting (XGBoost) algorithm demonstrating the highest accuracy (coefficient of determination R 2 = 99.38 % for training data and R 2 = 99.11 % for test data). The validated ML model is then employed to investigate key parameters—temperature, power-law index, incidence angle, cavity depth, and plate thickness—revealing their nonlinear interactions and impact on STL performance. The developed artificial intelligence (AI) framework provides an efficient tool for acoustic design optimization, offering real-time parameter tuning capabilities for engineers working with functionally graded acoustic barriers.},
  archive      = {J_EAAI},
  author       = {Chunfeng Jiang and Masoud Babaei},
  doi          = {10.1016/j.engappai.2025.112112},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112112},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning-based estimation of sound transmission loss in single and double-layered rectangular functionally graded plates},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cubic linguistic T-spherical fuzzy aggregation operator-based multi-attribute group decision-making model and its application to food waste treatment technique selection. <em>EAAI</em>, <em>161</em>, 112111. (<a href='https://doi.org/10.1016/j.engappai.2025.112111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food waste presents significant environmental, economic, and social challenges globally, contributing to resource depletion and greenhouse gas emissions. Effective treatment techniques are essential for minimizing these impacts, promoting sustainability, and supporting circular economy practices. However, selecting the most suitable food waste treatment technique is a complex multi-attribute group decision-making (MAGDM) problem that involves the simultaneous consideration of environmental, economic, and social factors under significant uncertainty. To address this challenge, this study proposes a novel cubic linguistic T-spherical fuzzy sets (CLT-SFSs) framework, which integrates linguistic T-spherical fuzzy sets and linguistic interval-valued T-spherical fuzzy sets to enhance decision-making precision under uncertainty. The proposed CLT-SF framework offers a unified structure capable of capturing both qualitative expert opinions and quantitative uncertainty ranges, offering unprecedented expressiveness for complex sustainability assessments. First, the formal definition and basic operations for CLT-SF numbers, including addition, multiplication, scalar multiplication, and scalar power, and a comparison law are established. Next, to efficiently aggregate cubic linguistic T-spherical fuzzy information, we propose the cubic linguistic T-spherical fuzzy weighted averaging and the cubic linguistic T-spherical fuzzy weighted geometric aggregation operators. These aggregation operators can effectively and comprehensively aggregate attribute values in MAGDM problems. Subsequently, utilizing these operators, a CLT-SFS-based combinative distance-based assessment model is developed to address MAGDM problems. The model's applicability and robustness are demonstrated through a real-world case study on the selection of food waste treatment techniques. A parameter analysis is also conducted to examine the sensitivity of ranking outcomes. Finally, a comparative analysis with existing methods confirms the proposed model's effectiveness, feasibility, and advantages in addressing complex decision-making scenarios. This research not only advances the theoretical framework of fuzzy decision-making but also provides a practical tool for stakeholders in waste management to make informed and sustainable choices.},
  archive      = {J_EAAI},
  author       = {Shahid Hussain Gurmani and Weiping Ding and Rana Muhammad Zulqarnain and Jiangfeng Hao},
  doi          = {10.1016/j.engappai.2025.112111},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112111},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cubic linguistic T-spherical fuzzy aggregation operator-based multi-attribute group decision-making model and its application to food waste treatment technique selection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextual and orientation correction modules enhance weakly-supervised aerial object detection in remote sensing images. <em>EAAI</em>, <em>161</em>, 112110. (<a href='https://doi.org/10.1016/j.engappai.2025.112110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenges of context and orientation ambiguity in weakly supervised aerial object detection. While current research focuses on improving detection accuracy and efficiency, it often encounters difficulties with contextual and rotational variations in aerial imagery. We propose a novel Context and Orientation Correction (COC) framework, which includes two innovative modules: a context correction module and an orientation correction module. The context correction module utilizes style normalization to guide the model in identifying atypical objects within specific contextual scenes by mitigating contextual disparities between instances and refining contextual information. Additionally, the orientation correction module aims to reduce feature distance between instances with varying orientations, leveraging contrastive learning to ensure consistent object representations. Furthermore, we introduce a category-aware aggregation loss to enhance similarity in feature representations of objects from the same category, thereby addressing the class collision issue commonly associated with contrastive learning. Our COC framework achieves 27.6% mean Average Precision and 59.8% mean Average Precision on the Detection in Optical Remote Sensing Image (DIOR) and Northwestern Polytechnical University Very High Resolution 10. v2 (NWPU VHR-10.v2) datasets, respectively, demonstrating its significant effectiveness.},
  archive      = {J_EAAI},
  author       = {Le Yang and Shunzhou Wang and Xuerong Wang and Shutong Wang and Yuting Lu and Binglu Wang},
  doi          = {10.1016/j.engappai.2025.112110},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112110},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contextual and orientation correction modules enhance weakly-supervised aerial object detection in remote sensing images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards detection of anomalous cosmic ray signals for observations acquired from cosmic ray extremely distributed observatory mobile detectors. <em>EAAI</em>, <em>161</em>, 112109. (<a href='https://doi.org/10.1016/j.engappai.2025.112109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose and test a method that allows the detection of anomalous cosmic ray signals acquired using Complementary Metal-Oxide-Semiconductor detectors. The method uses unsupervised embedding based on Principal Component Analysis which we named Eigenhits in apparent analogy to Eigenfaces. The embedding generated using Eigenhits allows the detection of potential anomalies, defined as images whose position described by the embedding relative to a given measure is above a certain distance threshold from other images. Thus, the problem of anomaly detection was reduced to the problem of detecting outliers which can be solved, for example, using clustering algorithms. We conducted tests of our approach on the Cosmic Ray Extremely Distributed Observatory (CREDO) dataset containing 13168 images and obtained satisfactory results demonstrating the stability and effectiveness of the method. The embedding generation method we propose in this paper and the evaluation of its effectiveness in detecting anomalies in images of cosmic ray events from CREDO dataset is a pioneering study with many critical applications.},
  archive      = {J_EAAI},
  author       = {Tomasz Hachaj and Łukasz Bibrzycki and Marcin Piekarczyk and Olaf Bar and Michał Niedźwiecki and Sławomir Stuglik and Piotr Homola and Dmitriy Beznosko and David Alvarez-Castillo and Bożena Poncyljusz and Ophir Ruimi and Oleksandr Sushchov and Krzysztof Rzecki and CREDO collaboration},
  doi          = {10.1016/j.engappai.2025.112109},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112109},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards detection of anomalous cosmic ray signals for observations acquired from cosmic ray extremely distributed observatory mobile detectors},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An uncertainty-aware safe-evolving reinforcement learning algorithm for decision-making and control in highway autonomous driving. <em>EAAI</em>, <em>161</em>, 112108. (<a href='https://doi.org/10.1016/j.engappai.2025.112108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rule-based and optimization-based approaches face challenges in decision-making and control for autonomous vehicles (AVs) in dynamic and complex highway scenarios. In contrast, reinforcement learning (RL) offers a more flexible and adaptable data-driven solution by allowing AVs to learn optimal actions through interactions with the environment, without requiring predefined rules or explicit programming. However, in real-world highway environments characterized by uncertainty, RL algorithm encounter difficulties in ensuring stability and safety. To address these challenges, this paper proposes an uncertainty-aware safe-evolving RL algorithm that integrates internal stability, external stability, and provable safety mechanisms. The internal stability mechanism ensures consistent performance improvements with high probability during policy updates itself, while the external stability leverages a benchmark policy as a reference to ensure the current policy performs at least as well as, if not better than, the benchmark. Furthermore, an action projection mechanism and a mixed learning procedure are incorporated to make minimal modifications to the learned policy, ensuring safety while supporting stable learning from both safe and original actions. The results show that the proposed algorithm maintains stability and safety throughout the learning process, achieves final performance comparable to traditional RL methods, and delivers higher training efficiency in a complex dynamic highway scenario in simulation. This suggests that the algorithm offers a viable solution for self-evolving systems in uncertain real-world environments, where traditional approaches may struggle.},
  archive      = {J_EAAI},
  author       = {Ping Lu and Sunan Zhang and Feihong Tan and Fulin Zhang and Yuxiang Feng and Bo Hu},
  doi          = {10.1016/j.engappai.2025.112108},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112108},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An uncertainty-aware safe-evolving reinforcement learning algorithm for decision-making and control in highway autonomous driving},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning-driven network for joint low-light enhancement and deblurring in maritime surveillance systems. <em>EAAI</em>, <em>161</em>, 112107. (<a href='https://doi.org/10.1016/j.engappai.2025.112107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {—Shipboard video surveillance systems are crucial for maritime environmental perception. However, shipborne cameras are often affected by challenges such as ship rolling and low illumination, causing motion blur and low-light degradation in captured images. These degradations significantly reduce the accuracy and robustness of sea-surface obstacle detection. To address this challenge, this paper presents a deep learning-based joint network model designed to simultaneously deblur and enhance low-light maritime images. Unlike existing step-by-step approaches that treat deblurring and low-light enhancement as separate tasks, the proposed model employs an encoder-decoder architecture to jointly address both tasks within a unified framework, thereby overcoming the limitations of separate processing. Furthermore, the model incorporates a novel adaptive wavelet curve attention mechanism and an extended spatial pyramid pooling module with dynamic global context to mitigate detail loss caused by sea surface reflections and artifacts in dynamic backgrounds. Additionally, a joint loss function is exploited to further enhance image restoration quality. Experiments on a self-constructed synthetic maritime dataset demonstrate that the proposed model achieves a Peak Signal-to-Noise Ratio (PSNR) of 31.81, a Structural Similarity Index Measure (SSIM) of 0.812, and a Learned Perceptual Image Patch Similarity (LPIPS) of 0.246, significantly outperforming existing competing methods. Moreover, evaluations on real-world degraded maritime images confirm the model's strong generalization ability and robustness. This advancement offers practical benefits for improving obstacle perception in autonomous ships navigating complex maritime environments.},
  archive      = {J_EAAI},
  author       = {Zeyuan Shao and Yong Yin and Hongguang Lyu and Qianfeng Jing and Tao Cheng},
  doi          = {10.1016/j.engappai.2025.112107},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112107},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep learning-driven network for joint low-light enhancement and deblurring in maritime surveillance systems},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A double hierarchy hesitant fuzzy forecasting model considering the influence of investor emotion and the co-movement of stock markets. <em>EAAI</em>, <em>161</em>, 112106. (<a href='https://doi.org/10.1016/j.engappai.2025.112106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stock market is a complex system influenced by various internal and external factors. Effective stock index forecasting models must balance interpretability with the ability to integrate multi-source information. While traditional fuzzy models offer high interpretability, they struggle to incorporate multiple dynamic factors. This study proposes a novel forecasting model based on double hierarchy hesitant fuzzy linguistic term sets (DHHFLTS), which integrates investor sentiment and international market co-movement. By constructing fuzzy logic rules, the model captures complex interactions underlying index fluctuations and enhances predictive accuracy in volatile environments. To evaluate its effectiveness, the model was tested on time series data from three major indices: the Shanghai Stock Exchange Composite Index (SSEC), Taiwan Capitalization Weighted Stock Index (TAIEX), and Financial Times Stock Exchange 100 Index (FTSE 100). The Root Mean Square Error (RMSE) achieved was 32.06 for the SSEC, 69.74 for the TAIEX, and 25.27 for the FTSE 100. Compared with existing benchmark methods, the proposed model demonstrates superior predictive accuracy and generalization performance. These findings confirm the model's capability in capturing multidimensional uncertainty and temporal patterns, highlighting its potential for intelligent financial forecasting and decision-making.},
  archive      = {J_EAAI},
  author       = {Liu Zhengmin and Du Chuantao and Zhang Jihao and Gao Shanshan and Liu Peide},
  doi          = {10.1016/j.engappai.2025.112106},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112106},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A double hierarchy hesitant fuzzy forecasting model considering the influence of investor emotion and the co-movement of stock markets},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Style prompt tuning for bridging visual gaps in autonomous driving. <em>EAAI</em>, <em>161</em>, 112105. (<a href='https://doi.org/10.1016/j.engappai.2025.112105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence models for semantic segmentation and image classification in autonomous driving must maintain reliability across adverse conditions such as rain, fog, snow, and nighttime. However, models trained on only clear daytime images often fail to generalize under such domain shifts. Existing unsupervised domain adaptation (UDA) methods employ image-level style transfer using generative adversarial networks (GANs) or diffusion models, which necessitate paired data and risk altering content. Therefore, this study proposes Style Prompt Tuning, a novel UDA framework that utilizes image–text models to automatically generate and optimize textual prompts representing target-domain styles. These prompts guide a U-Net-based style network to synthesize source images in the target style while preserving their semantic content. Our approach employs clustering within the Contrastive Language—Image Pretraining (CLIP) embedding space and a composite loss function, including content, style, transfer, patch, and total variation terms to optimize prompt quality. The generated stylized images augment the source dataset and are used to train more robust task models. Experiments on semantic segmentation benchmarks (Cityscapes-to-Adverse Conditions Dataset with Correspondences (ACDC), DarkZurich, BDD100k-night, and Nighttime Driving) and image classification (Visual Domain Adaptation 2017) reveal our approach to achieve improvements of +3.4 mean intersection-over-union (mIoU) and +0.8% accuracy over prior UDA methods. These results highlight our method’s practical effectiveness for real-world autonomous driving applications under visually challenging scenarios.},
  archive      = {J_EAAI},
  author       = {Suyeon Cha and Giyun Choi and Minji Kwak and Jongwon Choi},
  doi          = {10.1016/j.engappai.2025.112105},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112105},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Style prompt tuning for bridging visual gaps in autonomous driving},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing fuzzy cognitive map convergence through supervised and unsupervised learning algorithms: A case study of operational risk assessment in power distribution networks. <em>EAAI</em>, <em>161</em>, 112104. (<a href='https://doi.org/10.1016/j.engappai.2025.112104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Cognitive Maps (FCMs) are commonly used for modeling complex systems. However, their convergence challenges significantly limit their accuracy and reliability, especially in operational risk assessment. To address this issue, the current study proposes a novel approach that integrates advanced supervised and unsupervised learning algorithms: specifically, the Mesh Adaptive Direct Search (MADS) and Genetic Algorithm (GA). To meet the critical need for accurate risk modeling in power distribution networks, the proposed methodology utilizes ten years of time-series data from the Yazd Power Distribution Network as a real-life case study. This optimizes risk relationships and reduces convergence errors. The main contributions of this research are: (1) the development of an integrated FCM-based framework that improves convergence stability and accuracy through advanced learning algorithms, (2) the demonstration of the effectiveness of MADS in achieving faster convergence and lower error rates compared to GA, and (3) the provision of a data-driven, scalable solution for risk prioritization and decision-making in complex and dynamic systems. The results show a significant decrease in convergence error from 0.126 to 0.005, allowing for more precise risk analysis and mitigation strategies.},
  archive      = {J_EAAI},
  author       = {Elham Fallah Baghemoortini and Davood Shishebori and Mustafa Jahangoshai Rezaee and Armin Jabbarzadeh},
  doi          = {10.1016/j.engappai.2025.112104},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112104},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing fuzzy cognitive map convergence through supervised and unsupervised learning algorithms: A case study of operational risk assessment in power distribution networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised generative adversarial network for plant leaf disease detection. <em>EAAI</em>, <em>161</em>, 112103. (<a href='https://doi.org/10.1016/j.engappai.2025.112103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully supervised plant leaf disease segmentation methods based on convolutional neural networks (CNN) require large quantities of labeled images for training, which are time-consuming and labor-intensive to obtain in practical scenarios. Moreover, most diseases of plant leaf exhibit indistinct edge information and background noise interference, which hinders precise disease localization. To overcome these issues, a semi-supervised generative adversarial network (SSGAN) is proposed for plant leaf disease inspection. Firstly, to learn comprehensive semantic features from limited data, a semi-supervised method based on generative adversarial networks is developed to enhance the interaction of features among labeled and unlabeled disease images. Secondly, a boundary feature attention module (BFAM) is proposed to enhance edge detail representation, which makes the model pay more attention to the boundary feature of plant leaf diseases. Finally, a background noise suppression module (BNSM) is proposed to bolster the differentiation between the normal and disease areas so as to alleviate the adverse impact of background noise. The effectiveness of SSGAN is verified on two plant leaf disease datasets. The mean intersection over union (mIoU) on the apple and tomato leaf datasets improves by 2.07 % and 2.28 % respectively, compared with the suboptimal method. The testing results of experiments show that SSGAN achieves great performance on plant leaf disease segmentation under limited labeled data.},
  archive      = {J_EAAI},
  author       = {Lixiang Zhao and Jun Hao and Demin Li and Jianbo Yu},
  doi          = {10.1016/j.engappai.2025.112103},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112103},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised generative adversarial network for plant leaf disease detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Industrial device-aided data collection for real-time rail defect detection via a lightweight network. <em>EAAI</em>, <em>161</em>, 112102. (<a href='https://doi.org/10.1016/j.engappai.2025.112102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rail defect detection is challenging due to the diverse and irregular nature of defects, along with the limited availability of high-quality datasets. Existing methods struggle with effectively capturing multi-scale features for proper feature allocation and preserving crucial details in deep networks, leading to incomplete defect representation and reduced accuracy. To address these limitations, we propose Rail Defect Detection Network (REDNet), a lightweight deep learning model specifically designed for real-time rail defect detection in manufacturing and maintenance applications. We design the Multi-Scale Deep Feature Aggregation (MSDFA) module to enhance semantic consistency modeling and achieve more precise feature fusion. We develop the Adaptive Task Decomposition Head (ATDH) to address dynamic feature allocation, and we introduce the Reversible Column Network (RevCol) as the backbone to enhance feature extraction and ensure information reconstruction. Additionally, we developed a high-quality dataset using specialized equipment to address data scarcity and utilized it for training. REDNet achieved a high mean Average Precision at an Intersection over Union (IoU) threshold of 0.50 (mAP50) of 94.1% with exceptional real-time performance at 204.1 frames per second (FPS), while keeping an efficient design of 5.70 million parameters and surpassing state-of-the-art (SOTA) methods in accuracy and speed. These features make it suitable for defect detection, facilitating engineering deployment, and improve quality control in rail manufacturing and maintenance. Generalization tests on the public Microsoft Common Objects in Context (MS COCO) dataset yielded a mean Average Precision across IoU thresholds from 0.50 to 0.95 (mAP50–95) of 46.8%, further confirming the effectiveness of REDNet.},
  archive      = {J_EAAI},
  author       = {Qing Dong and Tianxin Han and Gang Wu and Lina Sun and Min Huang and Fu Zhang},
  doi          = {10.1016/j.engappai.2025.112102},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112102},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Industrial device-aided data collection for real-time rail defect detection via a lightweight network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A quantitative multi-dimensional resilience framework in process industries. <em>EAAI</em>, <em>161</em>, 112100. (<a href='https://doi.org/10.1016/j.engappai.2025.112100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process industries face significant safety challenges arising from the handling of hazardous materials, tightly coupled operations, and complex system interdependencies. Addressing these challenges requires management strategies that are both proactive and holistic rather than purely reactive. Resilience engineering embodies this approach by emphasizing a system's ability to anticipate disturbances, adapt under stress, and recover effectively. This study introduces a comprehensive, multi-dimensional framework for assessing resilience in process industries. The framework was developed through content analysis of expert interviews, a systematic literature review, and application of the spherical fuzzy Delphi method. Results revealed five primary dimensions of resilience: the organizational dimension, which encompasses leadership commitment, safety culture, and communication processes; the human resources dimension, focusing on workforce competence, training, and well-being; the individual dimension, addressing cognitive readiness, situational awareness, and decision-making skills; the risk management system dimension, which includes hazard identification, risk assessment, emergency preparedness, and continuous monitoring; and the technical dimension, covering equipment reliability, system redundancy, automation safeguards, and maintenance practices. Within these dimensions, factors such as leadership, effective communication, workforce capability, robust risk governance, and technical robustness emerged as particularly influential. By integrating these dimensions into a unified framework, our study advances theoretical understanding of resilience engineering and offers practical guidance for enhancing safety performance in process plants. Furthermore, this framework lays a foundation for future research aimed at developing standardized assessment tools, evaluating long-term outcomes of resilience interventions, and exploring the integration of emerging technologies—such as artificial intelligence, the internet of things, and advanced automation—into resilience engineering practices.},
  archive      = {J_EAAI},
  author       = {Mojtaba Emkani and Moslem Alimohammadlou and Esmaeil Zarei and Mehdi Jahangiri and Mojtaba Kamalinia},
  doi          = {10.1016/j.engappai.2025.112100},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112100},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A quantitative multi-dimensional resilience framework in process industries},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mutual transfer learning for cuff-less blood pressure estimation using photoplethysmography-based visibility graphs. <em>EAAI</em>, <em>161</em>, 112099. (<a href='https://doi.org/10.1016/j.engappai.2025.112099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cuff-less blood pressure (BP) estimation is critical to cardiovascular disease prevention and management. Photoplethysmography (PPG)-based monitoring technology offers advantages over cuff-based devices, including portability, lower power consumption, and faster measurements. However, current deep learning methods for BP estimation from PPG signals are limited by their analysis only from one-dimensional perspectives, failing to exploration of the underlying physiological patterns of cross-domain visual representations based on higher dimensional perspectives. Furthermore, conventional knowledge distillation techniques necessitate unidirectional knowledge transfer from pre-trained models, rendering it challenging to obtain feedback on the learning state of small networks for optimizing and adjusting the training process. This is inadequate for acquiring a profound understanding of the intricate mapping relationship between PPG and BP values. Therefore, this work presents a novel Transformer-based mutual transfer learning framework (MTL) that estimates BP values from phase-space reconstructed PPG signals using a multi-field complementary approach. The proposed MTL method leverages four phase-space reconstruction techniques to convert PPG signals into visibility graphs (VGs) that provide rich time-variant information. Furthermore, the joint optimization strategy with multiple losses of the soft label and structural knowledge learning enables us to transfer pre-trained knowledge from heterogeneous Transformer models and obtain cumulative multi-field complementary VG features during the fine-tuning process. We evaluate our MTL on three datasets of 1375 subjects using a subject-wise data-splitting paradigm based on five-fold cross-validation, achieving a state-of-the-art performance with estimation errors of 0.50 ± 4.94 millimeter of mercury (mmHg) and 0.21 ± 2.63 mmHg for systolic and diastolic BP, respectively. Our proposed end-to-end MTL offers a computationally efficient solution and elegant generalization ability for BP estimation using PPG-based VGs, providing a novel and innovative approach to BP monitoring that can advance cardiovascular disease prevention and management.},
  archive      = {J_EAAI},
  author       = {Chenbin Ma and Zhenchang Liu and Peng Zhang and Lishuang Guo and Haonan Zhang and Zeyu Liu and Guanglei Zhang},
  doi          = {10.1016/j.engappai.2025.112099},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112099},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mutual transfer learning for cuff-less blood pressure estimation using photoplethysmography-based visibility graphs},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Groundwater parameters estimation: A hybrid approach of convolutional layers with asynchronous and distributed bio-inspired algorithms. <em>EAAI</em>, <em>161</em>, 112098. (<a href='https://doi.org/10.1016/j.engappai.2025.112098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on aquifer hydraulic parameters estimation using bio-inspired algorithms since they can tackle groundwater model non-linearities. We propose two novel hybrid frameworks that combine the advantages of convolutional layers (CL) to enhance pattern recognition with heuristic search of Particle Swarm Optimization (PSO) and Differential Evolution (DE) algorithms. These integrations are implemented using an asynchronous and distributed approach to address efficiency issues in large-scale problems, resulting in ADPSO-CL (Asynchronous and Distributed Particle Swarm Optimization with Convolutional Layers) and ADDE-CL (Asynchronous and Distributed Differential Evolution with Convolutional Layers). The distributed method employs virtual machines, where a server generates and assigns particles to workers, which run in parallel with asynchronous iterative solution exchanges. We assess different algorithm configurations in an integrated water management model by coupling two software: Water Evaluation and Planning (WEAP) and MODFLOW. Results indicate that ADPSO-CL outperforms ADDE-CL by demonstrating more stable asynchronous communication, with fewer incomplete experiments (more than one worker was disconnected before completing all iterations), 33% in contrast to 71%. Additionally, produces results closer to the expected values, with mean absolute percentage error (MAPE) values of 78.25% for hydraulic conductivity ( K ) and 55.56% for specific yield ( S y ), compared to 299% and 209% in ADDE-CL. Moreover, ADPSO-CL has the fastest convergence rate, achieving efficient results in about half of the total iterations. This study introduces a novel and scalable architecture for intricate simulation–optimization problems, demonstrating its potential for future applications in real-world water resources planning and management.},
  archive      = {J_EAAI},
  author       = {Kiara Tesen and Hermilo Cortés and Sebastián Vicuña and Edmundo Molina-Perez and Francisco Suárez},
  doi          = {10.1016/j.engappai.2025.112098},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112098},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Groundwater parameters estimation: A hybrid approach of convolutional layers with asynchronous and distributed bio-inspired algorithms},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting power generation: A novel two-dimensional logistic fractional grey model. <em>EAAI</em>, <em>161</em>, 112097. (<a href='https://doi.org/10.1016/j.engappai.2025.112097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of power generation is essential for the stable operation of power systems, sustained economic growth, and harmonious social development. However, power systems exhibit chaotic characteristics such as complex and nonlinear dynamics during operation; for this reason, this study exploits the fact that two-dimensional logistic mapping helps with the recognition and control of the complex high-dimensional dynamics of the system. Additionally, the fractional-order chaotic system offers a more universal means to describe the chaotic phenomena, etc., and introduces the modelling mechanism of the two-dimensional logistic model and the fractional-order derivative theory into the grey model. A novel two-dimensional logistic fractional-order grey model is developed. The new model can simultaneously analyze two parallel major factors that evolve and are interrelated, and the fractional-order derivatives and nonlinear terms accurately portray the historical state and dynamic evolution process of the system, which can explore the evolution law in the time series of power generation more adequately. Furthermore, the particle swarm optimization algorithm is used to optimize the fractional order derivatives and parameters so that the adjustable model parameters can better capture the change pattern of the original power generation system data. The new model is applied to China's power generation prediction, and its validity is verified from three different perspectives through two different power generation modes as the research objects. Moreover, the new model outperforms the other seven models in its calculations. Finally, the new model effectively forecasts China's power generation for the next five years.},
  archive      = {J_EAAI},
  author       = {Mingyue Weng and Huiming Duan and Derong Xie},
  doi          = {10.1016/j.engappai.2025.112097},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112097},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting power generation: A novel two-dimensional logistic fractional grey model},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep reinforcement learning optimization algorithm based on heterogeneous graph neural network for hybrid flow shop scheduling problem with finite transportation resources. <em>EAAI</em>, <em>161</em>, 112096. (<a href='https://doi.org/10.1016/j.engappai.2025.112096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many actual process industries, transportation equipment represented by automated guided vehicles (AGVs) is widely used. However, current related research rarely considers the coordinated scheduling optimization of AGVs and production equipment. To this end, the hybrid flow shop scheduling problem (HFSP) with finite transportation resources (HFSP-FTR) in process industries is considered in this paper. Since it is necessary to consider the coordinated scheduling optimization of machines and AGVs at the same time, an end-to-end deep reinforcement learning scheduling method based on a heterogeneous graph neural network is proposed. First, a heterogeneous graph model capable of expressing any HFSP-FTR instance is constructed to visually represent the allocation relationship among jobs, machines, and AGVs. Second, a Markov decision process is formulated for solving HFSP-FTR, which specifically encompasses state features based on the heterogeneous graph model and a novel representation method for composite scheduling actions. Then, a novel heterogeneous graph neural network framework that can parallelly embed nodes of various types is proposed, aiming to derive graph-level embeddings for HFSP-FTR instances. Finally, a policy network is designed to obtain the probability distribution of each composite scheduling action being executed, and a deep reinforcement learning framework based on the multi-actor network is proposed for training. The results of numerical simulation experiments conducted on test instances with varying types demonstrate that the proposed method can acquire effective and highly generalized scheduling strategies in terms of makespan performance, outperforming other scheduling algorithms that are widely applied regarding the quality of scheduling solutions and other aspects.},
  archive      = {J_EAAI},
  author       = {Yejian Zhao and Xiaochuan Luo and Weixiang Xu and Yulin Zhang},
  doi          = {10.1016/j.engappai.2025.112096},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112096},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep reinforcement learning optimization algorithm based on heterogeneous graph neural network for hybrid flow shop scheduling problem with finite transportation resources},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unknown fault incremental learning based on shapelet prototypical network for streaming industrial signals. <em>EAAI</em>, <em>161</em>, 112094. (<a href='https://doi.org/10.1016/j.engappai.2025.112094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unknown faults represent faults that have never occurred before, they are constantly emerging due to the changing environments and operations in industrial processes. It is a challenge for existing fault diagnosis methods to continually detect unknown faults and effectively classify known faults in streaming industrial signals. This article proposes an unknown fault incremental learning method for streaming industrial signals. In this work, shapelet prototypical embedding combined with a memory distance matrix is employed to embed streaming industrial signals into a discriminative feature space. Therefore, the category information in the signals can be extracted and is not limited by the size of the sliding window. Besides, a new training paradigm based on meta-learning by sampling simulated-incremental tasks is proposed to obtain generalizable shapelets. Moreover, based on the new training paradigm, the meta-discovery module is proposed to continually detect unknown faults, and the meta-calibrate module can calibrate all prototypes into a distinguishable space. Experiments on the simulated streaming time series, benchmark Tennessee Eastman process, and real-world aluminum electrolysis process illustrate the superiority of the proposed method in terms of accuracy and interpretability. The code is available in https://github.com/XiaoxueWan/UFIL.git .},
  archive      = {J_EAAI},
  author       = {Xiaoxue Wan and Lihui Cen and Xiaofang Chen and Yongfang Xie and Zhaohui Zeng},
  doi          = {10.1016/j.engappai.2025.112094},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112094},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unknown fault incremental learning based on shapelet prototypical network for streaming industrial signals},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive attention graph convolution network with normalized embedded gaussian for rapid serial visualization presentation decoding. <em>EAAI</em>, <em>161</em>, 112093. (<a href='https://doi.org/10.1016/j.engappai.2025.112093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have been widely used in Brain Computer Interface (BCI) and have shown great prowess in identifying electroencephalogram (EEG) spatiotemporal features. However, most GCNs learn channels topological relationship by fixed adjacency matrix. This lacks connectivity strength information and ignores the data dependency. This paper proposes a data-driven adjacency matrix based on normalized embedded Gaussian function, and constructs a Gaussian-Adaptive Attention Graph Convolution Network (Gaussian-AAGCN). Brain regions connectivity is calculated by normalized embedded Gaussian function, and the topological relationship is adaptively learned by input data in a data-driven manner. This data-driven adaptive adjacency matrix avoids brain activity information loss caused by fixed adjacency matrix and improves the flexibility of graph construction. Convolutional block attention module (CBAM) is introduced to adaptive feature refinement in two independent dimensions, improving model representation ability. Experimental results show that the average area under curve (AUC), true positive rate (TPR) and false positive rate (FPR) of Gaussian-AAGCN on 14 subjects are 93.52 %, 91.59 %, and 4.58 % respectively. Compared to Transformer, Event-Related Potential Capsule Network (ERP-CapsNet), Electroencephalogram Convolutional Neural Network (EEGNet), and Multi-Granularity Information Fusion Network (MGIFNet), the AUC of Gaussian-AAGCN is higher by 18.02 %, 5.32 %, 2.62 %, and 1.82 %, respectively. Using the adaptive adjacency matrix, the model AUC and TPR are increased by about 4.8 % and 7.8 % respectively. After integrating CBAM, the AUC and TPR increased by about 3.5 % and 8 % respectively.},
  archive      = {J_EAAI},
  author       = {Mengyuan Zhao and Qingsong Ai and Kun Chen and Quan Liu and Sheng Quan Xie and Li Ma},
  doi          = {10.1016/j.engappai.2025.112093},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112093},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive attention graph convolution network with normalized embedded gaussian for rapid serial visualization presentation decoding},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GREEN: Graph reasoning enhanced encoder network for social intention-aware forecast of vessel navigating trajectory. <em>EAAI</em>, <em>161</em>, 112092. (<a href='https://doi.org/10.1016/j.engappai.2025.112092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have demonstrated that graph neural network (GNN) excel in interactive modeling, particularly by enhancing reasoning capabilities through the construction of interaction graphs, and the application of graph convolutional network (GCN). However, these methods remain heavily dependent on prior features, which limits the ability of vessels to accurately infer each other’s decision-making intentions in encounter situations. Therefore, this paper proposes graph reasoning enhanced encoder network (GREEN), which enables social community insight on multi-ships interactions, and latent intention aware for interactive trajectory forecast. The architecture of GREEN includes two layers of trajectory-graph-embedded encoders layer (TGEEL) and multi-graphs-gated fusion layer (MGGFL). In TGEEL, we respectively design intention trajectory generator unit for graph-embedded multi-ships trajectory representation via random walk process, and latent intention generator unit to forecast future navigating intentions via variational autoencoder. In MGGFL, we also design two units, where one unit is in charge of social aware construction and spatio-temporal features extraction based on interactive multi-graphs, and the other one is responsible for gated fusion of multi-scale features and forecast future trajectory using spatio-temporal attention. Experimental results across five datasets were collected from real-world maritime environments, which demonstrated that GREEN achieved improvements of 39.98%, 38.57%, 38.65%, and 63.33% in average displacement error , final displacement error, maximum displacement error, and miss rate, compared with state-of-the-art methods. The paper highlights GREEN robust potential in complex navigational scenarios, and provides pivotal support for advancing the development of intelligent maritime systems.},
  archive      = {J_EAAI},
  author       = {Junhao Jiang and Yi Zuo},
  doi          = {10.1016/j.engappai.2025.112092},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112092},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GREEN: Graph reasoning enhanced encoder network for social intention-aware forecast of vessel navigating trajectory},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffAT: Effective data augmentation with diffusion models for time series forecasting. <em>EAAI</em>, <em>161</em>, 112091. (<a href='https://doi.org/10.1016/j.engappai.2025.112091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation offers a promising solution to data scarcity in deep learning-based time series forecasting. However, current approaches face dual limitations (1) Hand-designed methods (e.g., cropping/masking): often disrupt the continuity of vital temporal patterns (such as seasonal and trend) by introducing abrupt pattern discontinuities; (2) Generative models often face difficulties in preserving task-critical features that are essential for prediction, especially when aiming to generate diverse augmented series. To tackle these dilemmas, we propose a novel conditional diffusion-based data augmentation framework, named DiffAT, for time series forecasting tasks. DiffAT synergizes: (1) Patch-wise masking reconstruction to capture structural invariants (such as autocorrelation and causality), and (2) encoding hand-designed augmentation prototypes for guiding diversity-preserving generation. DiffAT achieves dual enhancement: maintaining continuity of temporal patterns through progressive denoising process and exposing latent invariant patterns via guided diversity injection. We validate the efficacy of DiffAT through extensive experiments on seven real-world datasets, by comparing DiffAT with six state-of-the-art time series data augmentation methods. The results indicate our method can boost the forecasting performance of Autoformer by up to 6.49 % in 26/28 cases and improve forecasting performance of LightTS by up to 3.11 % in 23/28 cases on 7 real-world benchmarks. Extensive experiments also indicate that DiffAT can improve the accuracy of forecasting models in few-shot scenario (with 1 % training data) in 54/60 cases. We will release the source code upon publication.},
  archive      = {J_EAAI},
  author       = {Yang Yu and Ruizhe Ma and Wenbo Gu and Zongmin Ma},
  doi          = {10.1016/j.engappai.2025.112091},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112091},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DiffAT: Effective data augmentation with diffusion models for time series forecasting},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating reinforcement learning-based neural controllers for quadcopter navigation in windy conditions. <em>EAAI</em>, <em>161</em>, 112090. (<a href='https://doi.org/10.1016/j.engappai.2025.112090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate quadcopter navigation under windy conditions remains challenging for traditional control methods, especially in the presence of unpredictable wind gusts and strict navigational constraints. This paper evaluates Deep Reinforcement Learning (DRL) based controllers under such conditions, analysing the impact of wind domain randomisation, multi-goal training, enhanced state representations with explicit wind information, and the use of temporal data to capture affecting dynamics over time. Experiments in the AirSim simulator across four trajectories — evaluated under both no-wind and windy conditions — demonstrate that DRL-based controllers outperform classical methods, particularly under stochastic wind disturbances. Moreover, we show that training a DRL agent with domain randomisation improves robustness against wind but reduces efficiency in no-wind scenarios. However, incorporating wind information into the agent’s state space enhances robustness without sacrificing performance in wind-free settings. Furthermore, training with stricter waypoint constraints emerges as the most effective strategy, leading to precise trajectories and improved generalisation to wind disturbances. To further interpret the learned policies, we apply Shapley Additive explanations analysis, revealing how different training configurations influence the agent’s feature importance. These findings underscore the potential of DRL-based neural controllers for resilient autonomous aerial systems, highlighting the importance of structured training strategies, informed state representations, and explainability for real-world deployment.},
  archive      = {J_EAAI},
  author       = {Alain Andres and Aritz D. Martinez and Sümer Tunçay and Ignacio Carlucho},
  doi          = {10.1016/j.engappai.2025.112090},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112090},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluating reinforcement learning-based neural controllers for quadcopter navigation in windy conditions},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pixel-level semantics boosted fine-grained bird image classification. <em>EAAI</em>, <em>161</em>, 112089. (<a href='https://doi.org/10.1016/j.engappai.2025.112089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained bird image classification (FBIC) is crucial for endangered bird conservation and biodiversity research. However, existing methods often struggle to capture detailed features and manage the interference caused by complex backgrounds. To address these challenges, we propose a novel Pixel-Level Semantic Boosted Fine-Grained Bird Image Classification (PFIC) framework, which enhances fine-grained bird image classification by incorporating pixel-level semantic information. PFIC consists of two core components: the Grouped Detail Enhancement (GDE) module and the Background–Foreground Enhancement (BFE) strategy. GDE integrates multi-level pixel-level semantic information, derived from a segmentation feature extractor, into classification features via two submodules: grouped aggregation and detail enhancement. This approach enhances the model’s ability to capture fine-grained details. BFE augments training samples by restricting background ranges and applying random shifts to foreground objects, thereby improving the model’s capability to recognize foreground objects in complex environments. Experimental results demonstrate that our method achieves state-of-the-art performance on the CUB-200-2011 and NABirds datasets. Additionally, further experiments on the Stanford Cars dataset validate the framework’s potential for generalization to other fine-grained image classification tasks.},
  archive      = {J_EAAI},
  author       = {Haoxiang Ma and Yongjian Deng and Bochen Xie and Jian Liu and Hai Liu and Youfu Li and Zhen Yang},
  doi          = {10.1016/j.engappai.2025.112089},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112089},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pixel-level semantics boosted fine-grained bird image classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based soft sensor of five day biochemical oxygen demand indicators in the municipal wastewater treatment process. <em>EAAI</em>, <em>161</em>, 112088. (<a href='https://doi.org/10.1016/j.engappai.2025.112088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Five day biochemical oxygen demand (BOD 5 ) is usually used to measure whether wastewater treatment meets the standard. Previously, the development of machine learning technology was applied to predict BOD 5 for future planning of wastewater treatment. In real wastewater treatment, the monitoring of BOD 5 often lags behind for a long time, so neural network-based soft sensor methods are widely used in this field. However, the currently used BOD 5 soft sensor model has the problem of ignoring the synergistic effect of the model and stable information transmission. In order to monitor the BOD 5 concentration more accurately, a Transformer network model with embedded Long Short-Term Memory (LSTM) network is proposed in this article : LSTM is embedded into the calculation of the transformer multi-head attention, and the output method of the multi-head attention is improved so that the attention heads are output one by one in a serial manner, so it is named LSTM-Serial-Transformer (LSformer). Compared with previous models, LSformer optimizes input information through LSTM and Transformer to achieve synergistic effect, thus better capturing the characteristics of BOD 5 time series data, while reducing the risk of gradient vanishing or gradient exploding during data transmission to improve the stability of the model. Finally, the model was verified to have better soft sensor performance on a benchmark simulation model and a real-world dataset.},
  archive      = {J_EAAI},
  author       = {Xiaoling Zhang and Zhi Qi and Peng Chang and Zhiqi Hu},
  doi          = {10.1016/j.engappai.2025.112088},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112088},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer-based soft sensor of five day biochemical oxygen demand indicators in the municipal wastewater treatment process},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ForgetMe: Benchmarking the selective forgetting capabilities of generative models. <em>EAAI</em>, <em>161</em>, 112087. (<a href='https://doi.org/10.1016/j.engappai.2025.112087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of diffusion models in image generation has increased the demand for privacy-compliant unlearning. However, due to the high-dimensional nature and complex feature representations of diffusion models, achieving selective unlearning remains challenging, as existing methods struggle to remove sensitive information while preserving the consistency of non-sensitive regions. To address this, we propose an Automatic Dataset Creation Framework based on prompt-based layered editing and training-free local feature removal, constructing the ForgetMe dataset and introducing the Entangled evaluation metric. The Entangled metric quantifies unlearning effectiveness by assessing the similarity and consistency between the target and background regions and supports both paired ( Entangled-D ) and unpaired ( Entangled-S ) image data, enabling unsupervised evaluation. The ForgetMe dataset encompasses a diverse set of real and synthetic scenarios, including CUB-200-2011 (Birds), Stanford-Dogs, ImageNet, and a synthetic cat dataset. We apply LoRA fine-tuning on Stable Diffusion to achieve selective unlearning on this dataset and validate the effectiveness of both the ForgetMe dataset and the Entangled metric, establishing them as benchmarks for selective unlearning. Our work provides a scalable and adaptable solution for advancing privacy-preserving generative AI. Code is available at: https://github.com/YuZhenyuLindy/ForgetMe .},
  archive      = {J_EAAI},
  author       = {Zhenyu Yu and Mohd Yamani Idna Idris and Pei Wang and Yuelong Xia and Yong Xiang},
  doi          = {10.1016/j.engappai.2025.112087},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112087},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ForgetMe: Benchmarking the selective forgetting capabilities of generative models},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel data generation scheme for surrogate modelling with deep operator networks. <em>EAAI</em>, <em>161</em>, 112086. (<a href='https://doi.org/10.1016/j.engappai.2025.112086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operator-based neural network architectures such as deep operator networks have emerged as a promising tool for the surrogate modelling of physical systems. In general, the training data for operator surrogate modelling are generated by solving partial differential equations using the finite element method. The computationally intensive nature of data generation is one of the major bottlenecks in deploying these surrogate models, hindering the deployment of these surrogate models in practical applications. In this study, we propose a novel methodology to alleviate the computational burden associated with training data generation for deep operator networks. Unlike the existing literature, the proposed framework for data generation does not use any partial differential equation integration strategy, such as the finite element method. In the proposed strategy, the primary field consistent with the boundary conditions is first generated randomly using Gaussian process regression. Thereafter, from the primary field, the input source field is calculated using second-order accurate finite difference techniques. The computation of the derivatives from the finite difference scheme is significantly less computationally intensive and easier to implement compared to integrating the underlying governing equations, thereby reducing the computational cost associated with generating training datasets. To validate the proposed approach, we employ heat equations as a model problem and develop the surrogate model for numerous boundary value problems.},
  archive      = {J_EAAI},
  author       = {Shivam Choubey and Shailendra Rahi and Birupaksha Pal and Manish Agrawal},
  doi          = {10.1016/j.engappai.2025.112086},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112086},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel data generation scheme for surrogate modelling with deep operator networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable generalization diagnosis: Variational causal disentanglement-based coalitional game attribution network. <em>EAAI</em>, <em>161</em>, 112084. (<a href='https://doi.org/10.1016/j.engappai.2025.112084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretability and controllability are the keys to intelligent fault diagnosis in industrial scenarios. However, most intelligent methods have focused on post-hoc feature importance explanations, which cannot constrain the uncontrollable learning behavior or form an interpretable diagnosis process consistent to match expert experience. To address this problem, this paper proposes a variational causal disentanglement-based coalitional game attribution network (VCN) to achieve a controllable and interpretable modeling paradigm that can draw diagnostic conclusions with conforming to expert experience. This model enables independent causal factor disentanglement and model regularization during the training process, as well as fast explanation computation at test time. Variational causal disentanglement is defined and do-operations and variational inference processes are introduced to generate training data with independent causal factors for subsequent attribution. The coalitional game attribution establishes a coalitional game relationship between the model and the independent causal factors, and regularizes the model so that it converges to a state that conforms to logical axioms. Both laboratory and real-world data demonstrate the proposed method enables the provision of interpretable diagnostic conclusions while maintaining controllable performance. The code is available at: https://github.com/cyber-dogy/VCN-code .},
  archive      = {J_EAAI},
  author       = {Junwei Gu and Changhua Hu and Yu Wang and Mingquan Zhang and Yanzhuo Lin and Shangjing Peng and Dongdong Li},
  doi          = {10.1016/j.engappai.2025.112084},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112084},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable generalization diagnosis: Variational causal disentanglement-based coalitional game attribution network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel photovoltaic cell defect detection method: A deep learning model based on multi-scale enhanced feature extraction. <em>EAAI</em>, <em>161</em>, 112083. (<a href='https://doi.org/10.1016/j.engappai.2025.112083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasingly widespread application of clean energy technology, the global demand for photovoltaic cells is gradually increasing, and the status and defects of photovoltaic cells are also being taken seriously. However, there are various types of defects in photovoltaic cells, including those that are difficult to detect, making detection work somewhat challenging. This article proposes a novel improved model for defect detection in photovoltaic cells based on You Only Look Once (YOLO). Firstly, the Multi-Head Self-Attention (MHSA) mechanism is adopted to compensate for the shortcomings of the Cross Stage Partial Bottleneck with 2 Convolutions (C2f) module in channel feature extraction. Secondly, the Receptive-Field Coordinate Attention Convolutional (RFCAConv) operation module is utilized to expand the receptive field of defect detection in the model and increase the range of feature extraction. Finally, the Bi-directional Feature Pyramid Network (BiFPN) and Concat modules are integrated to enhance the feature relationships between the output connections of each module and strengthen the output results. The final experimental results demonstrate that the improved model achieves an accuracy of 90.3%, representing a 5.2% increase compared to the original model. Through experimental verification, the improved model proposed in this paper can not only detect defects in photovoltaic cells in electroluminescence (EL) images but also in infrared thermal images. The model has strong generalization ability.},
  archive      = {J_EAAI},
  author       = {Yu Gao and Zhanying Li and Yinghao Zhang and Kangye Zhang and Haoyang Yu},
  doi          = {10.1016/j.engappai.2025.112083},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112083},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel photovoltaic cell defect detection method: A deep learning model based on multi-scale enhanced feature extraction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wind power prediction based on hybrid deep learning and monte carlo simulation. <em>EAAI</em>, <em>161</em>, 112082. (<a href='https://doi.org/10.1016/j.engappai.2025.112082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a hybrid deep learning model combining Variational Mode Decomposition (VMD), Convolutional Neural Networks (CNN), and a Three-Dimensional Gated Neural Network (TGNN) to enhance wind power prediction accuracy. VMD decomposes wind power time series into intrinsic mode functions, CNN extracts deep features, and TGNN captures temporal dependencies with error feedback control. A Monte Carlo simulation based on the Central Limit Theorem is introduced to evaluate predictive uncertainty and interval coverage. Experimental results from three wind farms in China demonstrate that the proposed model significantly outperforms baseline hybrid models. Specifically, it achieves a coverage probability (CP) of 0.887, an average interval width (AIW) of 200.870, and a normalized mean square error (NMSE) of 0.057. Compared with the VMD-CNN-LSTM model, the proposed VMD-CNN-TGNN reduces root mean error (RMSE) by approximately 50%, indicating its superior accuracy, robustness, and practical value in wind power forecasting.},
  archive      = {J_EAAI},
  author       = {Zhiyong Guo and Qiaoli Han and Fangzheng Wei and Wenkai Qi},
  doi          = {10.1016/j.engappai.2025.112082},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112082},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Wind power prediction based on hybrid deep learning and monte carlo simulation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A parallel memetic algorithm for qubit mapping on noisy intermediate-scale quantum machines. <em>EAAI</em>, <em>161</em>, 112081. (<a href='https://doi.org/10.1016/j.engappai.2025.112081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computer technologies are advancing rapidly, but current devices are still limited to the realm of Noisy Intermediate Scale Quantum (NISQ) systems. Due to the limited set of gates and scarce physical qubit connectivity, most quantum circuit-based programs need to be transpiled to be executed on such hardware. This transpilation, which consists in converting the quantum circuit into a hardware-compliant one includes the critical qubit mapping step, where logical qubits are mapped onto physical qubits to meet the hardware connectivity constraints. In this paper, we investigate the application of Artificial Intelligence (AI) to the qubit mapping problem. More exactly, we propose a Parallel Memetic Algorithm for Qubit Mapping (PMA-QM), designed to tackle this challenge efficiently. Using a fine-tuned parallel model to accelerate this inherently computationally expensive hybrid approach, our algorithm takes problem-specific knowledge into account to optimize circuit depth, reducing execution time, and minimizing error rates consequently. PMA-QM has been experimented using various medium-to-large scale circuit benchmarks. PMA-QM outperforms the widely used SWAP-based BidiREctional (SABRE) algorithm, delivering consistently better solutions.},
  archive      = {J_EAAI},
  author       = {Jérôme Rouzé and Nouredine Melab and Jan Gmys and Daniel Tuyttens},
  doi          = {10.1016/j.engappai.2025.112081},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112081},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A parallel memetic algorithm for qubit mapping on noisy intermediate-scale quantum machines},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing non-orthogonal multiple access systems: A reconfigurable machine learning classification approach. <em>EAAI</em>, <em>161</em>, 112080. (<a href='https://doi.org/10.1016/j.engappai.2025.112080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-Orthogonal Multiple Access (NOMA) is being considered as a Multiple Access (MA) technique for the next-generation systems, due to factors such as a high per-user spectral resource allocation, grant-free transmission, support for millimeter Waves (mmWaves) and massive-MIMO (mMIMO). A practical limitation of the NOMA systems is imperfect Successive Interference Cancellation (SIC); and the involved decoding delay. This work develops a data-driven Machine Learning (ML) model providing the functionality of a SIC receiver. While most of the Deep Learning (DL) algorithms have high complexity and training times, the given ML approach utilizes the received symbol as the only primary predictor. The other two predictors are derived from the primary predictor, and utilized for the Power-Domain (PD)-NOMA symbol-decoding process. The model utilizes a developed low-complexity NOMA-ML-based Decoder (MLbD) dataset for the same. The extensive test simulations confirm the reconfigurable ML-based receiver to be at par with the existing Maximum Likelihood (MLH) decoder in terms of decoding accuracy. Still, the former supports its integration into the next-generation systems due to its reconfigurable nature and removes the drawbacks related to SIC in the NOMA systems.},
  archive      = {J_EAAI},
  author       = {Saurabh Srivastava and Rampravesh Kumar and Prajna Parimita Dash},
  doi          = {10.1016/j.engappai.2025.112080},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112080},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing non-orthogonal multiple access systems: A reconfigurable machine learning classification approach},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaborative energy-saving path planning of unmanned surface vehicle cluster based on multi-head attention mechanism and multi-agent deep reinforcement learning. <em>EAAI</em>, <em>161</em>, 112078. (<a href='https://doi.org/10.1016/j.engappai.2025.112078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a Multi-Agent Deep Reinforcement Learning (MADRL) algorithm to address the overlooked issue of energy consumption optimization in existing cluster path planning methods, enabling collaborative energy-efficient path planning for Unmanned Surface Vehicle (USV) clusters. Meanwhile, it provides an alternative MADRL approach to address practical engineering challenges. We not only consider the problems of avoiding danger, reaching the target point and avoiding path conflicts between USV, but also further consider the energy consumption and speed planning of USV cluster. Specifically, firstly, we establish the USV motion model and the USV cluster conflict model, and propose a new energy consumption model, which considers the relationship among speed, marine environment and propulsion load. Secondly, we propose a multi-head local state relevance capture mechanism-multi-agent proximal policy optimization (MLSRC-MAPPO) algorithm. This algorithm can use multi-head attention mechanism (MHA) to capture the potential dependencies between USV, thus enhancing the convergence performance of multi-agent. Finally, in order to reduce the training difficulty, we propose a multi-dimensional action space method for action networks. The experimental results demonstrate that the proposed multi-dimensional action space method has achieved significant success in the lightweighting of the action network: the number of network parameters was reduced by 89.10%, and the computational complexity was decreased by 88.94%, significantly enhancing training efficiency. Meanwhile, the MLSRC-MAPPO algorithm, by incorporating a multi-head attention mechanism, greatly improved the convergence performance of the multi-agent system. In test scenarios with both identical and different starting points, the method reduced energy consumption by 26.24% and 38.47% respectively, fully validating its effectiveness and superiority. Furthermore, comparative experiments with existing cluster energy-saving path planning methods show that the proposed method exhibits clear advantages in terms of energy consumption and path planning efficiency, further verifying its superiority. The corresponding code for this paper is as follows: https://github.com/xhpxiaohaipeng/Multi_USV_Trajectory_energy_plan},
  archive      = {J_EAAI},
  author       = {Haipeng Xiao and Lijun Fu and Chengya Shang and Yunfeng Lin and Longfei Yue and Yaxiang Fan},
  doi          = {10.1016/j.engappai.2025.112078},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112078},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Collaborative energy-saving path planning of unmanned surface vehicle cluster based on multi-head attention mechanism and multi-agent deep reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification of surface subsidence risk in deep foundation pits using a mamba fusion model. <em>EAAI</em>, <em>161</em>, 112077. (<a href='https://doi.org/10.1016/j.engappai.2025.112077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel artificial intelligence–driven neural network model, CNN-Mamba-LSTM-SA, for predicting surface settlement induced by deep foundation pit excavation. The model integrates Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), a Self-Attention (SA) mechanism, and the Mamba architecture to capture both spatial and long-range temporal dependencies in multi-source monitoring data. Bayesian optimization is employed for hyperparameter tuning, and Variational Mode Decomposition (VMD) is used for data denoising, resulting in improved prediction accuracy. To enhance model interpretability, Shapley Additive Explanations (SHAP) are applied to identify key deformation drivers, revealing groundwater level and building settlement as the most influential factors. Model performance is validated using monitoring data from the Nanjing Gemini excavation project, where it achieves superior results compared to conventional models. The CNN-Mamba-LSTM-SA model reduces Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and Root Mean Square Error (RMSE) by up to 69.77 %, 62.45 %, and 79.45 %, respectively. Further analysis through ablation experiments confirms the contribution of each module. Interestingly, the combined removal of CNN and SA results in greater performance degradation than the sum of their individual effects. Finally, a risk warning framework is developed to enable the dynamic transformation of predicted and observed settlement values into actionable risk levels. This integrated artificial intelligence approach offers a robust and interpretable tool for managing excavation-induced risks in urban geotechnical engineering.},
  archive      = {J_EAAI},
  author       = {Chenhe Ge and Pengfei Li and Mingju Zhang and Meng Yang},
  doi          = {10.1016/j.engappai.2025.112077},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112077},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identification of surface subsidence risk in deep foundation pits using a mamba fusion model},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk management in maintenance processes: A spherical fuzzy-based failure mode and effect analysis approach in the glass processing industry. <em>EAAI</em>, <em>161</em>, 112076. (<a href='https://doi.org/10.1016/j.engappai.2025.112076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality management systems are essential tools that aim to increase the competitiveness of businesses and ensure customer satisfaction by creating reliable quality control processes. In this study, the importance of the "risk-based thinking" approach of the International Organization for Standardization (ISO) 9001:2015 standard within the scope of quality management systems was emphasized, and a risk assessment was made for the maintenance process of a business in the glass processing sector. In order to eliminate the deficiencies of the failure mode and effect analysis (FMEA) method, the integration of spherical fuzzy sets (SFSs) and the Technique of Order Preference Similarity to the Ideal Solution (TOPSIS) method was used. Within the scope of the study, 17 different risks were determined by five experts from the maintenance, repair, and quality assurance departments. The experts evaluated these identified risks according to occurrence, severity, and detection factors. Then, these risks were ranked using the Spherical Fuzzy TOPSIS (SF-TOPSIS) method. Finally, different scenarios were created, and their results were discussed to provide a more comprehensive and sensitive risk management approach. This study focuses on maintenance processes in the glass processing industry as a case study. However, the risks related to the maintenance process defined in the study (e.g., machine failures, maintenance inefficiencies, spare parts shortages) are common in the manufacturing sector. Therefore, it can be applied to the sector where the application was carried out and to many different sectors and enterprises.This methodology also serves as a guide for businesses that want to manage process risks within the scope of ISO 9001:2015.},
  archive      = {J_EAAI},
  author       = {Buse Duygu Dağıdır and Barış Özkan},
  doi          = {10.1016/j.engappai.2025.112076},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112076},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Risk management in maintenance processes: A spherical fuzzy-based failure mode and effect analysis approach in the glass processing industry},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot augmentation based on variational auto-generative adversarial network with moving losses: Application to the variable stiffness prediction in composites. <em>EAAI</em>, <em>161</em>, 112075. (<a href='https://doi.org/10.1016/j.engappai.2025.112075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dataset of carbon fiber reinforced plastics (CFRP) materials presents characteristics of high-dimensional, low-rank, and sparse, which pose difficulties in the combination of mechanical modeling. In this paper, a Variational Auto-Generative Adversarial Network (VAGAN) with moving losses is proposed as a data augmentation method, which extends the size of the CFRP dataset covering components, processes, elasticity, and strengths factors, and increases the information conveyed in the surrogate modeling. A compression strength prediction model for CFRP laminates was constructed by combining the component, process, and mechanical tensor with a neural network optimized by the search algorithm. Combined with the data augmentation strategy, not only was the amount of data expanded, but the prediction accuracy was also significantly improved. The allowable value of compression strength is analyzed and calculated by the predicted values, which brings direct benefits in simplifying the test.},
  archive      = {J_EAAI},
  author       = {Zhicen Song and Yunwen Feng and Cheng Lu and Jiaqi Liu},
  doi          = {10.1016/j.engappai.2025.112075},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112075},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Few-shot augmentation based on variational auto-generative adversarial network with moving losses: Application to the variable stiffness prediction in composites},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multivariate time series forecasting based on temporal decomposition and graph neural network. <em>EAAI</em>, <em>161</em>, 112074. (<a href='https://doi.org/10.1016/j.engappai.2025.112074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is quite challenging to forecast the Multivariate Time Series (MTS) accurately due to the high dimensionality of MTS and the entangled correlation between variables. Recently, graph-based networks have been demonstrated to be an effective model to handle the complex correlations between MTS. However, all existing graph-based methods construct the graph model of the MTS using only the shallow correlations from the raw MTS data, ignoring the deep-rooted correlations hidden in the features. In this paper, we propose for the first time to construct a comprehensive graph model of MTS that incorporates both shallow correlations from raw data and hidden correlations from decomposed temporal properties. Then, we propose a novel graph-based MTS forecasting framework, which optimizes the graph structure jointly with the model parameters. By doing so, the graph structure can adaptively model the correlations of MTS at a deep level, while the joint optimization can make the constructed graph compatible with the forecasting tasks of MTS, contributing to a globally optimal solution. Finally, we conduct extensive experiments on seven real-world datasets, the results demonstrate the superiority of our method on MTS forecasting over the state-of-the-art baselines. The source codes of the experiments with datasets are available at https://github.com/ironweng/MF-TDGNN .},
  archive      = {J_EAAI},
  author       = {Yan Qiao and Pei Zhao and Junjie Wang and Rongyao Hu and Minyue Li and Xinyu Yuan and Meng Li and Zhenchun Wei and Cuiying Feng},
  doi          = {10.1016/j.engappai.2025.112074},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112074},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multivariate time series forecasting based on temporal decomposition and graph neural network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified framework for lung disease screening using chest X-ray images. <em>EAAI</em>, <em>161</em>, 112073. (<a href='https://doi.org/10.1016/j.engappai.2025.112073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest X-ray (CXR) imaging is a crucial diagnostic tool for identifying respiratory diseases. The existing methods face challenges such as misclassification caused by overlapping radiologic patterns and the shortage of trained radiologists. However, previous studies have utilized deep learning (DL) models to overcome these limitations, but they struggle with imbalanced datasets, and noise sensitivity. In addition, most of the studies are based on the binary classification of CXR images. Thus, the proposed framework integrates segmentation and multi-class classification for improved generalization and robustness. In this work, artificial intelligence techniques like encoder–decoder and ensemble learning are utilized for segmentation and classification of CXR images that offers reliable, and efficient solution. The output of the presented framework classifies the CXR images into four different classes, along with their corresponding class score. The proposed classification model is ensemble of three pre-trained DL architectures. The last five layers of these base models are fine tuned to match the classification process and combined through a multi-layer perceptron classifier for improved accuracy. The proposed model achieves overall accuracy of 88.98%, and area under curve value of 0.9753, outperforming several state-of-the-art models. It is a lightweight model and demonstrates significant robustness under noisy conditions compared to other models. Moreover, the proposed segmentation and ensemble models are trained and tested on different datasets to obtain greater robustness. The data augmentation is also employed to address class imbalance nature of dataset and enhance the generalization capability. Further, statistical analysis is performed to present the comprehensive comparison among the models.},
  archive      = {J_EAAI},
  author       = {Bhavana Singh and Pushpendra Kumar},
  doi          = {10.1016/j.engappai.2025.112073},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112073},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A unified framework for lung disease screening using chest X-ray images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid bayesian model updating and non-dominated sorting genetic algorithm framework for intelligent mix design of steel fiber reinforced concrete. <em>EAAI</em>, <em>161</em>, 112071. (<a href='https://doi.org/10.1016/j.engappai.2025.112071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steel fiber reinforced concrete (SFRC) improves the strength and toughness of conventional concrete, but the high cost and carbon footprint of fibers challenge the balance among performance, cost and sustainability. To address this, an intelligent mix design framework is proposed to optimize compressive and splitting tensile strengths, cost and emissions. Based on 671 experimental records, posterior models were built using Markov Chain Monte Carlo sampling and Bayesian model updating, enabling accurate strength predictions. Compared to traditional regression methods, R 2 scores improved by 15.7 % and 12.4 %, confirming its predictive advantage. Cost-wise, materials dominate, while emissions mainly arise from production, transport and mixing. A non-dominated sorting genetic algorithm identified optimal designs under given constraints. Results show that reducing water-to-cement and aggregate-to-cement ratios, and increasing sand ratio and fiber reinforcement index, enhances SFRC strength. Larger coarse aggregates reduce compressive strength but have limited effect on tensile strength. Optimization suggests potential cost and emission reductions of up to 60 %. Moreover, for compression-prone components, fiber use is inefficient due to high cost and emissions, whereas for crack-resistant or strength-balanced elements, fiber inclusion offers a more sustainable alternative to merely lowering the water-to-cement ratio. The proposed framework enables tailored SFRC mix designs, guiding the efficient use of steel fibers.},
  archive      = {J_EAAI},
  author       = {Yong Yu and Jie Su and Bo Wu},
  doi          = {10.1016/j.engappai.2025.112071},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112071},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid bayesian model updating and non-dominated sorting genetic algorithm framework for intelligent mix design of steel fiber reinforced concrete},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional human pose estimation based on multi-scale spatial–temporal transformer. <em>EAAI</em>, <em>161</em>, 112068. (<a href='https://doi.org/10.1016/j.engappai.2025.112068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, transformer-based methods have become dominant in the domain of three-dimensional (3D) human pose estimation, yet the U-net model based on convolutional neural networks (CNN) struggles to model long temporal sequences, and sequence-to-frame (Seq2frame) and sequence-to-sequence (Seq2seq) approaches often fail to preserve dependencies at the start and end of sequences. To address these challenges, this paper proposes a Multi-Scale Spatial–Temporal Transformer network (MSST). This network utilizes Sequence Padding Module (SPM) to extract edge features of the first and last frames, and employs Spatial–Temporal Transformer (STT) to model the spatial–temporal correlations of keypoints. Additionally, we design a Multi-Scale Module (MSM) that analyzes the human skeletal topology to extract multi-scale features of keypoints, local information, and global information, and fuse semantic information at different scales. Finally, we utilize regression heads to project the processed keypoint feature information into 3D space. We conduct quantitative evaluations on two benchmark datasets using four evaluation metrics and design multiple sets of comparative experiments to validate the effectiveness of the proposed modules. Experimental results demonstrate that the proposed network achieves excellent performance.},
  archive      = {J_EAAI},
  author       = {Xiaogang Song and Yongxin Cui and Jichen Chen and Xinhong Hei},
  doi          = {10.1016/j.engappai.2025.112068},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112068},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-dimensional human pose estimation based on multi-scale spatial–temporal transformer},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SharpEdge: High-quality data-driven monocular depth estimation for enhanced boundary precision. <em>EAAI</em>, <em>161</em>, 112067. (<a href='https://doi.org/10.1016/j.engappai.2025.112067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While existing monocular depth estimation methods have achieved commendable performance, they often fall short in accurately distinguishing object boundaries. This deficiency largely stems from the inherent noise in dataset acquisition, such as unclear edges and missing depth information. To address these challenges, this paper introduces a novel, high-quality, data-driven monocular depth estimation method tailored for autonomous driving. The approach significantly enhances depth predictions with clearer object boundaries and reduced noise, making it well-suited for real-time, safety-critical applications. Central to our approach is the Self-Adaptive Consistency Filtering mechanism, which dynamically selects high-quality training samples, ensuring that the model learns from the most reliable data and reducing the impact of noise. Additionally, we introduce a Dual-Prior Learning strategy that combines geometric and semantic edge priors. Unlike traditional methods that rely solely on raw depth maps, our approach enhances boundary detection by providing detailed guidance on object contours. This leads to more accurate depth estimation, especially in complex regions where other methods struggle. Empirical evaluations on popular benchmark datasets show that our approach leads to performance improvements of 1.2% on the autonomous driving dataset KITTI and 1.8% on the indoor scene dataset NYU. Compared with recent state-of-the-art methods such as DPT and NewCRFs, our approach achieves superior performance, particularly in recovering fine object boundaries and maintaining spatial consistency across diverse scenes. These results highlight the strong generalization ability of our method, demonstrating that it can enhance depth estimation quality across diverse environments — improving edge precision and spatial coherence, which are critical for autonomous vehicles navigating both complex and dynamic scenarios.},
  archive      = {J_EAAI},
  author       = {Mengke Song and Luming Li and Xu Yu and Chenglizhao Chen and Shanchen Pang},
  doi          = {10.1016/j.engappai.2025.112067},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112067},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SharpEdge: High-quality data-driven monocular depth estimation for enhanced boundary precision},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review on vision-based gaze estimation: Advance in computer vision and deep learning. <em>EAAI</em>, <em>161</em>, 112066. (<a href='https://doi.org/10.1016/j.engappai.2025.112066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eye gaze estimation is all about figuring out where a person is looking by analyzing eye movements. This is usually done using cameras or eye-tracking devices, a key technique in computer vision. Gaze estimation has a wide range of uses—from helping people interact with computers more naturally (HCI), monitoring drivers, enhancing virtual reality experiences, and reading emotional cues in affective computing. Deep learning has improved how accurately and reliably these systems work in recent years. Models like Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Generative Adversarial Networks (GANs) have made it easier to detect and interpret eye movements in complex settings. This review closely examines how gaze estimation works, the datasets commonly used, and both traditional and deep learning-based methods. It also points out what's working well, where current methods fall short, and what researchers still need to solve. The goal is to offer helpful insights for anyone working to improve or apply gaze tracking technologies in real-world scenarios.},
  archive      = {J_EAAI},
  author       = {Sapna Singh Kshatri and Deepak Singh},
  doi          = {10.1016/j.engappai.2025.112066},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112066},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A systematic review on vision-based gaze estimation: Advance in computer vision and deep learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel framework for improving railway driver performance based on emotional intelligence and job-driven factors: An artificial neural network method. <em>EAAI</em>, <em>161</em>, 112065. (<a href='https://doi.org/10.1016/j.engappai.2025.112065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient transportation systems critically rely on human factors to ensure safety, reliability, and service quality. This study introduces a novel framework for evaluating and improving the performance of the Tehran Urban and Suburban Railway Company (TRS) drivers by focusing on the role of emotional intelligence (EI) and job-driven (JD) factors. The core of the proposed method is a two-stage hybrid approach: first, an Artificial Neural Network (ANN) is used to model driver performance using EI and JD factors as inputs and outputs, respectively; then, Data Envelopment Analysis (DEA) validates the results and benchmarks performance levels. Data were collected from 146 TRS drivers through a standardized questionnaire. Sensitivity analysis and statistical tests evaluated the impact of EI and JD factors on driver performance. Additionally, a SWOT (Strengths, Weaknesses, Opportunities, Threats) analysis translated the findings into practical recommendations for system improvement. The findings reveal high job satisfaction and low job stress levels among TRS drivers, highlighting the significant contribution of EI and JD factors. By combining data-driven prediction, performance benchmarking, and strategic analysis, this study introduces a novel, human-centered framework for driver Performance Evaluation (PE)—one that fills methodological gaps in the literature and supports enhancing safety, efficiency, and passenger satisfaction in railway systems.},
  archive      = {J_EAAI},
  author       = {Narges Hajloo and Behnaz Salimi and Mahdi Hamid and Masoud Rabbani},
  doi          = {10.1016/j.engappai.2025.112065},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112065},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel framework for improving railway driver performance based on emotional intelligence and job-driven factors: An artificial neural network method},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient fusion-based deep learning framework for land use and land cover image clustering. <em>EAAI</em>, <em>161</em>, 112061. (<a href='https://doi.org/10.1016/j.engappai.2025.112061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land use and land cover (LULC) analysis is vital for understanding spatial dynamics and informing environmental management, urban planning, and sustainable development. Traditional approaches, such as manual surveys and conventional image clustering methods, often face limitations in scalability and adaptability. This paper presents a novel deep learning framework that combines the Vision Transformer (ViT) and Variational Autoencoder (VAE) to extract complementary feature representations for LULC image clustering. The ViT tokenizes image patches to capture high-level semantic features, while the VAE models latent structures to integrate contextual and structural information. To further improve clustering performance, the framework incorporates Uniform Manifold Approximation and Projection (UMAP) for dimensionality reduction followed by k -means++ clustering, enabling a scalable and robust solution for diverse datasets. Experiments on multiple datasets, including the Urban Atlas LULC 2018 dataset and recent LULC maps of Japan and Vietnam, demonstrate the framework’s superior ability to capture complex LULC patterns compared to traditional methods. The datasets and source code will be made publicly available at https://github.com/ClarkDinh/LULCMiner . This framework has broad applications across geospatial and remote sensing engineering, civil and environmental engineering, agricultural planning, transportation, and urban development.},
  archive      = {J_EAAI},
  author       = {Tai Dinh and Dat Tran and Zdena Dobešová and Huynh Van Hong and Daniil Lisik and Rameesh Khan},
  doi          = {10.1016/j.engappai.2025.112061},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112061},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient fusion-based deep learning framework for land use and land cover image clustering},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing multi-objectives urban siting of hydrogen refueling dispenser using fuzzy NSGA-II: A case study in fez, morocco. <em>EAAI</em>, <em>161</em>, 112060. (<a href='https://doi.org/10.1016/j.engappai.2025.112060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To support the growing need for sustainable urban transport, it is essential to reduce the environmental impact of vehicles; this study focuses on optimizing hydromobility through the strategic integration of hydrogen dispensers (HDs) into existing locations, rather than deploying standalone hydrogen refueling stations (HRSs). This approach minimizes costs while enhancing accessibility, addressing the current limitations in hydrogen vehicle (HV) adoption. A novel method combining the non-dominated sorting genetic algorithm II (NSGA-II) with fuzzy logic and Pareto front analysis is proposed to identify optimal HD locations using a real case study of Fez city in Morocco. The results provide actionable strategies for implementing HDs in a way that balances efficiency, accessibility, and budget constraints. The study demonstrates how intelligent planning can support the transition to cleaner energy solutions in urban mobility.},
  archive      = {J_EAAI},
  author       = {Soukayna Abibou and Dounia El Bourakadi and Ali Yahyaouy and Hamid Gualous},
  doi          = {10.1016/j.engappai.2025.112060},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112060},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing multi-objectives urban siting of hydrogen refueling dispenser using fuzzy NSGA-II: A case study in fez, morocco},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic data enhancement using diffusion models for improved miscanthus identification and bioenergy extraction. <em>EAAI</em>, <em>161</em>, 112059. (<a href='https://doi.org/10.1016/j.engappai.2025.112059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Miscanthus, a high-yielding perennial grass pivotal for bioenergy production, requires precise species identification to optimize bioenergy extraction. However, limited annotated spectral datasets hinder robust classification model development. To address this challenge, the paper proposes a novel diffusion probabilistic model tailored for near-infrared spectral synthesis. Unlike conventional generative approaches, the proposed model integrates a bidirectional gated recurrent unit-based temporal encoder and one dimension convolutional neural networks within a diffusion framework, augmented by a spectral attention module to prioritize critical absorption bands. This architecture uniquely addresses the sequential dependencies and subtle biochemical variations inherent in near-infrared spectral, enabling high-fidelity generation of diverse synthetic data. The diffusion process is optimized through a hybrid loss function combining variational lower bound training with mean squared error for pixel-level fidelity and maximum mean discrepancy for distributional alignment. Evaluated on 517 near-infrared spectral samples across three Miscanthus species, the proposed model outperforms traditional variational autoencoders , generative adversarial networks, and standard diffusion models in terms of sample authenticity and diversity. Incorporating synthetic data enhanced the accuracy, precision, and recall of downstream classifiers by 10%–15%, with the convolutional neural networks attaining 87% accuracy using hybrid real-synthetic training data. Remarkably, even with 50% synthetic data substitution, classification accuracy remained robust at 75%, demonstrating the model’s efficacy in mitigating data scarcity and advancing precision agriculture for bioenergy optimization.},
  archive      = {J_EAAI},
  author       = {Xinyue Wang and Xiangdong Chen and Jun Jiang and Ronggao Gong and Biao Wang},
  doi          = {10.1016/j.engappai.2025.112059},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112059},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synthetic data enhancement using diffusion models for improved miscanthus identification and bioenergy extraction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-order feature learning with global–local attention for real-time X-ray security inspection. <em>EAAI</em>, <em>161</em>, 112058. (<a href='https://doi.org/10.1016/j.engappai.2025.112058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X-ray security inspection in high-throughput environments such as airports faces fundamental challenges stemming from the intrinsic complexity of baggage scanning. These challenges include feature entanglement from overlapping objects, visual distortions due to fixed imaging angles, inconsistent pseudo-color representations caused by varying X-ray absorption, and the difficulty of detecting prohibited items across multiple scales. To tackle these challenges, we introduce Multi-Order Gated Network (MoGNet), a lightweight transformer-based architecture that integrates three core innovations. First, a Multi-order Gated Aggregation Block designed for efficient multi-order feature extraction. Second, a Global–Local Self-Attention mechanism that enhances differentiation between foreground and background elements. Finally, a DynamicFusion module for adaptive integration of multi-scale features. Comprehensive evaluations on five challenging datasets establish our proposed framework, MoGNet, as the new state-of-the-art (SOTA). The model demonstrates superior performance, achieving mean Average Precision (mAP) scores at a 50% Intersection over Union (IoU) threshold (mAP 50 ) of 75.4%, 91.9%, 91.2%, 96.6%, and 80.0%, respectively. This high accuracy is maintained while operating at an efficient 64.1 Frames Per Second (FPS). These comprehensive experimental results demonstrate its remarkable capability to optimize the balance between computational efficiency and detection accuracy, establishing it as a preferable solution for real-time contraband detection in practical security screening.},
  archive      = {J_EAAI},
  author       = {Ling Guo and Yangbin Xu and Shouhong Chen},
  doi          = {10.1016/j.engappai.2025.112058},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112058},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-order feature learning with global–local attention for real-time X-ray security inspection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stress-dependent strength neural network model for predicting the true triaxial strength of rocks. <em>EAAI</em>, <em>161</em>, 112057. (<a href='https://doi.org/10.1016/j.engappai.2025.112057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the true triaxial strength of rocks is essential for safe underground engineering, yet existing empirical and data-driven models often fail to capture the nonlinear effects of the intermediate principal stress σ 2 . This study proposes a stress-dependent strength neural network (SDSNN) that integrates physically informed constraints, including monotonicity and boundary conditions, as well as an exponential adaptive weighting strategy to balance data and constraint losses. Cohesion and internal friction angle are used as input features, replacing conventional reliance on uniaxial strength. Compared with a purely data-driven neural network (DDNN) and a constraint-aware variant without adaptive weighting (SDSNN#0), SDSNN achieves significantly better predictive accuracy and robustness across test sets, representative rock types, and five-fold cross-validation. In particular, it maintains consistent strength trends and improved stability across six representative rocks with diverse mechanical properties. Importantly, the model maintains high performance even when trained only on low-to-mid σ 2 data and tested on high σ 2 conditions—demonstrating strong generalization under extrapolation. This capability has received relatively limited attention in data-driven models and is particularly valuable in practical scenarios where high- σ 2 test data are limited or difficult to obtain. Furthermore, ablation analysis demonstrates that removing physical constraints leads to a notable decrease in model accuracy, underscoring the importance of incorporating strength variation characteristics into the model. SDSNN shows particular advantage under boundary stress conditions and when facing noisy or sparse datasets, indicating its potential to serve as a robust and interpretable tool for true triaxial strength prediction in geotechnical applications.},
  archive      = {J_EAAI},
  author       = {Tianzhi Yao and Yunpeng Gao and Jianhai Zhang and Ru Zhang and Li Qian and Qijun Hu and Xianliang Wang and Feng Jiang},
  doi          = {10.1016/j.engappai.2025.112057},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112057},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A stress-dependent strength neural network model for predicting the true triaxial strength of rocks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source contrastive cluster center method for cross-domain bearing fault identification. <em>EAAI</em>, <em>161</em>, 112056. (<a href='https://doi.org/10.1016/j.engappai.2025.112056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the complexity and time-varying attributes of the exterior surroundings, rolling bearings commonly operate under variable working conditions at any time. Therefore, there is a multi-source domain adaptation problem that involves multiple source domains and a target domain. In this circumstance, identifying faults directly in a multi-source domain through a model built in a single source domain will also lead to limited model generalization ability, i.e., due to the incompleteness of the training sample size caused by the singularity of the domain quantity limited access to fault knowledge in a single source domain, the established model may be prone to over-fitting, thus whose generalization ability has been decreased under complex and variable working conditions to a certain extent. Hence, this paper has proposed a Multi-source Contrastive Cluster Center (MS3C) Method for addressing the aforementioned issues. Experimental findings on two datasets have suggested that MS3C has not only considered the domain shifts of the same classes between different source domains and the target domain but also adaptively aligned the feature distributions of the same classses in different source domains, therefore, MS3C has a higher identification rate, a better clustering and classification performance and a superior convergence.},
  archive      = {J_EAAI},
  author       = {Pengfei Chen and Lizhen Wu and Rongzhen Zhao and Kongyuan Wei and Yuqiao Zheng and Linfeng Deng and Yongfei Zhang and Mingkuan Shi and Zhuo Chen},
  doi          = {10.1016/j.engappai.2025.112056},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112056},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-source contrastive cluster center method for cross-domain bearing fault identification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced encoder–decoder network for temporomandibular joint segmentation in magnetic resonance images. <em>EAAI</em>, <em>161</em>, 112054. (<a href='https://doi.org/10.1016/j.engappai.2025.112054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of the condyle, articular disc, and articular eminence from magnetic resonance imaging (MRI) is essential for the diagnosis and treatment planning of temporomandibular joint (TMJ) disorders. However, current deep learning methods for TMJ segmentation face significant challenges: (1) anatomical structures of the TMJ exhibit complex inter-patient variability; (2) structural boundaries are often ambiguous; and (3) large inter-slice spacing in MRI makes it difficult to fully utilize spatial context, limiting the effectiveness of both three-dimensional and two-dimensional approaches. To address these challenges, we propose an edge-enhanced TransUNet-based encoder–decoder framework that effectively integrates local edge features and global contextual information to obtain accurate and robust TMJ segmentation. Specifically, a cross-slice attention transformer (CAT) is introduced to capture inter-slice dependencies, addressing the challenge of large slice spacing and enhancing the utilization of contextual information across slices. Moreover, a feature enhancement module (FEM) is designed to explicitly fuse edge information, facilitating accurate localization where boundaries are blurred or indistinct. In addition, an attention gate (AG) mechanism adaptively highlights salient anatomical structures and suppresses irrelevant background, improving the model’s overall focus and resistance to noise. Evaluated on the private TMJ MRI dataset, our method achieves Dice similarity coefficients (DSC) of 0.922, 0.834, and 0.837 for the condyle, articular disc, and articular eminence, respectively, outperforming baseline and comparison methods. Further validation on a public knee MRI dataset demonstrates the good generalizability of the proposed method. These results demonstrate robust and precise TMJ segmentation, supporting reliable automated analysis in clinical settings.},
  archive      = {J_EAAI},
  author       = {Yilin Hu and Yunan Zhang and Wei Tang and Jixiang Guo},
  doi          = {10.1016/j.engappai.2025.112054},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112054},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An enhanced encoder–decoder network for temporomandibular joint segmentation in magnetic resonance images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way decision method integrating probabilistic linguistic term sets and prospect theory in large-scale scenarios. <em>EAAI</em>, <em>161</em>, 112053. (<a href='https://doi.org/10.1016/j.engappai.2025.112053'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probability linguistic term sets (PLTSs), owing to their ability to effectively represent the uncertainty and complexity of decision information, have been widely adopted in large-scale multiattribute decision-making (MADM) scenarios. However, existing decision-making methods in the PLTS environment typically suffer from information loss in similarity computation, subjectivity in weight determination, and inadequate consideration of decision-makers’ behavioral psychology, which limits their applicability in real-world complex situations. To address these issues, this paper proposes an innovative hybrid three-way decision (TWD) method that integrates prospect theory with multiobjective optimization on the basis of the ratio analysis (MOORA) approach. Compared with existing studies, the main contributions of this paper include (1) an objective weight determination mechanism based on the information entropy of PLTSs, which improves the scientific validity and computational efficiency of weight allocation compared with subjective or complex traditional methods (2) a novel direct similarity degree based on the probability linguistic Jensen–Shannon (PLJS) divergence, which effectively overcomes the information loss caused by indirect distance measures and achieves accurate similarity characterization between PLTSs (3) a new conditional probability determination strategy utilizing θ -level similarity classes that enhances the dynamic adaptability and accuracy of conditional probability estimation and (4) the integration of prospect theory and the MOORA method within the TWD framework, enabling hierarchical classification of alternatives while fully reflecting decision-makers’ psychological and behavioral characteristics, thereby facilitating the classification and ranking of alternatives. Furthermore, through comparative analysis with large-scale real-world air quality assessment data and mainstream PLTS-based decision-making methods, the effectiveness and rationality of the proposed method are comprehensively verified, demonstrating its superiority, robustness, and practical application value.},
  archive      = {J_EAAI},
  author       = {Zhaxi Pahua and Haidong Zhang and Yizhu Cairang and Yanping He},
  doi          = {10.1016/j.engappai.2025.112053},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112053},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-way decision method integrating probabilistic linguistic term sets and prospect theory in large-scale scenarios},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive feature-level fusion of manifold and deep learning for robust multi-view face recognition. <em>EAAI</em>, <em>161</em>, 112052. (<a href='https://doi.org/10.1016/j.engappai.2025.112052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust face recognition across varying poses, lighting conditions, and viewpoints remains a significant challenge in engineering applications such as surveillance, authentication, and human–computer interaction. This paper presents Dynamic Manifold–Deep Learning Fusion (DM-DLF), an artificial intelligence (AI)-based framework that integrates manifold learning with deep neural networks using an adaptive feature-level weighting strategy. By combining global semantic features and local geometric structures, the proposed AI model enhances identity recognition under real-world multi-view scenarios. Experimental results show that DM-DLF surpasses recent transformer-based and graph-based models, achieving up to 94.00 % classification accuracy. The method also reduces prediction error and improves training efficiency. These findings confirm DM-DLF as a powerful AI solution for multi-view face recognition in engineering systems where labeled data is limited and view diversity is high.},
  archive      = {J_EAAI},
  author       = {Faraein Aeini},
  doi          = {10.1016/j.engappai.2025.112052},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112052},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive feature-level fusion of manifold and deep learning for robust multi-view face recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing long-term load forecasting with convolutional informer-based hybrid model. <em>EAAI</em>, <em>161</em>, 112051. (<a href='https://doi.org/10.1016/j.engappai.2025.112051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term load forecasting (LTLF) is essential for energy management but challenged by the complexity of non-stationary time series. The Informer model struggles to capture localized peak–valley patterns, while Variational Mode Decomposition (VMD) faces issues with feature complexity. This study proposes a hybrid framework integrating VMD, Informer, and a Convolutional Long Short-Term Memory (CNN-LSTM) module for accurate LTLF. VMD decomposes non-stationary load data into multi-scale intrinsic mode functions, refined through spectral and autocorrelation analyses to ensure robust feature extraction. The Informer employs sparse self-attention for efficient long-sequence modeling, with CNN-LSTM enhancing the decoder to capture localized temporal dynamics. Experiments on non-stationary load time series across multiple prediction horizons demonstrate that the proposed framework significantly improves forecasting accuracy and robustness compared to baseline models, including Informer and its derivatives. By excelling in complex load pattern prediction, the framework supports efficient grid scheduling and resource optimization in energy systems.},
  archive      = {J_EAAI},
  author       = {Bin Sun and Xudong Chen and Tao Shen and Liyao Ma},
  doi          = {10.1016/j.engappai.2025.112051},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112051},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing long-term load forecasting with convolutional informer-based hybrid model},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault diagnosis of high-voltage three-phase asynchronous motors using residual neural networks and bidirectional gated recurrent units. <em>EAAI</em>, <em>161</em>, 112049. (<a href='https://doi.org/10.1016/j.engappai.2025.112049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-voltage three-phase asynchronous motors are extensively used in industrial production; however, rotor bar breakage faults are characterized by strong concealment and severe consequences, making early and accurate diagnosis difficult with traditional methods. To address this issue, this paper proposes a deep learning model based on a Residual Neural Network (ResNet) and a Bidirectional Gated Recurrent Unit (Bi-GRU) for motor fault diagnosis. The proposed model integrates the spatial feature extraction advantages of ResNet with the temporal modeling capabilities of Bi-GRU, simultaneously capturing spatiotemporal information from voltage and current signals. The model was trained and tested on a large-scale dataset comprising 324,000 data points under nine distinct operating conditions. Experimental results demonstrate that the proposed method achieves over 99.83 % in key metrics such as accuracy, precision, recall, and F1-score, significantly outperforming traditional approaches and other comparative models. Additionally, it maintains stable performance under varying operating conditions, demonstrating strong robustness and generalization capability. Further ablation experiments also validated the effectiveness of each module within the proposed model. This study indicates that the application of deep learning in industrial motor fault diagnosis has promising prospects and practical value.},
  archive      = {J_EAAI},
  author       = {Huihui Yang and Yuxin Wu},
  doi          = {10.1016/j.engappai.2025.112049},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112049},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis of high-voltage three-phase asynchronous motors using residual neural networks and bidirectional gated recurrent units},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot image translation via query compensation and style enhancement. <em>EAAI</em>, <em>161</em>, 112048. (<a href='https://doi.org/10.1016/j.engappai.2025.112048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In zero-shot image translation methods based on diffusion models, two prevalent challenges are the loss of identity information and insufficient stylization. To address these issues, we propose a zero-shot image translation method. Specifically, we use the edit-friendly noise space for image inversion. By this way, the identity of the input image is largely preserved. Additionally, we introduce an identity compensation mechanism by injecting the source query vectors into the denoising process. Furthermore, to tackle the model’s insufficient stylization ability, we propose cross-attention style modulation (CSM) to transfer style information from the reference to the input image. Finally, to further enhance the style effect of the translated image, we design initial latent self-enhancement (ILS), style supplementation (SS), and style alignment (SA) strategies. Our zero-shot image translation method does not require training samples, optimization, or fine-tuning. We achieve this by manipulating the self-attention features of a pre-trained diffusion model in a manner analogous to cross-attention—by replacing the key and value vectors of the input image with those of the reference image during the denoising process. Extensive in-domain and cross-domain translation experiments demonstrate the effectiveness of our method across a wide range of object categories and show strong robustness to variations in object shape, size, posture and instance between the input and reference image. The proposed method achieves competitive performance in identity preservation, as measured by the mean Intersection over Union (mIoU), and attains the best style transfer in terms of Single Image Fréchet Inception Distance (SIFID). In addition, qualitative comparisons demonstrate that our approach significantly outperforms the baselines.},
  archive      = {J_EAAI},
  author       = {Heng Zhang and Yi-Jun Yang and Wei Zeng},
  doi          = {10.1016/j.engappai.2025.112048},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112048},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-shot image translation via query compensation and style enhancement},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Camouflaged object detection with boundary localization in complex backgrounds. <em>EAAI</em>, <em>161</em>, 112047. (<a href='https://doi.org/10.1016/j.engappai.2025.112047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary challenge of Camouflaged Object Detection (COD) lies in the high similarity between the target and the complex background, making it difficult for the human eye to distinguish them. Based on the phenomenon that human attention shifts between the target and the background when observing objects, we propose a network model named MENet. This model adopts a three-stage decoupled architecture of “localization-interaction-fusion.” In the localization stage, we utilize an attention mechanism-based backbone network (Pyramid Vision Transformer V2, abbreviated as PVT-V2) to generate multi-level features, which can initially locate the target area. In the interaction stage, we design a Contour-Aware Edge Module (CAEM) and an Area Decoder (AD) to capture the target edges and background information, respectively, thereby achieving precise localization of the target boundary and reducing interference from background noise. Furthermore, we developed a Boundary Guidance Module (BGM) that effectively injects boundary cues and relevant background information separately into the multi-level features, enhancing the model’s ability to detect target edges in complex backgrounds. In the fusion stage, we design two Feature Fusion Modules (FFM and KFFM) to effectively merge multi-level features with precise boundaries and de-noised features, thereby enhancing the prediction performance of camouflaged objects. Extensive experiments on three challenging benchmark datasets demonstrate that our MENet outperforms many existing state-of-the-art methods. Our method leverages artificial intelligence (AI) techniques to improve the accuracy of camouflaged object and pest detection in complex visual environments. Our code is publicly available at: https://github.com/yang19950966666/MENet .},
  archive      = {J_EAAI},
  author       = {Guangjian Zhang and Zhengming Yang and Yong Wang and Yuliang Chen and Duoqian Miao},
  doi          = {10.1016/j.engappai.2025.112047},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112047},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Camouflaged object detection with boundary localization in complex backgrounds},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A grid-based boundary sharpening clustering algorithm. <em>EAAI</em>, <em>161</em>, 112045. (<a href='https://doi.org/10.1016/j.engappai.2025.112045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the clustering problem for arbitrary shapes, in this paper, we propose a Grid-based Boundary Sharpening clustering algorithm called as “GBSharp”. This method is grounded in morphology and relies on two fundamental morphological operations: dilation and erosion. The main innovations of the proposed algorithm lie in two aspects. Firstly, we further introduce the concepts of inward dilation and bridge erosion based on the basic morphological operations to reduce the impact of the chain effect. Secondly, a unique indexing structure is designed specifically for non-empty cells in high dimensional space. In addition, to tackle the complex conditional judgments encountered in high-dimensional scenarios, we further utilize the inversion method for bridge-erosion operation. Experiments conducted on synthetic datasets and real-world datasets further validate the effectiveness and efficiency of the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Lin Ma and Qijing Yan and Mengxia Lv and Tiefeng Ma and Mingchang Cheng},
  doi          = {10.1016/j.engappai.2025.112045},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112045},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A grid-based boundary sharpening clustering algorithm},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advances in physics-informed neural networks for solving complex partial differential equations and their engineering applications: A systematic review. <em>EAAI</em>, <em>161</em>, 112044. (<a href='https://doi.org/10.1016/j.engappai.2025.112044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most physical and engineering problems can be described by partial differential equations (PDEs), which are typically solved using numerical methods such as the finite difference method and the finite element method. However, conventional numerical discretization approaches face significant challenges in terms of computational efficiency and convergence speed when dealing with complex nonlinear PDEs, such as high-dimensional nonlinear PDEs, stiff PDEs, PDEs with complex boundary conditions or irregular geometries, and multi-scale PDEs. Recently, physics-informed neural networks (PINNs) have emerged as a transformative methodology for solving complex PDEs by integrating physical laws intrinsically into deep learning architectures. While PINNs effectively overcome mesh dependency and dimensionality constraints inherent in traditional numerical methods, they still encounter persistent challenges related to training convergence and generalization robustness. This paper aims to present a comprehensive review of the state-of-the-art developments in PINNs for solving complex PDE problems. The core ideas, network architectures, and generic implementation frameworks, along with associated open-source Python libraries, are first introduced in detail. Furthermore, a systematic taxonomy of optimization techniques is provided, covering hyperparameter selection, adaptive sampling strategies, physics-constrained loss formulations, hybrid differentiation approaches, and architectural innovations. Subsequently, various coping strategies and research advancements of PINNs in addressing complex nonlinear PDE problems are thoroughly discussed. Real-world engineering applications are then reviewed across multiple domains, including cosmology and quantum mechanics, materials science and manufacturing, fluid mechanics, energy systems, biological and environmental sciences, and power and information technologies. Finally, this paper discusses the current challenges and limitations of PINNs in solving complex PDEs and outlines potential directions for future research. By addressing the current limitations and pursuing targeted improvements in architectures, training, interpretability and generalization, PINNs can become a powerful tool in engineering and scientific applications.},
  archive      = {J_EAAI},
  author       = {Jiangtao Guo and Hao Zhu and Yujie Yang and Chenrui Guo},
  doi          = {10.1016/j.engappai.2025.112044},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112044},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Advances in physics-informed neural networks for solving complex partial differential equations and their engineering applications: A systematic review},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DPMF-net: A dual-path perceptive multi-stage fusion network for skin lesion segmentation. <em>EAAI</em>, <em>161</em>, 112043. (<a href='https://doi.org/10.1016/j.engappai.2025.112043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of skin lesions in dermoscopic images is crucial for skin cancer detection and treatment. Despite progress in deep learning-based methods, challenges remain due to diverse skin lesion shapes, colors, and blurred boundaries. We propose a novel Dual-path Perceptive Multi-stage Fusion Network (DPMF-Net) for skin lesion segmentation. DPMF-Net integrates multiple feature refinement modules. It aims to gradually optimize lesion representations by leveraging the dual-path framework to perceive high-level contextual information. The Spatial Frequency Dual-path Cascaded Perception Module (SFDCP) synergizes spatial and frequency domains to model long-range dependencies and suppress noise, enhancing perception of low-contrast lesions. Subsequent to the SFDCP, the Spatial Channel Dual-path Parallel Perception Module (SCDPP) employs entropy-driven attention and multi-granularity convolutions in skip connections to dynamically select informative channels and extract lesion details across spatial scales. To verify the efficacy of our proposed DPMF-Net, extensive experimental assessments are carried out across four challenging datasets. The outcomes of these quantitative and qualitative experiments confirm that our approach significantly outperforms current state-of-the-art methods in terms of all evaluation metrics.},
  archive      = {J_EAAI},
  author       = {Yuling Huang and Yaoyao Ma and Jing Wang and Chao Xu and Zhiwei Fan and Di Wu},
  doi          = {10.1016/j.engappai.2025.112043},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112043},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DPMF-net: A dual-path perceptive multi-stage fusion network for skin lesion segmentation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradient surgery: A necessity for robust test-time adaptation for detecting casting defects. <em>EAAI</em>, <em>161</em>, 112039. (<a href='https://doi.org/10.1016/j.engappai.2025.112039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Casting defects pose a significant challenge in the manufacturing industry, leading to material waste, production inefficiencies, and compromised product quality. While deep learning models have shown promise in automating defect detection, their effectiveness is often constrained by domain shifts and variability in real-world data distributions. In this work, we propose Bayesian Test-Time Adaptation (BTTA), a novel framework designed to enhance the robustness and adaptability of machine learning models in such dynamic environments. Unlike traditional Test-Time Adaptation (TTA) methods, our approach employs gradient-guided diversification with Stein Variational Gradient Descent (SVGD) to explore diverse optimization paths. Experimental results on benchmark datasets, including CIFAR-10-C , Casting Defects , and GDXray , demonstrate significant performance improvements across key metrics. Notably, the framework achieves an average accuracy improvement of 2-3% under severe corruption levels and excels in cross-domain generalization, highlighting its ability to handle diverse and unseen defect categories. This dynamic adaptability not only addresses the limitations of static models but also offers a practical and cost-effective solution for real-time defect detection in industrial settings. Our study underscores the potential of BTTA to transform quality assurance processes, ensuring reliable performance across varying operational conditions without the need for extensive retraining or large annotated datasets. The codebase for BTTA is available on: https://github.com/afsharshamsi/GradSurgery .},
  archive      = {J_EAAI},
  author       = {Afshar Shamsi and Rejisa Becirovic and Hamid Alinejad-Rokny and Arash Mohammadi and Ahmadreza Argha},
  doi          = {10.1016/j.engappai.2025.112039},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112039},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Gradient surgery: A necessity for robust test-time adaptation for detecting casting defects},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing real-time detection transformer for small floating targets. <em>EAAI</em>, <em>161</em>, 112038. (<a href='https://doi.org/10.1016/j.engappai.2025.112038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing the challenge of detecting small floating target in complex water environments, where it is difficult to balance real-time performance and end-to-end capabilities, this study introduces a specialized model called the Enhancing Real-Time Detection Transformer (ERT-DETR). This model integrates a Dynamic Feature Pyramid Network (DFPNet) with a Micro-Attention Module (MAM) to achieve refined feature extraction and enhanced object recognition mechanisms. Additionally, it incorporates an Inner Intersection over Union (Inner-IoU) auxiliary bounding box loss function, which accelerates model convergence and improves bounding box accuracy. Experiments conducted on the Floating Object in Water Image Dataset (FloW-Img) demonstrate that the ERT-DETR model achieves a 92.6% Average Precision (AP) and 118.84 Frames Per Second (FPS), outperforming the baseline Real-Time Detection Transformer (RT-DETR) by 4.3% and 19.8%, respectively. The ERT-DETR model’s precision and real-time performance in dynamic water surface environments surpass those of the most advanced You Only Look Once (YOLO) and Detection Transformer (DETR) series detectors. This model is significant for enhancing small floating target detection capabilities in complex water environments and can be extended to applications in marine management, environmental monitoring, and vessel tracking.},
  archive      = {J_EAAI},
  author       = {Guobing Xie and Xinran Wu and Jiefeng Shi and Yixin Su and Binghua Shi},
  doi          = {10.1016/j.engappai.2025.112038},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112038},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing real-time detection transformer for small floating targets},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-contact weight intelligent estimation based on yak skeleton localization. <em>EAAI</em>, <em>161</em>, 112036. (<a href='https://doi.org/10.1016/j.engappai.2025.112036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weight estimation is a vital method for monitoring the growth and health of yaks, however, traditional techniques-such as relying on herders’ experience or using weighbridge-are labor-intensive, time-consuming and pose safety risks. Currently, many studies have shown that yak body size can be an effective indicator of weight. With the advancement of computer vision, non-contact weight estimation has become increasingly feasible for livestock. Yet, studies focusing on yak weight estimation, particularly in high-altitude plateau regions, remain limited. Herein, we propose a novel weight estimation approach based on deep learning and binocular vision technology to address this gap. The method involves four main steps: (1) yak image acquisition, (2) skeletal key point localization, (3) body size calculation (4) weight estimation using Gaussian process regression. To enhance practicality and mobility, we also developed two edge-intelligent devices: an intelligent inspection vehicle and a handheld detection unit, enabling convenient and non-invasive weight estimation. Our models are trained and tested on a yak dataset collected by our team on the Tibetan Plateau. Experimental results demonstrate the effectiveness of our approach, achieving an Mean Absolute Percentage Error (MAPE) of 0.12 percent, a Mean Absolute Error (MAE) of 25.4 kilograms (kg) and a Coefficient of determination ( R 2 ) value of 0.72. It not only provides a new technical solution for the yak industry but also provides innovative insights for advancing intelligent animal husbandry. The code and data can be accessed at https://github.com/FeiWang-swun/YakWeight .},
  archive      = {J_EAAI},
  author       = {Fei Wang and Xinghua Zou and Zhijiang Chen and Qi Tang and Tianshuo Li and Shuiying Wang and Lijun Yang and Dongming Tang},
  doi          = {10.1016/j.engappai.2025.112036},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112036},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Non-contact weight intelligent estimation based on yak skeleton localization},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of the performances of artificial intelligence bots using continuous intuitionistic fuzzy evaluation based on distance from average solution method. <em>EAAI</em>, <em>161</em>, 112033. (<a href='https://doi.org/10.1016/j.engappai.2025.112033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of artificial intelligence (AI) has introduced novel opportunities and challenges in various fields. In this study, we present a pioneering approach known as Continuous Intuitionistic Fuzzy (CINFU) Evaluation based on Distance from Average Solution (EDAS), an innovative extension of the EDAS method tailored to Continuous Intuitionistic Fuzzy Sets. This methodology is designed to compare the performance of AI tools. The capabilities of AI bots have been examined through their success rates in various tasks and uncertainty levels in decision-making processes. The study aims to evaluate the effectiveness of different models in decision-making processes by analyzing the performances of AI bots such as Chat Generative Pre-trained Transformer (ChatGPT), Bard, and Claude based on both objective measurements and fuzzy evaluation criteria. The comparison focuses on key performance criteria such as Bots Triggered, User Engagement, Message Click-Through Rate, Chat Handoff, User Retention, Bounce Rate & Dwell Time, Leads Captured, and Customer Satisfaction Score. Ultimately, the validity and robustness of the approach have been tested with sensitivity analysis.},
  archive      = {J_EAAI},
  author       = {Nurşah Alkan and Umut Aydın and Akın Menekşe and Cengiz Kahraman},
  doi          = {10.1016/j.engappai.2025.112033},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112033},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comparison of the performances of artificial intelligence bots using continuous intuitionistic fuzzy evaluation based on distance from average solution method},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A global linear attention incorporated video transformer for robust sintering condition recognition. <em>EAAI</em>, <em>161</em>, 112032. (<a href='https://doi.org/10.1016/j.engappai.2025.112032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust and accurate sintering condition recognition is a fundamental yet critical issue in the design of image-based intelligent combustion control systems. However, owing to the weak texture and fast changing characteristics of flame videos, capturing the condition indicator using existing gradient-based methods is challenging. To address this issue, we propose a global linear attention incorporated video transformer model for sintering condition recognition. First, to reduce the prediction error and uncertainty, the spatial-temporal features are extracted to describe the dynamic characteristics of the flame video streams based on the video shifted window (Swin) Transformer architecture. Next, to address the problem that the local attention strategy used in the Video Swin Transformer is insufficient for global flame feature extraction, we propose a Video Linear Attention block that obtains the global attention as a supplement. Extensive experiments conducted on a real-world rotary kiln sintering dataset demonstrate the effectiveness of our approach, achieving an overall accuracy of 97.76% and an F1-score of 95.30%. Compared to the Video Swin Transformer model, these results represent improvements of 2.00% in accuracy and 4.96% in F1-score, respectively. This research is particularly significant in the context of real-time identification of combustion process conditions, optimization of control parameters, and realization of more stable and efficient combustion process control.},
  archive      = {J_EAAI},
  author       = {Leyuan Wu and Junlin Wu and Dingxiang Wang and Qiang Fu},
  doi          = {10.1016/j.engappai.2025.112032},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112032},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A global linear attention incorporated video transformer for robust sintering condition recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Markerless gait analysis for parkinson’s disease diagnosis: A study on machine learning integration and features explainability. <em>EAAI</em>, <em>161</em>, 112031. (<a href='https://doi.org/10.1016/j.engappai.2025.112031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease is a common neurodegenerative disorder with progressive loss of dopaminergic and other subcortical neurons that significantly impair motor functions, necessitating accurate diagnostic and monitoring techniques. Researchers commonly use gait analysis to estimate gait parameters to classify diseases and their progression. Traditional gait analysis, while effective, typically requires expensive, specialized equipment and lacks the flexibility for widespread clinical use. Furthermore, many existing studies on markeless approaches do not use public datasets, giving comparable and benchmarking results. Additionally, these methods often do not incorporate explainability, leaving a gap in understanding which specific gait features most significantly impact diagnostic outcomes. To address this issue, we propose a novel system to support diagnosis and analysis of the gait of Parkinson’s disease. The two-step approach involves pose extraction with vision-based pose estimation and classification employing machine learning techniques based on the subject’s temporal, kinematic, and symmetric characteristics. The explainability technique used in this study shows the important role of features such as the knee angle, cadence, and double support duration in influencing diagnostic outcomes. The system shows promising results for non-invasive, low-cost Parkinson’s disease diagnostics, reaching an accuracy of 0.95, a sensitivity of 0.90, a specificity of 0.97, a Matthew’s Correlation Coefficient (MCC) of 0.88, an Area Under the Curve (AUC) of 0.99.},
  archive      = {J_EAAI},
  author       = {Cesare Davide Pace and Alessandro Marco De Nunzio and Claudio De Stefano and Francesco Fontanella and Mario Molinara},
  doi          = {10.1016/j.engappai.2025.112031},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112031},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Markerless gait analysis for parkinson’s disease diagnosis: A study on machine learning integration and features explainability},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Offshore wind power multi-step forecasting based on multi-scale attention mechanism fusion network. <em>EAAI</em>, <em>161</em>, 112026. (<a href='https://doi.org/10.1016/j.engappai.2025.112026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonlinear, unstable, and multi-scale characteristics of offshore wind power present significant challenges for grid scheduling and power forecasting. To address this issue, this paper proposes a multi-step forecasting hybrid model for offshore wind power based on the sequence-to-sequence (Seq2Seq) architecture, which is named Multi-scale, Denoising, Attention Fusion Network (mDAFNet). The model integrates a multi-level learnable wavelet decomposition network, frequency-domain interpolation denoising technique, and dual-attention mechanism, and improves forecasting performance through joint high- and low-frequency dual-branch predictions. The process begins by improving data quality through outlier cleaning and feature selection based on grey correlation analysis and mutual information. Subsequently, a multi-level learnable wavelet decomposition network is introduced to extract high- and low-frequency subsequences from the frequency domain and optimize parameters dynamically through backpropagation. To address the noise impact on high-frequency subsequences, frequency domain interpolation denoising technique is applied for noise reduction. Then, a sequence-to-sequence model based on the dual-attention mechanism is used to forecast the denoised high-frequency subsequences, while a Long Short-Term Memory (LSTM) neural network predicts the low-frequency subsequences. Finally, the dual-branch forecasting network enables joint modeling of high- and low-frequency subsequences. We conducted experiments on two offshore wind power datasets. The results indicate that, compared to baseline models, the proposed mDAFNet reduces Mean Absolute Error, Root Mean Square Error, and Mean Absolute Percentage Error by an average of 33.94 %, 36.62 %, and 39.84 %, respectively, while significantly improving forecasting accuracy and stability. This study provides a new approach and perspective for offshore wind power forecasting.},
  archive      = {J_EAAI},
  author       = {Yizhuang Xiong and Wenbo Wang},
  doi          = {10.1016/j.engappai.2025.112026},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112026},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Offshore wind power multi-step forecasting based on multi-scale attention mechanism fusion network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted multi-granularity fuzzy probabilistic rough set based on semi-overlapping function and its application in three-way decision. <em>EAAI</em>, <em>161</em>, 112023. (<a href='https://doi.org/10.1016/j.engappai.2025.112023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel model of fuzzy probabilistic rough sets and develops an interesting three-way decision (TWD) applicable to multi-attribute group decision-making and classification problems. First, we simultaneously consider the cut-levels of fuzzy relations and decision-making fuzzy sets, investigating a new fuzzy probabilistic rough set model. This model employs semi-overlapping functions as the range of the membership functions of the fuzzy set, enhancing interpretability since the semi-overlapping functions can act as the truth tables of fuzzy logic. Second, by assigning different weights to various granular fuzzy relations, we propose a weighted multi-granularity fuzzy probabilistic rough set model. It is proven that the proposed (weighted multi-granularity) fuzzy probabilistic rough set model encompasses many existing models as special cases, thereby providing a very broad framework for rough set theory. Third, by integrating the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) method with Bayesian theory, we develop a method for computing the threshold of fuzzy probabilistic rough sets and construct a new TWD. Sorting and classification rules and algorithms for TWD are provided. Finally, we perform parameter analysis and comparative experiments on nine public datasets to verify the effectiveness and rationality of our TWD. The experimental results demonstrate that our approach exhibits superior fault tolerance and noise reduction capabilities. Specifically, the introduction of semi-overlapping functions enhances our TWD model’s performance, with A c c u r a c y improving the most on the Heart dataset, reaching 9.37%, and the F 1 score increasing the most on the Heart and Plrx datasets, reaching 5.3%. In summary, this paper offers a novel solution for applying artificial intelligence in decision-making scenarios.},
  archive      = {J_EAAI},
  author       = {Xinru Li and Lingqiang Li and Chengzhao Jia},
  doi          = {10.1016/j.engappai.2025.112023},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112023},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Weighted multi-granularity fuzzy probabilistic rough set based on semi-overlapping function and its application in three-way decision},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-driven double deep Q-network with iterated greedy for intelligent scheduling optimization in reentrant hybrid flow shops. <em>EAAI</em>, <em>161</em>, 112012. (<a href='https://doi.org/10.1016/j.engappai.2025.112012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reentrant hybrid flow shop scheduling problem (RHFSP) poses significant challenges due to its complex structure and limited research on model accuracy, solution space exploration, and adaptive strategy selection. To address these gaps, this paper proposes a novel feature-driven double deep Q-network with iterated greedy (FD3QNIG) algorithm. First, a five-dimensional mixed-integer linear programming (MILP) model is developed to significantly improve modeling accuracy. Second, a feature-driven initialization strategy (FDNEH) enhances the quality of initial solutions, while an adaptive historical information-driven destruction and reconstruction strategy (AHDDR) effectively balances exploration and exploitation during the search process. Third, multi-scale local search strategies are employed, including the first application of comprehensive exploration-driven mandatory operations local search (CED_MOLS) to RHFSP, substantially deepening the search capability. Fourth, an adaptive strategy selection mechanism based on double deep Q-Network (DDQN_ASS) dynamically guides the algorithm toward more efficient decision-making. Extensive experiments on 285 benchmark instances demonstrate that FD3QNIG achieves a 53 %–94 % improvement in average relative percentage increase ( A R P I ) over state-of-the-art methods, confirming its effectiveness and robustness.},
  archive      = {J_EAAI},
  author       = {Chexiang Li and Yuyan Han and Yuting Wang and Yiping Liu and Biao Zhang and Leilei Meng},
  doi          = {10.1016/j.engappai.2025.112012},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112012},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-driven double deep Q-network with iterated greedy for intelligent scheduling optimization in reentrant hybrid flow shops},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semi-supervised framework for generating multi-dimensional taxonomies from asset maintenance documents. <em>EAAI</em>, <em>161</em>, 112010. (<a href='https://doi.org/10.1016/j.engappai.2025.112010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operation and maintenance of buildings generate large volumes of unstructured textual data, such as inspection reports and service requests. These records contain valuable insights that can support fault detection, cost tracking, and resource planning. However, existing classification approaches often rely on static, expert-defined labels that fail to reflect the complexity of real-world maintenance operations. This paper introduces a hybrid framework that combines sentence embedding, clustering, topic modeling, and network modularization to uncover recurring patterns in maintenance text. The extracted patterns are then reviewed and refined by facility management experts to develop a multi-dimensional taxonomy model tailored to operational needs. The methodology is applied to a case study involving over 30,000 work orders. The results demonstrate how the proposed system captures fine-grained details such as system type, failure mode, and required trade expertise. A proof-of-concept software tool, developed in collaboration with facility managers, showcases the practical value of the taxonomy in enabling data-driven decision-making, such as identifying cost drivers and recurring issues. Additionally, the resulting taxonomy models serve as effective prompts for zero-shot text classification, enabling large language models to classify new maintenance records without requiring retraining or labeled data. This approach provides a scalable and adaptable foundation for text classification systems in asset management.},
  archive      = {J_EAAI},
  author       = {Soroush Sobhkhiz and Tamer El-Diraby},
  doi          = {10.1016/j.engappai.2025.112010},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112010},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A semi-supervised framework for generating multi-dimensional taxonomies from asset maintenance documents},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive review of facial beauty prediction using deep learning techniques. <em>EAAI</em>, <em>161</em>, 112009. (<a href='https://doi.org/10.1016/j.engappai.2025.112009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial beauty prediction (FBP) is an emerging area of artificial intelligence (AI) that focuses on the development of models that analyze facial features to assess beauty, based on human perception. This task is particularly challenging due to the subjective nature of beauty and limited resources. Deep learning methods have proven their exceptional ability to capture complex features and are therefore well suited for FBP tasks. This paper reviews recent advances in FBP, focusing on deep learning techniques and benchmark datasets. A proposed taxonomy organizes the main methods according to their design and applications, and comparative analyzes highlight trends and the performance of different models. Finally, the study outlines future research directions to drive progress in this evolving field.},
  archive      = {J_EAAI},
  author       = {Djamel Eddine Boukhari and Fadi Dornaika and Ali Chemsa and Abdelmalik Taleb-Ahmed},
  doi          = {10.1016/j.engappai.2025.112009},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112009},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comprehensive review of facial beauty prediction using deep learning techniques},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum relevant minimum redundant multi-label feature selection using ant colony optimization. <em>EAAI</em>, <em>161</em>, 112007. (<a href='https://doi.org/10.1016/j.engappai.2025.112007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning tasks involve instances that may belong to multiple categories simultaneously, making feature selection particularly challenging in high-dimensional feature spaces. Existing multi-label feature selection methods often suffer from limitations such as high computational complexity, inadequate handling of feature redundancy, and insufficient modelling of label dependencies. To overcome these challenges, we propose a novel framework called Maximum Relevant Minimum Redundant Multi-Label Feature Selection (MR2MLFS), which integrates a two-layer graph representation with a modified Ant Colony Optimization (ACO) strategy. The first graph layer clusters correlated features using Louvain community detection, while the second constructs a meta-graph to model inter-cluster relationships. ACO then explores this structure, favouring the selection of highly relevant and non-redundant features. To reduce computational overhead, we introduce an information-theoretic metric that estimates both feature-label relevance and feature-feature redundancy, eliminating the need for repeated classifier training during the search. We evaluated the proposed method on ten benchmark multi-label datasets using several multi-label classifiers. Experimental results show that the proposed method outperforms six state-of-the-art methods across multiple evaluation metrics, achieving an average relative improvement of 5–12 % while reducing feature dimensionality by up to 80 %. These results confirm the method's robustness, efficiency, and effectiveness in multi-label feature selection.},
  archive      = {J_EAAI},
  author       = {Mohammad Hatami and Parham Moradi and Sadegh Sulaimany and Mahdi Jalili},
  doi          = {10.1016/j.engappai.2025.112007},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112007},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Maximum relevant minimum redundant multi-label feature selection using ant colony optimization},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage model for unified sentence- and document-level biomedical event extraction. <em>EAAI</em>, <em>161</em>, 112001. (<a href='https://doi.org/10.1016/j.engappai.2025.112001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical event extraction, a cornerstone of information extraction, has increasingly attracted attention within the biomedical research community. Moreover, it is a highly complex task, which not only deals with many sub-tasks but also involves nested events. Currently, the research on biomedical event extraction, whether pipelined model or joint method, needs to be processed for each sub-task. The process of processing each sub-task one by one lead to the degradation of event extraction performance. In addition, most studies focus on extracting sentence-level events and ignore cross-sentence event information. To solve these problems, we simplify the process of event extraction, reduce the processing steps, and combine the two sub-tasks of relation extraction and argument combination as one sub-task. In addition, we consider document-level event extraction, which not only extracts cross-sentence events but also considers broader context information. Experimental results indicate that our novel approach outperforms prior studies. Additionally, the document-level event extraction model attains the top performance on the BioNLP’11 test data and achieves near-leading performance on the BioNLP’13 test data.},
  archive      = {J_EAAI},
  author       = {Fangfang Su and Yue Zhang and Pengfei Jiao and Zhidong Zhao and Bobo Li and Fei Li and Donghong Ji},
  doi          = {10.1016/j.engappai.2025.112001},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112001},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two-stage model for unified sentence- and document-level biomedical event extraction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A position-aware sets based weakly supervised framework for whole-slide subtype classification. <em>EAAI</em>, <em>161</em>, 111998. (<a href='https://doi.org/10.1016/j.engappai.2025.111998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying cancer subtypes is essential for personalized treatment and accurate prognosis due to the varying sensitivities of subtypes to therapies. However, in cancer subtype classification tasks, normal slides are usually scarce or absent as negative samples, while subtype whole-slide images (WSIs) often contain extensive unannotated normal tissue regions. These regions introduce significant noise during feature fusion and subtype classification, leading to degraded performance of existing weakly supervised methods In this paper, we propose the Position-aware Sets based Weakly Supervised learning framework (PSWS), designed for cancer subtype classification using WSIs, with a two-stage structure to enhance model efficiency. Specifically, it first presents a novel patch organization approach, distinct from the bag concept of traditional Multiple Instance Learning (MIL), called position-aware sets, as basic units for learning. Then, PSWS automatically selects subtype-specific features based on enhanced histological features and mutual-patch relations, mitigating the negative impact of unannotated negative regions. In the experiments, the superior performance of PSWS over representative MILs is validated through subtype classification tasks on both public datasets and our internally constructed dataset. Furthermore, class probabilities of position-aware sets and attention region visualizations demonstrate its post-hoc interpretability, assisting pathologists in locating suspicious areas.},
  archive      = {J_EAAI},
  author       = {Jiuman Song and Bo Yu and Xiaomin Liu and Lele Cong and Zilong Zhou and Xianling Cong and Hongyan Sun and Shuchao Pang and Hechang Chen},
  doi          = {10.1016/j.engappai.2025.111998},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111998},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A position-aware sets based weakly supervised framework for whole-slide subtype classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Action understanding in low-light and pitch-dark conditions: A comprehensive survey. <em>EAAI</em>, <em>161</em>, 111996. (<a href='https://doi.org/10.1016/j.engappai.2025.111996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action understanding in low-light and dark environments (AULLD) is a critical and technically demanding challenge at the intersection of computer vision and engineering applications. This task focuses on interpreting human actions using motion cues under visually constrained conditions, such as poor illumination or complete darkness. Since 2010, machine learning and, more notably, deep learning have significantly advanced AULLD by enabling systems to extract and learn discriminative features from complex, low-visibility data. These techniques have resulted in state-of-the-art solutions, with recent methods achieving accuracies on various benchmark datasets of up to 97.10%, and a 73.20% top-1 accuracy on an infrared dataset. These solutions have had applications across domains such as healthcare monitoring, surveillance and security, human–computer interaction, and social computing. In this survey, we provide the first comprehensive overview of the progress of the research and topical developments in AULLD. We cover a broad range of elements, including the datasets, evaluation protocols, methods, challenges, and emerging research directions. To organize and evaluate the literature in a structured, integrated way, we introduce a novel taxonomic framework, grounded in four core dimensions: body representation, temporal representation, feature representation, and neural architectures. Employing this taxonomy, we perform an analysis of AULLD approaches, exploring their methodological foundations, system design considerations, performance outcomes, and inherent trade-offs. The survey concludes with an in-depth discussion of the existing challenges confronting AULLD, highlighting several promising research directions that hold potential for advancing the field and setting the stage for future innovations and improvements in AULLD.},
  archive      = {J_EAAI},
  author       = {Muhammad Munsif and Samee Ullah Khan and Noman Khan and Altaf Hussain and Sung Wook Baik},
  doi          = {10.1016/j.engappai.2025.111996},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111996},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Action understanding in low-light and pitch-dark conditions: A comprehensive survey},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer learning framework integrating attention mechanism and domain adaptation for low earth orbit satellite network traffic prediction. <em>EAAI</em>, <em>161</em>, 111992. (<a href='https://doi.org/10.1016/j.engappai.2025.111992'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction is a crucial prerequisite for planning and even network security in Low Earth Orbit (LEO) satellite networks (LSNs). This paper designed a transfer learning framework for LSN traffic prediction that leverages attention mechanism and domain adaptation. Firstly, by integrating five-dimensional data including global population distribution, local time coefficient, the Internet penetration rate of the country, daily data volume of a single Internet user, and global aeronautical traffic demand, a traffic model that could characterize the traffic situation of the area covered by LEO satellite within a specific time range was constructed. Considering the problem of insufficient online traffic data, knowledge was transferred from terrestrial network traffic (source domain) to satellite network traffic (target domain) by incorporating the Domain-Adversarial Neural Network (DANN) method to tackle the data distribution discrepancies between the source and target domains. Finally, by combining DANN with the attention mechanism, the domain-invariant features of the source domain and the target domain were extracted to predict satellite network traffic accurately. Experimental results show that compared to baseline models, the error of the proposed framework in terms of root mean square error measurement is reduced by 9.57% to 33.47% and 18.85% to 38.99% in the two simulated LSN traffic scenarios. Moreover, this framework has low computational complexity among other transfer learning models, which can lay a foundation for subsequent satellite traffic planning and network security.},
  archive      = {J_EAAI},
  author       = {Yan Zhang and Yong Wang and Qingsong Zhao and Yadi Zhai and Zhi Lin and Luda Zhao and Yihua Hu},
  doi          = {10.1016/j.engappai.2025.111992},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111992},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transfer learning framework integrating attention mechanism and domain adaptation for low earth orbit satellite network traffic prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skeleton-based multi-person action recognition towards real-world violence detection. <em>EAAI</em>, <em>161</em>, 111987. (<a href='https://doi.org/10.1016/j.engappai.2025.111987'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action recognition is crucial in intelligent systems like robotics, healthcare, and surveillance, gaining significant attention with the rise of AI in computer vision. This work presents the Multi-Skeleton Action Recognizer (MSAR), a comprehensive multi-stage process specifically designed to enhance the recognition and classification of violent activities involving multiple individuals. The approach aims to improve accuracy and robustness in real violence detection and classification leveraging skeletal data. The proposed MSAR pipeline consists of five main stages: Human detection, Human tracking, Skeleton extraction, Data pre-processing and Padding, and Action classification. Experimental results demonstrate the effectiveness of our multi-stage process, showing significant improvements in multi-person action recognition in violence detection. In the human detection stage, our integration of multiple detection models provides a comprehensive visual comparison of model performance, offering empirical insights into accuracy, computational efficiency, and processing speed. The fusion Bidirectional Long Short-Term Memory - Gated Recurrent Unit (BiLSTM-GRU) architecture designed for action classification integrating Deep Bidirectional Long Short-Term Memory (BiLSTM) and Gated Recurrent Unit (GRU) components, demonstrated maximum accuracy of 96.46% and an average accuracy of 91.18%. The proposed architecture is explored to potentially enhance the model’s ability to capture temporal dependencies in action sequences. Additionally, our proposed multi-stage pipeline for action recognition exemplifies a modular, systematic approach, where each stage functions as an independent module is expanded, optimized, replaced without affecting others. This modularity enhances the flexibility, adaptability, scalability of the pipeline, providing a solid foundation for future advancements across various tasks, application domains.},
  archive      = {J_EAAI},
  author       = {Minh-Trieu Truong and Van-Dung Hoang},
  doi          = {10.1016/j.engappai.2025.111987},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111987},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Skeleton-based multi-person action recognition towards real-world violence detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Malware attack and defense game in fractional-order internet of underwater things: Model-based and model-free approaches. <em>EAAI</em>, <em>161</em>, 111970. (<a href='https://doi.org/10.1016/j.engappai.2025.111970'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the Internet of Underwater Things (IoUT), its cybersecurity faces increasingly severe challenges, as malware attacks have become a common and highly destructive threat. However, most existing studies rely on integer-order models or static defense mechanisms, which fail to capture the memory and hereditary properties of underwater malware propagation and lack adaptability in dynamic adversarial environments. To address this issue, this paper constructs a fractional-order propagation model and introduces differential game theory to investigate the dynamic interactions between malware and system defense, aiming to derive the optimal dynamic strategies and the corresponding Nash equilibrium for both parties. Furthermore, two innovative artificial intelligence strategy learning approaches are proposed: a model-based method and a model-free method, designed to approximate the optimal control strategies in the game. Extensive comparative experiments and simulation results demonstrate the effectiveness of the proposed methods in strategy learning. We further discuss the practical applications of these methods in IoUT as well as their scalability to other domains.},
  archive      = {J_EAAI},
  author       = {Guiyun Liu and Zulong Peng and Tingting Tan and Xiaojing Zhong and Zhongwei Liang},
  doi          = {10.1016/j.engappai.2025.111970},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111970},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Malware attack and defense game in fractional-order internet of underwater things: Model-based and model-free approaches},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised graph contrastive learning for emotion recognition based on electroencephalogram signals. <em>EAAI</em>, <em>161</em>, 111969. (<a href='https://doi.org/10.1016/j.engappai.2025.111969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition plays a crucial role in affective computing, aiming to identify and interpret human emotions. Since electroencephalography (EEG) measures brain electrical activity associated with emotional processing, its use in emotion recognition has garnered significant attention. However, due to the complexity of EEG, capturing the low-dimensional manifold structure from a high-dimensional EEG signal remains a challenge. Moreover, even though EEG labeling is expensive and requires specialization, the development of emotion recognition models has predominantly relied on labeled EEG datasets. To address these issues, we propose a semi-supervised graph contrastive learning (SGCL) model for EEG-based emotion recognition, leveraging the abundance of unlabeled EEG data to generate clearer representations. The proposed SGCL extracts two frequency-domain features from the EEG signal, differential entropy (DE) and power spectral density (PSD), which are integrated through a symmetric similarity network fusion (SSNF) with graph contrastive learning (GCL) to improve the generalization and representation capability of the graph convolutional network (GCN) to complex EEG data in transductive learning tasks. Extensive experimental results on three public datasets reveal that the proposed SGCL consistently outperforms state-of-the-art models. Notably, on the Shanghai Jiao Tong University EEG Emotion dataset (SEED), SGCL achieves an average accuracy of 99.99% using only 3.5% of the data as labeled input, setting a new benchmark in both effectiveness and efficiency. Further analyses confirm our model learns highly discriminative representations and offers insightful explanations, demonstrating its potential for robust emotion recognition.},
  archive      = {J_EAAI},
  author       = {Dae Hyeon Kim and Young-Seok Choi},
  doi          = {10.1016/j.engappai.2025.111969},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111969},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised graph contrastive learning for emotion recognition based on electroencephalogram signals},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable automated wild-orchid identification combining deep neural networks and bayesian networks. <em>EAAI</em>, <em>161</em>, 111961. (<a href='https://doi.org/10.1016/j.engappai.2025.111961'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been shown repeatedly to be a successful method of obtaining accurate classifiers. This also applies to orchid identification from digital photographs. However, deep neural networks possess the major weakness of lack of explainability, missing the ability to explain the reasons behind a decision. Nevertheless, most current research regarding automated orchid identification applies this blackbox approach. By contrast, in this paper we propose a new method for trustworthy automated orchid identification combining two complementary methods: deep neural networks and feature-based Bayesian networks, where the Bayesian network is also utilized for providing an explanation of the generated solutions. We use other deep neural networks to extract flower characteristics, the features, from the images which are subsequently fed into the Bayesian network as uncertain evidence. When combining the deep neural network and the Bayesian network as an ensemble classifier, both reaching the same conclusion, an accuracy of 89.4% is achieved, the most trustworthy outcome. With a human-in-the-loop ensemble classifier, validation results are even better, yielding an accuracy of 98.1%. Our approach also exploits the taxonomic knowledge represented in the Bayesian network to provide an explanation of the solutions for every case, reinforcing further trust in the method. The result is an explainable user-in-the-loop ensemble classifier. Providing explainability can help build user trust in a system and may play a major role when it is used as a learning aid for new orchid enthusiasts. Finally, the proposed method may be also of value in many fields other than plant determination.},
  archive      = {J_EAAI},
  author       = {Diah Harnoni Apriyanti and Luuk J. Spreeuwers and Peter J.F. Lucas},
  doi          = {10.1016/j.engappai.2025.111961},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111961},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable automated wild-orchid identification combining deep neural networks and bayesian networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A safe multi-agent reinforcement learning algorithm using constraint update projection approach. <em>EAAI</em>, <em>161</em>, 111929. (<a href='https://doi.org/10.1016/j.engappai.2025.111929'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional reinforcement learning has a major limitation, which is that they optimize agent’s policy purely for maximizing rewards. It completely ignore safety considerations. However, in certain critical engineering fields, ensuring safety is of utmost importance, otherwise it can cause incalculable losses. Therefore, this paper proposes a safe Multi-Agent Constrained Update Projection(MACUP) algorithm, which can safely control agents to complete tasks. We solve this problem from the perspective of policy constraint optimization. Firstly, we derive the new bounds of multi-agent policy performance difference based on a tighter general policy performance difference. It contains generalized advantage estimates, and we utilize these bounds as surrogate functions concerning the objective and constraints. Secondly, to address the coordination issue among multiple agents, we employ a multi-agent sequential policy update framework. Finally, we use a projection method to optimize policies, which has low computational complexity and does not require convex approximation of the surrogate function for solving. It can help us reduce errors. Finally, we have validated our algorithm in two different multi-agent safety environments, and the results show that it is able to satisfy safety constraints while achieving higher rewards.},
  archive      = {J_EAAI},
  author       = {Yang Liu and Xiang Feng and Huiqun Yu},
  doi          = {10.1016/j.engappai.2025.111929},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111929},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A safe multi-agent reinforcement learning algorithm using constraint update projection approach},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-criteria group decision-making method using spherical fuzzy Z-numbers for smart technology revolution in municipal waste management. <em>EAAI</em>, <em>161</em>, 111928. (<a href='https://doi.org/10.1016/j.engappai.2025.111928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the new phenomenon of globalization and the fast growing cities, there is drastic pressure on the conventional methods of waste management hence the need for innovative management wastage that is proactive to the theme of environmental and economic challenge of the modern world. This paper aims at investigating the following research question: How has the introduction of smart technologies impacted waste management in the context of a mid-sized city that is in the cross-road of generating more wastes while at the same time, concerns over ecological attainability. They present a new type of Spherical Fuzzy Z-Number Sets in organizational environments dealing with multi criteria group decision making where it possess higher order of uncertainty than conventional fuzzy sets. For handling the multi facility nature of multi criteria group decision making in waste management, we propose the so-called Additive Ratio Assessment method when the attribute weights are unknown. To ensure that the criteria weights are determined objectively in this research, the CRITIC (CRiteria Importance Through Intercriteria Correlation) technique is used. The first part of the study provides a theoretical framework of spherical fuzzy Z-numbers concerning accuracy, scoring functions, and operations. Then we introduce this framework to actual multi criteria group decision making cases in municipal waste management to show that how Spherical Fuzzy Z-Number can facilitate decision-making processes by dealing with the vagueness and fuzziness of stakeholder preferences. The TODIM (Tomada de Decisao Iterativa Multicriterio) technique is used in this to validate and compare for efficiency of the proposed additive ratio assessment method. Besides, this research will not only enhance the theoretical aspect of fuzzy decision making but also present a feasible and effective framework for handling unsound and random decision making problems especially within the context of urban waste management.},
  archive      = {J_EAAI},
  author       = {Shahzaib Ashraf and Muhammad Naeem and Chiranjibe Jana and Maria Akram and Gerhard-Wilhelm Weber},
  doi          = {10.1016/j.engappai.2025.111928},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111928},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-criteria group decision-making method using spherical fuzzy Z-numbers for smart technology revolution in municipal waste management},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From image processing to artificial intelligence-driven tools: A comprehensive survey on the evolution of feature extraction methods in paintings. <em>EAAI</em>, <em>161</em>, 111794. (<a href='https://doi.org/10.1016/j.engappai.2025.111794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the computational process of converting qualitative elements of paintings, such as shape, color, texture, and line, into quantitative numerical values, which aid in identifying and extracting features from painting images. These identified features are then used to classify paintings based on artist, art style, genre, and art movements. This review employs a systematic literature review methodology, examining approximately 80 research papers to track trends in this field from 2015 to 2025. With the increasing presence of paintings in online media, museums, and galleries, artificial intelligence (AI) plays a significant role in interpreting these subjective elements. This review examines various image processing techniques in conjunction with AI implementations to extract the local and global features of a painting. These methods are combined with AI models, such as deep learning and computer vision algorithms, to improve feature extraction and provide a more thorough and accurate paintings analysis.},
  archive      = {J_EAAI},
  author       = {Rekha Sharma and Rishi Gupta and Aditya Sinha},
  doi          = {10.1016/j.engappai.2025.111794},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111794},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {From image processing to artificial intelligence-driven tools: A comprehensive survey on the evolution of feature extraction methods in paintings},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
