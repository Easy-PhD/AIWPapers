<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EJOR</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ejor">EJOR - 25</h2>
<ul>
<li><details>
<summary>
(2026). Dynamic mode decomposition for online portfolio selection task. <em>EJOR</em>, <em>328</em>(1), 349-365. (<a href='https://doi.org/10.1016/j.ejor.2025.04.049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online portfolio selection (OPS) is a complex task aimed at maximizing investment returns through strategic allocation of capital among risky assets. Traditional Follow the Winner (FTW) strategies, grounded in the Best Constant Rebalanced Portfolios strategy, assume market is independent and identically distributed (i.i.d.), which often fails to capture real-world financial market dynamics, leading to sub-optimal performance in practical applications. To address this limitation, we propose integrating Dynamic Mode Decomposition (DMD) into FTW strategies. DMD is a powerful data-driven technique that originated in the field of fluid dynamics. It is designed to extract coherent structures and identify temporal patterns within complex data. By applying DMD to financial market data, we can uncover underlying patterns and trends that are not apparent under the i.i.d. assumption. Significantly, the integrated DMD in this paper allows for efficient recursion, which is particularly crucial for OPS task. To illustrate the effectiveness of the proposed idea, we consider the Exponential Gradient (EG) strategy as an example and proposed Exponential Gradient with Dynamic Mode Decomposition (EGDMD). The results demonstrate that the proposed EGDMD outperforms traditional EG-type strategies, significantly improves risk-adjusted returns, and maintains computational efficiency. The integration of DMD allows for more accurate identification of market patterns, leading to more effective investment decisions and enhanced portfolio performance.},
  archive      = {J_EJOR},
  author       = {Jiahao Li and Yong Zhang and Xiaoteng Zheng},
  doi          = {10.1016/j.ejor.2025.04.049},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {349-365},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic mode decomposition for online portfolio selection task},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Choice-based crowdshipping for next-day delivery services: A dynamic task display problem. <em>EJOR</em>, <em>328</em>(1), 336-348. (<a href='https://doi.org/10.1016/j.ejor.2025.05.046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies integrating the crowd workforce into next-day home delivery services. In this setting, both crowd drivers and contract drivers collaborate in making deliveries. Crowd drivers have limited capacity and can choose not to deliver if the presented tasks do not align with their preferences. The central question addressed is: How can the platform minimize the total task fulfilment cost, which includes payouts to crowd drivers and additional payouts to contract drivers for delivering the unselected tasks by customizing task displays to crowd drivers? To tackle this problem, we formulate it as a finite-horizon Stochastic Decision Problem, capturing crowd drivers’ utility-driven task preferences, with the option of not choosing a task based on the displayed options. An inherent challenge is approximating the non-constant marginal cost of serving orders not chosen by crowd drivers, which are then assigned to contract drivers. We address this by leveraging a common approximation technique, dividing the service region into zones. Furthermore, we devise a stochastic look-ahead strategy that tackles the curse of dimensionality issues arising in dynamic task display execution and a non-linear (problem specifically concave) boundary condition associated with the cost of hiring contract drivers. In experiments inspired by Singapore’s geography, we demonstrate that choice-based crowd shipping can reduce next-day delivery fulfilment costs by up to 16.9%. The observed cost savings are closely tied to the task display policies and the task choice behaviours of drivers.},
  archive      = {J_EJOR},
  author       = {Alp Arslan and Fırat Kılcı and Shih-Fen Cheng and Archan Misra},
  doi          = {10.1016/j.ejor.2025.05.046},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {336-348},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Choice-based crowdshipping for next-day delivery services: A dynamic task display problem},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). When cost metafrontiers are nonconvex in the outputs, then the production metafrontier is nonconvex: The price of a convexification strategy. <em>EJOR</em>, <em>328</em>(1), 324-335. (<a href='https://doi.org/10.1016/j.ejor.2025.05.048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metafrontier analysis is widely used to account for technological heterogeneity among producers. The approach involves combining a number of group-specific production possibilities sets to form a production possibilities metaset. Even though the union of the group sets normally results in a nonconvex metaset, most authors proceed as if this metaset is convex. Kerstens, O’Donnell and Van de Woestyne (2019) obtain new results on the union operator on sets under various assumptions and empirically illustrate that the popular convexification strategy is highly questionable. In this paper we transpose their results on the union operator from a production to a cost context: this is new. We then explore the extent to which convexity of the cost function is corroborated using a newly developed test. Furthermore, we check to which extent a convexification strategy is tenable when estimating a cost metafrontier. We use an original banking data set from China and the USA to illustrate the main issues. We establish that the cost function is not convex in the outputs for China and that the convexification strategy leads to potentially-biased estimates of the cost metafrontier and associated measures of efficiency.},
  archive      = {J_EJOR},
  author       = {Kristiaan Kerstens and Christopher O’Donnell and Ignace Van de Woestyne and Shirong Zhao},
  doi          = {10.1016/j.ejor.2025.05.048},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {324-335},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {When cost metafrontiers are nonconvex in the outputs, then the production metafrontier is nonconvex: The price of a convexification strategy},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mitigating adversarial attacks on transformer models in credit scoring. <em>EJOR</em>, <em>328</em>(1), 309-323. (<a href='https://doi.org/10.1016/j.ejor.2025.05.029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of unstructured data, such as text created by borrowers, offers new opportunities for improving credit default prediction but also introduces new risks. This study examines the robustness of transformer-based credit scoring models that utilize textual data and assesses their vulnerability to adversarial attacks. Using peer-to-peer lending data, we show that small, semantically neutral changes in loan descriptions can substantially alter model outputs. These vulnerabilities expose lenders and borrowers to economic risks through distorted risk assessments and mispriced loans. We evaluate two mitigation strategies: adversarial training and topic modeling. Adversarial training improves robustness without compromising predictive performance. Topic modeling provides a more interpretable and stable representation of borrower narratives. An economic analysis confirms that robust models reduce mispricing and improve outcomes for all parties. The findings underscore the importance of robustness as the use of unstructured data in credit scoring becomes more accessible.},
  archive      = {J_EJOR},
  author       = {Brandon Schwab and Johannes Kriebel},
  doi          = {10.1016/j.ejor.2025.05.029},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {309-323},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mitigating adversarial attacks on transformer models in credit scoring},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cost-sensitive single-index classification model. <em>EJOR</em>, <em>328</em>(1), 295-308. (<a href='https://doi.org/10.1016/j.ejor.2025.08.058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-index models (SIMs) are a type of semiparametric model in which a response variable is assumed to be related to a linear combination of explanatory variables by an unknown function, on which any restriction is imposed. Thus, they provide both interpretability and flexibility to capture complex data relationships. In this paper, SIMs are extended to the cost-sensitive classification problem by minimizing the different misclassification costs. The flexibility of SIMs combined with a cost-sensitive approach results in a powerful model to minimize losses and optimize decision making. This is demonstrated through an extensive simulation study and the analysis of five real data sets, where the proposed approach outperforms both parametric and semi-parametric previous approaches.},
  archive      = {J_EJOR},
  author       = {Jorge C-Rella and Ricardo Cao and Juan M. Vilar},
  doi          = {10.1016/j.ejor.2025.08.058},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {295-308},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cost-sensitive single-index classification model},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Diverse ensemble cost-sensitive logistic regression. <em>EJOR</em>, <em>328</em>(1), 282-294. (<a href='https://doi.org/10.1016/j.ejor.2025.07.028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, cost-sensitive methods have become increasingly crucial for decision-making in various real-world applications. These methods have been developed for the purpose of minimizing costs or risks for stakeholders. Moreover, the interpretability of cost-sensitive methods has gained considerable attention in critical domains such as finance and medical care. In this article, we propose a diverse ensemble of cost-sensitive logistic regression models to reduce costs for binary classification tasks, as well as a novel algorithm based on the partial conservative convex separable quadratic approximation to solve this non-convex optimization problem. The proposed method demonstrates substantial cost savings through extensive simulations and real-world applications, including fraud detection and gene expression analysis. Additionally, unlike other ensembling techniques, the resulting model of the proposed method is fully interpretable as a logistic regression model and achieves a high level of sparsity induced by the proposed algorithm. We believe this approach offers deeper insights into the relationship between predictors and response, enabling more informed decision-making in practical scenarios.},
  archive      = {J_EJOR},
  author       = {Bing Yang and Stefan Van Aelst and Tim Verdonck},
  doi          = {10.1016/j.ejor.2025.07.028},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {282-294},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Diverse ensemble cost-sensitive logistic regression},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view ensemble feature selection via SemiDefinite programming. <em>EJOR</em>, <em>328</em>(1), 269-281. (<a href='https://doi.org/10.1016/j.ejor.2025.07.014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning faces significant challenges in selecting discriminative features while managing redundancy and noise across heterogeneous data sources. To address these issues, this paper introduces Multi-view Ensemble Feature Selection (MEFS), a novel framework that systematically integrates view generation (VG) and view selection (VS) through a unified optimization paradigm. By reformulating feature selection as a MaxCut problem and leveraging SemiDefinite Programming (SDP) relaxation, MEFS dynamically balances the generalization capability of individual views with their pairwise diversity, eliminating the need for manual parameter tuning. A key innovation is the proposed pairwise diversity metric, which quantifies inter-view dissimilarity using between-class scatter matrices to ensure complementary feature subsets. Extensive experiments on ten benchmark datasets demonstrate that MEFS consistently outperforms state-of-the-art methods in accuracy, robustness, and computational efficiency. Ablation studies validate the synergistic effect of combining VG and VS modules.},
  archive      = {J_EJOR},
  author       = {Xiaojian Ding and Xin Wang and Pengcheng Shi},
  doi          = {10.1016/j.ejor.2025.07.014},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {269-281},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-view ensemble feature selection via SemiDefinite programming},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the price of diversity for multiwinner elections under (weakly) separable scoring rules. <em>EJOR</em>, <em>328</em>(1), 258-268. (<a href='https://doi.org/10.1016/j.ejor.2025.06.013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a model of multi-winner elections, where each voter expresses a linear preference over a finite set of alternatives. Based on voters’ preferences, the primary goal is to select a subset of admissible alternatives, forming what is referred to as a committee. We explore (weakly) separable committee scoring rules, the voting mechanisms that assess each alternative individually using a scoring vector and select the top k alternatives, where k represents the committee’s size. Furthermore, we operate under the assumption that alternatives are categorized based on specific attributes. Within each attribute category, there exists a targeted minimum number of alternatives that the selected committee should encompass, emphasizing the necessity for diversity. In this context, we assess the cost associated with imposing such a diversity constraint on the voting process. This assessment is conducted through two methodologies, referred to as the “price of diversity” and the “individual price of diversity”. We set the upper bounds for both prices across all (weakly) separable committee scoring rules. Additionally, we show how the maximum price of diversity can be used to discriminate between different voting rules in this context. Ultimately, we illustrate that concentrating on the candidates’ performance yields a more accurate estimation of the price of diversity compared to a focus on the enforced diversity constraint.},
  archive      = {J_EJOR},
  author       = {Mostapha Diss and Clinton Gubong Gassi and Eric Kamwa},
  doi          = {10.1016/j.ejor.2025.06.013},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {258-268},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the price of diversity for multiwinner elections under (weakly) separable scoring rules},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nonconvex truncated conditional value at risk-based sparse linear regression. <em>EJOR</em>, <em>328</em>(1), 246-257. (<a href='https://doi.org/10.1016/j.ejor.2025.06.004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional value at risk (CVaR) is a widely recognized risk measure used to manage data uncertainty within risk management. In this paper, we study a class of sparse linear regression models based on truncated CVaR measure and ℓ 0 -norm regularization. Due to the nonconvexity and nonsmoothness of the objective functions, as well as the NP-hardness of the problem with the ℓ 0 -norm regularization, we propose an approximation model that employs a tight relaxation of the ℓ 0 -norm. The solution equivalence between the proposed model and its approximation model is explored. To efficiently solve the approximation model, we develop a semismooth Newton-based proximal majorization-minimization algorithm. Furthermore, the convergence analysis of the proposed algorithm is presented, and the convergence rate for the reduced CVaR-based sparse linear regression model is established. Moreover, extensive numerical experiments conducted on both synthetic and real datasets validate the stability and effectiveness of the proposed algorithm, demonstrating significant improvements in both sparsity and accuracy compared to existing state-of-the-art methods.},
  archive      = {J_EJOR},
  author       = {Boyi Xie and Zhongming Wu and Min Li},
  doi          = {10.1016/j.ejor.2025.06.004},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {246-257},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nonconvex truncated conditional value at risk-based sparse linear regression},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Designing and computing explanations for comparisons inferred from an additive value model. <em>EJOR</em>, <em>328</em>(1), 232-245. (<a href='https://doi.org/10.1016/j.ejor.2025.05.058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many decision models are based on an additive representation of preferences. Recommendations obtained from such additive decision models are sometimes considered as self-evident. On the contrary, we claim that these recommendations deserve an explanation so as to be fully understood by the user/decision-maker and to foster her trust. We propose to explain a preference statement x preferred to y by decomposing this statement into simpler ones. Arguments in favor of x (Pros), and arguments in favor of y (Cons) are decomposed using a covering scheme in which each Con is covered by a Pro. We use a decomposition language in which elementary self-evident statements involve ( i ) one Pro against one Con, ( ii ) one pro against several Cons, or ( iii ) several Pros against one Con. We prove that computing such explanations is computationally difficult in case ( ii ) and ( iii ), and propose a mathematical programming formulation to solve it. Numerical experiments provide insights on the actual behavior of our algorithm. We also illustrate the usefulness of our approach in the context of multicriteria decision aid but also for machine learning approaches.},
  archive      = {J_EJOR},
  author       = {Manuel Amoussou and Khaled Belahcene and Nicolas Maudet and Vincent Mousseau and Wassila Ouerdane},
  doi          = {10.1016/j.ejor.2025.05.058},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {232-245},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Designing and computing explanations for comparisons inferred from an additive value model},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bayesian variable selection in kriging metamodeling for quality design. <em>EJOR</em>, <em>328</em>(1), 216-231. (<a href='https://doi.org/10.1016/j.ejor.2025.06.003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity of production processes and rapid developments in digital technology have fueled the adoption of metamodels in quality design. Kriging has emerged as one of the most popular emulation methods for both deterministic and stochastic simulations. Conventional Kriging models with predetermined mean functions, such as ordinary or universal Kriging, may exhibit subpar predictive performance when strong trends exist. This paper proposes a novel variable selection procedure for the mean function that ensures prediction accuracy while using only a limited number of variables to capture the potential existing trends in deterministic simulations. The proposed method integrates the benefits of Bayesian variable selection and frequentist statistical tests. Initially, a group of potential models is chosen to build the mean function, employing the Bayesian method with priors designed to guarantee sparsity. This results in a significant reduction in the number of models to be considered in the next stage. Subsequently, each candidate model undergoes rigorous frequentist tests to thoroughly assess its reliability and validity. Extensive simulation studies are conducted using the well-known Borehole function and a real-life case. The results demonstrate the superiority of the proposed method over several existing approaches, establishing its effectiveness in achieving robust parameter design.},
  archive      = {J_EJOR},
  author       = {Baoping Tao and Zifei Han and Wen Shi and Min Wang and Linhan Ouyang},
  doi          = {10.1016/j.ejor.2025.06.003},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {216-231},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bayesian variable selection in kriging metamodeling for quality design},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Design and pricing of extended warranty menus with reference effects. <em>EJOR</em>, <em>328</em>(1), 201-215. (<a href='https://doi.org/10.1016/j.ejor.2025.05.056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumer durables increasingly come with extended warranty menus—beyond manufacturers’ base warranties—that offer multiple options with differentiated protection lengths and prices. When choosing from an extended warranty menu, consumers might not only evaluate the intrinsic utility of each option but also form a reference point against which the available options are compared. In this paper, we posit that consumers compare the price-length ratios of available options when determining their willingness to pay, and investigate the design and pricing of extended warranty menus under such reference effects. To this end, we adapt the standard multinomial logit choice model to incorporate two types of reference point that are generated endogenously and exogenously, respectively, with respect to the given menu. We show that if the warranty options are ordered in the protection length, then the optimal pricing policies prescribe the same adjusted markup and the same price-length ratio alternately. We further extend our analysis to price competition under reference effects, where multiple firms compete in the aftermarket, each offering a single extended warranty. We prove the existence of a unique Nash equilibrium and develop an efficient method to identify it. Numerical examples are presented to illustrate the analytical findings, and sensitivity analyses are conducted to examine the impact of reference-effect coefficients on the optimal pricing policies. Overall, this work highlights the importance of incorporating reference effects into the design and pricing of extended warranty menus.},
  archive      = {J_EJOR},
  author       = {Xiao-Lin Wang and Chenglong Li and Junjie Wang},
  doi          = {10.1016/j.ejor.2025.05.056},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {201-215},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Design and pricing of extended warranty menus with reference effects},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Planning bayesian reliability demonstration tests via a generalized test statistic. <em>EJOR</em>, <em>328</em>(1), 189-200. (<a href='https://doi.org/10.1016/j.ejor.2025.08.011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability demonstration testing (RDT) has been extensively employed to verify whether a product meets specific reliability requirements at a desired confidence level. Driven by intense market competition and constrained test resources, manufacturers are motivated to seek effective strategies to reduce the testing efforts required for RDT. In this paper, we propose a method that utilizes existing knowledge and information obtained from the product design and development phase to construct a Bayesian prior distribution of the product’s reliability. Based on this prior, a preliminary disposition decision on whether to accept or reject the product is made. A subsequent demonstration test is needed only when the prior information is deemed insufficient for an immediate disposition. A RDT planning method is developed based on the posterior distribution of the product’s reliability, which is applicable to general cases involving non-conjugate priors. We study two types of demonstration testing: binomial and exponential. For each, we prove the existence of an optimal test plan and develop an efficient searching algorithm to determine it. Numerical studies are conducted to demonstrate the effectiveness of the proposed method, supplemented by a case study on RDT for systems of different configurations. Overall, this work provides a unified and effective framework for reliability demonstration under the Bayesian paradigm.},
  archive      = {J_EJOR},
  author       = {Zan Li and Jianyu Xu and Chengjie Wang and Xiao-Lin Wang},
  doi          = {10.1016/j.ejor.2025.08.011},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {189-200},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Planning bayesian reliability demonstration tests via a generalized test statistic},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A primal–dual policy iteration algorithm for constrained markov decision processes. <em>EJOR</em>, <em>328</em>(1), 174-188. (<a href='https://doi.org/10.1016/j.ejor.2025.08.038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The solution algorithms of Constrained Markov Decision Process (CMDP), a widely adopted model for sequential decision-making, have been intensively studied in the literature. Despite increasing effort, the Linear Programming (LP) formulation of CMDP remains the dominant exact method that leads to the optimal solution without constraint violations. However, the LP formulation is computationally inefficient due to the curse of dimensionality in CMDP state and action spaces. In this study, we introduce a novel policy iteration method for CMDP, based on decomposition and row-generation techniques. We design a Primal–Dual Policy Iteration (PDPI) algorithm that utilizes state values and Lagrangian multipliers to improve randomized stationary policies in an iterative fashion. We analytically show that upon convergence, PDPI produces the optimal solution for CMDP. An upper bound of the convergence iterations is also given. To validate the algorithm performance, we conduct comprehensive computational experiments on six benchmarking problems curated from the literature. Results show that PDPI outperforms conventional methods considerably, improving the total algorithm runtime by up to 89.19%. The improvement becomes more significant as the problem size grows larger. We further provide insights and discuss the impact of the developed method.},
  archive      = {J_EJOR},
  author       = {Zeyu Liu and Xueping Li and Anahita Khojandi},
  doi          = {10.1016/j.ejor.2025.08.038},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {174-188},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A primal–dual policy iteration algorithm for constrained markov decision processes},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Controlling antithetic variates. <em>EJOR</em>, <em>328</em>(1), 162-173. (<a href='https://doi.org/10.1016/j.ejor.2025.08.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish and investigate a theoretical framework for controlling covariance matrices in the method of antithetic variates through control variates to further reduce estimator variance. Instead of preemptively and carefully designing an estimator vector with negatively correlated components, the proposed framework starts with a predefined estimator vector that incorporates specified control variates. The weights and control matrix are then analytically determined through matrix algebra. The joint optimality of the resulting estimator variance is ensured with respect to both the weights and the control matrix, with closed-form implementable formulas derived for the optimal parameter pair. Numerical results are provided for various typical examples to illustrate the effectiveness, potential, and challenges of the proposed framework.},
  archive      = {J_EJOR},
  author       = {Reiichiro Kawai},
  doi          = {10.1016/j.ejor.2025.08.027},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {162-173},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Controlling antithetic variates},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust multi-period blood inventory routing under multiple uncertainties. <em>EJOR</em>, <em>328</em>(1), 137-161. (<a href='https://doi.org/10.1016/j.ejor.2025.05.036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a multi-period blood inventory routing problem that integrates production, inventory, and distribution decisions under uncertainties in demand, donation supply, and travel times, all while accounting for the limited shelf life of blood products. Our model captures transportation efficiency through a disutility measure based on vehicles’ arrival times at hospitals, and addresses supply–demand imbalances by allowing selective rejection of service requests at a high penalty cost. We formulate a robust optimization model that simultaneously determines production quantities, inventory levels, hospital service selections, and vehicle routing for each period. The objective is to minimize the total cost over the planning horizon, which includes worst-case inventory holding, wastage, and transportation costs, unserved demand penalties, and overall transportation disutility. To obtain an exact solution, we propose an integrated algorithm within the L -shaped framework that combines Benders decomposition with a branch-and-price-and-cut (BPC) scheme. This approach decomposes the robust model into a master problem and period-specific subproblems. For a given master solution, we first use constraint programming to verify the feasibility of the subproblems, and then, if feasible, solve them with a tailored BPC algorithm to generate Benders cuts that eliminate suboptimal master solutions. Extensive numerical experiments, including a case study at the Blood Center in Chongqing, demonstrate the effectiveness of our approach. Our analysis quantifies the benefits of incorporating uncertainty and robustness while providing managerial insights through a systematic evaluation of various parameters.},
  archive      = {J_EJOR},
  author       = {Ling Qing and Yunqiang Yin and Joshua Ignatius and Dujuan Wang},
  doi          = {10.1016/j.ejor.2025.05.036},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {137-161},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust multi-period blood inventory routing under multiple uncertainties},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-driven joint optimization of maintenance and spare parts provisioning: A distributionally robust approach. <em>EJOR</em>, <em>328</em>(1), 122-136. (<a href='https://doi.org/10.1016/j.ejor.2025.06.025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the joint optimization of condition-based maintenance and spare provisioning, incorporating insights obtained from sensor data. Prognostic models estimate components’ remaining lifetime distributions (RLDs), which are integrated into an optimization model to coordinate maintenance and spare provisioning. The existing literature addressing this problem assumes that prognostic models provide accurate estimates of RLDs, thereby allowing a direct adoption of Stochastic Programming or Markov Decision Process methodologies. Nevertheless, this assumption often does not hold in practice since the estimated distributions can be inaccurate due to noisy sensors or scarcity of training data. To tackle this issue, we develop a Distributionally Robust Chance Constrained (DRCC) formulation considering general discrepancy-based ambiguity sets that capture potential distribution perturbations of the estimated RLDs. The proposed formulation admits a Mixed-Integer Linear Programming (MILP) reformulation, where explicit formulas are provided to simplify the general discrepancy-based ambiguity sets. Finally, for the numerical illustration, we test a type- ∞ Wasserstein ambiguity set and derive closed-form expressions for the parameters of the MILP reformulation. The efficacy of our methodology is showcased in a wind turbine case study, where the proposed DRCC formulation outperforms other benchmarks based on stochastic programming and robust optimization.},
  archive      = {J_EJOR},
  author       = {Heraldo Rozas and Weijun Xie and Nagi Gebraeel and Stephen Robinson},
  doi          = {10.1016/j.ejor.2025.06.025},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {122-136},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Data-driven joint optimization of maintenance and spare parts provisioning: A distributionally robust approach},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards blockchain-enabled circular closed-loop supply chain and impact of consumers’ distrust in price, product greenness sensitivity and carbon tax and subsidy. <em>EJOR</em>, <em>328</em>(1), 105-121. (<a href='https://doi.org/10.1016/j.ejor.2025.06.030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing emphasis on environmental sustainability, both governments and consumers are more concerned than ever about the greenness of products. In this complex landscape, Supply Chains (SCs) face challenges in building trust and avoiding greenwashing accusations. Blockchain technology offers a promising solution by ensuring transparency and circularity within SCs, particularly in identifying customers for product recycling. This study pioneers the exploration of consumers' distrust in pricing and product greenness, alongside the impact of carbon policies (taxes and subsidies) within a closed-loop supply chain (CLSC). Using classical Stackelberg game theory, we develop two models that identify equilibrium decisions for SC members, focusing on pricing, green production investment, circularity, and blockchain adoption. Additionally, we propose an evolutionary game theory model to find the optimal government policies and identify the long-term behaviour of the CLSC and government in two heterogeneous populations. Our findings reveal that if the retailer's share of blockchain costs falls below a certain threshold, blockchain adoption becomes less profitable than exclusive investment in green production. A higher (lower) subsidy rate benefits (harms) the retailer but disadvantages (benefits) the collector. Blockchain adoption is generally more profitable for manufacturers and retailers, though less so for collectors, and it also drives greater investment in green production. While subsidies encourage blockchain adoption, they are not a sustainable long-term strategy for governments. Ultimately, the evolutionarily stable strategy for SCs involves a balanced investment in both green production and blockchain or green production alone, depending on market characteristics and cost-sharing structures.},
  archive      = {J_EJOR},
  author       = {Mohammad Akbarzadeh Sarabi and Ata Allah Taleizadeh and Arijit Bhattacharya},
  doi          = {10.1016/j.ejor.2025.06.030},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {105-121},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Towards blockchain-enabled circular closed-loop supply chain and impact of consumers’ distrust in price, product greenness sensitivity and carbon tax and subsidy},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A split-embedded metaheuristic for the heterogeneous inventory routing problem with batch size. <em>EJOR</em>, <em>328</em>(1), 91-104. (<a href='https://doi.org/10.1016/j.ejor.2025.05.044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handling transportation and inventory management simultaneously is a challenging problem. The most famous optimization problem in this domain, known as the Inventory Routing Problem (IRP), aims to determine the routes and quantities to be delivered by a set of vehicles to meet customer demands at a minimum total inventory and transportation cost. The vast majority of works carried out so far on the IRP consider a homogeneous fleet of vehicles. This paper addresses, instead, a new IRP variant that considers intrinsic characteristics of real supply chains, such as a period-dependent heterogeneous fleet of vehicles and batch sizes for the delivered quantities. We model the problem with a Mixed Integer Linear Programming (MILP) formulation and propose a Split-Embedded Metaheuristic with a Post-Optimization phase (SEMPO) to solve it. Extensive computational experiments are conducted on a set of 80 new benchmark instances with up to 183 customers and a challenging time horizon of up 7 to 28 time periods to evaluate the performance of our approaches. The proposed SEMPO algorithm provides high-quality solutions and faster convergence compared to the MILP formulation.},
  archive      = {J_EJOR},
  author       = {Diego Perdigão Martino and Philippe Lacomme and Katyanne Farias},
  doi          = {10.1016/j.ejor.2025.05.044},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {91-104},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A split-embedded metaheuristic for the heterogeneous inventory routing problem with batch size},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The role of scarcity behavior in inventory management. <em>EJOR</em>, <em>328</em>(1), 78-90. (<a href='https://doi.org/10.1016/j.ejor.2025.05.043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A well-known phenomenon related to inventory, but often neglected in inventory management, is the scarcity effect, i.e., the increase in the demand if inventory is low. We consider a repeated purchase setting with a single firm and multiple buyers and address the question of whether inventory management decisions concerning the control policy and the service configuration (determining when and how much to order) impact scarcity behavior arising from buyers’ stock-out perception. We study common inventory control policies that assume a demand independent of the inventory management, and we challenge this critical assumption of an exogenous demand. This research explores two prevalent classes of inventory policies widely used in practice (periodic and continuous) configured according to fill rates, a popular way of measuring service. We conduct a laboratory experiment with four automated inventory management treatments (2 policies × 2 configurations) where participants act as buyers. We observe stock-out induced scarcity and find support for the hypothesis that the periodic policy leads to a stronger effect compared to the continuous policy if the service level is low. The study also supports the hypothesis that buyers act forward-looking as their demand peaks before the inventory reaches its lowest level. Overall, our research provides a new perspective on inventory management as it reveals that the chosen control policy and the selected service configuration influence stock-out pressure induced inventory runs. Inventory managers should be aware of scarcity effects and its consequences, like the disadvantages of a periodic policy for low service level.},
  archive      = {J_EJOR},
  author       = {Sebastian Schiffels and Christian Jost},
  doi          = {10.1016/j.ejor.2025.05.043},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {78-90},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The role of scarcity behavior in inventory management},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Green scheduling with time-of-use tariffs and machine states: Optimizing energy cost via branch-and-bound and bin packing strategies. <em>EJOR</em>, <em>328</em>(1), 64-77. (<a href='https://doi.org/10.1016/j.ejor.2025.06.026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a branch-and-bound algorithm, enhanced with bin packing strategies, for scheduling under variable energy pricing and power-saving states. The proposed algorithm addresses the 1 , TOU | states | TEC problem, which involves scheduling jobs to minimize total energy cost (TEC) while considering time-of-use (TOU) electricity prices and different machine states (e.g., processing, idle, off). Key innovations include instance pre-processing for rapid lower bound calculations, a novel branching scheme combined with initializations, a block-finding primal heuristic, and a tighter lower bound for jobs with non-coprime processing times. These enhancements result in an efficient algorithm capable of solving benchmark instances with real energy prices with 200 jobs more than 100 times faster than existing state-of-the-art methods.},
  archive      = {J_EJOR},
  author       = {Ondřej Benedikt and István Módos and Antonin Novak and Zdeněk Hanzálek},
  doi          = {10.1016/j.ejor.2025.06.026},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {64-77},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Green scheduling with time-of-use tariffs and machine states: Optimizing energy cost via branch-and-bound and bin packing strategies},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Flight test scheduling: A generic model, lower bounds, and iterated local search. <em>EJOR</em>, <em>328</em>(1), 49-63. (<a href='https://doi.org/10.1016/j.ejor.2025.06.001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flight tests play a critical role in the R&D process for new aircraft as they help verify the airworthiness and capabilities and expose design and manufacturing defects. During the test course, a large number of tasks need to be scheduled appropriately so that the flight tests can be completed with minimum cost and high efficiency. Therefore, there is a strong need for developing an efficient method that can generate high-quality test schedules. In this paper, we study flight test scheduling to minimize the number of required test flights, thereby decreasing the cost and time required during the entire test course. We establish a mixed-integer programming model to formally describe the problem, propose several computationally efficient lower bounds to help verify the quality of obtained solutions, and develop an iterated local search algorithm for generating a high-quality solution in an effective manner. Comprehensive computational experiments are performed to demonstrate the efficiency of our proposed algorithm. We report some general managerial insights based on the obtained computational results.},
  archive      = {J_EJOR},
  author       = {Hanqiao Tao and Guopeng Song and Roel Leus and Zhe Liang and Jiang Jiang},
  doi          = {10.1016/j.ejor.2025.06.001},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {49-63},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Flight test scheduling: A generic model, lower bounds, and iterated local search},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nested logic-based benders decomposition for an integrated home healthcare problem. <em>EJOR</em>, <em>328</em>(1), 32-48. (<a href='https://doi.org/10.1016/j.ejor.2025.06.006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we apply nested logic-based Benders decomposition to solve an integrated home healthcare staffing, assignment, routing, and scheduling problem with application in Norway. The proposed method operates at two decomposition levels. Consequently, the entire problem is decomposed into three hierarchical sub-problems: the staffing problem, the assignment problem, and the routing and scheduling problem. These sub-problems are interrelated through two levels of logic-based Benders cuts. Computational experiments on 40 test instances demonstrate the superior performance of nested logic-based Benders decomposition compared to directly solving a mixed-integer linear programming model available in the literature. Specifically, the proposed solution method achieved proven optimality in 28 instances and provided feasible solutions for the remaining 12 instances. In contrast, directly solving the mixed-integer linear programming model yielded proven optimality in 16 instances, provided feasible solutions for 20 instances, and failed to find feasible solutions for 4 instances within the same computational time limit.},
  archive      = {J_EJOR},
  author       = {Abdalrahman Algendi and Sebastián Urrutia and Lars Magnus Hvattum and Rafael A. Melo},
  doi          = {10.1016/j.ejor.2025.06.006},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {32-48},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nested logic-based benders decomposition for an integrated home healthcare problem},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A reduction approach for the parallel machine scheduling problem with a separate server for loading and unloading operations. <em>EJOR</em>, <em>328</em>(1), 15-31. (<a href='https://doi.org/10.1016/j.ejor.2025.05.030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the non-preemptive identical parallel machine scheduling problem with a dedicated loading server and a dedicated unloading server. Each job has to be loaded by the dedicated loading server immediately before being processed on one of the identical parallel machines, and unloaded immediately by the dedicated unloading server after its processing. The objective function involves the minimization of the makespan. This problem arises in the semiconductor industry, plastic injection industry, kitchen production systems, healthcare, container terminals, and many other industrial fields. We prove the problem to be strongly NP-hard, analyze a special case with identical loading, processing, and unloading times, and establish a tight lower bound. In addition, we propose two novel mixed-integer linear programming formulations: one utilizing time-indexed variables with an iterative strengthening algorithm, and the other employing linear-ordering variables along with two enhanced valid inequalities. Given the complexity of the problem, we introduce a reduction approach that simplifies the problem by modifying certain constraints, enabling the determination of a feasible solution much more quickly. Building on this reduction, we provide a linear-time reduction algorithm and a fast formulation based on assignment-and-positional date variables. Furthermore, we study a special case involving regular jobs. To solve large-scale instances of the problem with up to 250 jobs and up to 5 machines, we design a hybrid approach combining an iterated greedy algorithm with variable neighborhood descent. As shown in the computational experiments on two sets of benchmark instances, the reduction approach significantly outperforms all previous methods existing in the literature.},
  archive      = {J_EJOR},
  author       = {Abdelhak Elidrissi and Jatinder N.D. Gupta and Rachid Benmansour and Bertrand M.T. Lin},
  doi          = {10.1016/j.ejor.2025.05.030},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {15-31},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A reduction approach for the parallel machine scheduling problem with a separate server for loading and unloading operations},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cutting stock problem with usable leftovers: A review. <em>EJOR</em>, <em>328</em>(1), 1-14. (<a href='https://doi.org/10.1016/j.ejor.2025.03.014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a comprehensive literature review of the Cutting Stock Problem with Usable Leftovers (CSPUL). The most recent review on this topic dates to 2014, covering articles published before 2013. Since then, the number of publications on CSPUL has increased significantly, driven by new applications and more efficient solution approaches. We analyze fifty two relevant articles from twenty four different journals, focusing on works published after 2008 while acknowledging foundational contributions from the 1980s and 1990s. This review categorizes variations of CSPUL based on their dimensions (1D, 2D, and 3D), planning period characteristics (single-period and multi-period), objective functions, and solution methods. The article provides a detailed summary of the key features in the mathematical models and solution methods proposed in these studies. Additionally, it highlights several industrial applications of CSPUL, illustrating its practical relevance. Through this analysis, we identify important applications and propose promising directions for future research. The findings and insights presented here have practical implications for optimizing resource utilization and promoting sustainability in industries facing cutting challenges.},
  archive      = {J_EJOR},
  author       = {Victor Senergues and Nadjib Brahimi and Adriana Cristina Cherri and François Klein and Olivier Péton},
  doi          = {10.1016/j.ejor.2025.03.014},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cutting stock problem with usable leftovers: A review},
  volume       = {328},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
