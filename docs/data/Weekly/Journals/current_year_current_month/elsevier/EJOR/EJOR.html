<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EJOR</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ejor">EJOR - 42</h2>
<ul>
<li><details>
<summary>
(2025). Optimal lot-sizing and service level weighting in sequential multi-attribute global transportation service procurement. <em>EJOR</em>, <em>327</em>(3), 1052-1072. (<a href='https://doi.org/10.1016/j.ejor.2025.05.037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of on-demand global transportation service procurement (oGTSP) through digital trading platforms has accelerated due to frequent fluctuations in transport capacity. In the oGTSP model, the exporter must consider logistics service quality and transport prices when sourcing global logistics services. To satisfy the continuous transport needs, procurement is conducted sequentially throughout multiple auction cycles. For a single auction, we constructed a service-level weight-scoring function and analysed the trading parties’ behavioural strategies to obtain an auction equilibrium strategy in a specific context. Then, we developed a multi-cycle sequential decision method based on a single-cycle equilibrium decision by forwarders that can dynamically adjust the auction lot size to help the exporter obtain optimal utility. Finally, based on the real case of a large electronic product exporter, the proposed approach was verified. The results demonstrated that exporters should pay more attention to the quality of service when choosing freight forwarders to improve the utility of transportation service procurement. The exporter can attract more forwarders to participate in auctions to obtain more capacity supply by increasing the weighting of service levels. Besides, the proposed auction system could effectively accommodate strategic forwarders with learning abilities. The exporter’s utility will significantly improve if the freight forwarders have learning ability. There is a marginal diminishing effect in that the benefits from additional participation of learning-oriented bidders are initially large but eventually stabilized. The strategic auction participation of learning-oriented freight forwarders smooths the capacity supply trend, reduces extreme fluctuations and makes multi-cycle predictions more accurate.},
  archive      = {J_EJOR},
  author       = {Xiang T.R. Kong and Zhan He and Kaize Yu and Pengyu Yan},
  doi          = {10.1016/j.ejor.2025.05.037},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {1052-1072},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal lot-sizing and service level weighting in sequential multi-attribute global transportation service procurement},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Government’s optimal inter-temporal subsidy and manufacturer’s dynamic pricing in the presence of strategic consumers. <em>EJOR</em>, <em>327</em>(3), 1039-1051. (<a href='https://doi.org/10.1016/j.ejor.2025.05.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Governments in many countries offer fiscal incentives—such as subsidies or tax breaks—to consumers to encourage the purchase of environmentally-friendly products like solar panels and electric vehicles. Early adoption by consumers facilitates manufacturers’ learning-by-doing and reduces production cost over time, although the cost reduction itself is subject to uncertainty. Governments face a challenge: should they commit to a multi-period subsidy path (commitment policy) or adjust the subsidy contingent on the realized production cost reduction (dynamic policy)? What are the implications for manufacturers and consumers? We consider a two-period monopoly setting to study these policies. Given the subsidy policy, the manufacturer sets its prices, whereas consumers strategically decide when to purchase the product, if at all. Naturally, the two policies result in different subsidy paths. We find that products with higher initial unit cost (implying higher prices) do not deserve higher subsidies. Our key result is that governments, who seek to maximize expected social welfare, should adopt the dynamic policy. Insightfully, the four components of social welfare—consumer surplus, manufacturer’s profit, environmental benefit and subsidy expenditure—may all be realized higher under the commitment policy than under the dynamic policy when the realized cost reduction falls short of its expected value. This is because the second-period effective price (price minus subsidy) is more sensitive to cost uncertainty under the dynamic policy. Nevertheless, the dominance of the dynamic policy persists also when considering the realized social welfare. We study several extensions demonstrating the robustness of our results, while highlighting certain exceptions.},
  archive      = {J_EJOR},
  author       = {Weichun Chen and Benny Mantin and Bo Li},
  doi          = {10.1016/j.ejor.2025.05.027},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {1039-1051},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Government’s optimal inter-temporal subsidy and manufacturer’s dynamic pricing in the presence of strategic consumers},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated model for predictive maintenance and inventory management under a reliability chance constraint. <em>EJOR</em>, <em>327</em>(3), 1023-1038. (<a href='https://doi.org/10.1016/j.ejor.2025.05.018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new model that integrates opportunistic maintenance and routine maintenance to enhance the effectiveness of predictive maintenance and inventory management in complex manufacturing systems subject to a reliability chance constraint. It considers both hard and soft failure modes and their mutual dependence. When a machine experiences a hard failure, an opportunistic maintenance policy is utilized on the machine’s components. When the soft failure degradation level of a machine component surpasses a threshold, imperfect preventive maintenance or replacement maintenance is carried out. The choice of component supplier, including OEM and aftermarket suppliers, significantly impacts the joint decision model. To improve the model’s realism and applicability, a random variable representing supplier availability intervals is introduced, reflecting a more nuanced understanding of supply chain dynamics. We develop a simulation optimization method to determine the degradation thresholds for opportunistic and regular maintenance, the component inventory policy, and supplier selection. The objective is to minimize the total maintenance and inventory cost, while ensuring a high level of system reliability. The proposed algorithm effectively addresses the system reliability chance constraint by formulating a surrogate model of the quantile of system downtime. A numerical study is conducted to verify the efficacy of the proposed model and to demonstrate the efficiency of the solution method in finding the optimal feasible solution. Furthermore, the influence of critical factors in the model on the optimal policy is analyzed to derive useful managerial insights.},
  archive      = {J_EJOR},
  author       = {Kuo-Hao Chang and Xin-Pei Wu and Robert Cuckler},
  doi          = {10.1016/j.ejor.2025.05.018},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {1023-1038},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An integrated model for predictive maintenance and inventory management under a reliability chance constraint},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ordinal regression meets online learning: Interactive preference learning for multiple criteria choice and ranking with provable guarantees. <em>EJOR</em>, <em>327</em>(3), 1003-1022. (<a href='https://doi.org/10.1016/j.ejor.2025.05.045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a theoretical and practical bridge between ordinal regression for multiple criteria choice and ranking problems and the framework of sequential prediction, also known as online learning. By reframing the ordinal regression as a sequential prediction task, we study a general class of algorithms that assign probabilities to a sequence of the preferences expressed by the Decision Maker (DM). This approach allows us to evaluate various statistical algorithms on a common basis, providing theoretical guarantees on their regret. To model the likelihood, we employ an additive value function that scores pairwise comparisons given by the DM. We explore two likelihood models: (1) a linear model, which we demonstrate is analogous to sequential investment, and (2) the Bradley–Terry model, widely used in statistics and preference learning. For both models, we establish theoretical bounds for the Bayesian method and the Regularized Maximum Likelihood algorithm (also known as Follow the Regularized Leader). We design Monte Carlo Markov Chain methods based on Metropolis–Hastings and Nested Sampling for efficient approximation of the posterior in Bayesian methods. Extensive empirical testing on synthetic and real-world data shows that our methods outperform the best existing approaches in the literature.},
  archive      = {J_EJOR},
  author       = {Marco Grillo and Wojciech Kotłowski and Miłosz Kadziński},
  doi          = {10.1016/j.ejor.2025.05.045},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {1003-1022},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Ordinal regression meets online learning: Interactive preference learning for multiple criteria choice and ranking with provable guarantees},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Alternative ranking in trust network group decision-making: A distributionally robust optimization method. <em>EJOR</em>, <em>327</em>(3), 986-1002. (<a href='https://doi.org/10.1016/j.ejor.2025.05.052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In group decision making problems, preference information can be conveniently and productively used to express the decision-makers’ evaluations over the given set of alternatives. However, the inherent imprecision of preference information may lead to fragile priority weights and unreliable alternative ranking. In this study, we propose a distributionally robust ranking model based on social networks to derive stable priorities, which takes into account the influence of uncertain preference information and the strength of relationships among decision-makers. Specifically, to capture the true data-generating distribution of uncertain parameters, we first develop a distributionally robust ranking model with a moment-based ambiguity set that contains all possible probability distributions over a support set. Then, we verify that the solutions exhibit strong finite-sample performance guarantees. Additionally, the developed model can be reformulated into an equivalent semidefinite programming model. To account for the strength of relationships among decision-makers, we employ propagation efficiency based on Shannon’s theorem, and develop the trust propagation and aggregation operators to obtain decision-makers’ weights. Finally, a numerical experiment is provided, in which the justification and robustness of the distributionally robust ranking model outperform several benchmark models by comparative discussions and robustness analyses.},
  archive      = {J_EJOR},
  author       = {Longlong Shao and Jinpei Liu and Chenyi Fu and Ning Zhu and Huayou Chen},
  doi          = {10.1016/j.ejor.2025.05.052},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {986-1002},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Alternative ranking in trust network group decision-making: A distributionally robust optimization method},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When and should streamers choose high-quality products? effects of streamer types. <em>EJOR</em>, <em>327</em>(3), 971-985. (<a href='https://doi.org/10.1016/j.ejor.2025.05.057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of live-streaming commerce, research has largely focused on manufacturers, leaving streamer decision-making underexplored. This study uses game theory to analyze streamers’ product selection strategies, while also examining how streamer types influence these decisions. The findings reveal that: (a) Streamers do not always prioritize high-quality products. Their choices are shaped by various factors, including product pricing, quality gaps, commission ratios, fan-shoppers’ trust, and sales abilities. High-quality manufacturers are advised to collaborate with knowledge-based streamers, while low-quality manufacturers should partner with entertainment-based streamers. Moderate commission ratios can optimize profits for all parties. (b) For well-known products, knowledge-based streamers with strong sales abilities are more likely to select high-quality items, as they can leverage fan-shoppers' willingness to pay. In contrast, entertainment-based streamers do not exhibit this preference. For unknown products, entertainment-based streamers with strong sales abilities may promote low-quality items, even resorting to deception. Interestingly, entertainment-based streamers with weaker sales abilities may promote high-quality products, while knowledge-based streamers may opt for lower-quality options. (c) When product quality is endogenous, streamers with lower sales abilities should focus on entertainment-based content to attract attention. As their sales abilities improve and fan-shoppers’ trust grows, they should transition to knowledge-based content.},
  archive      = {J_EJOR},
  author       = {Shengyan Cheng and Qiang Guo and Chris K Anderson},
  doi          = {10.1016/j.ejor.2025.05.057},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {971-985},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {When and should streamers choose high-quality products? effects of streamer types},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting two-dimensional projection-efficient units in data envelopment analysis under big data scenarios. <em>EJOR</em>, <em>327</em>(3), 957-970. (<a href='https://doi.org/10.1016/j.ejor.2025.05.053'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the age of big data, traditional estimation methods may struggle to process large datasets efficiently. Ali (1993) laid the foundation for improving efficiency assessment using Data Envelopment Analysis (DEA). Building on this work, we demonstrate how to detect two-dimensional projection-efficient units. This is achieved by projecting the multidimensional DEA production frontier onto two-dimensional subspaces and utilizing slope analysis to identify key efficient units. These units are then linked to their full-dimensional counterparts to define projection-efficient units. We propose using these key efficient units as a preliminary step to speed up the identification of full-dimensional efficient units or to estimate the relative density of datasets. Simulations show that our method reduces computation time for the two fastest approaches by an average of 54.2 % across different datasets.},
  archive      = {J_EJOR},
  author       = {Shuqi Xu and Qingyuan Zhu and Zhiyang Shen and Michael Vardanyan and Yinghao Pan},
  doi          = {10.1016/j.ejor.2025.05.053},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {957-970},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Detecting two-dimensional projection-efficient units in data envelopment analysis under big data scenarios},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deck of cards method for hierarchical, robust and stochastic ordinal regression. <em>EJOR</em>, <em>327</em>(3), 937-956. (<a href='https://doi.org/10.1016/j.ejor.2025.05.025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the recently introduced application of the Deck of Cards Method (DCM) to ordinal regression proposing two extensions related to two main research trends in Multiple Criteria Decision Aiding, namely scaling and ordinal regression generalizations. On the one hand, procedures, different from DCM (e.g. AHP, BWM, MACBETH) to collect and elaborate Decision Maker’s (DM’s) preference information are considered to define an overall evaluation of reference alternatives. On the other hand, Robust Ordinal Regression and Stochastic Multicriteria Acceptability Analysis are used to offer the DM more detailed and realistic decision-support outcomes. More specifically, we consider preference imprecision and indetermination through a set of admissible comprehensive evaluations of alternatives provided by the whole set of value functions compatible with DM’s preference information rather than relying on a single definitive evaluation based on one value function. In addition, we also consider alternatives evaluated on a set of criteria hierarchically structured. The methodology we propose allows the DM to provide precise or imprecise information at different levels of the hierarchy of criteria. Like scaling procedures, the compatible value function we consider can be of a different nature, such as weighted sum, linear or general monotone value function, or Choquet integral. Consequently, the approach we propose is versatile and well-equipped to be adapted to DM’s characteristics and requirements. The applicability of the proposed methodology is shown by a didactic example based on a large ongoing research project in which Italian regions are evaluated on criteria representing Circular Economy, Innovation-Driven Development and Smart Specialization Strategies.},
  archive      = {J_EJOR},
  author       = {Salvatore Corrente and Salvatore Greco and Silvano Zappalà},
  doi          = {10.1016/j.ejor.2025.05.025},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {937-956},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Deck of cards method for hierarchical, robust and stochastic ordinal regression},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum likelihood probability measures over sets: Existence, computation, and convergence. <em>EJOR</em>, <em>327</em>(3), 922-936. (<a href='https://doi.org/10.1016/j.ejor.2025.07.054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider maximum likelihood estimation of a distribution over a general measurable space where realizations of the uncertainty are not directly observable but instead are known to lie within observable sets. We show that maximum likelihood estimates concentrate on a collection of maximal intersections (CMI) and can be found by solving a convex optimization problem whose size is linear in the size of the CMI. We provide an enumerative algorithm to compute the estimates and show that there are estimates that assign positive weight only to T + 1 elements of the CMI ( T being the number of observed sets). Motivated by this, we provide a column generation algorithm to compute the estimates that avoids enumerating the CMI. Under the assumption that either the observed sets are mixed-integer representable, or that the range of the underlying distribution is finite and known, we provide formulations of the algorithms that can be solved with commercial solvers. We study convergence properties of the maximum likelihood estimate both in terms of traditional notions of converge, as well as in terms of Wasserstein distances. Our results show that convergence to the underlying distribution cannot be guaranteed in general, but we identify sufficient conditions for convergence. We also perform numerical experiments that show that the estimates can be computed within minutes, that column generation can significantly reduce computational times, and that there is convergence even in cases where no theoretical guarantees are known.},
  archive      = {J_EJOR},
  author       = {Juan S. Borrero and Denis Sauré},
  doi          = {10.1016/j.ejor.2025.07.054},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {922-936},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Maximum likelihood probability measures over sets: Existence, computation, and convergence},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Worst-case values of target semi-variances with applications to robust portfolio selection. <em>EJOR</em>, <em>327</em>(3), 905-921. (<a href='https://doi.org/10.1016/j.ejor.2025.07.057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expected regret and target semi-variance are two of the most important risk measures for downside risk. When the distribution of a loss is uncertain, and only partial information of the loss is known, their worst-case values play important roles in robust risk management for finance, insurance, and many other fields. Jagannathan (1977) derived the worst-case expected regrets when only the mean and variance of a loss are known and the loss is arbitrary, symmetric, or non-negative. While Chen et al. (2011) obtained the worst-case target semi-variances under similar conditions but focusing on arbitrary losses. In this paper, we first complement the study of Chen et al. (2011) on the worst-case target semi-variances and derive the closed-form expressions for the worst-case target semi-variance when only the mean and variance of a loss are known and the loss is symmetric or non-negative. Then, we investigate worst-case target semi-variances over uncertainty sets that represent undesirable scenarios faced by an investor. Our methods for deriving these worst-case values are different from those used in Jagannathan (1977) and Chen et al. (2011). As applications of the results derived in this paper, we propose robust portfolio selection methods that minimize the worst-case target semi-variance of a portfolio loss over different uncertainty sets. To explore the insights of our robust portfolio selection methods, we conduct numerical experiments with real financial data and compare our portfolio selection methods with several portfolio selection models related to the models proposed in this paper.},
  archive      = {J_EJOR},
  author       = {Jun Cai and Zhanyi Jiao and Tiantian Mao},
  doi          = {10.1016/j.ejor.2025.07.057},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {905-921},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Worst-case values of target semi-variances with applications to robust portfolio selection},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint model for longitudinal and spatio-temporal survival data. <em>EJOR</em>, <em>327</em>(3), 892-904. (<a href='https://doi.org/10.1016/j.ejor.2025.07.060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In credit risk analysis, survival models with fixed and time-varying covariates are commonly used to predict a borrower’s time-to-event. When time-varying covariates are endogenous, jointly modeling their evolution with the event time — known as the joint model for longitudinal and time-to-event data — provides a principled approach. In addition to temporal dynamics, incorporating borrowers’ geographical information can enhance predictive accuracy by capturing spatial clustering and its variation over time. We propose the Spatio-Temporal Joint Model (STJM), a Bayesian hierarchical model that accounts for spatial and temporal effects and their interaction. The STJM captures the impact of unobserved heterogeneity across regions, affecting borrowers residing in the same area at a given time. To ensure scalability to large datasets, we implement the model using the Integrated Nested Laplace Approximation (INLA) framework. We apply the STJM to predict the time to full prepayment on a large dataset of 57,258 US mortgage borrowers with more than 2.5 million observations. Empirical results indicate that including spatial effects consistently improves the performance of the joint model. However, the gains are less definitive when we additionally include spatio-temporal interactions.},
  archive      = {J_EJOR},
  author       = {Victor Medina-Olivares and Finn Lindgren and Raffaella Calabrese and Jonathan Crook},
  doi          = {10.1016/j.ejor.2025.07.060},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {892-904},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Joint model for longitudinal and spatio-temporal survival data},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Staggered routing in autonomous mobility-on-demand systems. <em>EJOR</em>, <em>327</em>(3), 875-891. (<a href='https://doi.org/10.1016/j.ejor.2025.06.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In autonomous mobility-on-demand systems, effectively managing vehicle flows to mitigate induced congestion and ensure efficient operations is imperative for system performance and positive customer experience. Against this background, we study the potential of staggered routing, i.e., purposely delaying trip departures from a system perspective, in order to reduce congestion and ensure efficient operations while still meeting customer time windows. We formalize the underlying planning problem and show how to efficiently model it as a mixed integer linear program. Moreover, we present a matheuristic that allows us to efficiently solve large-scale real-world instances both in an offline full-information setting and its online rolling horizon counterpart. We conduct a numerical study for Manhattan, New York City, focusing on low- and highly-congested scenarios. Our results show that in low-congestion scenarios, staggering trip departures allows mitigating, on average, 98 % of the induced congestion in a full information setting. In a rolling horizon setting, our algorithm allows us to reduce 82 % of the induced congestion. In high-congestion scenarios, we observe an average reduction of 60 % as the full information bound and an average reduction of 30 % in our online setting. Surprisingly, we show that these reductions can be reached by shifting trip departures by a maximum of six minutes in both the low and high-congestion scenarios.},
  archive      = {J_EJOR},
  author       = {Antonio Coppola and Gerhard Hiermann and Dario Paccagnan and Maximilian Schiffer},
  doi          = {10.1016/j.ejor.2025.06.008},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {875-891},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Staggered routing in autonomous mobility-on-demand systems},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The storage location assignment and picker routing problem: A generic branch-cut-and-price algorithm. <em>EJOR</em>, <em>327</em>(3), 857-874. (<a href='https://doi.org/10.1016/j.ejor.2025.05.041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Storage Location Assignment Problem (SLAP) and the Picker Routing Problem (PRP) have received significant attention in the literature due to their pivotal role in the performance of the Order Picking (OP) activity, the most resource-intensive process of warehousing logistics. The two problems are traditionally considered at different decision-making levels: tactical for the SLAP, and operational for the PRP. However, this paradigm has been challenged by the emergence of modern practices in e-commerce warehouses, where decisions are more dynamic. This shift makes the integrated problem, called the Storage Location Assignment and Picker Routing Problem (SLAPRP), pertinent to consider. Scholars have investigated several variants of the SLAPRP, including different warehouse layouts and routing policies. Nevertheless, the available computational results suggest that each variant requires an ad-hoc formulation. Moreover, achieving a complete integration of the two problems, where the routing is solved optimally, remains out of reach for commercial solvers, even on trivial instances. In this paper, we propose an exact solution framework that addresses a broad class of variants of the SLAPRP, including all the previously existing ones. This paper proposes a Branch-Cut-and-Price framework based on a novel formulation with an exponential number of variables, which is strengthened with a novel family of non-robust valid inequalities. We have developed an ad-hoc branching scheme to break symmetries and maintain the size of the enumeration tree manageable. Computational experiments show that our framework can effectively solve medium-sized instances of several SLAPRP variants and outperforms the state-of-the-art methods from the literature.},
  archive      = {J_EJOR},
  author       = {Thibault Prunet and Nabil Absi and Diego Cattaruzza},
  doi          = {10.1016/j.ejor.2025.05.041},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {857-874},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The storage location assignment and picker routing problem: A generic branch-cut-and-price algorithm},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust parallel machine selection and scheduling with uncertain release times. <em>EJOR</em>, <em>327</em>(3), 838-856. (<a href='https://doi.org/10.1016/j.ejor.2025.05.032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a parallel machine selection and scheduling (PMSS) problem with uncertain release times. To handle uncertain release times, we propose a two-stage robust PMSS model where the release time deviation (RTD) is characterized by a budget uncertainty set. In the first stage, machine selection and job assignment decisions are made to minimize startup costs before the uncertainties are revealed. In the second stage, once release times are known, job sequences are optimized to minimize the makespan on each machine. Robust constraints are introduced to ensure that the worst-case minimum makespan on each machine does not exceed a pre-specified due date. The proposed model is a tri-level min–max–min optimization problem with mixed-integer recourse decisions, which cannot be solved efficiently by existing algorithms. To this end, we propose a novel logic-based Benders decomposition (LBBD) algorithm with strengthened Benders cuts and speedup techniques. Specifically, we first provide an equivalent mixed-integer linear programming reformulation for the max–min subproblem by analyzing an optimality condition of the worst-case RTD. Second, we design novel combinatorial and analytical Benders cuts, which dominate cuts found in the literature, and we further strengthen them by lifting procedures. Third, we design a relaxation-and-correction procedure and a warm-start procedure to speed up the LBBD algorithm. Numerical experiments show the proposed robust model greatly reduces job tardiness compared with the deterministic model. The proposed cuts efficiently reduce the runtime, and the LBBD algorithm is at least three orders of magnitude faster than the state-of-the-art column-and-constraint-generation algorithm.},
  archive      = {J_EJOR},
  author       = {Linyuan Hu and Yuli Zhang and Muyang Wen and Roel Leus and Ningwei Zhang},
  doi          = {10.1016/j.ejor.2025.05.032},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {838-856},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust parallel machine selection and scheduling with uncertain release times},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast optimization approach for a complex real-life 3D multiple bin size bin packing problem. <em>EJOR</em>, <em>327</em>(3), 820-837. (<a href='https://doi.org/10.1016/j.ejor.2025.05.016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a real-life air cargo loading problem which is a variant of the three-dimensional Variable Size Bin Packing Problem with special bin forms of cuboid and non-cuboid unit load devices (ULDs). Packing is constrained by additional practical restrictions, such as load stability, (non-)stackable items, and weight distribution constraints. To solve the problem, we present an insertion heuristic embedded into a Randomized Greedy Search. The solution space is limited by only considering certain candidate points (so-called extreme points), which are promising positions to load an item. We extend the concept of extreme points proposed in the literature and allow moving extreme points for non-cuboid ULDs. A special sorting of the items, which combines a layered structure and free packing, is suggested. Moreover, we propose dividing the space of each ULD into smaller cells to accelerate the collision, non-floating, and stackability check while loading items. In a computational study, we analyze individual algorithm components and show the effectiveness of our method on adapted real-life instances from the literature.},
  archive      = {J_EJOR},
  author       = {Katrin Heßler and Timo Hintsch and Lukas Wienkamp},
  doi          = {10.1016/j.ejor.2025.05.016},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {820-837},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A fast optimization approach for a complex real-life 3D multiple bin size bin packing problem},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning assisted differential evolution for the dynamic resource constrained multi-project scheduling problem with static project schedules. <em>EJOR</em>, <em>327</em>(3), 808-819. (<a href='https://doi.org/10.1016/j.ejor.2025.05.059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large modular construction projects, such as shipbuilding, multiple similar projects arrive stochastically. At project arrival, a schedule has to be created, in which future modifications are difficult and/or undesirable. Since all projects use the same set of shared resources, current scheduling decisions influence future scheduling possibilities. To model this problem, we introduce the Dynamic Resource Constrained Multi-project Scheduling Problem with Static project Schedules. To find schedules, both a greedy approach and simulation-based approach with varying scenarios are introduced. Although the simulation-based approach schedules projects proactively, the computing times are long, even for small instances. Therefore, a method is introduced that learns from schedules obtained in the simulation-based method and uses a neural network to estimate the objective function value. It is shown that this method achieves a significant improvement in objective function value over the greedy algorithm, while only requiring a fraction of the computation time of the simulation-based method.},
  archive      = {J_EJOR},
  author       = {T. van der Beek and J.T. van Essen and J. Pruyn and K. Aardal},
  doi          = {10.1016/j.ejor.2025.05.059},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {808-819},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Machine learning assisted differential evolution for the dynamic resource constrained multi-project scheduling problem with static project schedules},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A flexible mathematical model for home health care problems. <em>EJOR</em>, <em>327</em>(3), 791-807. (<a href='https://doi.org/10.1016/j.ejor.2025.05.055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the health and social care sectors it is common for some specialized teams to travel to patients homes to provide care. These teams are typically made up of by a number of staff members with varying skills, starting locations and working hours. Patients require different types of care, during specific time windows, and may have special requirements, such as needing two staff members, or multiple visits with some sort of temporal dependency between them. Since teams need to decide which staff member will visit each patient, as well as the routes they will take to do so, this kind of planning problem is known in the literature as the Home Health Care Routing and Scheduling Problem (HHCRSP). We introduce a new mixed integer linear programming formulation for the HHCRSP that extends previous models. Our formulation can readily be adapted to address more specific variants in the scientific literature, proving a larger number of optimal solutions and stronger lower bounds on benchmark instances using the same computational framework. We further propose an instance generator for producing scenarios that closely resemble those of the National Health Service in the United Kingdom.},
  archive      = {J_EJOR},
  author       = {Miguel Reula and Consuelo Parreño-Torres and Carlos Lamas-Fernandez and Antonio Martinez-Sykora},
  doi          = {10.1016/j.ejor.2025.05.055},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {791-807},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A flexible mathematical model for home health care problems},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The dial-a-ride problem with limited pickups per trip. <em>EJOR</em>, <em>327</em>(3), 776-790. (<a href='https://doi.org/10.1016/j.ejor.2025.05.051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Dial-a-Ride Problem (DARP) is an optimization problem that involves determining optimal routes and schedules for several vehicles to pick up and deliver items at minimum cost. Motivated by real-world carpooling and crowdshipping scenarios, we introduce an additional constraint imposing a maximum number on the number of pickups per trip. This results in the Dial-a-Ride Problem with Limited Pickups per Trip (DARP-LPT). We apply a fragment-based method for DARP-LPT, where a fragment is a partial path. Specifically, we extend two formulations from Rist and Forbes (2021): the Fragment Flow Formulation (FFF) and the Pickup-Space Fragment Formulation (PSFF). Furthermore, our results show that PSFF outperforms FFF, which in turn surpasses traditional arc-based formulations in both solution quality and computational efficiency. Additionally, we compare several existing fragment sets that differ in the length of their partial paths and find that the sets with shorter partial paths yield the best solution times when used with PSFF. In addition, we propose a new mixed fragment set, which is useful when the sets with longer partial paths become too large. In such cases, it yields the lowest CPU time.},
  archive      = {J_EJOR},
  author       = {Boshuai Zhao and Kai Wang and Wenchao Wei and Roel Leus},
  doi          = {10.1016/j.ejor.2025.05.051},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {776-790},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The dial-a-ride problem with limited pickups per trip},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new class of lower bounds for scheduling a batch processing machine to minimize makespan. <em>EJOR</em>, <em>327</em>(3), 754-775. (<a href='https://doi.org/10.1016/j.ejor.2025.05.047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of minimizing makespan on a batch-processing machine with limited capacity. Each job has a size and processing time, and multiple jobs can be processed simultaneously in a batch, provided the machine’s capacity is not exceeded. The batch processing time is determined by the longest processing time in batch. We show that the existing lower bound method has a worst-case performance ratio of 1/2, and propose a class of lower bound procedures ( LB m ) and its improved variant ( ILB m ). The new procedures take integer m , used to partition jobs depending on whether their sizes are greater than B / m or not, and provide tighter bounds as m increases. We prove that the worst-case performance ratio of LB m and ILB m is no worse than 4/7. Additionally, we show that they can be computed efficiently for m ≤3. Based on the structure of the proposed lower bound procedures, we introduce different valid inequalities ( VI ) and embed them into an existing MILP model to achieve a formulation with a tighter LP bound. To gain understanding on the quality of the bounds, we employ them in a branch and bound ( B & B ) algorithm. Results indicate that the B&B with new lower bound methods increases the number of optimally solved problem instances by 44% and 35% compared to the existing B&B and branch and price algorithms, respectively. Furthermore, the lower bound-driven VI s help increase the number of solved problems by more than 30%, achieving an optimality rate exceeding 96% across a wide range of problem instances.},
  archive      = {J_EJOR},
  author       = {Ali Husseinzadeh Kashan and Onur Ozturk},
  doi          = {10.1016/j.ejor.2025.05.047},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {754-775},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new class of lower bounds for scheduling a batch processing machine to minimize makespan},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EATKG: An open-source efficient exact algorithm for the two-dimensional knapsack problem with guillotine constraints. <em>EJOR</em>, <em>327</em>(3), 735-753. (<a href='https://doi.org/10.1016/j.ejor.2025.05.033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the Two-Dimensional Knapsack Problem with Guillotine Constraints, which is a famous NP -hard problem and is commonly encountered in industries where rectangular raw materials are cut into smaller pieces using guillotine cuts. We propose an efficient exact algorithm (EATKG) to solve this problem, which incorporates advanced techniques and novel elements, including an adapted preprocessing procedure, two enhanced upper bounds, an improved bidirectional tree search approach, and an iterative combination enumeration process. These components effectively balance the computation of upper and lower bounds and handle the issue of memory overflow. We extensively evaluate EATKG on eight classic benchmark sets, comprising 1,277 instances. Our algorithm solves 87% of the instances with an average computing time of 7 seconds, and 93% with an average computing time of 49 seconds. Moreover, EATKG efficiently solves nearly all small- and medium-sized instances, providing better solutions for 46 instances and tighter upper bounds for 109 instances. These results demonstrate the superior performance of our algorithm compared to leading algorithms. To support future research, we have made the source code for the proposed algorithm, along with the corresponding instance data, aggregated results, and detailed solutions, publicly available. This will facilitate further investigations and comparisons of solution methods.},
  archive      = {J_EJOR},
  author       = {Sunkanghong Wang and Roberto Baldacci and Qiang Liu and Lijun Wei},
  doi          = {10.1016/j.ejor.2025.05.033},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {735-753},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {EATKG: An open-source efficient exact algorithm for the two-dimensional knapsack problem with guillotine constraints},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Greedy randomized adaptive search procedures with path relinking. an analytical review of designs and implementations. <em>EJOR</em>, <em>327</em>(3), 717-734. (<a href='https://doi.org/10.1016/j.ejor.2025.02.022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a comprehensive review of the Greedy Randomized Adaptive Search Procedure (GRASP) metaheuristic and its hybridization with Path Relinking (PR). GRASP with PR has become a widely adopted approach for solving hard optimization problems since its proposal in 1999. The paper covers the historical development of GRASP with PR and its theoretical foundations, as well as recent advances in its implementation and application. The review includes a careful analysis of PR variants, paying special attention to memory-based and randomized designs, with a total of ten different implementations. It identifies the design questions that are still open in the scientific literature. The experimental section applies advanced PR implementations on two well-known combinatorial optimization problems, linear ordering and max-cut, in an effort to answer these open questions. The paper also explores the hybridization of PR and other metaheuristics, such as tabu search, scatter search, and random-keys genetic algorithms. Overall, this review provides valuable insights for researchers and practitioners seeking to implement GRASP with PR for solving optimization problems.},
  archive      = {J_EJOR},
  author       = {Manuel Laguna and Rafael Martí and Anna Martínez-Gavara and Sergio Pérez-Peló and Mauricio G.C. Resende},
  doi          = {10.1016/j.ejor.2025.02.022},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {717-734},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Greedy randomized adaptive search procedures with path relinking. an analytical review of designs and implementations},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The devil in the details: Dynamic prediction of loan portfolio profitability with macroeconomic drivers through multi-state modelling. <em>EJOR</em>, <em>327</em>(2), 703-715. (<a href='https://doi.org/10.1016/j.ejor.2025.07.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In typical loan portfolios such as mortgages and credit cards, many accounts often experience different stages of delinquency before eventually recovering, fully repaying their balance, or defaulting. From the lender perspective, these events, coupled with the state of the economy, can affect cash-flow and profitability significantly. This paper presents a novel framework for dynamic monitoring future expected profit margins and cash flows of loan accounts, taking into account (i) individual risk profiles, (ii) macroeconomic trends, and (iii) transitions between different stages of delinquency. We make three contributions. First, we show a method to predict future cash flows and profit margins over the life of a loan where the predicted probabilities of an account jumping between delinquency states are obligor specific, time varying, adjusted to be competing risks and dependent on predictions from a macroeconomic model. This model is much more comprehensive model than those in the literature. Second, we investigate different methods to compute optimised cut-offs to be used with the transition probabilities to predict jumps an account is expected to make between different states of delinquency. Third, we illustrate the method using a large sample of 30-year term mortgages and show the expected profit margins for segments of the portfolio. The method will be particularly useful to lenders, who must comply with IFRS9 or CECL.},
  archive      = {J_EJOR},
  author       = {Viani B. Djeundje and Jonathan Crook and Galina Andreeva},
  doi          = {10.1016/j.ejor.2025.07.008},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {703-715},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The devil in the details: Dynamic prediction of loan portfolio profitability with macroeconomic drivers through multi-state modelling},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bankruptcy prediction with fractional polynomial transformation of financial ratios. <em>EJOR</em>, <em>327</em>(2), 690-702. (<a href='https://doi.org/10.1016/j.ejor.2025.07.036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that simple nonlinear transformations of financial ratios, within a multivariate fractional polynomial approach, yield substantial improvements in bankruptcy prediction. The approach selects optimal power functions balancing parsimony and complexity. Focusing on a dataset comprising of non-financial firms, we develop a parsimonious nonlinear logit model with minimal parameter specification and clear interpretability, outperforming linear logit models. The model improves the in-sample fit, while out-of-sample it significantly reduces costly misclassification errors and improves discriminatory power. Similar insights are obtained when applying fractional polynomials on a secondary dataset consisting of banking firms. Interestingly, the fractional polynomial model compares favourably with other nonlinear models. By simulating a competitive loan market, we demonstrate that the bank using the fractional polynomial model builds a higher-quality loan portfolio, resulting in superior risk-adjusted profitability compared to banks employing alternative models.},
  archive      = {J_EJOR},
  author       = {Zenon Taoushianis},
  doi          = {10.1016/j.ejor.2025.07.036},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {690-702},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bankruptcy prediction with fractional polynomial transformation of financial ratios},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entrepreneurs’ optimal decisions in equity crowdfunding campaigns. <em>EJOR</em>, <em>327</em>(2), 673-689. (<a href='https://doi.org/10.1016/j.ejor.2025.07.004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equity crowdfunding is a method of financing an initiative whereby an entrepreneur sells shares in her firm to a group of people (the crowd) on a dedicated platform. Understanding the forces that shape the behavior of both buyers in the crowd and entrepreneurs in equity crowdfunding platforms can help design more efficient platforms and increase the welfare of all participants. We therefore develop a common value sequential crowdfunding game-theoretic model, where the entrepreneur sells a percentage of her firm in order to raise money for its establishment and then shares the future value of the firm with the crowd. Buyers on the platform who visit the campaign decide whether or not to invest in it. Each buyer’s decision depends on the amount that has already been invested before him and on his own knowledge about the firm and the market in which it operates (which we model as a noisy signal that he obtains regarding the true value of the firm). By offering a different percentage in the firm, the entrepreneur leads the crowd to a different equilibrium. We characterize these equilibria and then analyze the entrepreneur’s decision. We show that the entrepreneur’s optimal percentage she offers for sale is non monotonic in the ex-ante probability of success. This is in-line with recent empirical findings. We further show that when buyers’ signals are very noisy, the entrepreneur may prefer buyers that have a less accurate signal regarding the true value of the firm over buyers with a more accurate signal.},
  archive      = {J_EJOR},
  author       = {Hana Tzur and Ella Segev},
  doi          = {10.1016/j.ejor.2025.07.004},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {673-689},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Entrepreneurs’ optimal decisions in equity crowdfunding campaigns},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision-making framework for supporting an equitable global vaccine distribution under humanitarian perspectives. <em>EJOR</em>, <em>327</em>(2), 655-672. (<a href='https://doi.org/10.1016/j.ejor.2025.05.007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is motivated by the occurrence of vaccine nationalism in the setting of pandemics. Certain high-income countries (HICs) aggressively accumulated vaccinations while showing little concern for the vaccination challenges faced by low- and middle- income countries. This disparity fosters the proliferation and mutation of viruses, thus risking the global population’s health and welfare. Hence, we create a data-driven framework to tackle this humanitarian problem by facilitating the provision of vaccines. The framework comprises of two models: a network model named multi-strain Susceptible–Vaccinated–Infected–Removed–Susceptible and a vaccine distribution model with equitable constraints. The latter also encompasses the diverse uncertainty associated with vaccination hesitancy in different countries, in order to avoid potential wastage of resources. The vaccine distribution from our framework is based on greedy thought, thus enabling decision-makers to actively engage in the real-time vaccine allocation process. When the suggested framework is applied to the scenario of the COVID-19 pandemic, the simulation results indicate that fair distributions could accelerate the end of the pandemic. Additional scenarios, such as equitable levels and traveling intensity, are also examined in the sensitivity analysis. The progression of the epidemic under vaccine nationalism is moreover simulated to highlight its harmfulness and validate the efficacy of our framework. We demonstrate that the inequitable advantage experienced by HICs is temporary, as HICs are bound to suffer from virus variants in due course when vaccinations become less efficacious against them.},
  archive      = {J_EJOR},
  author       = {Jian Zhou and Junyang Cai and Athanasios A. Pantelous and Zhen Li and Musen Kingsley Li},
  doi          = {10.1016/j.ejor.2025.05.007},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {655-672},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A decision-making framework for supporting an equitable global vaccine distribution under humanitarian perspectives},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effects of geopolitical strain on global pharmaceutical supply chain design and drug shortages. <em>EJOR</em>, <em>327</em>(2), 641-654. (<a href='https://doi.org/10.1016/j.ejor.2025.05.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging geopolitical risks have begun to threaten global supply chains, including those that produce life-saving drugs. Export bans may prevent a company from shipping products internationally, and it is unclear how these new dynamics may affect company plans and persistent, worldwide drug shortages. To address these questions, we present a global pharmaceutical supply chain design model that considers the risk of export bans that are induced by supplier capacity disruptions and corresponding price increases. The model takes the company’s perspective as a decision-maker looking to locate plants and distribute drugs globally. It is a two-stage stochastic program that includes uncertainty in capacity, ability-to-export, and demand. The model is solved by integrating the Sample Average Approximation and L-shaped methods. We present conditions related to when demand will be met and a case study of a generic oncology drug. We find that preparing for geopolitical strain may increase resilience and profits as well as reduce shortages in the short term. At baseline, expected global shortages are high (17.2%) with disparities across country income levels (0.3%, 0.8%, 87.2%, and 87.6% for high, upper-middle, lower-middle, and low income countries, respectively). Pricing policies may improve drug access overall, back-shoring may slightly improve access for the country where it is implemented, and bilateral alliances may not be effective at improving access.},
  archive      = {J_EJOR},
  author       = {Martha L. Sabogal De La Pava and Emily L. Tucker},
  doi          = {10.1016/j.ejor.2025.05.002},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {641-654},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Effects of geopolitical strain on global pharmaceutical supply chain design and drug shortages},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling consumer stickiness in online platform pricing. <em>EJOR</em>, <em>327</em>(2), 623-640. (<a href='https://doi.org/10.1016/j.ejor.2025.04.041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the operational practice of JD.com, China’s largest online retailer, our study delves into the phenomenon of consumer stickiness. It measures the probability that consumers will remain loyal to a specific product, refraining from purchasing alternatives, even in the temporary absence of the focal product. Based on real data from JD.com, we show that consumer stickiness has a significantly positive impact on online sales, which is used to justify our formulation of the demand function in theoretical analysis. Specifically, we adopt a game-theoretical approach to analyze the impact of consumer stickiness on two-period pricing strategies in monopolistic and competitive markets. Findings reveal that incorporating consumer stickiness leads to differentiated pricing strategies, with low-quality products reducing prices in the second period and high-quality products increasing them. Stickiness enhances total sales in monopolistic markets with high-quality products and in competitive markets with high market potential. Furthermore, stickiness contributes to increased revenue and improvements in consumer surplus and social welfare under large or small market conditions, underscoring its strategic importance for pricing and welfare outcomes. These findings contribute valuable insights into the dynamics of online platform competition and highlight the strategic implications of consumer stickiness in influencing pricing and platform revenue.},
  archive      = {J_EJOR},
  author       = {Nina Yan and Tingting Tong and Gangshu (George) Cai},
  doi          = {10.1016/j.ejor.2025.04.041},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {623-640},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modeling consumer stickiness in online platform pricing},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning for the real-time inventory rack storage assignment and replenishment problem. <em>EJOR</em>, <em>327</em>(2), 606-622. (<a href='https://doi.org/10.1016/j.ejor.2025.05.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The e-commerce industry is quickly transforming towards more automation and technological advancements. With the growing intricacy of warehouse operations, there is a need for control systems that can efficiently handle this complexity. This study considers a Robotic Mobile Fulfillment System (RMFS), a semi-automated warehousing system. This system employs autonomous mobile robots (AMRs) to retrieve inventory racks from the storage area; this way, human activity is eliminated within the storage area itself. The fleet of robots both store and retrieve the inventory racks to either workstations, where human pickers are stationed that pick items from the racks, or replenishment stations, where depleted inventory racks can be restocked with items. An attractive characteristic of the RMFS is that it dynamically changes the positioning of the inventory racks based on the frequency of inventory rack requests and the state of their stock levels. The optimization objective considered in this study for the dynamic positioning problem of the racks within the storage area is to minimize the average cycle time of the mobile robots to perform retrieval and replenishment activities. We propose a deep reinforcement learning approach to train a decision-making agent to learn a policy for the storage assignment and replenishment of inventory racks. The learned policy is compared to the commonly used decision rules in the academic literature on this problem. The experimental results show the potential benefits of training an agent to learn a storage and replenishment policy. Cycle time improvements up to 5.4 % can be achieved over the best-performing decision rules. This research contributes to advancing the understanding of intelligent storage assignment and replenishment strategies for the real-time decision-making process within an RMFS.},
  archive      = {J_EJOR},
  author       = {Sander Teck and Tú San Phạm and Louis-Martin Rousseau and Pieter Vansteenwegen},
  doi          = {10.1016/j.ejor.2025.05.008},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {606-622},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Deep reinforcement learning for the real-time inventory rack storage assignment and replenishment problem},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying hidden critical elements in interconnected systems: An influence dynamics analysis approach considering structural constraints. <em>EJOR</em>, <em>327</em>(2), 592-605. (<a href='https://doi.org/10.1016/j.ejor.2025.05.038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The systems analysis field has traditionally focused on identifying the essential elements within an interconnected system and analyzing the cause-and-effect relationships among them. However, most decision-making methods in system analysis have been one-sided. They primarily rely on the interactions between elements to make decisions, neglecting to account for the non-uniform influence attenuation among elements and unequal importance diffusion. Furthermore, these two factors are closely tied to the topological structure of systems, which has been an often-overlooked aspect in previous research, leading to inaccurate identification and omission of hidden key elements. In response to these challenges, this paper introduces a novel method called SIDA ( S tructural-constrained I nfluence D ynamic A nalysis). We utilize structural constraint coefficients derived from structural hole theory to describe the non-uniform attenuation. Furthermore, we integrate an influence and distance-weighted PageRank algorithm to manage the unequal importance diffusion taking into account both the influence and the distance between elements within systems. We validated our proposed method through a comprehensive analysis of a pharmaceutical industry ecosystem, comparing its performance with previous approaches to validate its effectiveness and practicality. The case study results demonstrate that SIDA produces more reasonable element analysis and ranking outcomes.},
  archive      = {J_EJOR},
  author       = {Caibo Zhou and Wenyan Song and Huiwen Wang and Lihong Wang},
  doi          = {10.1016/j.ejor.2025.05.038},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {592-605},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Identifying hidden critical elements in interconnected systems: An influence dynamics analysis approach considering structural constraints},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust binary and multinomial logit models for classification with data uncertainties. <em>EJOR</em>, <em>327</em>(2), 577-591. (<a href='https://doi.org/10.1016/j.ejor.2025.05.013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary logit (BNL) and multinomial logit (MNL) models are the two most widely used discrete choice models for travel behavior modeling and prediction. However, in many scenarios, the collected data for those models are subject to measurement errors. Previous studies on measurement errors mostly focus on “better estimating model parameters” with training data. In this study, we focus on using BNL and MNL for classification problems, that is, to “better predict the behavior of new samples” when measurement errors occur in testing data. To this end, we propose a robust BNL and MNL framework that is able to account for data uncertainties in both features and labels. The models are based on robust optimization theory that minimizes the worst-case loss over a set of uncertainty data scenarios. Specifically, for feature uncertainties, we assume that the ℓ p -norm of the measurement errors in features is smaller than a pre-established threshold. We model label uncertainties by limiting the number of mislabeled choices to at most Γ . Based on these assumptions, we derive a tractable robust counterpart. The derived robust-feature BNL and the robust-label MNL models are exact. However, the formulation for the robust-feature MNL model is an approximation of the exact robust optimization problem. An upper bound of the approximation gap is provided. We prove that the robust estimators are inconsistent but with a higher trace of the Fisher information matrix. They are preferred when out-of-sample data has errors due to the shrunk scale of the estimated parameters. The proposed models are validated in a binary choice data set and a multinomial choice data set, respectively. Results show that the robust models (both features and labels) can outperform the conventional BNL and MNL models in prediction accuracy and log-likelihood. We show that the robustness works like “regularization” and thus has better generalizability.},
  archive      = {J_EJOR},
  author       = {Baichuan Mo and Yunhan Zheng and Xiaotong Guo and Ruoyun Ma and Jinhua Zhao},
  doi          = {10.1016/j.ejor.2025.05.013},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {577-591},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust binary and multinomial logit models for classification with data uncertainties},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalarisation-based risk concepts for robust multi-objective optimisation. <em>EJOR</em>, <em>327</em>(2), 559-576. (<a href='https://doi.org/10.1016/j.ejor.2025.04.054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust optimisation is a well-established framework for optimising functions in the presence of uncertainty. The inherent goal of this problem is to identify a collection of inputs whose outputs are both desirable for the decision maker, whilst also being robust to the underlying uncertainties in the problem. In this work, we study the multi-objective case of this problem. We identify that the majority of all robust multi-objective algorithms rely on two key operations: robustification and scalarisation. Robustification refers to the strategy that is used to account for the uncertainty in the problem. Scalarisation refers to the procedure that is used to encode the relative importance of each objective to a scalar-valued reward. As these operations are not necessarily commutative, the order that they are performed in has an impact on the resulting solutions that are identified and the final decisions that are made. The purpose of this work is to give a thorough exposition on the effects of these different orderings and in particular highlight when one should opt for one ordering over the other. As part of our analysis, we showcase how many existing risk concepts can be integrated into the specification and solution of a robust multi-objective optimisation problem. Besides this, we also demonstrate how one can principally define the notion of a robust Pareto front and a robust performance metric based on our “robustify and scalarise” methodology. To illustrate the efficacy of these new ideas, we present two insightful case studies which are based on real-world data sets.},
  archive      = {J_EJOR},
  author       = {Ben Tu and Nikolas Kantas and Robert M. Lee and Behrang Shafei},
  doi          = {10.1016/j.ejor.2025.04.054},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {559-576},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scalarisation-based risk concepts for robust multi-objective optimisation},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A structured framework for supporting the participatory development of consensual scenario narratives. <em>EJOR</em>, <em>327</em>(2), 540-558. (<a href='https://doi.org/10.1016/j.ejor.2025.04.048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High levels of uncertainty faced by decision makers can be alleviated by characterizing multiple possible ways in which the future might unfold with scenario narratives. Aiming at describing alternative plausible chains of outcomes of key uncertainty factors, scenario narratives are often associated with graphical networks describing the relationships between the outcomes of the factors. We present a participatory framework for bottom-up development of such networks, the PACNAP (PArticipatory development of Consensual narratives through Network Aggregation and Pruning) framework. In this framework, relationships of influence between factor outcomes are judged by a group of scenario process participants. We develop an optimization model for pruning an aggregated graph based on these judgments. The model selects those edges of the aggregate graph that the participants most agree upon and can be tailored to identify compact graphs of varying degrees of cyclicity. As a result, a variety of graphical representations of varying structural richness can be explored to arrive at a succinct representation of a consensus view on the structure of a joint narrative. To this end, the main formal results are the representation of the participants’ agreement lexicographically in a linear objective function of a 0-1 program, and the translation of the requisites of the compactness and cyclicity of the resulting pruned graphs into a set of network flow constraints. The problem of identifying a consensus graphical representation is a general one and our graph pruning method has application potential outside the specific domain of narrative development as well.},
  archive      = {J_EJOR},
  author       = {Teemu Seeve and Eeva Vilkkumaa and Alec Morton},
  doi          = {10.1016/j.ejor.2025.04.048},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {540-558},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A structured framework for supporting the participatory development of consensual scenario narratives},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Index policies for campaign promotion strategies in reward-based crowdfunding. <em>EJOR</em>, <em>327</em>(2), 515-539. (<a href='https://doi.org/10.1016/j.ejor.2025.07.020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reward-based crowdfunding plays a crucial role in fundraising for start-up entrepreneurs. Recent studies, however, have shown that the actual success rate of fundraising projects is surprisingly low across multiple crowdfunding platforms. This paper considers crowdfunding platforms’ decision-making of selecting projects to highlight on their homepage to boost the chance of success for projects, and investigates promotion strategies aiming at maximizing platforms’ revenue over a fixed period. We characterize backers’ investment decisions by a discrete choice model with a time-varying coefficient of herding effect, and formulate the problem as a stochastic dynamic program, which is however computationally intractable. To address this issue, we follow the Whittle’s Restless Bandit approach to decompose the problem into a collection of single-project problems and prove indexability for each project under some mild conditions. We show that the index values of the proposed index policy can be directly derived from the value-to-go of each project under the non-promotion policy, which is calculated recursively offline with a linear-time complexity. Moreover, to further enhance the scalability we develop a closed-form approximation to calculate the index values online. To the best of our knowledge, this work is the first in the literature to develop index policies for campaign promotions in reward-based crowdfunding. It is also the first attempt to provide indexability analysis of bi-dimensional restless bandits coupled by not only resource but also demand. Extensive numerical experiments show that the proposed index policies outperform the other benchmark heuristics in most of the scenarios considered.},
  archive      = {J_EJOR},
  author       = {Chenguang Wang and Dong Li and Baibing Li},
  doi          = {10.1016/j.ejor.2025.07.020},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {515-539},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Index policies for campaign promotion strategies in reward-based crowdfunding},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Singular control in a cash management model with ambiguity. <em>EJOR</em>, <em>327</em>(2), 500-514. (<a href='https://doi.org/10.1016/j.ejor.2025.07.023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a singular control model of cash reserve management, driven by a diffusion under ambiguity. The manager is assumed to have maxmin preferences over a set of priors characterized by κ -ignorance. A verification theorem is established to determine the firm’s cost function and the optimal cash policy; the latter taking the form of a control barrier policy. In a model driven by arithmetic Brownian motion, we use Dynkin games to show that an increase in ambiguity leads to higher expected costs under the worst-case prior and a narrower inaction region. The latter effect can be used to provide an ambiguity-driven explanation for observed cash management behavior. Our findings can be applied to broader applications of singular control in managing inventories under ambiguity.},
  archive      = {J_EJOR},
  author       = {Arnon Archankul and Giorgio Ferrari and Tobias Hellmann and Jacco J.J. Thijssen},
  doi          = {10.1016/j.ejor.2025.07.023},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {500-514},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Singular control in a cash management model with ambiguity},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fair and profitable even when serving different customer classes: How pricing and lead-time quotation can help. <em>EJOR</em>, <em>327</em>(2), 491-499. (<a href='https://doi.org/10.1016/j.ejor.2025.05.034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we model a production/inventory system serving two classes of customers with a single type of product. Demand from each class depends on the price and the lead-time quoted. One class comprises customers sensitive to delays who are willing to pay higher prices for shorter lead times. Customers of the other class are price sensitive who can tolerate waiting longer for product delivery if they are charged lower prices. By modeling the system as an M n / M / 1 type make-to-stock queue, we propose four fair policies. These fair policies assure that customers are charged lower prices when they are quoted longer lead times and a high proportion of the deliveries is made during the quoted lead times. Two FCFS (first-come, first-served) policies ignore class differences. Two multilevel rationing (MR) policies prioritize the delay-sensitive class over the other. While determining the price and the lead-time, the refined FCFS and MR policies additionally consider the order in which a customer enters the queue. With a numerical study, we explore when the MR policies taking customer differences into consideration are more profitable than the FCFS policies.},
  archive      = {J_EJOR},
  author       = {Sinan Dede and Barış Balcıog̃lu},
  doi          = {10.1016/j.ejor.2025.05.034},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {491-499},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fair and profitable even when serving different customer classes: How pricing and lead-time quotation can help},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nested branch-and-price for multi-mode nanosatellite task scheduling with interior-point regularization and GPU acceleration. <em>EJOR</em>, <em>327</em>(2), 469-490. (<a href='https://doi.org/10.1016/j.ejor.2025.05.020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capabilities of nanosatellites are constrained by their limited power availability and size, which poses challenges for mission planning and operation. This study addresses the Offline Nanosatellite Task Scheduling (ONTS) problem by introducing multi-mode capability into the scheduling process, enhancing its relevance for more realistic, adaptable, and robust mission planning. We propose a Mixed-Integer Linear Programming (MILP) model for this problem that accommodates conventional resource and temporal constraints across multiple operational modes. The MILP model is improved with valid inequalities incorporating auxiliary variables alongside multi-mode cover cuts enhanced with lifting procedures. Furthermore, we introduce a Nested Branch-and-Price (NB&P) algorithm that enhances the standard branch-and-price approach by incorporating a dual-level optimization structure for handling hierarchical scheduling. This dual framework simultaneously facilitates job allocation and mode selection, employing dynamic column generation influenced by dual prices to progressively refine task schedules towards optimality. Additionally, enhanced interior-point methods have been effectively adapted for tackling large-scale instances, aligned with a GPU-accelerated dynamic programming solution utilizing CUDA technology. Empirical evaluations show that the modified MILP approach, combined with the NB&P algorithm, significantly improves computational efficiency, demonstrating up to a 629-fold reduction in computation time and consistently achieving zero-gap solutions.},
  archive      = {J_EJOR},
  author       = {Laio Oriel Seman and Cezar Antônio Rigo and Eduardo Camponogara and Pedro Munari},
  doi          = {10.1016/j.ejor.2025.05.020},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {469-490},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nested branch-and-price for multi-mode nanosatellite task scheduling with interior-point regularization and GPU acceleration},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An exact algorithm for fleet co-deployment and slot co-chartering in a sustainable shipping alliance under emissions trading system. <em>EJOR</em>, <em>327</em>(2), 450-468. (<a href='https://doi.org/10.1016/j.ejor.2025.05.021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shipping alliances have emerged as a cooperation platform between independent shipping companies, aiming to enhance customer satisfaction and exploit the economies of scale through capacity and information sharing. A sustainable shipping alliance should operate in a profitable, fair and environmentally friendly way under emerging Emissions Trading System (ETS). A non-convex mixed-integer nonlinear programming model is suggested to jointly optimize the fleet co-deployment in the network, sailing speed in each shipping leg, schedule design for each shipping service, and the slot allocation and co-chartering for each alliance member. These decisions ultimately determine each company’s carbon emissions. Under the ETS, companies are charged for emissions that exceed their allowances, while any surplus allowances can be traded for revenue in carbon markets. In addition to maximizing the alliance’s total profit, this study minimizes profit margin variation among members in proportion to their investment, promoting fairness in a novel way. A tailored spatial branch-and-bound (SB&B) algorithm is developed to deliver the global optimal solution for the problem. Novel problem relaxation and branching strategies are suggested based on the structure of the programming model. The SB&B algorithm significantly outperforms an existing non-convex nonlinear solver. Compared to case which do not consider slot co-chartering and fairness, our study improves total profit by 3.13 %, meets 0.52 % more freight demand, and ensures a fairer profit distribution on average. Under the ETS, carbon emissions can be reduced by up to 54.3 %, with smaller ships being used and average sailing speeds decreasing as the emission trading price rises from $0/tonne to $300/tonne.},
  archive      = {J_EJOR},
  author       = {Yadong Wang and Shenghui Zhu and Çağatay Iris},
  doi          = {10.1016/j.ejor.2025.05.021},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {450-468},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An exact algorithm for fleet co-deployment and slot co-chartering in a sustainable shipping alliance under emissions trading system},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lagrangian relaxation and branch-and-price algorithm for resource assignment problem in divisional seru systems. <em>EJOR</em>, <em>327</em>(2), 432-449. (<a href='https://doi.org/10.1016/j.ejor.2025.02.038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses seru formation problem in divisional seru production system (SPS), which focuses on job-seru assignment, worker-seru assignment and operation-worker assignment in each seru. The problem is formulated as a mixed-integer nonlinear programming (MINLP) model with the objective of minimizing training and processing costs of workers. Once the job-seru assignment is determined, we employ a mixed-integer linear programming (MILP) model to describe worker-seru and operation-worker assignment in each seru. To tackle this challenge, we propose a two-phase approach to deal with this problem. In the first phase, we propose a Lagrangian relaxation algorithm to determine job-seru assignment, this approach can quickly compute the lower bound of the MILP by enumerating all possible job-seru assignments and eliminate unpromising ones. Subsequently, in the second phase, for each remaining job-seru assignment, we develop a branch-and-price algorithm to solve the MILP exactly. It is in the branch-and-bound framework, each node is solved by column generation (CG) algorithm. In CG, we apply a Dantzig Wolfe decompose to divide the original problem into a master problem and the pricing problems. A novel label-setting algorithm is employed based on the characteristics of the pricing problem. Additionally, we introduce effective acceleration strategies such as dominance rules and heuristic pricing. It facilitates the selection of the optimal job-seru assignment and obtains the optimal solution for the entire problem. Finally, extensive experiments validate the effectiveness and superiority of our proposed algorithm. We also discuss the impact of selected parameters on the cost and offer managerial insights.},
  archive      = {J_EJOR},
  author       = {Shiming Chen and Chengkuan Zeng and Yu Zhang and Jiafu Tang and Chongjun Yan},
  doi          = {10.1016/j.ejor.2025.02.038},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {432-449},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Lagrangian relaxation and branch-and-price algorithm for resource assignment problem in divisional seru systems},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The generalized assignment problem with fixed processing times and uniform processing costs to minimize total cost. <em>EJOR</em>, <em>327</em>(2), 420-431. (<a href='https://doi.org/10.1016/j.ejor.2025.05.031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generalized assignment problem (GAP) is a foundational problem in operations research, but its progress is quite limited. In this paper we study an important special case of the GAP with fixed processing times and uniform processing costs, where the upper bound of the makespan is given, and the objective to minimize the total processing cost. We prove a critical technical lemma, which enables us to develop an approximation algorithm with an improved performance ratio of 1 + ( γ − 1 ) ϵ , where ϵ ∈ ( 0 , 1 3 ] can be any small constant and γ is the maximum to the minimum processing cost per unit time on a machine, improving on the existing performance ratio of 2 + γ 3 in the literature. For the general problem when γ is arbitrarily, we show that it is NP-hard to approximate within a constant performance ratio. For the special case when γ is a constant, we present an efficient PTAS (polynomial time approximation scheme) by applying the technical lemma. Our techniques and results bring new insights into the GAP research.},
  archive      = {J_EJOR},
  author       = {Weidong Li and Jinwen Ou},
  doi          = {10.1016/j.ejor.2025.05.031},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {420-431},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The generalized assignment problem with fixed processing times and uniform processing costs to minimize total cost},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using helical polyhedron for online irregular strip packing problem with free rotations. <em>EJOR</em>, <em>327</em>(2), 407-419. (<a href='https://doi.org/10.1016/j.ejor.2025.05.019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The packing of irregular pieces is widely applied across various industries including metalworking, woodworking, clothing manufacturing, and leather goods production. Allowing rotation during packing, particularly in scenarios where materials are homogeneous, can yield superior outcomes by reducing material wastage, thus contributing to cost-saving and environmental preservation. This study investigates the online irregular strip packing problem allowing free rotation, inspired by a leather handicraft workshop, where orders arrive infrequently and vary widely in content. The objective is to minimize the sheet length utilized. Most existing literature models irregular strip packing problem with rotation as a nonlinear programming problem, making it challenging to obtain the optimal position and orientation of every single input piece despite advancements in optimization solvers. In this paper, a novel approach is proposed to solve online irregular strip packing problem with rotation. We rotate the input polygon while simultaneously translating it along the z -axis, forming a helix. Thus, the problem of selecting the rotation angle is transformed into determining the z -coordinate of the helix’s cross-section. Subsequently, meshing the helix into a polyhedron allows us to propose a mixed integer linear formulation based on its Minkowski sum with other polygons. To ensure guaranteed optimality, we introduce a branch-and-bound algorithm tailored to the problem. Extensive numerical experiments indicate the effectiveness and competitiveness of our algorithm over state-of-the-art nonlinear formulations for irregular strip packing problem with rotation.},
  archive      = {J_EJOR},
  author       = {Yulin Liu and Li Zheng},
  doi          = {10.1016/j.ejor.2025.05.019},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {407-419},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using helical polyhedron for online irregular strip packing problem with free rotations},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Presolving and cutting planes for the generalized maximal covering location problem. <em>EJOR</em>, <em>327</em>(2), 394-406. (<a href='https://doi.org/10.1016/j.ejor.2025.05.017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the generalized maximal covering location problem (GMCLP) which establishes a fixed number of facilities to maximize the weighted sum of the covered customers, allowing customer weights to be positive or negative. Due to the huge number of linear constraints to model the covering relations between the candidate facility locations and customers, and particularly the poor linear programming (LP) relaxation, the GMCLP is extremely difficult to solve by state-of-the-art mixed integer programming (MIP) solvers. To improve the computational performance of MIP-based approaches for solving GMCLPs, we propose customized presolving and cutting plane techniques, which are isomorphic aggregation, dominance reduction, and two-customer inequalities. The isomorphic aggregation and dominance reduction can not only reduce the problem size but also strengthen the LP relaxation of the MIP formulation of the GMCLP. The two-customer inequalities can be embedded into a branch-and-cut framework to further strengthen the LP relaxation of the MIP formulation on the fly. By extensive computational experiments, we show that all three proposed techniques can substantially improve the capability of MIP solvers in solving GMCLPs. In particular, for a testbed of 40 instances with identical numbers of customers and candidate facility locations in the literature, the proposed techniques enable us to provide optimal solutions for 13 previously unsolved benchmark instances; for a testbed of 336 instances where the number of customers is much larger than the number of candidate facility locations, the proposed techniques can turn most of them from intractable to easily solvable.},
  archive      = {J_EJOR},
  author       = {Wei Lv and Cheng-Yang Yu and Jie Liang and Wei-Kun Chen and Yu-Hong Dai},
  doi          = {10.1016/j.ejor.2025.05.017},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {394-406},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Presolving and cutting planes for the generalized maximal covering location problem},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fifty years of research in scheduling — Theory and applications. <em>EJOR</em>, <em>327</em>(2), 367-393. (<a href='https://doi.org/10.1016/j.ejor.2025.01.034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an overview of scheduling research done over the last half century. The main focus is on what is typically referred to as machine scheduling. The first section describes the general framework for machine scheduling models and introduces the notation. The second section discusses the basic deterministic machine scheduling models, including single machine, parallel machines, flow shops, job shops, and open shops. The third section describes more elaborate models, including multi-objective and multi-agent scheduling models, scheduling with controllable processing times, scheduling with rejection, just-in-time scheduling, scheduling with due date assignments, time-dependent scheduling, and scheduling with batching and setups. The two subsequent sections consider scheduling under uncertainty; section four goes into online and robust scheduling and section five covers stochastic scheduling models. The next section describes a variety of important scheduling applications, including applications in manufacturing, in services, and in information processing. The last section presents the main conclusions and discusses future research directions.},
  archive      = {J_EJOR},
  author       = {Alessandro Agnetis and Jean-Charles Billaut and Michael Pinedo and Dvir Shabtay},
  doi          = {10.1016/j.ejor.2025.01.034},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {367-393},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fifty years of research in scheduling — Theory and applications},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
