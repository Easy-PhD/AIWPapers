<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ASOC</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="asoc">ASOC - 189</h2>
<ul>
<li><details>
<summary>
(2025). Detail-aware semantic segmentation network for brain tumor MRI images combining multi-frequency directional filtering and lifting wavelets. <em>ASOC</em>, <em>185</em>, 113969. (<a href='https://doi.org/10.1016/j.asoc.2025.113969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors segmentation in Magnetic Resonance Imaging (MRI) images poses significant challenges owing to the uncertain location and size of the tumors, the difficulty in describing their boundaries, and the fuzzy demarcation of diseased tissues. Although U-Net and its recent variants have emerged as leading models for semantic segmentation in medical imaging, they still face structural limitations. These limitations cause the erosion of detail information during downsampling and poor performance in segmenting small lesions when handling targets of varying sizes, indicating a lack of detail handling capability. To counteract these issues, we designed a segmentation model that enhances detail features using frequency information. To reduce the loss of feature information during downsampling, we developed a downsampling module based on lifting wavelets. By lifting wavelets to group and integrate features according to frequency from high to low, we reduce feature resolution while enhancing information transmission and minimizing feature information loss. In our designed multi-frequency directional filtering edge feature extraction module, we extract low-frequency and high-frequency features and construct a dual-channel multi-directional filtering combination. This combination extracts directional information from low-frequency and high-frequency features separately, increasing the multi-angle directional information of the features and enriching the detailed information such as direction and position within the features. On the BraTS2018, BraTS2020, and BraTS2024 brain tumor datasets, our model demonstrated optimal results compared to 14 other advanced models. The average Dice Similarity Coefficients are 78.48 %, 79.80 %, and 74.35 %, while the 95th percentile Hausdorff Distances are 5.75, 6.60, and 7.72. Our code link is https://github.com/Eric-H8/BraTS_Seg_Model .},
  archive      = {J_ASOC},
  author       = {Xin Hua and Zhijiang Du and Hongjian Yu and Zibo Li and Qiaohui Lu and Hui Zhao},
  doi          = {10.1016/j.asoc.2025.113969},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113969},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Detail-aware semantic segmentation network for brain tumor MRI images combining multi-frequency directional filtering and lifting wavelets},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DT and LLM driven intelligent maintenance system for L-DED and DAG-based LLM fault diagnosis evaluation framework. <em>ASOC</em>, <em>185</em>, 113942. (<a href='https://doi.org/10.1016/j.asoc.2025.113942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal additive manufacturing (AM) has revolutionized industries such as aerospace and automotive manufacturing due to its ability to rapidly prototype complex structures. Laser Directed Energy Deposition (L-DED) is a key AM technique, offering high deposition rates and superior mechanical properties. However, the inherent complexity and high cost of L-DED equipment demand reliable maintenance management to minimize downtime. Traditional maintenance approaches struggle to keep pace with escalating production demands and to cope with growing equipment complexity. To address this, we propose a dual-driven intelligent maintenance system for L-DED, integrating Digital Twins (DT) and Large Language Models (LLMs). The system features a comprehensive DT framework that synchronizes the virtual entity with the physical one in real time, it also incorporates an intelligent maintenance Q&A assistant powered by Retrieval-Augmented Generation (RAG), leveraging L-DED maintenance knowledge bases to provide accurate operational support. Additionally, we propose a Directed Acyclic Graphs (DAG)-based framework to assess LLMs’ ability to guide users through complete fault diagnosis. Our work aims to enhance the reliability and efficiency of L-DED maintenance through advanced digital technologies, ultimately improving productivity and reducing downtime in additive manufacturing.},
  archive      = {J_ASOC},
  author       = {Jian Tang and Shitong Peng and Jianan Guo and Danya Song and Dongna Gao and Weiwei Liu and Fengtao Wang},
  doi          = {10.1016/j.asoc.2025.113942},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113942},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DT and LLM driven intelligent maintenance system for L-DED and DAG-based LLM fault diagnosis evaluation framework},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new large model with multi-scale feature fusion for fault diagnosis based on unified time series model. <em>ASOC</em>, <em>185</em>, 113941. (<a href='https://doi.org/10.1016/j.asoc.2025.113941'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large model technology exemplified by large language models has been applied in the field of industrial fault diagnosis. However, existing large models are optimized for specific equipment types and have yet to fully exploit the potential of time-series monitoring data to enable widespread application across diverse mechanical equipment in various industrial scenarios. To address this challenge, a fault diagnosis large model (UniTS-FD) is designed based on unified time series model (UniTS). First, a multi-scale feature fusion backbone network is developed based on UniTS backbone to capture general mechanical fault features. Second, the fault classification head integrates the Pearson correlation coefficient to assess the similarity of class information within linear space for enabling adaptive classification. Third, P-LoRA fine-tuning approach incorporating LoRA and prompt technology is proposed to fine-tune the fault classification head, which enhances the generalization ability of the UniTS-FD model for fault diagnosis tasks of various mechanical equipment. Finally, the UniTS-FD model is pre-trained on 11 fault datasets and fine-tuning experiments were conducted on four different fault datasets to achieve cross-machine fault diagnosis. Experimental results demonstrate the effectiveness of the UniTS-FD in fault diagnosis tasks.},
  archive      = {J_ASOC},
  author       = {Zhiwei Zhang and Chengbin Wei and Weimin Zhang and Long Wen},
  doi          = {10.1016/j.asoc.2025.113941},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113941},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A new large model with multi-scale feature fusion for fault diagnosis based on unified time series model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling. <em>ASOC</em>, <em>185</em>, 113920. (<a href='https://doi.org/10.1016/j.asoc.2025.113920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agentic workflows, powered by Industrial Large Models (ILMs), represent a significant development emphasizing collaboration between humans and intelligent systems. This paper presents a structured perspective on the role of agentic workflows for smart design and manufacturing, grounded in integrating ILMs. We define an agentic workflow as a labeled Activity-on-Vertex (AOV) graph, where each node represents a functionally closed subtask and is executed by an ILM-based agent, a human operator, or an automated system. This formalism supports analyzable, modular, and hybrid execution, offering a foundation for modeling complex, mixed-initiative processes in manufacturing environments. To support real-world deployment, we introduce a set of reusable agentic workflow patterns that describe how ILM agents perceive, plan, and act in coordination with other components. Besides, a proof-of-concept case study illustrates the practical application of the human-in-the-loop framework through the agentic generation of CAD models. The study covers task decomposition, workflow implementation, and benchmarking, providing evidence for the feasibility of agentic workflows. Building upon these findings, this work contributes to advancing the development and application of agentic workflows in smart manufacturing contexts.},
  archive      = {J_ASOC},
  author       = {Keyou Zheng and Yuanwei Zhong and Xuyang Su and Jiewu Leng and Qiang Liu and Xin Chen},
  doi          = {10.1016/j.asoc.2025.113920},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113920},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time traffic flow optimization using large language models and reinforcement learning for smart urban mobility. <em>ASOC</em>, <em>185</em>, 113917. (<a href='https://doi.org/10.1016/j.asoc.2025.113917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of metropolitan populations causes transportation network congestion, which increases fuel usage, travel time, and environmental damage. Traditional traffic management systems (TMS) seldom handle these issues in real time. Recently developed Large Language Models (LLMs), especially those using Reinforcement Learning (RL), may enhance urban transportation systems. Traffic management technology's real-time flexibility and shifting congestion patterns provide improved potential. Traditional approaches cannot estimate traffic flow or adapt to urban settings. A strong AI-driven method is needed to improve urban mobility and traffic flow. This paper introduces the LLM-RL Traffic Optimization Framework (LLM-RL-TOF). LLMs analyze real-time traffic data and give predictive insights in this context. Due to these new insights, the RL algorithm can improve traffic flow in real time and reduce congestion via dynamic traffic management. IoT sensors and urban traffic cameras capture real-time traffic data, including traffic volume and incidents. This data helps the LLM estimate bottlenecks, accidents, and traffic congestion. An RL agent uses LLM outputs to adjust traffic signal timing and suggest alternate routes. With real-time alternatives, traffic flow and urban mobility may be optimized. The junction throughput rate rose 17.5 %, the queue length accumulation index fell 22.3 %, and the average vehicle delay fell 18.6 %. The decrease in average vehicle delay enabled all these gains.},
  archive      = {J_ASOC},
  author       = {Arvind R. Singh and Muhammad Wasim Abbas Ashraf and Rajkumar Singh Rathore and Bin Li and M.S. Sujatha},
  doi          = {10.1016/j.asoc.2025.113917},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113917},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Real-time traffic flow optimization using large language models and reinforcement learning for smart urban mobility},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wind turbine blades defect detection based on global and local attention with multi-feature fusion. <em>ASOC</em>, <em>185</em>, 113914. (<a href='https://doi.org/10.1016/j.asoc.2025.113914'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind turbine blades are prone to small-scale defects—such as cracks, corrosion, and contamination—during long-term operation. Accurate detection of these defects is essential for ensuring the safety and efficiency of wind power systems. However, small-object detection remains challenging due to limited feature representation and weak discriminative cues. To address this, an enhanced YOLOX-s-based framework called Global-Frequency Dual-aware YOLOX (GFD-YOLOX) is proposed. GFD-YOLOX introduces three main improvements. First, the Path Aggregation Feature Pyramid Network (PAFPN) in the neck is replaced with Dual-Frequency Fused Bidirectional Feature Pyramid Network (DFF-BiFPN) to strengthen multi-scale contextual representation. Second, the backbone bottleneck is redesigned with a lightweight structure, improving computational efficiency and convergence speed. Third, a Hierarchical Frequency-Adaptive Fusion (HFAF) module is integrated to enhance cross-scale feature interaction by combining fine-grained and global information. On the self-constructed WTBlade-Defect dataset (3570 annotated images, five defect types: corrosion, hide-craze, surface-eye, thunderstrike, dirt), GFD-YOLOX achieves mAP@0.5 and mAP@0.5:0.95 scores of 94.5 % and 68.9 %, respectively, with 44.3 FPS inference—improving by 13.6 % and 14.4 % over state-of-the-art models. On the public dataset of Ashley Foster et al., it achieves 94.8 % and 69.3 %, with gains of 10.4 % and 10.9 %. These results demonstrate that GFD-YOLOX delivers substantial accuracy gains while maintaining real-time speed and strong cross-dataset generalization, indicating high potential for deployment in operational wind turbine inspection systems.},
  archive      = {J_ASOC},
  author       = {Dandan Liu and Mingjie Liu},
  doi          = {10.1016/j.asoc.2025.113914},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113914},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Wind turbine blades defect detection based on global and local attention with multi-feature fusion},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval multi-feature sparse transformer-CNN: A synergistic approach to precise and efficient spatio-temporal wind speed interval-value prediction. <em>ASOC</em>, <em>185</em>, 113910. (<a href='https://doi.org/10.1016/j.asoc.2025.113910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable wind speed prediction is critical for stabilizing wind power integration. However, current methods are limited by accuracy and stability issues, hindering their large-scale application in wind farms. To overcome these problems, this study innovatively proposes an IMFSformer-CNN model integrating three core components. First, the spatio-temporal and multi-factor feature extraction technology comprehensively captures the spatio-temporal patterns and complex dependencies of wind speed dynamics, incorporating multiple factors such as meteorological variables and spatial correlation. Second, the multi-feature sparse attention mechanism reduces computational complexity by combining sparse attention with multi-feature attention, enhancing representation ability and scalability for precise interval value prediction. Finally, the enhanced interval spatio-temporal prediction fusion model combines the global dependency modeling capabilities of the improved Transformer architecture with the local receptive field advantages of CNN. This hybrid design facilitates the simultaneous capture of both macro-scale atmospheric patterns and micro-scale wind speed fluctuations. The model achieved prediction interval coverage probabilities of 0.921 and 0.899, and coverage width criteria of 1.493 and 3.776, outperforming other models on both datasets. This significantly enhances accuracy and practical value for wind farm cluster forecasting, supporting more reliable and efficient wind energy integration into power grids.},
  archive      = {J_ASOC},
  author       = {Weiyi Jiang and Jujie Wang and Xuecheng He},
  doi          = {10.1016/j.asoc.2025.113910},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113910},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval multi-feature sparse transformer-CNN: A synergistic approach to precise and efficient spatio-temporal wind speed interval-value prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity spatiotemporal fusion neural network with denoising reconstruction for human motion prediction. <em>ASOC</em>, <em>185</em>, 113909. (<a href='https://doi.org/10.1016/j.asoc.2025.113909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction has significant application value in many fields. However, existing methods often fail to fully capture the spatial relationships between joints and the temporal flow of information when modeling complex spatiotemporal dependencies. Additionally, these methods are prone to overfitting dominant features while neglecting other important aspects, and struggle with perceiving contour features effectively. To address these issues, this study introduces a novel encoder-decoder framework. The encoder generates a dual-layer adaptive adjacency matrix using a distance partition strategy to parameterize joint relationships, while incorporating a gating mechanism to control the temporal flow of information. The decoder then employs separate spatiotemporal attention modules to decode temporal and spatial features independently. These features are subsequently reconstructed through a spatiotemporal fusion strategy, effectively decoupling and modeling complex spatiotemporal dependencies. To address the issue of overfitting to dominant features, we introduce a denoising reconstruction strategy that allows the model to learn richer combinations of spatiotemporal features under multiple constraints. Furthermore, a multi-granularity information adaptive fusion module is incorporated to achieve adaptive fusion of both local and contour features. Experimental results across several benchmark datasets demonstrate that our method significantly outperforms the state-of-the-art approaches, showcasing its effectiveness in human motion prediction tasks.},
  archive      = {J_ASOC},
  author       = {Yong Li and Linfeng Zhu and Haofei Xie and Xinchang Yi},
  doi          = {10.1016/j.asoc.2025.113909},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113909},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-granularity spatiotemporal fusion neural network with denoising reconstruction for human motion prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the risk level of saltwater intrusion in the modaomen waterway of the pearl river estuary based on the deep temporal clustering model. <em>ASOC</em>, <em>185</em>, 113897. (<a href='https://doi.org/10.1016/j.asoc.2025.113897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, extreme events caused by global climate change have intensified the phenomenon of saltwater intrusion (SWI) in estuaries. The nonlinear and non-stationary characteristics of estuarine SWI have led to an exponential decline in the timeliness of traditional regression prediction models, making it difficult to meet the operational needs of SWI forecasting. To address this, this study proposed a technical framework for SWI risk level forecasting based on temporal clustering, with its core innovation lying in algorithmic improvements for accurately characterizing complex disaster systems. The key challenges in forecasting SWI risk levels involved capturing the dynamic nonlinear relationships between multidimensional disaster factors (such as runoff, tide level, and wind) and SWI severity, as well as enhancing feature discriminability in label-limited scenarios. Accordingly, this study optimized algorithms through dual-path supervised and unsupervised learning: In the supervised learning framework, LightGBM, RF, XGBoost, and Extra trees were introduced as base learners into the Deep Forest (DF) model. The complementary feature-space partitioning of diverse learners was leveraged to improve the model’s ability to distinguish risk -level boundaries, achieving an average performance gain of 7.8 %. In the unsupervised learning framework, discriminative regularization was incorporated into the Extreme Learning Machine-Autoencoder (ELM-AE) model. By forcing features of samples from the same class to cluster toward the class center, the model’s feature separability for rare events (e.g., severe SWI) was enhanced, leading to an average performance improvement of 11 %. Finally, the optimal model was used to extract dynamic evolution patterns between multidimensional disaster factors and SWI risk levels, with interpretability analysis conducted for real-world forecasting. Notably, upstream flow sequences exhibited high distinguishability between no-SWI and severe-SWI, while mild and moderate SWI showed similar flow patterns, with tidal sequences being the primary differentiator. The algorithmic advancements not only enhanced the accuracy and efficiency of SWI forecasting but also provided a generalizable framework for risk classification in nonlinear hydrological systems.},
  archive      = {J_ASOC},
  author       = {Qingqing Tian and Hongyu Yang and Yu Tian and Peiyao Weng},
  doi          = {10.1016/j.asoc.2025.113897},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113897},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of the risk level of saltwater intrusion in the modaomen waterway of the pearl river estuary based on the deep temporal clustering model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning with mirror-task for multimodal sentiment analysis. <em>ASOC</em>, <em>185</em>, 113896. (<a href='https://doi.org/10.1016/j.asoc.2025.113896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Task Learning (MTL) in Multimodal Sentiment Analysis (MSA) involves implementing various parameter-sharing strategies among tasks. Currently, MSA primarily focuses on hard parameter-sharing mechanisms based on encoder sharing, while soft parameter-sharing is often neglected. To explore a reasonable combination of soft and hard mechanisms in MSA and optimize multimodal representations, along with multimodal contrastive learning, we propose D 3 MSA. It consists of D ouble network (primaryNet and MirrorNet), D ouble parameter-sharing strategies and D ouble contrastive learning modes for multimodal sentiment analysis. D 3 MSA utilizes hard-sharing to consolidate correlations between positive samples of intra-sample contrastive learning. In soft-sharing, we propose a pre-trained MirrorNet (MN) that generates negative samples by the learned inverse distributions. This optimizes the feature space of negative samples. MN interacts with the MSA task through soft-sharing during inter-sample contrastive learning. Experimental results demonstrate that our proposed method can achieve advanced performance on the CMU-MOSI and CMU-MOSEI datasets with lightweight training that requires only a small number of parameters.},
  archive      = {J_ASOC},
  author       = {Hang Shi and Lianmin Zhou and Yuanyuan Pu and Zhengpeng Zhao and Jinjing Gu and Dan Xu},
  doi          = {10.1016/j.asoc.2025.113896},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113896},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Contrastive learning with mirror-task for multimodal sentiment analysis},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nearest-best neighbors optimization algorithm for constrained multimodal multiobjective problems. <em>ASOC</em>, <em>185</em>, 113895. (<a href='https://doi.org/10.1016/j.asoc.2025.113895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multimodal multiobjective problems (CMMOPs) have multiple equivalent constrained Pareto optimal sets in the decision space corresponding to the identical constrained Pareto front in the objective space. The key to solving CMMOPs is how to balance feasibility, convergence, and diversity of solutions in both the decision and objective spaces. In view of this, this paper proposes a Nearest-Best neighbors optimization algorithm with constraint-based fitness (NBNOA) to solve CMMOPs. First, a constraint-based fitness assignment scheme is designed to assign specific fitness values to individuals in the population. Then, the Nearest-better-neighbor clustering method is adopted to identify the nearest-better neighbor and best neighbor of each individual according to the specific fitness values. On this basis, a Nearest-Best neighbors guided strategy is developed to guide the search direction of individuals, striking a better balance between exploration and exploitation capabilities. Moreover, a CDP-density elite selection mechanism is constructed to obtain feasible Pareto optimal solutions with higher precision and better diversity. Extensive experiments on two CMMOPs test suites demonstrated that the proposed NBNOA significantly outperforms nine state-of-the-art algorithms. Notably, NBNOA ranks first among all ten algorithms and achieves the best values for 23 out of 31 benchmark functions regarding the reciprocal of Pareto sets proximity and inverted generational distance. Furthermore, NBNOA is applied to a real-world CMMOP, verifying its effective practical application capability. Additionally, NBNOA is tested on two high-dimensional constrained multiobjective optimization problems test suites, further proving its competitive performance in solving complex problems.},
  archive      = {J_ASOC},
  author       = {Xuming Han and Ting Zhou and Limin Wang and Yali Chu},
  doi          = {10.1016/j.asoc.2025.113895},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113895},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A nearest-best neighbors optimization algorithm for constrained multimodal multiobjective problems},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency decomposition and patch modeling framework for time-series forecasting. <em>ASOC</em>, <em>185</em>, 113890. (<a href='https://doi.org/10.1016/j.asoc.2025.113890'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is widely applied across diverse fields, including finance, transportation, and energy, and has made significant contributions in these areas. However, in real-world applications, time series data can be complex and dynamic. Current methodologies still encounter several challenges in managing high-dimensional data, extracting intricate features, and making long-term forecasts. In this study, we propose a Frequency Decomposition and Patch Modeling Framework (FPF). Our FPF consists of the Frequency Domain Decomposition Block (FDB) and the Dual Patch Modeling Block (DPMB). DPMB consists of Patch Enhancement Block and Patch Mixing Block. First, FDB transforms the input sequence to the frequency domain through the Fast Fourier Transform and designs frequency masks to decompose the data into high-frequency and low-frequency components, to extract fast-changing patterns and trend information respectively. Subsequently, DPMB divides the components into patches, where the high-frequency components are modeled by MLP-based Patch Enhancement Block to capture local features, and the low-frequency components are modeled by Transformer-based Patch Mixing Block to capture global dependencies and cross-patch correlations. We conducted comprehensive experiments using seven real-world time series forecasting datasets, including ETT, Traffic, Electricity, and Weather. The findings indicate that this method demonstrates superior performance in the field of time series forecasting.},
  archive      = {J_ASOC},
  author       = {Denghui Xu and Hua Wang and Fan Zhang},
  doi          = {10.1016/j.asoc.2025.113890},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113890},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Frequency decomposition and patch modeling framework for time-series forecasting},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density peak clustering algorithm based on boundary elimination and backbone construction. <em>ASOC</em>, <em>185</em>, 113880. (<a href='https://doi.org/10.1016/j.asoc.2025.113880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peak clustering (DPC) is an effective clustering algorithm, but it still has some problems and faces some challenges. For instance, it cannot identify the variable density datasets, the assignment strategy is easy to produce domino phenomenon, and the clustering results of DPC and its improved algorithms are easily affected by the intersection points between clusters. To solve these problems, in this paper, we propose a novel density peak clustering algorithm based on boundary elimination and backbone construction, called BEBC-DPC. A new local density is defined based on the natural neighbor search, and the boundary degree is defined by the position relationship between each point and its neighbors, which accurately describes the local distribution information of the point. The boundary points of clusters are eliminated by fusing the density and the boundary degree, which reduces the influence of the intersection points on the cluster division. In addition, the cluster backbone construction method based on representative points and representative sets is proposed. The density relationship among non-boundary points is used to form representative sets, and the similarity between representative sets is used to construct the cluster backbones, which can effectively describe the overall distribution structure characteristics of the clusters. Moreover, the adjacency degree of each boundary point is defined by using the neighbor information and distance information, and the boundary points are gradually assigned to the most appropriate cluster backbone based on it to complete the clustering. Finally, sufficient experiments are performed on synthetic, UCI and image datasets, and the proposed BEBC-DPC is compared with DPC and its improved algorithms. Experimental results show the effectiveness of the proposed BEBC-DPC on various types of datasets.},
  archive      = {J_ASOC},
  author       = {Zhizhong Zhao and Sugen Chen and Cong Hu},
  doi          = {10.1016/j.asoc.2025.113880},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113880},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Density peak clustering algorithm based on boundary elimination and backbone construction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliable type 2 fuzzy Min–Max neural networks for pattern classification. <em>ASOC</em>, <em>185</em>, 113875. (<a href='https://doi.org/10.1016/j.asoc.2025.113875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fuzzy Min–Max (FMM) algorithm is a powerful classification method capable of handling non-linear class boundaries and making both hard and soft decisions while learning from online data. However, it faces significant challenges, including sensitivity to the expansion coefficient, information loss during the contraction stage, and the overlap problem. To address these limitations, we propose a Reliable Type-2 Fuzzy Min–Max (RT2FMM) algorithm, which incorporates type-2 fuzzy logic to consider hyperbox uncertainty and effectively resolve the overlap problem. By assigning distinct certainties to overlapping regions, RT2FMM eliminates the need for the contraction stage and the overlap test. Additionally, we introduce weighted factors for hyperboxes, which enhances the reliability of membership values and models their mutual effects. Our comprehensive experimental evaluation across twenty datasets demonstrates that RT2FMM significantly outperforms existing FMM-based models in terms of robustness and accuracy. The Friedman test further confirms the superior performance of RT2FMM compared to commonly used classifiers, highlighting its potential as a robust solution for complex classification tasks.},
  archive      = {J_ASOC},
  author       = {Ali Nik-Khorasani and Mohammad-R. Akbarzadeh-T.},
  doi          = {10.1016/j.asoc.2025.113875},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113875},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Reliable type 2 fuzzy Min–Max neural networks for pattern classification},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fortifying vision models: A comprehensive survey of defences against adversarial examples. <em>ASOC</em>, <em>185</em>, 113874. (<a href='https://doi.org/10.1016/j.asoc.2025.113874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence and Machine learning (ML) have seen many advancements in the past two decades. It has led to the creation of several techniques, including Deep Neural Networks (DNN), Convolution Neural Networks (CNN), Autoencoders, Generative Adversarial Networks (GAN) and Diffusion models. These techniques have been applied to various real-world applications, such as self-driving cars, medical diagnosis and voice assistants. Despite these advancements, a carefully crafted input can fool the ML model. Such attacks are known as adversarial examples. It is a serious threat to safety critical systems. This survey provides a comprehensive review of defences against adversarial examples by tracing their evolution from early empirical methods to more principled, theoretically grounded approaches. We systematically categorise defences based on their underlying mechanisms. In addition to surveying state-of-the-art techniques, we spotlight emerging trends such as generative defences and diffusion-based purification. Finally, we identify persistent vulnerabilities and outline promising directions for future research towards building truly resilient vision models. This work aims to equip researchers and practitioners with a deep understanding of current defences and inspire innovation in adversarial robustness for the next generation of vision applications.},
  archive      = {J_ASOC},
  author       = {Siddheshwar Kumar and Shashank Srivastava and Shashwati Banerjea},
  doi          = {10.1016/j.asoc.2025.113874},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113874},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fortifying vision models: A comprehensive survey of defences against adversarial examples},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AOT-PixelNet: Lightweight and interpretable detection of forged images via adaptive orthogonal transform. <em>ASOC</em>, <em>185</em>, 113873. (<a href='https://doi.org/10.1016/j.asoc.2025.113873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative image detection faces persistent challenges in terms of generalization and interpretability, limiting its reliability in complex scenarios. To address these issues, we propose AOT-PixelNet, a lightweight and interpretable detection framework that integrates an Adaptive Orthogonal Transform (AOT) module with a streamlined 1 × 1 convolution-based PixelNet architecture. The AOT module leverages diverse orthogonal transforms, such as FFT and DCT, to extract informative frequency-domain features, thereby enhancing sensitivity to medium- and high-frequency artifacts. Meanwhile, PixelNet minimizes parameter count (only 0.98 million) while effectively capturing cross-channel inconsistencies and mitigating overfitting. Experimental evaluations on multiple unseen GAN and diffusion-based datasets demonstrate that AOT-PixelNet achieves superior performance with minimal computational cost. Specifically, it outperforms the NPR method by 0.6% and 11.76% on the ForenSynths and GenImage datasets, respectively, validating the framework’s robustness, effectiveness, and interpretability.},
  archive      = {J_ASOC},
  author       = {Dengtai Tan and Deyi Yang and Boao Tan and Chengyu Niu and Yang Yang and Shichao Li},
  doi          = {10.1016/j.asoc.2025.113873},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113873},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AOT-PixelNet: Lightweight and interpretable detection of forged images via adaptive orthogonal transform},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Status prediction using attentive and cascaded deep network by fault tolerant and priority-based scheduling for load balancing in cloud. <em>ASOC</em>, <em>185</em>, 113872. (<a href='https://doi.org/10.1016/j.asoc.2025.113872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cloud facilitates the user to complete their work utilizing the cost strategy of pay-as-you-go, which is based on the consumed Virtual Machine (VM) hours. Thus, the scheduler must offer the highest throughput to attain efficient allocation of resources in the cloud paradigm. Cloud services are dependent on characteristics such as fault tolerance, security, scalability, and availability. Hence, an effective scheduler is necessary to arrange the scheduling tasks and adjust the server loads. Typically, a load-balancing task focuses on detecting the overloaded and under-loaded nodes and adjusting the load between them. When considering the significant role of fault-tolerance in load-balancing algorithms, it seems to suffer from poor organization and a lack of in-depth experiments in this sector. This paper proposes a new task for the load-balancing operation. Initially, task scheduling is performed where the fault tolerance and the priority-aided scheduling approach are adopted. Furthermore, resource optimization is carried out in the scheduling task using Randomly Improved Electric Fish Optimization (RIEFO). To validate the load balancing operation, several multi-objective functions such as resource utilization, delay, time, makespan, active servers, throughput, success rate, fault tolerance rate, and energy consumption are derived. Moreover, because of the system’s dynamic environment, the status of the server varies simultaneously. The server status prediction is significant in allocating the tasks to the server or the VM resources. Thus, the Attention-based Cascaded Residual Bidirectional Long Short-Term Memory (ACRes-BiLSTM) is employed to predict the server status before performing the resource allocation. Finally, the tasks are scheduled effectively using the predicted server status. The performance is estimated using numerous performance metrics.},
  archive      = {J_ASOC},
  author       = {Gudivada Lokesh and Kasarapu Ramani and K.K. Baseer},
  doi          = {10.1016/j.asoc.2025.113872},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113872},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Status prediction using attentive and cascaded deep network by fault tolerant and priority-based scheduling for load balancing in cloud},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid deep learning framework for detecting grape leaf diseases by integrating ResNeSt-50 and CBAM attention into DeepLabv3 +. <em>ASOC</em>, <em>185</em>, 113871. (<a href='https://doi.org/10.1016/j.asoc.2025.113871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grape leaf diseases, such as black rot, powdery mildew, and downy mildew, pose a significant threat to global viticulture, leading to substantial yield losses and reduced fruit quality. Early and accurate identification of these diseases is essential for precision agriculture and sustainable crop management. This study presents a comprehensive comparison of traditional and deep learning-based image segmentation methods for detecting grape leaf lesions. A series of classical segmentation techniques, including Mean Shift, Fuzzy C-Means (FCM), Normalized Cut, K-Means, and Fuzzy K-Means (FKM), were evaluated alongside an advanced DeepLabv3 + model. The baseline DeepLabv3 + architecture was further enhanced by integrating a ResNeSt-50 backbone with various attention mechanisms, including Squeeze-and-Excitation (SE) Block, Convolutional Block Attention Module (CBAM), Bottleneck Attention Module (BAM), Self-Attention, and Dual Attention Network (DANet). Among all models, DeepLabv3 + with ResNeSt-50 and CBAM achieved the highest performance, attaining 98.2 % accuracy, 97.1 % precision, 96.7 % recall, 96.6 % mean Intersection over Union (mIoU), and a 96.8 % Dice Score. The results demonstrate that attention-augmented deep networks significantly outperform classical methods, especially in handling complex lesion structures under diverse environmental conditions. While traditional algorithms remain useful in resource-constrained scenarios, deep learning models, particularly those enhanced with spatial and channel-wise attention, offer greater accuracy and robustness, making them ideal for integration into intelligent agricultural platforms such as drones, mobile scanners, and automated disease monitoring systems. Future work will focus on incorporating temporal and multimodal data, expanding dataset diversity, and optimizing lightweight models for real-time deployment on edge devices.},
  archive      = {J_ASOC},
  author       = {Kittipol Wisaeng},
  doi          = {10.1016/j.asoc.2025.113871},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113871},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A hybrid deep learning framework for detecting grape leaf diseases by integrating ResNeSt-50 and CBAM attention into DeepLabv3 +},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic proportional–differential TLBO algorithm and its applications for wafer transfer finger. <em>ASOC</em>, <em>185</em>, 113870. (<a href='https://doi.org/10.1016/j.asoc.2025.113870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Teaching-Learning-Based optimization (TLBO) algorithm, which includes teacher phase and learner phase, is a widely used method for global optimization. However, TLBO will experience premature convergence and get stuck in local optimum when faced with complex optimization challenges. Especially when tackling complex problems in practical engineering applications, which involves multiple variables and numerous constraints. To address this issue, a new variant termed Stochastic Proportional–Differential TLBO (SPD-TLBO) has been developed. The SPD phase allows students to learn not only from the current population but also from previous stochastic errors and their generation differences using adaptive random operators. By incorporating an SPD operator into the original TLBO framework, the algorithm’s search diversity is enhanced, reducing the likelihood of premature convergence to local optimum. The experimental results conducted at the IEEE Conference on Evolutionary Computation 2014 (CEC 2014) indicated that the proposed SPD-TLBO algorithm achieved an effective balance between exploration and exploitation capabilities. Specifically, the SPD-TLBO algorithm achieves the highest ranking in 21 out of 30 cases (70%) for 30-dimensional problems and 18 out of 30 cases (60%) for 50-dimensional problems. Statistical tests and convergence analyses show that the SPD-TLBO algorithm outperforms other algorithms in solving global optimization problems. Additionally, when applied to engineering optimization problems, the SPD-TLBO algorithm shows significant advantages over other algorithms. Therefore, the SPD-TLBO algorithm is further applied to optimize the structure of a wafer transfer finger in semiconductor manufacturing.},
  archive      = {J_ASOC},
  author       = {Jinfeng Sun and Yunlang Xu and Haibo Zhou},
  doi          = {10.1016/j.asoc.2025.113870},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113870},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A stochastic proportional–differential TLBO algorithm and its applications for wafer transfer finger},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the health effects of COVID using hybrid classifier with attention-based LSTM-deep temporal convolution network. <em>ASOC</em>, <em>185</em>, 113867. (<a href='https://doi.org/10.1016/j.asoc.2025.113867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus Disease 2019 (COVID-19) is an infectious illness that affects both humans and animals. Individuals infected with COVID-19 are prone to lung complications during the recovery phase . Radiography and Computed Tomography (CT) are the most commonly used methods for diagnosing lung-related diseases. The primary aim of this paper is to assess the impact of COVID-19 on patients’ lungs, heart, and blood sugar levels using a deep learning-based approach. Initially, data related to the heart, blood sugar levels, and lungs of COVID-19-infected individuals are collected. From this dataset, three types of features are extracted. Deep features are obtained using Iterated Dilated Convolutional Neural Networks (IDCNN). From these deep features, which are obtained from the IDCNN, the optimal weighted features are derived by implementing the Hybrid Dolphin Pod Cuttlefish Optimization (HDPCO) algorithm. Subsequently, the HDPCO algorithm is also employed for optimal feature extraction. In addition, dimensionality reduction is performed using Principal Component Analysis (PCA). These three sets of features from the IDCNN, HDPCO, and PCA, are then fused into a single feature set . This fused feature set is fed into a hybrid classifier composed of a Deep Temporal Convolutional Network (DTCN) and an Attention-based Long Short-Term Memory (ALSTM) network . The classifier parameters are optimized using the HDPCO algorithm. The output from the hybrid classifier provides the final prediction result. Experimental results demonstrate that the proposed COVID-19 impact prediction model significantly outperforms existing models in terms of prediction accuracy and efficiency.},
  archive      = {J_ASOC},
  author       = {Sadanandam Kalvala and B. Baranidharan},
  doi          = {10.1016/j.asoc.2025.113867},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113867},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of the health effects of COVID using hybrid classifier with attention-based LSTM-deep temporal convolution network},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum fuzzy logic for edge detection: A demonstration on NISQ hardware. <em>ASOC</em>, <em>185</em>, 113866. (<a href='https://doi.org/10.1016/j.asoc.2025.113866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing offers the potential to enhance computational efficiency beyond classical methods, but practical implementation remains challenging due to the limitations of Noisy Intermediate-Scale Quantum (NISQ) hardware, namely, restricted qubit counts, limited connectivity, and the presence of noise and decoherence. This study presents a novel approach to edge detection by leveraging a recently developed Quantum Fuzzy Inference Engine, implemented on a NISQ device. We introduce an optimized quantum circuit for its implementation, reducing qubit requirements and gate depth to improve execution on NISQ hardware. To overcome constraints related to large-scale image processing, a hybrid quantum–classical lookup table approach is employed. Edge detection performance is evaluated on the Berkeley Segmentation Data Set and Benchmarks 500 dataset under different conditions, including classical execution, ideal quantum simulation, noisy quantum simulation, and NISQ hardware calculation. Results demonstrate that the quantum fuzzy logic-based edge detection achieves outcomes comparable to classical methods by using fewer operations, marking a step toward practical quantum-enhanced image processing.},
  archive      = {J_ASOC},
  author       = {G. Nunziata and S. Crisci and G. De Gregorio and R. Schiattarella and G. Acampora and L. Coraggio and N. Itaco},
  doi          = {10.1016/j.asoc.2025.113866},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113866},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Quantum fuzzy logic for edge detection: A demonstration on NISQ hardware},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompted complex context generation guided fine-grained ship recognition. <em>ASOC</em>, <em>185</em>, 113856. (<a href='https://doi.org/10.1016/j.asoc.2025.113856'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained ship recognition in complex marine environments is challenged by background interference, high inter-class similarity, and limited labeled data. Existing methods often rely on inefficient cascades or holistic feature extraction, which limits both accuracy and efficiency. To address these issues, we propose a Prompted Complex Context Generation Guided Fine-Grained Ship Recognition framework, consisting of two core modules. The Cross-Attention Context Generation Module utilizes a diffusion model to generate diverse background images from prompts, maintaining target consistency and enriching the training data to mitigate data scarcity. It also employs a cross-attention map to highlight target-relevant regions, guiding the Attention Map Guided Fusion Module. The Attention Map Guided Fusion Module adopts a dual-branch transformer architecture: one branch extracts global features from background-enhanced images, and the other captures local features through attention-guided cropping of target-specific regions. By integrating both global and local features, our method effectively identifies key target characteristics. Experimental results demonstrate that our approach achieves 97.04% accuracy on the publicly available MAR-ships dataset and 84.57% accuracy on the challenging GCS dataset, outperforming state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Runtian Wang and Kejun Wu and Renjie Qiao and Chunsheng Yang and Chengtao Cai},
  doi          = {10.1016/j.asoc.2025.113856},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113856},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prompted complex context generation guided fine-grained ship recognition},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-granularity decision tree algorithm based on variable precision rough sets and zentropy. <em>ASOC</em>, <em>185</em>, 113851. (<a href='https://doi.org/10.1016/j.asoc.2025.113851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing decision tree algorithms often use a single-layer measure to process data, which cannot fully consider the complex interactions and dependencies between different granularity levels. In addition, decision tree algorithms inevitably face the issue of multi-value preference, which may lead to the selection of unreasonable attributes in the process of partition, thereby affecting the performance of the algorithms. Therefore, this paper proposes an improved decision tree algorithm, called Ze-VNDT, which combines variable precision rough sets with Zentropy. First, to avoid the information loss caused by data discretization, this paper introduces variable precision neighborhood rough sets for data processing. Second, by analyzing the granularity level structure within the variable precision neighborhood rough set model, knowledge uncertainty is analyzed from three granularity levels: decision classes, approximate relations, and similarity classes. We describe the uncertain knowledge from the overall to the internal using the idea of going from coarse to fine, and design a Zentropy to measure uncertainty. To address the issue of multi-value preference, an adaptive weighted Zentropy uncertainty measure is designed based on the definition of uncertainty measure based on Zentropy. Third, when constructing the improved decision tree algorithm, the optimal attributes are selected based on the designed uncertainty measure. Finally, numerical experiments on 18 UCI datasets validated the effectiveness and rationality of the proposed algorithm. The experimental results showed that, compared to traditional algorithms and the latest improved algorithms, the proposed algorithm achieved an average accuracy of 94.79%, an average precision of 85.77%, an average recall rate of 84.68%, and an F1-score of 84.97% across the 18 datasets. It ranked first in all five evaluation metrics, demonstrating higher stability and accuracy.},
  archive      = {J_ASOC},
  author       = {Hui Dong and Caihui Liu and Xiying Chen and Duoqian Miao},
  doi          = {10.1016/j.asoc.2025.113851},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113851},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-granularity decision tree algorithm based on variable precision rough sets and zentropy},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skin lesion classification with mini-batch sampling and deep metric learning. <em>ASOC</em>, <em>185</em>, 113850. (<a href='https://doi.org/10.1016/j.asoc.2025.113850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin lesion image classification based on deep learning has recently garnered significant attention. However, directly applying methods that perform well in general computer vision tasks to skin lesion image classification is not ideal, as skin lesion image datasets possess intrinsic characteristics, such as class imbalance, intra-class variability, and inter-class similarity. To tackle these challenges simultaneously, we propose a novel unified learning framework, named mBSML, which integrates mini-batch sampling and deep metric learning. In this framework, mini-batch sampling re-samples data in real-time during each iteration of learning, while a new loss function combines mini-batch distance metric-based loss with cross-entropy loss. Through the alternating training procedure on both imbalanced training data and balanced re-sampling data, mBSML effectively learns from global distribution information and local similarity information, not only from the original dataset but also from the minority classes. Extensive experiments conducted on two publicly available datasets demonstrate the effectiveness of mBSML for skin lesion image classification.},
  archive      = {J_ASOC},
  author       = {Shengdan Hu and Zhifei Zhang and Li Ying and Guangming Lang},
  doi          = {10.1016/j.asoc.2025.113850},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113850},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Skin lesion classification with mini-batch sampling and deep metric learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AOD-YOLO: A self-modulating multi-scale feature aggregation mechanism for small object detection in airport surface scenes. <em>ASOC</em>, <em>185</em>, 113849. (<a href='https://doi.org/10.1016/j.asoc.2025.113849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in airport surface scenes is crucial for enhancing safety. However, the coexistence of objects with significant scale disparities within the same region complicates feature representation, limiting existing models’ ability to capture fine-grained details, especially for small objects. To address this challenge, we propose AOD-YOLO, an Airport Object Detection (AOD) model incorporating a Self-Modulating Multi-Scale Feature Aggregation Mechanism. This model introduces two key innovations: (1) Enhanced Context Modeling: By leveraging large-kernel convolution, frequency-domain modulation, and statistical feature analysis, our approach effectively adjusts feature contributions across different object scales, improving contextual understanding in complex scenes; (2) Optimized Small Object Representation: A dynamic gradient gain allocation strategy refines small-object features, enhancing detection accuracy and overall feature presentation. AOD-YOLO consistently improves performance across model scales. On our self-constructed Airport dataset and the public VisDrone-DET2019 dataset, it achieves mean Average Precision (mAP 0.5 ) of 87.9% and 44.9%, respectively—outperforming state-of-the-art models like YOLOv11 and Gold-YOLO by substantial margins. Additionally, through optimized network module placement, AOD-YOLO achieves 112 FPS, striking a balance between computational efficiency and accuracy, making it well-suited for real-time airport object detection.},
  archive      = {J_ASOC},
  author       = {Yingqing Wang and Weili Zeng and Ziyu Zhao and Baogeng Li and Zhibin Quan},
  doi          = {10.1016/j.asoc.2025.113849},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113849},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AOD-YOLO: A self-modulating multi-scale feature aggregation mechanism for small object detection in airport surface scenes},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient mathematical-based optimization method to optimize multi-hydropower operating rules. <em>ASOC</em>, <em>185</em>, 113846. (<a href='https://doi.org/10.1016/j.asoc.2025.113846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing hydropower multi-reservoir systems requires both effective operating rules and efficient optimization techniques. The main contribution of this paper is offering a unique approach that elegantly combines two important parts: creating an efficient optimization method and developing hydropower operating rules. In this regard, a nonlinear rule curve (NLRC) and a linear rule curve (LRC), are tailored for the coordination of a hydropower multi-reservoir system (HMRS) in Iran. To optimize operating rules, the study fabricates a novel algorithm termed the multi-operator weighted mean of vectors (MINFO). The algorithm combines a powerful global search strategy (GSS) that thoroughly searches the solution space with an efficient local search (LS), striking a balance between solution diversity and convergence speed. To fine-tune this balance, an adaptive parameter-tuning strategy is applied. Furthermore, the active-set sequential quadratic programming (ASQP) serves as a localized escaping operator to enhance the algorithm's convergence speed. The effectiveness of the proposed MINFO algorithm is first evaluated through a nonlinear five-reservoir problem. The findings indicate that the MINFO algorithm outperforms a set of 14 distinct optimization methods. Subsequently, the MINFO algorithm is applied to identify optimal NLRC and LRC for a six-reservoir hydropower system. The results underscore the superiority of optimized NLRC, yielding a potential power augmentation of up to 17 % in comparison to the LRC approach. In summation, this study constitutes a seminal contribution by cultivating an efficient rule curve framework for the management of HMRSs.},
  archive      = {J_ASOC},
  author       = {Shuguang Li and Iman Ahmadianfar and Aitazaz A. Farooque and Zaher Mundher Yaseen},
  doi          = {10.1016/j.asoc.2025.113846},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113846},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An efficient mathematical-based optimization method to optimize multi-hydropower operating rules},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced YOLOv4 for real-time underwater object detection: An application-oriented approach. <em>ASOC</em>, <em>185</em>, 113837. (<a href='https://doi.org/10.1016/j.asoc.2025.113837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting debris and monitoring marine life in sea aquaculture face challenges due to limited visibility and the presence of diverse. Underwater object detection by Autonomous Unmanned Vehicle(AUV) is inherently more challenging than land due to light attenuation and water turbidity, especially for small and dense objects in murky images, where extracting high-quality features is hindered. In this paper, we present an efficient approach for real-time underwater object detection through improvements in image enhancement, data augmentation, and feature aggregation. Initially, U-Shape Transformer is applied to enhance the original images. For data augmentation, it is observable that while Mosaic data augmentation enhances complex images but fails to improve small-object detection due generation of less number of images with small objects. To address this limitation, we propose Underwater-Mosaic (U-Mosaic), a modified Mosaic data augmentation technique designed to enhance small-object detection. Additionally, it was noted that existing YOLOv4 struggles with detecting small and densely populated objects in underwater images as unable to get sufficient features for small objects due to downsampling, image quality and also found difficulty in selecting anchor box size. Therefore, we propose a model called Advanced YOLOv4, tailored for underwater object detection. The proposed Advanced YOLOv4 aims to improve object detection efficiency by altering the neck and prediction layers of YOLOv4. Moreover, we introduce an additional spatial pyramid pooling layer to aggregate features and reduce feature dimensions thereby improving object detection rates. Also, the proposed work concentrates on very large object detection and for this purpose used downsampling during the detection of large objects. The proposed approach is validated through two distinct application areas: (i) detecting and locating debris (ii) detecting fish from underwater images. For validation, the Trash ICRA19 dataset is used for debris detection, while the Brackish dataset is employed for fish detection. UIQM and UCIQE, image enhancement assessment metrics are used to measure quality of enhanced images and found more than 20% better result for both the datasets. The proposed real-time underwater object detection model outperformed single-stage object detectors like YOLOv3, YOLOv4, YOLOv5, YOLOv7, and KPE-YOLOv5 by 5% in terms of mean Average Precision(mAP). Also proposed work compared with two-stage detector RCNN and found 8% better mAP than RCNN.},
  archive      = {J_ASOC},
  author       = {Pratima Sarkar and Sourav De and Prasenjit Dey and Sandeep Gurung},
  doi          = {10.1016/j.asoc.2025.113837},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113837},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advanced YOLOv4 for real-time underwater object detection: An application-oriented approach},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniCon: Unified image-guiding generation with noise consistency. <em>ASOC</em>, <em>185</em>, 113832. (<a href='https://doi.org/10.1016/j.asoc.2025.113832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have demonstrated remarkable capabilities in image-to-image tasks. However, existing methods typically focus either on structural (e.g., layout, content) or stylistic guidance, with few approaches effectively excel at both. On the other hand, many methods require time-consuming fine-tuning or high inference latency, making interactive generation applications challenging to realize. To address these issues, we propose a two-stage framework referred as UniCon ( Uni fied Image-guiding Generation with Noise Con sistency). To improve time efficiency, we follow the paradigm of inversion-based image manipulation and introduce a novel method called Noise Consistency Inversion . Leveraging the nature of Consistency Models, this inversion process is highly efficient, requiring only a single neural function evaluation (NFE) in the inversion process. To achieve high consistency and finer control, we introduce a unified attention-based guidance mechanism that supports structural, stylistic, or joint reference inputs, without any additional fine-tuning. Experiments with structure- and style-specific methods show that our approach performs competitively or better in each individual aspect. In comparison of style transfer tasks that demand both structure and style, our method outperforms state-of-the-art baselines, confirming the effectiveness of our union control strategy. And overall, our approach also achieves the best efficiency in terms of runtime performance.},
  archive      = {J_ASOC},
  author       = {Yuanjun Liao and Yuning Gong and Yanci Zhang},
  doi          = {10.1016/j.asoc.2025.113832},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113832},
  shortjournal = {Appl. Soft. Comput.},
  title        = {UniCon: Unified image-guiding generation with noise consistency},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of the financial performance of the textile and apparel industry in interval type-2 fuzzy environment. <em>ASOC</em>, <em>185</em>, 113830. (<a href='https://doi.org/10.1016/j.asoc.2025.113830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Turkish textile and apparel sector plays a crucial role in the national economy through employment, exports, and investment. The financial performance of companies is a key determinant of their sustainability and competitiveness, especially in global markets. The Turkish textile and apparel sector is one of the essential industries in terms of macro-economic indicators such as net foreign exchange inflow, employment and investment. This sector is also one of the critical actors in world trade. A robust performance evaluation model is essential for stakeholders such as investors, creditors, and managers. However, the assessment of firms is a very critical decision involving uncertainty due to various conflicting criteria based on judgements. In this study, an integrated multi-criteria decision-making (MCDM) model including interval type-2 fuzzy hierarchy process (IT2FAHP) and Compromise Ranking of Alternatives from Distance to Ideal Solution (CRADIS) approaches are proposed to assess the financial performance of Turkish textile and clothing firms that are traded in Borsa İstanbul (BİST) in the period from 2006 to 2020. In line with the determined purpose, the arithmetic average of the determined financial ratios during the analysis period covering 15 years is computed to obtain long-term performance indicators. The importance weights of the selected financial criteria for the performance evaluation model are identified by employing the IT2FAHP approach. Then, the firms are ranked according to their financial performances with the CRADIS method. In addition, the results from the sensitivity analysis validate the proposed approach and prove that it is practical. Moreover, practical and managerial implications are discussed based on the results. The results offer valuable insights for strategic decision-making and can support efforts to enhance financial stability in the textile and apparel sector. According to the results, "LUKSK" had the highest long-term financial performance among the 11 companies discussed. This company is followed by BOSSA, YATAS, and ATEKS companies. The alternatives confirm the robustness of the proposed model in maintaining its place in the ranking in 190 scenarios. In addition, the comparative analysis confirms the consistency of the proposed ranking framework.},
  archive      = {J_ASOC},
  author       = {Ömer Faruk Görçün and Mohsin Shabir and Ahmet Çalık and Özcan Işık},
  doi          = {10.1016/j.asoc.2025.113830},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113830},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluation of the financial performance of the textile and apparel industry in interval type-2 fuzzy environment},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interpretable dual-output multivariate wind speed interval prediction scheme using hyper-heuristic optimization algorithm and deep neural networks. <em>ASOC</em>, <em>185</em>, 113829. (<a href='https://doi.org/10.1016/j.asoc.2025.113829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty analysis of wind speed forecasting using the Lower Upper Bound Estimation (LUBE) represents an advanced interval prediction method that does not require assumptions about data distribution. Previous studies, however, have exclusively focused on univariate prediction models, neglecting the information from other variables, and have not fully exploited the prediction errors in their loss function during training. To address these issues, an interpretable dual-output multivariate wind speed interval prediction scheme (IMWSIPS) that utilizes a hyper-heuristic optimization algorithm and a deep neural network is proposed, along with a novel loss function for training. The system initially takes multiple inputs such as historical wind speed and other influencing factors including wind direction, density, temperature, and pressure into a deep neural network. The actual wind speeds are then scaled up and down by factors of 1 + θ 1 (0 <θ 1 <1) and 1 + θ 2 (-1 <θ 2 <0), respectively, to produce two outputs from the network. On this basis, an optimization problem to minimize interval width under a given coverage probability is formulated and solved using the developed hyper-heuristic algorithm, yielding optimal values for θ 1 and θ 2 and the prediction intervals for sub-models. Subsequently, the advantages of five deep neural network models are leveraged to construct an ensemble model, with weights optimized by the hyper-heuristic algorithm to derive the final prediction intervals. Ultimately, the system's interpretability is analyzed at both variable and sub-model levels. Experimental and discussion results demonstrate that the introduction of IMWSIPS not only signifies enhancements in forecasting performance but also implies improvements in wind energy utilization efficiency and reductions in operational costs for power systems.},
  archive      = {J_ASOC},
  author       = {Mengzheng Lv and Jianzhou Wang and Shuai Wang and Yang Zhao and Jialu Gao and Yuansheng Qian},
  doi          = {10.1016/j.asoc.2025.113829},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113829},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An interpretable dual-output multivariate wind speed interval prediction scheme using hyper-heuristic optimization algorithm and deep neural networks},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging the semantic-numerical gap: A numerical reasoning method of cross-modal knowledge graph for material property prediction. <em>ASOC</em>, <em>185</em>, 113776. (<a href='https://doi.org/10.1016/j.asoc.2025.113776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Material properties are illustrated by numerical data and semantic factors. In general, existing methods typically adopt machine learning (ML) algorithms to regress numerical properties or transfer other pre-trained knowledge graphs (KGs) to the material, due to the limitations of small-sample datasets. However, integrating semantic and numerical information from multi-modal data which across diverse experimental conditions remains a significant challenge in materials science. In this paper, a numerical reasoning method for material KGs (NR-KG) 1 was proposed, which constructs a cross-modal KG using semantic nodes and numerical proxy nodes. Both types of information by projecting KG into a canonical KG were captured and a graph neural network to predict material properties was utilized. In process, a novel projection prediction loss is proposed to extract semantic features from numerical information. NR-KG facilitates end-to-end processing of cross-modal data, mining relationships and cross-modal information in small-sample datasets, and fully utilizes effective experimental data to enhance the accuracy of material prediction. We propose two new high-entropy alloys (HEA) property datasets with semantic descriptions. NR-KG outperforms state-of-the-art (SOTA) methods on two material datasets, with MSE values of 3520 and 2.210, and achieving relative improvements of 25.9% and 16.1%, respectively, over the second-best methods, KANO and PCHMLP (semantic). It also achieves RMSE values of 0.584 and 0.521 on the FreeSolv and ESOL public molecular datasets, surpassing SOTA methods by 48.8% and 22.2% over KANO, highlighting its potential application and generalizability.},
  archive      = {J_ASOC},
  author       = {Guangxuan Song and Dongmei Fu and Zhongwei Qiu and Zijiang Yang and Jiaxin Dai and Lingwei Ma and Dawei Zhang},
  doi          = {10.1016/j.asoc.2025.113776},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113776},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Bridging the semantic-numerical gap: A numerical reasoning method of cross-modal knowledge graph for material property prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based actor–critic for adaptive cryptocurrency portfolio rebalancing. <em>ASOC</em>, <em>185</em>, 113697. (<a href='https://doi.org/10.1016/j.asoc.2025.113697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-frequency trading in volatile markets, such as cryptocurrencies, requires portfolio models that can swiftly adapt to regime shifts while controlling risk. We propose a novel approach that frames portfolio management as a dynamic strategy-selection problem. Instead of directly predicting asset weights, our agent selects from a pool of expert strategies based on recent market trends. We introduce a Transformer-based Variational Autoencoder (VAE) to extract disentangled trend representations, and a trend-aware actor–critic model to perform expert selection. Experiments demonstrate that this modular, strategy-level control mechanism outperforms existing methods in risk-sensitive crypto portfolio management.},
  archive      = {J_ASOC},
  author       = {Ahmad Asadi and Reza Safabakhsh},
  doi          = {10.1016/j.asoc.2025.113697},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113697},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transformer-based actor–critic for adaptive cryptocurrency portfolio rebalancing},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustainable bridge management using refined feature selection for machine learning-aided bridge condition prediction: Incorporation of pareto distribution in MRMR method. <em>ASOC</em>, <em>184</em>, 113878. (<a href='https://doi.org/10.1016/j.asoc.2025.113878'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the critical phases of bridge management is condition prediction, which was enhanced after machine learning emerged. Researchers have used feature selection (FS) methods to reduce the predictors and optimise the prediction models. Prior studies have either explored a unified feature set for the overall bridge condition or focused solely on the deck, leading to limited predictions. This study proposes a refined feature selection method highlighting the importance of specific predictors for different bridge elements’ conditions using the California State inspection database from 1983 to 2021. The implemented FS approach consists of a verified Minimum-Redundancy Maximum-Relevance (MRMR) method followed by a Pareto analysis that identifies the most contributory factors in predicting the condition of bridges’ decks, superstructures, and substructures. The applied experiment on the US National Bridge Inventory database reveals that 28–33 predictor variables, out of more than 140 available features, contribute the most to each component’s health prediction with a cumulative importance score of over 95 %. Additionally, 22 mutual data items among the selected features are proposed as the minimum required predictors to be gathered by the asset management authorities. This study’s achievements help both researchers reduce the running costs of their prediction models and asset managers with data gathering and registration optimisation and, consequently, whole-of-life cycle cost reduction for sustainable asset management.},
  archive      = {J_ASOC},
  author       = {Vandad Dayan and Nicholas Chileshe and Reza Hassanli and Amin Parvaneh},
  doi          = {10.1016/j.asoc.2025.113878},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113878},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sustainable bridge management using refined feature selection for machine learning-aided bridge condition prediction: Incorporation of pareto distribution in MRMR method},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of fuzzy rule-based models in the presence of the big data environment. <em>ASOC</em>, <em>184</em>, 113869. (<a href='https://doi.org/10.1016/j.asoc.2025.113869'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a series of methods to build fuzzy rule-based models (FRBMs) in the presence of the big data environment such that the formed predictive models are more accurate, efficient, and robust. We follow two major steps to realize this target. In the first step, we build numeric FRBMs with the big data set such that the formed predictive models are more accurate and efficient. Specifically, based on the divide-and-conquer strategy, the big data set is divided into subsets through either the hyperplane division-based method or the K -Means clustering-based method; then either a global-based strategy or a local-based strategy is used to build numeric FRBMs. As a result, four Options are generated to develop numeric FRBMs. In the second step, we build the granular FRBMs based on the four Options developing the numeric FRBMs. Specifically, given a certain Option, based on the Principle of Justifiable Granularity (PJG), we granulate both condition parts and conclusion parts of the rules, forming the granular FRBMs; then the predictive models are further evaluated based on the PJG and optimized based on the Particle Swarm Optimization (PSO) algorithm to enhance the robustness. Finally, experimental studies on both synthetic datasets and publicly available datasets are conducted to prove the effectiveness of the proposed methods.},
  archive      = {J_ASOC},
  author       = {Yinghua Shen and Dan Zhao and Yan Li and Xingchen Hu and Yuan Chen and Bingsheng Liu},
  doi          = {10.1016/j.asoc.2025.113869},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113869},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Development of fuzzy rule-based models in the presence of the big data environment},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CMFF: A cross-modal multi-layer feature fusion network for multimodal sentiment analysis. <em>ASOC</em>, <em>184</em>, 113868. (<a href='https://doi.org/10.1016/j.asoc.2025.113868'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis seeks to interpret speaker sentiment by integrating information from multiple modalities, typically text and audio. While existing methods often focus on fusing deep-layer features extracted from the final stages of unimodal encoders, they may overlook crucial fine-grained information present in shallow-layer features (e.g., subtle phonetic variations or basic syntactic structures) relevant for nuanced sentiment understanding. Furthermore, effectively fusing features from different modalities presents the dual challenges of dynamically weighting each modality’s contribution and accommodating their inherent data heterogeneity. To address these limitations, we propose a novel Cross-modal Multi-layer Feature Fusion (CMFF) network. CMFF explicitly leverages the hierarchical information contained in both shallow-layer and deep-layer features from text and audio modalities. It employs multi-head cross-modal attention mechanisms within its fusion layers to facilitate interaction across feature layers and modalities. Crucially, CMFF incorporates a Mixture of Gated Experts (MoGE) network within these fusion layers. The MoGE utilizes modality-specific expert sub-networks, each tailored to process the distinct characteristics of text or audio data, thereby directly addressing data heterogeneity. Concurrently, each expert employs an internal gated feed-forward mechanism. This allows the model to dynamically control the information flow for each feature vector, effectively learning to weigh the importance of different feature dimensions from each layer and modality based on the input context. Extensive experiments conducted on the benchmark CMU-MOSI and CMU-MOSEI datasets demonstrate that the proposed CMFF model achieves competitive or superior performance compared to state-of-the-art methods across various standard evaluation metrics.},
  archive      = {J_ASOC},
  author       = {Shuting Zheng and Jingling Zhang and Yuanzhao Deng and Lanxiang Chen},
  doi          = {10.1016/j.asoc.2025.113868},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113868},
  shortjournal = {Appl. Soft. Comput.},
  title        = {CMFF: A cross-modal multi-layer feature fusion network for multimodal sentiment analysis},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating over-squashing in graph few-shot learning by leveraging local and global similarities. <em>ASOC</em>, <em>184</em>, 113863. (<a href='https://doi.org/10.1016/j.asoc.2025.113863'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised machine learning models, particularly neural networks, often fail to deliver satisfactory results in scenarios with insufficient data. This becomes even more challenging when dealing with inherently complex data, such as graph data. This paper addresses the issue of learning with a limited number of samples, known as n -way k -shot learning, within the context of graph data. Our research extends the concept of similarity from neighboring nodes to the entire graph by leveraging transitivity relations. By employing edges and strong transitivity relations, we utilize a bipartite graph neural network that capitalizes on both local neighborhoods and distant, yet similar, nodes to generate node embeddings. This approach has demonstrated effectiveness in tasks such as node classification. Our proposed model’s ability to mitigate the over-squashing problem enhances its generalizability, resulting in a task-invariant model. Experimental results on various graph datasets show that the embeddings produced by our model are not task-specific. Consequently, our model outperforms other models in few-shot learning scenarios, where only a limited number of labeled nodes are available for each distinct downstream task.},
  archive      = {J_ASOC},
  author       = {Yassin Mohamadi and Mostafa Haghir Chehreghani},
  doi          = {10.1016/j.asoc.2025.113863},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113863},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Mitigating over-squashing in graph few-shot learning by leveraging local and global similarities},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal intervention for feedback information in fairness recommendation. <em>ASOC</em>, <em>184</em>, 113862. (<a href='https://doi.org/10.1016/j.asoc.2025.113862'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, users’ feedback information is greatly affected by individual differences between users and usually interferes with the interaction between users and items, causing unfairness in the recommendation results. To alleviate the problem of unfair recommendation results caused by the confounding of feedback information, we propose a novel causal intervention for feedback information in fairness recommendation (CIFair). First, we construct a causal graph based on the interaction between users and items and analyze the reasons for unfair recommendation results caused by feedback information as the confounding factor through the causal graph. Then, we design a two-phase predicted rating generation, namely, the elimination and reconstruction phases. In the elimination phase, we analyze the dual effects of the confounding factor on the recommender system and eliminate it through causal intervention to improve the fairness of the recommendation results and obtain a fair predicted rating. In the reconstruction phase, we design personalized feedback information based on user and item attributes to ensure recommendation performance and obtain a personalized predicted rating. Finally, we combine the predicted ratings generated in the elimination and reconstruction phases and provide users with personalized recommendation results with fairness. We conduct experiments on three publicly available datasets (MovieLens-1M, Last.fm, and Yelp) to verify the significance of the CIFair. The ablation experiment confirms that the CIFair model can achieve relatively fair recommendations from both the user and item sides while ensuring recommendation performance.},
  archive      = {J_ASOC},
  author       = {Chenyu Wang and Guanxi Wang and Guowei Yang and Dun Li},
  doi          = {10.1016/j.asoc.2025.113862},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113862},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Causal intervention for feedback information in fairness recommendation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixing deep early exit ensembles for sensor-based human activity recognition through uncertainty quantification. <em>ASOC</em>, <em>184</em>, 113861. (<a href='https://doi.org/10.1016/j.asoc.2025.113861'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic deep neural networks (DNNs) have recently achieved outstanding success on a wide range of resource-constrained human activity recognition (HAR) tasks. However, prior most works are deterministic and could not provide any uncertainty estimate. Though an early exit can facilitate adaptive activity inference by producing intermediate predictions at multiple stages during forward pass, these predictions are only meaningful in real-world while complemented with reliable uncertainty estimates. Until now, the quality of uncertainty estimates has always been ignored in the context of early exit HAR. How to quantify predictive uncertainty in dynamic DNNs still remains challenging and yet unsolved. To address this issue, this paper introduces a new framework of early exit ensembles, which provides a probabilistic treatment of such dynamic DNNs to capture uncertainty estimates through an implicit ensemble of sub-networks sharing weights. We evaluate the proposed approach using three strong state-of-the-art DNN backbones on several mainstream HAR benchmarks, i.e., UCI-HAR, UniMib-SHAR and WISDM. Depending on the backbones and datasets, our approach can lower calibration error up to around 11 × , while increasing accuracy by up to 0.588% over its single counterpart. Both theoretical computational efficiency and practical runtime latency are analyzed. We provide an intuitive illustration of accounting for both aleatoric and epistemic uncertainty, which validates that such probabilistic treatment can adequately capture uncertainty estimates to aid decision-making while varying the computational budgets.},
  archive      = {J_ASOC},
  author       = {Xin Liu and Lei Zhang and Wenbo Huang and Dongzhou Cheng and Hao Wu and Aiguo Song},
  doi          = {10.1016/j.asoc.2025.113861},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113861},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fixing deep early exit ensembles for sensor-based human activity recognition through uncertainty quantification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transformer-based water quality prediction model with mixed fractional brownian features and multi-feature bottleneck transformation. <em>ASOC</em>, <em>184</em>, 113860. (<a href='https://doi.org/10.1016/j.asoc.2025.113860'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven water-quality model inference typically depends on large datasets. In emergency or resource-constrained settings, however, small sample sizes hinder a model’s ability to faithfully capture the complex nonlinear and multiscale dynamics of water quality. To address this challenge, we propose an improved Transformer. First, we enrich the inputs with features from mixed fractional Brownian motion with a perturbation factor (rMFBM). The rMFBM module captures heterogeneous temporal dependencies via multiple Hurst exponents and applies a Cholesky-based covariance sampler with a diagonal perturbation to ensure numerical stability. Second, a multi-feature bottleneck layer performs compression and dimensionality reduction to yield compact yet information-dense representations. Finally, the optimized features are modeled by a lightweight Transformer trained with the AMSGrad optimizer and an early-stopping strategy. On the task of predicting the N S F W Q I water-quality index, the proposed model reduces root-mean-square error (RMSE) by approximately 43.1% relative to a standard Transformer and improves the coefficient of determination ( R 2 ) by 1.89% across four small-sample datasets. It also outperforms widely used alternatives, including GNNs and PINNs. These results suggest that certain water-quality parameters exhibit mixed fractional Brownian-motion characteristics, enabling rapid and reliable prediction under data scarcity and in emergency scenarios.},
  archive      = {J_ASOC},
  author       = {Genghao Cui and Zhiyao Zhao and Li Wang and Huiyan Zhang and Jiabin Yu},
  doi          = {10.1016/j.asoc.2025.113860},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113860},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A transformer-based water quality prediction model with mixed fractional brownian features and multi-feature bottleneck transformation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MPCMamba: Privacy-preserving inference for mamba models via secure multi-party computation. <em>ASOC</em>, <em>184</em>, 113859. (<a href='https://doi.org/10.1016/j.asoc.2025.113859'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is increasingly critical across high-stakes domains, but privacy risks during model inference remain a major concern. Secure multi-party computation (SMPC) offers a promising solution by enabling privacy-preserving collaborative inference without exposing sensitive data. The recently proposed Mamba model, which outperforms Transformer in certain tasks, presents unique challenges for SMPC due to its state-space architecture and nonlinear operations. This paper introduces a framework for executing Mamba model inference under SMPC while preserving privacy. The framework natively supports linear operations and securely computes nonlinear functions – including square roots, exponentials, logarithms, and SiLU activations – without altering the original model architecture. Experimental results demonstrate that the proposed method achieves accuracy improvements of 2.4%, 2.84%, and 8.23% on CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets, respectively, compared to existing SMPC-based vision Transformer approaches, MPCViT. Additionally, inference latency is reduced by factors of 2.14 × , 2.14 × , and 26.13 × on these benchmarks, significantly advancing efficient and secure deployment of state-space models in privacy-sensitive scenarios.},
  archive      = {J_ASOC},
  author       = {Yongqiang Yu and Yuliang Lu and Xuehu Yan and Wei Yan and Shengyang Luo},
  doi          = {10.1016/j.asoc.2025.113859},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113859},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MPCMamba: Privacy-preserving inference for mamba models via secure multi-party computation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A depth-estimation-based method for multi-view synthesis applied to chinese landscape paintings. <em>ASOC</em>, <em>184</em>, 113858. (<a href='https://doi.org/10.1016/j.asoc.2025.113858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenging task of novel view synthesis for traditional Chinese landscape paintings, which typically offer only a single perspective and lack clear depth information. To overcome the limitations of existing methods that rely on multi-view input and depth estimation, we propose a multi-view synthesis method for Chinese landscape paintings, termed MVSM-CLP. The proposed CLPDepth Module employs a high-low resolution fusion mechanism to enhance detail expression while preserving the original scene structure. We introduce an image restoration technique guided by landscape ink lines, termed LInpainting, to improve edge extraction and the accuracy of painting inpainting Additionally, our method tackles the issue of scarce 3D data in current view synthesis efforts by constructing multi-view data from a single ancient painting. Our approach effectively bridges the gap between 2D art and 3D visualization, creating vivid and realistic virtual environments while preserving the traditional style and essence of Chinese paintings. Experimental results demonstrate the effectiveness of our method in achieving high-quality multi-view synthesis, offering new possibilities for the digital preservation of cultural heritage. A preprint has previously been published (Peng et al., 2024 [1] ). The code and dataset is available at https://github.com/LPDLG/DepCLP_Dataset .},
  archive      = {J_ASOC},
  author       = {Xianlin Peng and Wanlin Zhou and Qiyao Hu and Tengfei Li and Dong Zhang and Rui Cao},
  doi          = {10.1016/j.asoc.2025.113858},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113858},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A depth-estimation-based method for multi-view synthesis applied to chinese landscape paintings},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGBA: Subspace guidance backdoor attack with feature alignment in image classification. <em>ASOC</em>, <em>184</em>, 113857. (<a href='https://doi.org/10.1016/j.asoc.2025.113857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widely use of deep neural networks (DNNs) in a variety of classification and generation tasks with remarkable performance, the security of DNN models has attracted further attention. Recently, backdoor attacks have made a significant threat to DNN models, where attackers intentionally introduce malicious patterns into the model and manipulate the behavior of the model upon encountering the specific trigger. In this paper, we analyze the workflow of backdoor attacks with feature-guide classifier, and propose a novel method to conduct the backdoor attack based on feature alignment. We find that using samples with adversarial perturbation for training can mislead the model during the inference stage. Inspired by this observation, we leverage the intrinsic distribution of target class features in the latent space to generate effective and invisible triggers by adding directional perturbations to target images. We evaluate the attack under three widely used datasets and results show that our method can achieve considerable performance in comparison with other four state-of-the-art attacks. Furthermore, we also make extensive experiment to emphasize the robustness and stealthiness of our attack method.},
  archive      = {J_ASOC},
  author       = {Hao Luo and Zhi Qin and Lin Wang and Ziyue Wu and Min Yang},
  doi          = {10.1016/j.asoc.2025.113857},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113857},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SGBA: Subspace guidance backdoor attack with feature alignment in image classification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based kiwifruit flower recognition method to facilitate automated pollination. <em>ASOC</em>, <em>184</em>, 113855. (<a href='https://doi.org/10.1016/j.asoc.2025.113855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate flowering-stage recognition is vital for intelligent orchard management, automated pollination, and yield forecasting. However, in complex natural scenes, existing models struggle to balance detection accuracy with inference speed. To bridge this gap, we propose the Kiwifruit Recognition Network (KiwiRecNet), a lightweight yet high-performance framework tailored to kiwifruit blossoms in the wild. KiwiRecNet first employs the Kiwifruit Generative Adversarial Network for Low-light Improvement (KiwiGAN-LI) to enhance under-exposed images. We then design a novel backbone, the Multi-Scale Shuffle Block (MSBlock), which combines structural re-parameterisation with channel–spatial shuffling to shrink the network footprint. Next, we propose the Partial-Mixing Vision Transformer (PMVIT), a convolution-Transformer hybrid that captures fine-grained features and remains robust to occlusion. Finally, we devise a Bidirectional Cross-Scale Fusion module (Bi-CSF) to enrich multiscale perception. Evaluated on the NWAFU Kiwifruit_F dataset, KiwiRecNet achieves 94.07 % mAP at 82.67 FPS with only 0.93 million parameters, outperforming existing lightweight detectors while approaching heavyweight baselines at a fraction of their cost. Consistent gains across multiple flower datasets confirm its generalisation ability. These results demonstrate an effective route to high-accuracy, real-time flowering-phase recognition on resource-constrained devices, paving the way for scalable agricultural automation.},
  archive      = {J_ASOC},
  author       = {Xiaopeng Li and Jinzhi Du and Xiaoyu Chen and Fuxi Shi and Shuqin Li},
  doi          = {10.1016/j.asoc.2025.113855},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113855},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep learning-based kiwifruit flower recognition method to facilitate automated pollination},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Searching for local pareto fronts based on the non-dominance range in the decision space. <em>ASOC</em>, <em>184</em>, 113853. (<a href='https://doi.org/10.1016/j.asoc.2025.113853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal multi-objective optimisation problems (MMOPs) involve multiple equivalent Pareto sets that share the same Pareto front, and a special subclass is known as MMOPs with local Pareto fronts (MMOPLs). Conventional multi-modal multi-objective optimisation evolutionary algorithms (MMOEAs) struggle to effectively identify local Pareto fronts, and existing methods tailored for MMOPLs exhibit notable limitations. Additionally, commonly used performance metrics lack systematic evaluation and suffer from inherent shortcomings. A simple yet effective MMOEA that leverages the non-dominance range in the decision space is proposed to address these challenges. By prioritising individuals with above-average non-dominance ranges, the algorithm enhances the identification and retention of both global and local optima. Convergence is further improved using the local outlier factor method. The limitations of existing performance metrics are analysed and six new performance metrics tailored for MMOPLs are introduced. To facilitate evaluation, benchmark problems are modified to create scenarios in which global and local optima coexist on the same Pareto set. Extensive experimental results confirm that the proposed algorithm achieves competitive performance, effectively identifying global and local optima while ensuring well-distributed solutions.},
  archive      = {J_ASOC},
  author       = {Yimin Shen and Yu Guo and Shaohua Huang and Weiwei Qian and Shengbo Wang and Litong Zhang},
  doi          = {10.1016/j.asoc.2025.113853},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113853},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Searching for local pareto fronts based on the non-dominance range in the decision space},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Normalizing flow defect detection model based on similar self-supervision. <em>ASOC</em>, <em>184</em>, 113847. (<a href='https://doi.org/10.1016/j.asoc.2025.113847'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome the limitations in unsupervised industrial anomaly detection, such as poor modeling of the appearance differences between synthetic and real defects and the failure to capture multi-scale feature relationships, this paper proposes a Normalizing Flow Defect Detection Model Based on Similar Self-Supervision (NF-SS). First, a feature-level defect generation method is introduced. It synthesizes realistic defect samples by fusing defect background features, known defect features from related domains, and other auxiliary features. This enhances the model's understanding of defect characteristics and reduces the gap between synthetic and real defects. Second, a multi-scale joint Normalizing Flow decoder is proposed. It replaces independent NF layers with progressive multi-scale fusion, allowing the model to integrate features hierarchically across scales. This preserves spatial relationships, reduces edge blurring, and improves defect localization accuracy. Extensive experiments on the MVTec AD dataset show that NF-SS outperforms state-of-the-art models, achieving an average image-level AUC of 99.54 % and pixel-level AUC of 98.76 %. It significantly improves the detection of subtle and ambiguous defects. NF-SS combines unsupervised and self-supervised learning, providing a robust solution for industrial quality inspection with limited defect samples.},
  archive      = {J_ASOC},
  author       = {Zhenlian Miao and Guangzhu Chen and Herui Cao and Yuan Tang and Xiaojuan Liao},
  doi          = {10.1016/j.asoc.2025.113847},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113847},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Normalizing flow defect detection model based on similar self-supervision},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refined vision to obtain the vibration trajectory of rotating body. <em>ASOC</em>, <em>184</em>, 113845. (<a href='https://doi.org/10.1016/j.asoc.2025.113845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-contact vision technology has been widely used in many fields, but it still has limited accuracy in dealing with complex motion, small displacement and boundary recognition, especially in the rotating body scene, where it is difficult to balance global robustness and local sensitivity. To achieve high-precision visual measurement of rotating structure vibration, this paper proposes a detection-guided target tracking method to address the shortcomings of existing visual algorithms in target identity preservation and temporal consistency. In the face of the above challenges, this paper constructs lightweight encoder–decoder network to extract multi-scale semantic information to enhance the target edge modeling capability, and designs a multidimensional regression mechanism to predict the target boundary from the center point and extract sub-pixel vibration signals. At the same time, a guide term is introduced to optimize trajectory association and improve the temporal continuity and spatial consistency of tracking. Experimental results show that the average performance of the proposed method is improved by about 51.2% on the basis of multiple mainstream visual algorithms, and the main frequency recognition error is reduced to 0.32 Hz, which effectively suppresses high-frequency vibration errors. Ablation experiments verify the contribution of each module to the measurement accuracy, and low-quality image tests further show that the method has good generalization ability and application prospects.},
  archive      = {J_ASOC},
  author       = {Rongliang Yang and Tao Liu and Sen Wang},
  doi          = {10.1016/j.asoc.2025.113845},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113845},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Refined vision to obtain the vibration trajectory of rotating body},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving lightweight semi-supervised text classification via teacher intervention. <em>ASOC</em>, <em>184</em>, 113844. (<a href='https://doi.org/10.1016/j.asoc.2025.113844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most recent semi-supervised text classification frameworks have focused on pre-trained models like BERT. While effective, their large-scale parameters and slow inference speed hinder deployment in many practical scenarios. In this work, we develop a general Li ghtweight S emi-supervised T ext classification framework (LiST), which significantly enhances the performance of lightweight models in semi-supervised settings, thus improving inference efficiency. LiST employs a teacher intervention strategy, where pseudo-labels initially rely on the teacher model and gradually shift to the lightweight model’s own predictions, progressively correcting the teacher’s incorrect predictions over time. Experimental results on multiple benchmark datasets demonstrate the generality and effectiveness of LiST. It not only approaches or exceeds the performance of the teacher model (UDA) at a 20 × faster inference speed but also outperforms existing lightweight methods in both performance and efficiency. Notably, LiST achieves significant performance improvements even with extremely few labeled samples, such as a 36.4% increase in accuracy on AG News with only 2 labeled samples per class.},
  archive      = {J_ASOC},
  author       = {Shaohuan Cheng and Wenyu Chen and Wanlong Liu and Hong Qu},
  doi          = {10.1016/j.asoc.2025.113844},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113844},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Improving lightweight semi-supervised text classification via teacher intervention},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chaotic property based multi-interval informer modeling method for long-term photovoltaic power generation prediction. <em>ASOC</em>, <em>184</em>, 113843. (<a href='https://doi.org/10.1016/j.asoc.2025.113843'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The long-term prediction of photovoltaic (PV) power generation capacity can significantly enhance the maintenance planning of photovoltaic power stations and support the long-term development strategies of power supply and distribution networks. Currently, two major challenges hinder the realization of effective long-term prediction for PV power generation: First, PV power generation data is heavily influenced by environmental factors, leading to high randomness and significant volatility in long-term data sequences; Second, the temporal continuity of long-term data must be considered, which complicates the construction of an accurate predictive model. To address these issues, this paper proposes a long-term PV power generation prediction method based on interval division, modeled using an improved Informer architecture with a modified activation function. Initially, by analyzing the fluctuation characteristics of PV power generation data, the K-nearest neighbors algorithm is applied for data interpolation, while the moving average (MA) method is employed for data smoothing, effectively reducing data randomness while preserving the overall trend. Subsequently, the Kmeans＋＋ clustering algorithm is utilized to group the generation data into multiple intervals, thereby enhancing feature similarity within each cluster. Finally, the activation function of the Informer model is replaced with ReLU to improve its adaptability to photovoltaic data characteristics. Additionally, this study introduces evaluation metrics such as the Hurst exponent and the Maximum Lyapunov Exponent (MLE) to assess the predictability of partitioned data and identify the interval to which predicted values belong. Simulation experiments demonstrate that, compared to several commonly used prediction models, the proposed interval-based approach achieves superior performance in long-term PV power generation prediction.},
  archive      = {J_ASOC},
  author       = {Ying Han and Xinggang Hu and Kun Li},
  doi          = {10.1016/j.asoc.2025.113843},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113843},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Chaotic property based multi-interval informer modeling method for long-term photovoltaic power generation prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A noisy multi-objective evolutionary optimization algorithm based on elman neural network. <em>ASOC</em>, <em>184</em>, 113842. (<a href='https://doi.org/10.1016/j.asoc.2025.113842'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks have emerged as potent tools for tackling multi-objective optimization problems with remarkable success. This research delves into the performance of dynamic neural networks in resolving noisy multi-objective optimization problems (NMOPs). The local regression structure of the Elman neural network enables it to deal with the dynamic noise problem well. This paper integrates the Elman neural network into the framework of the non-dominated sorting genetic algorithm II (NSGA-II) to solve NMOP, called E-NSGA-II. In this method, the Elman neural network is employed for modeling, estimating the fitness value of each individual. Simultaneously, a hybrid selection solution strategy is implemented to select individuals for modeling, providing more diverse solutions in the modeling process to improve the convergence. Furthermore, E-NSGA-II incorporates a noise-driven sampling mechanism that intelligently adapts the sampling frequency based on the noise intensity. This feature could not only enhance the accuracy of neural network modeling, but also minimize the amount of calculation. Notably, the embedding of neural network does not impose much additional evaluation overheads, thereby bolstering the overall efficiency of E-NSGA-II. Experimental results prove the superiority of E-NSGA-II over four state-of-the-art noisy multi-objective optimization algorithms on dealing with NMOPs.},
  archive      = {J_ASOC},
  author       = {Jianxia Li and Ruochen Liu and Wanfeng Chen and Weibin Li},
  doi          = {10.1016/j.asoc.2025.113842},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113842},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A noisy multi-objective evolutionary optimization algorithm based on elman neural network},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective detection algorithm for small UAV based on lightweight you-only-look-once (YOLOv4-l) approach. <em>ASOC</em>, <em>184</em>, 113841. (<a href='https://doi.org/10.1016/j.asoc.2025.113841'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control and monitoring of small Unmanned Aerial Vehicles (UAV) plays a crucial role in national defense and security. However, due to their compact size and high mobility, the detection of small UAV across diverse scenarios remains a significant challenge. To address this issue, this study proposes an improved detection algorithm tailored for small UAV. The model is initially trained on a virtual dataset, and the learned parameters are transferred to real-world data through a transfer learning framework. To optimize anchor box generation, clustering analysis is performed on bounding box dimensions, resulting in anchor boxes with appropriate scales and aspect ratios. Furthermore, the Ghost module is introduced to replace conventional convolutions in CSPDarknet53, enhancing feature extraction efficiency. An Efficient Channel Attention (ECA) mechanism is also incorporated to strengthen output feature representations and improve the capture of texture details critical for small target detection. Through experiments, the proposed algorithm can achieve the mAP0.5 of 82.2 %. Experimental results demonstrate the effectiveness of the proposed small UAV detection method.},
  archive      = {J_ASOC},
  author       = {Guoning Li and Jianghao Cheng and Yanyan Liu and Jin Li and Zengming Lv and Qiang Li},
  doi          = {10.1016/j.asoc.2025.113841},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113841},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An effective detection algorithm for small UAV based on lightweight you-only-look-once (YOLOv4-l) approach},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TPLLM: A traffic prediction framework based on pretrained large language models. <em>ASOC</em>, <em>184</em>, 113840. (<a href='https://doi.org/10.1016/j.asoc.2025.113840'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction constitutes a critical component in sustainable urban data analysis, playing a pivotal role in optimizing transportation systems for reduced carbon emissions and improved energy efficiency. The precision of prevailing deep learning-driven traffic prediction models typically improves as the volume of training data increases. However, the procurement of comprehensive spatiotemporal datasets for traffic is often fraught with challenges, primarily stemming from the substantial costs associated with data collection and retention. This limitation severely hinders the deployment of models in regions with insufficient historical data. Consequently, developing a model that can achieve accurate predictions and good generalization ability in areas with limited historical traffic data is a challenging problem. It is noteworthy that the rapidly advancing pretrained Large Language Models (LLMs) of recent years demonstrate exceptional proficiency in cross-modality knowledge transfer and few-shot learning. Recognizing the sequential nature of traffic data, similar to language, we introduce TPLLM, a novel traffic prediction framework leveraging LLMs. In this framework, we construct a sequence embedding layer based on Convolutional Neural Networks (CNNs) and a graph embedding layer based on Graph Convolutional Networks (GCNs) to extract sequence features and spatial features, respectively. These are subsequently integrated to form inputs that are suitable for LLMs. A Low-Rank Adaptation (LoRA) fine-tuning approach is applied to TPLLM, thereby facilitating efficient learning and minimizing computational demands. Experiments on two real-world datasets demonstrate that TPLLM exhibits commendable performance in both full-sample and few-shot prediction scenarios.},
  archive      = {J_ASOC},
  author       = {Tian Ma and Yixuan Zhao and Minda Li and Yue Chen and Fangshu Lei and Yanan Zhao and Maazen Alsabaan},
  doi          = {10.1016/j.asoc.2025.113840},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113840},
  shortjournal = {Appl. Soft. Comput.},
  title        = {TPLLM: A traffic prediction framework based on pretrained large language models},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-linguistic fusion for brain tumor classification: A cross-modal attention framework with clinical interpretability. <em>ASOC</em>, <em>184</em>, 113839. (<a href='https://doi.org/10.1016/j.asoc.2025.113839'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate classification of brain tumors is a key challenge in medical image analysis, and existing methods mainly rely on static MRI images, which are difficult to capture the dynamic evolutionary features of tumors. In addition, the lack of descriptive clinical text and efficient multimodal feature fusion limits the classification accuracy and generalization. To overcome these limitations, this paper proposes a new dynamic language fusion (DLF) framework. The framework (1) utilizes ResNet18 in conjunction with LSTM for time series modeling to capture the temporal evolution of tumor morphology, (2) uses BioGPT and BERT for clinical text processing for semantic understanding, and (3) applies an interpretable cross-modal attentional mechanism for feature fusion to optimize dynamic perception and semantic alignment. Experiments on 10,287 images (from four publicly available datasets) show that the proposed framework achieves an overall accuracy of 98.96 %, a precision of 99.58 %, and an AUC higher than 0.998 for all categories on the test set, which is significantly better than the existing SOTA models, and especially exhibits stronger robustness and discriminative ability in boundary ambiguity and feature overlap samples. This study validates the synergistic effect of temporal modeling and semantic understanding in brain tumor diagnosis, providing clinicians with interpretable classification outputs to assist in decision-making for complex cases, while establishing a scalable framework for medical AI systems based on large language models.},
  archive      = {J_ASOC},
  author       = {Jiancong Fan and Fangyuan Chen and Yang Li and Jiehan Zhou},
  doi          = {10.1016/j.asoc.2025.113839},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113839},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic-linguistic fusion for brain tumor classification: A cross-modal attention framework with clinical interpretability},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Path planning for flexible needle puncture based on multi-objective particle swarm optimization. <em>ASOC</em>, <em>184</em>, 113838. (<a href='https://doi.org/10.1016/j.asoc.2025.113838'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a mixed-parameter MOPSO algorithm designed to address the puncture problem of flexible needles in obstacle environments. The algorithm incorporates the damage caused by the pivotal angle to soft tissues as an objective function, marking the first time this has been applied to the MOPSO algorithm. In comparison with four classical algorithms through simulation experiments, the path deviation is reduced to just 0.1 mm, significantly lower than the CPSO algorithm. The final path score achieves 35 points, surpassing the performance of other algorithms. A self-built FPAA hybrid control platform was employed for puncture experiments using a gelatin prosthesis. The experimental results confirm that the flexible needle successfully avoids obstacles and reaches the target, demonstrating the feasibility of the proposed puncture algorithm.},
  archive      = {J_ASOC},
  author       = {Ting Yang and Beibei Liu and Ru Sun and Bi Chen and Guijuan Ji},
  doi          = {10.1016/j.asoc.2025.113838},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113838},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Path planning for flexible needle puncture based on multi-objective particle swarm optimization},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-goal reinforcement learning framework for motion planning of a quadrotor UAV in 3D cluttered environment with unseen random goals. <em>ASOC</em>, <em>184</em>, 113836. (<a href='https://doi.org/10.1016/j.asoc.2025.113836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The standard reinforcement learning (RL) approaches render an optimal solution for a specific task by learning an optimal policy. Therefore, these RL approaches are suitable for single goal problems only. However, there exist numerous practical challenges that involve multiple goals to be achieved in a specific environment. For example, navigation of an unmanned aerial vehicle (UAV) to achieve multiple random targets in a specific three-dimensional (3D) cluttered space is a multi-goal problem. Using the standard RL approaches, the UAV agent needs to learn a separate optimal policy for each target. Thus, a multi-goal problem with random unseen goal allocations, especially in the 3D space of UAVs, increases computational effort substantially. To solve this issue, this paper presents a relatively generalized approach that learns the optimal state values and related optimal policies considering various regions of the robot environment. The proposed approach transforms the 3D robot environment into a Markov decision process (MDP) and further divides it into various virtual sub-spaces. For every initial goal position in a sub-space, value iteration algorithm enables the aerial agent to learn the optimal state values and the relevant policy. These optimal state values and policies are then stored in a replay buffer for later use. Once the initial state values for every sub-space are learned, the proposed approach allows the agent to use them from replay buffer and run a local search algorithm to connect every new goal position to any feasible state in the existing state values. Our proposed framework significantly reduces the computational effort for multiple unseen goal targets by restricting the re-computation of state values for each new goal. To validate the proposed method, a simulator is designed and an RL-based motion planning approach for a quadrotor UAV is presented. The results under various scenarios confer the superior performance of our anticipated multi-goal RL framework.},
  archive      = {J_ASOC},
  author       = {Ghulam Farid and Lanyong Zhang and Talha Younas and Muhammad Ilyas and Asma Iqbal},
  doi          = {10.1016/j.asoc.2025.113836},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113836},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-goal reinforcement learning framework for motion planning of a quadrotor UAV in 3D cluttered environment with unseen random goals},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wind speed prediction based on U-shaped 2D multi-scale model. <em>ASOC</em>, <em>184</em>, 113835. (<a href='https://doi.org/10.1016/j.asoc.2025.113835'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind speed forecasting is essential for enhancing energy efficiency and reducing maintenance costs in wind power systems. However, existing CNN-LSTM and Transformer-based models face limitations in capturing periodic features, modeling long-term dependencies, and preserving information during multi-layer encoding. To overcome these challenges, this paper proposes a novel U-shaped 2D multi-scale model that integrates Bi-RLSTM encoding, wavelet transform, and multi-scale 2D convolution. The proposed model first encodes input sequences into a high-dimensional space via feature embedding and Bi-RLSTM, effectively capturing long-term dependencies. Subsequently, a wavelet transform extracts primary fluctuation patterns and their periods, converting 1D sequences into 2D feature maps to enhance periodic feature representation while preserving temporal information. Multi-scale convolutional layers are then employed to extract fine-grained spatial–temporal features from these maps. Finally, a Bi-RLSTM decoding layer, augmented with skip connections, mitigates information loss during deep encoding and reinforces long-range correlation modeling. Extensive experiments on two real-world wind speed datasets demonstrate that the proposed model significantly outperforms CNN-LSTM and attention-based approaches achieving superior performance in terms of MAE, RMSE, and R 2 , confirming its effectiveness and application potential.},
  archive      = {J_ASOC},
  author       = {Yue Gao and Zhongda Tian},
  doi          = {10.1016/j.asoc.2025.113835},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113835},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Wind speed prediction based on U-shaped 2D multi-scale model},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing multi-task learning-based tornado identification using spatial and temporal information from weather radar images. <em>ASOC</em>, <em>184</em>, 113834. (<a href='https://doi.org/10.1016/j.asoc.2025.113834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tornadoes, as dynamic weather phenomena, exhibit unique spatial and temporal evolution characteristics that reflect their formation and development. Existing tornado detection algorithms often struggle with high false alarm rates, primarily due to insufficient capture of temporal correlations in tornado development. As an improvement, we propose a multi-task tornado identification network with three-dimensional temporal and spatial information (TS-MTINet). Taking continuous three-frame radar data as input, the Multi-frame Temporal Interaction Block (MTIB) utilizes multi-head attention to model the dynamic interaction information between the radar data, thus exploring in-depth the temporal features during tornado development. Further, we design a Spatial-Temporal Enhancement Module (STEM), which analyzes the difference information between continuous data to extract local and global spatial and temporal feature variations about tornadoes. Based on this architecture, TS-MTINet incorporates a multi-task learning framework to perform tornado detection and number estimation tasks simultaneously, thus extracting comprehensive information related to tornadoes. To validate the performance of the proposed model, we construct the first Chinese tornado identification dataset with fine radar features. The experimental results show that the proposed method shows significant advantages in several evaluation metrics, especially in reducing false alarms. In practical case studies, compared to the traditional TVS method, TS-MTINet achieves an increase in POD of approximately 30% and a decrease in FAR of about 20% in several typical tornado events. Particularly in environments with strong interference, TS-MTINet demonstrates higher detection accuracy, reflecting greater robustness and practical value.},
  archive      = {J_ASOC},
  author       = {Jinyang Xie and Kanghui Zhou and Lei Han and Liang Guan and Maoyu Wang and Yongguang Zheng and Hongjin Chen and Jiaqi Mao},
  doi          = {10.1016/j.asoc.2025.113834},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113834},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhancing multi-task learning-based tornado identification using spatial and temporal information from weather radar images},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating regional green industry competitiveness in china: A CoSOGR-MABAC-sort framework. <em>ASOC</em>, <em>184</em>, 113831. (<a href='https://doi.org/10.1016/j.asoc.2025.113831'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of concepts such as the green economy and sustainable development, the development of green industry has become increasingly urgent. Regional green industry competitiveness, as a key indicator reflecting the development status and competitive advantages of regional green industry, has not yet received sufficient attention and research. To fill this research gap, this paper proposes an evaluation framework, CoSOGR-MABAC-Sort (Combined Subjective-Objective, Grey Relational analysis-Multi-Attributive Border Approximation area Comparison-Sort), to assess the green industry competitiveness in 31 regions of China. In the proposed framework, the MABAC-Sort method is a novel multi-criteria decision sorting method with six classification rules. Compared to other MCDS methods, this method does not require predefined profile boundaries and can provide more detailed classification results. Furthermore, we propose an optimal model , called CoSOGR, to determine the weights of each indicator. Finally, by collecting subjective and objective data, we use the proposed framework to assess the green industry competitiveness in the 31 provinces of China. The main findings are as follows: 1) The CoSOGR demonstrates the highest consistency (99.33 %) in regions ranking compared to existing weight methods (CRITIC, EWM, ROCOSD, and MEREC). 2) The CoSOGR addresses the weight determination issues that ROCOSD (a mixed-integer linear programming model) cannot resolve. 3) The CoSOGR-MABAC-Sort method exhibit strong robustness and stability. 4) The green industry competitiveness in each region shows a positive correlation with the sustainable development of that region.},
  archive      = {J_ASOC},
  author       = {Jiafu Su and Baojian Xu and Lvcheng Li and Yijun Chen and Hongyu Liu and Na Zhang},
  doi          = {10.1016/j.asoc.2025.113831},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113831},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluating regional green industry competitiveness in china: A CoSOGR-MABAC-sort framework},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AutoTandemML: Active learning enhanced tandem neural networks for inverse design problems. <em>ASOC</em>, <em>184</em>, 113828. (<a href='https://doi.org/10.1016/j.asoc.2025.113828'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse design in science and engineering involves determining optimal design parameters that achieve desired performance outcomes, a process often hindered by the complexity and high dimensionality of design spaces, leading to significant computational costs. To tackle this challenge, we propose a novel hybrid approach that combines active learning with Tandem Neural Networks to enhance the efficiency and effectiveness of solving inverse design problems. Active learning allows to selectively sample the most informative data points, reducing the required dataset size without compromising accuracy. We investigate this approach using three benchmark problems: airfoil inverse design, photonic surface inverse design, and scalar boundary condition reconstruction in diffusion partial differential equations. We demonstrate that integrating active learning with Tandem Neural Networks outperforms standard approaches across the benchmark suite, achieving better accuracy with fewer training samples.},
  archive      = {J_ASOC},
  author       = {Luka Grbcic and Juliane Müller and Wibe Albert de Jong},
  doi          = {10.1016/j.asoc.2025.113828},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113828},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AutoTandemML: Active learning enhanced tandem neural networks for inverse design problems},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized cross-domain recommendation with meta networks and contrastive learning. <em>ASOC</em>, <em>184</em>, 113827. (<a href='https://doi.org/10.1016/j.asoc.2025.113827'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel cross-domain recommendation (CDR) model that integrates matrix factorization (MF), attention networks, meta-networks, and contrastive learning (CL) to address the challenges of data sparsity and cold-start problems in recommender systems. Our model consists of five modules: the MF module extracts user and item embeddings from rating matrices in both information-rich and information-scarce domains; the transferable feature extraction module uses an attention network to identify and extract transferable features from users’ interactions in the information-rich domain; the cross-domain meta-knowledge transfer module employs a meta-network to transfer these features across domains while preserving users’ personalized preferences; the intra-domain CL module ensures temporal consistency of users’ preferences by learning from their interaction sequences in the information-rich domain; and the inter-domain CL module leverages feedback from users’ interactions in the information-scarce domain to refine the transferable features. We conduct extensive experiments on the Amazon and Douban datasets, evaluating our model across three different CDR tasks. The results demonstrate that our proposed model outperforms other prevalent CDR models in terms of MAE and RMSE. Additionally, our model shows the robust performance in cold-start scenarios, effectively utilizing both intradomain and interdomain knowledge to enhance the recommendation accuracy.},
  archive      = {J_ASOC},
  author       = {Shudong Liu and Xiping Hao and Xu Chen and Wenming Ma and Feng Gu},
  doi          = {10.1016/j.asoc.2025.113827},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113827},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Personalized cross-domain recommendation with meta networks and contrastive learning},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient real-time visual anomaly detection via frequency-aware diffusion model and information fusion. <em>ASOC</em>, <em>184</em>, 113826. (<a href='https://doi.org/10.1016/j.asoc.2025.113826'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time visual anomaly detection is always a big challenge since advanced techniques usually suffer from intensive computation, while simple methods cannot obtain desirable performance. To address this issue, an Efficient Real-time Anomaly Detection method via frequency-aware diffusion model and information fusion (ERAD) is proposed, which uses the diffusion model to achieve a nice reconstruction for the frequency information obtained by Discrete Wavelet Transform (DWT) and utilizes the information fusion technique to take full consideration of local and global various features. First, the input image is fed into the DWT module to produce one low-frequency and three high-frequency coefficient images, in this way, data dimensions can be reduced by 75% but the important information can be greatly retained. Then, a diffusion model with one-step denoising is developed rather than the traditional iterative denoising to accelerate the reconstruction speed. As well, information fusion in the framework of selective fusion is embedded into the reconstruction process to improve the model performance. Furthermore, during the segmentation, a wavelet-based upsampling module is put forward to seamlessly combine global semantic context with detailed edge information, achieving both consistent semantics and high-resolution feature reconstruction. Finally, extensive experiments conducted on a variety of benchmark datasets demonstrate the remarkable superiority of our method in both model performance and time efficiency. Specifically, the proposed method achieves an Image AUROC of 99.7 and a Pixel AUROC of 99.5, with an inference time of only 0.04 s.},
  archive      = {J_ASOC},
  author       = {Xianzhe Yao and Ping Kong and Quanquan Li and Yan Song},
  doi          = {10.1016/j.asoc.2025.113826},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113826},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Efficient real-time visual anomaly detection via frequency-aware diffusion model and information fusion},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-splitting conformal prediction for multi-step time series forecasting. <em>ASOC</em>, <em>184</em>, 113825. (<a href='https://doi.org/10.1016/j.asoc.2025.113825'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is crucial for applications like resource scheduling and risk management, where multi-step predictions provide a comprehensive view of future trends. Uncertainty Quantification (UQ) is a mainstream approach for addressing forecasting uncertainties, with Conformal Prediction (CP) gaining attention due to its model-agnostic nature and statistical guarantees. However, most variants of CP are designed for single-step predictions and face challenges in multi-step scenarios, such as reliance on real-time data and limited scalability. This highlights the need for CP methods specifically tailored to multi-step forecasting. We propose the Dual-Splitting Conformal Prediction (DSCP) method, a novel CP approach designed to capture inherent dependencies within time-series data for multi-step forecasting. Experimental results on real-world datasets from four different domains demonstrate that DSCP significantly outperforms existing CP variants in terms of the Winkler Score, improving performance by up to 23.59% compared to state-of-the-art methods. Furthermore, the deployment of DSCP for renewable energy generation and IT load forecasting in the power management of a real-world trajectory-based application achieves an 11.25% reduction in carbon emissions through predictive optimization of data center operations and control strategies.},
  archive      = {J_ASOC},
  author       = {Qingdi Yu and Zhiwei Cao and Ruihang Wang and Zhen Yang and Lijun Deng and Min Hu and Yong Luo and Xin Zhou},
  doi          = {10.1016/j.asoc.2025.113825},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113825},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual-splitting conformal prediction for multi-step time series forecasting},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDP-net: Fourier transform guided lightweight depthwise and pointwise dynamic pooling based neural network for medical image classification. <em>ASOC</em>, <em>184</em>, 113824. (<a href='https://doi.org/10.1016/j.asoc.2025.113824'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, deep learning-based medical image classification has become essential, especially in developing countries because of the high volume of patients with less medical professionals as well as required infrastructures. Deep learning models often help in the early detection of diseases; however, it require a high amount of processing power, and sometimes it becomes less scalable for various computer-aided diagnosis. To this end, in this paper, a lightweight Fourier Transform guided Depth and Pointwise Dynamic Pooling based Neural Network (FDP-Net), has been proposed for medical image classification. This paper introduces a Depth and Pointwise Feature Fusion (DPFF) block for learning the important features with less computation and without increasing the model parameters. It also proposes a dynamic pooling technique, an alternative to traditional max-pooling, which dynamically selects the important features. The proposed FDP-Net model is trained to classify medical images with the guidance of Fourier Transformation and multitask loss function, which makes the model converge faster and reduces overfitting. The proposed model has been tested on Acute Lymphoblastic Leukemia (ALL) dataset, Peripheral Blood Cell (PBC) dataset, and Raabin White blood Cell (Raabin-WBC) dataset, and it outperforms the state-of-the-art models with 100%, 98.13% and 96.79% classification accuracies, respectively. Additionally, the proposed model is made with only 0.349 million parameters, thereby enabling faster processing. Code will be avilabe at https://github.com/asfakali/FDP-Net .},
  archive      = {J_ASOC},
  author       = {Asfak Ali and Rajdeep Pal and Aishik Paul and Ram Sarkar},
  doi          = {10.1016/j.asoc.2025.113824},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113824},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FDP-net: Fourier transform guided lightweight depthwise and pointwise dynamic pooling based neural network for medical image classification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explicit cooperation mechanism and multimodal fusion prediction model empower DouDizhu agents. <em>ASOC</em>, <em>184</em>, 113823. (<a href='https://doi.org/10.1016/j.asoc.2025.113823'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imperfect information games require agents to make decisions under uncertainty, presenting significant challenges yet offering broad applicability in real-world scenarios. DouDizhu, a representative example, features complex cooperative-competitive dynamics, imperfect information, and a large strategy space. To address these challenges, a strategic decision-making algorithm is developed by integrating multi-agent credit allocation with information prediction. Specifically, an explicit credit allocation mechanism based on team reward decomposition improves cooperative behavior among peasant agents by enabling more stable and targeted policy updates. Meanwhile, combining long short-term memory networks and multi-head attention enhances the prediction of hidden opponent information through multimodal feature fusion. Moreover, convolutional neural networks are incorporated into the DouZero framework to extract high-level features and reduce the policy solution space. The resulting CAPRE_DMC significantly improves agent performance in adversarial settings. Extensive evaluations demonstrate that CAPRE_DMC outperforms baseline DouDizhu agents, achieving substantial gains in point margin and win percentage. Additionally, evaluations on benchmark multi-agent cooperative tasks demonstrate the framework’s scalability and generality in large-scale imperfect-information environments.},
  archive      = {J_ASOC},
  author       = {Jiao Wang and Longyue Fu and Xiang Li and Hongchen Luo and Zhifen Guo},
  doi          = {10.1016/j.asoc.2025.113823},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113823},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Explicit cooperation mechanism and multimodal fusion prediction model empower DouDizhu agents},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight detection method for X-ray security inspection based on YOLOV8. <em>ASOC</em>, <em>184</em>, 113822. (<a href='https://doi.org/10.1016/j.asoc.2025.113822'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of public safety, the prohibited items detection during X-ray security inspection is crucial for preventing potential threats. The recent advances in artificial intelligence, particularly deep learning, have achieved success in this area. However, the high number of parameters and computational load of these deep learning-based object detection methods result in significant hardware requirements limiting their practical application. To address these issues, a lightweight method for detecting prohibited items in X-ray security inspections, utilizing the YOLOV8 framework, is proposed in this paper. The key innovations of this method are threefold. First, a lightweight convolution module is designed to optimize the YOLOV8 model. This optimization significantly reduces both the number of parameters and the computational load, making the model more efficient. Second, an adaptive spatial-and-channel attention module is designed to enhance feature extraction capabilities. This module enhances feature extraction capabilities without compromising detection accuracy. Third, the Wise-IOU loss function is incorporated to enhance the overall performance of the detection method during training. Finally, the method is evaluated on our real X-ray pseudo-color image dataset, PIDRAY and CLCXRAY with the existing methods. Our proposed method attains a detection accuracy of 98.83 % on the self-constructed dataset, demonstrating a 0.6 % improvement, while concomitantly reducing the parameters by 64.2 % and computational load by 66.3 %. Furthermore, it achieves accuracy enhancements of 0.7 % and 0.82 % on the two public datasets, respectively. The experimental results indicate that this method not only reduces hardware requirements due to a lower number of parameters and computational load but also broadens the model's applicability. This work underscores the importance of balancing model complexity with performance and sets the stage for future research in AI-driven security inspection technologies.},
  archive      = {J_ASOC},
  author       = {Xizhuo Yu and Chunyang Chen and Shu Cheng and Jingming Li},
  doi          = {10.1016/j.asoc.2025.113822},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113822},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A lightweight detection method for X-ray security inspection based on YOLOV8},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic transformation of basic probability assignment based on weighted visibility graph networks. <em>ASOC</em>, <em>184</em>, 113821. (<a href='https://doi.org/10.1016/j.asoc.2025.113821'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster-Shafer evidence theory (DSET) provides a powerful framework for uncertain reasoning, offering a theoretical basis for decision-making under ambiguity. However, its core representation, the basic probability assignment (BPA), cannot be directly applied to probabilistic decision-making, prompting the need for effective probability transformation methods. A key challenge lies in quantifying the uncertainty inherent in BPAs to guide this transformation process. To address this, we propose an improved probabilistic transformation method that integrates belief entropy and weighted visibility graph networks, which yields more accurate and interpretable probability distributions than existing approaches. Specifically, given a frame of discernment and mass function, we first apply two refined belief entropy measures to evaluate the informational content of each focal element. Based on these entropy-derived orderings, we construct a weighted visibility graph that captures the structural relationships among focal elements. The weights from this graph are then used to compute a proportional belief transformation. Experimental validation across benchmark cases on classical BPA scenarios demonstrates that our method outperforms traditional approaches in terms of entropy consistency and decision quality, as evidenced by lower Kullback–Leibler (KL) divergence, higher probability information capacity (PIC), and reduced Shannon entropy. These results highlight the method’s dual advantage in balancing decisiveness (via PIC maximization) and fidelity (via entropy minimization), making it a robust tool for uncertainty-aware decision support systems.},
  archive      = {J_ASOC},
  author       = {Yongchuan Tang and Kangkang Wu and Rongfei Li and He Guan and Deyun Zhou and Yubo Huang},
  doi          = {10.1016/j.asoc.2025.113821},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113821},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Probabilistic transformation of basic probability assignment based on weighted visibility graph networks},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electric network frequency-based digital audio tampering event identification using multimodal feature interaction network. <em>ASOC</em>, <em>184</em>, 113820. (<a href='https://doi.org/10.1016/j.asoc.2025.113820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of digital Audio Tampering Event (ATE) detection based on Electric Network Frequency (ENF), accurately extracting ENF signals is crucial for tampering event identification. However, ENF signals are susceptible to noise interference, and it is difficult to establish an effective matching relationship with the reference frequency database, which poses a challenge to the effectiveness of existing ATE detection methods. To solve these problems, a Multimodal Feature Interactive Network (MFIN) is proposed for ATE identification under low-SNR conditions. First, a Modified Kaiser-window-based S-Transform (MKST) method is proposed to extract the estimated frequency, phase, rate of change of frequency, and rate of change of phase of the ENF component in digital audio. The frequency and time resolution are increased through the improved control function, thereby enhancing the accuracy of ENF estimation. Subsequently, a Multi-Branch Multi-Scale Attention Convolutional (MBSAC) neural network is further proposed to extract and classify ENF features. In MBSAC, the Multi-Branch Multi-Scale Temporal (MBST) attention fusion block, serving as the network’s primary structure, increases feature diversity and enhances classification performance. Finally, the ATE data acquisition hardware platform is built. Experimental results on a dataset comprising six types of ATEs demonstrate that the proposed MFIN outperforms several state-of-the-art ATE detection methods in both ENF extraction and tampering type classification.},
  archive      = {J_ASOC},
  author       = {Bing Li and Junfeng Duan and Yao Zheng and Xinxin Cai and Wei Qiu and He Yin and Wenxuan Yao},
  doi          = {10.1016/j.asoc.2025.113820},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113820},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Electric network frequency-based digital audio tampering event identification using multimodal feature interaction network},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing financial resilience in manufacturing SMEs: A q-rung picture fuzzy set-based decision framework for digital transformation adoption. <em>ASOC</em>, <em>184</em>, 113819. (<a href='https://doi.org/10.1016/j.asoc.2025.113819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital transformation (DT) has emerged as a crucial strategy for enhancing the financial resilience of small and medium-sized enterprises (SMEs) in the manufacturing sector. Despite its importance, there is a significant gap in the quantitative evaluation of the factors influencing SMEs’ DT adoption. This study addresses this gap by developing a decision framework using q-rung picture fuzzy sets (q-RPF) to identify and analyze the drivers of DT implementation aimed at boosting financial resilience in manufacturing SMEs. The proposed framework incorporates the q-RPF-weighted Heronian mean aggregation operator to aggregate expert evaluations and capture the interrelationships among input decision data. A novel weighting approach, based on the q-RPF deviation measure, is introduced to assess the significance of various enablers. Furthermore, the q-RPF-MARCOS’H model is employed to evaluate the effectiveness of DT in enhancing financial resilience across different SMEs by integrating the methodologies mentioned above. A numerical example involving manufacturing SMEs from a specific city demonstrates the practical application of the q-RPF-MARCOS’H model-based framework. The results reveal that “concurrent operations” (0.102) is a significant enabler of DT adoption in promoting financial resilience. The framework’s validity is confirmed through both sensitivity and comparative analyses. These outcomes offer recommendations for policymakers and industry leaders to design effective incentives for DT adoption and provide practical guidance for SMEs seeking to leverage DT for improved financial resilience.},
  archive      = {J_ASOC},
  author       = {Zhengyan Yang and Wei Zhong Wang and Zelin Wang and Muhammet Deveci and Dursun Delen},
  doi          = {10.1016/j.asoc.2025.113819},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113819},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhancing financial resilience in manufacturing SMEs: A q-rung picture fuzzy set-based decision framework for digital transformation adoption},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A regret theory-based three-way decision model under comparative linguistic expressions. <em>ASOC</em>, <em>184</em>, 113816. (<a href='https://doi.org/10.1016/j.asoc.2025.113816'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real world, experts often prefer to utilize linguistic expressions over numerical data when evaluating alternatives. However, due to the complexity of actual decision-making, single linguistic terms are insufficient for experts to express their judgments accurately. Thus, it is necessary to employ a richer form of linguistic expression, known as comparative linguistic expressions (CLEs). Furthermore, existing multi-attribute decision-making (MADM) models under CLE suffer from the following limitations: (1) they fail to provide decision-making references for alternatives; (2) they do not incorporate the psychological factors of experts. In order to address the aforementioned challenges, this paper proposes a novel regret theory (RT)-based three-way decision (TWD) model under CLE. First, the attribute weights are calculated by an improved optimization model. This model combines index variability with comprehensive entropy, enabling a more objective conclusion to be drawn regarding the relative importance of attributes. Second, an enhanced neighborhood relationship is introduced, which is shown to fulfill the properties of Symmetry, Reflexivity, and Non-transitivity. Building on this foundation, this study integrates RT with the neighborhood relationship to construct a wide TWD framework. This framework incorporates decision-making references for the alternatives and accounts for the influence of experts’ psychological factors. Subsequently, the ranking of alternatives is determined using the technique for order preference by similarity to ideal solution (TOPSIS) method. Finally, the feasibility of the proposed method is demonstrated through a real-case study. Comparative experiments and parameter sensitivity analysis are designed to demonstrate the superiority and effectiveness of the model.},
  archive      = {J_ASOC},
  author       = {Zhanhao Liu and Huangjian Yi and Yushan Yao and Jiajia Wang},
  doi          = {10.1016/j.asoc.2025.113816},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113816},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A regret theory-based three-way decision model under comparative linguistic expressions},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A Q-learning based estimation of distribution algorithm for automated guided vehicle scheduling in disassembly workshop. <em>ASOC</em>, <em>184</em>, 113815. (<a href='https://doi.org/10.1016/j.asoc.2025.113815'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid upgrade of electronic products, the disassembly process is becoming increasingly crucial in facilitating resources recycling. In practical disassembly workshops, the automated guided vehicle (AGV) plays an important role in improving efficiency of product transportation between different disassembly machines. In this paper, a Q-learning based estimation of distribution algorithm (QEDA) is proposed to solve the AGV scheduling problem in disassembly workshops with minimization of makespan for all transportation tasks. Firstly, a mathematical model for the problem is established, and specific encoding and decoding rules are designed for solution representation. Secondly, a novel update mechanism of EDA is designed by fully information utilization of both elite and poor solutions to accelerate convergence. Thirdly, a local search strategy based on Q-learning with three time-related states is designed for the elite solutions to enhance exploitation. Finally, comparative experiments on 120 benchmark test sets demonstrate that the QEDA outperforms the state-of-the-art algorithms in both solution quality and convergence speed, confirming its superior effectiveness for AGV scheduling in disassembly workshops.},
  archive      = {J_ASOC},
  author       = {Honggui Han and Teng Wang and Jingjing Wang},
  doi          = {10.1016/j.asoc.2025.113815},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113815},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A Q-learning based estimation of distribution algorithm for automated guided vehicle scheduling in disassembly workshop},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Criterion-guided polypharmacy side effects prediction with dual-view contrastive learning. <em>ASOC</em>, <em>184</em>, 113814. (<a href='https://doi.org/10.1016/j.asoc.2025.113814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting side effects from taking multiple drugs (polypharmacy) is a critical challenge in healthcare, with significant implications for patient safety. Traditional machine learning methods often overlook the multi-scale nature of drug information and the interdependencies among side effects, limiting their predictive power. To address these gaps, we propose CASE (Criterion-guided polyphArmacy Side Effects prediction with dual-view contrastive learning). CASE captures both microscopic (molecular graph) and macroscopic (biochemical knowledge) drug features via an adaptive substructure encoder and a biochemical feature aggregator, respectively, under a dual-view framework. Then, contrastive learning is employed to jointly balance and integrate structural and biochemical representations, enabling a more comprehensive and synergistic understanding of drug interactions. Moreover, a criterion-guided decoding strategy is designed to model complex side effect relationships. This effective design enables the proposed CASE model to achieve superior performance, with an accuracy of 88.70 %, precision of 83.62 %, recall of 96.45 %, F1-score of 89.56 %, AUROC of 94.75 %, and AUPRC of 91.16 %, respectively, on the benchmark dataset. Ablation experiments and case studies further confirm the robustness and practical utility of the model. These results demonstrate that CASE can effectively assist clinical decision-making by identifying high-risk drug combinations and delivering reliable polypharmacy risk assessments, thereby supporting safer and more personalized treatment strategies.},
  archive      = {J_ASOC},
  author       = {Yike Wang and Huifang Ma and Zihao Gao and Zhixin Li and Liang Chang},
  doi          = {10.1016/j.asoc.2025.113814},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113814},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Criterion-guided polypharmacy side effects prediction with dual-view contrastive learning},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying suicidal ideations from social media posts using deep learning and explainable AI-driven approach. <em>ASOC</em>, <em>184</em>, 113813. (<a href='https://doi.org/10.1016/j.asoc.2025.113813'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background At present, suicide has become one of the leading causes of unnatural deaths worldwide. Individuals having suicidal urges often express their self-harming ideas through social media posts. Early identification of such ideations is critical for timely intervention and prevention. Besides, continuous assessment of the texts containing suicidal thoughts can uncover the hidden triggers of suicidal urges. This study presents a comprehensive approach to analyze the user-generated textual contents on social media that reflect suicidal ideas. Methodology For identifying the underlying topics that express suicidal ideations, this study has employed the Latent Dirichlet Allocation (LDA) model. Semantic Network Analysis (SNA) is used to gain a deeper quantitative and qualitative insight into these texts. Besides, an exploratory investigation of different deep learning (DL) models has been performed to identify the posts speculating suicidal ideations. Furthermore, this study has integrated Explainable AI (XAI) techniques like Local Interpretable Model-agnostic Explanations (LIME) and Shapley Additive Explanations (SHAP) to enhance interpretability of the decisions taken by the DL models. Techniques like LDA and SNA offer a better understanding of the linguistic features of the suicidal posts, while the integration of the XAI techniques with the DL models elevates the transparency of their decisions. Contributions This study has developed an end-to-end web application, that can perform real-time classification of posts for suicidal ideation. Moreover, this application can provide insights into the rationale behind the taken decisions. This study aims to contribute to suicide prevention efforts through an innovative combination of computational techniques and AI-driven tools.},
  archive      = {J_ASOC},
  author       = {Md. Sabab Zulfiker and Nasrin Kabir and Al Amin Biswas and Md. Mashih Ibn Yasin Adan and Mohammad Shorif Uddin},
  doi          = {10.1016/j.asoc.2025.113813},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113813},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Identifying suicidal ideations from social media posts using deep learning and explainable AI-driven approach},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight network enhanced by attention-guided cross-scale interaction for underwater object detection. <em>ASOC</em>, <em>184</em>, 113811. (<a href='https://doi.org/10.1016/j.asoc.2025.113811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the image quality degradation caused by multipath effects and scattering in underwater environments, we propose a lightweight neural network architecture, PRCII-Net, optimized for small target detection under complex underwater conditions. First, a Progressive Re-parameterized Attention-based Intra-scale Feature Interaction module (PR-AIFI) is proposed, which improves the network performance while reducing the difficulty of training and maintaining training stability. Second, a feature pyramid network named as the Cross-scale Information Interaction Feature Pyramid Network (CII-FPN) is proposed, including the two main fusion structures. The CII-FPN not only fully utilizes shallow and deep information, but also enhances the network’s spatial representation and the interaction between deep feature layers, thereby boosting the detection capability for small targets. Meanwhile, to reduce the model’s size and resource consumption, 1x1 convolutions are introduced into the backbone network for efficient channel compression and cross-channel feature fusion, significantly lowering computational complexity. Experiments on the Detecting Underwater Objects (DUO) and Real-time Underwater Object Detection (RUOD) datasets demonstrate that PRCII-Net outperforms existing real-time neural network models in mAP and F1 scores while maintaining efficient inference on resource-constrained devices.},
  archive      = {J_ASOC},
  author       = {Dehua Zhang and Changcheng Yu and Zhen Li and Chunbin Qin and Ruixue Xia},
  doi          = {10.1016/j.asoc.2025.113811},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113811},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A lightweight network enhanced by attention-guided cross-scale interaction for underwater object detection},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preferences relative ordering by frequency inclusion technique (PROFIT) for optimizing performance evaluation. <em>ASOC</em>, <em>184</em>, 113807. (<a href='https://doi.org/10.1016/j.asoc.2025.113807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this investigation is to introduce the novel concept of the neutro-cardinal family of inclusion measures, a four-parameter family of fuzzy inclusion measures tailored for single-valued neutrosophic sets (SVNSs). These measures are built using a new scalar cardinality measure for SVNSs, termed weighted average cardinality, and incorporate logical operators such as single-valued neutrosophic Frank t-norms and their corresponding dual t-conorms. The versatility offered by this four-parameter family allows the variation of t-norms and t-conorms within each measure based on a fixed combination of parameters. This flexibly supports modeling various layers of human cognitive behavior, particularly the outermost states: optimism (via fuzzy Lukasiewicz t-norms and t-conorms), neutrality (via product and probabilistic sum operators), and pessimism (via min and max operators). Moreover, capturing these distinct mental states, the family allows combinations of them, enabling the representation of more complex and deeper cognitive processes. Consequently, the proposed inclusion measures serve as robust and versatile mathematical tools for designing artificial intelligence (AI) systems in multi-criteria decision making (MCDM) environments. Building upon this family, we present a new MCDM method named PROFIT (Preferences Relative Ordering by Frequency Inclusion Technique). PROFIT is designed as a simple yet effective decision-making approach that leverages the neutro-cardinal measures to support AI-based evaluation processes. It is investigated in the context of organizational management, in which it enables diligent performance evaluation. The PROFIT model’s data-driven and adaptive structure is consistent with resilience-focused initiatives like Resilient Manufacturing, ManuChain II, and Towards Resilience in Industry 5.0. As such, it serves as a strategic tool for optimizing decision-making, enhancing performance, and strengthening organizational resilience in dynamic and complex environments.},
  archive      = {J_ASOC},
  author       = {Madiha Qayyum and Dania Farooq and Muhammad Riaz and Muhammad Aslam and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2025.113807},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113807},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Preferences relative ordering by frequency inclusion technique (PROFIT) for optimizing performance evaluation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A state alignment-centric approach to federated system identification: The FedAlign framework. <em>ASOC</em>, <em>184</em>, 113800. (<a href='https://doi.org/10.1016/j.asoc.2025.113800'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents FedAlign, a Federated Learning (FL) framework, designed for System Identification (SYSID) of linear State-Space Models (SSMs) by aligning state representations. Local workers can learn linear SSMs with equivalent representations but different parameter basins. We demonstrate that directly aggregating these local SSMs via FedAvg results in a global model with altered system dynamics. FedAlign overcomes this problem by employing similarity transformation matrices to align state representations of local SSMs, thereby establishing a common parameter basin that retains the dynamics of local SSMs. FedAlign computes similarity transformation matrices via two distinct approaches. In FedAlign-A, we represent the global SSM in controllable canonical form (CCF). We use control theory to analytically derive similarity transformation matrices that convert each local SSM into this form. Yet, establishing global SSM in CCF brings additional alignment challenges in multi-input multi-output SYSID, as CCF representation is not unique, unlike in single-input single-output SYSID. In FedAlign-O, we address the alignment challenges by reformulating the local parameter basin alignment problem as an optimization task. We set the parameter basin of a local worker as the common parameter basin and solve least square problems to obtain the transformation matrices needed to align the remaining local SSMs. The experiments conducted on synthetic and real-world datasets show that FedAlign outperforms FedAvg, converges faster, and provides improved global SSM stability thanks to local parameter basins’ alignment.},
  archive      = {J_ASOC},
  author       = {Ertuğrul Keçeci and Müjde Güzelkaya and Tufan Kumbasar},
  doi          = {10.1016/j.asoc.2025.113800},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113800},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A state alignment-centric approach to federated system identification: The FedAlign framework},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal harmonics prediction for distribution systems powered by multi-energy sources using bidirectional long-short term memory combined with data sequence. <em>ASOC</em>, <em>184</em>, 113799. (<a href='https://doi.org/10.1016/j.asoc.2025.113799'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-energy resource aims to maintain a balance between energy output and load consumption and to ensure power continuity during different operating conditions. The harmonic distortions can be estimated from the output current of a harmonic source, which may not fully reflect its true harmonic distortions due to the interactions between the state changes at the power network level and the harmonic sources. System operators monitor each system's harmonic performance under different conditions of operation to find the actual contribution of grid-connected systems to harmonic-related issues. Development of machine learning algorithms leads to effective progress in the harmonic prediction and computation. In this paper, the combined data sequencing, and Bidirectional Long-Short Term Memory (Bi-LSTM) network has been exploited for the real-time harmonic prediction of future events in multi-energy sources. The validity of the proposed Model including the applications of ANFIS, ANNs, MLRA and LSTM is conducted on the two standard systems as IEEE 9-bus and IEEE 34-bus multi energy resources system that is associated with PV systems. The simulation results, based on climate changes of solar irradiance and ambient temperature in PV systems, demonstrate that the proposed methods can accurately forecast changes in total harmonic distortion (THD) as well as the voltage profile at the point of common coupling. The performance of Bi-LSTM, original LSTM, Machine Linear Regression (MLR), and Artificial Neural Networks (ANNs) techniques were assessed. These findings provide valuable insights. Four performance validation indices, RMSE, R-squared and MSE are considered to assess the performance of the competitive learning algorithms. The results showed that in the model IEEE 9-bus, Bi-LSTM outperformed all the applied methods as its RMSE value was 0.000019 while its MSE value was 3.61e-10 and finally, the Bi-LSTM had a higher value squared error (R 2 ) was equal 1 which indicates the effectiveness of Bi-LSTM for predicting sequential total harmonic distortion. On the other hand, in case study of IEEE 34-bus, the RMSE, MSE and R 2 are 0, 3.276e-30 and 1 using Bi-LSTM which means that the Bi-LSTM leads to the best performance validation indices compared to other competitive algorithms for the tested multi-energy systems.},
  archive      = {J_ASOC},
  author       = {Hasnaa M. El-Arwash and Almoataz Y. Abdelaziz and Ragab A. El-Sehiemy},
  doi          = {10.1016/j.asoc.2025.113799},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113799},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimal harmonics prediction for distribution systems powered by multi-energy sources using bidirectional long-short term memory combined with data sequence},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced robot path planning on rough terrain: A Q-learning-based multi-objective PSO algorithm. <em>ASOC</em>, <em>184</em>, 113798. (<a href='https://doi.org/10.1016/j.asoc.2025.113798'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning remains one of the most extensively studied problems in mobile robotics. While particle swarm optimization (PSO) has been widely adopted for this task, conventional implementations exhibit critical limitations including being prone to local optima, lacking population diversity, and having low accuracy — all of which compromise both the quality and efficiency of path planning solutions. To address these challenges, this paper proposes a novel hybrid algorithm called MOQLCPSO that synergistically integrates Q-learning (QL) with crossover operators into multi-objective particle swarm optimization (MOPSO) for car-like mobile robots operating in known static rough terrain environments. The proposed framework aims to generate collision-free optimal paths characterized by minimal length and terrain roughness through three key innovations: Firstly, we implement QL-based dynamic parameter adaptation to autonomously adjust PSO’s inertia weight and learning factors during optimization, effectively enhancing convergence towards the Pareto front. Secondly, a strategic crossover operator is introduced to augment exploration capabilities and maintain population diversity throughout the optimization process. Finally, comprehensive comparative simulations against state-of-the-art alternatives demonstrate MOQLCPSO’s superior performance metrics. The experimental results reveal statistically significant improvements in search accuracy, population diversity, and optimization efficiency across multiple terrain complexity levels. Notably, when benchmarked against the most competitive contemporary algorithm, MOQLCPSO achieves path length reduction of 0.64%, 2.42%, and 3.87%, terrain roughness reduction of 6.68%, 5.24%, and 4.72% in simple, moderately complex, and highly complex terrains, respectively. These advancements highlight the algorithm’s strong potential for deployment in multi-objective optimization scenarios ranging from autonomous mobile robot navigation and smart manufacturing resource allocation to power grid dispatch operations.},
  archive      = {J_ASOC},
  author       = {Zhaoxia Duan and Yi Zhang and Zhen Shao and Zhen Xu and Zhengrong Xiang},
  doi          = {10.1016/j.asoc.2025.113798},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113798},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advanced robot path planning on rough terrain: A Q-learning-based multi-objective PSO algorithm},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combined variable precision fuzzy rough set and its application in medical diagnosis. <em>ASOC</em>, <em>184</em>, 113797. (<a href='https://doi.org/10.1016/j.asoc.2025.113797'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data processing, variable precision fuzzy rough set plays a crucial role in removing noisy data. Different variable precision ideas have been used to solve various problems and achieve different goals. Among them, the variable precision ideas by Zhao and Yao are widely recognized by researchers. However, a single method is often insufficient to solve complex problems. In this study, we combined these two variable precision ideas and introduced a new variable precision fuzzy rough set model ( O - C-VPFR ), which includes the advantages and properties of the aforementioned two models. Next, using the concept of attribute importance in O - C-VPFR , we developed a simple, objective method for calculating attribute weights. Based on this method, we further developed a comprehensive decision-making method integrating Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) and Preference Ranking Organization Method for Enrichment Evaluations (PROMETHEE). The new method was applied to the problem of health risk assessment of pregnant women (HRPW, https://archive.ics.uci.edu/dataset/863/maternal+health+risk ). We conducted parameter and comparative analyses by randomly selecting 10 data points from HRPW, proving the stability and reliability of our method through the Pearson correlation coefficient. Further, we used the entire dataset and performed an ordered similarity experiment and a hypothesis testing experiment to verify the stability, effectiveness, and robustness of the proposed method. In all experiments, our method comprehensively ranked pregnant women, identified high-risk individuals, and enabled timely treatment.},
  archive      = {J_ASOC},
  author       = {Jingwen Xie and Lingqiang Li},
  doi          = {10.1016/j.asoc.2025.113797},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113797},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Combined variable precision fuzzy rough set and its application in medical diagnosis},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing evacuation path planning in high-rise building fires using an improved ant colony algorithm and dynamic window approach under smoke control scenarios. <em>ASOC</em>, <em>184</em>, 113796. (<a href='https://doi.org/10.1016/j.asoc.2025.113796'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional emergency evacuation strategies are constrained by limited adaptability to dynamic conditions and inefficient allocation of rescue resources. To assess the impact of smoke control facilities during high-rise fire evacuations, Building EXODUS software was used to simulate occupant behavior under the influence of air curtains and mechanical smoke exhaust systems. Furthermore, to address real-time obstacle avoidance in dynamic environments and during group movement in fire emergencies, a multi-person evacuation path planning method was developed by integrating an improved ant colony optimization algorithm with the dynamic window approach. This method incorporates a heuristic function that considers fire conditions and potential fields, along with a dynamic pheromone update strategy featuring reward and punishment mechanisms. The results indicate that the effectiveness of smoke control facilities in improving evacuation outcomes ranks as follows: combined operation of mechanical smoke extraction and air curtains, mechanical smoke extraction alone, and air curtains alone. Compared to the standard ant colony algorithm, the improved algorithm reduced planned path length by 7.71 %, decreased turn times by 73.30 %, and improved computational efficiency by 6.56 %. Furthermore, under scenarios with and without operational smoke control facilities, the improved algorithm combined with the dynamic window approach reduced path overlap areas by 11.76 % and 18.19 %, respectively, and shortened path lengths by 13.49 % and 14.19 %, respectively, compared to the Building EXODUS. The proposed method effectively addresses dynamic fire environments in high-rise buildings and provides a theoretical foundation for intelligent occupant evacuation.},
  archive      = {J_ASOC},
  author       = {Yaping Yu and Qinghe Wang and Lu Jin and Ji-nan Ding and Faqi Liu},
  doi          = {10.1016/j.asoc.2025.113796},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113796},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimizing evacuation path planning in high-rise building fires using an improved ant colony algorithm and dynamic window approach under smoke control scenarios},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ribonucleic-acid protein interaction prediction based on deep learning: A comprehensive survey. <em>ASOC</em>, <em>184</em>, 113795. (<a href='https://doi.org/10.1016/j.asoc.2025.113795'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interaction between Ribonucleic Acids (RNAs) and proteins, also called RNA Protein Interaction (RPI), governs biological processes, including gene regulation and disease pathogenesis. This comprehensive survey examines Artificial Intelligence (AI) applications in Deep Learning-based RPI Prediction (DL-based RPIP) through eight Research Questions (RQs), analyzing 179 studies (2014–2023). The key findings include: sustained technical evolution through embryonic (2014–2017), accelerated (2018–2022), and expansion phases (2023) (RQ1); hybrid models integrating Graph Neural Networks (GNNs) (for topological interface modeling) and Transformers (for long-range dependencies) achieve state-of-the-art performance (RQ4); pretrained language models enhance small-sample learning, but the cross-species generalization declines sharply with evolutionary distance (RQ5). Critical challenges persist, including data heterogeneity across databases, the scarcity of standardized benchmarks (RQ2), and balancing the trade-off between feature encoding and information preservation (RQ3). Future advancements require biologically informed DL architectures, multi-feature fusion, and rigorous cross-validation to bridge the generalization-interpretability gap (RQ8): This would accelerate the clinical translation of predictive tools (RQ6/RQ7). As the first comprehensive analysis spanning feature encoding, modeling, evaluation, applications, and tools, this work fills a critical gap in the DL-based RPIP literature.},
  archive      = {J_ASOC},
  author       = {Danyu Li and Rubing Huang and Chenhui Cui and Dave Towey and Ling Zhou and Jinyu Tian and Bin Zou},
  doi          = {10.1016/j.asoc.2025.113795},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113795},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ribonucleic-acid protein interaction prediction based on deep learning: A comprehensive survey},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level pooling self-adaptive evolutionary multi-objective gene selection algorithm for microarray data classification. <em>ASOC</em>, <em>184</em>, 113794. (<a href='https://doi.org/10.1016/j.asoc.2025.113794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gene selection is a vital preprocessing technique for cancer classification using microarray data, focusing on identifying a subset of genes that achieve high classification accuracy while minimizing the gene selection rate. Despite the prevalence of multi-objective optimization algorithms in microarray data classification, balancing high classification accuracy and effective guidance in microarray classification remains challenging for most existing algorithms. This study proposes a novel multi-objective gene selection method, MOGS-MLPSAE, which utilizes multi-level pooling and self-adaptive evolutionary techniques to enhance classification accuracy. MOGS-MLPSAE employs a Pareto-based ranking pool division strategy to facilitate cross-level learning among individuals and introduces a population-biased evolutionary mechanism with five rules to drive the population toward higher classification accuracy. Compared with seven state-of-the-art multi-objective algorithms across 14 microarray datasets, MOGS-MLPSAE achieves superior performance, with classification accuracy 1.56–8.04 % higher than other algorithms and the lowest gene selection rate (average 1 %, minimum 0.01 %). This study demonstrates MOGS-MLPSAE's effectiveness in balancing classification accuracy and gene selection rate, offering a robust solution for microarray-based cancer classification.},
  archive      = {J_ASOC},
  author       = {Min Li and Rutun Cao and Chen Jin and Junke Wang and Shaobo Deng and Xiang Yu},
  doi          = {10.1016/j.asoc.2025.113794},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113794},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-level pooling self-adaptive evolutionary multi-objective gene selection algorithm for microarray data classification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Activity transitions for semi-supervised federated learning in sensor-based human activity recognition. <em>ASOC</em>, <em>184</em>, 113793. (<a href='https://doi.org/10.1016/j.asoc.2025.113793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor-based Human Activity Recognition (HAR) is a core component in many real-world applications such as healthcare, fitness tracking, and smart environments. However, training effective HAR models is often constrained by limited labeled data and growing privacy concerns. Federated Learning (FL) offers a privacy-preserving solution by enabling collaborative model training without sharing raw sensor data. To further address the label scarcity challenge, we propose ATCoFed, a Semi-Supervised Federated Learning (SSFL) framework that introduces a novel pseudo-label filtering method based on activity transition patterns. Unlike existing approaches that rely solely on confidence thresholds, ATCoFed incorporates temporal context by using Long Short-Term Memory (LSTM) networks and Large Language Models (LLMs) as data-driven evaluators to validate the consistency of predicted activity sequences. This dual-evaluator mechanism improves the quality of pseudo-labels and enhances model robustness. Experimental results on benchmark HAR datasets demonstrate that ATCoFed consistently outperforms SSFL baselines, achieving better accuracy while maintaining computational and communication efficiency. These findings highlight the potential of activity-aware filtering to improve semi-supervised learning in privacy-preserving HAR applications.},
  archive      = {J_ASOC},
  author       = {Tori Andika Bukit and Ericka Pamela Bermudez Pillado and Bernardo Nugroho Yahya and Seok-Lyong Lee},
  doi          = {10.1016/j.asoc.2025.113793},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113793},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Activity transitions for semi-supervised federated learning in sensor-based human activity recognition},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TPCMEA: A tri-population evolutionary algorithm with adaptive stage-switching for complex CMOPs. <em>ASOC</em>, <em>184</em>, 113792. (<a href='https://doi.org/10.1016/j.asoc.2025.113792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems (CMOPs) involve the optimization of objective functions along with the satisfaction of constraints, presenting significant challenges in obtaining optimal solutions. To address difficulties such as conflicting objectives, complex constraints, disconnected and narrow feasible regions, this paper proposes a novel tri-population constrained multi-objective evolutionary algorithm (TPCMEA). This algorithm innovatively introduces an adaptive diversity-convergence stage-switching method (DCSSM), based on dual indicators of diversity and convergence, by dynamically monitoring the Euclidean distance distribution of the populations and convergence towards the optimal objective vector, overcoming the issues of premature convergence or resource wastage in traditional algorithms. Moreover, TPCMEA adopts a collaborative framework with three populations, each utilizing different search strategies to effectively solve complex CMOPs. These strategies encompass achieving rapid convergence under constraints, exploring unconstrained fronts to enhance solution diversity, and integrating information from the first two populations through knowledge transfer and compressive sampling strategies. Experimental results demonstrate that TPCMEA exhibits significant competitive advantages across the MW, LIRCMOP, CF benchmark test suites and real-world engineering problems, not only in terms of superior convergence and diversity but also displaying stronger robustness and adaptability in addressing issues related to narrow feasible regions and disconnected fronts.},
  archive      = {J_ASOC},
  author       = {Jun Chen and Xiaobo Li and Yuxin Zhao and Zhendi Ma and Zhongmei Han and Yanxia Bao},
  doi          = {10.1016/j.asoc.2025.113792},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113792},
  shortjournal = {Appl. Soft. Comput.},
  title        = {TPCMEA: A tri-population evolutionary algorithm with adaptive stage-switching for complex CMOPs},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective differential evolution algorithm integrating a directional generation mechanism for multi-objective optimization problems. <em>ASOC</em>, <em>184</em>, 113791. (<a href='https://doi.org/10.1016/j.asoc.2025.113791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective Evolutionary Algorithms (MOEAs) have gained significant attention due to their effectiveness in solving multi-objective optimization problems. However, when dealing with complex problems, they often face challenges such as low convergence accuracy and poor diversity. To address these issues, we propose a novel multi-objective differential evolution algorithm, MODE-FDGM, which integrates a directional generation mechanism. The key contributions are: (1) A directional-generation method leverages current and past information to rapidly build feasible solutions, boosting both speed and quality in exploring Pareto non-dominated space; (2) An update mechanism that combines crowding distance evaluation, iterating the population and incorporating historical information to enhance diversity and improve the ability to escape local optima; and (3) The introduction of an ecological niche radius concept along with a dual-mutation ecological niche selection evolution strategy, which improves exploration of unexplored spaces and preserves population diversity. Comparative experiments against 7 algorithms, including both classical and contemporary ones, on 24 benchmark functions demonstrate that the proposed algorithm markedly enhances the exploration of Pareto non-dominated solutions, exhibiting superior performance and advanced capabilities.},
  archive      = {J_ASOC},
  author       = {Zhuoxuan Yuan and Haibin Ouyang and Steven Li and Essam H. Houssein and Nagwan Abdel Samee},
  doi          = {10.1016/j.asoc.2025.113791},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113791},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective differential evolution algorithm integrating a directional generation mechanism for multi-objective optimization problems},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relaxation-based exploration and clustering-based exploitation for multimodal multi-objective optimization. <em>ASOC</em>, <em>184</em>, 113790. (<a href='https://doi.org/10.1016/j.asoc.2025.113790'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multi-objective optimization problems represent a specific type of multi-objective optimization problem where multiple distinct Pareto optimal solution sets (PSs) correspond to the same Pareto optimal front. Although the local PSs may not be as effective as the global PSs, obtaining the latter can be more costly. Therefore, the local PSs still hold some value for decision makers. However, many multimodal multi-objective evolutionary algorithms (MMOEAs) adopt the convergence-first criterion, which makes it challenging to obtain both the global and local PSs. To address the above issue, this paper proposes a two-stage dual-population coevolutionary algorithm with relaxation-based exploration and clustering-based exploitation (RCEA). Specifically, the relaxation-based exploration strategy defines an adaptive maximum Pareto rank, and relaxes the selection threshold for candidates from strictly non-dominated solutions to valuable solutions within this rank. Moreover, the clustering-based exploitation strategy performs a density-based decomposition on the population, separating different global and local PSs to facilitate more targeted evolution. During exploitation, a novel offspring generation operator is employed for intra-subpopulation crossover, preventing the waste of computational resources. Additionally, an improved convergence indicator is proposed to measure the convergence of solutions, which effectively handles the isolated solutions that may be erroneously identified as local Pareto optimal solutions by adaptively adjusting the neighborhood radius. Experimental results demonstrate that RCEA outperforms seven state-of-the-art MMOEAs on 70 benchmark problems.},
  archive      = {J_ASOC},
  author       = {Qianlong Dang and Zhiyang Zhang and Xiaochuan Gao and Tingting Wang},
  doi          = {10.1016/j.asoc.2025.113790},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113790},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Relaxation-based exploration and clustering-based exploitation for multimodal multi-objective optimization},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compute-efficient and backpropagation-free pseudoinverse learning for neural networks: A comprehensive survey. <em>ASOC</em>, <em>184</em>, 113789. (<a href='https://doi.org/10.1016/j.asoc.2025.113789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pseudoinverse learning algorithm is a non-gradient, efficient learning scheme originally designed for training single hidden layer feedforward neural networks. It has been developed into various variants and successfully applied across numerous fields. This paper provides a systematic review of the fundamental theories of the pseudoinverse learning algorithm and its major variants, outlining different types of neural networks and learning system architectures based on the pseudoinverse learning scheme. Furthermore, we summarize the fundamental ideas and methodologies of applying the pseudoinverse learning scheme to various learning tasks such as classification, representation learning, time series forecasting, incremental learning, automated machine learning, and content generation. We also summarize and compare the performance of pseudoinverse learning with representative competing baselines on several commonly used data sets based on existing literature reports. The results demonstrate that PIL exhibits significant efficiency advantages over gradient-based approaches (training time was reduced by 72.73% to 99.37%), aligning with its inherent gradient-free nature. Notably, recent PIL variants maintain this computational superiority while achieving enhanced performance compared to other gradient-free algorithms. In addition, we briefly introduce the representative applications of pseudoinverse learning in various fields. To the best of our knowledge, this is the first comprehensive review in this field to encompass all aforementioned aspects. It facilitates the synthesis and integration of existing knowledge from disparate studies. By highlighting limitations in prior works including the computational complexity in large-scale pseudoinverse computation, potential numerical instability for ill-conditioned matrices, risk of overfitting, and constraints in modeling multidimensional patterns, this paper also recommends directions for future research in this area.},
  archive      = {J_ASOC},
  author       = {Ke Wang and Pandi Liu and Mohammed A.B. Mahmoud and Ping Guo and Yafei Li},
  doi          = {10.1016/j.asoc.2025.113789},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113789},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Compute-efficient and backpropagation-free pseudoinverse learning for neural networks: A comprehensive survey},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient constrained multi-population cooperation search algorithm for multi-objective optimization of multireservoir operation. <em>ASOC</em>, <em>184</em>, 113788. (<a href='https://doi.org/10.1016/j.asoc.2025.113788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-objective optimization of multireservoir operation, complex nonlinear constraints often result in highly fragmented and discontinuous feasible regions, making it difficult for traditional algorithms to simultaneously achieve rapid convergence and maintain solution diversity. To effectively address this challenge, this paper proposes a novel Constrained Multi-Population Cooperation Search Algorithm (cMPCSA), which establishes an adaptive balance between global exploration and local exploitation through a cooperative evolutionary mechanism. The proposed algorithm achieves key advancements by constructing a modular multi-population framework with distinct subpopulation roles, integrating a constraint-independent environmental selection mechanism, and introducing a multi-factor learning strategy that combines edge, mean, and stochastic solutions to guide the search process more effectively. Experimental results on four mainstream multi-objective benchmark test suites demonstrate that cMPCSA significantly outperforms existing algorithms in terms of convergence performance and solution quality. Further application to a real-world multireservoir operation case confirms its robustness and superiority in coordinating multiple objectives such as hydropower generation, water supply reliability, and ecological flow protection. Overall, this study provides an efficient and scalable algorithmic tool for addressing complex multi-objective optimization problems in modern water resource management.},
  archive      = {J_ASOC},
  author       = {Zhong-kai Feng and Li Zhang and Xia-yu Wang and Fang Yang and Yi-hong Jiang and Sen Wang and Wen-jing Niu},
  doi          = {10.1016/j.asoc.2025.113788},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113788},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An efficient constrained multi-population cooperation search algorithm for multi-objective optimization of multireservoir operation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep insights into cognitive decline: A survey of leveraging non-intrusive modalities with deep learning techniques. <em>ASOC</em>, <em>184</em>, 113787. (<a href='https://doi.org/10.1016/j.asoc.2025.113787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive decline is a natural part of aging. However, under some circumstances, this decline is more pronounced than expected, typically due to disorders such as Alzheimer’s disease. Early detection of an anomalous decline is crucial, as it can facilitate timely professional intervention. While medical data can help, it often involves invasive procedures. An alternative approach is to employ non-intrusive techniques such as speech or handwriting analysis, which do not disturb daily activities. This survey reviews the most relevant non-intrusive methodologies that use deep learning techniques to automate the cognitive decline detection task, including audio, text, and visual processing. We discuss the key features and advantages of each modality and methodology, including state-of-the-art approaches like Transformer architecture and foundation models. In addition, we present studies that integrate different modalities to develop multimodal models. We also highlight the most significant datasets and the quantitative results from studies using these resources. From this review, several conclusions emerge. In most cases, text-based approaches consistently outperform other modalities. Furthermore, combining various approaches from individual modalities into a multimodal model consistently enhances performance across nearly all scenarios.},
  archive      = {J_ASOC},
  author       = {David Ortiz-Perez and Manuel Benavent-Lledo and Jose Garcia-Rodriguez and David Tomás and M. Flores Vizcaya-Moreno},
  doi          = {10.1016/j.asoc.2025.113787},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113787},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep insights into cognitive decline: A survey of leveraging non-intrusive modalities with deep learning techniques},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving adversarial transferability with neighborhood gradient information. <em>ASOC</em>, <em>184</em>, 113786. (<a href='https://doi.org/10.1016/j.asoc.2025.113786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are known to be susceptible to adversarial examples, leading to significant performance degradation. In black-box attack scenarios, a considerable attack performance gap between the surrogate model and the target model persists. This work focuses on enhancing the transferability of adversarial examples to narrow this performance gap. We observe that the gradient information around the clean image, i.e., Neighborhood Gradient Information (NGI) , can offer high transferability. Based on this insight, we introduce NGI-Attack, incorporating Example Backtracking and Multiplex Mask strategies to exploit this gradient information and enhance transferability. Specifically, we first adopt Example Backtracking to accumulate Neighborhood Gradient Information as the initial momentum term. Then, we utilize Multiplex Mask to form a multi-way attack strategy that forces the network to focus on non-discriminative regions, which can obtain richer gradient information during only a few iterations. Extensive experiments demonstrate that our approach significantly enhances adversarial transferability. Especially, when attacking numerous defense models, we achieve an average attack success rate of 95.2%. Notably, our method can seamlessly integrate with any off-the-shelf algorithm, enhancing their attack performance without incurring extra time costs.},
  archive      = {J_ASOC},
  author       = {Haijing Guo and Jiafeng Wang and Zhaoyu Chen and Kaixun Jiang and Lingyi Hong and Pinxue Guo and Jinglun Li and Wenqiang Zhang},
  doi          = {10.1016/j.asoc.2025.113786},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113786},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Improving adversarial transferability with neighborhood gradient information},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated semi-supervised learning for in-domain/Cross-domain person re-identification. <em>ASOC</em>, <em>184</em>, 113785. (<a href='https://doi.org/10.1016/j.asoc.2025.113785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Person Re-identification (Re-ID) task refers to retrieving images of the same person from different camera views. However, the task faces three major challenges: building a person dataset may infringe on personal privacy, collecting large-scale datasets for identity annotation requires high costs, and low quality local datasets can lead to performance bottlenecks. To address the above challenges, we propose Federated semi-supervised frameworks for the first time to solve in-domain/Cross-domain Re-ID problems, which can reduce annotation costs while protecting privacy. Firstly, we propose two different weighted aggregation federated learning strategies. Specifically, under the in-domain setting, labeled clients are utilized to determine the quality of unlabeled clients. Under the cross-domain setting, the model’s recognition capability is extended to each unlabeled domain by measuring inter-domain differences. In addition, a cascaded Global-personalized Model System and Personalized Model Knowledge Transfer Module are proposed to further address the domain-gap issue by sufficiently decoupling the global shared knowledge and the personalized knowledge unique to each domain. Finally, a Classifier Checking Module is proposed to significantly reduce computational costs by dynamically adjusting the pseudo-labels of unlabeled samples. Extensive experiments on multiple public datasets of varying scales and quality verify that the proposed frameworks can achieve acceptable performance at a lower cost while ensuring the security of personal data. Meanwhile, the effectiveness of the proposed training strategies and modules in other tasks is also verified, which proves their inspirational significance for research and applications in the fields of weakly supervised learning, user privacy protection and intelligent video surveillance.},
  archive      = {J_ASOC},
  author       = {Xinyuan Chen and Mingwen Shao and Yi Niu and Qiao Zhang},
  doi          = {10.1016/j.asoc.2025.113785},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113785},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Federated semi-supervised learning for in-domain/Cross-domain person re-identification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-guided triplet framework for synthetic data generation and semantic segmentation of railway fasteners under data scarcity and disparity. <em>ASOC</em>, <em>184</em>, 113784. (<a href='https://doi.org/10.1016/j.asoc.2025.113784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railway infrastructure monitoring faces significant challenges due to limited data availability, labor-intensive annotations, and imbalanced datasets—factors that hinder efficient fastener maintenance. To address these issues, this study proposes a novel three-phase framework that leverages attention-guided deep learning for the generation and analysis of synthetic railway fastener images. In the first phase, an attention-based Deep Convolutional Generative Adversarial Network (DCGAN) is introduced to generate high-fidelity synthetic images that closely mimic real-world conditions. Unlike conventional GANs, the attention mechanism enables the model to focus on critical structural features of fasteners, enhancing the realism and diversity of the generated data. The second phase applies advanced denoising techniques, with the DnCNN model outperforming traditional methods like Median Filtering in preserving fine details. The final phase employs a Convolutional Autoencoder (CAE) for accurate semantic segmentation, achieving 88.8 % accuracy on the synthetic dataset. This end-to-end methodology improves model generalizability, reduces reliance on manual labeling, and provides a cost-effective solution for automated railway inspection. By bridging the gap between real and synthetic data, it also lays the groundwork for scalable, intelligent infrastructure monitoring systems, supporting the advancement of safer and more efficient railway operations.},
  archive      = {J_ASOC},
  author       = {Qasim Zaheer and Momina Malik and S.Muhammad Ahmed Hassan Shah and Chengbo Ai and Hongzhi Wang and Zhiyu Liang and Shi Qiu},
  doi          = {10.1016/j.asoc.2025.113784},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113784},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Attention-guided triplet framework for synthetic data generation and semantic segmentation of railway fasteners under data scarcity and disparity},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An Actor–Critic-based adapted deep reinforcement learning model for multi-step traffic state prediction. <em>ASOC</em>, <em>184</em>, 113783. (<a href='https://doi.org/10.1016/j.asoc.2025.113783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic state prediction is critical to decision-making in various traffic management applications. Despite significant advancements in Deep Learning (DL) models, such as Long Short-Term Memory (LSTM), Graph Neural Networks (GNN), and attention-based transformer models, multi-step predictions remain challenging. The state-of-the-art models face a common limitation: the predictions’ accuracy decreases as the prediction horizon increases, a phenomenon known as error accumulation. In addition, with the arrival of non-recurrent events and external noise, the models fail to maintain good prediction accuracy. Deep Reinforcement Learning (DRL) has been widely applied to diverse tasks, including optimising intersection traffic signal control. However, its potential to address multi-step traffic prediction challenges remains underexplored. This study introduces an Actor–Critic-based adapted DRL method to explore the solution to the challenges associated with multi-step prediction. The Actor network makes predictions by capturing the temporal correlations of the data sequence, and the Critic network optimises the Actor by evaluating the prediction quality using Q-values. This novel combination of Supervised Learning and Reinforcement Learning (RL) paradigms, along with non-autoregressive modelling, helps the model to mitigate the error accumulation problem and increase its robustness to the arrival of non-recurrent events. It also introduces a Denoising Autoencoder to deal with external noise effectively. The proposed model was trained and evaluated on three benchmark traffic flow and speed datasets. Baseline multi-step prediction models were implemented for comparison based on performance metrics such as Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). The results reveal that the proposed method outperforms the baselines by achieving average improvements of 0.26 to 21.29% in terms of MAE and RMSE for up to 24 time steps of prediction length on the three used datasets, at the expense of relatively higher computational costs. On top of that, this adapted DRL approach outperforms traditional DRL models, such as Deep Deterministic Policy Gradient (DDPG), in accuracy and computational efficiency.},
  archive      = {J_ASOC},
  author       = {Selim Reza and Marta Campos Ferreira and J.J.M. Machado and João Manuel R.S. Tavares},
  doi          = {10.1016/j.asoc.2025.113783},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113783},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An Actor–Critic-based adapted deep reinforcement learning model for multi-step traffic state prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grammatical evolution for automatic design of actuated traffic signal control plans. <em>ASOC</em>, <em>184</em>, 113782. (<a href='https://doi.org/10.1016/j.asoc.2025.113782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In traffic networks, proper signal control design is essential to ensure a reasonable level of service. Signal control designs are becoming increasingly complex, with numerous settings that must be calibrated and set. This paper introduces a novel approach for handling this complexity by automatically generating optimal actuated signal control plans using Grammatical Evolution (GE). GE has proven its effectiveness in automating the design of different complex systems, such as neural networks and analog electronic circuits. GE’s distinctive mapping and representation capabilities make it a powerful candidate for optimizing various systems. In contrast to traditional optimization methods for actuated signal plans, which focus on specific parameters, such as green times and cycle length, the GE-based approach evolves complete plans, including phases, detector placements, and transit priority strategies. As a result, it eliminates the need for human intervention in the design process, making it more efficient and less time-consuming. The proposed approach was tested with an application to an isolated intersection in Haifa, Israel. The results showed that the automatically generated signal plan outperformed the existing plan by reducing delay times and queue lengths. Moreover, this method demonstrated its efficiency in generating reliable traffic signal plans under challenging traffic conditions.},
  archive      = {J_ASOC},
  author       = {Mahmud Keblawi and Tomer Toledo},
  doi          = {10.1016/j.asoc.2025.113782},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113782},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Grammatical evolution for automatic design of actuated traffic signal control plans},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized resource management in containerized clouds via hierarchical autoregressive network based workload prediction. <em>ASOC</em>, <em>184</em>, 113781. (<a href='https://doi.org/10.1016/j.asoc.2025.113781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swift growth of containerized applications calls for highly precise and real-time prediction of workloads to make resource allocation in cloud environments efficient. Current methods are deficient either by not being able to catch the complex long-term workload dependencies in patterns or by introducing too much computational overhead that degrades real-time performance. We propose a new integrated model where a transformer-based Hierarchical Autoregressive Network (HARN) is dynamically fused with TES. With the use of self-attention mechanisms in modeling complex temporal dynamics and long-range dependencies, on the one hand, HARN captures the detailed seasonal variation but robustly deals with the smoother short-term oscillations, giving TES ample opportunity to function. The model dynamically adjusts their contributions to fit the best weighting in real-time, hence leading to optimal predictability even for changing workloads. Our analysis on the publicly released Alibaba v2018 dataset shows an average improvement in Mean Absolute Error (MAE) of 15.50% and an improvement in Root Mean Square Error (RMSE) of 14.80%. Furthermore, experiments on a specially designed container dataset show even more significant improvements, with improvements of up to 25% in CPU metrics and 40% in memory metrics. These findings and minimal computational overhead emphasize the model’s ability to facilitate real-time proactive resource provisioning in dynamic cloud settings.},
  archive      = {J_ASOC},
  author       = {Shivani Tripathi and Angelina Shibu and Priyadarshni and Rajiv Misra and T.N. Singh},
  doi          = {10.1016/j.asoc.2025.113781},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113781},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimized resource management in containerized clouds via hierarchical autoregressive network based workload prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pervasive multifaceted process based generative adversarial network for image quality enhancement. <em>ASOC</em>, <em>184</em>, 113780. (<a href='https://doi.org/10.1016/j.asoc.2025.113780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The practice of Generative Adversarial Networks (GAN) has extended a lot of consideration in recent times. In most of the GAN methods are problem-specific related that are personalized to report numerous trials of individual application rather than performing other image improvement tasks. Furthermore, the basic GAN generators influence their boundaries in numerous image restoration and development use cases. Therefore, in this paper, we propose a generic GAN referred to as Pervasive Multifaceted Process based Generative Adversarial Network (PMPGAN). In this generator, we introduced multiple Convolutional Neural Networks (CNN) followed by Multi-dimensional Pyramid Pooling Module (MPPM) and Attention Module (AM), of which the input for the AM is given as low-level features and it produces output with enhanced feature map. Meanwhile, we enhanced the improvement outcome of the generated image with discriminator loss function. Finally, we tested the efficiency of the proposed system through extensive experiments on five challenging applications for image enhancement, image restoration, and infrared image translation to determine the dominance and efficiency in eliminating image degradation and producing visually interesting fake images. Our PMPGAN quantitatively outperforms several latest models. The results show that the PMPGAN model is superior to the existing models.},
  archive      = {J_ASOC},
  author       = {K. Balaji},
  doi          = {10.1016/j.asoc.2025.113780},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113780},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Pervasive multifaceted process based generative adversarial network for image quality enhancement},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-term time series forecasting by a frequency-domain enhanced temporal convolutional network with the stationary residual regularization. <em>ASOC</em>, <em>184</em>, 113779. (<a href='https://doi.org/10.1016/j.asoc.2025.113779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current time series models can resolve the long-term time series forecasting problem by leveraging artificial neural networks (ANNs) to capture complex temporal dependencies. However, the state-of-the-art ANNs for long-term prediction, Transformer-based models, have two inherent shortcomings that undermine both credibility and accuracy: losing temporal order information and ignoring information in prediction residuals. To fill these gaps, this study proposes a frequency-domain enhanced multi-scale temporal convolutional network (FMTCN) and a hybrid loss function regularized by stationary residuals called QM. Firstly, to preserve temporal order information, a multi-scale block with dilated causal convolution is developed as the core component of FMTCN, which can ensure the dependencies of predictions on sequentially ordered data. Secondly, an adaptive fusion mechanism for time and frequency domain patterns is designed to bridge the performance gap between convolution-based and Transformer-based models. Thirdly, to reduce residual autocorrelation, the proposed hybrid loss function integrates the Ljung–Box statistic into the mean squared error loss function as the regularization. Finally, extensive experiments across five real-world datasets are conducted to validate the proposed methods. Compared with the state-of-the-art method, the proposal improves the accuracy by 8.6% in the univariate long-term prediction and 6.1% in the multivariate long-term prediction.},
  archive      = {J_ASOC},
  author       = {Jing Wang and Yanbing Ju and Peiwu Dong and Tian Ju},
  doi          = {10.1016/j.asoc.2025.113779},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113779},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Long-term time series forecasting by a frequency-domain enhanced temporal convolutional network with the stationary residual regularization},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Loss functions in classification: An comprehensive overview and comparative study. <em>ASOC</em>, <em>184</em>, 113778. (<a href='https://doi.org/10.1016/j.asoc.2025.113778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loss functions are among the most fundamental components of a classifier’s learning processes and consequently can significantly affect the performance of classification methods. However, despite the substantial potential impact of loss functions on the classification accuracy, they have been incomprehensively investigated in the literature. For this reason, this paper tries to comprehensively evaluate the potency and impact of loss functions on the performance and accuracy in classification problems. For this purpose, fifty-five different loss functions in twelve categories—Linear Continuous Distance, Nonlinear Continuous Distance, Linear Semi-Continuous Distance, Nonlinear Semi-Continuous Distance, Linear Discrete Distance, Nonlinear Discrete Distance, Linear Continuous Direction, Nonlinear Continuous Direction, Linear Semi-Continuous Direction, Nonlinear Semi-Continuous Direction, Linear Discrete Direction, and Nonlinear Discrete Direction, are considered. In addition, in this paper, six distinct environmental pollutants/pollution benchmark data sets, three classifier types—statistical, shallow intelligence, and deep intelligence, are exemplary considered. Furthermore, in this paper, the most important measure of regular classification problems, the classification rate, has been chosen in order to compare these loss functions. The experimental results have unequivocally validated that the choice of loss functions has a significant impact on accuracy and classification rates. Numerical results of loss functions indicate that the difference between the lowest and the highest classification rate in the statistical, shallow intelligent, and deep learning classifiers, is averagely equal to 6.41 %, 5.16 %, and 2.24 %, respectively. It means that the model designer, by choosing the appropriate loss function, can averagely improve more than 4 % the obtained classification rate. Empirical results show that in the general perspective, the lowest performances of loss functions are overall related to the linear, continuous, and distance-based categories, in contrast to the highest ones, which are nonlinear, discrete, and direction-based. The exception to this outcome is the Zero-One family, in which all their loss functions, i.e., linear/nonlinear, distance/direction, are equivalent and yield the same accuracy. The best classification rate is also related to this family, that significantly better than other loss functions in all cases, as well as all classifiers. The Zero-One loss functions can averagely achieve a 98.62 % classification rate that 17.65 % is averagely higher than others. These evidences illustrate that, in addition to other effective features and factors, the loss function type should also be considered by environmental model designers in order to yield a more desired classification rate.},
  archive      = {J_ASOC},
  author       = {Fatemeh Chahkoutahi and Mehdi Khashei and Naser Molaverdi},
  doi          = {10.1016/j.asoc.2025.113778},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113778},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Loss functions in classification: An comprehensive overview and comparative study},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultra-low memory spatiotemporal decomposition recurrent neural networks for edge structural fault monitoring. <em>ASOC</em>, <em>184</em>, 113777. (<a href='https://doi.org/10.1016/j.asoc.2025.113777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hardware memory resources of microcontrollers in wireless sensor network nodes are limited, currently only capable of data acquisition and simple computing, making it difficult to perform neural network inference for edge fault monitoring. Running neural networks on microcontrollers can enhance the edge data processing capabilities of the nodes. Recurrent neural networks with short and medium term memory excel at processing sequential data. However, inference on microcontrollers consumes a significant amount of memory, necessitating solutions to the memory constraints. This study proposes a spatiotemporal decomposition method for recurrent neural networks to address the memory constraint issue when performing inference on resource-constrained nodes, thus enabling edge fault monitoring. The method decomposes recurrent neural networks in spatiotemporal dimensions, significantly reducing memory usage during operation. Additionally, it proposes model parameter storage and addressing techniques to ensure accurate reading of Flash data. Experiments have verified that this method can achieve 99.7 % accuracy in edge fault classification, consuming only 332 bytes of RAM and 768 bytes of Flash. The spatiotemporal decomposition method also provides a solution for running other time-series models on resource-constrained edge devices.},
  archive      = {J_ASOC},
  author       = {Hao Fu and Lei Deng and Baoping Tang and Shuaiwen Cui and Yuguang Fu},
  doi          = {10.1016/j.asoc.2025.113777},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113777},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ultra-low memory spatiotemporal decomposition recurrent neural networks for edge structural fault monitoring},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid SpinalNet-fuzzy-shufflenet for brain tumor detection using MRI images. <em>ASOC</em>, <em>184</em>, 113775. (<a href='https://doi.org/10.1016/j.asoc.2025.113775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, a significant portion of the global population is affected by the serious medical condition known as Brain Tumor (BT). Damage to healthy brain tissue is suspected, as it is currently the most important cause of a huge quantity of mortality. To prevent patients from dying, early detection is very essential. Despite various notable efforts and hopeful results in this area, accurate segmentation and categorization remain a difficult task. To address these gaps, a SpinalNet Fuzzy Shufflenet (SFShuffleNet) is proposed for the detection of BT. First, the input image is fed into the preprocessing stage, utilizing ROI extraction. Subsequently, the preprocessed image undergoes enhancement using histogram equalization techniques. Then, the enhanced image undergoes segmentation with Fuzzy Local Information C-Means (FLICM). Following segmentation, the image is augmented through sharpening, translation, random erasing, and resizing techniques. Features such as mean, variance, standard deviation, average, contrast, skewness, kurtosis, and entropy with the Local Frequency Descriptor (LFD) are extracted. Finally, the proposed SFShuffleNet, which combines SpinalNet and Shufflenet with fuzzy concept modifications, detects BT. SFShuffleNet achieved the highest accuracy, sensitivity, specificity, and F1-score of 91.46 %, 90.96 %, 92.78 %, and 90.79 %, respectively.},
  archive      = {J_ASOC},
  author       = {P Srinivasa Rao and Swathi Sowmya Bavirthi and G. Sharada and Ponnaboyina Ranganath and Vemuri Sailaja and G Vimala Kumari},
  doi          = {10.1016/j.asoc.2025.113775},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113775},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hybrid SpinalNet-fuzzy-shufflenet for brain tumor detection using MRI images},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enzyme classification integrating LSTM and prot-BERT sequence encoding. <em>ASOC</em>, <em>184</em>, 113774. (<a href='https://doi.org/10.1016/j.asoc.2025.113774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enzyme classification is essential for deciphering cellular and biological processes, driving targeted research, and influencing domains such as drug discovery and bioengineering. While various automated tools exist for enzyme classification, many are limited in scope or no longer operational. This study utilizes advanced artificial intelligence (AI) algorithms, including SVM, RF, simpleRNN, LSTM, ConvLSTM, and bidirectional LSTM, combined with numeric and Prot-BERT-based protein sequence encodings, to classify 1991 enzymes across 7 main classes, 69 subclasses, 216 sub-subclasses, and 1333 substrates. Among all trained models, the bidirectional LSTM model integrated with Prot-BERT sequence encoding (ECiLPSE) demonstrated exceptional accuracy of 99.14 % on the training set and 98.41 % on the test set, effectively capturing intricate sequence details. In addition to high accuracy, ECiLPSE achieved an F1-score of 0.99 (training set) and 0.98 (test set), with AU-ROC scores of 0.98 and 0.97, respectively. Precision and recall were both 0.99 on the training set and 0.98 on the test set. The 95 % confidence interval for test set accuracy (98.00 % - 99.97 %) further supports the model’s robustness and discriminative capability across classes. To benchmark performance, ECiLPSE was evaluated against four EC prediction tools (ECPred, CLEAN, EZYPred, EzyDeep), demonstrating superior accuracy and computational efficiency. The results from three case studies (using New-1277, Price-149, and halogenases datasets) highlight the limitations of the existing tools, underscoring the predictive accuracy, reliability, and applicability of ECiLPSE. ECiLPSE is available as a standalone tool for large datasets and as a web server for small datasets, offering a robust resource for enzyme classification, advancing computational approaches in enzyme research, and promising applications in drug discovery.},
  archive      = {J_ASOC},
  author       = {Anju Sharma and Vineet Diwakar and Rajnish Kumar and Prabha Garg},
  doi          = {10.1016/j.asoc.2025.113774},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113774},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enzyme classification integrating LSTM and prot-BERT sequence encoding},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent urban GNSS measurement uncertainty prediction by exploring the spatial characteristics with transformer. <em>ASOC</em>, <em>184</em>, 113773. (<a href='https://doi.org/10.1016/j.asoc.2025.113773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global navigation satellite system (GNSS) positioning accuracy is essential for civil applications. Unfortunately, in urban areas, GNSS signals are easily blocked and reflected by tall buildings, namely non-line-of-sight (NLOS) receptions. Thus, it is essential to classify these contaminated receptions and mitigate their pseudorange error for positioning improvement. This paper designed a Transformer-based network that utilizes satellite spatial characteristics to predict GNSS measurement uncertainty. The proposed method accurately classifies 89 % of satellites’ visibility and around 45 % compensation in NLOS pseudorange error, outperforming the state-of-the-art algorithms. By analyzing the attention matrix generated by Transformer, we explore how Transformer utilizes spatial characteristics for satellite measurement uncertainty prediction, which regards satellite visibility and pseudorange as different tasks for training.},
  archive      = {J_ASOC},
  author       = {Zekun Zhang and Penghui Xu and Guohao Zhang},
  doi          = {10.1016/j.asoc.2025.113773},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113773},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Intelligent urban GNSS measurement uncertainty prediction by exploring the spatial characteristics with transformer},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling self-supervised learning for handling the concept drift with ternary-adaptive ensemble. <em>ASOC</em>, <em>184</em>, 113772. (<a href='https://doi.org/10.1016/j.asoc.2025.113772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last several decades, drift detection and adaptation models have been trained on historical drift labels struggle with real-world data streams due to evolving distributions, impacting accurate future predictions. Existing methods update predictive models but often fail to retain previously learned patterns from streaming data, hindered by insufficient predefined labels for categorizing drift detection. To address these constraints, the proposed work introduces a two-task framework comprising a Self-Supervised Learning (SSL) model with a pretext task and a downstream task to efficiently adapt the model to evolving data distributions. In the pretext task, the proposed approach learns patterns from the unlabeled offline data in a self-supervised manner and utilizes the knowledge from the performance-based drift detector. In a subsequent downstream task, the model that has been enhanced with a forgetting-aware Ternary-Adaptive Ensemble (TAE) learner without requiring the drift labels. In the proposed approach, the TAE algorithm comprises drift-aware model updation methods for the Long Short-Term Memory (LSTM) to resolve forgetting in sequential data streams, and the three updation methods involve the pretext model’s weight transfer, Bayesian Optimization-based hyperparameter tuning, and Elastic Weight Consolidation (EWC). The proposed approach effectively handles drifts and outperformed while testing on the real-world weather and synthetic, mixed drift datasets with 82.6% and 92.36% accuracy, respectively.},
  archive      = {J_ASOC},
  author       = {Shubhangi Suryawanshi and Anurag Goswami and Pramod Patil},
  doi          = {10.1016/j.asoc.2025.113772},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113772},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Modeling self-supervised learning for handling the concept drift with ternary-adaptive ensemble},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain knowledge distillation for domain adaptation with GCN-driven MLP generalization. <em>ASOC</em>, <em>184</em>, 113771. (<a href='https://doi.org/10.1016/j.asoc.2025.113771'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) and domain adaptation (DA) represent potential research directions for reducing costs associated with deploying deep neural networks (DNN) in real-world applications. KD focuses on model compression, exploring methods to transfer informative representations from a complex model to a lighter one without incurring additional costs. Conversely, DA emphasizes the data distribution perspective, aiming to decrease labeling expenses by leveraging knowledge extracted from a labeled source domain to minimize classification errors in an unlabeled target domain. In this paper, we introduce a novel knowledge distillation (KD) approach with a teacher–student paradigm for domain adaptation (DA) tasks, termed Improved Cross-domain Knowledge Distillation (ICDKD). Specifically, we employ a graph convolutional network (GCN) classifier as the teacher model and a multilayer perceptron (MLP) classifier as the student model. During training, the teacher model utilizes a message-passing mechanism to capture the topology of the training data through neighbor information, thus explicitly enhancing semantic representations in each category to improve classification accuracy. Subsequently, the extracted knowledge from the GCN teacher model is distilled to the MLP student model. Finally, in the inference stage, only the MLP student model is utilized to meet the latency constraints of applications. Our proposed method effectively combines the strengths of both GCN and MLP classifiers to improve the classification performance and satisfy the real-world application requirements. We implemented our method on various DA benchmark datasets under unsupervised and semi-supervised domain adaptation settings, including ImageCLEF-DA, Office-31, Office-Home, VisDA2017, and DomainNet. The experimental results demonstrate the effectiveness of our proposed method on both CNN-based and ViT-based architectures, achieving outstanding classification performance compared to prior state-of-the-art domain adaptation methods.},
  archive      = {J_ASOC},
  author       = {Ba Hung Ngo and Tae Jong Choi},
  doi          = {10.1016/j.asoc.2025.113771},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113771},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cross-domain knowledge distillation for domain adaptation with GCN-driven MLP generalization},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy delphi-SERVQUAL model using degree of belief structure for assessing customer satisfaction in automotive after-sales services. <em>ASOC</em>, <em>184</em>, 113770. (<a href='https://doi.org/10.1016/j.asoc.2025.113770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel two-phase fuzzy multi-attribute decision-making (MADM) framework for assessing customer satisfaction in automotive after-sales services under uncertainty. The proposed model integrates a modified Fuzzy Delphi Method (FDM) with an enhanced fuzzy SERVQUAL approach, both embedded within a Degree of Belief (DoB) structure to capture evaluative ambiguity and confidence levels in expert and customer judgments. In the first phase, a belief-based FDM enables the efficient screening and prioritization of 58 service quality criteria using a single-round process that incorporates both optimistic and pessimistic expert viewpoints. In the second phase, a belief-driven SERVQUAL model evaluates customer perceptions and expectations from both stringent and lenient perspectives across six dimensions, including a newly introduced Digital Technology dimension that reflects emerging service delivery mechanisms. The model also features a δ-based sensitivity analysis to examine the impact of decision-making attitudes and a seven-zone classification system to categorize service quality gaps with high diagnostic precision. Application of the proposed framework in the Iranian automotive after-sales sector enabled the prioritization of 29 key service quality criteria from an initial pool of 58 indicators, with the most critical factors identified in the ‘Reliability’ and ‘Responsiveness’ dimensions. The resulting insights support evidence-based managerial actions, including the reallocation of resources toward high-impact service areas, targeted digital transformation initiatives, and the formulation of differentiated improvement strategies based on gap severity and belief-based customer expectations .},
  archive      = {J_ASOC},
  author       = {Mojtaba Elahi and Ramin Enayati and Mehdi Keramatpour},
  doi          = {10.1016/j.asoc.2025.113770},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113770},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fuzzy delphi-SERVQUAL model using degree of belief structure for assessing customer satisfaction in automotive after-sales services},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing a hybrid circular intuitionistic fuzzy framework to assess tourism 5.0 challenges. <em>ASOC</em>, <em>184</em>, 113769. (<a href='https://doi.org/10.1016/j.asoc.2025.113769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of Industry 5.0 (I5.0) in tourism is still in its early stages, and its complex implementation presents challenges that are not fully understood. Existing studies often focus on context-specific challenges, limiting the exploration of broader obstacles. This research aims to identify a comprehensive set of challenges, rank them, and evaluate their interdependencies in I5.0 adoption within tourism. A systematic literature review was conducted to identify key challenges, and expert input was gathered to validate and refine the findings. To evaluate the significance of the identified challenges, a novel extension of the Stepwise Weight Assessment Ratio Analysis (SWARA) method into the Circular Intuitionistic Fuzzy (CIF) environment, referred to as CIF-SWARA, was formulated to determine the relative weights of each challenge under uncertainty with more precision. Additionally, the Decision-Making Trial and Evaluation Laboratory (DEMATEL) method was extended using CIF sets, termed CIF-DEMATEL, to evaluate the causal relationships and relative influence among the challenges. The results from both methods were combined to derive final weights. Furthermore, a conceptual model was constructed using Total Interpretive Structural Modeling (TISM) based on the CIF-DEMATEL output, providing a detailed qualitative assessment of the interactions among the challenges. Findings highlight that “infrastructure issues” are the most urgent challenge requiring attention. Additionally, “technical and technological issues,” “acceptance and adaptability issues,” and “financial issues” emerged as the three most significant challenges for transitioning to “Tourism 5.0.” The model’s robustness was confirmed via sensitivity analysis, and comparative evaluations demonstrated consistent performance against established fuzzy environments. This study advances I5.0 research in tourism by identifying and modeling key challenges, offering valuable insights for policymakers.},
  archive      = {J_ASOC},
  author       = {Vahideh Shahin and Dragan Pamucar and Moslem Alimohammadlou},
  doi          = {10.1016/j.asoc.2025.113769},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113769},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Developing a hybrid circular intuitionistic fuzzy framework to assess tourism 5.0 challenges},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-adaptive discrete artificial bee colony algorithm based on block swap for steelmaking and continuous casting scheduling problem. <em>ASOC</em>, <em>184</em>, 113768. (<a href='https://doi.org/10.1016/j.asoc.2025.113768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the high temperature characteristics of the steelmaking continuous casting production, the temperature decreasing energy consumption (TDEC) in the processing process cannot be ignored. Therefore, this paper establishes a mixed integer mathematical model for the steelmaking continuous casting scheduling problem with TDEC (SCCSP TDEC ). The SCCSP TDEC chooses to minimize the objective functions of the total weighted earliness and tardiness, the TDEC and the makespan. To solve the SCCSP TDEC , an improved heuristic based on problem-specific features is proposed in this paper, which takes into account the completion time of the third stage’s cast, and the effect of the cast’s holistic nature. Then, a self-adaptive discrete artificial bee colony algorithm based on block swap (SDABC bs ) is proposed to solve the SCCSP TDEC . This strategy can adaptively select an optimal structure suitable for the current population, and effectively expand the search space of neighborhood solutions. Finally, this paper tests the SDABC bs algorithm based on the extensive instances generated according to the actual production process, and the performance of the SDABC bs algorithm is verified by comparing with other efficient algorithms. The experimental results show that the proposed SDABC bs algorithm is more effective for the SCCSP TDEC among all the algorithms in comparison.},
  archive      = {J_ASOC},
  author       = {Yang Yu and Guo-Dong Yang and Qichun Zhang and Liangliang Sun and Xinfu Pang and Yefeng Liu},
  doi          = {10.1016/j.asoc.2025.113768},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113768},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A self-adaptive discrete artificial bee colony algorithm based on block swap for steelmaking and continuous casting scheduling problem},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained mutation operators for community hiding using genetic algorithms. <em>ASOC</em>, <em>184</em>, 113767. (<a href='https://doi.org/10.1016/j.asoc.2025.113767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection plays a key role in uncovering group structures in networks, but its misuse can lead to privacy risks by exposing sensitive relationships. As a proactive defense, community hiding seeks to perturb the network structure to reduce the effectiveness of community detection algorithms. Given the NP-hard nature of this task, genetic algorithms (GAs) widely used due to their robust global search capabilities. However, existing methods lack effective guidance when dealing with vast solution spaces, resulting in inefficient exploration and suboptimal obfuscation outcomes. To address this, we propose Network- T opology- C ombined Community Information H iding A lgorithm (TCHA), a novel GA-based method that leverages node similarity information via node embedding to guide perturbations more effectively. TCHA introduces a multidimensional mutation operator that combines coarse-grained and fine-grained mutation strategies. These fine-grained mutations are performed in the embedding space and decoded back to graph edits, enabling more precise and topologically-aware perturbations. To evaluate the efficiency of this process, we introduce a novel metric based on expected path length within a mutation transition graph, offering deeper insight into evolutionary search dynamics. Experiments on six real-world networks demonstrate that TCHA achieves an average modularity reduction of 31.92% and an average normalized mutual information of 0.6447, outperforming baselines such as Q-Attack, NEURAL, and DICE. These results confirm the superiority of the embedding-guided fine-grained mutation strategy in enhancing community hiding effectiveness.},
  archive      = {J_ASOC},
  author       = {Shanqing Yu and Jintao Zhou and Meng Zhou and Yidan Song and Jiaxiang Li and Zeyu Wang and Qi Xuan and Silu Mu and Xiaolei Qian},
  doi          = {10.1016/j.asoc.2025.113767},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113767},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fine-grained mutation operators for community hiding using genetic algorithms},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting scour depth in the presence of aprons using XGBoost-optuna. <em>ASOC</em>, <em>184</em>, 113766. (<a href='https://doi.org/10.1016/j.asoc.2025.113766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the impact of an apron in mitigating scour downstream of a trapezoidal PK weir through an experimental study. Three apron lengths were tested with two sediment types under varying hydraulic conditions to address local scouring. Results show that longer aprons reduce scouring, especially at lower densimetric Froude numbers, affecting the location of the maximum scour depth and its volume. On average, apron lengths of 1 P , 1.5 P , and 2 P ( P is weir height) decrease the scour hole areas and volumes by approximately 69–77 %. Scour indices decrease by 73–90 % for corresponding apron lengths. New empirical equations have been proposed to aid in apron design, and the estimation of various scour hole geometries . Bayesian Optimized Neural Network (BONN), Extreme Gradient Boosting model tuned by Optuna algorithm (XGBoost-Optuna), and Random Forest were also developed for forecasting scour hole characteristics in the presence of apron. Various regression tests, including residual plots and uncertainty quantification, were imposed to compare the models. The results demonstrated that the XGBoost-Optuna model outperformed the other models, achieving a correlation coefficient ranging from 0.924 to 0.985, a root mean squared error between 0.055 and 5.072, and a mean relative percentage error of 7.14–11.71 %. Most forecasts generated by the XGBoost-Optuna model fell within ±20 % error margins, highlighting its superiority in predicting scour hole characteristics in the presence of the apron for PK weirs.},
  archive      = {J_ASOC},
  author       = {Chonoor Abdi Chooplou and Saeed Balahang and Masoud Ghodsian and Mohammad Vaghefi},
  doi          = {10.1016/j.asoc.2025.113766},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113766},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Predicting scour depth in the presence of aprons using XGBoost-optuna},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LanPPT: Enhancing landslide crack detection through pyramid pooling transformers. <em>ASOC</em>, <em>184</em>, 113765. (<a href='https://doi.org/10.1016/j.asoc.2025.113765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Landslide cracks, also known as tension cracks, are a major part of landslides. Based on the distribution of landslide fractures, the location of a landslide can be broadly described, and the stress distribution of the sliding mass can be inferred. Cracks at a landslide’s head, which are a key indicator of the displacement of the landslide body, can provide early warning signs for landslide hazards. The complete knowledge of the crack development features is still lacking because of many influencing elements and intricate reasons for fracture creation. Even though some early interventions reported models for automated crack identification utilizing advanced machine learning techniques, the problem still has not been solved to its full potential. Thus, an effective deep architecture for landslide crack segmentation is suggested to address these issues, utilizing a synergistic blend of vision transformers and the pyramid pooling concept. In this work, we use the universal vision transformer backbone called the Pyramid Pooling Transformer, and plug it into our pooling-based multi-head spatial attention to build a deep architecture that identifies and segments the landslide cracks, namely LanPPT. Experiments revealed that when a pyramid pooling transformer is used as the backbone network, it performs significantly better than many earlier convolutional neural networks and normal transformer-based networks in various vision tasks. Systematic experiments show that the proposed model achieved superior performance in terms of mIoU and FPS when compared with the chosen state-of-the-art baselines in the landslide crack detection task.},
  archive      = {J_ASOC},
  author       = {S. Sreelakshmi and S.S. Vinod Chandra},
  doi          = {10.1016/j.asoc.2025.113765},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113765},
  shortjournal = {Appl. Soft. Comput.},
  title        = {LanPPT: Enhancing landslide crack detection through pyramid pooling transformers},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differential evolution algorithm with cosine similarity-based individual reduction and symmetric uncertainty-based attribute recovery for feature selection. <em>ASOC</em>, <em>184</em>, 113764. (<a href='https://doi.org/10.1016/j.asoc.2025.113764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the increase in data scaling, effectively handling high-dimensional datasets has become a focal point of attention. Feature selection (FS), a method for dealing with datasets containing features, has emerged as a crucial technique in fields such as machine learning and data mining with the objective of selecting features that contain richer information while eliminating redundancy. Due to their remarkable performance in global search, evolutionary computation techniques hold substantial potential in the application of FS. However, many existing FS methods overlook the relationships between features. In the context of classification problems, this study presents a novel wrapper FS algorithm based on the differential evolution algorithm. The proposed method reduces redundant features among individuals based on cosine similarity and selectively and recovers certain features in the crossover phase according to the uncertainty similarity. In addition, a probabilistic-based initialization method is designed. The proposed algorithm significantly outperforms five other algorithms in terms of classification error rates over 18 experimental datasets. The experimental results demonstrate a significant enhancement in the performance of the proposed algorithm attributed to these two components.},
  archive      = {J_ASOC},
  author       = {Chunzhi Hou and Ziqian Wang and Yu Zhang and Yuki Todo and Jun Tang and Zhenyu Lei and Shangce Gao},
  doi          = {10.1016/j.asoc.2025.113764},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113764},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Differential evolution algorithm with cosine similarity-based individual reduction and symmetric uncertainty-based attribute recovery for feature selection},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion model based on stochastic differential equation with transformer for stock price prediction. <em>ASOC</em>, <em>184</em>, 113763. (<a href='https://doi.org/10.1016/j.asoc.2025.113763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of stock prices is an exemplary interdisciplinary problem, straddling the domains of finance, computer science, econometrics, and mathematics. The fundamental characteristics of stock price data, notably its non-linearity, non-stationarity, and considerable complexity, make the prediction of stock prices an exceptionally challenging task. In recent years, the domain of deep neural networks has shown substantial promise in terms of learning capacities, leading to significant advancements in the field of stock price prediction. However, most existing methods are still limited to predicting the closing price of the next day, rather than the future trend of stock prices, leaving investors with insufficient information for trading decisions. We propose an innovative model, DiffVT, which incorporates a Volatility Transformer for feature extraction from historical data. We introduced a de-stationary attention mechanism that integrates non-stationary information into the model to capture the dependencies in highly volatile stock price sequences. The output is then fed into an improved diffusion model based on stochastic differential equation (SDE). By iteratively solving the reverse-time SDE, our model generates a probabilistic distribution. This approach not only predicts the single-point stock price for the next day but also forecasts the future trend of stock prices over a period, providing a possible range of stock price movements. To our knowledge, DiffVT is the first model to combine a diffusion model with Transformer for stock price prediction. Extensive experiments on multiple stock indices and individual stock datasets demonstrate that DiffVT significantly outperforms state-of-the-art baseline methods, exhibiting excellent performance across various prediction window lengths. Specifically, compared to the second-best models in each domain, our approach achieves reductions of up to 11.73% in Mean Absolute Error (MAE) for point predictions, 17.23% in Continuous Ranked Probability Score (CRPS) for probabilistic predictions, and an improvement of 12.93% in the Sharpe ratio, clearly establishing its superior performance. Our code is available at https://github.com/SoraKsgn/DiffVT/ .},
  archive      = {J_ASOC},
  author       = {Chaoyang Wang and Guangyu Liu and Ling Zhu},
  doi          = {10.1016/j.asoc.2025.113763},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113763},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Diffusion model based on stochastic differential equation with transformer for stock price prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective coevolutionary bayesian learning for hyperspectral sparse unmixing. <em>ASOC</em>, <em>184</em>, 113762. (<a href='https://doi.org/10.1016/j.asoc.2025.113762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capability of multiobjective evolutionary algorithms (MOEAs) to directly address ℓ 0 norm minimization has introduced innovative perspectives for solving sparse problems. However, enhancing the search efficiency of MOEAs remains a formidable challenge, especially in high-dimensional sparse problems. To alleviate the above problem, we propose a novel multiobjective coevolutionary Bayesian learning framework for a classical sparse problem—sparse unmixing. Leveraging the spatial similarity inherent in hyperspectral image patches, the proposed framework alleviates the complexity of the sparse unmixing task by segmenting the original image into homogeneous regions using superpixel segmentation. These regions are then demixed independently and jointly optimized under a cooperative evolutionary paradigm. During the optimization, the row-sparsity parameter inferred through cooperative Bayesian learning is embedded into a specially designed image-level genetic strategy. This parameter can guide the evolutionary direction of the population, encourages the solution to conform to the structural characteristic and significantly improves search efficiency. Experimental results on synthetic and real datasets demonstrated the effectiveness of the proposed algorithm as compared with several sparse unmixing methods.},
  archive      = {J_ASOC},
  author       = {Yiting Liu and Maoguo Gong and Xiangming Jiang and Jianzhao Li and Yue Zhao and Yan Pu and Ziqi Di},
  doi          = {10.1016/j.asoc.2025.113762},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113762},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiobjective coevolutionary bayesian learning for hyperspectral sparse unmixing},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time anomaly detection in seasonal time series with conditional variational autoencoder. <em>ASOC</em>, <em>184</em>, 113761. (<a href='https://doi.org/10.1016/j.asoc.2025.113761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time anomaly detection in high-frequency seasonal time series is commonly addressed using prediction-based methods, which require waiting for new values to perform subsequent predictions and demand continuous processing over time. This work introduces a novel framework for real-time anomaly detection in seasonal time series, with a practical implementation using Conditional Variational Autoencoders based on Multilayer Perceptrons. Our approach eliminates the need for historical time series data at inference time, instead generating a one-shot long-term expected time series that enables immediate evaluation of streaming data with minimal computational resources. Empirical evaluations on real-world seasonal time series demonstrate that the proposed approach achieves state-of-the-art performance compared in both semi-supervised and unsupervised settings. The framework provides computational efficiency and low energy consumption, making it suitable for deployment in commodity hardware and offline environments.},
  archive      = {J_ASOC},
  author       = {Lorenzo Porcelli and Marcello Trovati and Francesco Palmieri},
  doi          = {10.1016/j.asoc.2025.113761},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113761},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Real-time anomaly detection in seasonal time series with conditional variational autoencoder},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weight optimized stacked LSTM with conditional random fields using self-adaptive generalized normal distribution optimizer for crop yield forecasting. <em>ASOC</em>, <em>184</em>, 113760. (<a href='https://doi.org/10.1016/j.asoc.2025.113760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the agricultural sector, estimating crop production is a difficult task. A crucial element in recent years has forecasted the crop prediction, which is dependent on outside variables include soil, water, and agricultural characteristics. Crop feature extraction is used to predict crop yield using deep learning-based approaches. The predictive ability of the method heavily relies on the nature of the collected information because there is a nonlinear translation between the unprocessed information and crop yield data. Agricultural marketing, crop production, efficient harvest management, and effective fertilization management rely heavily on crop yield forecasts. Numerous manual analyses are used for remote sensing, which is often used for crop prediction. Here, the deep learning technique is more crucial for predicting crop yields from the remote sensing images, and more complicated approaches are needed to derive the essential spatiotemporal features of the data. Thus, this paper suggests a new weight-optimized Stacked Long Short Term Memory with Conditional Random Field (SLSTM-CRF) and a Modified Self-Adaptive Generalized Normal Distribution Optimizer (MSGNDO) for the prediction of crop yield. This research work has the following phases; data collection, data preprocessing, weighted feature selection, and crop yield forecasting. Primarily, the standard agricultural data is taken from the benchmark sources. Then, data preprocessing is carried out to improve the quality of data. Next, the features are optimally chosen using a newly recommended MSGNDO, in which the weights are tuned via MSGNDO. Further, the tuned weights are multiplied by the extracted features. The final crop yield prediction is done via weight-optimized SLSTM-CRF, where the parameter optimization is done using the same MSGNDO method. The prediction performance of the suggested framework is compared with existing techniques using diverse error-based measures to show effective performance regarding Dataset 1 and Dataset 2. While considering the Root Mean Squared Error (RMSE) analysis, the suggested framework shows 22.4571 less than 29.88774 of CNN, 29.20486 of RNN, 27.9877 of ResNet-50, and 25.38448 of LSTM. Overall, the performance analysis of the developed model while using dataset 1 achieves 3.549 and 24.46 for Mean Absolute Error (MAE) and RMSE, respectively. While comparing dataset 2, the developed model shows values of 5.196 and 29.16 regarding MAE and RMSE measures. Hence, the entire experimental evaluation of the recommended methods shows more effective outcomes than the existing conventional models.},
  archive      = {J_ASOC},
  author       = {Shaik Shameer Basha and B S Nissar Begum},
  doi          = {10.1016/j.asoc.2025.113760},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113760},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Weight optimized stacked LSTM with conditional random fields using self-adaptive generalized normal distribution optimizer for crop yield forecasting},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimized logic mining method for data processing through higher-order satisfiability representation in discrete hopfield neural network. <em>ASOC</em>, <em>184</em>, 113759. (<a href='https://doi.org/10.1016/j.asoc.2025.113759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A high performance classification tool such as logic mining has emerged as one of the future computing systems for big data processing. The collaboration between logic and neural network resulted in extracting the most suitable induced logic to represent knowledge from real-life datasets. However, there are certain limitations within the current logic mining models including a non-flexible logical structure, non-optimal computation of the best logic, and the generation of overfitting solutions. Motivated by these limitations, a novel logic mining model incorporating the non-systematic Satisfiability, namely Random 3 Satisfiability in Discrete Hopfield Neural Network is proposed as a logical structure to represent the behaviour of the dataset. The proposed logic mining models used flexible logical structures to prevent overfitting solutions and optimize synaptic weight values. A new computational approach of the best logic by considering True Positive and True Negative values of the learning system is applied in this work to preserve the significance behaviour of the dataset. Furthermore, the comparative experiments of the logic mining models by utilizing various repository real-life datasets are conducted from repositories to assess their efficiency. In accordance with the results, the proposed logic mining model dominates in all the metrics for the average rank. The average rank for each metrics are Accuracy (1.9375), Precision (1.9375), Specificity (1.8125), Mathews Correlation (1.5625), and Fowlkes Mallows Index (2.3125). Numerical results and in-depth analysis demonstrate that the proposed logic mining model consistently produces optimal induced logic that best represents the real-life dataset for all the performance metrics used in this study.},
  archive      = {J_ASOC},
  author       = {Nurul Atiqah Romli and Nur Fariha Syaqina Zulkepli and Mohd Shareduwan Mohd Kasihmuddin and Syed Anayet Karim and Siti Zulaikha Mohd Jamaludin and Nur ‘Afifah Rusdi and Gaeithry Manoharam and Mohd. Asyraf Mansor and Nur Ezlin Zamri},
  doi          = {10.1016/j.asoc.2025.113759},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113759},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An optimized logic mining method for data processing through higher-order satisfiability representation in discrete hopfield neural network},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing nonlinear dependencies of mamba via negative feedback for time series forecasting. <em>ASOC</em>, <em>184</em>, 113758. (<a href='https://doi.org/10.1016/j.asoc.2025.113758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mamba is a rising model designed to distill complex patterns from historical data, providing predictive capabilities for time series forecasting tasks. Mamba’s similarity to linear-based models has been criticized due to its limited ability to capture nonlinear dependencies. In this work, we propose a novel model named Embedding C hannel Attention M aclaurin E instein Mamba (CME-Mamba 1 .) based on Mamba framework, with both Embedding Channel Attention and Maclaurin mechanisms incorporated. To further address gradient vanishing issues, we integrate Einstein FFT algorithms, ensuring robust performance against abnormal behaviors of Mamba-based architectures. Extensive experiments conducted on 11 real-world datasets with different numbers of variates, domain focus and granularity, reveal that CME-Mamba achieves state-of-the-art performance in both MSE and MAE, while maintaining reasonable memory efficiency and low time cost. The robustness and credibility of all results are substantiated by a comprehensive convergence and stability analysis. Statistically, consolidated by the Friedman Nonparametric Test and the Wilcoxon Signed-Rank Test, CME-Mamba ranks the first place with significance over counterparts. In addition, in terms of time and memory analysis, CME-Mamba is among the top three models for time and memory efficiency. Despite this, our results further demonstrate that the main contributor is the Embedding Channel Attention Block, which greatly enhances nonlinear dependencies over datasets. The Einstein FFT Block effectively suppresses gradient vanishing occurrences and contributes considerably to performance improvements, driving CME-Mamba both stable and promising. Moreover, the Maclaurin Block based on negative feedback is asymptotically stable without additional gradient vanishing issues and pioneered in achieving synergies with other blocks and greatly enhances nonlinear dependencies. With enhanced nonlinear dependencies generated from the synergy effect of all the three blocks, CME-Mamba grows excellent to uncover complex paradigms and predict future states in various domains, especially improving the performance for periodic and high-variate situations, such as traffic flow management ( ≈ + 8 % ), electricity predictions( ≈ + 6 % ).},
  archive      = {J_ASOC},
  author       = {Sijie Xiong and Cheng Tang and Yuanyuan Zhang and Haoling Xiong and Youhao Xu and Atsushi Shimada},
  doi          = {10.1016/j.asoc.2025.113758},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113758},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhancing nonlinear dependencies of mamba via negative feedback for time series forecasting},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential unsupervised–supervised learning for clustering time-dependent patterns using ellipsoidal calculus. <em>ASOC</em>, <em>184</em>, 113757. (<a href='https://doi.org/10.1016/j.asoc.2025.113757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces a sequential clustering algorithm that combines unsupervised and supervised learning methodologies using ellipsoidal calculus and recurrent neural networks (RNNs). The unsupervised clustering algorithm (ULCA) identifies ellipsoidal sets for the data by applying Lagrange multipliers. These sets are then optimized with gradient descent to adjust their volume and orientation. For time-dependent data, the optimized ellipsoidal sets are updated dynamically by an RNN, which refines their center, orientation, and axis sizes in response to changes in the data. The ULCA is compared to density-based spatial clustering (DBSCAN) and K-means algorithms, showing superior accuracy without the need for pre-determined cluster numbers. Additionally, the convergence of the ULCA and RNN algorithms, working sequentially, is formally proven using Lyapunov stability theory, ensuring continuous classification of data that evolves over time. This study demonstrates the advantages of the proposed hybrid method over traditional clustering algorithms.},
  archive      = {J_ASOC},
  author       = {Alejandro Guarneros and Mariana Ballesteros and Iván Salgado and Isaac Chairez},
  doi          = {10.1016/j.asoc.2025.113757},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113757},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sequential unsupervised–supervised learning for clustering time-dependent patterns using ellipsoidal calculus},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid quantum annealing for large-scale exam scheduling: Validation in real-world educational scenarios. <em>ASOC</em>, <em>184</em>, 113756. (<a href='https://doi.org/10.1016/j.asoc.2025.113756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study applied the hybrid quantum annealing to address complex exam scheduling challenges in large-scale educational scenarios through hybrid quantum annealing enhanced by graph-based preprocessing. By formulating the problem as a Quadratic Unconstrained Binary Optimization (QUBO) model and leveraging the D-Wave Advantage system, our method integrates quantum annealing with classical preprocessing to resolve constraints on exam room availability, student-course conflicts, and batch synchronization. The approach was applied in a university’s 2022 pandemic-era makeup exam scheduling for 1807 students and 215 courses (2749 exam instances) with zero conflicts. Experimental results show that hybrid quantum annealing consumes merely 86 ms of Quantum Processing Unit (QPU) execution time. In contrast, classical simulated annealing requires 13547 ms of Central Processing Unit (CPU) execution time for the same problem scale. This work bridges quantum computing and educational operations, offering a comparative analysis of hybrid algorithms in multi-constraint optimization domains.},
  archive      = {J_ASOC},
  author       = {Ziyu Zhou and Qing Chen and Chaojie Zhang and Mengtong Tan and Shuyan Li},
  doi          = {10.1016/j.asoc.2025.113756},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113756},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hybrid quantum annealing for large-scale exam scheduling: Validation in real-world educational scenarios},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-phase evolutionary search space shrinking for large-scale multi-objective feature selection. <em>ASOC</em>, <em>184</em>, 113755. (<a href='https://doi.org/10.1016/j.asoc.2025.113755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is essential in machine learning, especially for high-dimensional datasets, where irrelevant and redundant features can degrade performance and increase computational cost. In such settings, the search space becomes exponentially large and sparsely populated with relevant solutions, making effective exploration highly challenging. Despite progress in evolutionary methods, many existing algorithms struggle to scale or maintain sparsity. There is an urgent need for scalable strategies that intelligently reduce the search space while retaining essential features. Using feature importance to guide search space shrinking offers a powerful, domain-specific approach tailored for feature selection. This paper proposes a novel large-scale multi-objective evolutionary algorithm, LMSSS, that addresses sparse feature selection through a multi-phase search space shrinking strategy. Features are ranked based on correlation with class labels and frequency in an initial low-cost evolutionary process. A voting-based crossover operator prioritizes parent solutions with better classification accuracy, while a guided mutation mechanism reintroduces prematurely excluded features for reevaluation. These components enable efficient exploration of sparse, high-dimensional spaces. Experiments on 15 large-scale datasets demonstrate that LMSSS achieves superior classification accuracy with smaller, more informative feature subsets compared to state-of-the-art methods, highlighting its effectiveness and scalability.},
  archive      = {J_ASOC},
  author       = {Azam Asilian Bidgoli and Shahryar Rahnamayan},
  doi          = {10.1016/j.asoc.2025.113755},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113755},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-phase evolutionary search space shrinking for large-scale multi-objective feature selection},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive information mesh for multimodal brain tumor segmentation. <em>ASOC</em>, <em>184</em>, 113754. (<a href='https://doi.org/10.1016/j.asoc.2025.113754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utilizing advanced deep learning techniques for automatically segmenting brain tumors in multiparametric magnetic resonance imaging (mpMRI) is crucial in enhancing diagnostic processes. However, extreme data imbalance between brain tumors and non-tumorous tissues, as well as among different subregions within the tumors, poses significant challenges for precise tumor segmentation. In this study, we revisit the problem of positive and negative sample balance from the perspective of segmentation difficulty, integrating information entropy theory. We propose an Adaptive Information Mesh that resamples based on the conditional entropy between each pixel in the original data and the final segmentation target. This resampling approach standardizes the data to a uniform level of segmentation difficulty while preserving contextual information. Our methodology includes Multi-density Sparse Convolution and Topological Reconstruction Operator to process data effectively after AI mesh sampling. Multi-density Sparse Convolution exploits the advantages of mesh data to overcome the limitations of traditional sparse convolutions, which cannot exchange information over long distances due to a fixed receptive field. The Topological Reconstruction Operator rebuilds the topological relationships between mesh layers, facilitating information exchange. We conducted training on the BraTS 2018, 2019, and 2021 datasets. Comprehensive benchmark testing on the same metrics demonstrates that our performance is comparable to state-of-the-art structured networks in terms of accuracy while reasonably allocating computational resources. Results on the ISLES 2022 dataset for infarct segmentation in ischemic stroke underscore the robustness of our method.},
  archive      = {J_ASOC},
  author       = {Qingfan Hou and Yanjun Peng and Zhuofei Wang and Jian Jiang and Nan Lv},
  doi          = {10.1016/j.asoc.2025.113754},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113754},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive information mesh for multimodal brain tumor segmentation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An attention-based multiple band interaction network for motor imagery EEG decoding. <em>ASOC</em>, <em>184</em>, 113750. (<a href='https://doi.org/10.1016/j.asoc.2025.113750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-computer interfaces (BCIs) based on motor imagery electroencephalogram (MI-EEG) have been extensively used in many applications to assist disabled people. Key frequency bands play a crucial role in MI-EEG signal decoding. However, existing researches pay insufficient attention to the interaction among different bands, especially during feature extraction process. To address this issue, in this work, a multiple band interaction network, called MBINet, is carefully constructed, which adopts band-dependent multi-branch setting. Particularly, an attention-based guide block and a multi-scale interaction block are elaborately designed. The former allows to improve the feature extraction process of μ and β bands by the lights of full band characteristics, and the latter enables to promote multi-angle and multi-scale interactive fusion of high-order significant features from multiple bands. The performance testing of MBINet is performed on two publicly available MI datasets, namely the BCI competition IV-2a dataset and the High gamma dataset. The experimental results show that MBINet outperforms the state-of-the-art methods, with an average classification accuracy of 81.66% and 95.78%, respectively. MBINet provides a new perspective for decoding nonlinear time series, especially EEG signals, by emphasizing diverse interactions between key frequency bands.},
  archive      = {J_ASOC},
  author       = {Weidong Dang and Kefa Zhang and Haoyu Li and Dongmei Lv and Wei Guo and Zhongke Gao},
  doi          = {10.1016/j.asoc.2025.113750},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113750},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An attention-based multiple band interaction network for motor imagery EEG decoding},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The neighborhood rough set based on division-mining-fusion strategy. <em>ASOC</em>, <em>184</em>, 113749. (<a href='https://doi.org/10.1016/j.asoc.2025.113749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neighborhood rough set (NRS) model exhibits significant value in numerous data mining tasks. However, most existing NRS models are only suitable for data mining problems in a single dataset, and their comprehensive performance in processing data is not ideal. To address these two challenges, we develop a novel NRS model by applying the division-mining-fusion (DMF) strategy. Specifically, we first decompose the original dataset into multiple subsets. Then, a submodel is established for each subset, and finally, all submodels are integrated to develop a new NRS model. The experimental results demonstrate that the developed model can not only effectively handle the data mining tasks in scenarios with multiple datasets, but also has outstanding comprehensive performance. The NRS model developed in the paper provides a novel solution for efficiently processing large-scale complex data.},
  archive      = {J_ASOC},
  author       = {Conghao Yan and Qingzhao Kong and Wenbin Zhang},
  doi          = {10.1016/j.asoc.2025.113749},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113749},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The neighborhood rough set based on division-mining-fusion strategy},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable deep learning framework for lower limb activity classification using reconstructed sEMG signals in healthy and pathological subjects. <em>ASOC</em>, <em>184</em>, 113748. (<a href='https://doi.org/10.1016/j.asoc.2025.113748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing human activities from Surface Electromyography (sEMG) signals is fraught with challenges, including noise susceptibility and signal crosstalk. Addressing these, our study analyses sEMG data from 11 healthy and 11 pathological subjects across three distinct activities: sitting, standing, and walking. We introduce a pioneering preprocessing approach that integrates Bandpass Filtering, Wavelet Denoising, and Ensemble Empirical Mode Decomposition (EEMD) for signal enhancement. A significant aspect of our approach involves the reconstruction of signals by selecting the top 50% of Intrinsic Mode Functions (IMFs) based on entropy, Signal-to-Noise Ratio (SNR), correlation, and energy, effectively capturing the most informative features of the sEMG signals. To counterbalance dataset imbalances and facilitate robust feature extraction, we applied Adaptive Synthetic (ADASYN) sampling and segmented the data into 256 ms windows with a 25% overlap. Our Convolution Neural Network (CNN) achieves remarkable classification accuracies: for sitting, 99.4% in healthy and 99.2% in pathological subjects; for standing, 99.7% and 98.8% respectively; and for walking, 99.4% and 98.6%, respectively. Furthermore, the integration of Explainable AI (XAI) through Permutation Feature Importance (PFI) provides critical insights into the significant impact of muscle signals, particularly highlighting the Rectus Femoris (RF) muscle’s role in sitting with leg extension, BF muscles’s role in standing with flexion. This comprehensive and innovative methodology not only overcomes the inherent challenges of sEMG signal analysis but also enhances the interpretability and reliability of activity recognition, marking a significant advancement for personalized healthcare interventions.},
  archive      = {J_ASOC},
  author       = {Pratibha Tokas and Vijay Bhaskar Semwal and Sweta Jain},
  doi          = {10.1016/j.asoc.2025.113748},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113748},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Explainable deep learning framework for lower limb activity classification using reconstructed sEMG signals in healthy and pathological subjects},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mission assignment and path planning for ground forces using permutation-based simplified swarm optimization with Q-learning adaptation. <em>ASOC</em>, <em>184</em>, 113747. (<a href='https://doi.org/10.1016/j.asoc.2025.113747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study tackles task assignment and path planning for counteroffensive operations using a bi-level programming model inspired by spatial crowdsourcing. While existing models often prioritize centralized platform decisions, they tend to overlook the autonomy and real-time judgment of on-site participants, whose local actions critically affect coordination outcomes. To address this, we propose the Defender Deployment and Routing Model (DDRM), which integrates upper-level task assignment with lower-level route planning. To solve DDRM efficiently, we develop a hybrid nested framework integrating an Adaptive Permutation-Based Simplified Swarm Optimization (APSSO) algorithm with Dijkstra’s algorithm. APSSO incorporates a task-aware initialization strategy and a lightweight Q-learning mechanism for operator selection. As the first SSO-based approach with permutation-based operators, APSSO effectively handles discrete task allocation structures. Experimental results on 36 benchmark instances show that APSSO achieves the best performance in 34 cases compared to six tailored evolutionary variants. Statistical analysis confirms its superiority in solution quality, while the added Q-learning module introduces minimal computational overhead. These results highlight APSSO’s efficiency and robustness across varying problem scales.},
  archive      = {J_ASOC},
  author       = {Jun-Lin Lin and Chyh-Ming Lai and Song-Pei Wu},
  doi          = {10.1016/j.asoc.2025.113747},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113747},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Mission assignment and path planning for ground forces using permutation-based simplified swarm optimization with Q-learning adaptation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic event-triggered adaptive fuzzy admittance control of robotic systems with uncertainties. <em>ASOC</em>, <em>184</em>, 113746. (<a href='https://doi.org/10.1016/j.asoc.2025.113746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern industrial production and daily life, the increasing complexity of application scenarios has led to higher requirements for the compliance and safety of robotic systems. However, during robot control, a large number of redundant signals are often sampled, which significantly increases the communication burden. Therefore, how to substantially reduce the communication burden while ensuring satisfactory performance has become an urgent issue to be addressed. To address this challenge, this paper proposes a dynamic event-triggered adaptive fuzzy admittance control (DETAFAC) strategy for robotic systems with uncertainties, where the more aggressive dynamic event-triggered condition can significantly reduce the communication burden and the admittance model is used to reshape the desired trajectory of the robotic systems. Additionally, a fuzzy logic system (FLS) is utilized to address the uncertainties of the robotic systems, the update law of the FLS and the stability of the control system are examined using the Lyapunov stability theorem, and the dynamic triggering condition is formulated to prevent Zeno behavior. Simulation and experimental validations are performed, and the results demonstrate that the proposed DETAFAC strategy can achieve better performances in comparison to the similar approaches.},
  archive      = {J_ASOC},
  author       = {Jinzhu Peng and Xuxin Liu and Shuai Ding and Yaqiang Liu},
  doi          = {10.1016/j.asoc.2025.113746},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113746},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic event-triggered adaptive fuzzy admittance control of robotic systems with uncertainties},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boxing action recognition using inertial data and deep learning. <em>ASOC</em>, <em>184</em>, 113745. (<a href='https://doi.org/10.1016/j.asoc.2025.113745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the ongoing shift toward automated sports performance analysis by employing Deep Convolutional Neural Networks (DCNNs) for the classification of movement data in combat sports, specifically boxing. Using data from wearable inertial measurement units (IMUs), this study addresses the limitations of traditional, expensive video analysis by providing an accessible, cost-effective alternative that can be seamlessly integrated into athletes' training routines. IMUs offer a practical solution for continuous performance monitoring and feedback, establishing a foundation for automated performance assessment during training sessions. In this study, the classification accuracy and recall of DCNNs are rigorously compared with alternative algorithms, demonstrating a high overall recall of 99 % and accuracy of 91 %. Focusing on pad work training as a key application area, this work advances the automation of boxing action recognition, with implications for both training optimization and real-time scoring automation in competitive boxing. These findings underscore the potential for wearable technology and advanced machine learning methods to transform athletic performance evaluation and bring engineering innovation to sports training.},
  archive      = {J_ASOC},
  author       = {J. Brindha and G. Nallavan and Radana Vilimkova Kahankova and Radek Martinek},
  doi          = {10.1016/j.asoc.2025.113745},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113745},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Boxing action recognition using inertial data and deep learning},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive dual-network control for modular robots in human–robot interaction. <em>ASOC</em>, <em>184</em>, 113744. (<a href='https://doi.org/10.1016/j.asoc.2025.113744'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to address safety and compliance challenges in physical human–robot interaction (pHRI), this paper presents an adaptive dual-neural network (NN) control framework for modular robot manipulators (MRMs). The proposed approach enables seamless switching between autonomous trajectory tracking and compliant motion guided by human interaction. An adaptive fuzzy model uncertainty compensation method is employed to estimate the interaction torque that is utilized to detect physical contact, determining the MRM’s operation mode. Additionally, the reference trajectory tracking information is provided by human motion intention identification via NNs. This method avoids the need for external force/torque sensors and increases the intention recognition accuracy by jointly estimating human impedance parameters. The overall control scheme simultaneously incorporates adaptive fuzzy PD control and decentralized impedance control through a mode-switching structure, ensuring compliant and accurate motion in the two operation modes. A Lyapunov-based analysis is then conducted. The obtained results demonstrate that the tracking errors of the closed-loop system are uniformly ultimately bounded (UUB). An experimental validation for various tasks also demonstrates the high robustness and effectiveness of the proposed strategy. Note that all the procedures adopted in this paper are conducted following standard safety guidelines, with full consideration of ethical aspects in pHRI.},
  archive      = {J_ASOC},
  author       = {Yuexi Wang and Tianjiao An and Bo Dong and Mingchao Zhu and Yuanchun Li},
  doi          = {10.1016/j.asoc.2025.113744},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113744},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive dual-network control for modular robots in human–robot interaction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-informed machine learning: Data-driven reconstruction of delay differential equations models. <em>ASOC</em>, <em>184</em>, 113743. (<a href='https://doi.org/10.1016/j.asoc.2025.113743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the understanding of the dynamical mechanisms underlying complex systems, this study presents a novel data-driven framework for modeling Delay Differential Equations. The Galerkin-Koornwinder theory is combined with Neural Ordinary Differential Equations for the first time, addressing the significant challenge of reconstructing models that incorporate time-delay effects by approximating them with Ordinary Differential Equations within a rigorous mathematical framework. Leveraging Neural Ordinary Differential Equations to learn these approximate models, the approach achieves high interpretability and generalizability, effectively capturing the dynamics of various delay systems, including those with discrete delays, multi-time delays, and distributed delays. Extensive simulation experiments on models exhibiting bifurcation and chaos, as well as real-world biological data, demonstrate the superior performance of this method in long-term prediction and system dynamics reconstruction. When validated on a set of real-world biological experimental data, the long-term behavior prediction error was reduced from 11% to below 1%. The comparison with similar studies elucidates that the approach can accurately capture complex behaviors and outperforms existing methods in terms of prediction accuracy and generalization capability. All data and code are openly available, facilitating reproducibility and further research.},
  archive      = {J_ASOC},
  author       = {Xiyuan Chen and Zhong Liu and Qiubao Wang and Zikun Han},
  doi          = {10.1016/j.asoc.2025.113743},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113743},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic-informed machine learning: Data-driven reconstruction of delay differential equations models},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusion of data-driven models with a knowledge-guided loss function for flood forecasting. <em>ASOC</em>, <em>184</em>, 113742. (<a href='https://doi.org/10.1016/j.asoc.2025.113742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heavy rainfall frequently causes flooding disasters in basins of all sizes; however, small and medium-sized basins -typically defined as drainage areas less than 1000 km²- are particularly vulnerable due to their rapid runoff response, often resulting in casualties and property losses. Researchers worldwide have made excellent progress in advancing flood prediction capabilities by developing intelligent data-driven models. However, these models rely only on available data and ignore expert knowledge of floods and fail to account for the varying importance of prediction errors during flood and non-flood events in their training process. Therefore, we propose fusing data-driven models with expert knowledge frameworks by designing a custom loss function for accurate flood forecasting. The proposed model effectively interprets the complexity of flood events in small and medium-sized basins and introduces accurate results. By incorporating expert knowledge constraints, it emphasises the importance of prediction errors during critical flood events. The model was tested using hourly streamflow data from the Heihe and Tunxi basins in China. Results show that our model improves prediction accuracy by up to 80 % in root mean square error (RMSE) and 87 % in mean absolute error (MAE) in Heihe and increases the coefficient of determination (R²) by 66 % and the Kling–Gupta efficiency (KGE) by 58 % in Tunxi compared to baseline models such as INFORMER, TD-CNN-LSTM, STA-LSTM, STA-TCN, LSTM, CNN, TCN, and SVR. These findings demonstrate the model’s superior performance in providing accurate and reliable 6-hour-ahead (T + 6) flood forecasts.},
  archive      = {J_ASOC},
  author       = {Haider Malik and Jun Feng and Mohammed Abdallah and Jiru Zhang and Pingping Shao and Zaid Ameen Abduljabbar},
  doi          = {10.1016/j.asoc.2025.113742},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113742},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fusion of data-driven models with a knowledge-guided loss function for flood forecasting},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-organizing interval type-2 fuzzy neural network based on eigenvalue decomposition. <em>ASOC</em>, <em>184</em>, 113741. (<a href='https://doi.org/10.1016/j.asoc.2025.113741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an eigenvalue decomposition-based self-organizing interval type-2 fuzzy neural network (ED-SOIT2FNN) is proposed to tackle the identification problem of nonlinear systems. The network model determines both the structure and parameters of the network through online learning, which can realize the structure learning and parameter learning simultaneously. Firstly, in the structure learning process of ED-SOIT2FNN, the error criterion and the completeness criterion of fuzzy rules are used to verify whether the rules grow. Meanwhile, the eigenvalue decomposition method is adopted to find the less active rules for deletion, so that obtain a more compact network structure. Secondly, in terms of ED-SOIT2FNN parameter optimization and the characteristics of network parameters, they are divided into the linear and nonlinear ones. The algorithm of adaptive discount recursive partial least square is employed to optimize the linear parameters, which is conducive to improving the noise resistance of the network model and solving the data saturation problem. And the sliding window adaptive second-order algorithm with a forgetting factor is adopted to optimize the nonlinear parameters. Compared with the algorithm of gradient descent optimization, it can accelerate the convergence and achieve a good adaptability with stability. Finally, the proposed ED-SOIT2FNN was applied to four typical nonlinear examples for identification. The experimental results showed that compared with similar methods in the existing literature, the proposed ED-SOIT2FNN could produce a more compact network structure with higher accuracies of identification and prediction.},
  archive      = {J_ASOC},
  author       = {Panchao Wang and Taoyan Zhao and Jiangtao Cao and Ping Li},
  doi          = {10.1016/j.asoc.2025.113741},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113741},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Self-organizing interval type-2 fuzzy neural network based on eigenvalue decomposition},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Berth-quay crane-experiment allocation method based on improved genetic algorithm for cargo and scientific research port. <em>ASOC</em>, <em>184</em>, 113740. (<a href='https://doi.org/10.1016/j.asoc.2025.113740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Against the background of booming global shipping trade and growing demand for marine scientific research, multifunctional ports with both cargo transportation and scientific research functions, namely CSR_Ports, are facing significant operational scheduling challenges. Due to the intricate mutual influence and resource competition among cargo vessels, research vessels, and marine experiments, the existing method struggles to cope with the diversified demands of port operations. To solve the above challenges, this study considers the differences in infrastructure requirements between cargo vessels and research vessels, designs differentiated work areas, abstracts the berth-quay crane-experiment allocation problem into a two-dimensional packing problem with time window constraints, and establishes a dual-objective berth-quay crane-experiment allocation (BQCEA) model to minimize the vessels' average turnaround time and the average variation of the experiment start time. Then, given the limitations of genetic algorithms, such as insufficient adaptive ability and a tendency to fall into local optimality, an improved algorithm, namely NQRGA, is proposed based on neighborhood search, quantum multi-point crossover, and retention mechanism. Finally, the BQCEA model is combined with the NQRGA to propose a novel solution method for solving the berth-quay crane-experiment allocation problem, referred to as BQCEA_NQRGA. The effectiveness of the BQCEA_NQRGA method is evaluated using real operational data from two CSR_Ports in China. The test results show that, compared with the FCFS method, the BQCEA_NQRGA method achieves at least a 49.79 % performance improvement, and the optimization effect gradually increases to 101 % with the increase in the scheduling scale. Compared with the six advanced algorithms selected in this paper, the proposed NQRGA performs best in all six different instances. Notably, the BQCEA_NQRGA method can generate high-quality allocation schemes for 70 vessels and 14 experiments simultaneously within 100 s.},
  archive      = {J_ASOC},
  author       = {Ming-Wei Li and Xiang-Yang Li and Jing Geng and Zhong-Yi Yang and Wei-Chiang Hong},
  doi          = {10.1016/j.asoc.2025.113740},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113740},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Berth-quay crane-experiment allocation method based on improved genetic algorithm for cargo and scientific research port},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep reinforcement learning model based on DDPG considering attention mechanism and combined with GRU network for short-term load forecasting. <em>ASOC</em>, <em>184</em>, 113739. (<a href='https://doi.org/10.1016/j.asoc.2025.113739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term load forecasting plays a crucial role in power system operations and energy market efficiency. This paper addresses the challenge of capturing complex nonlinear patterns and temporal dependencies in electricity load data, which traditional forecasting methods often fail to handle effectively. We propose a novel deep reinforcement learning approach that combines attention mechanisms with gated recurrent units within a deep deterministic policy gradient framework (Attention-GRU-DDPG). The key innovation lies in treating load forecasting as a decision-making problem, where the model learns to adapt its predictions based on multivariate inputs including historical load, weather conditions, and electricity prices. Our approach uniquely integrates three complementary components: attention mechanisms for feature prioritization, GRU networks for temporal pattern recognition, and reinforcement learning for adaptive strategy optimization. Extensive experiments on Australian electricity market data demonstrate that our model achieves superior forecasting accuracy compared to ten benchmark methods. The proposed framework offers a practical solution for power system operators requiring accurate 24–168 h ahead load predictions, contributing to more efficient grid management and market operations.},
  archive      = {J_ASOC},
  author       = {Xin He and Wenlu Zhao and Zhijun Gao and Licheng Zhang and Qiushi Zhang and Xinyu Li},
  doi          = {10.1016/j.asoc.2025.113739},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113739},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel deep reinforcement learning model based on DDPG considering attention mechanism and combined with GRU network for short-term load forecasting},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel blood supply management model using evolutionary neural network. <em>ASOC</em>, <em>184</em>, 113738. (<a href='https://doi.org/10.1016/j.asoc.2025.113738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing demand and supply uncertainties and the short lifetime of blood products cause wastage of the blood gathered from donors. Also, there is a high shortage of blood products because of the limited number of donors and emergency demands. Hence, there is a great significance to constructing a blood supply management model by minimizing (1) transportation cost, (2) shortage cost, (3) wastage cost, (4) ordering cost, and (5) inventory holding cost. The different types of costs with constraints make blood supply management a challenging multi-objective combinatorial optimization problem. Earlier, neural genetic algorithms mostly concentrate on single-objective optimization problems. In this paper, we propose a blood supply management procedure using a network-driven evolutionary network (D2NNEA). A set of pointer networks are utilized to solve the multi-objective problem. The performance of the proposed technique is analyzed by comparing it with existing techniques and the superiority of the proposed technique in solving multi-objective optimization problems is verified.},
  archive      = {J_ASOC},
  author       = {Harinandan Tunga and Soumyadip Dhar and Samarjit Kar and Debasis Giri},
  doi          = {10.1016/j.asoc.2025.113738},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113738},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel blood supply management model using evolutionary neural network},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial unified learning for dynamic change detection in hyperspectral images. <em>ASOC</em>, <em>184</em>, 113737. (<a href='https://doi.org/10.1016/j.asoc.2025.113737'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image change detection (HSI-CD) aims to identify changes in bi-temporal hyperspectral images (HSIs) captured at different times in the same location. Existing algorithms often overlook the inherent class imbalance in HSI-CD, leading to poor generalization in detecting changes while introducing redundant computation in unchanged regions. This paper introduces a novel mechanism based on Partial Unified Learning for Dynamic Change Detection (PUL-DCD) to address these limitations. Particularly, a novel partial unified learning network is proposed, whose backbone is trained using multiple datasets, whilst the task-specific networks are trained independently with each individual dataset. In so doing, the network can maintain outstanding performance on specific datasets while having strong generalization ability. Furthermore, an innovative dynamic architecture is introduced that distinguishes between easy and hard regions for change detection, thereby optimizing parameter configuration and enhancing detection performance in challenging areas, while mitigating redundancy regarding unchanged information. Experimental results on three datasets show that PUL-DCD is competitive in both accuracy and efficiency.},
  archive      = {J_ASOC},
  author       = {Keyun Zhao and Ying Li and Qingping Zheng and Qiang Shen},
  doi          = {10.1016/j.asoc.2025.113737},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113737},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Partial unified learning for dynamic change detection in hyperspectral images},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Offline reinforcement learning for job-shop scheduling problems. <em>ASOC</em>, <em>184</em>, 113736. (<a href='https://doi.org/10.1016/j.asoc.2025.113736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep learning have shown significant potential for solving combinatorial optimization problems in real-time. Unlike traditional methods, deep learning can generate high-quality solutions efficiently, which is crucial for applications like routing and scheduling. However, existing approaches like deep reinforcement learning (RL) and behavioral cloning have notable limitations, with deep RL suffering from slow learning and behavioral cloning relying solely on expert actions, which can lead to generalization issues and neglect of the optimization objective. Offline RL addresses these challenges by learning from fixed datasets while leveraging reward signals, making it especially suitable for constrained combinatorial problems where online exploration is impractical. This paper introduces a novel offline RL method designed for combinatorial optimization problems with complex constraints, where the state is represented as a heterogeneous graph and the action space is variable. Our approach encodes actions in edge attributes and balances expected rewards with the imitation of expert solutions. We demonstrate the effectiveness of this method on job-shop scheduling and flexible job-shop scheduling benchmarks, achieving superior performance compared to state-of-the-art techniques.},
  archive      = {J_ASOC},
  author       = {Imanol Echeverria and Maialen Murua and Roberto Santana},
  doi          = {10.1016/j.asoc.2025.113736},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113736},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Offline reinforcement learning for job-shop scheduling problems},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrogate-assisted multi-objective covariance matrix adaptation evolution strategies. <em>ASOC</em>, <em>184</em>, 113728. (<a href='https://doi.org/10.1016/j.asoc.2025.113728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is one of the most preferred evolutionary algorithms for single-objective black-box optimization, its performance is limited in the multi-objective space due to its reliance solely on Gaussian-based mutation without any crossover for offspring generation. To address this limitation, this work proposes a surrogate-assisted multi-objective CMA-ES algorithm with an ensemble of offspring generation schemes. In the proposed algorithm, trial solutions are generated from an ensemble of the standard CMA-ES operator and a Genetic Algorithm-inspired operator. Consequently, the solutions are evaluated on a Gaussian Process-based surrogate model, and the solution with the best Expected Improvement (EI) is selected as the generated offspring. Experiments on the Walking Fish Group (WFG) test suite and 18 benchmark multi-objective Neural Architecture Search (NAS) problems demonstrate that the proposed approach is statistically superior to existing multi-objective CMA-ES variants and other state-of-the-art non-CMA-ES multi-objective algorithms. Specifically, the proposed algorithm achieves a win rate of 79.63% and 77.8% on the WFG and NAS test suites, respectively, against other CMA-ES variants, and demonstrates a 68.8% win rate against state-of-the-art algorithms on the NAS test suite.},
  archive      = {J_ASOC},
  author       = {Oladayo S. Ajani and Adeyinka Adedigba and Kalyana C. Veluvolu and Rammohan Mallipeddi},
  doi          = {10.1016/j.asoc.2025.113728},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113728},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Surrogate-assisted multi-objective covariance matrix adaptation evolution strategies},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-source domain adaptation approach with learning domain-specific representations for bearing fault diagnosis under limited samples. <em>ASOC</em>, <em>184</em>, 113727. (<a href='https://doi.org/10.1016/j.asoc.2025.113727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearings, vital to train traction motors, directly influence train safety due to their exposure to harsh environments and alternating loads, leading to various faults. Bearing fault diagnosis is thus critical for ensuring train safety. However, the challenge of data privacy and the scarcity of data make diagnosing faults difficult. Currently, transfer models based on single-source domain adaptation are used to address the above issues. However, data from multiple related domains may exist simultaneously in some scenarios. Therefore, learning fault knowledge from multiple domains and transferring it to the target domain for faults is a difficult problem. In view of this, we propose a multi-source domain adaptation approach with learning domain-specific representations (MDA-LDDSR) for bearing fault diagnosis under limited samples. First, MDA-LDDSR adds a domain-specific feature extractor (MAS-Net) for source and target domain to align the target domain with the distribution. After purifying the features by a partial feature selection strategy, we innovatively construct an intra-class alignment strategy to keep the marginal and conditional distributions of the data in alignment. Then, we utilize the instance-to-domain Mahalanobis distance to explicitly model the similarity between different domains. Finally, this similarity is assigned in the form of weights to multiple domain hypotheses. Superiorly, experiments in real rolling bearing fault diagnosis also show that the model has better convergence while it is characterized by high efficiency and robustness. The proposed approach has a strong advantage to be used for real-time bearing fault diagnosis when noise is added to the environment. Also, it obtains the desired diagnosis results compared to other approaches of the same type.},
  archive      = {J_ASOC},
  author       = {Qiang Zhou and Wengang Ma and Yadong Zhang and Jin Guo},
  doi          = {10.1016/j.asoc.2025.113727},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113727},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-source domain adaptation approach with learning domain-specific representations for bearing fault diagnosis under limited samples},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrounding and context-aware network for individual emotion complement in social networks. <em>ASOC</em>, <em>184</em>, 113726. (<a href='https://doi.org/10.1016/j.asoc.2025.113726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most sentiment analysis focuses on identifying individual emotional shifts related to a specific topic or predicting an individual’s emotional state in the future. However, it overlooks the influence of surrounding factors and contextual emotional information within social networks. Furthermore, it is also important to address the gap in understanding the missing emotions of individuals during critical historical moments. In this paper, we propose a surrounding and context-aware network for individual emotion complement(denoted as SCAEC) to infer missing emotional states at pivotal moments in history. The SCAEC network consists of an encoder layer for emotion embedding, a surrounding-aware layer, a context-aware layer, a feature interactive learning layer and an emotion distribution layer. Additionally, we introduce a decay long short-term memory (LSTM) network (DLSTM) within the SCAEC, which effectively extracts emotional features from individuals during moments of emotional absence and allows for the decay of emotional influence over time. We use DLSTM to extract associated emotional features as global features and apply multi-head attention to capture key emotional features as local features from posts/comments before and after moments of emotional absence. This allows us to obtain surrounding and context features based on the global and local features, respectively. The feature interactive learning layer then combines these features between the surrounding and context features to learn their interaction. Additionally, the emotion distribution layer simulates the emotional interaction between the individual and their surroundings. Finally, we derive the individual’s emotion distribution. Experimental results demonstrate that SCAEC model achieves an F1 score of 67.52% on the X and 68.98% on the Microblog dataset, marking an improvement of 1%–10% compared to baseline methods.},
  archive      = {J_ASOC},
  author       = {Sai Kang and YaJun Du and Xianyong Li and Xiaoliang Chen and Chunzhi Xie and Jia Liu and Yan-li Lee},
  doi          = {10.1016/j.asoc.2025.113726},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113726},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Surrounding and context-aware network for individual emotion complement in social networks},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spam bot detection on twitter platform using positional attention based dense convolutional neural network. <em>ASOC</em>, <em>184</em>, 113725. (<a href='https://doi.org/10.1016/j.asoc.2025.113725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, social media platforms such as Twitter and Facebook play a major role in everyday life because of the incredible opportunities they offer users. Twitter is the most essential social media platform since it allows people to express themselves through tweets. However, because of its popularity among a vast number of users, the Twitter platform is being abused by automated accounts known as bots. Since automated accounts transmit fake news, fake ideas, and fake products, early detection of bots on the Twitter platform is critical. Previously, researchers introduced ineffective methods for identifying social media bots. Positional Attention-based Dense Convolutional Neural Network (PAtt_Dense CNN) is a new deep learning-based spam bot detection framework proposed in this paper. Pre-processing of the incoming data includes stop word removal, tokenization, stemming, n-gram identification, user mention, URL and hashtag removal, vocabulary density, and richness analysis. From the pre-processed images, significant features are extracted utilizing N-gram level vectorizer, TF-IDF vectorizer, character level vectorizer, and Extended Bidirectional Encoder Representations from Transformer (EBERT). After feature extraction, binary water wheel plant optimization is used to select the best characteristics. Finally, spam bot detection and classification are performed using a PAtt_Dense CNN. The performance of the proposed technique is then evaluated by analyzing the performance indicators and comparing them to existing procedures. According to the comparison results, the proposed technique achieved the enhanced outcome in terms of Accuracy, Precision, Recall, and F1-Score of 97.8 %, 97.2 %, 98.3 %, and 99.2 %, respectively.},
  archive      = {J_ASOC},
  author       = {Hemal Girishkumar Shah and Hiren Joshi},
  doi          = {10.1016/j.asoc.2025.113725},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113725},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Spam bot detection on twitter platform using positional attention based dense convolutional neural network},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistency- and ordinal consensus-based multiple scenario model for group decision-making with incomplete probabilistic linguistic preference relations. <em>ASOC</em>, <em>184</em>, 113722. (<a href='https://doi.org/10.1016/j.asoc.2025.113722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete probabilistic linguistic preference relations (InPLPRs), as a practical expression to portray the uncertainty of things, can describe the information on decision makers’ (DMs’) evaluation of things in pairwise comparisons in group decision making with two dimensions simultaneously. This paper investigates a group decision-making (GDM) method with InPLPRs to express the preference information of DMs and establish a consensus reaching mechanism for multiple scenarios. First, to obtain incomplete information, we define the concept of opinion swing neighborhood based on referring to the opinions of others and analyzing the mental behavior of DMs. Furthermore, a missing information estimation model of InPLPRs considering the opinion swing neighborhood is developed to obtain consistent optimal estimates. Secondly, the ordinal consensus index is defined, facilitating a more accurate measure of consensus attainment. Then, we thoroughly explore the classification of decision situations using consistency, consensus, illogical rate, and distinguishing index. Based on this, the corresponding consensus optimization models are proposed for different decision scenarios. Subsequently, the DMs’ weights are presented for aggregating individual opinions with acceptable consistency and consensus into group opinions, and the collective opinions are ranked and selected. Finally, numerical examples, simulation experiments, and comparative analysis demonstrate the proposed method’s applicability, effectiveness, and advantages. The proposed method offers a comprehensive GDM approach based on InPLPRs, which can be applied to various real-world GDM scenarios, demonstrating broad applicability.},
  archive      = {J_ASOC},
  author       = {Ran Dang and Peide Liu and Peng Wang and Luis Martínez},
  doi          = {10.1016/j.asoc.2025.113722},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113722},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Consistency- and ordinal consensus-based multiple scenario model for group decision-making with incomplete probabilistic linguistic preference relations},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Equidistant deep embedding-based multi-label group activity recognition with dependency-constrained training. <em>ASOC</em>, <em>184</em>, 113721. (<a href='https://doi.org/10.1016/j.asoc.2025.113721'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group activities in real-world scenarios are often complex and require multiple labels for adequate representation, as they involve multifaceted social interactions among individuals within a small group setting. Existing group activity recognition (GAR) methods primarily focus on model inference, overlooking the inherent challenges of multi-label learning (MLL). One common approach to MLL is the label powerset (LP) method, which transforms multi-hot label vectors into one-hot vectors, converting the multi-label problem into a single-label multi-classification problem. However, this projection loses correlations among active elements in multi-hot vectors, hindering the capture of inter-activity dependencies. To address this limitation, we propose a novel equidistant deep embedding-based (EDE) multi-label GAR framework with dependency-constrained training, building upon the LP approach. Our framework leverages a deep embedding network with self-supervised equidistant regularization loss to project multi-hot label vectors into evenly spaced dense vectors, which not only facilitate problem transformation but also contain latent activity patterns, including label correlations. We treat these dense vectors as new labels and design a corresponding deep learning and classification (DLC) strategy that optimizes all GAR model parameters except for the classification layers. Additionally, we propose a training-only auxiliary branch, dubbed TransOvR module, to bolster the model’s capacity for inter-activity dependency reasoning. By leveraging Transformer’s context-aware capability, this module facilitates interactions between multiple binary classifiers, focusing on correlations between activities. Our extensive experiments demonstrate the effectiveness of our method, outperforming state-of-the-art multi-label GAR methods.},
  archive      = {J_ASOC},
  author       = {Lindong Li and Linbo Qing and Pingyu Wang and Yang Xiao and Wang Tang and Yonghong Peng},
  doi          = {10.1016/j.asoc.2025.113721},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113721},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Equidistant deep embedding-based multi-label group activity recognition with dependency-constrained training},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced nonlinear optimization of low- and high-resolution medical images using adaptive deep spearman correlation analysis (D-SCA) for pattern sequence recognition. <em>ASOC</em>, <em>184</em>, 113720. (<a href='https://doi.org/10.1016/j.asoc.2025.113720'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the state-of-art model for those healthcare multimedia datasets that have nonlinear limitations during the processing of multi-dimensional or non-linear data that usually decrease the accuracy rate and increase computational cost as per computational resources. Such as correlation among the low-resolution images to high-resolution images, and videos, the reason is non-linearity between data, non-linear dimensions or variation and illusion in the data. The proposed state-of-the-art model uses multiple techniques with transfer learnings approach to solve these issues. This paper further explains the details of the proposed deep convolutional neural network model for visual feature maps extraction and then followed by the proposed algebraic extension of Spearman correlation analysis to create the relationship of low-resolution image to high-resolution image with adaptive optimization. Then it leads to the next component of model as Radial Basis Function Network (RBFN) for non-linear mapping among LR to HR images, for classification the hybrid Xception deep learning model is used and implemented on four benchmark datasets.},
  archive      = {J_ASOC},
  author       = {Muhammad Saddam Khokhar and Misbah Ayoub and Zakria and Abdullah Lakhan},
  doi          = {10.1016/j.asoc.2025.113720},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113720},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advanced nonlinear optimization of low- and high-resolution medical images using adaptive deep spearman correlation analysis (D-SCA) for pattern sequence recognition},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-modal deep interaction and modal-aware aggregation network for visible and infrared tracking. <em>ASOC</em>, <em>184</em>, 113719. (<a href='https://doi.org/10.1016/j.asoc.2025.113719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, developing a robust RGB-Thermal (RGBT) tracking method in complex environments remains challenging in effectively mining and fusing cross-modal complementary information, enhancing modal perception capabilities, and improving the representation ability of fused semantic features. To address these challenges, we propose a novel architecture called Multi-branch Cross-modal Deep Interaction Fusion and Adaptive Aggregation Integrating Hybrid Attention Semantic Enhancement Network (MCFTNet). Specifically, MCFTNet first extracts modality-specific features through dedicated branches, followed by designing a cross-modal deep interaction fusion network to achieves deep interaction and comprehensive fusion of cross-modal features through a fusion branch as the medium. Furthermore, a modal-aware adaptive aggregation module is developed to dynamically aggregates high-resolution features from different branches, while significantly enhancing the discriminative ability of multi-modal features. Finally, a hybrid attention semantic enhancement module is introduced that combines carefully designed enhanced multi-head attention and hierarchical attention to optimize the fused semantic features, thereby achieving highly accurate prediction of target position and shape. Extensive experiments on three mainstream public benchmark datasets, GTOT, RGBT234, and LasHeR, demonstrate the effectiveness and robustness of our proposed method.},
  archive      = {J_ASOC},
  author       = {Xiang Liu and Haiyan Li and Victor Sheng and Yujun Ma and Xiaoguo Liang and Guanbo Wang},
  doi          = {10.1016/j.asoc.2025.113719},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113719},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cross-modal deep interaction and modal-aware aggregation network for visible and infrared tracking},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Embedding neural sampling and adversarial bandit into gene expression programming for symbolic regression. <em>ASOC</em>, <em>184</em>, 113718. (<a href='https://doi.org/10.1016/j.asoc.2025.113718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary computation methods for symbolic regression problems use a search method to actively explore the mathematical expression space to find a solution. However, the evolutionary computation search process lacks a clear direction due to the randomness of evolutionary operations. In contrast, deep learning methods focus on learning a clear mapping from a given dataset to a mathematical function, but the learning process does not generally involve an active search of the potential solution space. To combine the advantages of the active search of evolutionary computation and the clear mapping direction of neural networks, this paper proposes a novel algorithm called GVAE-ABGEP. GVAE-ABGEP incorporates a grammar variational autoencoder and adversarial bandit into gene expression programming to guide its search process. GVAE-ABGEP partitions the mathematical expression space into many subspaces. It then leverages an adversarial bandit — AvgHExp3 to choose a subspace. In the selected subspace, it then utilizes an autoencoder to sample individuals whose fitnesses are near the local optima, and executes crossover, mutation, and selection in evolutionary computation to explore the global optima. Experiments on 18 symbolic regression and 12 physics benchmarks show that GVAE-ABGEP outperforms three baseline gene expression programming methods and six baseline machine learning methods.},
  archive      = {J_ASOC},
  author       = {Qiang Lu and Qiuchen Yuan and Dawei Li and Congwen Xu and Jake Luo and Zhiguang Wang},
  doi          = {10.1016/j.asoc.2025.113718},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113718},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Embedding neural sampling and adversarial bandit into gene expression programming for symbolic regression},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based analysis of problem space and genetic programming classifier performance using optimal transport dataset distance. <em>ASOC</em>, <em>184</em>, 113716. (<a href='https://doi.org/10.1016/j.asoc.2025.113716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding and interpreting machine learning tasks is a non-trivial endeavor. To this end, many works have proposed creative ways to organize and visualize a problem dataset, the learning process itself, or the models produced after learning has occurred. Moreover, as the scope of machine learning increases, the re-purposing or specialization of models becomes more common, or as continued automation is sought for algorithm deployment, understanding sets of problems has also become relevant. The present work proposes a graph-based representation of a set of machine learning problems, a novel characterization of the relationships and structures that are present in such a set. While similar proposals have been made before, the proposed methodology employs a recent and unique metric between problem datasets, the Optimal Transport Dataset Distance, which allows for the computation of a mathematically rigorous distance matrix for problem sets. This allows for the construction of a graph-based representation, while previous works relied on representations based on problem meta-features that were defined heuristically. Results show that the resulting graph representation of a problem set exhibits structural properties that are related to empirical indicators of problem difficulty, such as the average error, the size of the dataset, and the class imbalance. A similar analysis using meta-features shows that the structure of the resulting graphs cannot capture the same nuanced relationships between problems.},
  archive      = {J_ASOC},
  author       = {Joel Lee Nation and Daniel Fajardo and Yuliana Martínez and Arnoldo Díaz-Ramírez and Leonardo Trujillo},
  doi          = {10.1016/j.asoc.2025.113716},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113716},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph-based analysis of problem space and genetic programming classifier performance using optimal transport dataset distance},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based deep reinforcement learning for dynamic scheduling of flexible job-shop considering worker fatigue and multi-skill factors. <em>ASOC</em>, <em>184</em>, 113712. (<a href='https://doi.org/10.1016/j.asoc.2025.113712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the dynamic scheduling problem of flexible job shops (DFJSP) has garnered significant attention. However, most DFJSP studies focus solely on machine constraints, often overlooking the crucial factor of worker constraints. As an essential resource within the production process, the efficient utilization of workers can substantially enhance production efficiency. Consequently, the scheduling problem in dual-resource constrained (DRC) production systems, where operation times fluctuate according to worker skill levels and fatigue, is investigated. Considering new job arrivals as dynamic events, this study comprehensively integrates worker skill and fatigue factors, with the goal of minimizing total cost and makespan by developing a dual-resource constrained dynamic flexible job-shop scheduling (DRC-DFJSP) optimization model. To enable real-time model resolution in dynamic environments, an end-to-end deep reinforcement learning (DRL) scheduling method is introduced. The decision-making process is formulated as a Markov decision process (MDP) and guided by a reward mechanism tailored to optimization objectives. An enhanced proximal policy optimization (PPO) algorithm, combined with an adaptive clipping mechanism and a prioritized experience replay buffer, is applied to handle operation ordering, machine assignment, and worker allocation within the DRC-DFJSP framework. To further enhance decision-making capabilities, an attention-based graph neural network feature extraction method is incorporated to capture the intricate connections between operations, machines, and workers, resulting in a more precise characterization of the workshop state. Numerical experiments and case studies demonstrate that the proposed scheduling method surpasses existing strategies in dynamic environments that account for worker skill and fatigue levels.},
  archive      = {J_ASOC},
  author       = {Yiwen Hu and Zequn Zhang and Jie Chen and Dunbing Tang and Qixiang Cai},
  doi          = {10.1016/j.asoc.2025.113712},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113712},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph-based deep reinforcement learning for dynamic scheduling of flexible job-shop considering worker fatigue and multi-skill factors},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Command and control network architecture optimization method based on dual-layer weighting and TOPSIS-GRA of indicators. <em>ASOC</em>, <em>184</em>, 113711. (<a href='https://doi.org/10.1016/j.asoc.2025.113711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern warfare, the effectiveness of command and control (C2) networks plays a pivotal role in shaping operational performance and determining combat outcomes. Even under identical resource allocations, variations in command strategies and network architectures can lead to vastly different results. While many existing optimization methods rely on complex network theory to enhance system robustness, they often exhibit randomness and overlook commanders’ intent and expert knowledge during architecture design. Unlike civilian networks, military C2 networks are highly dependent on operational planning and domain expertise, emphasizing decision transparency and interpretability. Subjective evaluation methods-such as those based on rules or expert logic-are more intuitive for commanders but suffer from bias and inconsistency. Conversely, purely data-driven models like deep learning lack transparency, limiting their practical utility in high-stakes scenarios. To bridge this gap, this study proposes a dual-layer weighting optimization approach based on the TOPSIS and Grey Relational Analysis (GRA) methods. First, C2 network architectures are constructed using complex network theory. Then, an evaluation index system is developed around four key metrics: invulnerability, communication efficiency, connectivity, and network density. Subjective weights are derived via the Analytic Hierarchy Process (AHP), while objective weights are calculated using an improved entropy method. These are integrated into a variable-weight model to obtain final weights for optimization. By combining TOPSIS and GRA, the method accounts for both subjective preferences and objective measurements, ensuring a balanced evaluation. Simulation results demonstrate that the proposed method comprehensively considers both subjective and objective factors as well as the impact of state changes on weight adjustments, aligning more closely with real battlefield environments. The constructed C2 network architecture can adapt to different combat missions, guided by subjective evaluations of commander intent and expert experience while being refined through objective assessments to achieve adaptive adjustments. The ranking results account for both the distance and shape variations among indicators. Statistical analysis and comparisons with other methods further validate the effectiveness of the proposed approach, which also reduces computation time by a factor of five compared to alternative algorithms, highlighting its superiority.},
  archive      = {J_ASOC},
  author       = {Jianwei Wang and Qing Zhang and Chengsheng Pan},
  doi          = {10.1016/j.asoc.2025.113711},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113711},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Command and control network architecture optimization method based on dual-layer weighting and TOPSIS-GRA of indicators},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A distributed learning framework with blockchain and privacy-preserving for IoV. <em>ASOC</em>, <em>184</em>, 113710. (<a href='https://doi.org/10.1016/j.asoc.2025.113710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Vehicles (IoV), as a critical component of the Internet of Things (IoT), constructs a distributed system comprising vehicles, roadside units (RSUs), and cloud servers. In the IoV environment, the secure sharing of data and the protection of privacy are of paramount importance, as they directly impact the decision-making processes of intelligent vehicles and overall road safety. Given the openness of IoV, it faces risks of privacy leakage and poisoning attacks during data exchange and model training, which threaten the integrity and reliability of the data. To address these challenges, this study proposes a privacy protection framework that integrates blockchain technology and differential privacy. This framework incorporates dual differential privacy techniques within federated learning to enhance data privacy protection and designs a dynamic gradient aggregation mechanism to defend against data poisoning attacks, thereby ensuring the security of the data. Experimental results demonstrate that this framework maintains high model accuracy even under attack rates of up to 30%, exhibiting remarkable resilience against such attacks. Overall, this study emphasizes the significance of data security and privacy protection in the IoV domain and illustrates the potential of blockchain and differential privacy technologies in enhancing the security of IoV data and safeguarding user privacy. This research provides robust support for the sustainable development of IoV.},
  archive      = {J_ASOC},
  author       = {Chunhai Li and Yan Long and Yong Ding and Changsong Yang and Chuan Zhang and Meng Shen and Liehuang Zhu},
  doi          = {10.1016/j.asoc.2025.113710},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113710},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A distributed learning framework with blockchain and privacy-preserving for IoV},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chaotic vortex nanoparticle swarms (CVNPS): Formation and stability analysis. <em>ASOC</em>, <em>184</em>, 113708. (<a href='https://doi.org/10.1016/j.asoc.2025.113708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vortex Nanoparticle Swarms (VNPS) are a class of self-organizing systems that exhibit vortex-like collective behavior but often suffer from dynamic instability and poor angular momentum conservation. While VNPS may achieve partial spatial stability, coherent motion is typically unsustained. To address this, the Chaotic Vortex Nanoparticle Swarm (CVNPS) model is proposed, incorporating chaotic perturbations via logistic maps within a discrete particle model governed by the Generalized Morse Potential. This integration enhances system stability by accelerating convergence, reducing energy fluctuations, and promoting sustained vortex formation. Comparative analysis using key performance indicators – average nearest neighbor distance, polarization, angular momentum, swarm diameter, total energy, energy dissipation rate, and variance – demonstrates that CVNPS significantly outperforms traditional VNPS. It achieves faster stabilization and maintains coherent structure over time, even under varied initial conditions. By addressing both configurational and dynamical stability, CVNPS establishes a foundation for more reliable nanoparticle swarm applications in nanotechnology.},
  archive      = {J_ASOC},
  author       = {Mahvish Khurshid Bijli and Prabal Verma and Amrit Pal Singh},
  doi          = {10.1016/j.asoc.2025.113708},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113708},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Chaotic vortex nanoparticle swarms (CVNPS): Formation and stability analysis},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect-based context iterative network with hyperbolic tangent function for aspect-based sentiment classification. <em>ASOC</em>, <em>184</em>, 113707. (<a href='https://doi.org/10.1016/j.asoc.2025.113707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of natural language processing, sentiment analysis emerges as a pivotal undertaking. Especially, aspect-based sentiment classification has garnered significant attention in recent years, as it can identify and evaluate emotions related to specific aspects within sentences. Existing approaches typically achieve satisfactory results by extracting keyword information from the context to identify polarity. However, a common challenge faced by these methods is the inclusion of irrelevant words in the extracted keywords, leading to decreased classification accuracy. To tackle this issue, we propose an aspect-based context multiple iteration approach, which leverages the correlation between aspects and context and employs the multi-head attention mechanism to iteratively extract contextual keywords. By doing so, we aim to mitigate the interference of irrelevant words and enhance the accuracy of sentiment classification. Additionally, we address the peculiarities of hard samples by introducing a novel loss function that cleverly incorporates the hyperbolic tangent function and allows for improved model accuracy. To validate the effectiveness of our proposed approach, we conduct extensive experiments on four widely datasets and demonstrate the efficacy of our model in improving sentiment classification.},
  archive      = {J_ASOC},
  author       = {Chao Zhu and Benshun Yi and Laigan Luo},
  doi          = {10.1016/j.asoc.2025.113707},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113707},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Aspect-based context iterative network with hyperbolic tangent function for aspect-based sentiment classification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOGA: Multi-objective genetic algorithm to select stacking ensemble learning for classification. <em>ASOC</em>, <em>184</em>, 113706. (<a href='https://doi.org/10.1016/j.asoc.2025.113706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stacking Ensemble Learning (SEL) has been effectively integrated with Multi-Objective Optimisation (MOO) heuristics for classification tasks across various domains, including finance, healthcare, and cybersecurity. This study aims to address the challenge of generalising SEL to a diverse set of classification cases. Thus, the Multi-Objective Genetic Algorithm (MOGA) framework is proposed, utilising a Genetic Algorithm (GA) to evolve a population of distinct SELs, each built from a varied subset of base models. The goal is to select the subset that composes the most effective SEL for a given classification task. MOGA is designed with two main objectives—maximising p r e c i s i o n and r e c a l l —which helps to maintain independence from any specific classification case. In addition, incorporating models of varied types ensures adaptability and high performance in different situations. Comprehensive experimentation was conducted on 23 diverse datasets, where MOGA demonstrated high performance in nearly all datasets, outperforming other ensemble learning (EL) methods in 100% of the datasets in p r e c i s i o n , 78% in r e c a l l , 69.5% in f 1 − s c o r e , and 78% in a c c u r a c y . A t-test analysis yielded results of p -value < 0 . 05 , indicating a statistically significant improvement in the a c c u r a c y of the MOGA over the base models. Moreover, the framework’s application can be extended to regression tasks as well.},
  archive      = {J_ASOC},
  author       = {Abdellah Rezoug and Mohamed Bader-el-den},
  doi          = {10.1016/j.asoc.2025.113706},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113706},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MOGA: Multi-objective genetic algorithm to select stacking ensemble learning for classification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning with evolutionary algorithm-guided imitation for capacitated vehicle routing problems. <em>ASOC</em>, <em>184</em>, 113705. (<a href='https://doi.org/10.1016/j.asoc.2025.113705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacitated vehicle routing problem (CVRP) is a complex combinatorial optimization challenge that seeks to determine cost-effective routes for customer deliveries while adhering to specific capacity constraints. Although deep reinforcement learning (DRL) has shown promise in addressing CVRP, it often encounters issues such as slow convergence and suboptimal accuracy. This study introduces an innovative approach that enhances both convergence efficiency and solution quality by integrating DRL with imitation learning (IL), utilizing an evolutionary algorithm (EA) as an expert. The proposed methodology incorporates an attention mechanism-based neural network to effectively capture the intricate features of CVRP. It leverages IL to use EA-generated solutions as expert demonstrations, thereby guiding the DRL model toward a more efficient exploration of the solution space. The REINFORCE algorithm with baseline is employed to ensure stable and rapid training of the DRL model. Experimental results indicate that this hybrid approach significantly outperforms widely adopted baseline methods and approaches the performance levels of advanced algorithms like LKH3. Furthermore, the method demonstrates robust generalization capabilities across various CVRP instances, underscoring its potential for practical applications in diverse routing scenarios. This research contributes to the field by demonstrating how integrating EA as experts within an IL framework can effectively enhance DRL for solving CVRP.},
  archive      = {J_ASOC},
  author       = {Wenqiang Zhang and Xiaomeng Wang and Yashuan Mu and Miaolei Deng and Peng Li},
  doi          = {10.1016/j.asoc.2025.113705},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113705},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep reinforcement learning with evolutionary algorithm-guided imitation for capacitated vehicle routing problems},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A focal quotient gradient system method for deep neural network training. <em>ASOC</em>, <em>184</em>, 113704. (<a href='https://doi.org/10.1016/j.asoc.2025.113704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel approach for training deep neural networks, leveraging a mini-batch focal quotient gradient system (QGS-Focal). The proposed method addresses critical challenges in imbalanced datasets and optimization efficiency. By introducing residual constraints into the loss function, we construct a quotient gradient system that effectively mitigates model overfitting and gradient vanishing problems. By incorporating a focal loss mechanism, it innovatively solves data imbalance issues at the algorithmic level. The adoption of a mini-batch strategy and limited memory method significantly reduces computational costs. Our comprehensive experiments on imbalanced CIFAR-10 and CIFAR-100 have demonstrated the superiority of QGS-Focal, achieving 83.4 % precision, 83.6 % recall, and 82.9 % F1-score on CIFAR-10, significantly outperforming SGD, Adam, and QGS. Moreover, our approach reduces training time by 13.3 %, enhancing computational efficiency while maintaining superior classification performance. The t-SNE visualization further confirms that QGS-Focal has superior convergence properties compared to traditional optimization approaches.},
  archive      = {J_ASOC},
  author       = {Caili Lv and Xian-long Lv and Zhiyuan Wang and Tianqi Zhao and Wei Tian and Qingqing Zhou and Lin Zeng and Min Wan and Chenghu Liu},
  doi          = {10.1016/j.asoc.2025.113704},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113704},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A focal quotient gradient system method for deep neural network training},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial differential equations and machine learning integration for transit-oriented development. <em>ASOC</em>, <em>184</em>, 113703. (<a href='https://doi.org/10.1016/j.asoc.2025.113703'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate classification of rail transit stations is critical for advancing Transit-Oriented Development (TOD) and promoting sustainable urban growth. This research presents a novel hybrid framework that integrates Partial Differential Equations (PDEs) with Machine Learning (ML) techniques for the classification of rail transit stations. Unlike conventional TOD models, this study applies the heat equation to the Node, Place, Ridership-Time (NPRT) framework, offering a mathematically grounded approach to capture spatial-temporal dynamics in transit systems. This integration represents the first known application of PDE-based physical modeling combined with supervised learning for classifying transit stations within a TOD framework. This approach significantly enhances the model’s interpretability while maintaining competitive prediction accuracy. Through extensive case studies and empirical validation, the PDE-NPRT model demonstrates strong performance, with Mean Squared Error (MSE) values ranging from 0.0075 to 0.0222. Although slightly outperformed by enhanced ML models—such as K-Nearest Neighbors (KNN), Deep KNN (DKNN), and Deep Distributed Neural Networks (DDNN)—which achieve MSEs as low as 0.0034, the PDE-NPRT model offers a more interpretable and theoretically robust alternative. Additionally, the study introduces a multi-layer modeling strategy that combines regression analysis, clustering algorithms, PDEs, and neural networks, further enriching the understanding of ridership patterns and congestion mechanisms. Clustering outcomes are validated through external indices, confirming the alignment of model predictions with real-world site characteristics. This work represents a significant advancement in TOD modeling, offering a robust and explainable tool for urban planners and decision-makers. By bridging advanced mathematical modeling with machine learning, it paves the way for more intelligent, data-driven, and sustainable urban mobility strategies.},
  archive      = {J_ASOC},
  author       = {Ahad Amini Pishro and Shiquan Zhang and Alain L’Hostis and Qixiao Hu and Yuetong Liu and Zhengrui Zhang and Van Duc Nguyen and Yongguo Fu and Tianzeng Li},
  doi          = {10.1016/j.asoc.2025.113703},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113703},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Partial differential equations and machine learning integration for transit-oriented development},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic SLAM algorithm based on improved YOLOv9S. <em>ASOC</em>, <em>184</em>, 113700. (<a href='https://doi.org/10.1016/j.asoc.2025.113700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the limitations of conventional visual SLAM algorithms and the time-intensive process of semantic segmentation in dynamic environments, this paper proposes a SLAM algorithm that incorporates an enhanced version of YOLOv9S specifically designed for dynamic scenes. The ECASPPELAN and DRepNCSPELAN4 modules have been developed to improve the model’s detection capabilities in dynamic scenes. Secondly, the improved YOLOv9S is integrated into the ORB-SLAM2 framework, which employs bipolar geometry to reject dynamic targets and utilizes a depth separation algorithm to prevent the erroneous rejection of static features. Subsequently, the detection performance of the model was evaluated on the PASCAL VOC dataset, resulting in a 2% improvement in mAP_0.5 and a 1.3% improvement in mAP_0.5:0.95. The tracking performance of the system is examined in the TUM dynamic dataset, where the absolute trajectory root mean square error (RMSE) is reduced by 97.5%, and the relative rotational RMSE is reduced by 92.9% in comparison to ORB-SLAM2 in the high-dynamics scenario. Additionally, the average running rate surpasses 30 Hz while constructing high-quality dense maps in real indoor dynamic environments. This allows the robot to receive more detailed texture information. The experimental results demonstrate that the enhanced algorithm presented in this paper exhibits enhanced accuracy and resilience in dynamic scenarios.},
  archive      = {J_ASOC},
  author       = {Qiguang Zhu and Yuchao Zhao and Haofeng Zhang and Weidong Chen},
  doi          = {10.1016/j.asoc.2025.113700},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113700},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A dynamic SLAM algorithm based on improved YOLOv9S},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural semantic evaluation of blockchain policy tools in china. <em>ASOC</em>, <em>184</em>, 113699. (<a href='https://doi.org/10.1016/j.asoc.2025.113699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To explore the differences in policies guiding the development of the blockchain industry in different regions of mainland China, in this study, we developed a compound neural network model comprising bidirectional long short term memory and deep biaffine attention models that analyses the semantic texts of blockchain policies issued by 31 provinces in mainland China. Machine learning models — specifically, term frequency–inverse document frequency and K-means models are used to implement feature selection of the policy text matrix classification after semantic analysis. Finally, this study proposes an innovative policy tools matching approach. We construct a word-topological map for each text category based on semantic relationships. To validate the effectiveness of these tools, we conduct an empirical analysis using a multivariate linear regression model. The results demonstrate that blockchain policy tools significantly promote blockchain innovation in Mainland China.},
  archive      = {J_ASOC},
  author       = {Yuxi Zhang and Haifeng Guo and Ke Peng and Hongzhi Wang},
  doi          = {10.1016/j.asoc.2025.113699},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113699},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Neural semantic evaluation of blockchain policy tools in china},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable nature-inspired optimization via virtual and actual multi-objective strategies to establish a smart earthquake early warning system. <em>ASOC</em>, <em>184</em>, 113698. (<a href='https://doi.org/10.1016/j.asoc.2025.113698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geosynthetic-reinforced soil (GRS) structures are considered for reducing displacement and providing economical reinforcement solutions. The risk assessment of these structures against earthquakes, based on the prediction of seismic sliding displacement, is a major challenge in this field. Multi-objective optimization is a powerful machine learning tool for selecting efficient features for high-performance forecasting. This research investigates two strategies based on swarm intelligence and genetic programming for a comprehensive evaluation. These frameworks integrate multiobjective optimization algorithms and Newmark methods for utilizing effective physics-informed features. The first strategy is virtual multi-objective (VMO) optimization by applying particle swarm optimization (PSO) based on minimizing one function via variations of other functions. In this approach, the error function, as a computational error object, is minimized versus the nomination of interpretable feature space as a computational cost object through the virtual Pareto front. The second strategy is actual multi-objective (AMO) optimization by exploiting nondominated sorting genetic algorithm II (NSGA-II) based on minimizing several functions simultaneously with two various approaches, including bi-objective and many-objective algorithms through actual Pareto-optimal solutions. In this approach, the computational error value, computational cost value, and computational time value are minimized at the same time. The main novelty of the first technique is low computational complexity, resulting in high speed due to definite search space dimension-based exploration and exploitation to forecast seismic sliding displacement, whereas the major achievement of the second technique is high computational accuracy due to multiobjective structure-assisted exploitation and exploitation. Through numerical validation by employing the Newmark methods, the resultant model predicts the seismic sliding displacement of these structures using two algorithms efficiently. Nevertheless, both strategies have good performance for intelligent forecasting. The actual many-objective optimization algorithm is a more effective switchable machine learning tool based on the proposed adaptable performance index for developing a smart earthquake early warning software that can precisely detect imminent natural hazards.},
  archive      = {J_ASOC},
  author       = {Milad Zarchi and Reza A. Nazari and Kong Fah Tee},
  doi          = {10.1016/j.asoc.2025.113698},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113698},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Explainable nature-inspired optimization via virtual and actual multi-objective strategies to establish a smart earthquake early warning system},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DTKD-DL: Dual-teacher knowledge distillation with dual-loops for continuous few-shot relation extraction. <em>ASOC</em>, <em>184</em>, 113696. (<a href='https://doi.org/10.1016/j.asoc.2025.113696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new model named DTKD-DL, designed to address the issue of Continuous Few-Shot Relation Extraction (CFRE) across tasks, with the goal of learning and adapting to newly emerging relations while reducing catastrophic forgetting. In this paper, we have designed a dual-teacher knowledge distillation model based on relation information to enrich knowledge representation and retain prior knowledge. We employ a dual-loops distillation approach, which facilitates knowledge transfer and optimizes the direction of parameter updates, thereby reducing the occurrence of catastrophic forgetting. Furthermore, to avoid overfitting issues caused by multiple rounds of distillation, we have innovatively integrated reinforcement learning with the model. We have validated our model on the FewRel and TACRED datasets and compared it with the large language model Llama3-8b, demonstrating the effectiveness of our model in this scenario and its advantages over the most advanced methods, achieving state-of-the-art results.},
  archive      = {J_ASOC},
  author       = {Ruifeng Xu and Yi Chen and Zhongyan Yi and Shun Huang and Liang He},
  doi          = {10.1016/j.asoc.2025.113696},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113696},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DTKD-DL: Dual-teacher knowledge distillation with dual-loops for continuous few-shot relation extraction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage feature selection approach with fuzzy covering-based rough sets based on discernibility matrix. <em>ASOC</em>, <em>184</em>, 113695. (<a href='https://doi.org/10.1016/j.asoc.2025.113695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy β -covering has attracted considerable research attention due to its enhanced capability to accurately and comprehensively represent uncertain information. Unlike partition-based approaches, fuzzy β -covering maintains its covering properties when augmented with additional elements. This inherent flexibility necessitates rigorous redundancy analysis. Hence, the calculation of the reduct of fuzzy β -covering relative to decision attribute constitutes a fundamental challenge in this context. To address this issue, we formally define the concepts of indispensable covering elements and core of fuzzy β -covering with respect to the decision attribute. Then, to facilitate efficient computation of core and reduct, we introduce the discernibility matrix for fuzzy β -covering and establish equivalent representations of the core and reduct. Furthermore, we conduct systematic examinations to verify the indispensability of some existing concepts in fuzzy β -covering. Meanwhile, a significant limitation of current feature selection methods useing fuzzy β -covering lies in their computational complexity, primarily due to repeated recalculation of dependency functions during iterations. To overcome this limitation, we propose an efficient feature selection algorithm that identifies all reducts directly through the discernibility matrix. Furthermore, we propose a two-stage feature selection method for fuzzy β -covering, which iteratively eliminates redundant features to identify optimal feature subsets in each iteration. Finally, we verify through time complexity analysis and numerical experiments that the proposed algorithm significantly outperforms existing feature selection algorithms in computational efficiency. Comparative analysis further reveals that our method achieves superior results in terms of selected feature subset sizes and classification accuracy.},
  archive      = {J_ASOC},
  author       = {Tianyu Wang and Shuai Liu and Bin Yang},
  doi          = {10.1016/j.asoc.2025.113695},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113695},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-stage feature selection approach with fuzzy covering-based rough sets based on discernibility matrix},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-source remote sensing image watermarking model based on multi-domain generative adversarial networks. <em>ASOC</em>, <em>184</em>, 113694. (<a href='https://doi.org/10.1016/j.asoc.2025.113694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the heterogeneity stemming from distinct sensor types, quantized spatial resolution levels, and categorized acquisition angles within multi-source remote sensing images, their data distribution and characteristics vary significantly, leading to poor cross-domain consistency and weak resistance to domain-specific distortions in traditional watermarking approaches. Traditional watermarking methods often struggle to handle such heterogeneous datasets. To address this challenge, this paper presents a watermarking model based on a multi-domain generative adversarial network (MD-GAN). By incorporating a multi-domain adversarial training mechanism and designing multiple domain discriminators, the generator is optimized to work across various image domains, thereby enhancing model robustness. Additionally, a multi-scale generator is utilized to account for differences in spatial resolution, improving both the watermark’s concealment and extraction accuracy. Experimental results demonstrate that the MD-GAN model achieves a 7 % improvement in robustness over the state-of-the-art models in terms of resistance to noise attacks and geometric transformations. Ablation studies confirm that the multi-domain adversarial training mechanism and multi-scale generator contribute significantly to this enhancement. MD-GAN provides a powerful solution for the copyright protection of multi-source remote sensing images, with substantial potential for real-world applications such as secure transactions and data sharing.},
  archive      = {J_ASOC},
  author       = {Heyan Wang and Xingxiang Jiang and Minxuan Wang and Changqing Zhu and Na Ren and Luanyun Hu},
  doi          = {10.1016/j.asoc.2025.113694},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113694},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-source remote sensing image watermarking model based on multi-domain generative adversarial networks},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale convolution-attention model for efficient alzheimer’s disease and mild cognitive impairment diagnosis approach using sMRI. <em>ASOC</em>, <em>184</em>, 113693. (<a href='https://doi.org/10.1016/j.asoc.2025.113693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer's disease (AD) affects over 50 million people worldwide and causes a gradual decline in memory, language, and actions, with no known cure. Early identification and treatment are crucial to improve the quality of life of affected individuals. Deep learning algorithms based on brain structural magnetic resonance imaging (sMRI) show promise in predicting AD. However, relying solely on deep convolutional neural network (CNN) architecture has limitations in global modeling. Transformer, which is a feature learning technique, has excelled in computer vision applications, sparking interest in its application in brain image processing. However, pure Transformer architectures encounter challenges when trained on small sMRI datasets. Meanwhile, CNN-based methods do not consider the interdependence between voxels, which hinders the comprehensive understanding of the global characteristics of sMRI data. To address these challenges, an effecient deep learning framework was developed that combines the benefits of both the CNN and Transformer. In the preliminary phase of feature extraction, we introduce a multiscale feature fusion stem that employs convolutional kernels of varying scales to derive low-level features from the sMRI and integrate them to enhance the recognition accuracy. Furthermore, the proposed method introduces convolutional split attention with a squeeze and excitation block and additional convolution operations in the core sections of the Transformer, thereby enabling multiscale feature extraction and fusion. The model integrates multi-head light self-attention and a sandglass local feed-forward network block for classifier modeling, enhancing the extraction of sMRI features with a MobileNet cost. The proposed model, which was tested on the Alzheimer's Disease Neuroimaging Initiative dataset, achieved superior performance in AD diagnosis with fewer parameters and reduced computational costs, demonstrating its potential as a state-of-the-art solution.},
  archive      = {J_ASOC},
  author       = {Uttam Khatri and Jun-Hyung Kim and Goo-Rak Kwon},
  doi          = {10.1016/j.asoc.2025.113693},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113693},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiscale convolution-attention model for efficient alzheimer’s disease and mild cognitive impairment diagnosis approach using sMRI},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). F2CAU-net: A dual fuzzy medical image segmentation cascade method based on fuzzy feature learning. <em>ASOC</em>, <em>184</em>, 113692. (<a href='https://doi.org/10.1016/j.asoc.2025.113692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate medical image segmentation plays a pivotal role in clinical diagnosis and treatment planning. However, existing methods – particularly those based on U-Net architectures – still face considerable difficulties when dealing with ambiguous boundaries, low-contrast regions, and noise artifacts. These challenges arise from the deterministic nature of conventional convolutional and attention mechanisms, which are often inadequate in modeling the inherent uncertainty and variability present in medical images. To tackle these limitations, we propose F 2 CAU-Net, a Dual Fuzzy Medical Image Segmentation Cascade Method that integrates a fuzzy convolution module for better modeling of uncertain and imprecise features, and a fuzzy attention mechanism to suppress redundancy and enhance focus on regions of interest. The proposed method captures both local and global contextual fuzzy information to improve segmentation accuracy and robustness. Extensive experiments on multiple benchmark datasets – including COVID-19 lesions, brain tumors, and skin cancer – demonstrate that F 2 CAU-Net significantly outperforms existing state-of-the-art models, particularly in scenarios with complex boundaries and noise. This approach offers promising potential for clinical applications, providing a more reliable and uncertainty-aware solution for medical image analysis.},
  archive      = {J_ASOC},
  author       = {Tianyi Zhou and Haipeng Wang and Sheng Geng and Hengrong Ju and Jiashuang Huang and Fan Fu and Weiping Ding},
  doi          = {10.1016/j.asoc.2025.113692},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113692},
  shortjournal = {Appl. Soft. Comput.},
  title        = {F2CAU-net: A dual fuzzy medical image segmentation cascade method based on fuzzy feature learning},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics-informed mitigation method for DC microgrids under cyber attacks. <em>ASOC</em>, <em>184</em>, 113691. (<a href='https://doi.org/10.1016/j.asoc.2025.113691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber attacks pose serious threats to DC microgrids, making effective mitigation strategies very critical. However, most existing mitigation schemes ignore the physical characteristics of microgrids, which may lead to inaccurate attack detection and affect the mitigation performance. To address this issue, a physics-informed mitigation method for cyber attacks on DC microgrids is proposed. A cyber–physical framework of the DC microgrid is established, and the impact of cyber attacks on the microgrid is analyzed. The denoising autoencoder is utilized to improve the quality of the input data, and then the consistency characteristic of the DC microgrid is incorporated as a physical-informed constraint into the training of the state estimation model. Subsequently, anomaly detection is performed by comparing the estimated state and the real-time measured state. Once the attacks are detected, the estimated state is used to compensate the control inputs, mitigating the effect of attacks and ensuring the safe and stable operation of the DC microgrid. Simulation results show that compared with existing neural network-based estimators, the proposed physics-informed state estimation model can enhance the accuracy by 7 . 98 % ∼ 12 . 54 % , providing more precise estimated states to mitigate the effects of attacks.},
  archive      = {J_ASOC},
  author       = {Wanwan Ren and Jun Peng and Yun Zhou and Weirong Liu and Fu Jiang},
  doi          = {10.1016/j.asoc.2025.113691},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113691},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A physics-informed mitigation method for DC microgrids under cyber attacks},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Acquisition of representative data sets by filtering out redundant objects and attributes with fuzzy preference-based rough sets and dominance principles. <em>ASOC</em>, <em>184</em>, 113690. (<a href='https://doi.org/10.1016/j.asoc.2025.113690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dominance principle is crucial for evaluating consistency in dominance-based rough sets, yet redundant objects or attributes impair decision consistency. While existing work focuses on modeling and attribute reduction, object-induced inconsistency remains understudied. This study proposes a novel methodology for acquiring compact datasets through representative object extraction and attribute reduction in fuzzy preference-based rough sets, with a specific focus on preserving consistency in dominance principles. Firstly, the extent of dominance relations is quantified by fuzzy preference relations, while the evaluation of consistency between conditional and decision attributes is accomplished through distance measures. Subsequently, representative objects are identified by eliminating those with lower consistency in dominance principles, as assessed by distance measures with a predefined parameter. Further, a streamlined dataset is achieved through attribute reductions in fuzzy preference-based rough sets, incorporating representative objects. In conclusion, our proposed method is validated using numerical datasets, and its effectiveness is evaluated through measures rooted in rough set theory, machine learning, and statistics. This research contributes to a more comprehensive understanding of dominance-based rough sets by addressing the often-overlooked issue of inconsistency resulting from redundant objects.},
  archive      = {J_ASOC},
  author       = {Shuyun Yang and Guang Shi and Yuchao Li},
  doi          = {10.1016/j.asoc.2025.113690},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113690},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Acquisition of representative data sets by filtering out redundant objects and attributes with fuzzy preference-based rough sets and dominance principles},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spiking neural network with time-varying weights for rail squat detection. <em>ASOC</em>, <em>184</em>, 113689. (<a href='https://doi.org/10.1016/j.asoc.2025.113689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Axle box acceleration (ABA) measurements can be used for continuously monitoring rail infrastructure and detecting rail surface defects such as squats. However, accurately detecting squats is challenging due to their short-duration responses and low occurrence in ABA signals, particularly for light squats that exhibit subtle ABA responses. To address this challenge, we propose using a spiking neural network (SNN) with time-varying weights to enhance the detection performance of rail squats based on ABA measurements. Our approach employs a simple SNN architecture without hidden layers, trained using a method that combines genetic algorithms, k-fold cross-validation, and multi-start gradient-based approach to optimise hyperparameters and weights. The proposed methodology demonstrates competitive accuracy compared to other state-of-the-art SNN-based methods on UCI benchmarks for both binary and multi-class nonlinear problems. Part of its advantages include higher efficiency with a simpler architecture and training approach that reduces computational times while achieving effective spatiotemporal pattern detection. As shown by real-field measurements from Dutch and Swedish railways in anomaly detection, it effectively captures subtle changes in light squat defect responses in ABA signals and achieves a detection performance of 100% for severe squat defects and over 93% for light squat defects. Furthermore, we show that the spike responses, postsynaptic potentials, and membrane potentials can be used as a new way to explain and analyse the ABA signals. The proposed method using time-varying weights highlights a correspondence with the physical problem and offers an ability to capture sudden and subtle changes in the responses, which is crucial, particularly for detecting defects in their early stages.},
  archive      = {J_ASOC},
  author       = {Wassamon Phusakulkajorn and Jurjen Hendriks and Zili Li and Alfredo Núñez},
  doi          = {10.1016/j.asoc.2025.113689},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113689},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Spiking neural network with time-varying weights for rail squat detection},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectral–spatial representation progressive learning via segmented attention for 3D skeleton-based motion prediction. <em>ASOC</em>, <em>184</em>, 113688. (<a href='https://doi.org/10.1016/j.asoc.2025.113688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, GCNs-based methods have demonstrated impressive performance in human behavior prediction tasks. We believe that human motion modeling can explained as motion correlation extraction from the combination of the active and static motion parts analysis. However, existing methodologies fail to address the issue that feature information associated with static regions may overshadow feature information from dynamic regions, ultimately affecting the extraction of network features. Moreover, the unique low-pass feature pre-retention processing mechanism of GCN on the spectrum will lead to the attitude of some sequences remaining unchanged during the prediction process and further hurt the prediction. In this paper, we propose a Spectral–Spatial Representation Progressive Learning network to solve the problem above. Firstly, we propose a segmented attention block to compare the input observation sequence with the static contrast standard to obtain the motion region and the rest region. Then, we design the Spectrum Deconstruction Recombination Factor block(SDRF) to extract the global bandpass spectrum of human bone joints. The joint features of different regions are encoded by graph convolution and high-frequency feature filter coding based on geometric algebra. Specifically, a spectral–spatial interaction block is presented in each SDRF, focusing on the diversity of motion sequence frequency domain and spatial domain map, and realizes the fine extraction of historical pose sequence features from the two levels of space and spectral domain. Experimental results demonstrate that our approach outperforms state-of-art algorithms by 2.4%, 5.3% and 4.7% in terms of 3D mean per joint position error on Human 3.6M, CMU Mocap and 3DPW datasets, respectively.},
  archive      = {J_ASOC},
  author       = {Wenming Cao and Jianhua Zhang and Jianqi Zhong},
  doi          = {10.1016/j.asoc.2025.113688},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113688},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Spectral–spatial representation progressive learning via segmented attention for 3D skeleton-based motion prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal multi-trip supply chain model aided by smart contract victim tracking — An innovative pathway to disaster management under uncertainty. <em>ASOC</em>, <em>184</em>, 113687. (<a href='https://doi.org/10.1016/j.asoc.2025.113687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the complex challenges of post-earthquake rescue operations, using the recent earthquake in Turkey as a reference case. It focuses on developing an optimized model for scenarios with acute vehicle shortages, aiming to minimize both operational costs and response time during the critical initial phase of disaster relief. The proposed solution is built upon a robust mathematical framework that employs aerial vehicles for post-disaster area assessment, resource allocation, and the relocation of critically injured victims. The model leverages a soft computing approach, integrating the Weighted Sum Method (WSM) and Neutrosophic Compromise Programming (NCP). To enhance decision-making under uncertainty, the framework incorporates hexagonal type-2 fuzzy defuzzification, a technique grounded in soft computing principles. Results demonstrate the effectiveness of this approach: the NCP method achieved a response time of 213 min (3.55 h) and a cost of Rs 821,026.5, compared to 217.5 min (3.62 h) and Rs 820,860.3 for the WSM method—both successfully coordinating the rescue of 1,450 victims through efficient deployment of drones and helicopters. In addition, the study introduces a decentralized Ethereum-based smart contract to securely store and retrieve critical victim information. Validated through rigorous unit testing, the contract ensures data transparency and integrity, executing at a cost of 0.00379246 Ether. This blockchain-enabled feature complements the core optimization model, supporting real-time, tamper-proof data handling. To further validate the model’s applicability, a second real-life numerical example based on the recent Sikkim cloudburst is analyzed. The findings reinforce the model’s adaptability and practical value. The managerial implications of this research highlight the importance of soft computing-driven decision support, proactive contingency planning, and the integration of intelligent technologies in disaster response. This holistic framework — combining soft computing methodologies, advanced optimization models, and blockchain technology — offers an innovative and scalable solution for enhancing the resilience and efficiency of disaster management supply chains.},
  archive      = {J_ASOC},
  author       = {Alisha Roushan and Amrit Das and Anirban Dutta and Uttam Kumar Bera},
  doi          = {10.1016/j.asoc.2025.113687},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113687},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-modal multi-trip supply chain model aided by smart contract victim tracking — An innovative pathway to disaster management under uncertainty},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning with hard negatives for sentence embeddings. <em>ASOC</em>, <em>184</em>, 113685. (<a href='https://doi.org/10.1016/j.asoc.2025.113685'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised sentence representation learning remains a core challenge in natural language processing. Recent contrastive learning methods have shown strong potential in capturing sentence-level semantics, but their effectiveness is often constrained by the quality of positive and negative samples. In particular, constructing informative hard negatives in textual data is significantly more difficult than in vision tasks due to the ambiguity and compositionality of natural language. We propose HNCSE, a novel unsupervised contrastive learning framework that enhances sentence representations through hard negative compositional strategies. HNCSE introduces two key components: HNCSE-HNM, which synthesizes informative hard negatives via mixup within the batch, and HNCSE-PM, which generates harder positives by leveraging the most challenging negatives. This joint design improves both alignment and discrimination in embedding space without relying on external supervision. Extensive experiments on semantic textual similarity and transfer tasks demonstrate that HNCSE consistently outperforms existing unsupervised and supervised baselines.},
  archive      = {J_ASOC},
  author       = {Wenxiao Liu and Zihong Yang and Chaozhuo Li and Zijin Hong and Jianfeng Ma and Zhiquan Liu and Litian Zhang and Feiran Huang},
  doi          = {10.1016/j.asoc.2025.113685},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113685},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Contrastive learning with hard negatives for sentence embeddings},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HumanMoD: A multi-RAG collaborative LLM for inclusive urban public healthcare services. <em>ASOC</em>, <em>184</em>, 113684. (<a href='https://doi.org/10.1016/j.asoc.2025.113684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Large Language Models (LLMs) with healthcare systems offers transformative solutions for sustainable public health programs, especially in underserved urban and rural communities where access to professional medical expertise is limited. This paper introduces HumanMoD, a novel LLM framework designed to emulate collaborative clinical workflows of multi-expert medical doctors. Specifically, the proposed Mixture of Doctors module enables parallel diagnostic streams from diverse medical specialties, mimicking the collaborative decision-making of human doctors to ensure comprehensive assessments in resource-constrained environments. The Knowledge-driven Medical Assistant leverages domain-specific knowledge bases to mitigate LLM hallucinations, ensuring that recommendations are rooted in credible medical knowledge. Exquisitely, the Humanoid Health Conductor and LLM-powered Corrector further refine outputs to minimize diagnostic discrepancies, enhancing the reliability of responses for large-scale public health applications such as community health kiosks and mobile health apps serving remote or low-income areas. Unlike fine-tuned models, HumanMoD operates without parameter adjustment, enabling cost-effective deployment in regions with scarce computational resources, thus bridging the healthcare gap for socially vulnerable groups. Experimental results on MedQA and PubMedQA demonstrate that HumanMoD outperforms state-of-the-art models, highlighting its potential to drive equitable healthcare access and support data-driven public health policies in diverse urban and rural settings.},
  archive      = {J_ASOC},
  author       = {Song Sun and Zhijie Zhong and Nanlan Yu and Xinrong Gong and Kaixiang Yang},
  doi          = {10.1016/j.asoc.2025.113684},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113684},
  shortjournal = {Appl. Soft. Comput.},
  title        = {HumanMoD: A multi-RAG collaborative LLM for inclusive urban public healthcare services},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A KPI-related fault diagnosis method for multimode manufacturing processes based on supervised minimal gated unit and sparse broad learning system. <em>ASOC</em>, <em>184</em>, 113679. (<a href='https://doi.org/10.1016/j.asoc.2025.113679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multimode manufacturing processes, the key performance indicator (KPI)-related fault diagnosis plays a critical role in ensuring product quality and enhancing economic benefits. However, variability in working modes, lack dynamic description for the KPIs, and model structure redundancy may lead to poor universality and low diagnostic accuracy of conventional deep learning-based approaches. In this work, a supervised minimal gated unit and sparse broad learning system (SMGU-SBLS) is developed for KPI-related fault diagnosis. Specifically, the KPIs and process variables are simultaneously utilized in the SMGU to learn the KPI-related dynamic features. Then, aiming at simplifying the network structure, a sparse version of broad learning system is proposed for fault diagnosis. Furthermore, the expansion capability of SMGU-SBLS has been analyzed. Finally, the proposed SMGU-SBLS network is applied to a real hot strip mill process (HSMP). Simulation results show that the proposed method has higher diagnostic performance than the other four state-of-the-art deep learning methods.},
  archive      = {J_ASOC},
  author       = {Chuanfang Zhang and Wenxiao Yin and Chi Zhang and Kaixiang Peng and Xueyi Zhang},
  doi          = {10.1016/j.asoc.2025.113679},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113679},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A KPI-related fault diagnosis method for multimode manufacturing processes based on supervised minimal gated unit and sparse broad learning system},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Green maritime transport performance analysis of G-7 countries using an interval-valued fermatean fuzzy ARLON-based decision model. <em>ASOC</em>, <em>184</em>, 113677. (<a href='https://doi.org/10.1016/j.asoc.2025.113677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maritime transport operations are witnessing heightened environmental sensitivities, prompting the implementation of environmentally focused maritime transport practices. The principal aim is to develop a decision support system for evaluating countries' green maritime transport performance. To this end, the interval-valued Fermatean fuzzy (IVFF)-simple weight calculation (SIWEC)-skewness impact through distributional evaluation (SITDE)-alternative ranking using two-step logarithmic normalization (ARLON) model is developed within this study. This method enables the analysis of countries' green maritime transport performance by integrating expert opinions with environmental and maritime transport parameters. The model determines the influence of experts using IVFF sets. It further facilitates the simultaneous use of subjective and objective criteria weighting approaches to compute the weights of green maritime transport performance criteria. ARLON is employed to assess and rank countries' green maritime transport performance levels. The applicability of the IVFF-SIWEC-SITDE-ARLON model is tested through a case study focusing on G-7 countries, and the results supported the successful implementation of the method. Furthermore, sensitivity and comparative analyses demonstrated the consistency and robustness of the model. According to the findings of the case study, the United States emerges as the country with the highest green maritime transport performance among the G-7 countries. The "linear shipping connectivity index" is identified as the most influential criterion in the decision-making process. The study offers actionable recommendations for the maritime industry, thereby contributing to the advancement of green maritime transport practices.},
  archive      = {J_ASOC},
  author       = {Galip Cihan Yalçın and Karahan Kara and Emre Kadir Özekenci and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2025.113677},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113677},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Green maritime transport performance analysis of G-7 countries using an interval-valued fermatean fuzzy ARLON-based decision model},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive self-correction network for human motion prediction. <em>ASOC</em>, <em>184</em>, 113676. (<a href='https://doi.org/10.1016/j.asoc.2025.113676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction aims to generate future poses from the observed historical human motion sequence. It is fundamental to many intelligent systems, e.g., human–robot interaction and self-driving. Though the existing encoder–decoder methods obtain good performance in some scenarios, there is still a gap between their prediction results and ground truth in many cases. In this work, we propose to estimate the deviation between the decoding results (which will be referred to as the conventional human motion prediction ) and the groundtruth, and integrate this estimation with the conventional prediction results to derive the corrected human motion prediction . In this way, our method can self-correct the conventional prediction results based on a preliminary estimated deviation from it to the groundtruth, and thus enhance the performance. In our work, we adopt five independent lightweight branches rather than a global estimator to estimate the deviation of the five human body components ( i.e., left arm, right arm, torso, left leg, and right leg). Based on this component-wise deviation estimation strategy, we propose a Fixed Self-Correction Network (FSCNet) for human motion prediction to obtain enhanced performance. Recognizing that not all joints exhibit the same motion dynamics inside one given body component, we further propose the Adaptive Self-Correction Network (ASCNet) to let these five estimators adaptively capture the correlated deviations and thus enhance human motion prediction performance. Extensive experiments on three large datasets (Human3.6M, CMU-Mocap, and 3DPW) validate the superiority of our proposed FSCNet and ASCNet over the established works.},
  archive      = {J_ASOC},
  author       = {Jinkai Li and Jinghua Wang and Xin Wang and Liang Yan and Xiaoling Luo and Yong Xu},
  doi          = {10.1016/j.asoc.2025.113676},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113676},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive self-correction network for human motion prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RGB-D indoor scene parsing via wavelet sub-band guided transformer. <em>ASOC</em>, <em>184</em>, 113675. (<a href='https://doi.org/10.1016/j.asoc.2025.113675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth information has been shown to be complementary to RGB scene parsing. However, inherent disparities between RGB and depth modalities create challenges for effective feature fusion. Furthermore, current methods often lose high-frequency information during downsampling, limiting the full utilization of RGB and depth image information. To address these issues, we propose the Wavelet Sub-band Guided Transformer (WSGFormer), which utilizes wavelet sub-band to enhance feature correction, fusion, and refinement. The WSGFormer contains three important modules. Firstly, the Wavelet Cross-attention Rectification Module employs Haar wavelet transforms to decompose features into wavelet sub-band, and adaptively aligns RGB and depth features by extracting their mapping relationships. Secondly, the Multi-scale Fusion Module combines RGB and depth branches, utilizing vertical bar-shaped convolutions to enable cross-modal feature selection and enhance the sensitivity to high-frequency components through frequency-aware techniques. Finally, the Discrepancy Compensation Module starts with high-level semantic information and progressively guides the fusion of adjacent layers downwards, reducing disparities between them through subtraction operations. The evaluation conducted on the NYUv2, SUN-RGBD and ScanNetV2 datasets highlights the superior performance of the proposed WSGFormer.},
  archive      = {J_ASOC},
  author       = {Wen Xie and Heng Liu and JiaHao Li},
  doi          = {10.1016/j.asoc.2025.113675},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113675},
  shortjournal = {Appl. Soft. Comput.},
  title        = {RGB-D indoor scene parsing via wavelet sub-band guided transformer},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language model driven multiple operating conditions identification and predictive control. <em>ASOC</em>, <em>184</em>, 113674. (<a href='https://doi.org/10.1016/j.asoc.2025.113674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic changes in operating conditions are common in industrial process control. Efficient and accurate detection of condition transitions and identification of operating states are critical for achieving precise control across multiple operating conditions. Traditional condition identification methods primarily rely on the numerical similarity of input–output sequences, often neglecting the dynamic semantic information embedded within the data, such as variation rates and overshoot magnitudes, which can lead to frequent misclassifications. Recently, large language models (LLMs) have exhibited remarkable capabilities in semantic understanding of complex sequences, offering a new perspective for the identification of operating conditions. However, their application in industrial control still faces two major challenges. First, the enormous parameter scale of LLMs results in high computational costs, making it difficult to achieve real time comparisons between online sequences and large historical datasets, thereby compromising the timeliness of condition identification. Second, LLMs are designed primarily for textual input, leading to a significant modality gap when processing numerical input–output sequence data, which limits their full semantic understanding potential in industrial scenarios. To address these challenges, this paper proposes a novel large language model driven multiple operating conditions identification and predictive control method. The proposed method fully leverages the semantic understanding capabilities of LLMs by mining the underlying dynamic characteristics of input–output sequences, enabling rapid identification of operating conditions under limited sample scenarios and achieving precise control across multiple conditions. Specifically, first, to accurately detect condition changes in multiple operating condition industrial processes, an Approximate Entropy based operating condition change detection method is proposed. Considering that condition transitions often cause a prediction model mismatch, leading to increased complexity and irregularity in control sequences, approximate entropy is employed to quantify the sequence complexity. A data driven adaptive thresholding mechanism based on kernel density estimation is further developed to achieve robust detection of condition changes. Second, to address the issues of limited samples and low identification accuracy arising from solely relying on numerical features, a novel LLM driven multimodal condition identification method is proposed. This method constructs a sparse representation based prediction model for historical operating conditions, forming a high information density knowledge base consisting of prediction models and representative sequences. To bridge the modality gap between numerical and textual data, a numerical to textual sequence description method enriched with dynamic semantics is innovatively introduced, enabling effective alignment between the two modalities. Furthermore, a dynamic semantics enhanced prompt engineering strategy is developed to fully exploit the LLM’s semantic understanding capabilities, facilitating accurate condition identification even under limited sample conditions. Finally, to achieve rapid response and precise control following condition changes, the proposed method quickly matches a suitable prediction model based on the LLM driven condition identification results and dynamically adjusts control parameters using a rolling horizon optimization strategy, thereby significantly improving control accuracy across multiple operating conditions. Notably, the proposed approach eliminates the need for reconstructing condition models after changes, ensuring smooth and continuous control under dynamic conditions. Extensive experiments verified the superiority of the proposed method in terms of both condition identification and multiple operating conditions control performance.},
  archive      = {J_ASOC},
  author       = {Zhongyu Zhang and Minzhi Mao and Keke Huang and Dehao Wu and Chunhua Yang},
  doi          = {10.1016/j.asoc.2025.113674},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113674},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Large language model driven multiple operating conditions identification and predictive control},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MetaIndux-PLC: A control logic-guided LLM for PLC code generation in industrial control systems. <em>ASOC</em>, <em>184</em>, 113673. (<a href='https://doi.org/10.1016/j.asoc.2025.113673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programmable Logic Controllers (PLCs) are widely used for automation control, and they are well-suited for industrial systems control tasks. LLMs can assist engineers in streamlining the programming process and reducing development costs, and one of the key issues is the construction of the PLC code dataset. However, the lack of an open-source PLC code dataset in the research community, combined with the high complexity of industrial systems control logic, has caused most LLMs to struggle with generating accurate control code. This complexity arises from the need to manage real-time sensor data fusion, integrate various communication protocols, and ensure compliance with stringent safety and regulatory standards. In this study, we construct ST4Indux, a PLC code dataset specifically for industrial systems control. And we propose the Control Logic-Guided Iterative Fine-Tuning (CLIFT) method, which iteratively optimizes the model’s generation capability. Based on these, we train a large language model named MetaIndux-PLC, to enable the generation of complex motion control code. Additionally, we propose a multi-dimensional evaluation and optimization method to systematically assess the model’s performance in terms of task completion quality, efficiency, and user experience. The experimental results demonstrate that the proposed approach significantly enhances MetaIndux-PLC’s performance and reliability in real-world engineering environments, providing a foundation for the future development of intelligent programming assistance systems.},
  archive      = {J_ASOC},
  author       = {Lei Ren and Haotian Wang and Jiabao Dong and Haiteng Wang and Shuai Liu and Yuanjun Laili and Lin Zhang},
  doi          = {10.1016/j.asoc.2025.113673},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113673},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MetaIndux-PLC: A control logic-guided LLM for PLC code generation in industrial control systems},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage identification of false data injection attacks in power systems via semi-supervised deep learning. <em>ASOC</em>, <em>184</em>, 113672. (<a href='https://doi.org/10.1016/j.asoc.2025.113672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies find that malicious data manipulations against the state estimation, such as the false data injection attack (FDIA), can evade the detection of a conventional bad data detector equipped with a measurement meter. This calls for advanced FDIA identification approaches urgently. However, existing data-driven efforts are designed under the assumption that attacks are frequent and the amount of compromised data is comparable to benign data, which may not be realistic. Thus, these approaches deliver unsatisfactory performance under highly imbalanced data in the real world. To overcome this issue, we propose a novel two-stage FDIA identification pipeline, which formulates the problem as global detection and fine-grained localization. Following this framework, we leverage deep support vector data description to distinguish attacks from benign measurements in an unsupervised manner and employ a modified one-dimensional ResNet to locate the attacking aims upon detecting an FDIA. Our approach can overcome existing limitations induced by data-driven methods under infrequent FDIAs, leading to effective and robust FDIA identification. Case studies on IEEE standard 14-bus and 118-bus systems demonstrate the effectiveness and superiority of our approach and validate our findings.},
  archive      = {J_ASOC},
  author       = {Fengrui Liu and Keng-Weng Lao and Yida Xu and Yang Li and Haotian Guo and Xiaorui Hu and Yikun Yin},
  doi          = {10.1016/j.asoc.2025.113672},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113672},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Two-stage identification of false data injection attacks in power systems via semi-supervised deep learning},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic target continuous assignment method for unmanned clusters in fragmented information environments. <em>ASOC</em>, <em>184</em>, 113671. (<a href='https://doi.org/10.1016/j.asoc.2025.113671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target assignment stands as a pivotal resource management technique in collaborative clustering. During far-sea search and rescue (SAR) missions, challenges arise in formation control under fragmented information, stemming from unstable communication and incomplete data. Additionally, the dynamic nature of targets poses continuous assignment challenges. Addressing these issues in cluster collaboration represents a significant challenge. This paper proposes a method for dynamic target successive allocation tailored to fragmented information environments. First, inspired by biological cluster behaviors and integrating graph theory and complex network theory, the approach achieves decentered cluster formation by managing subgroup separation and aggregation. This solution effectively addresses the formation control challenge in fragmented information settings during cluster collaboration. Second, leveraging reinforcement learning principles, the method determines device behavioral strategies based on maximizing the device’s interaction rewards with the environment. This approach resolves the dynamic continuous target assignment challenge within clustered environments. This paper proposes a Broken Info-Driven Target Assignment (BI-DTA) method to address these research challenges. Experimental results demonstrate that the method achieves effective decentered formation control and dynamic continuous target assignment rapidly, exhibiting robustness and stability in fragmented information environments.},
  archive      = {J_ASOC},
  author       = {Rui Ding and Yuhan Zhu and Baojie Chai},
  doi          = {10.1016/j.asoc.2025.113671},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113671},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic target continuous assignment method for unmanned clusters in fragmented information environments},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A surrogate-assisted evolutionary algorithm based on the two-round selection strategy incorporating local search for expensive high-dimensional multi/many-objective optimization. <em>ASOC</em>, <em>184</em>, 113670. (<a href='https://doi.org/10.1016/j.asoc.2025.113670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted multi-objective optimization has exhibited excellent performance for solving optimization problems that involve time-intensive computer simulations or resource-intensive physical experiments. However, the majority of existing research has focused on low-dimensional problems. In this paper, a surrogate-assisted evolutionary algorithm based on the two-round selection strategy incorporating local search (TRLS) is proposed for expensive high-dimensional multi/many-objective optimization. Specifically, the convergence and diversity of the trial solutions are assessed based on the estimation of Pareto fronts, and the uncertainty is quantified by analyzing the distribution of relevant points in the decision space. The infill sampling task is guided by the above three performance indicators. Firstly, a preliminary screening is conducted by considering convergence and diversity performance. Subsequently, the quality of candidates is further refined through the implementation of a local search strategy. Finally, a comprehensive fitness is constructed to select the sampling individual. In addition, a dynamic termination criterion is devised for the surrogate-assisted evolution phase. Empirical studies, conducted on two classical benchmark suites and two real-world tasks, reveal the effectiveness and applicability of the proposed TRLS.},
  archive      = {J_ASOC},
  author       = {Yang Li and Weigang Li and Songtao Li and Qifeng Wang and Junwei Hu},
  doi          = {10.1016/j.asoc.2025.113670},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113670},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A surrogate-assisted evolutionary algorithm based on the two-round selection strategy incorporating local search for expensive high-dimensional multi/many-objective optimization},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study of the hesitant fuzzy aggregation operators for the transportation of perishable goods under real life scenarios. <em>ASOC</em>, <em>184</em>, 113668. (<a href='https://doi.org/10.1016/j.asoc.2025.113668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transportation of the perishable goods has always been a critical challenge in the market. The inherent susceptibility of the perishable items to spoilage and deterioration during transit necessitates the development and implementation of the preservation technologies that enhance the shelf life and maintain the quality of perishable products during transportation. Also, the carbon emissions stemming from activities associated with transportation present a significant and progressively urgent challenge, markedly contributing to environmental degradation. Consequently, the escalating carbon emissions linked to the transportation-related activities pose a threat to the sustainability of the environment. Recalling these facts, this paper explores the study of an interval valued multi-objective fixed charge solid transportation problem under hesitant fuzzy aggregation operators. Furthermore, this paper introduces a practical mathematical framework designed to represent the decision-making process inherited in the transportation scenarios. The proposed method leverages the hesitant fuzzy aggregation operators to offer a specific approach for the decision-making across such operators. Additionally, it introduces the notion of hesitant degrees for different objectives through the utilization of membership functions. Three conflicting objective functions: time minimization for customer satisfaction, profit maximization for the economic sustainability and minimization of the carbon emissions for the environmental sustainability have been addressed in the suggested model. The transportation time and the fuel consumption have been managed by introducing a variable called the vehicle speed coefficient. An analysis of the deterioration rates of the perishable products has been conducted considering the presence of a preservation value. Moreover, the proposed model has been formulated by employing the diverse approaches and have been solved using multi-objective techniques. A real-life-based numerical problem is presented and solved to validate the proposed concept. The results are compared with respect to different vehicle speeds and preservation values.},
  archive      = {J_ASOC},
  author       = {Awdhesh Kumar Bind and Deepika Rani and Ali Ebrahimnejad},
  doi          = {10.1016/j.asoc.2025.113668},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113668},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A study of the hesitant fuzzy aggregation operators for the transportation of perishable goods under real life scenarios},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAGE-net: Single-layer augmented gated encoder network for efficient multimodal sentiment analysis. <em>ASOC</em>, <em>184</em>, 113665. (<a href='https://doi.org/10.1016/j.asoc.2025.113665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis has achieved remarkable progress. However, the increasing computational complexity of existing models poses significant challenges in resource-constrained scenarios. To address these challenges, this study introduces a single-layer augmented gated encoder network (SAGE-Net), a novel lightweight multimodal sentiment analysis architecture. In contrast to conventional multilayer, deeply stacked architectures, SAGE-Net employs only a single-layer encoder to preserve multimodal feature comprehension, significantly reducing computational complexity. To enable effective inter-modal interaction, a single-layer cross-attention mechanism is integrated. We extensively evaluate multiple feature fusion strategies and data augmentation strategies to enhance model effectiveness. Experimental results on the CMU-MOSI and CMU-MOSEI, and CH-SIMS datasets demonstrate that SAGE-Net achieves competitive performance and significantly lowers model size and tuning costs. These results validate SAGE-Net as a viable lightweight solution for multimodal sentiment analysis in resource-constrained scenarios.},
  archive      = {J_ASOC},
  author       = {Jiazheng Zhou and Xin Kang and Weiping Ding and Linhuang Wang and Fei Ding and Kazuyuki Matsumoto and Chenmeng Zhang and Huiwen Chi},
  doi          = {10.1016/j.asoc.2025.113665},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113665},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SAGE-net: Single-layer augmented gated encoder network for efficient multimodal sentiment analysis},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust weakly supervised product surface defect segmentation based on guided cropping and inpainting extension. <em>ASOC</em>, <em>184</em>, 113661. (<a href='https://doi.org/10.1016/j.asoc.2025.113661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of industrial manufacturing, automatic detection and segmentation of surface defects in products is vital to enhance both product quality and efficiency. However, a large number of existing deep learning methods require a substantial amount of manually labeled data for training, and the high-cost labeling process hampers the practical application of such methods. Towards this end, we present a weakly supervised defect segmentation algorithm without any segment labels. First, a training enhancement method based on a contrastive learning module (CLM) coupled with a guided cropping module (GCM) is proposed to improve the network’s attention to defects in the Defect Focus Classifier (DFC) training phase. Subsequently, a novel inpainting extension module (IEM) generates a final class activation map (CAM) to obtain a pseudo label automatically for segment network training. Finally, conditional random field (CRF) and an additional training round refine the segmentation results. Moreover, the whole process is distilled into a fully supervised segmentation network to improve the inference efficiency. Conducting extensive experimentation, we have achieved 100% and 93.39% average precision (AP) and 41.73% and 53.14% average intersection-over-union (IOU) on the public datasets KolektorSDD and KolektorSDD2, respectively. Furthermore, we verified the generalizability of our method by conducting experiments on several industrial product classes in the MVTec AD, MTD, and DAGM datasets. In these experiments, we achieved favorable classification and segmentation results using solely image classification labels.},
  archive      = {J_ASOC},
  author       = {Rui Yan and Xiaojun Wu and Qixun Yang and Michael Yu Wang},
  doi          = {10.1016/j.asoc.2025.113661},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113661},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Robust weakly supervised product surface defect segmentation based on guided cropping and inpainting extension},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised lip-tongue segmentation with boundary region contrast sampling. <em>ASOC</em>, <em>184</em>, 113653. (<a href='https://doi.org/10.1016/j.asoc.2025.113653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Traditional Chinese Medicine, the accurate segmentation mask of the tongue and lip is the key of inspection. Although deep learning has made remarkable progress in medical image segmentation, a lot of manual annotations are still required for training. Semi-supervised learning (SSL) is used to reduce annotation work, but its performance often suffers when applied to tongue and lip segmentation, which is because tongue and lip images have noisy background information and unique boundary regions. To alleviate the problem, we propose a semi-supervised framework named Lip-Tongue segmentation with Boundary Region Contrast Sampling (Lip-Tongue-BReCoSample). We first preprocess the data, roughly locating the target and filtering out noisy background information. Then we generate the key boundary regions and sample to carry out contrast learning, which alleviates the problem that SSL cannot make fine modeling of the boundary regions of the target with limited information. After a lot of experiments, our method has achieved good results in SSL, and makes it reach or even exceed the performance of many traditional supervised methods, which can improve MIOU performance from 88.09 to 90.43 (+2.34) in SSL specifically. Our method is also better than the latest large-dataset pre-trained model (e.g., SegGPT). To the best of our knowledge, it is the first application of SSL in tongue and lip semantic segmentation.},
  archive      = {J_ASOC},
  author       = {Tao Jiang and Lechao Zhang and Wang Yuan and Liping Tu and Ji Cui and Xiaojuan Hu and Xin Tan and Lizhuang Ma and Jiatuo Xu},
  doi          = {10.1016/j.asoc.2025.113653},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113653},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Semi-supervised lip-tongue segmentation with boundary region contrast sampling},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-term multistep wind direction prediction of unmanned sailboats based on OVMD and optimized deep learning model. <em>ASOC</em>, <em>184</em>, 113651. (<a href='https://doi.org/10.1016/j.asoc.2025.113651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate short-term multistep wind direction prediction is crucial for enhancing the sailing performance and operational safety of unmanned sailboats. Existing methods often face challenges due to the complexity, non-stationarity, and diverse frequency characteristics of wind direction data. In this study, a novel approach is proposed that combines optimal variational mode decomposition (OVMD) with optimized deep learning model for wind direction prediction. First, OVMD is applied to decompose the wind data into stable modal signals, effectively reducing the impact of data complexity and non-stationarity on prediction performance. Considering that different subsequences exhibit distinct frequency patterns, five deep learning models, including Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks, are employed to predict each subsequence separately. The most suitable model for each subsequence is selected based on the root mean square error (RMSE) metric. Additionally, hyperparameter optimization is conducted to enhance prediction accuracy, reduce training time, and eliminate the need for subjective parameter settings. Experimental results demonstrate that the proposed method can accurately capture wind direction variations and achieves superior performance compared to baseline models across all evaluation metrics, ensuring high accuracy and stability in short-term multistep wind direction prediction.},
  archive      = {J_ASOC},
  author       = {Zhipeng Shen and Shaoqing Zhang and Yang Yang and Zhaoyang Wu and Haomiao Yu},
  doi          = {10.1016/j.asoc.2025.113651},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113651},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Short-term multistep wind direction prediction of unmanned sailboats based on OVMD and optimized deep learning model},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-inspired text-based recommender system with explanatory capabilities. <em>ASOC</em>, <em>184</em>, 113650. (<a href='https://doi.org/10.1016/j.asoc.2025.113650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are widely used to help users find relevant and personalized items in various domains. However, providing accurate recommendations is not enough to ensure user satisfaction, trust, and engagement. Nowadays, users demand transparency from these systems typically in the form of an explanation of the recommendation given. This paper presents a novel explainable Recommender System designed to generate recommendations from natural language queries while providing model-intrinsic explanations inspired by attention mechanisms. The system adds transparency, interpretability, and new user cold-start capabilities. We evaluate our approach on twelve datasets from diverse domains and languages, demonstrating its effectiveness and robustness. Results show that our proposal achieves competitive accuracy with respect to strong baselines, while consistently outperforming a prior interpretable model developed for the same task.},
  archive      = {J_ASOC},
  author       = {Pablo Pérez-Núñez and Paul Buitelaar and Jorge Díez and Oscar Luaces and Antonio Bahamonde},
  doi          = {10.1016/j.asoc.2025.113650},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113650},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Attention-inspired text-based recommender system with explanatory capabilities},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MHGCL: A multi-modal hypergraph contrastive learning framework for molecular property prediction. <em>ASOC</em>, <em>184</em>, 113645. (<a href='https://doi.org/10.1016/j.asoc.2025.113645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate molecular property prediction (MPP) is pivotal in drug discovery. Although current models integrate multi-modal (1D, 2D, and 3D) molecular features, they often suboptimally leverage pharmacophoric information and inadequately capture higher-order intramolecular relationships, such as conjugated systems. This study introduces a novel multi-modal hypergraph contrastive learning framework (MHGCL) to generate enriched molecular representations for enhanced MPP. MHGCL uniquely employs hypergraphs to model complex, many-to-many interactions within molecules. It incorporates a dual-channel architecture, featuring a hypergraph transformer and an equivariant graph neural network, to distinctly process 2D and 3D molecular information. Crucially, functional group and chemical element-oriented knowledge graphs are integrated to explicitly imbue the model with pharmacophoric knowledge. The contrastive learning strategy effectively aligns these diverse representations. Extensive experiments across ten benchmark datasets demonstrate that MHGCL consistently outperforms existing state-of-the-art methods. Further ablation studies confirm that the proposed hypergraph-based molecular representation captures structural motifs of molecular functional groups more effectively, thereby affirming the design efficacy of the model’s constituent modules.},
  archive      = {J_ASOC},
  author       = {Rui Han and Qun Liu and Xu Gong and Guoyin Wang and Li Liu and Xingping Xian},
  doi          = {10.1016/j.asoc.2025.113645},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113645},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MHGCL: A multi-modal hypergraph contrastive learning framework for molecular property prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-hop shapley-based framework for graph convolutional network node classification explanation. <em>ASOC</em>, <em>184</em>, 113615. (<a href='https://doi.org/10.1016/j.asoc.2025.113615'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks (GCNs) have recently demonstrated superior performance across various graph machine learning tasks. However, they are often regarded as “black-box” models, which has sparked significant interest in developing methods to interpret their predictions. Among various GCN explanation techniques, game-theoretic Shapley value approaches stand out for their ability to identify important nodes, edges, and features. Nonetheless, most Shapley-based explanation models tend to concentrate on dependencies within a fixed radius, resulting in a constrained perceptual field. Additionally, existing explanation methods primarily focus on the total marginal contributions of either very small or very large coalitions during sampling, which limits their effectiveness in capturing the joint marginal contributions inherent in mid-sized subgraphs. To address these challenges, we propose a novel Shapley-based GCN explanation model called MixHopShap, which incorporates multi-hop information and a balanced sampling strategy. MixHopShap employs a multi-hop computational graph construction process to generate an explanation domain, enabling it to capture both local and long-range dependencies. Moreover, MixHopShap introduces a new sampling strategy that promotes balanced coalition coverage, allowing for efficient sampling of mid-sized subgraphs and facilitating learning of marginal contributions for each edge. We conduct experiments on six real world datasets to evaluate the performance of MixHopShap in terms of Fidelity and ROAR metrics. The experimental results demonstrate the superiority of MixHopShap over state-of-the-art methods. Additionally, the explainability of MixHopShap can significantly improve the confidence of GCN’s prediction in node classification tasks.},
  archive      = {J_ASOC},
  author       = {Yifan Zheng and Xibei Yang and Qiguo Sun and Keyu Liu and Qihang Guo},
  doi          = {10.1016/j.asoc.2025.113615},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113615},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-hop shapley-based framework for graph convolutional network node classification explanation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural network-based interactive clustering enhanced by human knowledge. <em>ASOC</em>, <em>184</em>, 113595. (<a href='https://doi.org/10.1016/j.asoc.2025.113595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering techniques face persistent challenges in balancing automation with human interpretability. Traditional methods require laborious parameter tuning and domain expertise to define similarity measures and validate results, while deep learning approaches trade transparency for performance. To bridge this gap, we propose a human-in-the-loop framework that synergizes domain knowledge with graph-based semi-supervised learning. Our system enables users to iteratively refine clusters through intuitive visual adjustments on a subset of data, guided by real-time quality metrics to reduce errors and decision fatigue. These sparse annotations propagate to unlabeled instances via a graph neural network (GNN) that models latent relationships through modularity-driven structural learning. By translating cluster adjustments into semi-supervised classification tasks, our method eliminates manual feature engineering and scales to large datasets without retraining. Evaluations on two subsets of the MNIST dataset demonstrated that the NMI (Normalized Mutual Information) of our method improved by 50.44% and 64.77% relative to baseline clustering method, respectively.},
  archive      = {J_ASOC},
  author       = {Yunzhe Wang and Yushi Li and Qiming Fu and Chengtao Ji and You Lu and Jianping Chen},
  doi          = {10.1016/j.asoc.2025.113595},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113595},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph neural network-based interactive clustering enhanced by human knowledge},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced deep learning approaches for fault detection in solar PV systems: A comparative study of SPDA and AIFD-SolDL. <em>ASOC</em>, <em>184</em>, 113592. (<a href='https://doi.org/10.1016/j.asoc.2025.113592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient operation of solar photovoltaic (PV) systems is critical for maximizing power generation and ensuring optimal energy conversion. However, faults in PV modules can significantly impact system performance and reduce energy output. Therefore, accurate identification and diagnosis of these malfunctions are essential. To address the challenge of fault detection in solar PV systems, this study presents two distinct approaches. The first, called Solar Panel Degradation Assessment (SPDA), evaluates faults in solar panels by analyzing degradation effects while considering environmental factors like radiation and temperature. The second approach, named Efficient Ensemble Deep Learning Model for Enhancing Fault Detection in Solar PV Systems (AIFD-SolDL), utilizes advanced deep learning techniques, including DenseNet201, Inception-ResNet-v2, and Inception-v3, to enhance fault detection accuracy. In the AIFD-SolDL approach, PV module data undergo deep feature extraction followed by dimensionality reduction using principal component analysis (PCA). The reduced feature set is then used to train classifiers such as support vector machines (SVM), Gaussian Naive Bayes (GaussianNB), and random forests (RF) to differentiate between normal and fault conditions. Performance metrics, including precision, accuracy, recall, and F1-score, are computed for each combination of feature extractor and classifier. Extensive experiments with both the Solar Panel Images Dataset and the Infrared Solar Module Dataset show that the proposed approaches outperform state-of-the-art methods. For instance, the AIFD-SolDL approach utilizing SVM achieved perfect accuracy, precision, recall, and F1-score of 100% on the Solar Panel Images Dataset. Overall, the SPDA approach effectively detects faults, while deep learning techniques demonstrate high accuracy in fault classification, thereby enhancing the reliability of PV system maintenance and optimization.},
  archive      = {J_ASOC},
  author       = {Mohamed R. Shoaib and Heba M. Emara and Jun Zhao and Milad Taleby Ahvanooey and Essam Nabil},
  doi          = {10.1016/j.asoc.2025.113592},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113592},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advanced deep learning approaches for fault detection in solar PV systems: A comparative study of SPDA and AIFD-SolDL},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuroevolution-based multiobjective algorithm for feature selection and binary classification of DNA microarrays. <em>ASOC</em>, <em>184</em>, 113520. (<a href='https://doi.org/10.1016/j.asoc.2025.113520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The genomes of organisms have been sequenced for many years, leading to the discovery of thousands of genes. DNA microarrays are widely used tools for simultaneously analysing numerous genes, commonly employed in detecting and identifying various diseases, including cancer. However, microarray datasets have non-relevant and redundant information, hindering their analysis. This problem is further exacerbated considering the datasets’ high dimensionality and imbalanced classes. Consequently, standard practice involves incorporating a feature selection process to identify the most relevant genes and their associations with diseases. Various methods have been employed to address this task. However, none have taken a more holistic approach that effectively handles feature selection, automatically identifies the optimal classifier configuration, and manages potential conflicting objectives simultaneously. In response, this study introduces the S -metric selection - multiobjective neuroevolution of augmenting topologies (SMS-MONEAT) algorithm, which combines the multiobjective optimisation framework from S -metric selection - evolutionary multiobjective algorithm (SMS-EMOA) and the evolutionary operators from the neuroevolution algorithm N3O, a variation from NEAT which stands for ‘3 new operators’. SMS-MONEAT algorithm was designed to perform both feature selection and optimise the configuration of artificial neural networks for classification tasks. SMS-MONEAT was evaluated against classic and state-of-the-art methods for feature selection and microarray classification. The experiments were conducted on 20 highly challenging cancer-type datasets primarily sourced from the Curated Microarray Database, and the results were investigated for statistical significance. The findings suggest that SMS-MONEAT either outperforms or achieves competitive results in terms of classification compared to the mentioned methods, while at the same time, it selects a smaller subset of features.},
  archive      = {J_ASOC},
  author       = {Daniel García-Núñez and Katya Rodrígez-Vázquez and Carlos Hernández and Edgar Galván},
  doi          = {10.1016/j.asoc.2025.113520},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113520},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Neuroevolution-based multiobjective algorithm for feature selection and binary classification of DNA microarrays},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based bangla text normalization with emotion classification for expressive text-to-speech synthesizer. <em>ASOC</em>, <em>184</em>, 112899. (<a href='https://doi.org/10.1016/j.asoc.2025.112899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel method for text normalization and emotion classification specifically designed for the preprocessing steps of Expressive Text-to-Speech (ETTS) synthesizers. Text normalization, which converts non-standard words into standardized forms, is essential for generating clear and coherent output in ETTS synthesizers. Previous studies have encountered difficulties with Bangla homographic words, prompting the development of our proposed method. Our approach begins with the creation of a tokenized and categorized dataset consisting of 26 unique semiotic classes, utilizing a rule-based method with regular expressions. This dataset is derived from the Bangla Text Normalization Corpus (BTN Corpus), which contains 2 million Bangla sentences. Initially, Bangla written texts are tokenized, and each token is classified using a Temporal Convolutional Network (TCN) algorithm trained on the BTN Corpus to identify its semiotic class. This classification aids in generating normalized text, where the resulting tokens are reassembled into coherent sentences for final output. In addition to text normalization, we implement emotion classification for each normalized sentence using a Hierarchical Attention Network (HAN) model. The HAN model was trained on 67,277 normalized texts from the Bangla Normalized Emotion Text Corpus (BNET Corpus), categorizing each text into one of six emotion classes through a rule-based method with regular expressions. The proposed method demonstrates high accuracy rates, achieving a token classification accuracy of 99.977 % with the TCN and an emotion classification accuracy of 99.735 % with the HAN model.},
  archive      = {J_ASOC},
  author       = {Md. Rezaul Islam and Mohammad Shahidur Rahman},
  doi          = {10.1016/j.asoc.2025.112899},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {112899},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep learning-based bangla text normalization with emotion classification for expressive text-to-speech synthesizer},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
