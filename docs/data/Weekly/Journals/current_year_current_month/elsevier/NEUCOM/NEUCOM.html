<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NEUCOM</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="neucom">NEUCOM - 231</h2>
<ul>
<li><details>
<summary>
(2025). Dynamic sparse directed graph convolutional network with attention mechanisms for EEG emotion recognition. <em>NEUCOM</em>, <em>658</em>, 131749. (<a href='https://doi.org/10.1016/j.neucom.2025.131749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG)-based emotion recognition is limited by pronounced inter-individual variability and the non-stationarity of neural signals, which leads to key issues such as insufficient representation of existing brain networks and poor generalization performance of cross-subject models. Traditional graph convolution networks (GCNs) rely on symmetric adjacency matrices in modeling the relationships among EEG channels, which cannot characterize the directional transmission of neural signals, and static fully-connected graph structures are susceptible to redundant connection interference. To overcome these limitations, this study proposes a novel model named dynamic sparse directed graph convolutional network with attention mechanisms (DSDirGCN-AM), which adaptively constructs graph structures and preserves key connections through a dynamic sparse graph network, while augmenting the constructed graph structure by assigning importance weights to the channels in each brain region using channel attention. Directed graph convolution with direction awareness is employed to model asymmetric functional connectivity using a bidirectional normalized adjacency matrix to capture signal directions between brain regions. Additionally, a multi-head self-attentive cascade feature mechanism optimizes cascaded multiscale feature fusion through cross-layer correlation weight assignment. Experimental evaluations demonstrate that the proposed method has yielded the accuracies of 93.19 % in SEED and 81.30 % in SEED-IV, which are significantly better than existing methods. The proposed framework offers an EEG emotion recognition approach that better reflects neurophysiological mechanisms.},
  archive      = {J_NEUCOM},
  author       = {Kaiwei Shen and Qingshan She and Xiaoli Yang and Yunyuan Gao and Yingle Fan},
  doi          = {10.1016/j.neucom.2025.131749},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131749},
  shortjournal = {Neurocomputing},
  title        = {Dynamic sparse directed graph convolutional network with attention mechanisms for EEG emotion recognition},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven multi-model predictive control for nonlinear systems under cyber attacks. <em>NEUCOM</em>, <em>658</em>, 131732. (<a href='https://doi.org/10.1016/j.neucom.2025.131732'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model predictive control has demonstrated significant potential in managing nonlinear systems, but its effectiveness remains vulnerable to sophisticated cyber attacks. This paper presents a novel data-driven multi-model predictive control (DMMPC) framework that synergistically integrates cyber attack resilience with temporal feature learning. Compared with existing methods that focus on isolated channel attacks, the proposed framework explicitly considers cross-channel interference effects, enabling simultaneous mitigation of cyber attacks in sensor-controller and controller–actuator channels. Firstly, a data-driven anomaly detection system combining historical pattern matching with real-time signal deviation analysis is proposed to decrease the effects of sophisticated cyber attacks. Then, an expectation-based DMMPC method for nonlinear systems is designed to address the cyber attacks, and the bounded-input bounded-output stability of the closed-loop system is theoretically proven. Finally, the effectiveness of the proposed method is validated through numerical simulations and mobile robot experiments. Experimental results show that the proposed framework maintains tracking accuracy and system stability under various attack scenarios.},
  archive      = {J_NEUCOM},
  author       = {Yuesheng Liu and Zhongxian Xu and Ning He and Lile He and Ruoxia Li and Feng Gao},
  doi          = {10.1016/j.neucom.2025.131732},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131732},
  shortjournal = {Neurocomputing},
  title        = {Data-driven multi-model predictive control for nonlinear systems under cyber attacks},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UDA-DDA: Unsupervised domain adaptation with dynamic distribution alignment network for emotion recognition using EEG signals. <em>NEUCOM</em>, <em>658</em>, 131715. (<a href='https://doi.org/10.1016/j.neucom.2025.131715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the challenge of individual variability in affective brain-computer interfaces (aBCI), which employ electroencephalogram (EEG) signals to monitor and recognize human emotional states, thereby facilitating the advancement of emotion-aware technologies. The variability in EEG data across individuals poses a significant barrier to the development of effective and widely applicable aBCI models. To mitigate this issue, we propose a novel transfer learning framework called Unsupervised Domain Adaptation (UDA) with Dynamic Distribution Alignment (UDA-DDA). This approach aligns the marginal and conditional probability distributions of source and target domains by employing maximum mean discrepancy (MMD) and conditional maximum mean discrepancy (CMMD). Firstly, we introduce a dynamic distribution alignment mechanism to adjust differences throughout training and enhance adaptation. Additionally, a pseudo-label confidence filtering module is integrated into the unsupervised process to refine pseudo-label generation and optimize the estimation of conditional distributions. In order to demonstrate the effectiveness and robustness of the proposed UDA-DDA method, extensive experiments are conducted on EEG benchmark databases (SEED, SEED-IV and DEAP). Evaluations of the algorithm’s performance in comparison with other UDA with dynamic distribution alignment network methods indicate the proposed method achieves state-of-the-art results in emotion recognition across various scenarios, including cross-subject and cross-session conditions. This advancement significantly enhances the accuracy and generalization of emotion recognition, potentially fostering the development of personalized aBCI applications. The source code is accessible at https://github.com/XuanSuTrum/UDA-DDA .},
  archive      = {J_NEUCOM},
  author       = {Jiahao Tang and Youjun Li and Chun-Wang Su and Xiangting Fan and Yangxuan Zheng and Haoyu Wang and Hadia Naeem and Peng Fang and Jue Wang and Nan Yao and Xueping Li and Zi-Gang Huang},
  doi          = {10.1016/j.neucom.2025.131715},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131715},
  shortjournal = {Neurocomputing},
  title        = {UDA-DDA: Unsupervised domain adaptation with dynamic distribution alignment network for emotion recognition using EEG signals},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VLPRSDet: A vision–language pretrained model for remote sensing object detection. <em>NEUCOM</em>, <em>658</em>, 131712. (<a href='https://doi.org/10.1016/j.neucom.2025.131712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, numerous excellent vision-language models have emerged in the field of computer vision. These models have demonstrated strong zero-shot detection capabilities and better accuracy after fine-tuning on new datasets in the field of object detection. However, when these models are directly applied to the field of remote sensing, their performance is less than satisfactory. To address this problem, a novel vision-language pretrained model specifically tailored for remote sensing object detection task is proposed. Firstly, we create a new dataset composed of object-text pairs by collecting a large amount of remote sensing image object detection data to train the proposed model. Then, by integrating the CLIP model in the field of remote sensing with the YOLO detector, we propose a vision-language pretrained model for remote sensing object detection (VLPRSDet). VLPRSDet achieves enhanced fusion of visual and textual features through a vision language path aggregation network, and then aligns visual embeddings and textual embeddings through Region Text Matching to achieve the alignment between object regions and text. Experimental results indicate that the proposed VLPRSDet exhibits robust zero-shot capabilities in the field of remote sensing object detection, and can achieve superior detection accuracy after fine-tuning on specific datasets. Specifically, after fine-tuning, VLPRSDet can achieve 76.2 % mAP on the DIOR dataset and 94.2 % mAP on the HRRSD dataset. The code and dataset will be released at https://github.com/dyl96/VLPRSDet .},
  archive      = {J_NEUCOM},
  author       = {Dongyang Liu and Xuejian Liang and Yunxiao Qi and Yunqiao Xi and Jing Jin and Junping Zhang},
  doi          = {10.1016/j.neucom.2025.131712},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131712},
  shortjournal = {Neurocomputing},
  title        = {VLPRSDet: A vision–language pretrained model for remote sensing object detection},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fake news detection framework integrating multi-domain and multimodal features. <em>NEUCOM</em>, <em>658</em>, 131711. (<a href='https://doi.org/10.1016/j.neucom.2025.131711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread dissemination of video-based fake news on social media, identifying the authenticity of information in complex contexts has become increasingly challenging. News from different domains often differs significantly in vocabulary, expression styles, and modality distributions, leading to semantic ambiguity and increasing the difficulty of cross-news modeling. To address these challenges, this paper proposes a Multimodal Multi-Domain Fake News Detection framework (MMMD), which integrates textual, audio, and visual modalities. A domain gating mechanism is introduced to model domain-specific contextual structures, thereby enhancing the discriminative power of weak modalities (such as audio) and improving inter-modal coordination. Experiments conducted on multiple benchmark datasets show that MMMD outperforms mainstream multimodal methods in terms of accuracy, F1-score, and other metrics. Notably, on the FakeSV dataset, MMMD achieves a 6.87 % improvement in accuracy over the representative method SV-FEND. Furthermore, to address the high cost of domain annotation, a K-Means-based pseudo-label generation strategy is adopted. Comparative experiments across different numbers of clusters indicate that setting 10 yields performance close to that of human annotations, validating the method’s feasibility in low-supervision scenarios. Without relying on external user relationships, MMMD leverages domain-aware semantic structures and modality interaction mechanisms, providing an efficient and scalable solution for multimodal fake news detection in complex environments.},
  archive      = {J_NEUCOM},
  author       = {Longqin Guo and Zeqian Chen and Xiaoyang Liu},
  doi          = {10.1016/j.neucom.2025.131711},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131711},
  shortjournal = {Neurocomputing},
  title        = {A fake news detection framework integrating multi-domain and multimodal features},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FaceDisentGAN: Disentangled facial editing with targeted semantic alignment. <em>NEUCOM</em>, <em>658</em>, 131706. (<a href='https://doi.org/10.1016/j.neucom.2025.131706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial attribute editing in generative adversarial networks (GANs) involves two essential objectives: (1) accurately modifying the desired facial attribute, and (2) avoiding the unintended modification of irrelevant facial attributes. To address these challenges, we propose FaceDisentGAN, a novel generative framework for disentangled facial attribute manipulation. Specifically, we introduce: (1) a disentanglement module that decomposes feature maps into orthogonal spatial components (vertical and horizontal) to isolate target-related and unrelated semantics; (2) a two-stage training strategy that first learns general facial representations and then refines them to balance generic feature learning with fine-grained detail preservation; and (3) two novel evaluation metrics—Overall Preservation Score (OPS) and Perfect Match Rate (PMR)—which measure, respectively, the average preservation of non-target attributes and the proportion of perfectly disentangled results. This combination provides both soft and strict assessments of disentanglement quality. Extensive experiments demonstrate that FaceDisentGAN achieves accurate target attribute editing while effectively minimizing feature entanglement, outperforming several existing methods in both visual fidelity and semantic control.},
  archive      = {J_NEUCOM},
  author       = {Meng Xu and Prince Hamandawana and Xiaohan Ma and Zekang Chen and Rize Jin and Tae-Sun Chung},
  doi          = {10.1016/j.neucom.2025.131706},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131706},
  shortjournal = {Neurocomputing},
  title        = {FaceDisentGAN: Disentangled facial editing with targeted semantic alignment},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IntSTR: An integrated spatio-temporal relation transformer for video object detection. <em>NEUCOM</em>, <em>658</em>, 131704. (<a href='https://doi.org/10.1016/j.neucom.2025.131704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Transformer-based video object detection (VOD) methods have achieved remarkable progress by replacing the hand-crafted components traditionally used in CNN-based detectors. However, many existing approaches rely on staged spatio-temporal modeling strategies, which increase model complexity and restrict early interaction between spatial and temporal information. To overcome these limitations, we propose IntSTR, a novel framework for unified spatio-temporal modeling. At its core, the spatio-temporal relation encoder (STRE) integrates spatio-temporal feature processing within a single encoder through cascaded attention modules. To strengthen temporal consistency, the temporal query relation (TQR) module explicitly captures geometric relations between object queries across adjacent frames with minimal computational overhead. In addition, the Temporal Feature Memory (TFM) maintains a dynamic memory bank that caches temporal contexts, enabling effective feature aggregation and efficient online processing. Extensive experiments on the ImageNet VID dataset validate the effectiveness of our approach. IntSTR achieves an excellent trade-off between accuracy and efficiency, reaching a competitive 87.2 % mAP 50 with the ResNet-101 backbone while maintaining real-time performance at 33.4 FPS.},
  archive      = {J_NEUCOM},
  author       = {Wentao Zheng and Hong Zheng and Yuquan Sun and Ying Jing},
  doi          = {10.1016/j.neucom.2025.131704},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131704},
  shortjournal = {Neurocomputing},
  title        = {IntSTR: An integrated spatio-temporal relation transformer for video object detection},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SiTrEx: Siamese transformer for feedback and posture correction on workout exercises. <em>NEUCOM</em>, <em>658</em>, 131703. (<a href='https://doi.org/10.1016/j.neucom.2025.131703'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying Machine Learning and Deep Learning techniques to sequences of Human Pose Landmarks to recognize workout exercises and count repetitions is widely studied in the computer vision literature. However, existing approaches suffer from two major problems. The first issue is that they lack the ability to provide detailed feedback on the postures performed by the athletes or provide feedback for a limited range of exercises using hand-designed rules and algorithms. The second problem is that these approaches consider only a predefined set of exercises and do not generalize to exercises outside their training data, which limits their usability. In this paper, we aim to address these two shortcomings by proposing a one-shot learning approach that utilizes Siamese Transformers to provide detailed feedback on individual human joints and can generalize to new exercises that are not present in the used dataset. The proposed configuration of the Siamese Transformer model deviates from its standard use in that it outputs a vector of similarity indicators rather than a single similarity score. Additionally, an accompanying binary classification Transformer model is used to assess the usefulness of different parts of the human pose for the input exercise without prior knowledge of the exercise itself. These properties allow the proposed approach to be used in general-purpose fitness applications and coach/athlete training platforms. The proposed approach achieved a 5-fold cross-validation test accuracy of 94.4 % ± 0.8 on the collected dataset.},
  archive      = {J_NEUCOM},
  author       = {Abdellah Sellam and Dounya Kassimi and Abdelhadi Djebana and Sara Mokhtari},
  doi          = {10.1016/j.neucom.2025.131703},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131703},
  shortjournal = {Neurocomputing},
  title        = {SiTrEx: Siamese transformer for feedback and posture correction on workout exercises},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EIAformer: Empowering transformer with enhanced information acquisition for time series forecasting. <em>NEUCOM</em>, <em>658</em>, 131700. (<a href='https://doi.org/10.1016/j.neucom.2025.131700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based models have gained significant popularity and demonstrated remarkable performance in long-term time series forecasting. However, existing Transformer-based models are not designed to fully exploit the variation patterns and multiscale information of time series data. Moreover, there is a lack of channel strategy that effectively captures the essential connections between channels for improving the efficiency and accuracy of channel utilization. To overcome these problems, we propose a novel and adaptable architecture, EIAformer, to utilize comprehensive information to enhance the prediction performance. Firstly, hybrid decomposition is proposed to perform different operations on data with different variation patterns using a divide-and-conquer strategy. Then, dynamic patching based on dilated causal convolution is designed to capture multiscale information. Finally, channel fusion based on Granger Causality and DTW distance is constructed to capture the correlation between different channels, and the merged channels are fed into the encoder to perform prediction. Extensive experiments on nine datasets demonstrate that EIAformer achieves superior performance compared to existing Transformer-based models. Meanwhile, the proposed enhancement module as a plug-and-play solution can boost the performance and efficiency of the Transformer family models.},
  archive      = {J_NEUCOM},
  author       = {Weina Wang and Yongjie Wang and Xiaolong Qi and Hui Chen},
  doi          = {10.1016/j.neucom.2025.131700},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131700},
  shortjournal = {Neurocomputing},
  title        = {EIAformer: Empowering transformer with enhanced information acquisition for time series forecasting},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A small-sample cross-domain bearing fault diagnosis method based on knowledge-enhanced domain adversarial learning. <em>NEUCOM</em>, <em>658</em>, 131699. (<a href='https://doi.org/10.1016/j.neucom.2025.131699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional domain adaptation methods often perform poorly in cross-device bearing fault diagnosis when the target domain contains incomplete labels or exhibits imbalanced data. To address this issue, we propose an Adaptive meta-domain transfer learning network (AMTLN), which integrates a self-weighted fusion (SWF) module and a knowledge-enhanced domain adversarial learning (KEDA) framework to improve accuracy and robustness. An AMK-Fast DTW algorithm aligns vibration signals across domains, and kernel density estimation minimizes distributional differences. KEDA introduces auxiliary knowledge and meta-learning to enhance transfer performance in small-sample scenarios and reduce catastrophic forgetting. SWF further strengthens the forward knowledge transfer. Experiments show that AMTLN achieves high accuracy and strong generalization across varying operational conditions, even with incompletely labeled target data.},
  archive      = {J_NEUCOM},
  author       = {Peiming Shi and Yan Zhao and Xuefang Xu and Dongying Han},
  doi          = {10.1016/j.neucom.2025.131699},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131699},
  shortjournal = {Neurocomputing},
  title        = {A small-sample cross-domain bearing fault diagnosis method based on knowledge-enhanced domain adversarial learning},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRIFT: DCT-based robust and intelligent federated learning with trusted privacy. <em>NEUCOM</em>, <em>658</em>, 131697. (<a href='https://doi.org/10.1016/j.neucom.2025.131697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) allows collaborative model training across decentralized clients without sharing private data. However, traditional FL frameworks face dual challenges: vulnerability to Byzantine attacks (where malicious clients submit adversarial model updates) and privacy breaches (where curious clients infer sensitive information from exchanged parameters), exacerbated by decentralized operations and unencrypted communications. While existing work addresses robustness or privacy individually, the interplay between defense mechanisms, particularly the trade-off between attack resilience and utility degradation caused by privacy safeguards, remains understudied. To bridge this gap, we propose DRIFT , a novel FL framework that simultaneously achieves Byzantine robustness and privacy preservation. Our approach uniquely combines spectral analysis with cryptographic protection: By transforming model parameters into the frequency domain through Discrete Cosine Transform, DRIFT identifies malicious updates via spectral clustering while inherently obscuring sensitive parameter patterns. This defense mechanism is further reinforced by a privacy-preserving aggregation protocol leveraging fully homomorphic encryption with floating-point computation. It encrypts client updates during transmission and aggregation without compromising their computational usability. Extensive evaluations on MNIST and PathMNIST demonstrate that DRIFT outperforms baseline methods in resisting state-of-the-art Byzantine attacks while maintaining model utility and providing provable privacy guarantees.},
  archive      = {J_NEUCOM},
  author       = {Qihao Dong and Yang Bai and Mang Su and Yansong Gao and Anmin Fu},
  doi          = {10.1016/j.neucom.2025.131697},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131697},
  shortjournal = {Neurocomputing},
  title        = {DRIFT: DCT-based robust and intelligent federated learning with trusted privacy},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalizable 3D gaussian splatting via multi-view stereo and consistency constraints. <em>NEUCOM</em>, <em>658</em>, 131696. (<a href='https://doi.org/10.1016/j.neucom.2025.131696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent neural rendering methods still struggle with fine-grained detail reconstruction and scene generalization, especially when handling complex geometries and low-texture regions. To address these challenges, we propose a 3D Gaussian Splatting (3DGS) framework enhanced by Multi-view Stereo (MVS), aiming to improve both rendering quality and cross-scene adaptability. Specifically, we first introduce an Adaptive Perception-aware Feature Aggregation (APFA) module, which effectively fuses 2D image features into 3D geometry-aware representations via a Local Feature Adaptive Collaboration (LFAC) mechanism and a global Attention-Aware Module (AAM), significantly improving reconstruction performance in challenging scenes. Subsequently, we propose a depth and normal supervision strategy based on multi-view geometric consistency, where aggregated point clouds are utilized for optimized initialization, enhancing stability and fine-grained detail fidelity. Finally, a Gaussian geometric consistency regularization module is introduced to further enforce the coherence between depth and normal predictions, leading to more refined rendering results. Extensive experiments on standard benchmarks including DTU, Real Forward-facing, NeRF Synthetic, and Tanks and Temples demonstrate that our method outperforms state-of-the-art approaches in terms of PSNR, SSIM, and LPIPS metrics. Particularly in real-world complex scenes, our approach achieves superior generalization ability and perceptual quality, validating the effectiveness of the proposed framework. The code for our method will be made available at https://github.com/yangyongjuan/MVS-APFA-GS .},
  archive      = {J_NEUCOM},
  author       = {Yongjuan Yang and Jie Cao and Hong Zhao and Weijie Wang},
  doi          = {10.1016/j.neucom.2025.131696},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131696},
  shortjournal = {Neurocomputing},
  title        = {Generalizable 3D gaussian splatting via multi-view stereo and consistency constraints},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TensorProjection layer: A tensor-based dimension reduction method in deep neural networks. <em>NEUCOM</em>, <em>658</em>, 131695. (<a href='https://doi.org/10.1016/j.neucom.2025.131695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a dimension reduction method for features with tensor structure, implemented as a neural network layer called the TensorProjection Layer. This layer applies mode-wise linear projections to the input tensor to reduce its dimensionality, with the projection directions treated as trainable parameters optimized during model training. The method is particularly useful for image data, serving as an alternative to pooling layers that reduce spatial redundancy. It can also reduce channel dimensions, making it applicable to various forms of tensor compression. While especially effective for image-based tasks, its application is not limited to them—as long as the intermediate representation is a tensor. We also demonstrate its use in multi-channel time-series and language data, showcasing its flexibility across diverse modalities. We evaluate the method by replacing specific layers in standard baseline models with TPL, across tasks including medical image classification and segmentation, classification of medical time-series signals, and classification of medical abstract texts. Experimental results suggest that, compared to conventional downsampling techniques such as pooling, the proposed layer offers improved generalization performance, making it a promising alternative for feature summarization in diverse neural network architectures.},
  archive      = {J_NEUCOM},
  author       = {Toshinari Morimoto and Su-Yun Huang},
  doi          = {10.1016/j.neucom.2025.131695},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131695},
  shortjournal = {Neurocomputing},
  title        = {TensorProjection layer: A tensor-based dimension reduction method in deep neural networks},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disentangled adaptive multi-dimensional dynamic graph convolutional network for skeleton-based action recognition. <em>NEUCOM</em>, <em>658</em>, 131693. (<a href='https://doi.org/10.1016/j.neucom.2025.131693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition plays a key role in computer vision and has gained significant attention due to its broad range of applications. However, most existing methods using graph convolutional networks struggle to effectively learn rich temporal and spatial motion features of body joints. In this work, the disentangled adaptive multi-dimensional dynamic graph convolutional network model that we present consists of three modules: a disentangled adaptive graph convolutional network module, a multi-dimensional dynamic temporal convolutional network module, and an efficient multi-scale attention module. Firstly, the disentangled adaptive graph convolutional network module is able to learn crucial details and interactive relationships of body joints by updating the primitive anatomical structure of the human body and adaptively changing the structural graph topology. Then, the multi-dimensional dynamic temporal convolutional network module is proposed to improve the capability of rich trajectory feature extraction and comprehensive representation. Finally, the efficient multi-scale attention module can concentrate on spatial-temporal information across the temporal and spatial dimensions to strengthen features in critical temporal frames at significant joints. Extensive experiments are performed on three large-scale datasets, including NTU RGB+D, NTU RGB+D 120, and Kinetics-Skeleton, demonstrating that the proposed model achieves state-of-the-art performance and can extract rich trajectory and spatial information from skeleton data.},
  archive      = {J_NEUCOM},
  author       = {Jie Li and Peitao Ye and Yu Xia and Yanwen Wang and Yi Cao},
  doi          = {10.1016/j.neucom.2025.131693},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131693},
  shortjournal = {Neurocomputing},
  title        = {Disentangled adaptive multi-dimensional dynamic graph convolutional network for skeleton-based action recognition},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards explainable trajectory classification: A segment-based perturbation approach. <em>NEUCOM</em>, <em>658</em>, 131691. (<a href='https://doi.org/10.1016/j.neucom.2025.131691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory classification is essential in applications such as transportation analysis, wildlife tracking, and human mobility studies. However, many existing models, especially deep learning-based approaches, suffer from a lack of explainability, making it challenging to understand their decision-making processes. To address this issue, we propose a model-agnostic explainability framework for trajectory classification based on subsegment perturbation. Our method systematically perturbs individual trajectory subsegments and constructs an importance map to highlight their contributions to the classification outcome. Additionally, we also propose a novel fidelity to assess the ability to provide interpretations as well as the quality of the interpretations. We evaluate the framework using multiple benchmark trajectory datasets and various classifiers, including both traditional machine learning models and deep learning models. Experimental results demonstrate that our method provides effective and meaningful explanations, especially the flexibility to be applied to many types of models.},
  archive      = {J_NEUCOM},
  author       = {Le Xuan Tung and Bui Dang Phuc and Vo Nguyen Le Duy},
  doi          = {10.1016/j.neucom.2025.131691},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131691},
  shortjournal = {Neurocomputing},
  title        = {Towards explainable trajectory classification: A segment-based perturbation approach},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The development and future of digital rights management: A review. <em>NEUCOM</em>, <em>658</em>, 131672. (<a href='https://doi.org/10.1016/j.neucom.2025.131672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital rights management (DRM) serves as a critical technological mechanism for copyright protection, ensuring the legitimate use of digital content, and facilitating innovative business models in content distribution and access. This paper begins by introducing the fundamental concepts and typical architecture of DRM systems. It then provides a detailed analysis of the four distinct evolutionary phases of DRM, with a focus on key technologies including usage control, rights expression, content sharing, and decentralization. The paper further examines DRM standards, legal implications, and the tension between enforcement and fair use. Finally, it outlines future challenges and suggests promising directions for future research.},
  archive      = {J_NEUCOM},
  author       = {Xue Feng and Yijie Pan and Nai-an Xiao},
  doi          = {10.1016/j.neucom.2025.131672},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131672},
  shortjournal = {Neurocomputing},
  title        = {The development and future of digital rights management: A review},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight convolution and vision transformer integrated model with multi-scale self-attention mechanism. <em>NEUCOM</em>, <em>658</em>, 131670. (<a href='https://doi.org/10.1016/j.neucom.2025.131670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformer (ViT) has prevailed in computer vision tasks due to its strong long-range dependency modelling ability. However, its large model size and weak local feature modeling ability hinder its application in real scenarios. To balance computational efficiency and performance in downstream vision tasks, we propose an efficient ViT model with sparse attention (dubbed SAEViT) and convolution blocks. Specifically, a Sparsely Aggregated Attention (SAA) module has been proposed to perform adaptive sparse sampling and recover the feature map via deconvolution operation, which significantly reduces the computational complexity of attention operations. In addition, a Channel-Interactive Feed-Forward Network (CIFFN) layer is developed to enhance inter-channel information exchange through feature decomposition and redistribution, which mitigates the redundancy in traditional feed-forward networks (FFN). Finally, a hierarchical pyramid structure with embedded depth-wise separable convolutional blocks (DWSConv) is devised to further strengthen convolutional features. Extensive experiments on mainstream datasets show that SAEViT achieves Top-1 accuracies of 76.3 % and 79.6 % on the ImageNet-1 K classification task with only 0.8 GFLOPs and 1.3 GFLOPs, respectively, demonstrating a lightweight solution for fundamental vision tasks.},
  archive      = {J_NEUCOM},
  author       = {Yi Zhang and Lingxiao Wei and Bowei Zhang and Ziwei Liu and Kai Yi and Shu Hu},
  doi          = {10.1016/j.neucom.2025.131670},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131670},
  shortjournal = {Neurocomputing},
  title        = {A lightweight convolution and vision transformer integrated model with multi-scale self-attention mechanism},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). StreamVAD: A streaming framework with progressive context integration for multi-temporal scale video anomaly detection. <em>NEUCOM</em>, <em>658</em>, 131669. (<a href='https://doi.org/10.1016/j.neucom.2025.131669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection (VAD) plays a crucial role in intelligent surveillance systems by identifying abnormal events in video streams. However, most existing methods either rely on isolated feature extraction—failing to model inter-action contextual relationships critical for complex anomaly recognition—or demand full-video processing via graph/hierarchical architectures, which incur high latency, computational burden, and parameter/memory inefficiency with depth. Lightweight designs mitigate costs but sacrifice temporal sensitivity through shallow networks and short-clip inputs, limiting detection of subtle or multi-scale anomalies in streaming scenarios. To address these challenges, we propose StreamVAD, a lightweight streaming anomaly detection framework that achieves low-latency, long-term temporal modeling with minimal computational overhead. A Key Clip Generator (KCG) filters redundant inputs in a streaming manner, allowing the model to focus on informative content while reducing computational cost. A progressive context integration (PCI) module incrementally expands the temporal receptive field by integrating historical context without full-sequence buffering, enabling efficient detection of complex long-term anomalies. Additionally, a multi-scale temporal selection (MTS) strategy dynamically adapts temporal resolution to capture both short- and long-term abnormalities. Extensive experiments on UCF-Crime, XD-Violence, and a supplemental long-term anomaly dataset demonstrate that StreamVAD achieves effective video anomaly detection with fewer parameters and lower latency. The code and dataset are available at https://github.com/Han-lijun/StreamVAD .},
  archive      = {J_NEUCOM},
  author       = {Lijun Han and Gang Liang and Pengcheng Wang and Dingming Liu and Kui Zhao},
  doi          = {10.1016/j.neucom.2025.131669},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131669},
  shortjournal = {Neurocomputing},
  title        = {StreamVAD: A streaming framework with progressive context integration for multi-temporal scale video anomaly detection},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-feature interactive temporal knowledge graph reasoning with evolving retention mechanism. <em>NEUCOM</em>, <em>658</em>, 131663. (<a href='https://doi.org/10.1016/j.neucom.2025.131663'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graph (TKG) reasoning emphasizes deducing absent connections within evolving knowledge graphs (KGs), which is essential for comprehending dynamic engineering informatics. However, the ongoing dynamic evolution of TKGs presents significant challenges for accurate predictions. To address this challenge, this paper proposes a cross-feature temporal evolution network (CFTENet), which designs an evolving retention mechanism establishing a knowledge forgetting threshold to lock in snapshots of continuous evolution. The importance of knowledge gradually diminishes until the information becomes outdated and is completely forgotten. Historical information at previous time points is preserved in current snapshot to simulate continuous dynamic evolution of knowledge. Moreover, CFTENet incorporates a cross-feature interaction module, leveraging a multilayer dilated convolutional network and a residual network to grasp cross-feature intricate interactions among and across entity and relation characteristics. The proposed model improves the reasoning ability and resilience to unseen data. Comprehensive testing on four benchmark datasets (ICEWS14, ICEWS18, GDELT, WIKI) demonstrates that our model achieves significant performance improvements, surpassing the baseline methods by 1.5 %, 8.8 %, 6.5 %, and 2.2 %, which highlights its effectiveness in TKG reasoning.},
  archive      = {J_NEUCOM},
  author       = {Ying Cui and Xiao Song and Yishi Liu and Ming Liu},
  doi          = {10.1016/j.neucom.2025.131663},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131663},
  shortjournal = {Neurocomputing},
  title        = {Cross-feature interactive temporal knowledge graph reasoning with evolving retention mechanism},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tabular data generation models: An in-depth survey and performance benchmarks with extensive tuning. <em>NEUCOM</em>, <em>658</em>, 131655. (<a href='https://doi.org/10.1016/j.neucom.2025.131655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating realistic, safe, and useful tabular data is important for downstream tasks such as privacy preserving, imputation, oversampling, explainability, and simulation. However, the structure of tabular data, marked by heterogeneous types, non-smooth distributions, complex feature dependencies, and categorical imbalance, poses significant challenges. Although many generative approaches have been proposed, a fair and unified evaluation across datasets remains missing. This work benchmarks five recent model families on 16 diverse datasets (average 80 K rows), with careful optimization of hyperparameters, feature encodings, and architectures. We show that dataset-specific tuning leads to substantial performance gains, particularly for diffusion-based models. We further introduce constrained hyperparameter spaces that retain competitive performance while significantly reducing tuning cost, enabling efficient model selection under fixed GPU budgets. As future perspectives, we can study cross-domain and cross-table generation.},
  archive      = {J_NEUCOM},
  author       = {G.Charbel N. Kindji and Lina M. Rojas-Barahona and Elisa Fromont and Tanguy Urvoy},
  doi          = {10.1016/j.neucom.2025.131655},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131655},
  shortjournal = {Neurocomputing},
  title        = {Tabular data generation models: An in-depth survey and performance benchmarks with extensive tuning},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algorithmically-designed reward shaping for multiagent reinforcement learning in navigation. <em>NEUCOM</em>, <em>658</em>, 131654. (<a href='https://doi.org/10.1016/j.neucom.2025.131654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The practical applicability of multiagent reinforcement learning is hindered by its low sample efficiency and slow learning speed. While reward shaping and expert guidance can partially mitigate these challenges, their efficiency is offset by the need for substantial manual effort. To address these constraints, we introduce Multiagent Environment-aware semi-Automated Guide (MEAG), a novel framework that leverages widely known, highly efficient, and low-resolution single-agent pathfinding algorithms for shaping rewards to guide multiagent reinforcement learning agents. MEAG uses these single-agent solvers over a coarse-grid surrogate that requires minimal manual intervention, and guides agents away from random exploration in a manner that significantly reduces computational costs. When tested across a range of densely and sparsely connected multiagent navigation environments, MEAG consistently outperforms state-of-the-art algorithms, achieving up to 50 % faster convergence and 20 % higher rewards. These improvements enable the consideration of MARL for more complex real-world pathfinding applications ranging from warehouse automation to search and rescue operations, and swarm robotics.},
  archive      = {J_NEUCOM},
  author       = {Ifrah Saeed and Andrew C. Cullen and Zainab Zaidi and Sarah Erfani and Tansu Alpcan},
  doi          = {10.1016/j.neucom.2025.131654},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131654},
  shortjournal = {Neurocomputing},
  title        = {Algorithmically-designed reward shaping for multiagent reinforcement learning in navigation},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual perspective-aware graph neural network for graph-level anomaly detection. <em>NEUCOM</em>, <em>658</em>, 131649. (<a href='https://doi.org/10.1016/j.neucom.2025.131649'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-level anomaly detection based on graph neural networks (GAD-GNN) aims to identify graphs exhibiting anomalous characteristics distinct from the majority in a dataset. However, existing GAD-GNN methods face two critical challenges: Aggregation anomaly dilution occurs when the signals of sparsely distributed abnormal nodes are overwhelmed by the dominant influence of normal nodes during message passing. Readout anomaly dilution arises when locally concentrated anomalies are smoothed out in graph readout. To overcome these challenges, we propose the D ual P erspective-Aware G raph N eural N etwork (DPGNN), which integrates two complementary modules. The Global Awareness Module enhances node representations with multi-scale return-probability fingerprints, ensuring that signals of sparsely distributed abnormal nodes are preserved against overwhelming normal patterns. The Local Awareness Module adaptively identifies anomaly subgraphs using structural cues and employs attention-based readout to retain concentrated anomalies from being diluted in graph readout. Extensive experiments on multiple benchmark datasets demonstrate that DPGNN consistently outperforms state-of-the-art methods, validating its effectiveness in detecting graph-level anomalies.},
  archive      = {J_NEUCOM},
  author       = {Jianliang Gao and Xinqiu Zhang and Qiutong Li and Jiamin Chen},
  doi          = {10.1016/j.neucom.2025.131649},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131649},
  shortjournal = {Neurocomputing},
  title        = {Dual perspective-aware graph neural network for graph-level anomaly detection},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coordinate descent for top-k multi-label feature selection with pseudo-label learning and manifold learning. <em>NEUCOM</em>, <em>658</em>, 131640. (<a href='https://doi.org/10.1016/j.neucom.2025.131640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning plays an increasingly important role in handling complex problems where data instances are associated with multiple labels. However, current methods face significant limitations when dealing with high-dimensional feature spaces. They struggle to preserve the geometric structure among features while failing to fully exploit the latent correlations between labels. To address these key challenges, this paper proposes a novel feature selection method called coordinate descent for top-k multi-label feature selection with pseudo-label learning and manifold learning (CD-MPL), which integrates manifold learning with pseudo-label learning techniques. First, by constructing a feature graph Laplacian matrix, we establish a mathematical representation of the feature manifold structure, effectively preserving the local geometric properties of the feature space. Second, we introduce a pseudo-label learning mechanism, converting discrete binary labels into continuous representations to better model complex label correlations. Notably, to tackle the non-convex optimization problem caused by the ℓ 2 , 0 -norm constraint, we innovatively transform the original problem into the joint optimization of a continuous matrix and a discrete selection matrix. We then employ a coordinate descent (CD) method to efficiently solve the selection matrix, overcoming the non-convexity issue while enhancing model performance, interpretability, and practicality. Experimental results on ten multi-label datasets demonstrate that CD-MPL significantly outperforms existing methods across multiple key evaluation metrics, achieving an average performance improvement of 3.31 %. The algorithm maintains stable performance even with reduced feature subsets and exhibits rapid convergence within 10 iterations, fully validating its efficiency and effectiveness in multi-label classification tasks.},
  archive      = {J_NEUCOM},
  author       = {Ruijia Li and Yingcang Ma and Hong Chen and Xiaofei Yang and Zhiwei Xing},
  doi          = {10.1016/j.neucom.2025.131640},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131640},
  shortjournal = {Neurocomputing},
  title        = {Coordinate descent for top-k multi-label feature selection with pseudo-label learning and manifold learning},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic event-based asymptotic tracking and vibration control for constrained flexible manipulator systems with intermittent faults. <em>NEUCOM</em>, <em>658</em>, 131638. (<a href='https://doi.org/10.1016/j.neucom.2025.131638'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The angle constraint and vibration suppression issues of flexible manipulator (FM) systems subjected to intermittent faults are addressed in this article. Firstly, integral barrier Lyapunov functions (BLFs) that can directly constrain the angular position are introduced, eliminating the feasibility conditions of traditional BLFs. Secondly, a triggering mechanism with dynamic variables is provided to reduce the transmission of redundant information, thereby saving communication resources. To mitigate the impact of intermittent faults and handle system, the boundary estimation method and the neural networks (NNs) technology considering the influence of approximation error are adopted, which reduces the conservatism of the developed control algorithm. Through Lyapunov stability theory and Hamiltonian principle, a dynamic event-based fault-tolerant controller is designed, suppressing the offset of the FM while ensuring that the angular position asymptotically tracks the ideal position without exceeding the given constraint boundary. Eventually, the simulation results demonstrate the rationality of the developed control scheme.},
  archive      = {J_NEUCOM},
  author       = {Shan-Lin Liu and Meina Zhai and Rui Wang and Yufeng Tian},
  doi          = {10.1016/j.neucom.2025.131638},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131638},
  shortjournal = {Neurocomputing},
  title        = {Dynamic event-based asymptotic tracking and vibration control for constrained flexible manipulator systems with intermittent faults},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised temporal action segmentation with sample discrimination training and alignment-based boundary refinement. <em>NEUCOM</em>, <em>658</em>, 131636. (<a href='https://doi.org/10.1016/j.neucom.2025.131636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised temporal action segmentation (UTAS) addresses the task of partitioning untrimmed videos into coherent action segments without manual annotations. While boundary-detection-based approaches have demonstrated superior performance, they exhibit two critical limitations. First, these methods often uniformly treat all frames during training, resulting in over-segmentation and suboptimal performance. Second, they primarily rely on intra-video features while neglecting potentially valuable inter-video correlations within the dataset. To address these challenges, we present a comprehensive UTAS framework with three key innovations: (1) A discriminative training mechanism that differentiates between boundary/non-boundary frames in the temporal domain and motion/background pixels in the spatial domain, employing weighted training strategies alongside multiple temporal-scale modeling. (2) A self-validation mechanism for cross-verifying predictions across different input sequences. (3) A boundary refinement approach based on video alignment, which constructs reference video sets according to feature distributions and establishes inter-video correspondences to improve boundary localization. Extensive evaluations on three benchmark datasets, i.e. , the Breakfast, the 50Salads, and the YouTube Instructions, demonstrate that our approach achieves state-of-the-art performance, with quantitative results showing significant improvements over existing methods.},
  archive      = {J_NEUCOM},
  author       = {Feng Huang and Xiao-Diao Chen and Hongyu Chen and Haichuan Song},
  doi          = {10.1016/j.neucom.2025.131636},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131636},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised temporal action segmentation with sample discrimination training and alignment-based boundary refinement},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quaternion reservoir computing for spatiotemporal analysis in polarimetric synthetic aperture radar. <em>NEUCOM</em>, <em>658</em>, 131633. (<a href='https://doi.org/10.1016/j.neucom.2025.131633'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quaternion neural networks possess high generalization ability in three-dimensional (3D) information space by representing every 3D data point as a single quaternion entity. In polarimetric synthetic aperture radar (PolSAR) applications such as land surface classification, they are expected to deal with 3D Poincare parameters as inseparable physical entities. With the increasing acquisition frequency, there is a growing demand also for efficient and robust techniques to monitor temporal or spatiotemporal changes. Reservoir computing (RC) is a variation of recurrent neural networks (RNNs) capable of detecting changes in series data with low computational cost. In this context, we propose quaternion reservoir computing (QRC) for spatiotemporal analysis in PolSAR. First, in a benchmark prediction task for chaotic time-series derived from the 3D Lorenz equations, we demonstrate that QRC achieves higher prediction accuracy than real-valued RC and conventional RNNs. Secondly, we conduct spatiotemporal anomalous change detection for actual PolSAR data of (1) rice fields having seasonal changes in Japan and (2) Amazon rainforest suffering from deforestation in Brazil. Compared with real-valued RC, RNNs, one-dimensional convolutional neural networks, Transformer, and non-adaptive methods based on complex Wishart and Pauli RGB, QRC shows a larger area under the curve (AUC) score, demonstrating its high efficacy in capturing spatiotemporal anomalous variations in PolSAR data. Besides such high performance, QRC shows low training cost, which is very suitable for real-time processing in edge computing including highly frequent satellite observations. These experimental results indicate that combining quaternion representation with RC is a promising approach for analyzing the ever-increasing volume of PolSAR data.},
  archive      = {J_NEUCOM},
  author       = {Kitoshi Kawai and Bungo Konishi and Ryo Natsuaki and Akira Hirose},
  doi          = {10.1016/j.neucom.2025.131633},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131633},
  shortjournal = {Neurocomputing},
  title        = {Quaternion reservoir computing for spatiotemporal analysis in polarimetric synthetic aperture radar},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D gaussian splatting technologies and extensions: A review. <em>NEUCOM</em>, <em>658</em>, 131629. (<a href='https://doi.org/10.1016/j.neucom.2025.131629'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, 3D Gaussian Splatting (3DGS) has achieved remarkable progress in the field of novel view synthesis. Unlike implicit neural radiance field (NeRF) methods that primarily focus on positional and viewpoint transformations, 3DGS leverages millions of Gaussian ellipsoids for scene reconstruction and employs parallel differentiable rasterization to substantially improve rendering efficiency. Given the rapid advancement and promising prospects of this technique, this survey presents a systematic overview of recent developments in 3DGS. We provide a detailed exposition of the fundamental theory underlying 3DGS, along with relevant benchmark datasets. Uniquely, this work organizes existing optimization strategies according to the stages of the Gaussian splatting pipeline. In addition, we review various downstream applications based on 3DGS and discuss prospective research directions. This survey aims to serve as a valuable reference for researchers across all stages of engagement and to foster further advancements in 3DGS.},
  archive      = {J_NEUCOM},
  author       = {Fengkai Luan and Siliang Sun and Hu Zhang and Yong Yin and Ke Wang and Jiaxing Yang},
  doi          = {10.1016/j.neucom.2025.131629},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131629},
  shortjournal = {Neurocomputing},
  title        = {3D gaussian splatting technologies and extensions: A review},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prototype-based multi-domain self-distillation for unbiased scene graph generation. <em>NEUCOM</em>, <em>658</em>, 131625. (<a href='https://doi.org/10.1016/j.neucom.2025.131625'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene Graph Generation (SGG) plays an important role in reinforcing visual image understanding. Existing methods often encounter difficulties in effectively representing implicit relationship features, which limits their capacity to distinguish between predicates. Meanwhile, these approaches are susceptible to imbalanced instance distributions, hindering the efficient training of fine-grained predicates. To address these problems, we propose a novel prototype-based multi-domain self-distillation training framework. Specifically, a Multi-Domain Fusion (MDF) module is introduced to improve predicate feature representation by integrating global contextual information and local spatial-frequency domain information. Then, a Prototype Generation Network (PGN) is designed for building the class prototypes, which consists of the design of different granularity predicates and loss functions. Furthermore, we design two different data balancing strategies under the guidance of class prototypes, which correspond to mining the in-distribution and out-of-distribution information of the original data, respectively. The experimental results demonstrate that the proposed method is superior to the existing methods on VG, GQA and Open Images V6 datasets, which makes it more applicable to generating unbiased scene graph models.},
  archive      = {J_NEUCOM},
  author       = {Yuan Gao and Yaochen Li and Yujie Zang and Jingze Liu and Yuehu Liu},
  doi          = {10.1016/j.neucom.2025.131625},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131625},
  shortjournal = {Neurocomputing},
  title        = {Prototype-based multi-domain self-distillation for unbiased scene graph generation},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DJIST: Decoupled joint image and sequence training framework for sequential visual place recognition. <em>NEUCOM</em>, <em>658</em>, 131622. (<a href='https://doi.org/10.1016/j.neucom.2025.131622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional image-to-image (im2im) visual place recognition (VPR) involves matching a single query image to stored geo-tagged database images. In real-time robotic and autonomous applications, while a continuous stream of frames naturally leads to a simpler sequence-to-sequence (seq2seq) VPR problem, the challenges remain since labeled sequential data is much scarcer than labeled individual images. A recent work addressed this by using a unified network optimized for both seq2seq and im2im tasks, but the resulting sequential descriptors are heavily dependent on the individual descriptors trained on the im2im task. This paper proposes a decoupled joint image and sequence training (DJIST) framework, using a frozen backbone and two independent sequential branches, where one branch is supervised by both im2im and seq2seq losses and the other solely by the seq2seq loss. The feature reduction procedures for generating individual descriptors and sequential descriptors are further separated in the former branch. An attention separation loss is employed between the two branches, which forces them to focus on different parts of the images to produce more informative sequential descriptors. We retrain various existing seq2seq methods using the same backbone and two types of joint training strategies for a fair comparison. Extensive experimental results demonstrate that our proposed DJIST outperforms its original counterpart JIST by 3.9 % to 18.8 % across four benchmark test cases and achieves state-of-the-art Recall@1 scores against retrained baselines on three key benchmarks with robust cross-dataset generalization, negligible degradation under dimensionality reduction, and superior robustness against varying test-time sequence lengths. Code will be available at https://github.com/shuimushan/DJIST .},
  archive      = {J_NEUCOM},
  author       = {Shanshan Wan and Lai Kang and Yingmei Wei and Tianrui Shen and Haixuan Wang and Chao Zuo},
  doi          = {10.1016/j.neucom.2025.131622},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131622},
  shortjournal = {Neurocomputing},
  title        = {DJIST: Decoupled joint image and sequence training framework for sequential visual place recognition},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ABM: Adaptive bias mitigation for class-imbalanced semi-supervised learning. <em>NEUCOM</em>, <em>658</em>, 131617. (<a href='https://doi.org/10.1016/j.neucom.2025.131617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class-imbalanced semi-supervised learning (CISSL) poses significant challenges in real-world scenarios, where limited labeled data and skewed class distributions jointly hinder model generalization, especially for minority classes. Existing CISSL methods predominantly focus on adjusting model outputs, often overlooking the crucial role of representation learning in addressing classifier bias. In this paper, we propose a feature-aware adaptive bias mitigation framework that effectively alleviates class imbalance while enhancing representation learning. Specifically, our approach leverages the batch-wise feature mean as an additional input to guide the learning process, enabling the model to calibrate its representations against an unbiased reference. We refine classifier predictions by adjusting logits based on batch-wise feature mean, and further apply post-hoc logit adjustment to correct residual response bias. This combination not only improves pseudo-label quality but also fosters balanced and robust feature learning. Extensive experiments on four benchmark datasets under various class distribution settings demonstrate that our method consistently outperforms state-of-the-art competitors, achieving superior balanced accuracy and robustness against distribution mismatches.},
  archive      = {J_NEUCOM},
  author       = {Hongzhu Yi and Yue Cheng and Weiwei Xing and Xiang Wei},
  doi          = {10.1016/j.neucom.2025.131617},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131617},
  shortjournal = {Neurocomputing},
  title        = {ABM: Adaptive bias mitigation for class-imbalanced semi-supervised learning},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RAAG:Redundancy-adaptive and attention-guided token pruning for efficient video action detection. <em>NEUCOM</em>, <em>658</em>, 131615. (<a href='https://doi.org/10.1016/j.neucom.2025.131615'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video action detection faces significant computational challenges, especially with high-resolution and long video sequences. Existing fixed-rate pruning methods are often suboptimal, risking crucial information loss or retaining excessive redundancy. This paper introduces Redundancy-Adaptive and Attention-Guided Token Pruning (RAAG), a novel, adaptive framework for efficient end-to-end video action detection. RAAG integrates Information Redundancy-Adaptive Token Pruning (IRTP), which dynamically adjusts token keep rate based on inter-frame information redundancy, and a Hierarchical Attention-Guided (HAG) strategy, which refines pruning by allocating distinct layer-specific rates to preserve essential features in early layers and aggressively prune in actor-focused middle layers. Comprehensive experiments on AVA 2.2, JHMDB, and UCF101-24 demonstrate RAAG’s superior performance. Notably, RAAG (ViT-L) achieves 40.5 mAP on AVA 2.2, and robustly performs on JHMDB (90.7 mAP) and UCF101-24 (86.5 mAP). These results validate RAAG’s ability to intelligently balance computational efficiency with detection accuracy across diverse video contents.},
  archive      = {J_NEUCOM},
  author       = {Jun Chen and Sailong Deng and Wei Yu and Longsheng Wei},
  doi          = {10.1016/j.neucom.2025.131615},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131615},
  shortjournal = {Neurocomputing},
  title        = {RAAG:Redundancy-adaptive and attention-guided token pruning for efficient video action detection},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MPFBL: Modal pairing-based cross-fusion bootstrap learning for multimodal emotion recognition. <em>NEUCOM</em>, <em>658</em>, 131577. (<a href='https://doi.org/10.1016/j.neucom.2025.131577'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal emotion recognition (MER), a key technology in human-computer interaction, deciphers complex emotional states by integrating heterogeneous data sources such as text, audio, and video. However, previous works either retained only private information or focused solely on public information, resulting in a conflict between the strategies used in each approach. Existing methods often lose critical modality-specific attributes during feature extraction or struggle to align semantically divergent representations across modalities during fusion, resulting in incomplete emotional context modeling. To address these challenges, we propose the Modal Pairing-based Cross-Fusion Bootstrap Learning (MPFBL) framework, which integrates modal feature extraction, cross-modal bootstrap learning, and multi-modal cross-fusion into a unified approach. Firstly, the feature extraction module employs a Uni-Modal Transformer (UMT) and a Multi-Modal Transformer (MMT) to jointly capture modality-specific and modality-invariant information, addressing feature degradation in single-encoder paradigms, while alleviating inter-modal heterogeneity by explicitly distinguishing between modality-specific and shared representations. Subsequently, cross-modal bootstrap learning employs attention-guided optimization to align heterogeneous modalities and refine modality-specific representations, enhancing semantic consistency. Finally, a multi-modal cross-fusion network integrates convolutional mapping and adaptive attention to dynamically weight cross-modal dependencies, mitigating spatial-semantic misalignment induced by inter-modal heterogeneity in fusion processes. Extensive experimental results on CMU-MOSEI and CMU-MOSI demonstrate that MPFBL outperforms state-of-the-art methods, while ablation studies further confirm its effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Yong Zhang and Yongqing Liu and HongKai Li and Cheng Cheng and Ziyu Jia},
  doi          = {10.1016/j.neucom.2025.131577},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131577},
  shortjournal = {Neurocomputing},
  title        = {MPFBL: Modal pairing-based cross-fusion bootstrap learning for multimodal emotion recognition},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Auto-weighted graph tensor and rank-constrained bipartite graph fusion for multi-view clustering. <em>NEUCOM</em>, <em>658</em>, 131575. (<a href='https://doi.org/10.1016/j.neucom.2025.131575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor multi-view clustering generally outperforms non-tensor counterparts, as the tensor structure can effectively capture the higher-order correlations of data. Although the t-SVD-based tensor nuclear norm has shown remarkable performance, it treats the similar information across all views equally, overlooking the higher-order similarities between similar graphs. To address this issue, we propose a Pearson Correlation Coefficient-based A uto-weighted G raph T ensor and R ank-constrained B ipartite G raph F usion (AGTRBGF) approach for multi-view clustering. Specifically, the P-AGT learning method breaks free from the constraints of predefined weights, automatically assigning optimal weight values for each similarity graph by leveraging the higher-order similarities among the similar graphs of different views. Additionally, the Laplace rank is utilized to constrain the adaptive graph fusion, endowing learned consensus graph with strong diagonal structure and enhancing the model’s robustness. Experiments conducted on distinct datasets validate the effectiveness and superior clustering performance of AGTRBGF.},
  archive      = {J_NEUCOM},
  author       = {Jie Zhang and Xiaoqian Zhang and Jinghao Li and Yongyi Yang and Zhenwen Ren and Rong Tang and Dong Wang},
  doi          = {10.1016/j.neucom.2025.131575},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131575},
  shortjournal = {Neurocomputing},
  title        = {Auto-weighted graph tensor and rank-constrained bipartite graph fusion for multi-view clustering},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Encryption-decryption-based distributed state estimation against eavesdropping attacks over sensor networks with communication protocol. <em>NEUCOM</em>, <em>658</em>, 131570. (<a href='https://doi.org/10.1016/j.neucom.2025.131570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The secure distributed state estimation problem is investigated for a class of discrete time-varying systems over sensor networks regulated by encryption–decryption mechanism and round-robin protocol. To save energy and alleviate network congestion, the round-robin protocol is introduced to schedule the transmission order of the measurement data. To mitigate privacy leakage, an encryptor is designed to encrypt the measurement information of each sensor node, and then the encrypted measurements can be decrypted by the user. The primary objective of this paper is to present a distributed state estimation algorithm with recursive format for such time-varying systems, in which an upper bound on the estimation error covariance is derived, and appropriate estimator gains are determined to minimize this upper bound. In addition, a sufficient condition is provided to ensure that the estimation error of the user is exponentially bounded in the mean-square sense. Particularly, the properly designed encryption–decryption parameters guarantee that the state estimation error of the eavesdropper is unbounded. Finally, two simulation experiments are conducted to demonstrate the feasibility of the developed encryption–decryption-based distributed state estimation algorithm.},
  archive      = {J_NEUCOM},
  author       = {Xiaolong Yang and Wen Chen and Hongxu Zhang and Jiawen Zhang and Yuxin Guo},
  doi          = {10.1016/j.neucom.2025.131570},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131570},
  shortjournal = {Neurocomputing},
  title        = {Encryption-decryption-based distributed state estimation against eavesdropping attacks over sensor networks with communication protocol},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSF-GODE: Multi-scale frequency-domain learning in graph neural ODEs for accurate traffic flow forecasting. <em>NEUCOM</em>, <em>658</em>, 131566. (<a href='https://doi.org/10.1016/j.neucom.2025.131566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-quality traffic forecasting plays a critical role in intelligent transportation systems (ITS) and the development of smart cities. However, the pervasive spatiotemporal heterogeneity in traffic data poses significant challenges for existing models in reliably capturing complex and evolving traffic dynamics. In addition, the frequent neglect of features from non-hotspot regions and the absence of effective cross-channel feature fusion mechanisms further hinder both predictive accuracy and generalization capabilities. To address these challenges, we propose a novel framework named Multi-Scale Spatiotemporal Frequency-aware Graph Ordinary Differential Equation network (MSF-GODE), which offers a unified and systematic modeling strategy to tackle the above limitations. Specifically, the model first utilizes a multi-scale frequency sample generator that leverages time–frequency decomposition to extract periodic structures and capture temporal dependencies across multiple resolutions. It then incorporates a spatiotemporal feature extractor that combines key feature selection and contrastive learning, thereby enhancing the model’s ability to represent non-key regions. Finally, a spatiotemporal frequency-domain feature fusion module is employed to model structural evolution and integrate multi-channel features more effectively. Extensive experiments conducted on six real-world traffic datasets demonstrate that MSF-GODE significantly outperforms existing state-of-the-art methods in terms of both prediction accuracy and generalization, offering a robust and effective solution for traffic forecasting in heterogeneous environments.},
  archive      = {J_NEUCOM},
  author       = {Peng Liu and Yaodong Zhu and Yang Yang and Jilong Tang and Xiaojiao Jiang and Jinquan Wang},
  doi          = {10.1016/j.neucom.2025.131566},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131566},
  shortjournal = {Neurocomputing},
  title        = {MSF-GODE: Multi-scale frequency-domain learning in graph neural ODEs for accurate traffic flow forecasting},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fused adaptive tensor log-determinant and local smoothness regularizer for multi-view clustering. <em>NEUCOM</em>, <em>658</em>, 131564. (<a href='https://doi.org/10.1016/j.neucom.2025.131564'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevailing techniques for multi-view subspace clustering (MVC) methods often depend on the assumption of low-rankness, which asserts that data can be effectively represented in a low-dimensional subspace. While these approaches capture the structure of the data globally and remove noise and redundancy, they all neglect local smoothness prior, which has been extensively used to reduce noise in the image field. Besides, existing techniques often depend on the tensor nuclear norm (TNN)to approximate the intrinsically non-convex tensor rank function. However, the TNN approach equates all singular values, which gives rise to excessive penalization of the principal rank components and ultimately leads to sub-optimal tensor representations. In response to these challenges, we introduce an innovative method called fused adaptive tensor Log-determinant and local smoothness regularizer (FATLLSR) for multi-view clustering. Specifically, we initially derive the self-expressive matrix for each view and subsequently integrate these matrices into a tensor. Then in order to simultaneously explore low-rankness and local smoothness prior, FATLLSR is designed and is used to constrain the obtained tensor. By using FATLLSR, we can not only relax tensor multi-rank constraint better than TNN but also utilize the local smoothness information hidden in multi-view data, making our method more robust to noise and redundancy. These techniques are integrated to constitute a unified model that is effectively handled using the augmented Lagrange multiplier (ALM). As demonstrated by its performance on different datasets, FATLLSR achieves outstanding clustering performance compared to the most advanced methods. The code is publicly available at https://github.com/wangfii/FATLLSR .},
  archive      = {J_NEUCOM},
  author       = {Fei Wang and Gui-Fu Lu},
  doi          = {10.1016/j.neucom.2025.131564},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131564},
  shortjournal = {Neurocomputing},
  title        = {Fused adaptive tensor log-determinant and local smoothness regularizer for multi-view clustering},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised multi-blind network for real image denoising via multivariate gaussian-poisson noise. <em>NEUCOM</em>, <em>658</em>, 131557. (<a href='https://doi.org/10.1016/j.neucom.2025.131557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The noise in real images exhibits more complex distributions than the synthetic noise and distinguishes across different scenarios. Furthermore, the scarcity of "clean-to-noisy" paired image datasets makes the current models difficult to denoise successfully. To address these challenges, we propose MGP-MBF M 2 ANet, a self-supervised multi-blind feature multi-modulation attention network based on multivariate Gaussian-Poisson noise prior for real image denoising. Firstly, we propose a multivariate Gaussian-Poisson distribution to construct noisy images that contain more complex pixel spatial positions and intensity correlations, which expand the training domain and improve the model’s ability to generalize across diverse real noisy images. Building on this, we implement a random sampling mechanism based on four-neighborhood similarity to construct "noise-noise" training pairs, effectively exploiting the statistical properties of local structures in noisy images, without relying on any clean reference image. During the network design phase, a multi-blind feature multi-modulation attention module successfully enhances the representation of local features, which introduces multi-masked strategy to force network to learn more information to address the challenge of feature identity mapping. Experimental results demonstrate that the proposed method effectively suppresses noise and recovers high-frequency details within an unsupervised learning paradigm, achieving superior performance in both objective evaluation metrics and subjective visual quality across multiple real-world datasets.},
  archive      = {J_NEUCOM},
  author       = {Hang Zhao and Zitong Wang and Xiaoli Zhang and Zhaojun Liu},
  doi          = {10.1016/j.neucom.2025.131557},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131557},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised multi-blind network for real image denoising via multivariate gaussian-poisson noise},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interactive attention and contrastive learning for few-shot relation extraction. <em>NEUCOM</em>, <em>658</em>, 131551. (<a href='https://doi.org/10.1016/j.neucom.2025.131551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction is a critical task in natural language processing, often challenged by the problem of insufficient samples in real world scenarios. Therefore, studying few-shot relation extraction is of great significance. Currently, prototype networks and meta-learning-based parameter optimization are the mainstream methods to study this kind of problem. However, these methods still face sample confusion during classification, and the trained models are prone to overfitting. To solve these problems, this paper proposes a few-shot relation extraction method based on interactive attention. During the model training stage, we introduce two contrastive learning approaches to better capture sample features and reduce sample confusion. Contrastive learning strengthens the connections between instances and their corresponding relationship descriptions, thus improving relation extraction. In the testing phase, the model employs an attention mechanism to calculate the attention scores between the query set and the support set and employs a new classification layer to mitigate overfitting. We conducted experiments on two real-world few-shot relation extraction datasets, and the results demonstrate that our method achieved superior performance on both in-domain and cross-domain datasets, proving the effectiveness of the proposed approach. The code is available at https://github.com/xyzew/IACL.git .},
  archive      = {J_NEUCOM},
  author       = {Yan Li and Yao Wang and Zhaojie Wang and Wei Wang and Bailing Wang and Guodong Xin},
  doi          = {10.1016/j.neucom.2025.131551},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131551},
  shortjournal = {Neurocomputing},
  title        = {Interactive attention and contrastive learning for few-shot relation extraction},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAGNet: A multimodal knowledge-augmented graph network for early-stage misinformation detection. <em>NEUCOM</em>, <em>658</em>, 131533. (<a href='https://doi.org/10.1016/j.neucom.2025.131533'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid proliferation of multimodal misinformation on social media, detecting such content has become increasingly challenging. Existing approaches often rely on flat or shallow fusion strategies, which fail to capture structured semantic interactions across modalities. Moreover, most methods lack controllable, task-relevant mechanisms for integrating external knowledge, limiting their adaptability to emerging misinformation. In this paper, we present MAGNet, a Multimodal Augmented Graph Network that models fine-grained features with LLM-enhanced contextual knowledge through a hierarchical graph attention framework. MAGNet constructs heterogeneous graphs with modality- and context-specific edge weights based on semantic and affective alignment, enabling progressive reasoning from local features to global representations. Extensive experiments on three real-world datasets demonstrate that MAGNet consistently outperforms strong baselines across multiple evaluation metrics. The results underscore the effectiveness of combining graph-based modeling, fine-grained fusion, and structured knowledge integration in developing scalable and robust solutions for multimodal misinformation detection.},
  archive      = {J_NEUCOM},
  author       = {Wang Jinghong and Yang Hongbo and Wang Xizhao and Wang Wei and Li Yanan},
  doi          = {10.1016/j.neucom.2025.131533},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131533},
  shortjournal = {Neurocomputing},
  title        = {MAGNet: A multimodal knowledge-augmented graph network for early-stage misinformation detection},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive reverse perturbation network for audio deepfake detection. <em>NEUCOM</em>, <em>658</em>, 131466. (<a href='https://doi.org/10.1016/j.neucom.2025.131466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing prevalence of audio deepfakes underscores the urgent need for advanced detection frameworks capable of identifying subtle synthetic artifacts. In response to this challenge, we propose an Adaptive Reverse Perturbation Network, a novel architecture that leverages partial reversal strategies on speech segments and incorporates hierarchical feature discrepancy analysis to enhance deepfake detection. Specifically, the proposed framework employs learnable reversal modules to capture phase discontinuities and spectral anomalies, and utilizes Prime-window reversal to reveal synthetic artifacts that emerge exclusively in reversed speech. Evaluations conducted on five benchmark datasets demonstrate the superior performance of the proposed method, achieving an equal error rate of 1.98 %, representing a 39.6 % improvement over previous systems, as well as a t-DCF of 0.237. Further analysis reveals an inverse correlation between language-specific weight similarity and detection accuracy. These results validate the effectiveness of the trainable differential convolution and reverse perturbation strategies in combating the evolving threat of audio deepfakes, and provide novel insights into phonological artifact patterns associated with synthetic speech.},
  archive      = {J_NEUCOM},
  author       = {Xue Ouyang and Chunhui Wang and Bin Zhao and Hao Li},
  doi          = {10.1016/j.neucom.2025.131466},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131466},
  shortjournal = {Neurocomputing},
  title        = {Adaptive reverse perturbation network for audio deepfake detection},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RDNet: Region specific iterative deformation with multi-scale attention for medical image registration. <em>NEUCOM</em>, <em>658</em>, 131455. (<a href='https://doi.org/10.1016/j.neucom.2025.131455'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deformable medical image registration is essential for various clinical applications, including diagnosis, treatment planning, and disease monitoring. Although significant progress has been made with pyramid architecture, they often struggle to effectively capture the complex variations in deformation fields at feature maps with different resolutions. However, conventional skip connection designs inadequately address the asymmetric roles of moving and fixed images in deformation estimation, as they treat both images symmetrically without accounting for their distinct contributions to the alignment process. To address these challenges, we present RDNet, a learning-based dual-stream pyramid-based framework incorporating two key components: the Mapping Block (MB) and the Region Specific Layer (RSL). The MB module is carefully integrated into the fixed image skip connections to improve hierarchical feature alignment between the encoder and decoder. The high-level hierarchical semantic gap is efficiently minimized by MB through spatial and channel-wise attention methods, improving feature correspondence and registration accuracy. Additionally, to address the challenges caused by complex variations in the pyramid architecture, we present the RSL module in a multi-scale framework. This incorporation improves the capture of long-range dependencies specific to a region, resulting in more precise deformation estimation and improved registration accuracy while minimizing deformation loss. We conducted comprehensive experiments on two publicly available Brain MRI datasets, OASIS and LPBA40, and one Lung CT dataset to demonstrate that our proposed framework achieves state-of-the-art registration results.},
  archive      = {J_NEUCOM},
  author       = {Wenming Cao and Naeem Hussain and Zhiyue Yan},
  doi          = {10.1016/j.neucom.2025.131455},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131455},
  shortjournal = {Neurocomputing},
  title        = {RDNet: Region specific iterative deformation with multi-scale attention for medical image registration},
  volume       = {658},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale trend decomposition mixture of experts and time series retrieval-augmented modeling for erythromycin fermentation process. <em>NEUCOM</em>, <em>657</em>, 131701. (<a href='https://doi.org/10.1016/j.neucom.2025.131701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series (MTS) is the primary modality for storing data in real-world and industrial applications. In the context of batch fermentation processes, such data exhibit periodicity and repetition between samples, while demonstrating stage-wise and trending patterns within samples. Effectively leveraging historical production samples to uncover stage-specific characteristics and dynamic distribution patterns is a crucial approach for improving predictive accuracy. This paper proposes an MTS modeling framework that combines Retrieval-Augmented Generation (RAG) and a Mixture of Experts (MoE) model, i.e., M ulti-scale A ugmented S eries T rend E xperts with R etrieval, referred to as MASTER. We designed a general temporal feature augmentation method (MTS-RAG) to enhance predictive accuracy by efficiently completing contextual information during the data loading stage using representative historical samples. Additionally, we developed a multi-scale trend decomposition model based on the Kolmogorov-Arnold Network, which enhances both interpretability and predictive performance by independently modeling trend and seasonal components. Inspired by the success of sparse MoE in large language models, we introduce a Time Stage Router that employs temporal position embeddings and sparse gating structures to assist the model in identifying the current fermentation phase, thereby improving its generalization and practicality in multi-stage tasks. On an industrial dataset of erythromycin fermentation processes, MASTER achieved state-of-the-art predictive performance, and ablation studies further validated the effectiveness of its components.},
  archive      = {J_NEUCOM},
  author       = {Yifei Sun and Xuefeng Yan},
  doi          = {10.1016/j.neucom.2025.131701},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131701},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale trend decomposition mixture of experts and time series retrieval-augmented modeling for erythromycin fermentation process},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classroom activity recognition using hybrid 3D-CNNs and visualization of action features with grad-CAM. <em>NEUCOM</em>, <em>657</em>, 131694. (<a href='https://doi.org/10.1016/j.neucom.2025.131694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of advanced computer vision technology, it is possible to use automatic methods to detect and classify student and teacher activities in classroom environments, providing novel approaches to study or evaluate the quality of teaching or learning. However, to date, there has been little research developing and testing these methods to work towards an optimal activity recognition system. This paper proposes an automated framework using a 3D-convolutional neural network (CNN) to recognize classroom activities, including teacher and student behaviors, from classroom videos. The 3D-CNN captured spatiotemporal features from the video data. Then, an extreme learning machine (ELM) classifier was trained over the 3D-CNN features to recognize different activities in the classroom. Multi-layer perceptron (MLP) and support vector machine (SVM) classifiers were also examined in comparison to ELM. Gradient-weighted class activation mapping (Grad-CAM) was employed to provide visual explanations of what information the highest performing model learned from videos to classify classroom activities. To evaluate each model, classifications were carried out on the EduNet dataset, containing annotated classroom activities featuring students and teachers. Classroom videos from the internet were also utilized to further evaluate the performance of the proposed frameworks. The proposed 3D-CNN+ELM model achieved a maximum average recognition accuracy of 88.17 % on EduNet, as estimated by 5-fold cross-validation, which is 5.87 % higher than the standard baseline I3D-ResNet-50 model proposed by the EduNet authors. The model also achieved an accuracy of 80.00 % when applied to an independent dataset of videos sourced from the internet, indicating reasonable reliability and generalizability. The Grad-CAM outcomes indicate that the model focuses on valid features to determine its recognition; however, in some cases, the recognition can still be incorrect. With its high level of performance, the proposed automated framework may assist in providing information on a range of classroom actions, which may offer preliminary insights to support the evaluation of classroom teaching and learning in real-world educational environments.},
  archive      = {J_NEUCOM},
  author       = {Rajamanickam Yuvaraj and Jack S Fogarty and Ratnavel Rajalakshmi and Ritika Sarkar},
  doi          = {10.1016/j.neucom.2025.131694},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131694},
  shortjournal = {Neurocomputing},
  title        = {Classroom activity recognition using hybrid 3D-CNNs and visualization of action features with grad-CAM},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal 3D multi-object tracking with robust association and track drift compensation. <em>NEUCOM</em>, <em>657</em>, 131687. (<a href='https://doi.org/10.1016/j.neucom.2025.131687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D multi-object tracking is crucial for enhancing the understanding of the environment in autonomous driving and robotics. Low-quality detections and less robust associations are two challenges in the point-aware tracking-by-detection paradigm. Conventional approaches suffer from inadequate pre-processing of detected outliers, and poor appearance-based associations during occlusion. To address these issues, this paper proposes a real-time and robust 3D multi-object tracking framework based on the fusion of camera and LiDAR data. Firstly, a two-level association strategy is introduced, whereby high-confidence tracks and detections are initially linked through a straightforward 3D IoU cost, followed by the association of remaining entities using discriminative deep appearance features, emphasizing the similarity between the recently updated track appearance and reemerging targets within dynamically constrained search boundaries. Secondly, a track drift compensation method is presented to refine the low-quality detections using their historically matched tracks, facilitating accurate updates accordingly. Experiments show that the proposed method achieved 79.36 % HOTA and 74 % AMOTA in KITTI and nuScenes benchmarks, respectively. This result surpasses many advanced solutions, particularly exhibiting robust performance in occluded environments.},
  archive      = {J_NEUCOM},
  author       = {Chen Xie and Ciyun Lin and Xiaoyu Zheng and Bowen Gong and Antonio M. López},
  doi          = {10.1016/j.neucom.2025.131687},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131687},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal 3D multi-object tracking with robust association and track drift compensation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAMGnet: A self-learning classification model for univariate continuous time series signals via dynamic fusion of multi-dimensional cross-domain features. <em>NEUCOM</em>, <em>657</em>, 131686. (<a href='https://doi.org/10.1016/j.neucom.2025.131686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improvements in classifying continuous, univariate time series signals with low value density have been hindered by insufficient feature detail, inadequate modeling of cross-domain dynamics, and inefficient parameter optimization. To address this, we propose a self-learning Cross-domain Adaptive Multi-dimensional Fusion Graph Neural Network (CAMGnet). We construct a Temporal Synergetic Pyramid (TSP) module to hierarchically extract time domain features from short-term to long-term trends. We develop an Entropy-adaptive Graph Construction (EAGC) mechanism to model cross-domain feature correlations. EAGC dynamically infers implicit feature-space/graph-topology relationships using self-adaptive adjacency matrices, minimizing reliance on prior knowledge and enabling autonomous, data-driven discovery of cross-domain interactions. Graph Convolutional Network–Graph Isomorphism Network(GCN-GIN) based hybrid encoding facilitates deep collaborative optimization between feature spaces and graph topologies. We also develop a Competitive Cross-attention (CCA) fusion mechanism to perform competitive multi-modal feature selection, enabling temporal/multi-domain graphs to capture cross-modal dependencies. Furthermore, we propose an Adaptive Perturbation Dynamic Escape Exploration–Exploitation Co-evolutionary Pool Strategy (AEP-IVYA) for improving the Ivy Optimization Algorithm.Adaptive perturbation balances exploration-exploitation by dynamically adjusting perturbation parameters. The dynamic escape strategy introduces a cross-dimensional transition mechanism to overcome local optima. The co-evolutionary pool uses a dual-path architecture to optimize global diversity and convergence. Evaluated on weld seam defect diagnosis and UCR datasets, AEP-IVYA improved hyperparameter configuration reliability. The self-optimized CAMGnet achieved 98.7 % accuracy in weld defect classification, surpassing traditional methods by 8.1 percentage points. On 25 UCR datasets, CAMGnet achieved 13 optimal and 6 suboptimal results, with a Wilcoxon-test average rank of 2.0, demonstrating significant generalization and domain applicability advantages over mainstream models.},
  archive      = {J_NEUCOM},
  author       = {Rui Zhang and Zheqi Rong and Zehua Dong},
  doi          = {10.1016/j.neucom.2025.131686},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131686},
  shortjournal = {Neurocomputing},
  title        = {CAMGnet: A self-learning classification model for univariate continuous time series signals via dynamic fusion of multi-dimensional cross-domain features},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint entropy search for multi-objective bayesian optimization with constraints and multiple fidelities. <em>NEUCOM</em>, <em>657</em>, 131674. (<a href='https://doi.org/10.1016/j.neucom.2025.131674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization (BO) methods can be used to solve efficiently problems with several objectives and constraints. Each objective and constraint is considered a black-box function that is expensive to evaluate, lacking a closed-form expression. BO methods use a model of each black-box to guide the search for the problem’s solution. Specifically, they make intelligent decisions about where each black-box function should be evaluated next with the goal of finding the solution using a few evaluations only. Sometimes, however, the black-boxes may be evaluated at different fidelity levels. A lower fidelity is simply a cheap proxy for the corresponding black-box. These lower fidelities correlate with the actual black-boxes to optimize and can, therefore, be used to reduce the overall cost of solving the optimization problem. Here, we propose Multi-fidelity Joint Entropy Search for Multi-objective Bayesian Optimization with Constraints (MF-JESMOC), a BO method for solving the aforementioned problems. MF-JESMOC chooses the next point, and fidelity level at which to evaluate the black-boxes, as the combination that is expected to reduce the most the joint entropy of the Pareto set and the Pareto front, normalized by the fidelity’s evaluation cost. We use Deep Gaussian processes to model each black-box and the dependencies between fidelities. These are powerful probabilistic models that can learn the dependency structure among fidelity levels of each black-box. Several experiments show that MF-JESMOC outperforms other state-of-the-art methods for multi-objective BO with constraints and different fidelity levels in both synthetic and real-world problems.},
  archive      = {J_NEUCOM},
  author       = {Daniel Fernández-Sánchez and Daniel Hernández-Lobato},
  doi          = {10.1016/j.neucom.2025.131674},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131674},
  shortjournal = {Neurocomputing},
  title        = {Joint entropy search for multi-objective bayesian optimization with constraints and multiple fidelities},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COTA-motion: Controllable image-to-video synthesis with dense semantic trajectories. <em>NEUCOM</em>, <em>657</em>, 131671. (<a href='https://doi.org/10.1016/j.neucom.2025.131671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion transfer, which aims to animate an object in a static image by transferring motion from a reference video, remains a fundamental yet challenging task in content creation. While recent diffusion-based image-to-video models offer fine-grained control over visual appearance, most existing methods rely on ambiguous text prompts or coarse drag-based motion cues, making it difficult to achieve accurate and consistent motion synthesis. To address these limitations, we propose COTA-Motion, a general framework for controllable image-to-video motion transfer. Our method leverages a dense trajectory-based semantic representation extracted from the driving video to provide explicit motion guidance. Specifically, we segment the salient object and extract its point-wise trajectories across frames. These trajectories are enriched with semantic embeddings and reprojected into a spatial-temporal tensor, forming the motion embedding. To utilize this motion representation, we introduce the COTA Adapter, which integrates image content with semantic trajectories via cross-attention, enabling accurate and flexible control over the generated motion. At inference, we further incorporate an alignment module to address discrepancies between the input image and motion cues, ensuring spatial consistency. Built upon a pre-trained video diffusion model, COTA-Motion only requires lightweight fine-tuning on a small set of videos, and it enables high-quality, controllable motion transfer from video to image. Extensive experiments demonstrate the effectiveness of our approach in generating visually coherent and motion-aligned video outputs.},
  archive      = {J_NEUCOM},
  author       = {Yirui Chen and Wenqing Chu and Ye Wu and Jie Yang and Xiaonan Mao and Wei Liu},
  doi          = {10.1016/j.neucom.2025.131671},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131671},
  shortjournal = {Neurocomputing},
  title        = {COTA-motion: Controllable image-to-video synthesis with dense semantic trajectories},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance-barrier-based event-triggered leader–follower consensus control for nonlinear multi-agent systems. <em>NEUCOM</em>, <em>657</em>, 131664. (<a href='https://doi.org/10.1016/j.neucom.2025.131664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the leader–follower consensus issue for a class of nonlinear multi-agent systems (MASs) by putting forth a novel performance-barrier-based event-triggered control mechanism. First, a leader–follower consensus control law is proposed with a derived stability condition for the MASs, and a performance-barrier-based event-triggering mechanism is integrated to reduce control updates while guaranteeing the desired convergence of the Lyapunov function. Subsequently, the presence of the minimum inter-event time (MIET) is analytically established, reinforcing the practical feasibility of the proposed approach in real-world scenarios. In addition, a dynamic average consensus algorithm is incorporated to extend the strategy to distributed MASs. Finally, simulation results verify that the developed control protocol effectively achieves the prescribed convergence performance with strong robustness.},
  archive      = {J_NEUCOM},
  author       = {Song Gao and Jin-Liang Wang and Shun-Yan Ren and Bei Peng},
  doi          = {10.1016/j.neucom.2025.131664},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131664},
  shortjournal = {Neurocomputing},
  title        = {Performance-barrier-based event-triggered leader–follower consensus control for nonlinear multi-agent systems},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Both reliable and unreliable predictions matter: Domain adaptation for bearing fault diagnosis without source data. <em>NEUCOM</em>, <em>657</em>, 131661. (<a href='https://doi.org/10.1016/j.neucom.2025.131661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearing fault diagnosis is crucial for maintaining the reliability and safety of industrial systems. Recently, it has attracted increasing attention to transferring a diagnosis model from the source domain to the target domain without source data in real-world diagnosis scenarios due to confidentiality and efficiency concerns. However, existing approaches are sub-optimal as they simply exploit confidently pseudo-labeled target samples, and simultaneously overlook the intrinsic structural characteristics of the feature space. Besides, the reliability of fault pseudo-labels is always estimated with entropy, whose accuracy could be improved through more sophisticated strategies. To address these issues, we propose to explore the correlation between features and pseudo-labels in the target domain to maintain the balance between feature discriminability and feature diversity. In addition, we develop a voting-based strategy associated with data augmentation for more accurate reliability estimation of fault pseudo-labels. The proposed method is able to utilize both the reliable samples and unreliable samples for diagnosis model transfer via self-supervised training and distribution structure discovering respectively. Extensive experiments on two bearing fault benchmarks demonstrate the effectiveness and superiority of our proposed method. The source code is publicly available at: https://github.com/BdLab405/SDALR .},
  archive      = {J_NEUCOM},
  author       = {Wenyi Wu and Hao Zhang and Zhisen Wei and Xiao-Yuan Jing and Qinghua Zhang and Songsong Wu},
  doi          = {10.1016/j.neucom.2025.131661},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131661},
  shortjournal = {Neurocomputing},
  title        = {Both reliable and unreliable predictions matter: Domain adaptation for bearing fault diagnosis without source data},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neuromorphic binocular framework fusing directional and depth motion cues towards precise collision prediction. <em>NEUCOM</em>, <em>657</em>, 131660. (<a href='https://doi.org/10.1016/j.neucom.2025.131660'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological studies have significantly advanced our understanding of collision detection, driving improvements in visual systems for safer navigation of mobile intelligent machines. Directionally selective neurons (DSNs), extensively studied in insects like locusts and flies, have inspired computational models that effectively detect specific directional motion cues with low computational demands, making them suitable for real-time applications. Despite these advancements, there remains a gap between biological systems and current computational models. Typically, monocular computational approaches project the three-dimensional world onto two-dimensional representations, resulting in the loss of critical depth information essential for accurately detecting looming objects, i.e., those directly approaching the observer. Consequently, such methods often suffer interference from background motion distractors and nearby translating objects. To address these limitations, we developed a binocular visual framework integrating neuromorphic components, including directionally selective neural networks and depth-disparity computing pathway. This binocular approach enhances looming detection accuracy and improves collision prediction capabilities. Additionally, evolutionary learning techniques were employed to optimize network structures and parameters, prioritizing robustness across diverse real-world scenarios. The resulting binocular model selectively responds to imminent collision trajectories while effectively suppressing peripheral distractors such as near-miss and passing movements. We conducted comprehensive evaluations comparing our proposed framework against a latest binocular neural model across various complex scenarios. Systematic ablation studies further validated the effectiveness and robustness of our approach. The results confirm its potential for deployment in mobile robots and autonomous vehicles, assisting their collision avoidance in real-world applications.},
  archive      = {J_NEUCOM},
  author       = {Chuankai Fang and Haoting Zhou and Renyuan Liu and Qinbing Fu},
  doi          = {10.1016/j.neucom.2025.131660},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131660},
  shortjournal = {Neurocomputing},
  title        = {A neuromorphic binocular framework fusing directional and depth motion cues towards precise collision prediction},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traffic prediction based on spatio-temporal feature embedding fusion and gate operation optimization. <em>NEUCOM</em>, <em>657</em>, 131658. (<a href='https://doi.org/10.1016/j.neucom.2025.131658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world traffic prediction problems, there are often complex spatio-temporal features and patterns. To enhance the accuracy and performance of traffic prediction and address these complexities, it is essential to employ effective models and methods to capture spatio-temporal features and patterns of change. For this purpose, we propose a network model that integrates spatio-temporal feature embeddings with gate operation optimization(TSGO). In our model, we design a novel module: the spatio-temporal feature embedding fusion module, which combines input data to strengthen the model’s ability to extract spatio-temporal correlation features, particularly in enhancing temporal features. To further bolster the capture of spatial features, we design an adaptive graph structure learning method based on a node repository, dynamically capturing non-Euclidean spatial correlations within the traffic network. Additionally, to better capture long-term dependence and short-term variations in sequential data, we adopt a new strategy in the Gated Recurrent Unit (GRU): treating the even and odd positions in the input sequence as two separate input streams to generate corresponding update gates and reset gates. This approach enables the model to utilize data more evenly, achieving complementarity between the two sets of features and allowing it to adapt to information at different time scales within the sequential data. In short-term, medium-term, and long-term predictions across three real-world traffic datasets, the TSGO model achieved average MAE reductions of 8.76 %, 10.12 %, and 11.86 %, respectively, compared to the baseline. This demonstrates its capability to generalize across different time scales and significantly improve prediction performance.},
  archive      = {J_NEUCOM},
  author       = {Xiaotong Geng and Fan Zhang and Mingli Zhang and Hua Wang},
  doi          = {10.1016/j.neucom.2025.131658},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131658},
  shortjournal = {Neurocomputing},
  title        = {Traffic prediction based on spatio-temporal feature embedding fusion and gate operation optimization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional plane-based multi-scene representation for novel view synthesis. <em>NEUCOM</em>, <em>657</em>, 131657. (<a href='https://doi.org/10.1016/j.neucom.2025.131657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing explicit and implicit-explicit hybrid neural representations for novel view synthesis are scene-specific. In other words, they represent only a single scene and require retraining for every novel scene. Implicit scene-agnostic methods rely on large multilayer perception (MLP) networks conditioned on learned features. They are computationally expensive during training and rendering times. In contrast, we propose a novel plane-based representation that learns to represent multiple static and dynamic scenes during training and renders per-scene novel views during inference. The method consists of a deformation network, explicit feature planes, and a conditional decoder. Explicit feature planes are used to represent a time-stamped view space volume and a shared canonical volume across multiple scenes. The deformation network learns the deformations across shared canonical object space and time-stamped view space. The conditional decoder estimates the color and density of each scene constrained by a scene-specific latent code. We evaluated and compared the performance of the proposed representation on static (NeRF) and dynamic (Plenoptic videos) datasets. The results show that explicit planes combined with tiny MLPs can efficiently train multiple scenes simultaneously. The project page: https://anonpubcv.github.io/cplanes/ .},
  archive      = {J_NEUCOM},
  author       = {Uchitha Rajapaksha and Hamid Laga and Dean Diepeveen and Mohammed Bennamoun and Ferdous Sohel},
  doi          = {10.1016/j.neucom.2025.131657},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131657},
  shortjournal = {Neurocomputing},
  title        = {Conditional plane-based multi-scene representation for novel view synthesis},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of neural signal decoding based on domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131653. (<a href='https://doi.org/10.1016/j.neucom.2025.131653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important objective in brain-computer interfaces (BCIs) is to develop robust and reliable neural signal decoders. However, the decoders will encounter challenges under cross-subject or cross-session conditions due to the randomness, non-stationarity, and individual variability of brain electrical activity. Reducing distributional differences is an exceptionally intuitive way to eliminate inter-subject/session differences and enhance decoder generalizability. In this context, domain adaptation (DA) emerges as a valuable technique, enabling the rapid transfer of knowledge acquired from large datasets with labeled data to new subjects or sessions. This paper provides a comprehensive survey of DA research in neural decoding from 2014 to the present. We categorize neural decoding methods related to DA by considering instance-based, feature-based, and model-based, which is motivated by three fundamental challenges in DA: How can one effectively select suitable source domains or samples for transfer? How can inter-domain distributional differences be minimized through feature space transformation? And how can decoder parameters be optimally shared? Additionally, several decoding methods that combine deep learning with DA are highlighted, given the significant advantages of deep learning over traditional feature extraction techniques. Furthermore, our paper explores the application of DA in complex scenarios, such as multiple source domains and low-resource settings. In summary, we have reviewed domain-adaptive decoding algorithms and their application considerations, while identifying various challenges that need to be addressed in future research.},
  archive      = {J_NEUCOM},
  author       = {Suchen Li and Zhuo Tang and Mengmeng Li and Lifang Yang and Zhigang Shang},
  doi          = {10.1016/j.neucom.2025.131653},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131653},
  shortjournal = {Neurocomputing},
  title        = {A survey of neural signal decoding based on domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An 80/20 cortical balance stabilizes information-rich dynamics. <em>NEUCOM</em>, <em>657</em>, 131651. (<a href='https://doi.org/10.1016/j.neucom.2025.131651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cortex maintains a remarkably consistent 4:1 ratio between excitatory and inhibitory neurons, yet the computational advantages of such an architecture remain poorly understood. Here, we demonstrate that this ratio optimally stabilizes a dynamical regime characterized by intermittent, burst-like activity, a state associated with maximal information capacity. Using a balanced spiking network model, we show that near the 80:20 ratio, this intermittent regime emerges robustly across a wide range of parameters and with low energy cost. These findings suggest that the canonical cortical E/I ratio is not arbitrary, but that it is functionally tuned to support efficient and flexible computation. Our results provide a dynamical explanation for a long-standing anatomical observation, bridging structural organization and information processing in neural circuits.},
  archive      = {J_NEUCOM},
  author       = {Mozhgan Khanjanianpak and Maryam Pakpour and Matjaž Perc and Alireza Valizadeh},
  doi          = {10.1016/j.neucom.2025.131651},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131651},
  shortjournal = {Neurocomputing},
  title        = {An 80/20 cortical balance stabilizes information-rich dynamics},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on generalization of random weight network with flat loss. <em>NEUCOM</em>, <em>657</em>, 131650. (<a href='https://doi.org/10.1016/j.neucom.2025.131650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the scheme of learning which adjusts model parameters by minimizing a loss function, there is a conjecture that the loss function with flatter minimum may correlate with better stability and generalization of the model. This paper provides experimental evidence within the Random Weight Network (RWN)/Extreme Learning Machine (ELM) framework and further develops a theoretical analysis linking flatness to the local generalization error upper bound by deriving the RWN loss as a quadratic polynomial with respect to random weights and representing the flatness as the maximum eigenvalue of a semi-positive definite matrix. By adjusting the random weights using a genetic algorithm, where the fitness function is defined as the flatness, we validate on 10 benchmark datasets within the ELM framework that flatter loss indeed improves the model’s generalization ability. The improvement size depends on the specific characteristics of datasets, particularly, on the relative decrease of maximum eigenvalues. This study shows that RWN generalization performance can be improved by optimizing random weight selection.},
  archive      = {J_NEUCOM},
  author       = {Chao Liu and Qiang Liu and Rihao Li and Xinlei Zhou and Mustafa Servet Kiran and Xizhao Wang},
  doi          = {10.1016/j.neucom.2025.131650},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131650},
  shortjournal = {Neurocomputing},
  title        = {A study on generalization of random weight network with flat loss},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wavelet-integrated deep neural networks: A systematic review of applications and synergistic architectures. <em>NEUCOM</em>, <em>657</em>, 131648. (<a href='https://doi.org/10.1016/j.neucom.2025.131648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wavelet transforms, known for their exceptional capabilities in multi-resolution analysis, have garnered significant attention in the integration with deep neural networks to address key challenges in complex pattern analysis and recognition tasks. This review examines how the integration of wavelet transforms with emerging deep learning techniques has accelerated progress across various domains, such as image and video processing, graph and spatial-temporal data analysis. By integrating wavelets into traditional deep learning models, such as convolutional neural networks (CNNs), and emerging architectures like transformers and diffusion models, we show how these hybrid methods improve multi-scale feature representation, efficiency, and interpretability, while mitigating common deep learning limitations such as high computational costs and reduced robustness in multi-resolution analysis. We systematically address the synergy between wavelet transforms and deep learning, a topic underexplored in previous literature, and highlight the diverse strategies of wavelet integration—ranging from foundational methods to advanced neural network architectures—and conduct a comparative analysis of their performance in real-world applications. We also identify critical gaps and present directions for future research, particularly in the areas of adaptive, data-driven wavelet frameworks and their potential in generative modeling and domain adaptation.},
  archive      = {J_NEUCOM},
  author       = {Jiangtao Wu and Jiaqi Li and Jie Yang and Shuli Mei},
  doi          = {10.1016/j.neucom.2025.131648},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131648},
  shortjournal = {Neurocomputing},
  title        = {Wavelet-integrated deep neural networks: A systematic review of applications and synergistic architectures},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view least squares support vector classifiers with the principles of complementarity and consensus. <em>NEUCOM</em>, <em>657</em>, 131647. (<a href='https://doi.org/10.1016/j.neucom.2025.131647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we examine the multi-view learning framework, which adheres to the principles of complementarity and consensus. Despite significant advances in various support vector machine (SVM)-based multi-view learning methods, many focus exclusively on one of these principles. To bridge this gap, we first introduce the multi-view least squares support vector classifier (MvLSSVC-2C), which effectively minimizes the squares of the differences in decision functions across diverse views while also integrating information from multiple views through a coupling term. Furthermore, we propose a structural information-based model, termed SMvLSSVC-2C, which leverages hierarchical agglomerative clustering to enhance information exchange among views, thereby promoting complementarity and consensus. Meanwhile, by incorporating a weight allocation strategy, adaptive learning is conducted, and the importance of each view is adjusted to adhere to the principle of complementarity. We adopt the alternating optimization method to solve it. The two proposed methods exhibit superior performance, which is demonstrated by theoretical and numerical analysis. Our experimental results demonstrate the effectiveness of the proposed models on diverse datasets, highlighting their enhanced performance in multi-view learning tasks.},
  archive      = {J_NEUCOM},
  author       = {Siyuan Zhang and Qianfei Liu and Mengyang Fan and Weisong Mu and Jianying Feng},
  doi          = {10.1016/j.neucom.2025.131647},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131647},
  shortjournal = {Neurocomputing},
  title        = {Multi-view least squares support vector classifiers with the principles of complementarity and consensus},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KING: An efficient optimization approach. <em>NEUCOM</em>, <em>657</em>, 131645. (<a href='https://doi.org/10.1016/j.neucom.2025.131645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world engineering optimization problems are often highly challenging due to narrow feasible regions, numerous local optima, and intricate constraints. Metaheuristic algorithms (MAs) have shown promise in addressing these issues owing to their global search capability, flexibility, and adaptability. However, a critical challenge with MAs is effectively balancing the global search (exploration) and local search (exploitation) phases, which significantly influences the efficiency and precision of convergence. Many MAs require problem-specific adjustments to control convergence behavior, thereby increasing computational cost and implementation effort. Moreover, existing improvements are often tailored to specific problems, lacking comprehensive validation in terms of generality, robustness, and scalability. To overcome these limitations, this paper proposes a novel high-performance optimization algorithm with enhanced adaptability, named the Three Kingdoms Optimization Algorithm (KING), inspired by historical dynamics of the Three Kingdoms period in China. We establish an analogy between key components of MAs—such as population initialization, exploration, and exploitation—and four historical phases: the ascent of the might, joint confrontation, three-legged tripod, and whole country united. KING incorporates a new reinforcement convergence mechanism to systematically guide the search process while maintaining an effective balance between exploration and exploitation, enabling rapid and efficient convergence. Additionally, a dynamic, tolerance-based constraint-handling technique is introduced to strengthen its capability in solving complex constrained problems. The performance of KING is extensively evaluated on the IEEE CEC 2017 and IEEE CEC 2022 benchmark test suites, comparing it with classical algorithms, high-performance variants, and state-of-the-art methods across problems of varying scales. Experimental results demonstrate that KING outperforms the compared algorithms in convergence speed, solution accuracy, and stability. Its superiority is further validated through applications to four real-world engineering problems. The proposed algorithm proves to be an effective and reliable tool for engineering optimization. Its source code will be made publicly available at https://aliasgharheidari.com/KING.html and other websites.},
  archive      = {J_NEUCOM},
  author       = {Dong Zhao and Zhen Wang and Yupeng Li and Ali Asghar Heidari and Zongda Wu and Yi Chen and Huiling Chen},
  doi          = {10.1016/j.neucom.2025.131645},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131645},
  shortjournal = {Neurocomputing},
  title        = {KING: An efficient optimization approach},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sensitivity-propagated dual-frequency graph neural network for multivariate time series forecasting. <em>NEUCOM</em>, <em>657</em>, 131644. (<a href='https://doi.org/10.1016/j.neucom.2025.131644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have become one of the mainstream frameworks in multivariate time series (MTS) forecasting due to their powerful spatio-temporal dependency modeling capability. The process of extracting spatio-temporal features can be summarized into three stages: graph generation, graph convolution, and node updating. However, existing works recognize that the quality of the generated graph significantly impacts model performance, while overlooking that effective node updating can produce richer series representations. Furthermore, existing GNNs exhibit a pronounced bias toward capturing low-frequency temporal patterns, with inadequate attention to high-frequency components. Therefore, we propose SensGCN, a novel dynamic graph spatio-temporal network by introducing the concept of series sensitivity features to optimize the node updating process. Built upon a graph convolutional Gated Recurrent Unit (GRU) framework, SensGCN derives sensitivity features from series volatility patterns under non-autocorrelation conditions. These features subsequently guide node updating after aggregating external series information through graph convolution. Additionally, a novel dynamic graph estimation method is developed that extracts high-frequency components via series decomposition to jointly model time-varying spatial dependencies in MTS data, thereby enhancing GNNs’ capability in learning high-frequency features. Extensive evaluations across five public datasets show that our SensGCN achieves competitive or state-of-the-art performance in both multi-step and single-step forecasting tasks. Notably, in multi-step forecasting with a predefined graph structure, SensGCN achieves the best performance in four out of six cases and consistently attains the lowest MAE, outperforming the best baselines by up to approximately 1.3 %.},
  archive      = {J_NEUCOM},
  author       = {Yaling Xun and Shuo Han and Jianghui Cai and Haifeng Yang and Jifu Zhang},
  doi          = {10.1016/j.neucom.2025.131644},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131644},
  shortjournal = {Neurocomputing},
  title        = {Sensitivity-propagated dual-frequency graph neural network for multivariate time series forecasting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explaining and interpreting hyperdimensional computing classifiers on tabular data. <em>NEUCOM</em>, <em>657</em>, 131643. (<a href='https://doi.org/10.1016/j.neucom.2025.131643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the rise in the usage of artificial intelligence models and machine learning approaches in our day-to-day lives, it has become increasingly important to explain these models to increase user trust. Hyperdimensional Computing (HDC) has been introduced as a powerful, energy-efficient algorithmic framework that is intrinsically less opaque than (deep) neural networks. Nevertheless, the possibility of explaining and interpreting the HDC-based classification model has not yet been explored explicitly. Therefore, this work proposes an explanation method and an interpretation method for the HDC-based classification model working with tabular data. The proposed methods have been successfully evaluated on three tabular data sets with a diverse number of samples, features, and classes. Their faithfulness is validated with coherence checks, the deletion and insertion metrics, and a feature ablation study. The results of the proposed explanation method align well with the well-studied LIME explanations.},
  archive      = {J_NEUCOM},
  author       = {Laura Smets and Werner Van Leekwijck and Steven Latré and José Oramas},
  doi          = {10.1016/j.neucom.2025.131643},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131643},
  shortjournal = {Neurocomputing},
  title        = {Explaining and interpreting hyperdimensional computing classifiers on tabular data},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A 3D UNet-based fusion network for brain tumor segmentation with missing modalities. <em>NEUCOM</em>, <em>657</em>, 131642. (<a href='https://doi.org/10.1016/j.neucom.2025.131642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal magnetic resonance imaging provides complementary information for brain tumor segmentation, significantly enhancing the accuracy of diagnosis and prognosis. However, the common issue of missing modalities in clinical practice severely undermines the performance of existing methods, as they predominantly rely on complete multimodal data and struggle to effectively handle dynamic inter-modality correlations and tumor region specificity. To address this challenge, we propose a novel fusion network based on 3D U-Net, termed MPDF-UNET. Its core innovation lies in the introduction of the Modality Priors and Dynamic Features fusion (MPDF) module, which adaptively learns the unique representations of different MRI modalities under conditions of partial modality loss while effectively integrating complementary information across modalities. Additionally, we develop a modality combination sampling strategy that dynamically adjusts the distribution of modality combinations in the training data. This strategy encourages the network to fully exploit prior knowledge from each modality, thereby enhancing model robustness under conditions of missing modalities. To mitigate the impact of missing modality-associated dynamic feature information, we further propose a feature loss function. By imposing constraints on dynamic features, this loss function facilitates the learning of modality priors, alleviating the degradation of the network’s representational capacity caused by missing modalities. Experiments conducted on BRATS2018 and BRATS2020 benchmark datasets demonstrate the superiority of MPDF-UNET. Notably, the model achieves significant improvements in the fine-grained segmentation of enhancing tumors, surpassing current SOTA. Specifically, on BRATS2018 dataset, our method improves the Dice score of enhancing tumor segmentation by 7.78 % on average compared to the best-performing baseline Region-aware Fusion Network (RFNet), demonstrating superior robustness under missing modalities. This work provides a reliable solution for incomplete or resource-limited multimodal data in clinical settings, demonstrating significant practical value.},
  archive      = {J_NEUCOM},
  author       = {Yutian Xiao and Xiaomao Fan and Yuanyuan Liao and Chongguang Yang and Yang Zhao},
  doi          = {10.1016/j.neucom.2025.131642},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131642},
  shortjournal = {Neurocomputing},
  title        = {A 3D UNet-based fusion network for brain tumor segmentation with missing modalities},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Connected multi-hierarchies lightweight global hierarchical model in hyper-relational knowledge graphs. <em>NEUCOM</em>, <em>657</em>, 131641. (<a href='https://doi.org/10.1016/j.neucom.2025.131641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyper-relational knowledge graphs enriched by qualifiers have wide applications across diverse fields, and knowledge representation learning is emerging as a prominent research focus. Existing representation methods primarily concentrate on the local hierarchies of each element, overlooking the global hierarchies and their complex dependencies which can result in substantial semantic incompleteness and degraded model generalization. While modeling global hierarchical semantics presents a challenge, integrating local and global hierarchies further increases computational complexity. To tackle these challenges, we propose CMLG, a lightweight global hierarchical representation learning method that connects multiple hierarchies and leverages varied hierarchical details to improve learning effectiveness. Specifically, interactions within local hierarchies are utilized to update the local vectors of triples and qualifiers, thereby capturing essential semantic aggregations at the local hierarchies to construct global hierarchical expressions of entities and relations. These global representations encompass the essential features of hyper-relational facts and are utilized for computational tasks across various domains. To enhance the quality of embeddings, contrastive methods that connect multi-hierarchies are utilized within and across these hierarchies to boost the model’s learning capabilities. Considering the computational resources required for learning at both local and global hierarchies, CMLG adopts the lightweight design to reduce the parameters and computational demands of training, thereby enhancing its suitability for large-scale datasets. Comprehensive experiments on various datasets reveal that our approach outperforms advanced models, achieving up to a 12 % improvement in MRR over the runner-ups.},
  archive      = {J_NEUCOM},
  author       = {Jiahang Li and Qilong Han and Hui Zhang and Lijie Li and Dan Lu},
  doi          = {10.1016/j.neucom.2025.131641},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131641},
  shortjournal = {Neurocomputing},
  title        = {Connected multi-hierarchies lightweight global hierarchical model in hyper-relational knowledge graphs},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The generative adversarial network combined with noise guidance and global features generates high quality defect samples. <em>NEUCOM</em>, <em>657</em>, 131639. (<a href='https://doi.org/10.1016/j.neucom.2025.131639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous improvement of industrial production intelligence and automation, surface defect detection has become a critical aspect of industrial quality control. However, due to the significantly reduced frequency of surface defects, obtaining sufficient defect data becomes extremely difficult, which limits the performance of deep learning models. To address this challenge, we propose a generative adversarial network (GAN) with noise guidance and global information to generate high-quality defect sample images, thereby enhancing strip detection accuracy. First, the Patch method is used to divide images into blocks, and the feature context of real samples is captured through encoded information. This allows the learning of the potential spatial distribution of real samples, guiding the generator toward directional learning. Second, an adaptive simulated annealing attenuation algorithm is designed to find the global optimal solution of the training process by constraining the minimum temperature stability. Third, a denoising module is introduced to generate high-quality samples by leveraging deep multi-scale feature extraction and residual structures. Experimental results show that, compared to existing advanced models, the proposed method performs well in terms of structural similarity (SSIM) and peak signal-to-noise ratio (PSNR). The method is evaluated on two industrial small sample datasets (GC10-DET and NEU-DET), where it demonstrates particularly strong performance in generating normal images. Furthermore, the generated images are added to the training set as augmented data, improving the performance of three advanced target detection models. Overall, this research offers an effective solution for small sample defect detection in industrial scenarios and holds significant application potential.},
  archive      = {J_NEUCOM},
  author       = {Meishun Wu and Jinmin Peng and Xinyi Yu and Liulu Zhang and Chaoqi Jiang and Wenkai Dong and Liangshen Chen},
  doi          = {10.1016/j.neucom.2025.131639},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131639},
  shortjournal = {Neurocomputing},
  title        = {The generative adversarial network combined with noise guidance and global features generates high quality defect samples},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing continual semantic segmentation with visual explanations and model adaptations. <em>NEUCOM</em>, <em>657</em>, 131637. (<a href='https://doi.org/10.1016/j.neucom.2025.131637'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual Semantic Segmentation (CSS) faces challenges such as catastrophic forgetting, background shift, and limited interpretability, which hinder its real-world deployment. Existing approaches mainly rely on knowledge distillation mechanisms and adaptive pseudo-labeling but struggle with efficiency and generalization. To address these gaps, we propose a novel framework that enhances segmentation accuracy while reducing computational overhead. Our contributions include the use of replay mechanisms with augmented pseudo labels that leverage the unknown class to tackle background shift and mitigate forgetting, as well as the use of modified Atrous Spatial Pyramid Pooling (ASPP) blocks to improve feature extraction without increasing the number of parameters. Additionally, we integrate a visual model explanation loss to enhance interpretability and trust in segmentation decisions. Experimental results on the PASCAL VOC and Cityscapes datasets show that our approach outperforms prior CSS methods by more than 10 % in mIoU score while significantly reducing model size, making it more suitable for real-world applications such as autonomous driving. Further validation in the CARLA simulator demonstrates its feasibility for deployment. The source code is available at https://github.com/daoducmanh194/RRR-CISS .},
  archive      = {J_NEUCOM},
  author       = {Manh Dao and Tuan Linh Dang},
  doi          = {10.1016/j.neucom.2025.131637},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131637},
  shortjournal = {Neurocomputing},
  title        = {Enhancing continual semantic segmentation with visual explanations and model adaptations},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label webpage text classification based on feature segmentation and attention mechanism. <em>NEUCOM</em>, <em>657</em>, 131635. (<a href='https://doi.org/10.1016/j.neucom.2025.131635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the natural distribution differences of webpage content, multi-label webpage text datasets suffer from the long-tailed label problem. Moreover, the length of multi-label webpage text varies, making it difficult for sequence based deep learning models to set the sequence length. In order to solve the above problems, a feature self segmentation strategy is proposed in this paper, which executes different segmentation strategies for webpage texts of different lengths based on the sequence length of the deep learning model, so as to preserve long webpage texts without introducing too much noisy data for short webpage texts. In addition, by calculating the attention of adjacent segments, calculating the attention of labels and different segments, and constructing the co-attention networks, not only can important content in the document be highlighted, but also content related to labels can be highlighted, which can effectively extract features associated with low-frequency labels and solve the long-tailed label problem. The comparative experimental results on the manually annotated Energy Website Multi-Label Webpage Text dataset and three benchmark multi-label text classification datasets demonstrate that the method constructed in this paper outperforms all baseline methods. The main codes are available at https://github.com/sgysgywaityou/MLWT-FSAM/tree/main/MLWT-FSAM .},
  archive      = {J_NEUCOM},
  author       = {Yanan Cheng and Wenling Li and Zhichao Zhang and Hao Chen and Zhaoxin Zhang},
  doi          = {10.1016/j.neucom.2025.131635},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131635},
  shortjournal = {Neurocomputing},
  title        = {Multi-label webpage text classification based on feature segmentation and attention mechanism},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density peak clustering via only new upward distance on sub-cluster shared neighbors space without setting cluster centers manually. <em>NEUCOM</em>, <em>657</em>, 131634. (<a href='https://doi.org/10.1016/j.neucom.2025.131634'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peak clustering (DPC) algorithm is widely applied in data analysis field due to its efficiency and simplicity. However, most improvements to DPC depend on human experience and prior knowledge to identify cluster centers, leading to subjective and inaccurate results. Existing non-prior DPC methods select cluster centers based on the maximum value of the product between local density and upward distance, which ignores the cluster centers of tiny or sparse clusters and identifies the noise and outlier points as cluster centers, resulting in misclassification. In order to address these challenges and provide an accurate method for defining the cluster centers, we propose a DPC algorithm that automatically determines the cluster centers using only new upward distance (NUD) within the sub-cluster shared neighbors space (SSNS). First, sub-clusters are constructed by defining neighbor density and shared neighbor distance. Next, the distance between sub-cluster centers based on shared neighbors is utilized to build the SSNS, reflecting the interconnected nature of sub-clusters. Then, we redefine the upward distance based on SSNS and automatically select cluster centers according to the maximum value of NUD. Furthermore, adaptive threshold filter is applied to adjust parameters and mitigate the effects of noise and outlier points. Finally, sub-clusters are merged based on SSNS similarity, which significantly enhances computational efficiency. Experimental results on synthetic and real datasets show that NUD-SSNS DPC outperforms state-of-the-art methods, achieving improvements of 28 % and 63 % in Fowlkes–Mallows index (FMI) and adjusted rand index (ARI), respectively, while offering computational speed advantage for large-size datasets.},
  archive      = {J_NEUCOM},
  author       = {Jinglong Wang and Jintao Tao and Yu Zhang and Changju Liu and Jiangtao Xu},
  doi          = {10.1016/j.neucom.2025.131634},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131634},
  shortjournal = {Neurocomputing},
  title        = {Density peak clustering via only new upward distance on sub-cluster shared neighbors space without setting cluster centers manually},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid neural network adaptive fuzzy sliding mode online compensatory control for robots with global stability. <em>NEUCOM</em>, <em>657</em>, 131632. (<a href='https://doi.org/10.1016/j.neucom.2025.131632'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to parameter variations, joint friction, and external disturbances, nonlinear robot system models may suffer from modeling inaccuracies or parameter identification difficulties. In addition, traditional control methods make it difficult to estimate the uncertainty of the system model accurately, and the uncertainty of the internal model parameters of the system will also seriously affect the tracking control accuracy of the robot. To solve the above problems, this paper proposes a hybrid neural network adaptive fuzzy sliding mode online compensation control method for robots with global stability. The technique uses an RBF neural network to estimate the uncertainty and dynamically compensates for it by introducing it into an adaptive fuzzy sliding mode controller. Compared to the traditional approximation network, the method ensures the stability of the global consistent final boundedness of the system signals. Also, it achieves the convergence of the neural network weights to the ideal values. To effectively suppress the system jitter, this paper proposes a scheme based on the combination of hyperbolic tangent function sliding mode and fuzzy control. The focus of this paper is on the simulation verification of the proposed control method. The simulation experiment results verify the effectiveness of the proposed method. The accuracy of the integral squared error of the technique in the presence of internal uncertainty and maximum friction moment disturbance is 3.24e-5 rad, which greatly improves the dynamic tracking performance of the robot.},
  archive      = {J_NEUCOM},
  author       = {Guocheng Xiao and Bei Liu and Yufeng Li and Haibin Yin},
  doi          = {10.1016/j.neucom.2025.131632},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131632},
  shortjournal = {Neurocomputing},
  title        = {Hybrid neural network adaptive fuzzy sliding mode online compensatory control for robots with global stability},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grade: Generative graph contrastive learning for multimodal recommendation. <em>NEUCOM</em>, <em>657</em>, 131630. (<a href='https://doi.org/10.1016/j.neucom.2025.131630'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal recommender systems based on graph convolutional networks have made significant progress by integrating multiple modal data for item recommendation. While most existing approaches learn user and item representations through modality-related interaction graphs, these approaches still encounter challenges inherent to graph convolutional networks: over-smoothing. To address this challenge, we propose a model named Grade, G enerative G r aph Contr a stive Learning for Multimo d al R e commendations. It combines generative models and contrastive learning and design four task losses. In particular, the generative graph contrastive task generates contrastive views inter-modal through variational graph reconstruction, effectively aligning modal features to improve user and item representations. In addition, the feature perturbation contrastive task generates multimodal noisy views with interference for intra-modal contrast through noise-based self-supervised learning, effectively enhancing the robustness of modality-specific representations. Finally, we incorporate the Variational Graph Autoencoders (VGAE) task and the Bayesian Personalized Ranking (BPR) task. The combination of these four task losses effectively mitigates the issues of over-smoothing. Extensive experiments conducted on three publicly available datasets confirm the superiority of our model. The related code is available on https://github.com/Ricardo-Ping/Grade .},
  archive      = {J_NEUCOM},
  author       = {Yu-Chao Ping and Shu-Qin Wang and Zi-Yi Yang and Yong-Quan Dong and Meng-Xiang Hu and Pei-Lin Zhang},
  doi          = {10.1016/j.neucom.2025.131630},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131630},
  shortjournal = {Neurocomputing},
  title        = {Grade: Generative graph contrastive learning for multimodal recommendation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GDViT: Group-level decorrelation-based vision transformer for domain generalization. <em>NEUCOM</em>, <em>657</em>, 131624. (<a href='https://doi.org/10.1016/j.neucom.2025.131624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality-inspired domain generalization aims to improve model generalization by removing correlations between relevant and irrelevant features. However, a key challenge lies in effectively distinguishing the two. Existing methods, lacking explicit feature grouping, often eliminate all feature correlations indiscriminately, which disrupts the internal structure of relevant features and degrades generalization performance. In this work, we propose a group-level decorrelation-based vision Transformer that explicitly separates features (tokens) into relevant and irrelevant groups. This design preserves the internal correlations within relevant features while removing the correlations between the two groups. To achieve this, we introduce a feature grouping module that guides the separation process, followed by a grouping Transformer encoder that performs inter-group decorrelation, enabling the model to focus more on task-relevant information. Additionally, a supervised contrastive loss is employed to further enhance generalization. Extensive experiments demonstrate that our method significantly improves out-of-distribution performance. Visual analysis further shows that our model suppresses attention to irrelevant features, mitigating spurious correlations and resulting in more stable predictions. Our approach achieves strong performance in both multi-source and single-source domain generalization settings.},
  archive      = {J_NEUCOM},
  author       = {Wenqiang Tang and Zhouwang Yang and Yanzhi Song},
  doi          = {10.1016/j.neucom.2025.131624},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131624},
  shortjournal = {Neurocomputing},
  title        = {GDViT: Group-level decorrelation-based vision transformer for domain generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed GNE seeking for aggregative games under event-triggered communication: Predefined-time convergent algorithm design. <em>NEUCOM</em>, <em>657</em>, 131623. (<a href='https://doi.org/10.1016/j.neucom.2025.131623'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the context of distributed generalized Nash equilibrium (GNE) seeking in aggregative games, it is challenging yet interesting to design fast GNE seeking algorithms using energy-efficient communication strategy. However, most existing distributed GNE seeking algorithms can only achieve asymptotic convergence under continuous-time communication setting, resulting in a slower convergence rate and greater consumption of communication resources. In this paper, by exploiting two time-varying gain feedback functions, we present a new kind of distributed GNE seeking algorithm by integrating predefined-time control law with event-triggered communication strategy. It is theoretically shown that the proposed algorithm can solve the predefined-time GNE seeking problem for aggregative games with Zeno behavior being avoided during the seeking process. Compared with the existing algorithms, the present one exhibits several salient features: 1) the convergence time can be preset according to task requirements; 2) the communication resources can be significantly saved by the event-triggered mechanism; and 3) the proposed algorithms exhibit simplicity in their structures and possess the advantage of easy implementability.},
  archive      = {J_NEUCOM},
  author       = {Zhijun Guo and Lingwei Zeng and Jinlei Cheng and Pengwen Xiong and Qian Li},
  doi          = {10.1016/j.neucom.2025.131623},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131623},
  shortjournal = {Neurocomputing},
  title        = {Distributed GNE seeking for aggregative games under event-triggered communication: Predefined-time convergent algorithm design},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FACET–VLM: Facial emotion learning with text-guided multiview fusion via vision-language model for 3D/4D facial expression recognition. <em>NEUCOM</em>, <em>657</em>, 131621. (<a href='https://doi.org/10.1016/j.neucom.2025.131621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) in 3D and 4D domains presents a significant challenge in affective computing due to the complexity of spatial and temporal facial dynamics. Its success is crucial for advancing applications in human behavior understanding, healthcare monitoring, and human-computer interaction. In this work, we propose FACET–VLM, a vision–language framework for 3D/4D FER that integrates multiview facial representation learning with semantic guidance from natural language prompts. FACET–VLM introduces three key components: Cross-View Semantic Aggregation (CVSA) for view-consistent fusion, Multiview Text-Guided Fusion (MTGF) for semantically aligned facial emotions, and a multiview consistency loss to enforce structural coherence across views. Our model achieves state-of-the-art accuracy across multiple benchmarks, including BU-3DFE, Bosphorus, BU-4DFE, and BP4D-Spontaneous. We further extend FACET–VLM to 4D micro-expression recognition (MER) on the 4DME dataset, demonstrating strong performance in capturing subtle, short-lived emotional cues. FACET–VLM achieves up to 99.41 % accuracy on BU-4DFE and outperforms prior methods by margins as high as 15.12 % in cross-dataset evaluation on BP4D. The extensive experimental results confirm the effectiveness and substantial contributions of each individual component within the framework. Overall, FACET–VLM offers a robust, extensible, and high-performing solution for multimodal FER in both posed and spontaneous settings.},
  archive      = {J_NEUCOM},
  author       = {Muzammil Behzad},
  doi          = {10.1016/j.neucom.2025.131621},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131621},
  shortjournal = {Neurocomputing},
  title        = {FACET–VLM: Facial emotion learning with text-guided multiview fusion via vision-language model for 3D/4D facial expression recognition},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based multi-modal MRI analysis with probabilistic attention for stroke lesion detection. <em>NEUCOM</em>, <em>657</em>, 131620. (<a href='https://doi.org/10.1016/j.neucom.2025.131620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke lesion detection in brain MRI remains challenging as existing deep learning methods process single modalities and ignore anatomical boundaries, limiting clinical adoption. We develop a graph-based framework that integrates neuroanatomical priors and multi-modal imaging for automated stroke lesion detection. Our approach uses anatomically-constrained supervoxel generation and graph attention networks with probabilistic attention attribution for interpretable lesion detection. Evaluated on the SOOP dataset (1715 subjects including 1461 stroke patients), our method achieves a Dice coefficient, sensitivity, and ROC-AUC of 0.85 ± 0.03, 0.88, and 0.94, respectively, outperforming CNN baselines by 15 %. The framework provides clinically meaningful attention maps and accurate automated stroke analysis.},
  archive      = {J_NEUCOM},
  author       = {Luis R. Mercado-Diaz and Derek Aguiar and Hugo F. Posada-Quintero},
  doi          = {10.1016/j.neucom.2025.131620},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131620},
  shortjournal = {Neurocomputing},
  title        = {Graph-based multi-modal MRI analysis with probabilistic attention for stroke lesion detection},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LEAD: LLM-enhanced deep reinforcement learning for stable decision-making in critical autonomous driving scenarios. <em>NEUCOM</em>, <em>657</em>, 131619. (<a href='https://doi.org/10.1016/j.neucom.2025.131619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated significant potential in addressing decision-making problems in the field of autonomous driving due to their strong reasoning capabilities. However, deploying LLMs in real-world driving scenarios often encounters challenges such as high computational requirements, elevated costs, and increased latency. On the other hand, Deep Reinforcement Learning (DRL) exhibits strong adaptability to decision-making tasks in autonomous driving with a relatively smaller parameter scale. Nevertheless, DRL agents often suffer from low exploration efficiency and high sensitivity to parameter variations. To address the above issues, we propose an LLM-Enhanced Autonomous Driving (LEAD) training framework, which integrates a high-level agent based on LLMs into the training process of DRL models, effectively improving the policy learning efficiency and generalization capability of DRL models. During the early stage of training, a dynamic intervention mechanism is introduced to identify key decision points within the DRL model, and a predefined expert guidance algorithm is utilized to integrate high-level decision strategies from LLMs into these critical nodes. During the later stage of training, the DRL model transitions into an autonomous optimization phase, where the agent, enhanced with LLM priors, continuously interacts with the environment to further refine the policy network, ultimately surpassing the performance of the LLM-based agent. Experimental results demonstrate that the LEAD-PPO model, built upon the proposed framework, reduces collision rates by 49.49 % and 59.4 % in low-density and high-density scenarios, respectively, during training compared to the baseline model. In the testing phase, the DRL model optimized through LEAD achieves task completion rates that are 9.60 %, 35.94 %, and 65.63 % higher than those of the baseline model in simple, moderate, and difficult scenarios, respectively. Overall, the proposed LEAD framework significantly improves the robustness, sample efficiency, and generalization ability of DRL models.},
  archive      = {J_NEUCOM},
  author       = {Dongwei Xu and Enwen Qiao and Tongcheng Gu and Hongda Fu and Chengju Sun and Haifeng Guo and Yuqing Liu},
  doi          = {10.1016/j.neucom.2025.131619},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131619},
  shortjournal = {Neurocomputing},
  title        = {LEAD: LLM-enhanced deep reinforcement learning for stable decision-making in critical autonomous driving scenarios},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed/Preassigned-time synchronization of delayed fuzzy memristive neural networks with reaction–diffusion terms. <em>NEUCOM</em>, <em>657</em>, 131618. (<a href='https://doi.org/10.1016/j.neucom.2025.131618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to effectively handle the synchronization of reaction–diffusion fuzzy memristive neural networks (MNNs) and shorten their synchronization time has become a worthwhile and meaningful issue to study. This paper mainly studies fixed-time synchronization (FXTS) and preassigned-time synchronization (PATS) problems for delayed fuzzy memristive neural networks (DFMNNs) with reaction–diffusion terms. First, a DFMNNs model with reaction–diffusion terms is introduced, which can effectively describe the spatial distribution characteristics of the network. Second, through the Lyapunov stability theory, the FXTS criterion and the upper limit of the settling-time (ST) are obtained. Subsequently, a state feedback controller is proposed to ensure that the system achieves synchronization within a specified time, and the synchronization time is independent of initial conditions and control parameters, which gives the designed controller a wider range of applications. Finally, two examples are presented to illustrate the effectiveness of the results.},
  archive      = {J_NEUCOM},
  author       = {Hanrui Chen and Dongbing Tong and Qiaoyu Chen},
  doi          = {10.1016/j.neucom.2025.131618},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131618},
  shortjournal = {Neurocomputing},
  title        = {Fixed/Preassigned-time synchronization of delayed fuzzy memristive neural networks with reaction–diffusion terms},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond sparsity: An empirical study of structured collaboration in modular AI. <em>NEUCOM</em>, <em>657</em>, 131616. (<a href='https://doi.org/10.1016/j.neucom.2025.131616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Mixture-of-Experts (MoE) architectures, the prevailing paradigm emphasizes sparse expert activation for computational efficiency. This paper explores an alternative architectural approach centered on structured collaboration, hypothesizing that the quality and nature of inter-module interactions are as significant as computational cost. We present a series of targeted proof-of-concept experiments to validate three distinct principles of structured interaction, inspired by cognitive science. First, we demonstrate that a hierarchical fusion mechanism, modeled on the brain's segregated visual pathways, enhances compositional reasoning on the VQA v2.0 benchmark. Second, by employing a redesigned reinforcement learning task in MiniGrid, we demonstrate that a system-wide differentiated credit assignment (SDCA) mechanism, with conflict detection learned end-to-end, facilitates more robust policy learning. Third, we ascertain that integrating reasoning "tools" as co-adaptive modules offers superior out-of-distribution robustness on the DROP dataset compared to a more powerful baseline agent utilizing external LLM-based tools. Our work provides concrete validation for these principles, highlighting a series of trade-offs between performance, robustness, and efficiency, and suggesting that prioritizing cognitive synergy over simple sparsity offers a promising direction for future research in modular AI.},
  archive      = {J_NEUCOM},
  author       = {Xiaofei Zhou and Soohong Kim and Yiru Wang and Kailin Zhang},
  doi          = {10.1016/j.neucom.2025.131616},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131616},
  shortjournal = {Neurocomputing},
  title        = {Beyond sparsity: An empirical study of structured collaboration in modular AI},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph transformer-driven reinforcement learning based on popularity for mining complex network key nodes. <em>NEUCOM</em>, <em>657</em>, 131614. (<a href='https://doi.org/10.1016/j.neucom.2025.131614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Key nodes in complex networks play a crucial role in maintaining the stability, functionality, and robustness of networked systems. Accordingly, the accurate identification of such nodes is of fundamental importance. Their significance spans multiple domains, including communication systems, transportation infrastructures, life sciences, and social networks. Existing algorithms for key node identification typically rely on heuristic measures or standard deep reinforcement learning frameworks. However, these approaches often suffer from limited feature extraction capabilities, high computational complexity, and insufficient generalizability, and a lack of dynamic adaptability. To overcome these limitations, this study proposes a novel architecture, GTRP (Graph Transformer-Driven Reinforcement Learning Based on Popularity). GTRP extends Epidemic-aware Heterogeneous Graph Transformer (GT) by introducing distinct attention mechanisms for both nodes and edges, enabling the integration of local structural features and global propagation properties. In addition, GTRP incorporates Dual-dynamics Reward Optimization (DR) to identify key nodes based on a network disintegration strategy. The model is trained on randomly generated Barabási–Albert (BA) networks and evaluated on synthetic networks of varying scales as well as multiple real-world network scenarios. Comparative experiments with six representative algorithms demonstrate that GTRP achieves substantial performance improvements—outperforming existing methods by 6.30 % in unweighted networks and 15.90 % in weighted networks. These results underscore the potential of GTRP to advance key node detection in complex network analysis.},
  archive      = {J_NEUCOM},
  author       = {Kaili Wang and Muqing Wu and Min Zhao},
  doi          = {10.1016/j.neucom.2025.131614},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131614},
  shortjournal = {Neurocomputing},
  title        = {A graph transformer-driven reinforcement learning based on popularity for mining complex network key nodes},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CCINet: A cascaded consensus interaction network for co-saliency object detection. <em>NEUCOM</em>, <em>657</em>, 131613. (<a href='https://doi.org/10.1016/j.neucom.2025.131613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-saliency object detection imitates human attention behavior, with the aim of identifying common salient objects in a set of related images. Previous approaches generally suffer from a lack of interaction among the extracted co-saliency information. As a result, the detection maps often turn out to be incomplete or redundant. In this paper, we propose a Cascaded Consensus Interaction Network (CCINet) for co-saliency object detection. This network improves the fusion and interaction among features, thus making full use of the co-saliency information. In the encoding stage, we introduce an Edge Semantic Consensus (ESC) module. It effectively integrates low-level and high-level encoding information. In this way, it is able to capture both fine edge details and rich semantics. Meanwhile, the ESC module refines the co-saliency features, which enhances the detection of co-saliency regions. During the up-sampling stage, the Cascaded Contextual Aggregation (CCA) module employs attention mechanisms, adaptive pooling, and separated-dilated convolution for comprehensive feature extraction. This approach effectively reduces background noise and controls the number of parameters. Extensive experiments indicate that our model outperforms many excellent CoSOD methods in recent years on the three most popular benchmark datasets. Source code is available at: https://github.com/JoeLAL24/CCINet.git .},
  archive      = {J_NEUCOM},
  author       = {Longsheng Wei and Xu Pei and Jiu Huang and Fan Xu},
  doi          = {10.1016/j.neucom.2025.131613},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131613},
  shortjournal = {Neurocomputing},
  title        = {CCINet: A cascaded consensus interaction network for co-saliency object detection},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). K-core-guided adaptive learning and policy optimization for targeted influence maximization in complex networks. <em>NEUCOM</em>, <em>657</em>, 131612. (<a href='https://doi.org/10.1016/j.neucom.2025.131612'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximizing information propagation in complex networks is essential for shaping public discourse, optimizing marketing strategies, and driving social change. Traditional influence maximization approaches often emphasize network topology, neglecting the critical need to align strategies with user semantics to influence specific user groups effectively. To address this issue, we introduce the Targeted Core-based Q-learning framework (TCQ), a hybrid optimization approach that draws inspiration from evolutionary network structures derived from K-core decomposition, tailored to tackle the problem of targeted influence maximization (TIM). TCQ integrates semantic insights (e.g., interests, demographics, or topical categories) with the network structure by combining a target-based probabilistic scoring function with K-core evolutionary hierarchies, enabling the efficient identification of key influential candidates within the network. Leveraging reinforcement learning, TCQ dynamically optimizes its seed selection policy through a process of exploration and exploitation in order to minimize influence overlap among selected seeds while maintaining adaptability across diverse network scenarios. Extensive experiments on real-world and synthetic networks demonstrate that TCQ not only maximizes targeted influence effectively but also achieves computational efficiency, showcasing its potential for optimizing influence propagation in complex networks.},
  archive      = {J_NEUCOM},
  author       = {Waseem Ahmad and Bang Wang},
  doi          = {10.1016/j.neucom.2025.131612},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131612},
  shortjournal = {Neurocomputing},
  title        = {K-core-guided adaptive learning and policy optimization for targeted influence maximization in complex networks},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient classification and error correction knowledge distillation framework for remaining useful life prediction of bearings in air turbine starter. <em>NEUCOM</em>, <em>657</em>, 131611. (<a href='https://doi.org/10.1016/j.neucom.2025.131611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prognostics and Health Management (PHM) is critical for industrial equipment maintenance, whose core task is to predict the Remaining Useful Life (RUL) of a system or component accurately. However, traditional deep learning-based approaches often demand significant computational and memory resources, limiting their feasibility for edge deployment. As an effective model compression technique, Knowledge Distillation (KD) has emerged as a core strategy for enabling edge intelligence by transferring knowledge from a teacher model to a lightweight student model. However, traditional KD methods exhibit a high dependency on the teacher model's output. This dependency limits the student model's capacity for autonomous error correction, impairing its distillation performance. To solve these problems, this paper proposes a novel Classification and Error Correction Knowledge Distillation (CEKD) framework. The framework employs Gaussian kernel-based feature entropy to dynamically evaluate teacher models' predictive capabilities, facilitating comprehensive assessment and sample differentiation. Furthermore, the knowledge self-reflection learning strategy extends error correction to continuous dynamic adjustment, enabling deep optimization of complex data. Experimental results on the air turbine starter bearing datasets show that CEKD surpasses KD methods by improving MAE and RMSE by 79.8 % and 78.6 % on average, while reducing memory consumption and inference time by nearly 10 × and 8 × , respectively, enabling deployment on resource-constrained devices.},
  archive      = {J_NEUCOM},
  author       = {Runxia Guo and Jingxu Yi and Xianfeng Luo},
  doi          = {10.1016/j.neucom.2025.131611},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131611},
  shortjournal = {Neurocomputing},
  title        = {An efficient classification and error correction knowledge distillation framework for remaining useful life prediction of bearings in air turbine starter},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Power-law-based preassigned-time bipartite output consensus for heterogeneous multi-agent systems under event-triggered control. <em>NEUCOM</em>, <em>657</em>, 131610. (<a href='https://doi.org/10.1016/j.neucom.2025.131610'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the preassigned-time (PST) bipartite output consensus problem for heterogeneous multi-agent systems (HMASs) using distributed dynamic event-triggered control (DETC). Firstly, based on PST stability lemma, a simpler PST dynamic compensator is developed to attain a novel consensus criterion, which does not require the satisfaction of the Hurwitz stability condition. Subsequently, to reduce the computational burden and the influence of control parameters, through the dynamic compensator, a novel PST control strategy with distributed dynamic event-triggered control is proposed. This control scheme not only removes the limitations of traditional control in terms of infinite control gain but also ensures error dynamics approach zero within preset time. Furthermore, the paper excludes Zeno behavior through a proof by contradiction. Finally, a numerical example is provided to demonstrate the practicality of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Wanli Jin and Huaguang Zhang and Yapeng Yang and Juan Zhang},
  doi          = {10.1016/j.neucom.2025.131610},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131610},
  shortjournal = {Neurocomputing},
  title        = {Power-law-based preassigned-time bipartite output consensus for heterogeneous multi-agent systems under event-triggered control},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time lag consensus and finite-time h∞ lag consensus for nonlinear multi-agent systems under communication delay. <em>NEUCOM</em>, <em>657</em>, 131609. (<a href='https://doi.org/10.1016/j.neucom.2025.131609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, the finite-time lag consensus (FTLC) and finite-time H ∞ lag consensus (FTHLC) problems for first-order multi-agent systems (MASs) are studied. On the one hand, a new state feedback controller considering the communication delay between agents is proposed. Besides, based on several inequality scaling techniques and finite-time stability theory, a sufficient criterion is derived to guarantee the FTLC of MASs. On the other hand, an adaptive state feedback controller and the corresponding adaptive law are put forward, which can also help MASs realize lag consensus in finite time without any additional conditions. Moreover, to address inevitable external disturbances in practice, the proposed control strategies are further enhanced to achieve FTHLC, which further expands the application range of the research results. Finally, the effectiveness of these provided FTLC and FTHLC control schemes in different scenarios is manifested through some numerical simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Song Gao and Jin-Liang Wang and Kun Ling and Shun-Yan Ren and Ming-Zhu Wei and Bei Peng},
  doi          = {10.1016/j.neucom.2025.131609},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131609},
  shortjournal = {Neurocomputing},
  title        = {Finite-time lag consensus and finite-time h∞ lag consensus for nonlinear multi-agent systems under communication delay},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed generalized nash equilibrium computing based on dynamic tracking mechanism for nonsmooth aggregative games over time-varying networks. <em>NEUCOM</em>, <em>657</em>, 131608. (<a href='https://doi.org/10.1016/j.neucom.2025.131608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the computation of generalized Nash equilibrium in aggregative games with coupling constraints over time-varying networks. The player’s cost objective comprises a differentiable function dependent on the aggregate of all players’ decisions and a possibly non-smooth term with a linear mapping. In this context, designing solution methods for such game formulation is relatively scarce. We thus develop a fully distributed equilibrium-seeking algorithm that accommodates time-varying communication networks while circumventing the need for global decision information. The proposed algorithm synergistically embeds dynamic tracking of aggregate decisions through a consensus-based mechanism with projected pseudo-gradient updates, augmented by a proximal splitting scheme to handle non-smooth components. Theoretically, we establish convergence guarantees to the variational equilibrium through a new operator splitting framework. Finally, numerical experiments are conducted to substantiate the validity of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Liang Ran and Huaqing Li and Zheng Wang and Lifeng Zheng and Jun Li and Zhe Li},
  doi          = {10.1016/j.neucom.2025.131608},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131608},
  shortjournal = {Neurocomputing},
  title        = {Distributed generalized nash equilibrium computing based on dynamic tracking mechanism for nonsmooth aggregative games over time-varying networks},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlocking spatial textures: Gradient-guided pansharpening for enhancing multispectral imagery. <em>NEUCOM</em>, <em>657</em>, 131607. (<a href='https://doi.org/10.1016/j.neucom.2025.131607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pansharpening aims to integrate the high spatial resolution of panchromatic images (PAN) with the spectral richness of multispectral images (MSI), producing high-resolution multispectral outputs. While deep learning-based approaches have achieved remarkable performance in pansharpening, most methods primarily focus on developing advanced model architectures, often overlooking the potential of manually crafted features. Unlike previous works where gradient information has been primarily utilized in model-based optimization methods, we demonstrate that gradient features derived from the gradient magnitude can provide complementary information that guides the fusion process of PAN and MSI, significantly enhancing pansharpening performance. Specifically, we propose a gradient-guided pansharpening network, termed GGPNet, which consists of two branches: a guidance feature extraction branch that captures gradient features from the gradient magnitude, and a gradient-guided fusion branch that integrates the PAN and MSI with the additional information from gradient features. Within the fusion branch, a multi-image cross-attention block is designed to facilitate the gradual integration of features from images with varying spectral bands and resolutions. Moreover, a gradient loss is introduced to guarantee the effectiveness of the extracted gradient feature information, which is then combined with the widely-used spectral image loss. Extensive experiments on the GaoFen-2 (GF2), QuickBird (QB), and WorldView-3 (WV3) datasets validate the efficacy of our approach, demonstrating its superiority over state-of-the-art methods with substantial improvements in PSNR, ERGAS, and other commonly adopted metrics. The source code will be made publicly available at: https://github.com/sevenzero70/GGPNet_code .},
  archive      = {J_NEUCOM},
  author       = {Lanyue Liang and Tianyu Li and Guoqing Wang and Lin Mei and Xiongxin Tang and Chaofan Qiao and Dongyu Xie},
  doi          = {10.1016/j.neucom.2025.131607},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131607},
  shortjournal = {Neurocomputing},
  title        = {Unlocking spatial textures: Gradient-guided pansharpening for enhancing multispectral imagery},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of memristor performance in neural networks using an AHaH framework. <em>NEUCOM</em>, <em>657</em>, 131606. (<a href='https://doi.org/10.1016/j.neucom.2025.131606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristor-based neural networks show significant potential for advancing neuromorphic computing by mimicking synaptic behavior. However, their performance can be compromised by various operational conditions, including noise, degradation, and sudden resistance changes. In this paper, we propose a refined simulation method and a novel device evaluation framework, leveraging the AHaH Framework, to enhance the performance and reliability of memristor-based neural networks. The improved simulation approach is designed to incorporate realistic features, such as linear and non-linear decay, periodic and aperiodic fluctuations, and customizable behaviors, allowing for a more accurate depiction of memristor dynamics. Through this evaluation, critical impacts on neural network accuracy and efficiency are uncovered, particularly under complex noise patterns and degradation scenarios. The device evaluation framework illustrates how devices, despite exhibiting similar classification accuracy, can display distinct dynamic properties through the monitoring of midpoint voltage variations. These findings provide a basis for robust neuromorphic circuit development.},
  archive      = {J_NEUCOM},
  author       = {Xiang Xu and Gangquan Si and Minglin Xu and Yukaichen Yang and Chenhao Li},
  doi          = {10.1016/j.neucom.2025.131606},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131606},
  shortjournal = {Neurocomputing},
  title        = {Evaluation of memristor performance in neural networks using an AHaH framework},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TMAN: A temporal multimodal attention network for backchannel detection. <em>NEUCOM</em>, <em>657</em>, 131605. (<a href='https://doi.org/10.1016/j.neucom.2025.131605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backchannel responses play an essential role in human communication, which are often expressed by listeners to show their attention and engagement to speakers without interrupting their speech. Their automatic detection is crucial for developing conversational AI agents that engage in human-like, responsive communication. Backchanneling can be conveyed via a combination of various non-verbal cues, such as head nodding and facial expressions. However, these cues are often subtle, brief and sparse during conversations, posing significant challenge in the accurate detection of backchannel responses. This study introduces TMAN, a sequential three-stage multimodal temporal network designed to effectively encode behavioral features from four human visual modalities. It incorporates three attention modules to encode subtle “micro” actions, such as specific gestures or facial expressions, that occur at each frame, as well as temporal “macro” behavior patterns, such as sustained body and head movements, into a final representation for backchannel detection. These are often expressed in backchannel responses, thereby enhancing the detection capabilities. Comprehensive experiments conducted on two public datasets demonstrate that TMAN significantly enhances performance and achieves state-of-the-art results. Extensive ablation studies validate the contribution of each attention module and visual modality employed in our model, and identify the appropriate feature transformation and implementation setups for effective backchannel detection. An in-depth investigation of the model inference process further demonstrates the effectiveness of TMAN attention modules, particularly in processing both “micro” and temporal “macro” behavior patterns in multimodal visual cues.},
  archive      = {J_NEUCOM},
  author       = {Kangzhong Wang and Xinwei Zhai and M.K.Michael Cheung and Eugene Yujun Fu and Peter Qi Chen and Grace Ngai and Hong Va Leong},
  doi          = {10.1016/j.neucom.2025.131605},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131605},
  shortjournal = {Neurocomputing},
  title        = {TMAN: A temporal multimodal attention network for backchannel detection},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-based distributed adaptive synchronization control for multi-weighted complex networks with aperiodic intermittent coupling. <em>NEUCOM</em>, <em>657</em>, 131604. (<a href='https://doi.org/10.1016/j.neucom.2025.131604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the synchronization control for multi-weighted complex networks (MWCNs) with unknown disturbances and aperiodic intermittent coupling. Firstly, an adaptive neural network strategy is used to approximate the unknown components derived from nonlinear function, while a novel continuous function is proposed by utilizing the idea of time-varying boundary layer technique to deal with the influence of approximation errors. Secondly, different from the continuous coupling and periodic intermittent coupling mechanisms in existing works, an aperiodic intermittent coupling mechanism is taken into consideration in MWCNs. Thirdly, to synchronize MWCNs under aperiodic intermittent coupling, adaptive strategies are developed to adjust coupling strengths and coupling gains based on all edges and partial edges, respectively. Note that these two strategies are fully distributed, i.e., they do not require any global information. Finally, some numerical simulations are provided to verify the effectiveness of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Bin Zhang and Dan Liu and Binrui Wang and Kaibo Shi},
  doi          = {10.1016/j.neucom.2025.131604},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131604},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based distributed adaptive synchronization control for multi-weighted complex networks with aperiodic intermittent coupling},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RoleCF: Role-oriented coarse-to-fine emotion cause recognition for empathetic response generation. <em>NEUCOM</em>, <em>657</em>, 131603. (<a href='https://doi.org/10.1016/j.neucom.2025.131603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In empathetic response generation, reasoning about conversational emotions by recognizing the causes of emotions is a key technique for achieving empathy. However, existing approaches encounter two fundamental limitations. First, they predominantly focus on fine-grained analysis of emotion causes at the token level, neglecting the broader, more comprehensive analysis at the utterance level. Second, these methods fail to consider emotion causes from the perspectives of different roles, resulting in biased emotional inference. To tackle the aforementioned challenges, we propose RoleCF, an innovative framework that aims to improve empathetic response generation by identifying role-oriented emotion causes in a coarse-to-fine-grained manner. Our approach models the extraction of emotion causes from different perspectives by constructing two distinct heterogeneous graphs for the user and the agent, respectively. Emotion cause nodes within each graph are utilized to swiftly capture emotion causes at the utterance level, providing a holistic understanding of the dialogue context. In addition, we employ two role-interaction modules to selectively integrate the most relevant information from the counterpart, thereby enhancing the recognition of fine-grained emotion causes. Guided by the agent’s state in the generation process, our model achieves superior performance on two benchmark datasets. This is supported by both automatic and human evaluations, demonstrating its effectiveness in capturing and leveraging the underlying causes of emotions for response generation.},
  archive      = {J_NEUCOM},
  author       = {Wei Zhang and Lifang Wang and Ming Xia and Ronghan Li and Zhongtian Hu and Jiashi Lin},
  doi          = {10.1016/j.neucom.2025.131603},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131603},
  shortjournal = {Neurocomputing},
  title        = {RoleCF: Role-oriented coarse-to-fine emotion cause recognition for empathetic response generation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective framework with hybrid augmentation for visual reinforcement learning generalization. <em>NEUCOM</em>, <em>657</em>, 131602. (<a href='https://doi.org/10.1016/j.neucom.2025.131602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current studies in Visual Reinforcement Learning focus on developing policies to acclimate to unknown environments through data augmentation. This paper aims to develop a new methodology to improve upon existing results. To this end, we first categorize existing methods into three groups based on the focus of augmentation: Task-Aware Augmentation, Image-Processing Augmentation, and Image-Scene Augmentation. Subsequently, we establish a unified framework that integrates these three augmentation categories. The core of our framework is hybrid data augmentation, which enhances data diversity. In this framework, we employ hyperspherical space and regularization techniques to address the side effects of such augmentation, specifically the discrepancy between augmented and original data, as well as the instability associated with hybrid augmentation. Finally, we evaluate the proposed framework across three benchmarks, demonstrating its significant advantages over current state-of-the-art methods. Notably, our framework outperforms existing approaches by an average of 4.59 % across 10 tasks in DMC-GB, 28.81 % across 6 tasks in Robosuite, and 20.50 % across 4 tasks in Adroit. The code for our framework will be released at https://github.com/csufangyu/MuHA .},
  archive      = {J_NEUCOM},
  author       = {Yu Fang and Xuehe Zhang and Haoshu Cheng and Xizhe Zang and Changle Li and Jie Zhao},
  doi          = {10.1016/j.neucom.2025.131602},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131602},
  shortjournal = {Neurocomputing},
  title        = {An effective framework with hybrid augmentation for visual reinforcement learning generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-tail learning with rebalanced contrastive loss. <em>NEUCOM</em>, <em>657</em>, 131601. (<a href='https://doi.org/10.1016/j.neucom.2025.131601'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating supervised contrastive loss to cross entropy-based classification has recently been proposed as a solution to address the long-tail learning problem. However, when the class imbalance ratio is high, it requires adjusting the supervised contrastive loss to support the tail classes, as the conventional contrastive learning is biased towards head classes by default. To this end, we present Rebalanced Contrastive Learning (RCL), an efficient means to increase the long-tail classification accuracy by addressing three main aspects: 1. Feature space balancedness – Equal division of the feature space among all the classes 2. Intra-Class compactness – Reducing the distance between same-class embeddings 3. Regularization – Enforcing larger margins for tail classes to reduce overfitting. RCL adopts class frequency-based SoftMax loss balancing to supervised contrastive learning loss and exploits scalar multiplied features fed to the contrastive learning loss to enforce compactness. We implement RCL on the Balanced Contrastive Learning (BCL) Framework, which has the SOTA performance. Our experiments on three benchmark datasets CIFAR10-LT,CIFAR100-LT and ImageNet-LT demonstrate the richness of the learnt embeddings and increased top-1 balanced accuracy RCL provides to the BCL framework. We further demonstrate that the performance of RCL as a standalone loss also achieves state-of-the-art level accuracy.},
  archive      = {J_NEUCOM},
  author       = {Charika De Alvis and Dishanika Denipitiyage and Suranga Seneviratne},
  doi          = {10.1016/j.neucom.2025.131601},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131601},
  shortjournal = {Neurocomputing},
  title        = {Long-tail learning with rebalanced contrastive loss},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing robust generalization through appropriate adversarial example attack intensity. <em>NEUCOM</em>, <em>657</em>, 131599. (<a href='https://doi.org/10.1016/j.neucom.2025.131599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) are notoriously susceptible to adversarial examples. To mitigate the impact of well-designed adversarial attacks on network models, researchers have developed various defense mechanisms, among which adversarial training has emerged as one of the most effective strategies to date. Adversarial training aims to augment training data with adversarial examples, thus giving DNNs a certain degree of robustness to defend against adversarial attacks. However, while obtaining adversarial robustness, this method comes at the cost of reducing the generalization performance, manifested in the reduced classification effect of clean test datasets. Researchers have been actively seeking to counter the balance between adversarial robustness and model generalization. We believe that the key to balancing these two aspects lies in identifying appropriate adversarial examples. Overly potent examples can lead to a decline in clean accuracy, whereas weaker examples may offer limited robustness. Based on our analysis, a new adversarial example generation algorithm called Denoising Projection Gradient Descent (DPGD) was proposed. DPGD adds a purification module and a constraint in generating adversarial examples, the former is used to limit the influence of too strong adversarial examples on model training and the latter is used to ensure the necessary attack intensity. Combining DPGD with the framework of traditional adversarial training, we obtain the Diffusion Adversarial Training (DifAT) approach. To verify the effectiveness of our proposed method, we conducted extensive experiments on benchmark datasets, including CIFAR-10, CIFAR-100, and Tiny-Imagenet. Our results demonstrate the effectiveness of DifAT in improving the robustness of DNNs while maintaining or even improving their generalization performance.},
  archive      = {J_NEUCOM},
  author       = {Xiaoguo Ding and Liangjian Zhang and Qiqi Bao and Yaguan Qian and Bin Wang and Zhaoquan Gu and Yanchun Zhang},
  doi          = {10.1016/j.neucom.2025.131599},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131599},
  shortjournal = {Neurocomputing},
  title        = {Enhancing robust generalization through appropriate adversarial example attack intensity},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User identification based on the topology consistency of cross-layer common neighbors in social network. <em>NEUCOM</em>, <em>657</em>, 131591. (<a href='https://doi.org/10.1016/j.neucom.2025.131591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, it has become a common practice to create multiple accounts on various social networks for online recreation. When accounts in different networks share similar structural features, i . e . , they have topology consistency, they may belong to the same individual. However, having multiple accounts for the same person across different networks can be inconvenient and uncertain, leading to difficulties in accurate recommendations. Therefore, some researchers have focused on identifying users within single network layers, but without involving the information from various network platforms, resulting in identification confusion and reduced algorithm accuracy. This paper proposes a novel topology consistency-based link prediction algorithm (Topology Consistency: TC) for user identification, combining separate layers of a multilayer network into a single-layer network to include more layer information. TC applies topology information from the cross-layer common neighbors produced in layer combination to distinguish target node pairs and utilizes matrix computation to reduce complexity. Furthermore, to address controversial identification situations appearing after layer combination, the edges between the cross-layer common neighbors are innovatively considered. Finally, experimental results in real-world and artificial networks show that TC has superior performance to state-of-the-art algorithms and has applicability and practicality.},
  archive      = {J_NEUCOM},
  author       = {Yujie Yang and Shuai Cao and Long Wang and Dong Liu and Marcus Kaiser},
  doi          = {10.1016/j.neucom.2025.131591},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131591},
  shortjournal = {Neurocomputing},
  title        = {User identification based on the topology consistency of cross-layer common neighbors in social network},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of linear optics network for pattern recognition task via the generation of continuous variable entangled states. <em>NEUCOM</em>, <em>657</em>, 131588. (<a href='https://doi.org/10.1016/j.neucom.2025.131588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear optics neural networks or optical neural networks offer potential advantages over traditional electronic neural networks in terms of speed, energy efficiency, scalability, and improved parallelism, particularly for high-bandwidth applications. The use of photonics allows for more compact and integrated neural network designs, potentially enabling the development of larger and more complex networks. A linear optics network is developed to implement a quantum classifier. Indeed, the designed network is a quantum circuit consisting of some Gaussian gates such as displacement, noiseless linear amplification (NLA), squeezer and Green machine. At first, the classical inputs are encoded with the help of position-displacement operator to prepare single-mode coherent states. Then, the amplitudes of the coherent states are amplified by passing through NLA elements followed by squeezer gates that may transform classical coherent states into nonclassical ones. Finally, the transformed coherent states are fed into the Green machine which provides entangled states as the outcome of the network. As a primary goal of this work, the network generates a multi-mode entangled state by applying the displacement operator on the vacuum state encoded classical data. Besides, it is shown that the output state of the circuit may possess squeezing characteristics as another nonclassical feature. In the continuation, as a practical application, the network is implemented to perform some pattern recognition tasks. At first, the Bayes theorem is employed to define discriminant functions to perform a general classification task, then the outcome distribution of the network is utilized to classify some corrupted LEDs that display English letters. Finally, we show that the outcome of the circuit may be manipulated to embed classical neural networks into a continuous-variable variational quantum circuit (VQC). The network is trained via the logistic regression algorithm with the MNIST database. The results show that the digits can be recognized with relatively high accuracy. Ongoing research is focused on developing new linear optical techniques for machine learning, improving the efficiency and scalability of optical networks, and exploring new applications of linear optics in machine learning and quantum computing. Hence, such a quantum circuit may also be used to design novel high-accuracy pattern recognition devices.},
  archive      = {J_NEUCOM},
  author       = {Ebrahim Ghasemian and Mohammad Kazem Tavassoly and Habib Rostami},
  doi          = {10.1016/j.neucom.2025.131588},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131588},
  shortjournal = {Neurocomputing},
  title        = {Implementation of linear optics network for pattern recognition task via the generation of continuous variable entangled states},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning generic and specific prompts with contrastive constraints for multi-task visual scene understanding. <em>NEUCOM</em>, <em>657</em>, 131586. (<a href='https://doi.org/10.1016/j.neucom.2025.131586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning has emerged as a crucial research direction in the field of computer vision, offering improved performance and efficiency across multiple tasks. Recent studies have incorporated prompt learning into multi-task learning to enhance the interaction between prompt vectors and image representations. However, these studies fail to consider the inter-task and intra-task relations of prompt vectors under multi-task scenarios. To address this issue, we propose learning Generic and Specific Prompts (GSPrompt) with contrastive constraints for multi-task visual scene understanding. Our approach assumes that each task possesses both commonality and individuality, leading us to design two distinct types of prompt vectors: task-generic prompts and task-specific prompts. By constraining the prompt vectors through pulling task-generic prompts and pushing task-specific prompts, we enable multi-task models to learn prompts capable of adapting to multiple tasks simultaneously. Extensive experiments on NYUD-v2, PASCAL-Context, and Cityscapes show that GSPrompt learns effective prompts and achieves state-of-the-art performance. The code is publicly available at https://github.com/teeyohan/GSPrompt-main .},
  archive      = {J_NEUCOM},
  author       = {Tianyu Han and Zhimin Xu and Wanying Li and Haohao Hu and Xinxin He and Song He and Peng Zan and Xiaochen Bo},
  doi          = {10.1016/j.neucom.2025.131586},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131586},
  shortjournal = {Neurocomputing},
  title        = {Learning generic and specific prompts with contrastive constraints for multi-task visual scene understanding},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-based passenger head detection for carriage crowd density estimation. <em>NEUCOM</em>, <em>657</em>, 131584. (<a href='https://doi.org/10.1016/j.neucom.2025.131584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carriage crowd density monitoring is a key component in developing intelligent transportation systems, such as maglev transportation system. Surveillance images captured by sensors, such as carriage monitoring cameras, serve as a new solution for estimating crowd density inside the carriage due to their wide coverage and real-time updates. In this study, a passenger head detection dataset (PHD) is developed using 3717 images acquired from carriage surveillance. Based on these images, over 67,215 head instances are precisely annotated manually. To address the issue of insufficient feature fusion in existing detection algorithms, an efficient cross-scale feature enhancement (CFE) module is proposed and introduced into the advanced YoloX model. The PHD dataset is, to the best of our knowledge, the first public dataset of surveillance images for carriage crowd density estimation. To prove the usability of the PHD dataset and the validity of the proposed method, 12 different versions of detectors are applied and compared. The results demonstrate the performance of these algorithms in the detection of passenger heads. Our research offers a new approach for carriage crowd density estimation. The dataset is publicly available at: https://github.com/Xujiajing111/PHD .},
  archive      = {J_NEUCOM},
  author       = {Jiajing Xu and Mingda Zhai and Yuan Tian and Jun Wu},
  doi          = {10.1016/j.neucom.2025.131584},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131584},
  shortjournal = {Neurocomputing},
  title        = {Vision-based passenger head detection for carriage crowd density estimation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSTGT: Multi-scale spatio-temporal guidance for visual tracking. <em>NEUCOM</em>, <em>657</em>, 131583. (<a href='https://doi.org/10.1016/j.neucom.2025.131583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing the challenge of target tracking in complex scenarios with limited data samples is a highly significant research endeavor. Nevertheless, most trackers primarily concentrate on intricate model architectures or template updating strategies, overlooking the depth of training sample exploitation and the efficient utilization of spatio-temporal target information. To alleviate the above problem, we propose a novel visual tracking framework tailored for complex scenarios, named MSTGT, which integrates mixed data sampling with multi-scale spatio-temporal guidance. Specifically, we innovatively employ a video sequence sampling and feature mixing strategy to simulate complex scenarios, enhancing the representation of video sequences. Concurrently, our multi-scale visual cue encoder harnesses multi-scale target information to fortify feature representation and cue construction. Furthermore, our multi-scale spatio-temporal guidance encoder, a groundbreaking approach, seamlessly integrates spatial and temporal dimensions with multi-scale information, precisely guiding the prediction of target trajectories. This not only bolsters the handling of intricate motion patterns but also circumvents the need for intricate online updating strategies. MSTGT achieves SOTA performance on six benchmarks, while running at real-time speed. Code is available at https://github.com/capf-2011/MSTGT .},
  archive      = {J_NEUCOM},
  author       = {Fei Pan and Lianyu Zhao and Chenglin Wang and Chunlei Du and Xiaolei Zhao},
  doi          = {10.1016/j.neucom.2025.131583},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131583},
  shortjournal = {Neurocomputing},
  title        = {MSTGT: Multi-scale spatio-temporal guidance for visual tracking},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WaterBox: Weakly supervised underwater instance segmentation and a new benchmark. <em>NEUCOM</em>, <em>657</em>, 131582. (<a href='https://doi.org/10.1016/j.neucom.2025.131582'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Box-supervised instance segmentation has gained increasing attention due to its reliance on weak box annotations, which are considerably less expensive than pixel-wise mask annotations. Despite the advantage, existing methods in this category often struggle in complex underwater scenes, where degraded image quality causes foreground objects to become heavily entangled with the background. To address this issue, we propose WaterBox, a cost-effective box-supervised underwater instance segmentation method. Considering the intrinsic characteristics of underwater imaging, we introduce a novel pairwise loss function that leverages a mixed color affinity map with a dynamic threshold to effectively disambiguate foreground and background boundaries. Additionally, we devise a bounding box refinement strategy that generates tight and accurate bounding boxes for each instance, alleviating the negative impact of imprecise box annotations on segmentation performance. Furthermore, to fill in the gaps caused by data scarcity, we construct the first diver instance segmentation dataset, DSeg, which consists of 2000 underwater images with high-quality instance masks. Extensive experiments on two underwater datasets demonstrate the superiority of our approach over the state-of-the-art (SOTA) weakly supervised methods. The code and dataset will be made publicly available.},
  archive      = {J_NEUCOM},
  author       = {Meng Wu and Yifeng Cui and Rong Min and Shanghang Jiang and Lei Zhang and Jing Yu},
  doi          = {10.1016/j.neucom.2025.131582},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131582},
  shortjournal = {Neurocomputing},
  title        = {WaterBox: Weakly supervised underwater instance segmentation and a new benchmark},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-client GAN-based backdoor attacks for asynchronous federated learning. <em>NEUCOM</em>, <em>657</em>, 131580. (<a href='https://doi.org/10.1016/j.neucom.2025.131580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) enables distributed collaborative training while preserving data privacy; however, it demonstrates significant vulnerability to backdoor attacks. Existing attack methodologies predominantly require control of numerous malicious clients to achieve efficacy and largely neglect asynchronous FL scenarios. In response to these limitations, we propose a novel GAN-based backdoor attack framework capable of injecting effective and covert backdoors with minimal malicious client participation, functioning efficiently across both synchronous and asynchronous environments. Our framework operates effectively with a single malicious client, eliminating the need for coordination among multiple adversarial participants or prior knowledge of benign client data distributions. This reduction in resource requirements enhances the framework's practicality in real-world FL implementations. The malicious client employs a Generative Adversarial Network to synthesize adversarial samples containing predefined triggers, which are subsequently incorporated into local training datasets. The concurrent training on legitimate and triggered data enhances attack effectiveness, while gradient injection—manipulating differences between local and global gradients to introduce strategic noise—facilitates backdoor embedding with improved stealth characteristics. Empirical evaluations demonstrate that in a configuration of 200 clients with a single attacker, our framework achieves attack success rates of 98.66 % on MNIST and 86.29 % on CIFAR-10 datasets. Comprehensive experimentation across both datasets substantiates the framework's effectiveness, imperceptibility, and resilience in synchronous and asynchronous FL environments. This research contributes significant insights into backdoor attack strategies in FL, particularly within asynchronous contexts, and underscores the imperative for developing robust defensive countermeasures.},
  archive      = {J_NEUCOM},
  author       = {Siyu Guan and Chunguang Huang and Hai Cheng},
  doi          = {10.1016/j.neucom.2025.131580},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131580},
  shortjournal = {Neurocomputing},
  title        = {Single-client GAN-based backdoor attacks for asynchronous federated learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UA-PDFL: A personalized approach for decentralized federated learning. <em>NEUCOM</em>, <em>657</em>, 131579. (<a href='https://doi.org/10.1016/j.neucom.2025.131579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a privacy preserving machine learning paradigm designed to collaboratively learn a global model without data leakage. Specifically, in a typical FL system, the central server solely functions as a coordinator to iteratively aggregate the collected local models trained by each client, potentially introducing single-point transmission bottleneck and security threats. To mitigate this issue, decentralized federated learning (DFL) has been proposed, where all participating clients engage in peer-to-peer communication without a central server. Nonetheless, DFL still suffers from training degradation as FL does due to the non-independent and identically distributed (non-IID) nature of client data. And incorporating personalization layers into DFL may be one of the most effective solutions to alleviate the side effects caused by non-IID data. Therefore, in this paper, we propose a novel unit representation aided personalized decentralized federated learning framework, named UA-PDFL, to deal with the non-IID challenge in DFL. By adaptively adjusting the level of personalization layers through the guidance of the unit representation, UA-PDFL is able to address the varying degrees of data skew. Based on this scheme, client-wise dropout and layer-wise personalization are proposed to further enhance the learning performance of DFL. Extensive experiments empirically prove the effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Zhu and Yuxiang Fan and Zhenping Xie},
  doi          = {10.1016/j.neucom.2025.131579},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131579},
  shortjournal = {Neurocomputing},
  title        = {UA-PDFL: A personalized approach for decentralized federated learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning interpretable dynamics: Influence-based clustering of energy consumption time series. <em>NEUCOM</em>, <em>657</em>, 131578. (<a href='https://doi.org/10.1016/j.neucom.2025.131578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy consumption is governed by dynamic temporal patterns, context, and user behavior. Traditional clustering methods, often operating on raw data, struggle to capture evolving feature relationships and provide interpretable subgroup definitions. To overcome these limitations, we propose a novel framework, Dynamic Influence-Based Clustering , that leverages explainable machine learning (XML) to transform time-series data into an interpretable influence space. Unlike existing approaches that apply XML post-hoc or treat clustering and explanation separately, our framework is the first to jointly optimize influence representation generation and dynamic clustering within a unified mathematical framework. In this space, each data point is represented by a vector of feature contributions to an energy usage prediction, estimated using robust attribution methods such as SHAP or Integrated Gradients applied to predictive models like gradient boosting machines or neural networks. We then introduce a dynamic clustering algorithm that optimizes a composite objective balancing cluster cohesion in the influence space with novel constraints for temporal continuity and contextual alignment—capabilities entirely absent from existing clustering methods. This integrated design enables the robust detection of evolving consumer subgroups and facilitates subgroup transition analysis and anomaly detection. Extensive experiments on two real-world energy datasets demonstrate that our framework produces demonstrably more interpretable, stable, and coherent clusters compared to both standard clustering on raw features and state-of-the-art time-series clustering baselines. The proposed framework provides actionable insights into dynamic energy usage and offers a rigorous foundation for developing interpretable learning systems in time-sensitive domains.},
  archive      = {J_NEUCOM},
  author       = {Binbin Li and Xiufeng Liu and Rongfei Ma and Yuhao Ma},
  doi          = {10.1016/j.neucom.2025.131578},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131578},
  shortjournal = {Neurocomputing},
  title        = {Learning interpretable dynamics: Influence-based clustering of energy consumption time series},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Face clustering using a novel density peaks clustering algorithm. <em>NEUCOM</em>, <em>657</em>, 131576. (<a href='https://doi.org/10.1016/j.neucom.2025.131576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face clustering remains a challenging task due to the high intra-class variability and uneven density distributions inherent in real-world face datasets. These characteristics often undermine the performance of conventional clustering algorithms. To address these limitations, this paper introduces a novel density-based clustering method, termed DPC-MK (Density Peak Clustering with Mixed k-Nearest Neighbor strategy). Initially, the reverse nearest neighbors and shared nearest neighbors of each sample are identified based on the k-nearest neighbor (KNN) method, and their counts are quantitatively assessed. Subsequently, the distances between each sample and its k-nearest neighbors are computed to evaluate their respective contributions to the local density. The quantified reverse and shared neighbor counts are then integrated with the distance-based density metric to yield an enhanced local density estimate. Using this refined density, the relative distance between each sample and any other point with higher density is computed. A decision graph is then constructed from the modified local density and relative distance values to identify cluster centers. Finally, non-center points are assigned to clusters by following density gradients toward their nearest higher-density neighbors. The results of the ablation study clearly demonstrate the complementary roles of each component as well as the effectiveness of the method we proposed. The efficacy of DPC-MK is further validated on multiple UCI benchmark datasets and public face clustering datasets. Comparative evaluations against baseline and state-of-the-art algorithms—including K-means, DBSCAN, FCM, DPC, DPC-KNN, DPC-NN, DPC-FWSN, and LPMNN-DPC—demonstrate that DPC-MK achieves superior clustering performance and maintains robustness across diverse clustering scenarios and varying cluster counts, highlighting its strong generalization capability.},
  archive      = {J_NEUCOM},
  author       = {Yu Zhou and Jiaoyang Cheng and Jianqiao Long and Jiguang Li and Jiaqing Li and Jichun Li},
  doi          = {10.1016/j.neucom.2025.131576},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131576},
  shortjournal = {Neurocomputing},
  title        = {Face clustering using a novel density peaks clustering algorithm},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel two-stage hybrid feature selection: Exploiting ubiquitous intrinsic feature groups. <em>NEUCOM</em>, <em>657</em>, 131574. (<a href='https://doi.org/10.1016/j.neucom.2025.131574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) has emerged as an important data pre-processing technology to solve the challenging task of data mining. However, most existing FS methods primarily focus on exploiting the independent contributions provided by individual features, while neglecting the critical contributions inherent in ubiquitous intrinsic feature groups. As a result, they may fail to fully capture the potentially valuable information embedded in data. This issue becomes more pronounced in modern large-scale data environments, such as JointCloud, where cross-organizational collaborative data analysis over non-shared datasets is often required. To address this issue, this paper proposes a N ovel T wo- S tage H ybrid FS approach (NTSHFS) that jointly considers the informative contributions of both individual features and collaborative feature groups, enabling a comprehensive evaluation of feature relevance, redundancy and discriminative capability. In the first stage, the correlation coefficient-based co-association matrix (CC-CAM) is developed to ensemble the results obtained by different univariate and structured regularization techniques. Then, a CC-CAM-based embedded FS is proposed to select and rank representative features, achieving strong relevance prioritization and redundancy elimination. In the second stage, a quasi fuzzy-rough set (QFRS) model is designed by integrating the similarity relations at both individual-feature level and multi-feature level through the intersection operation. Based on this model, a QFRS-based filter FS is presented to determine the final feature subset with stronger discriminative capability using internal rankings of feature groups. Experimental results on 24 datasets demonstrate that the proposed approach typically outperforms the compared methods (i.e., achieving an average classification accuracy improvement ranging from 1.77 % to 7.69 %), highlighting its effectiveness, robustness and generalization in data mining.},
  archive      = {J_NEUCOM},
  author       = {Lin Qiu and Xingwei Wang and Bo Yi and Yanpeng Qu and Min Huang and Kaimin Zhang},
  doi          = {10.1016/j.neucom.2025.131574},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131574},
  shortjournal = {Neurocomputing},
  title        = {A novel two-stage hybrid feature selection: Exploiting ubiquitous intrinsic feature groups},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view semi-supervised feature selection with multi-order similarity and tensor learning. <em>NEUCOM</em>, <em>657</em>, 131573. (<a href='https://doi.org/10.1016/j.neucom.2025.131573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view data has attracted extensive attention because it can better characterize samples, and multi-view semi-supervised feature selection can not only effectively improve multi-view performance, but also maintain the original real structure of the data. To this end, many scholars have proposed various models to achieve this goal. However, most of the existing methods rely on the graph structure constructed from the original data and use the constructed graph as a guide for feature selection. This not only ignores multi-order domain knowledge, but also ignores the high-order relations between views. Therefore, this study effectively integrates multi-order domain information with graph learning, and performs tensor low-rank learning on the graph structure between multiple views. A multi-view semi-supervised feature selection method based on multi-order similarity and tensor learning is proposed, which not only integrates multi-order domain information, but also takes into account the relationship between views. Based on this, we propose an iterative method to solve the objective function and prove the superiority of our method on multiple basic datasets.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Chen and Xijiong Xie and Yujie Xiong},
  doi          = {10.1016/j.neucom.2025.131573},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131573},
  shortjournal = {Neurocomputing},
  title        = {Multi-view semi-supervised feature selection with multi-order similarity and tensor learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection via risk-bound utility maximization. <em>NEUCOM</em>, <em>657</em>, 131572. (<a href='https://doi.org/10.1016/j.neucom.2025.131572'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultimate goal of supervised feature selection is to identify a feature subset that minimizes classification risk. Contemporary methods, however, often rely on heuristic or model-dependent proxy criteria that lack a direct theoretical connection to this fundamental objective. To bridge this gap, we introduce a new feature selection framework that directly optimizes a model-agnostic utility function grounded in statistical learning theory. Our approach defines the utility of a feature subset based on the 1-Wasserstein distance between class-conditional distributions. This metric is theoretically powerful as it can be used to construct an upper bound on the Bayes classification error, allowing us to construct a utility function that is a direct surrogate for this risk bound. We instantiate this framework with a subset search strategy that effectively captures feature interactions by maximizing this risk-bound utility. Extensive experiments on real-world datasets demonstrate that our method not only achieves state-of-the-art classification performance but also demonstrates superior robustness and interpretability, providing a principled and powerful alternative to traditional feature selection methods, confirming our framework’s theoretical soundness.},
  archive      = {J_NEUCOM},
  author       = {Chunxu Cao and Qiang Zhang},
  doi          = {10.1016/j.neucom.2025.131572},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131572},
  shortjournal = {Neurocomputing},
  title        = {Feature selection via risk-bound utility maximization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projected variable three-term conjugate gradient algorithm for enhancing generalization performance in deep neural network training. <em>NEUCOM</em>, <em>657</em>, 131568. (<a href='https://doi.org/10.1016/j.neucom.2025.131568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning optimization faces a fundamental trade-off between convergence efficiency and generalization. First-order methods such as stochastic gradient descent (SGD) and adaptive moment estimation (Adam) tend to find flatter minima but converge slowly, while higher-order methods converge rapidly but are often drawn to sharp minima that generalize poorly. To address this, we introduce the projected variable three-term conjugate gradient (PVTTCG) algorithm. Motivated by the geometric instabilities in modern networks that use techniques such as batch normalization (BN), PVTTCG integrates an orthogonal projection into the higher-order optimization framework. This mechanism eliminates radial components from the search direction, inherently guiding the optimization toward flatter regions without requiring additional regularization terms or hyperparameters. The effectiveness of PVTTCG is validated across diverse tasks, including language modeling, large-scale image classification, and a real-world engineering application. In complex scenarios, PVTTCG consistently improves upon its higher-order baseline, achieving up to a 3.92 percentage point gain on CIFAR-100 while remaining competitive with leading first-order methods. A systematic analysis reveals that PVTTCG demonstrates superior robustness to batch size variations, particularly excelling at larger batch sizes. This robustness enables the algorithm to process batch sizes up to 2,048 in engineering applications, achieving a 35.9% test loss reduction compared to Adam. These findings establish PVTTCG as an effective solution for bridging the convergence-generalization trade-off.},
  archive      = {J_NEUCOM},
  author       = {Sanghyuk Kim and Hansu Kim and Namwoo Kang and Tae Hee Lee},
  doi          = {10.1016/j.neucom.2025.131568},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131568},
  shortjournal = {Neurocomputing},
  title        = {Projected variable three-term conjugate gradient algorithm for enhancing generalization performance in deep neural network training},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DVC2: Deep video cascade clustering from video structures. <em>NEUCOM</em>, <em>657</em>, 131565. (<a href='https://doi.org/10.1016/j.neucom.2025.131565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video clustering is a critical unsupervised learning task, where category labels are unavailable, unlike in supervised video classification. The primary challenge is learning meaningful video representations without annotations to effectively group similar videos. Most existing methods extract frame-level features and apply standard clustering algorithms such as K-means, but they often fail to capture temporal relationships inherent in video data. In this paper, we introduce Deep Video Cascade Clustering ( DVC 2 ), a novel unsupervised video learning paradigm. Unlike image-based clustering methods, DVC 2 first learns an initial video representation through frame clustering, which serves as guidance, and then aligns video clustering results with both long-term and short-term structures as well as nearest neighbors. We evaluate DVC 2 on benchmark datasets, including UCF101 and Kinetics-400, achieving state-of-the-art results. Notably, even in annotation-free scenarios where self-supervised learning with K-means already yields reasonable clustering, DVC 2 demonstrates significantly superior performance.},
  archive      = {J_NEUCOM},
  author       = {Zihua Wang and Siya Mi and Yu Zhang},
  doi          = {10.1016/j.neucom.2025.131565},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131565},
  shortjournal = {Neurocomputing},
  title        = {DVC2: Deep video cascade clustering from video structures},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SiFH: Siamese frequency harmonization self-supervised learning for motion forecasting. <em>NEUCOM</em>, <em>657</em>, 131563. (<a href='https://doi.org/10.1016/j.neucom.2025.131563'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion forecasting is a fundamental component of the autonomous driving system and plays an important role in ensuring safety. While supervised learning methods have achieved promising performance in many domains, their model capacity is typically limited by the availability of annotated data. Some previous works have tried to introduce this paradigm into motion forecasting. However, these early studies neglect the task-specific characteristics. To address this, we incorporate two key insights into motion forecasting tasks within the self-supervised paradigm and propose a novel self-supervised motion forecasting framework. First, we design a Frequency Information Harmonization pretext task that explicitly encourages the model to integrate frequency domain features with their time domain counterparts, making them work harmoniously. Second, we introduce an Implicit Scene Alignment task, which enables the model to learn scene-level semantics by aligning masked and unmasked views through shared prototypes. By jointly optimizing these objectives, the model is encouraged to leverage abundant unlabeled data and capture rich spatio-temporal representations. Extensive experiments conducted on the challenging Argoverse 2 and Argoverse 1 benchmarks demonstrate that our proposed model outperforms previous state-of-the-art baselines and can produce more accurate and reliable predictions.},
  archive      = {J_NEUCOM},
  author       = {Chunyu Liu and Zeyu Liu and Tiechui Yao and Shijie Li},
  doi          = {10.1016/j.neucom.2025.131563},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131563},
  shortjournal = {Neurocomputing},
  title        = {SiFH: Siamese frequency harmonization self-supervised learning for motion forecasting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RosMS-ECDBTM: Efficient channel attention enabled distributed deep learning model for mental state detection using EEG signal. <em>NEUCOM</em>, <em>657</em>, 131559. (<a href='https://doi.org/10.1016/j.neucom.2025.131559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, mental stress is emerging as a common social problem triggering different health disorders, including nervousness, heart attacks, strokes, and depression. Specifically, the Electroencephalography (EEG) signal, capable of reflecting the variations in brain activity, is highly used for mental state detection. Despite their promising performance, the existing EEG-based detection methods fail to capture the inherent characteristics of highly intricate and nonstationary EEG signals. In order to address the drawbacks of existing methods, this research proposes the Deep Learning model namely, Rosmarus Migrative Search Optimized Efficient channel attention enabled Distributed Bi-directional Long Short-Term Memory (RosMS-ECDBTM) model for precise mental state detection. More specifically, the efficient channel attention facilitates the proposed model to dynamically highlight the important parts of the signal characteristics while suppressing the irrelevant regions. Besides, the distributed DL architecture improves the learning capability and scalability of the proposed model to process the large datasets, through the parallel processing of sequential data. Further, the proposed approach exploits the Rosmarus Migrative Search Optimization (RosMS) algorithm for optimizing the RosMS-ECDBTM architecture, resulting in improving the training process. Ultimately, the proposed model, combining efficient channel attention and distributed learning mechanism, captures the intricate patterns and reduces the computational complexity of mental state detection. In addition, the Hybrid Discrete Wavelet transform (DWT) approach decomposes the EEG signal into several frequency components for capturing the hidden patterns and anomalous states in the EEG signal, providing key insights for improving the mental state detection. Extensive experiments show that the RosMS-ECDBTM method provides superior performance, achieving a high accuracy of 96.78 %, precision of 98.99 %, recall of 95.91 %, and F1-score of 97.42 % for the Mental Stress Detection dataset compared to other state-of-the-art methods. Ultimately, these findings reveal the high learning efficiency of the proposed deep learning approach in enhancing the mental state detection accuracy, significantly contributing to advancing the field of mental health monitoring.},
  archive      = {J_NEUCOM},
  author       = {Mandar Nitin Kakade},
  doi          = {10.1016/j.neucom.2025.131559},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131559},
  shortjournal = {Neurocomputing},
  title        = {RosMS-ECDBTM: Efficient channel attention enabled distributed deep learning model for mental state detection using EEG signal},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient semantic segmentation of remote sensing images through dynamic feature enhancement and multimodal alignment fusion. <em>NEUCOM</em>, <em>657</em>, 131555. (<a href='https://doi.org/10.1016/j.neucom.2025.131555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion has shown promising applications in integrating information from different modalities. However, existing multimodal fusion approaches in remote sensing face two main challenges: First, multimodal fusion models relying on Convolutional Neural Networks (CNNs) or Visual Transformers (ViTs) have limitations in terms of remote modeling capabilities and computational complexity, while state-space model (SSM)-based fusion models are prone to feature redundancy due to the use of multiple scanning paths, and similarly suffer from high computational complexity. Second, existing methods do not fully address inter-modal heterogeneity, leading to poor multimodal data fusion. To address these issues, we propose an efficient multimodal fusion network, AFMamba, based on the state-space model (SSM) for semantic segmentation of remote sensing images. Specifically, we design the Efficient Dynamic Visual State Space (EDVSS) module, which enhances the efficiency of the standard Mamba model by dynamically improving local features and reducing channel redundancy. Furthermore, we introduce the Cross Attention Alignment Fusion (CAAFM) module, which combines cross-image attention fusion and channel interaction alignment to effectively improve the accuracy and efficiency of cross-modal feature fusion and mitigate feature inconsistency. Experimental results demonstrate that in multimodal hyperspectral image semantic segmentation, the proposed model reduces computational complexity, measured in GFLOPs, by at least 61 % while maintaining a low parameter count, achieving optimal overall accuracy (OA) of around 92 %, and effectively balancing performance and computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {Wenqian Chen and Wendie Yue and Kai Chang and Hongzhi Wang and Kaijun Tan and Xinyu Liu and Xiaoyi Cao},
  doi          = {10.1016/j.neucom.2025.131555},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131555},
  shortjournal = {Neurocomputing},
  title        = {Efficient semantic segmentation of remote sensing images through dynamic feature enhancement and multimodal alignment fusion},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-step minimax Q-learning algorithm for two-player zero-sum markov games. <em>NEUCOM</em>, <em>657</em>, 131552. (<a href='https://doi.org/10.1016/j.neucom.2025.131552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An interesting iterative procedure is proposed to solve two-player zero-sum Markov games. Under suitable assumptions, the boundedness of the proposed iterates is obtained theoretically. Using results from stochastic approximation, the almost sure convergence of the proposed multi-step minimax Q-learning is obtained theoretically. More specifically, the proposed algorithm converges to the game theoretic optimal value with probability one, when the model information is not known. Numerical simulations authenticate that the proposed algorithm is effective and easy to implement.},
  archive      = {J_NEUCOM},
  author       = {Shreyas S.R. and Antony Vijesh},
  doi          = {10.1016/j.neucom.2025.131552},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131552},
  shortjournal = {Neurocomputing},
  title        = {A multi-step minimax Q-learning algorithm for two-player zero-sum markov games},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained multi-agent evasion using deep reinforcement learning. <em>NEUCOM</em>, <em>657</em>, 131550. (<a href='https://doi.org/10.1016/j.neucom.2025.131550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing effective evasion strategies in pursuit–evasion scenarios is challenging, particularly when the pursuer’s model is unknown and inaccessible. This limitation hinders the application of conventional evasion policy design methods. To overcome this challenge, especially when evaders have constrained maneuverability against unrestricted pursuers, we propose a novel multi-agent evasion algorithm based on deep reinforcement learning. Our approach employs a staged learning framework, progressively guiding evaders from simpler to more complex tasks to refine their evasion strategies. Crucially, our algorithm enables evaders to infer pursuers’ intentions even without prior knowledge of pursuers’ objectives, allowing for optimal decision-making despite mobility constraints. Simulation results demonstrate that our method significantly enhances evasion success, validating the effectiveness of learning-based strategies. Additionally, the algorithm exhibits strong adaptability to environmental changes, ensuring reliable performance across diverse pursuit–evasion scenarios.},
  archive      = {J_NEUCOM},
  author       = {Bowei Yan and Runle Du and Xiaojun Ban and Di Zhou},
  doi          = {10.1016/j.neucom.2025.131550},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131550},
  shortjournal = {Neurocomputing},
  title        = {Constrained multi-agent evasion using deep reinforcement learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STD-explain: Generalizing explanations for spatio-temporal graph convolutional networks based on spatio-temporal decoupled perturbation. <em>NEUCOM</em>, <em>657</em>, 131539. (<a href='https://doi.org/10.1016/j.neucom.2025.131539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph convolutional networks utilize an alternating combination of one-dimensional ordinary convolution and graph convolution to extract spatio-temporal features. This alternation intertwines temporal and spatial features closely, leading to a tight coupling between them. The presence of spatio-temporal coupling complicates the analysis of spatio-temporal data, posing challenges for existing explainability algorithms to effectively separate and interpret these intertwined features. Therefore, we propose STD-Explain, an explainable algorithm based on spatio-temporal decoupled perturbation, which employs a two-stage perturbation approach considering subgraph and node-level explanations. Firstly, targeting the spatio-temporal coupling issue in spatio-temporal graph convolutional networks, the algorithm proposes a temporal perturbation algorithm based on Slice Graph and a spatial perturbation algorithm aimed at important subgraph node features. Secondly, to avoid introducing additional semantic information when extracting temporal subgraphs, we propose a method for generating temporal subgraphs in spatio-temporal decoupling, slicing human skeleton sequences with discrete masks to ensure each subsequence maintains spatial structure integrity without introducing additional edges. Furthermore, to ensure the maximum correlation between the interpreted subgraphs and model predictions, we propose a temporal important subgraph discrimination strategy to select the most relevant subgraphs to model predictions. Experimental results demonstrate that STD-Explain performs well in qualitative and quantitative analysis.},
  archive      = {J_NEUCOM},
  author       = {Yanshan Li and Ting Shi and Suixuan He and Zhiyuan Chen and Li Zhang and Rui Yu and Weixin Xie},
  doi          = {10.1016/j.neucom.2025.131539},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131539},
  shortjournal = {Neurocomputing},
  title        = {STD-explain: Generalizing explanations for spatio-temporal graph convolutional networks based on spatio-temporal decoupled perturbation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MGSA: Enhancing transferability of multimodal adversarial attacks via multi-granularity semantic alignment. <em>NEUCOM</em>, <em>657</em>, 131534. (<a href='https://doi.org/10.1016/j.neucom.2025.131534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision–language pretraining (VLP) models have demonstrated exceptional performance across a wide range of image–text multimodal tasks. Despite their prominence, research confirms that these systems retain significant susceptibility to adversarial manipulation. Existing multimodal adversarial attack methods often fail to fully exploit sample-specific semantic structures, resulting in suboptimal cross-modal alignment and limited transferability of adversarial examples. To overcome this limitation, we propose MGSA—a Multi-Granularity Semantic Alignment Attack framework that enhances adversarial perturbation transferability by jointly disrupting cross-modal semantics at both global and fine-grained levels. MGSA captures coarse-grained alignment using overall representations and fine-grained correspondence by selectively aggregating key image regions and words based on importance. This dual-level joint optimization effectively perturbs both holistic consistency and detailed correspondences, thereby significantly enhancing attack effectiveness in white-box scenarios and transferability to black-box models. Extensive experiments conducted across diverse model architectures and multimodal tasks demonstrate that our method achieves strong performance in white-box settings while significantly improving black-box attack success rates. The results highlight the vulnerability of current VLP models and the effectiveness of our approach in generating transferable and semantically grounded adversarial examples.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Liu and Haohua Zhou and Zhidong Shen and Hui Sun},
  doi          = {10.1016/j.neucom.2025.131534},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131534},
  shortjournal = {Neurocomputing},
  title        = {MGSA: Enhancing transferability of multimodal adversarial attacks via multi-granularity semantic alignment},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). StrongerCenter: Enhancing TransCenter for robust multi-object tracking. <em>NEUCOM</em>, <em>657</em>, 131527. (<a href='https://doi.org/10.1016/j.neucom.2025.131527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based multi-object tracking (MOT) research has made significant progress. The typical representative TransCenter method performs well by combining transformers and center-based object tracking. However, it only focuses on predicting object center coordinates, ignoring scale prediction and ReID. To address these limitations, a novel StrongerCenter framework incorporating motion prediction and ReID is proposed in this paper. To enhance spatial contextual feature representation, we first propose an Enhanced Multi-scale Attention Track Memory (EMATM) module. This module incorporates Convolutional Block Attention Module (CBAM) and deformable convolution for improved feature extraction. Then, a Kalman-Guided Motion Prediction module is designed to estimate the state of objects in scenarios involving non-linear motion, scale variations, or occlusion. To ensure robust long-term tracking under occlusion, we develop a ReID module with detail enhancement that captures both local and global features. Finally, a data association strategy that incorporates awareness of occlusion and cascade matching is designed to further improve the robustness of tracking. Extensive experimental results confirm the advantages of our method on the MOT17 and MOT20 datasets. The comparative results demonstrate that the proposed model outperforms comparable methods. Especially on the MOT17 dataset, our method has improved by 9.5 % in IDF1 and 5.2 % in HOTA.},
  archive      = {J_NEUCOM},
  author       = {Xiangzeng Liu and Heng Liu and Kailai Wang and Bocheng Zhao and Qiguang Miao},
  doi          = {10.1016/j.neucom.2025.131527},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131527},
  shortjournal = {Neurocomputing},
  title        = {StrongerCenter: Enhancing TransCenter for robust multi-object tracking},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Urban multi-domain mixing (UMDMix) based unsupervised domain adaptation for LiDAR semantic segmentation. <em>NEUCOM</em>, <em>657</em>, 131526. (<a href='https://doi.org/10.1016/j.neucom.2025.131526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D semantic maps generated from Light Detection and Ranging (LiDAR) point clouds enable scene understanding in diverse applications such as autonomous driving and urban planning. However, existing deep learning models struggle when tested on different domains, worsened by limited labeled data. Unsupervised Domain Adaptation (UDA) can bridge this gap, but existing UDA methods often face adaptation challenges due to domain shifts arising from variations in the physical environment, data sparsity, and sensor differences. To address these limitations, we propose UMDMix , a novel UDA architecture that operates on the mixing of multiple labeled source domains with unlabeled target domains to make the predictive model robust to cross-domain variations. UMDMix integrates a teacher–student learning scheme to produce a robust teacher model and an adaptable student model. The performance of the teacher model in the source domain is further strengthened by a position-aware loss that assigns greater significance to semantically rich neighborhoods. A combination of entropy regularization and KL-divergence loss in the target domain updates the knowledge of the teacher model to the student model during adaptation. Our extensive experiments across diverse environments show that UMDMix achieves an average improvement of 13 % on minor classes such as bicycle, traffic sign, and person in target domain datasets, outperforming previous State-Of-The-Art (SOTA) UDA methods.},
  archive      = {J_NEUCOM},
  author       = {Anurag Nihal and Pyare Lal and Vaibhav Kumar},
  doi          = {10.1016/j.neucom.2025.131526},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131526},
  shortjournal = {Neurocomputing},
  title        = {Urban multi-domain mixing (UMDMix) based unsupervised domain adaptation for LiDAR semantic segmentation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixtures of posterior and prior variational autoencoders for representation learning and cluster analysis in latent space. <em>NEUCOM</em>, <em>657</em>, 131524. (<a href='https://doi.org/10.1016/j.neucom.2025.131524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster analysis aims to identify groups of similar items within an unlabelled dataset. This is particularly challenging in high-dimensional data, necessitating the finding of hidden or latent structure within the data, for which variational methods have proven to be successful. We introduce a generative model based on the variational autoencoder (VAE) that uses a mixture distribution for both the prior and variational posterior components over the latent variables. This pair of distributions means that the algorithm can better capture the underlying structure of the data. We evaluated clustering performance on a set of benchmark datasets. Our proposed model demonstrates superior clustering performance compared with state-of-the-art deep clustering algorithms, as well as demonstrating reasonable reconstruction performance and generation of realistic examples from the latent space.},
  archive      = {J_NEUCOM},
  author       = {Mashfiqul Huq Chowdhury and Yuichi Hirose and Stephen Marsland and Yuan Yao},
  doi          = {10.1016/j.neucom.2025.131524},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131524},
  shortjournal = {Neurocomputing},
  title        = {Mixtures of posterior and prior variational autoencoders for representation learning and cluster analysis in latent space},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-enhanced asymmetric prescribed performance control for multi-task cooperative navigation of USVs via an adaptive formation structure. <em>NEUCOM</em>, <em>657</em>, 131521. (<a href='https://doi.org/10.1016/j.neucom.2025.131521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a prescribed performance control algorithm with asymmetric boundary for Unmanned Surface Vehicle (USV) formation to achieve cooperative navigation under marine disturbances. The proposed algorithm consists of a guidance switching mechanism and a robust adaptive control method. In the improved guidance principle, a velocity correction rule is provided to generate accurate reference signals for USVs during path following. Combined with the guidance term, the communication load between controller and actuator is significantly reduced by employing the Dynamic Event-Triggered Mechanism (DETM) with adaptive updating of threshold parameters. By integrating the initial errors into the performance boundary function, the controller can effectively adapt to different initial states. In addition, due to the smooth property of the shifting function, the error oscillation of the system before steady state is effectively suppressed. The Radial Basis Function Neural Networks (RBF-NNs) are utilized to design damping terms, enhancing the anti-interference capability in marine environments and mitigating the effects of nonlinearities in the model. Through the Lyapunov theorem, the Semi-Globally Uniformly Ultimately Bounded (SGUUB) stability of all state variables is guaranteed. Finally, quantitative validation of the algorithm is performed through numerical simulations and comparative analysis. The results demonstrate a control accuracy within 0.5 meters while showing that, compared to Static Event-Triggering Mechanisms (SETM), the DETM reduces control update frequency for surge force and yawing moment by 12.32 % and 18.78 %, respectively.},
  archive      = {J_NEUCOM},
  author       = {Guoqing Zhang and Junji Feng and Shilin Yin and Matthew Montebello},
  doi          = {10.1016/j.neucom.2025.131521},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131521},
  shortjournal = {Neurocomputing},
  title        = {Neural network-enhanced asymmetric prescribed performance control for multi-task cooperative navigation of USVs via an adaptive formation structure},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding neural networks with logarithm determinant entropy estimator. <em>NEUCOM</em>, <em>657</em>, 131520. (<a href='https://doi.org/10.1016/j.neucom.2025.131520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring entropy and entropy-based informative functionals plays a vital role in many aspects of modern machine learning. However, recent practices find that the commonly used entropy estimators are often ineffective in handling samples with high dimensions. Meanwhile, many of them are expensive in computation and storage. These challenges have severely limited the design of information theory-based methods in machine learning. To address this, we proposed the L o g D e t estimator – a reliable matrix-based entropy estimator based on the logarithm determinant of the statistical quantities. We construct informative functionals of multivariate samples and design tests to ensure they are free from saturation problems in high dimensions. Besides, our method scales linearly in storage with the same computational complexity as the recently proposed α - R e ´ n y i entropy, which makes it more suitable for real-world practices of modern machine learning, such as neural network analysis, feature selection and design optimisation objectives. For application, we utilise this method to analyse the informative behaviour of neural networks, which provides a novel empirical interpretation of neural networks’ Information Bottleneck Theory.},
  archive      = {J_NEUCOM},
  author       = {Zhanghao Zhouyin and Ding Liu},
  doi          = {10.1016/j.neucom.2025.131520},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131520},
  shortjournal = {Neurocomputing},
  title        = {Understanding neural networks with logarithm determinant entropy estimator},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wavelet-RNN: A randomized neural network with wavelet-transform-based feature extension. <em>NEUCOM</em>, <em>657</em>, 131515. (<a href='https://doi.org/10.1016/j.neucom.2025.131515'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random vector functional link (RVFL) network is a leading shallow randomized neural network (RNN) known for its simple architecture and fast training. However, conventional RVFL networks have limited capacity to capture localized and multi-scale features, which restricts their effectiveness in modeling complex data patterns. Moreover, their dependence on random feature mappings often leads to suboptimal representations, especially in real-world datasets. To overcome these limitations, we introduce the Wavelet-transformed RVFL network (Wavelet-RNN), which integrates wavelet decomposition to enhance feature extraction. By leveraging wavelet transformation, our model effectively captures both spatial and frequency-domain information, improving generalization and robustness. This approach enables a more accurate representation of localized patterns and multi-scale structures, which conventional RVFL networks often overlook. To assess the effectiveness of the proposed Wavelet-RNN, we conduct extensive empirical studies on 20 binary and 20 multiclass real-world datasets from the UCI repository. Experimental results demonstrate that Wavelet-RNN consistently outperforms both standard RVFL and state-of-the-art RNN variants, showcasing superior robustness and effectiveness across diverse datasets.},
  archive      = {J_NEUCOM},
  author       = {Manoj Kumar Singh and Prakrut Moon},
  doi          = {10.1016/j.neucom.2025.131515},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131515},
  shortjournal = {Neurocomputing},
  title        = {Wavelet-RNN: A randomized neural network with wavelet-transform-based feature extension},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mine-SSD: Dual-threshold set abstraction and radius-adaptive grouping for 3D object detection in open-pit mines. <em>NEUCOM</em>, <em>657</em>, 131507. (<a href='https://doi.org/10.1016/j.neucom.2025.131507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient 3D object detection is essential for ensuring both safety and operational efficiency in open-pit mines. Due to complex scene structures, broad perception ranges, and significant object size variations, existing point-based 3D detection methods face challenges that limit their applicability in open-pit mines. To address these issues, Mine-SSD, a single-stage 3D object detection method, is developed with dual-threshold set abstraction (DT-SA) and a radius-adaptive grouping mechanism. Specifically, a dual-head self-correlation module is introduced to calculate comprehensive importance scores for each point, enhancing the model’s ability to prioritize key features. Using these importance scores, a dual-threshold self-correlative farthest point sampling (DTSC-FPS) method is applied to retain key non-local information points during downsampling in set abstraction (SA). Additionally, a radius-adaptive grouping mechanism is designed to dynamically adjust the candidate point aggregation radius, capturing critical features of unconventional objects and supporting multi-scale feature processing. Finally, a novel regression loss function is constructed to improve prediction accuracy and balanced performance across objects of different sizes, ensuring reliable performance of Mine-SSD in multi-scale detection. Extensive experiments on an open-pit mine dataset validate the effectiveness of Mine-SSD.},
  archive      = {J_NEUCOM},
  author       = {Zhongyu Xie and Yuqian Zhao and Fan Zhang and Biao Luo and Wenliu Hu and Tenghai Qiu},
  doi          = {10.1016/j.neucom.2025.131507},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131507},
  shortjournal = {Neurocomputing},
  title        = {Mine-SSD: Dual-threshold set abstraction and radius-adaptive grouping for 3D object detection in open-pit mines},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust multimodal fault diagnosis for rod pumping systems via temporal convolutional network and multi-task learning. <em>NEUCOM</em>, <em>657</em>, 131499. (<a href='https://doi.org/10.1016/j.neucom.2025.131499'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rod pumping systems (RPSs) are crucial components in oil extraction processes, where accurate automatic fault diagnosis, including both fault detection and fault prediction, plays a pivotal role in ensuring operational efficiency. Existing diagnostic approaches often exhibit limited adaptability to complex and varying operating conditions. To address this limitation, a novel method is proposed based on a multimodal multitask temporal fusion model (MMTF). This approach integrates multimodal information and uses a temporal convolutional network (TCN), effectively capturing long-range temporal dependencies while improving continuity. The model is constructed under a multitask learning framework, featuring a cascaded structure that enables joint learning of detection and prediction tasks. Validation on archival data from the Daqing oil field demonstrates that the MMTF model achieves leading performance in both diagnostic tasks and maintains high stability under adversarial scenarios.},
  archive      = {J_NEUCOM},
  author       = {Shichao Li and Peng Zeng and Dongliang Zheng and Liting Zhang and Haibo Cheng},
  doi          = {10.1016/j.neucom.2025.131499},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131499},
  shortjournal = {Neurocomputing},
  title        = {Robust multimodal fault diagnosis for rod pumping systems via temporal convolutional network and multi-task learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRDA: Self-regulating distribution alignment based on prompt learning for unsupervised domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131498. (<a href='https://doi.org/10.1016/j.neucom.2025.131498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although large-scale pre-trained vision–language models (VLMs) exhibit significant potential for cross-domain visual tasks, existing prompt-learning-based unsupervised domain adaptation (UDA) methods suffer from source domain overfitting and target domain performance degradation. This paper experimentally demonstrates that conventional prompt learning exhibits insufficient cross-domain generalization due to optimization being heavily biased toward the source distribution. To address this challenge, we propose a Self-regulating Distribution Alignment (SRDA) framework. Its core innovation is a dual-branch collaborative optimization mechanism that dynamically balances cross-domain semantic alignment with pre-trained knowledge preservation. Specifically, the self-regulating multimodal prompt branch incorporates three constraints: semantic consistency regularization, dual-domain collaborative contrastive regularization, and text semantic diversity enhancement. This design suppresses prompt overfitting to the source domain while preserving CLIP’s zero-shot generalization capability. The cross-domain alignment branch introduces dynamic dual-domain feature bank and Cross-domain Collaborative Dual Attention module, achieving fine-grained local semantic calibration through moving average prototypes and a dual-layer attention mechanism. Extensive experiments validate SRDA’s effectiveness on downstream UDA tasks. The code is available at https://github.com/QYw12/SRDA .},
  archive      = {J_NEUCOM},
  author       = {Yang Qu and Jinlong Shi and Yun Cui and Ao Zhang and Suqin Bai and Ye Lu},
  doi          = {10.1016/j.neucom.2025.131498},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131498},
  shortjournal = {Neurocomputing},
  title        = {SRDA: Self-regulating distribution alignment based on prompt learning for unsupervised domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault-tolerant synchronization of drive-response memristive competitive neural networks with multiple actuator failures. <em>NEUCOM</em>, <em>657</em>, 131489. (<a href='https://doi.org/10.1016/j.neucom.2025.131489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the synchronization of drive-response memristive competitive neural networks (MCNNs) under multiple actuator failures is studied through implementing fault-tolerant control scheme. Unlike previous studies, the actuator failures considered in this paper include both bias and effectiveness failures. To address these challenges, a proper mathematical model is first established to capture the impact of actuator failures on control inputs. Subsequently, several sufficient conditions are deduced by designing an appropriate bilayer fault-tolerant controller and constructing a Lyapunov functional to achieve the global exponential synchronization, finite-time synchronization, fixed-time synchronization and predefined-time synchronization respectively. Additionally, the settling time upper bounds for the proposed synchronization methods are determined. In the end, numerical simulations with analysis and comparison are performed to confirm the validity of the proposed results.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Duan and Yanli Huang and Quang Dan Le and Tse Chiu Wong},
  doi          = {10.1016/j.neucom.2025.131489},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131489},
  shortjournal = {Neurocomputing},
  title        = {Fault-tolerant synchronization of drive-response memristive competitive neural networks with multiple actuator failures},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging hyper-interval granules labeling and local mixed neighborhood entropy for semi-supervised feature selection. <em>NEUCOM</em>, <em>657</em>, 131482. (<a href='https://doi.org/10.1016/j.neucom.2025.131482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real scenarios, most datasets contain only a small number of labeled instances and partial features may be missing. Feature selection based on local neighborhood rough set has received much attention for applications on partially labeled data. However, local neighborhood rough set is susceptible to parameterization and only considers labeled data when evaluating upper and lower approximations. Moreover, training label prediction models and labeling unlabeled instances inevitably introduce labeling errors, which subsequently bias the feature selection results. Based on these topics, in order to fully utilize the unlabeled instances and data with missing features and minimize the negative impact of labeling errors, this paper aims at selecting the informative feature subset from partially labeled data. Firstly, the local neighborhood dependency of partially labeled data is computed based on the local neighborhood rough set. Secondly, an improved hyper-interval granulation and label recovery algorithm based on adaptive local density peak for predicting unlabeled instances is proposed, which is a granular computing-based labeling method, and then the global conditional neighborhood entropy is computed on the completely labeled data. Finally, we develop a semi-supervised feature selection algorithm that combines the local neighborhood dependency and the global conditional neighborhood entropy. Comparative dataset experiments demonstrate superior accuracy of our method with fewer features versus existing semi-supervised algorithms.},
  archive      = {J_NEUCOM},
  author       = {Wenhao Shu and Guojing Liao and Wenbin Qian},
  doi          = {10.1016/j.neucom.2025.131482},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131482},
  shortjournal = {Neurocomputing},
  title        = {Leveraging hyper-interval granules labeling and local mixed neighborhood entropy for semi-supervised feature selection},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label distribution learning with structured manifold subspace. <em>NEUCOM</em>, <em>657</em>, 131481. (<a href='https://doi.org/10.1016/j.neucom.2025.131481'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, label distribution learning (LDL) has been proposed to solve the label ambiguity problem. To alleviate the overwhelming output space of LDL, most of the existing methods explore label correlations at a global or local level through common low-rank assumptions. However, the real-valued label description degrees have more complex correlations, making the low-rank assumption usually not hold. To tackle this issue, the proposed method leverages the label distribution manifold with structured subspaces, aiming for a more compact and accurate output space while preserving the high rank of the label distribution matrix. Specifically, a robust high-order correlation measure for label distributions is defined. Then, we simultaneously infer model parameters and conduct the label subspace clustering through the maximum correlation entropy (MCE) regularization to achieve mutual enhancement. It is further proven that the resulting label correlation matrix exhibits a block-diagonal structure under the assumption of independent subspaces. Extensive experiments on widely used benchmark datasets demonstrate the clear advantages of our proposed algorithm over state-of-the-art LDL methods. The code is accessible at https://github.com/yan-yp/LDL-MCE .},
  archive      = {J_NEUCOM},
  author       = {Yaping Yan and Yunlong Tang and Yongxin Jiang and Songlin Du},
  doi          = {10.1016/j.neucom.2025.131481},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131481},
  shortjournal = {Neurocomputing},
  title        = {Label distribution learning with structured manifold subspace},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double-boundary awareness of shared categories for source-free universal domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131473. (<a href='https://doi.org/10.1016/j.neucom.2025.131473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-Free Universal Domain Adaptation (SF-UniDA) aims to adapt a pre-trained source model to an unlabeled target domain without access to source data or prior knowledge of cross-domain category shifts. Existing methods focus on distinguishing target-private unknown samples and assigning pseudo-labels to known samples across the entire label space, including both shared and source-private categories as pseudo-labels, for self-training. However, this data-aware pseudo-labeling approach could mistakenly assign known samples to either source-private or target-private categories, making it sensitive to category shifts and potentially introducing errors or mislabeling. In this paper, we propose Double-boundary Awareness Domain Adaptation (DADA), a class-aware framework that partitions the target domain pseudo-label space into shared, potential source-private, and target-private categories. By labeling target-private samples as unknown and filtering out misassigned source-private samples, DADA enhances the quality of target samples and the reliability of pseudo-labels. To achieve this, we introduce Double-bounded Shared Categories Refinement (DSCR) module, which refines shared classes by identifying both source- and target-private categories based on prior class probabilities and the entropy distribution. Additionally, we incorporate Class-Aware Discriminative Learning (CADL) to enhance discrimination between shared and target-private samples across domains. Experiments on four benchmarks demonstrate the effectiveness of DADA, with overall H-score gains of 8.2 % in the OPDA scenario on Digit dataset and accuracy gains of 10.6 % in the PDA scenario on VisDA dataset. Code is available at: https://github.com/W2Wzj/DADA .},
  archive      = {J_NEUCOM},
  author       = {Zhijing Wang and Ji Guo and Xu Sun and Yi Luo and Aiguo Chen},
  doi          = {10.1016/j.neucom.2025.131473},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131473},
  shortjournal = {Neurocomputing},
  title        = {Double-boundary awareness of shared categories for source-free universal domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGN: Stochastic guidance network for sim-to-real generalization. <em>NEUCOM</em>, <em>657</em>, 131468. (<a href='https://doi.org/10.1016/j.neucom.2025.131468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant domain differences between synthetic data and real data are a challenging problem for current domain generalized segmentation networks. Therefore, this paper proposes a stochastic guidance network (SGN) for sim-to-real generalization that includes the category reweighting strategy, Multi-scale Feature Fusion Guidance (MSFFG) module and multiple style perturbation modules, which improves the issues caused by the imbalance of the source domain’s sample categories as well as large domain gap. Experimental results show that our SGN can effectively enhance the model’s generalization ability to unseen data. In terms of mean intersection over union (mIoU) metric, compared with SOTA, the SGN improves by 3.86 % and 2.05 % respectively on two real scene-enhanced datasets(Rain_Cityscapes, Foggy_Cityscapes), and an average improvement of 1.48 % on four conventional datasets (BDD100k, Cityscapes, Mapillary, Synthia). Our project can be found at https://githubcom/leo-lab-511/SGN.},
  archive      = {J_NEUCOM},
  author       = {Yao Li and Jinlong Shi and Yun Cui and Dan Xu and Wei Teng and Yan Jiang},
  doi          = {10.1016/j.neucom.2025.131468},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131468},
  shortjournal = {Neurocomputing},
  title        = {SGN: Stochastic guidance network for sim-to-real generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IncGridDBC: Incremental density-based clustering with grid partitioning on streaming data. <em>NEUCOM</em>, <em>657</em>, 131460. (<a href='https://doi.org/10.1016/j.neucom.2025.131460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density-Based Spatial Clustering of Applications with Noise (DBSCAN) is a well-established algorithm, recognized for its ability to discover arbitrarily shaped clusters and detect noise. However, it suffers from a fundamental computational bottleneck in dynamic environments, as new object insertions require reprocessing the entire dataset. This paper proposes a novel method, Incremental Density-Based Clustering with a Grid Graph Structure (IncGridDBC), to address this limitation. The key idea is a grid graph structure, where nodes correspond exclusively to non-empty grid cells that contain objects. This grid graph structure abstracts complex object-level relationships into efficient cell-level connections, enabling IncGridDBC to rapidly identify a minimal subset of potentially affected regions upon a new object insertion. The cluster update process is thereby confined exclusively to this minimal subset, an approach that avoids full dataset scans and significantly reduces computational costs. Importantly, this efficiency gain is not based on approximation; the proposed method guarantees that the final clustering results are identical to those produced by a full re-execution of the standard DBSCAN algorithm. In extensive experiments on six real-world datasets with up to 78 dimensions, IncGridDBC achieved a speedup factor of up to 60 times compared to competing state-of-the-art incremental density-based clustering methods. This experimental validation establishes IncGridDBC as a practical and robust solution for high-performance, real-time analytics in dynamic environments such as the Internet of Things (IoT) and manufacturing.},
  archive      = {J_NEUCOM},
  author       = {Tserenpurev Chuluunsaikhan and Jeong-Hun Kim and Fei Hao and Jong-Hyeok Choi and Aziz Nasridinov},
  doi          = {10.1016/j.neucom.2025.131460},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131460},
  shortjournal = {Neurocomputing},
  title        = {IncGridDBC: Incremental density-based clustering with grid partitioning on streaming data},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disjointed representation learning for better fall recognition. <em>NEUCOM</em>, <em>657</em>, 131451. (<a href='https://doi.org/10.1016/j.neucom.2025.131451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preprocessing video frames to extract the human ROIs has been widely adopted in many fall recognition tasks, demonstrating improved results compared to approaches that use raw frames. Nonetheless, these methods have limitations because the preprocessing is not optimized alongside the fall events classifier. This leads to high dependence on the quality of preprocessed results and consequently, limited generalization for the classifier in complex environments. In this study, we introduce Disjointed Representation Networks (DisJRNet) as a unified method that is capable of learning a general strategy for separating human and background components. We note that our method only needs raw frames without additional preprocessing steps to obtain human ROIs. DisJRNet first explicitly disjoints convolutional feature maps into two independent components “human” and “background”, and then reassembles them. This enables the model to learn the human-background separation process to obtain a balanced representation, which is useful for recognizing fall events as a result. Also, as the proposed model optimizes feature-level human ROI localization along with the classifier, our model learns more general representations about fall-related movements than existing approaches that use preprocessed data. In experiments, we applied our method to R(2+1)D, which is one of the variants of 3D convolutional neural networks, and achieved state-of-the-art performance on fall video benchmark datasets. Furthermore, by comparing Grad-CAMs, we observe that our model effectively separates the two components while paying more attention to the actual movements related to fall events and reducing background influence as intended.},
  archive      = {J_NEUCOM},
  author       = {Hosang Yu and Sangwook Kim and Byungeun Shon and Jungrae Cho and Dongwon Woo and Ho Young Chung and Sungmoon Jeong},
  doi          = {10.1016/j.neucom.2025.131451},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131451},
  shortjournal = {Neurocomputing},
  title        = {Disjointed representation learning for better fall recognition},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdvOT: Oblivious transfer based on generative adversarial networks against multiple attackers. <em>NEUCOM</em>, <em>657</em>, 131449. (<a href='https://doi.org/10.1016/j.neucom.2025.131449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oblivious Transfer (OT) is crucial in various security protocols, as it serves as a privacy-preserving and secure communication protocol. However, traditional OT protocols often necessitate complex encryption algorithms and involve intricate steps. Given the rapid advancements in artificial intelligence, it is imperative to explore the potential of artificial neural networks in simplifying OT protocols while still meeting stringent security and privacy requirements. To this need, we introduce the Adv ersarial O blivious T ransfer (AdvOT) protocol, which integrates OT with the adversarial learning mechanism of Generative Adversarial Network (GAN). Our approach involves training a neural network model to learn encryption techniques through end-to-end adversarial training, thereby eliminating the reliance on specific algorithms. The AdvOT protocol comprises two phases. Firstly, a Random Oblivious Transfer (ROT) protocol is employed to generate and distribute keys based on the CKKS homomorphic encryption algorithm. Subsequently, neural networks are introduced to replace specific symmetric encryption algorithms and encrypt the messages to be transferred. These neural networks undergo training using the adversarial learning mechanism to develop a symmetric encryption algorithm. Furthermore, to enhance the model, attack networks with varying capabilities are created, resulting in a more secure encryption algorithm capable of withstanding multiple attackers. Experimental results demonstrate that the execution speed of the CKKS-based ROT algorithm is significantly faster compared to the BFV and Paillier algorithms. Moreover, in adversarial network models with multiple attackers, the decryption accuracy for the recipient approaches 100 %, while the accuracy or classification error rate for attackers is approximately 50 %. These findings indicate that the proposed method effectively safeguarded communication between parties from interception.},
  archive      = {J_NEUCOM},
  author       = {Yuke Wang and Zhentian Zhong and Ninghao Liu and Xiaohui Li and Junfeng Wang},
  doi          = {10.1016/j.neucom.2025.131449},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131449},
  shortjournal = {Neurocomputing},
  title        = {AdvOT: Oblivious transfer based on generative adversarial networks against multiple attackers},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ColonNeRF: High-fidelity neural reconstruction of long colonoscopy. <em>NEUCOM</em>, <em>657</em>, 131445. (<a href='https://doi.org/10.1016/j.neucom.2025.131445'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colonoscopy is an effective procedure for the detection and prevention of colorectal cancer. A high-quality colonoscopy reconstruction greatly enhances the ability of clinicians to perform a post-reviews, visualize, and detect subtle lesions and colorectal cancer. However, accurate long-sequence colonoscopy reconstruction faces three major challenges: (1) dissimilarity among segments of the colon due to its meandering and convoluted shape, (2) co-existence of more consistent color distribution and intricately folded geometric structures, and (3) sparse viewpoints due to constrained camera trajectories. To tackle these challenges, we introduce a new reconstruction framework based on the neural radiance field, ColonNeRF, for novel view synthesis of long-sequence colonoscopy. Specifically, ColonNeRF introduces a region division and stitching module to reconstruct the entire colon piecewise, overcoming the challenges of shape dissimilarity. To learn both the consistent color distribution and complex geometry in a unified framework, ColonNeRF incorporates a multi-level fusion module that progressively models the colon structure. Additionally, to eliminate the geometric ambiguities from sparse views, we devise a DensiNet module for densifying camera poses under the guidance of semantic consistency. We conduct extensive experiments on synthetic, phantom and real-world datasets to evaluate our ColonNeRF. Quantitatively, ColonNeRF exhibits 49 % increase in LPIPS-ALEX scores on synthetic datasets. Qualitatively, our reconstruction visualizations show much clearer textures and more accurate geometric details. These findings sufficiently demonstrate our superior performance over the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yufei Shi and Beijia Lu and Jia-Wei Liu and Ming Li and Si Yong Yeo and Mike Zheng Shou},
  doi          = {10.1016/j.neucom.2025.131445},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131445},
  shortjournal = {Neurocomputing},
  title        = {ColonNeRF: High-fidelity neural reconstruction of long colonoscopy},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Challenges and advancements in modeling shock fronts with physics-informed neural networks: A review and benchmarking study. <em>NEUCOM</em>, <em>657</em>, 131440. (<a href='https://doi.org/10.1016/j.neucom.2025.131440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving partial differential equations (PDEs) with discontinuous solutions—such as shock waves in multiphase viscous flow in porous media—is critical for a wide range of scientific and engineering applications, as they represent sudden changes in physical quantities. Physics-Informed Neural Networks (PINNs), an approach proposed for solving PDEs, encounter significant challenges when applied to such systems. Accurately solving PDEs with discontinuities using PINNs requires specialized techniques to ensure effective solution accuracy and numerical stability. Various methods have been developed to address the challenges of modeling discontinuities within the PINNs framework. This work reviews and benchmarks these approaches across problems of varying complexity, categorizing them into three broad groups, influencing solution accuracy differently. (1) Physics-modification (PM) methods improve accuracy by modifying the system’s physics, such as adding artificial viscosity or enforcing entropy constraints. (2) Loss and training modification (LM) techniques focus on regularizing the loss landscape, often by refining the loss term in high-error regions. (3) Architecture-modification (AM) approaches, on the other hand, propose advanced network designs to handle discontinuities better. A benchmarking study was conducted on two multiphase flow problems in porous media: the classic Buckley-Leverett (BL) problem and a fully coupled system of equations involving shock waves but with varying levels of solution complexity. The findings show that PM and LM approaches can provide accurate solutions for the BL problem by effectively addressing the infinite gradients associated with shock occurrences. In contrast, AM methods failed to effectively resolve the shock waves. When applied to fully coupled PDEs (with more complex loss landscapes), the generalization error in the solutions quickly increased, highlighting the need for ongoing innovation. This study provides a comprehensive review of existing techniques for managing PDE discontinuities using PINNs, offering information on their strengths and limitations. The results underscore the necessity for further research to improve PINNs’ ability to handle complex discontinuities, particularly in more challenging problems with complex loss landscapes. This includes problems involving higher dimensions or multiphysics systems, where current methods often struggle to maintain accuracy and efficiency.},
  archive      = {J_NEUCOM},
  author       = {Jassem Abbasi and Ameya D. Jagtap and Ben Moseley and Aksel Hiorth and Pål Østebø Andersen},
  doi          = {10.1016/j.neucom.2025.131440},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131440},
  shortjournal = {Neurocomputing},
  title        = {Challenges and advancements in modeling shock fronts with physics-informed neural networks: A review and benchmarking study},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SparseSCIGaussian: Sparse snapshot compressed images 3D gaussian splatting. <em>NEUCOM</em>, <em>657</em>, 131422. (<a href='https://doi.org/10.1016/j.neucom.2025.131422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose SparseSCIGaussian, a novel method for achieving high-quality novel view synthesis under sparse input conditions. Previous methods often rely heavily on depth or neural priors, which can lead to generalization challenges and significant quality degradation on complex datasets. These limitations arise primarily from the insufficient scene information available in sparse regular images. To overcome these issues, our approach utilizes images captured through Snapshot Compressive Imaging (SCI) as input. SCI-captured images inherently encode richer scene information compared to regular images, thereby substantially improving the quality of novel view synthesis under sparse input conditions. Moreover, SCI images can be conveniently captured using a software-implemented encoder, making them as accessible as traditional images. Experimental results demonstrate that our method improves 2.65 dB (13.04 %) in PSNR compared to previous methods, and further exhibits the inherent advantages of using SCI images for sparse input novel view synthesis.},
  archive      = {J_NEUCOM},
  author       = {Haoyuan He and Xuan Wang and Nanning Zheng and Caigui Jiang},
  doi          = {10.1016/j.neucom.2025.131422},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131422},
  shortjournal = {Neurocomputing},
  title        = {SparseSCIGaussian: Sparse snapshot compressed images 3D gaussian splatting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RehearMixup: Improving rehearsal-based continual learning. <em>NEUCOM</em>, <em>657</em>, 131404. (<a href='https://doi.org/10.1016/j.neucom.2025.131404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks often suffer from catastrophic forgetting when learning new tasks, leading to the loss of previously acquired knowledge. To address this issue, rehearsal-based methods have emerged, which involve storing a subset of data from previous tasks and accessing it during the learning of new tasks. Current rehearsal-based methods focus on selecting representative samples to store in memory. However, there is a considerable lack of exploration of how to exploit the data at hand and consider the correlation between tasks or between past and new knowledge to improve performance. Therefore, we propose a simple yet effective approach named RehearMixup that adapts the Mixup technique into rehearsal-based methods, which synthesizes new samples for learning by interpolating data from past or current tasks. Specifically, we introduce three strategies, namely Cross-Mixup , Intra-Memory-Mixup , and Intra-Current-Mixup , based on the inherent characteristics of rehearsal-based methods - involving the memory and new tasks. Through empirical evaluations under various benchmark scenarios, we compare our approach against different rehearsal-based baselines. The results demonstrate that ours, particularly Intra-Current-Mixup , improves accuracy, backward transfer, forward transfer, and enhances the model’s robustness.},
  archive      = {J_NEUCOM},
  author       = {Yan Zhang and Kaiyuan Qi and Dong Wu and Guoqiang Wu and Yilong Yin},
  doi          = {10.1016/j.neucom.2025.131404},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131404},
  shortjournal = {Neurocomputing},
  title        = {RehearMixup: Improving rehearsal-based continual learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A zero-shot high-performance fire detection framework based on large language models. <em>NEUCOM</em>, <em>657</em>, 131403. (<a href='https://doi.org/10.1016/j.neucom.2025.131403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire detection is crucial for minimizing economic damage and safeguarding human lives. Existing methods, including advanced AI and ML techniques, face challenges such as detecting small fires in complex environments and relying on extensive labeled data for training. This paper proposes a novel zero-shot fire detection framework leveraging large language models (LLMs) and contrastive learning-based image–text pre-training models. The framework introduces an enhanced self-attention mechanism for optimizing image embeddings, diverse prompt generation using GPT-3.5 for improved generalization, and a dynamic threshold calculation method based on statistical analysis to enhance detection accuracy and reliability. The proposed method is tested on the public FLAME dataset and a self-collected dataset. Experimental results demonstrate that the proposed method outperforms state-of-the-art models in detecting small fires within complex backgrounds, achieving better detection performance without the need for any training data. This study highlights the potential of zero-shot learning in fire detection and provides a promising solution for real-world fire detection applications.},
  archive      = {J_NEUCOM},
  author       = {Hongyang Zhao and Yi Liu and Yuhang Han and Xingdong Li and Yanan Guo and Jing Jin},
  doi          = {10.1016/j.neucom.2025.131403},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131403},
  shortjournal = {Neurocomputing},
  title        = {A zero-shot high-performance fire detection framework based on large language models},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADMS-LSTM: A multi-scale stacked LSTMs long-term prediction method based on an adaptive decomposition framework with DFT-AutoCorrelation. <em>NEUCOM</em>, <em>657</em>, 131362. (<a href='https://doi.org/10.1016/j.neucom.2025.131362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective long-term forecasting can provide valuable decision-making information and demonstrate significant application value. Because of the difficulty of learning complex time patterns and the accumulation of prediction errors, the current research on long-term forecasting is still limited. In this paper, to capture multi-scale long-term dependencies, a novel framework Discrete Fourier Transform (DFT)-AutoCorrelation Pyramid Decomposition LSTM (ADMS-LSTM) is proposed. ADMS-LSTM mainly includes an adaptive decomposition window analysis module, a pyramid decomposition module, and a prediction-fusion module. First, the adaptive decomposition window analysis module based on DFT and the AutoCorrelation mechanism is designed to select the optimal decomposition window adaptively and provide a reliable theoretical basis for the pyramid decomposition module. Furthermore, multi-scaled information from the pyramid decomposition module is beneficial for mining distant historical dependencies. Finally, in the prediction-fusion module, the complex time patterns are learned and multi-scaled prediction series are fused, to improve the local prediction information and solve the problem of prediction error accumulation. To verify the effectiveness and robustness of the proposed method, six publicly available benchmark datasets are chosen for our experiment. Comparative experimental results show that our proposed method achieves state-of-the-art performance on these datasets compared with other latest methods. The proposed method can effectively alleviate the problem of error accumulation, extract the long-term temporal characteristics, and obtain excellent long-term prediction results. To the best of our knowledge, this is the first work based on rigorous mathematical theory to adaptively select decomposition windows for long-sequence information learning.},
  archive      = {J_NEUCOM},
  author       = {Jinqi Zhao and Haomiao Shang},
  doi          = {10.1016/j.neucom.2025.131362},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131362},
  shortjournal = {Neurocomputing},
  title        = {ADMS-LSTM: A multi-scale stacked LSTMs long-term prediction method based on an adaptive decomposition framework with DFT-AutoCorrelation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hetero-MoE by attention: Three-plus tasks learning solver. <em>NEUCOM</em>, <em>657</em>, 131333. (<a href='https://doi.org/10.1016/j.neucom.2025.131333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) stands as a promising sub-field of machine learning, aiming to simultaneously tackle multiple tasks. By leveraging shared representations and structures across diverse tasks, MTL models often exhibit higher data efficiency compared to single-task models across various domains, including recommender system applications, multi-label classification and other AI applications. However, the efficacy of MTL models is sometimes hindered by the multi-causal task conflict problem. To address this challenge, existing research predominantly focuses on enhancing structural designs and the underlying optimizers. Nevertheless, these approaches often fall short in comprehensively mitigating task conflicts, especially in scenarios involving three or more tasks, such as recommender systems. When shared experts contend with excessive task-related information simultaneously, the effective filtration of potentially harmful knowledge becomes challenging. To this end, we propose a novel Heterogeneous Multi-Expert model with an attention layer, termed HMEA. HMEA introduces Heterogeneous Experts as shared experts to decompose signal connections among three or more tasks. Additionally, it integrates an attention layer to further decouple conflicts among mini-tasks within shared experts. The experiments and ablation studies on various standard and synthetic datasets illustrate the effectiveness of HMEA in alleviating the task conflict problem inherent in three-plus task learning systems.},
  archive      = {J_NEUCOM},
  author       = {Dandan Zhang and Guanqi Zeng and Haotian Wu and Hongwen Zhang and Zheng Ye and Yao Yang},
  doi          = {10.1016/j.neucom.2025.131333},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131333},
  shortjournal = {Neurocomputing},
  title        = {Hetero-MoE by attention: Three-plus tasks learning solver},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). T2-cGAN: A new modeling paradigm for joint DEM spatial interpolation and super-resolution reconstruction. <em>NEUCOM</em>, <em>657</em>, 131181. (<a href='https://doi.org/10.1016/j.neucom.2025.131181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digital elevation model (DEM) has important application value in the fields of geographic information systems, earth sciences, and path planning. However, due to the limitations of high sampling costs and complex terrain, the acquired DEM data often have the problems such as missing sampling points and low resolution. Current solutions treat these issues as highly dependent linear series tasks, and sequentially perform spatial interpolation and super-resolution reconstruction operations, ignoring the correlation and complementarity between them, which leads to a significant difference between the super-resolution reconstruction results and the real terrain. To solve this problem, we proposed the end-to-end T2-cGAN (task transformer conditional generative adversarial network) by combining DEM spatial interpolation and super-resolution reconstruction tasks, which can directly generate high-quality and high-resolution reconstruction results from low-resolution DEM data that are undersampled and contain missing values. This model can make full use of the shared information in the process of spatial interpolation and super-resolution reconstruction, achieve efficient interaction and collaborative optimization of information, and provide a brand-new idea and method for solving the super-resolution reconstruction task of DEM data. Moreover, the experimental results demonstrate that our proposed T2-cGAN can interpolate and complete the DEM data without adding additional information, while also improving the spatial resolution by 4 times. This research not only provides a practical method for high-resolution DEM modeling in resource-constrained areas, but also offers a new idea for the intelligent processing of DEM data, which is of great value for applications such as geological disaster early warning and urban layout planning.},
  archive      = {J_NEUCOM},
  author       = {Ziqiang Huo and Jiabao Wen and Desheng Chen and Meng Xi and Jiachen Yang},
  doi          = {10.1016/j.neucom.2025.131181},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131181},
  shortjournal = {Neurocomputing},
  title        = {T2-cGAN: A new modeling paradigm for joint DEM spatial interpolation and super-resolution reconstruction},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting nonlinear dynamic systems by causal physics-informed neural networks with ResNet blocks. <em>NEUCOM</em>, <em>656</em>, 131589. (<a href='https://doi.org/10.1016/j.neucom.2025.131589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of data computational science, the prediction of nonlinear systems has provided effective support for investigating complex problems in the field of natural sciences. Physics-Informed Neural Networks (PINNs) are playing an increasingly prominent role in nonlinear system prediction. Although PINNs have been widely applied across various engineering domains, their utilization in chaotic system prediction remains notably scarce. This paper proposes a novel causal PINNs framework integrated with ResNet blocks. On the one hand, the framework incorporates temporal weighting into the residual loss, utilizing maximum temporal weight as the training termination criterion. Additionally, an annealing strategy is adopted to adaptively adjust the causal parameters, ensuring that the model adheres to physical causality constraints throughout the training process. On the other hand, the framework employs a ResNet-block-based network, which transforms identity mappings into residual mappings. This architectural design significantly enhances training stability when utilizing deep networks. To validate the performance of the proposed method, numerical experiments are conducted on the Lorenz system, Dadras system, and Kuramoto-Sivashinsky equation. The results demonstrate that the causal PINNs with ResNet blocks significantly outperform conventional PINNs in predicting chaotic systems.},
  archive      = {J_NEUCOM},
  author       = {Man-Hong Fan and Jun-Hao Zhao and Lin Ding and Xiao-Ying Ma and Rui-Lin Fu},
  doi          = {10.1016/j.neucom.2025.131589},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131589},
  shortjournal = {Neurocomputing},
  title        = {Predicting nonlinear dynamic systems by causal physics-informed neural networks with ResNet blocks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-aware fusion for improved video object segmentation. <em>NEUCOM</em>, <em>656</em>, 131585. (<a href='https://doi.org/10.1016/j.neucom.2025.131585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, most mainstream memory-based semi-supervised video object segmentation (VOS) methods rely on pixel-level matching to identify target objects. However, the majority of these approaches depend solely on spatial-domain features for representation, which limits their ability to preserve fine-grained details. In addition, they typically adopt a single bottom-up matching strategy, which lacks sufficient global semantic guidance, ultimately leading to suboptimal segmentation performance. To address these issues, we propose a Frequency-Aware Fusion for Improved Video Object Segmentation algorithm (FAFVOS), which incorporates frequency-domain information enhancement and a bidirectional matching mechanism to improve segmentation accuracy. First, we design a Hierarchical Frequency-Aware Encoder (HFAE), which enhances shallow features by leveraging high-frequency components to preserve edge and texture details, and strengthens deep features via low-frequency components to maintain global structural consistency, thereby achieving multi-scale frequency–spatial feature fusion. Second, a frequency-guided bidirectional matching Transformer module is proposed to establish pixel-level and object-level dual-path interactions. By incorporating a cross-attention mechanism, the model effectively facilitates joint reasoning between local pixel-wise details and global object-level semantics. Finally, a high-order moment refinement module is introduced to integrate high-order statistical features, enhancing the model’s ability to capture object deformation and leading to high-quality segmentation results. The proposed method is evaluated on the DAVIS, YouTube-VOS, and MOSE datasets. Experimental results demonstrate that, without relying on complex pretraining strategies or additional datasets, our approach achieves a real-time inference speed of 56 FPS with a J & F score of 88.5 % on the DAVIS 2017 benchmark, surpassing existing representative methods. Moreover, it also achieves consistently superior performance on the more challenging YouTube-VOS and MOSE datasets, further validating the generalization ability and robustness of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Hou and Hao Cui and Chenxu Wang and Sugang Ma and Xiaobao Yang and Lei Pu},
  doi          = {10.1016/j.neucom.2025.131585},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131585},
  shortjournal = {Neurocomputing},
  title        = {Frequency-aware fusion for improved video object segmentation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Utility-driven free tree mining in graph databases. <em>NEUCOM</em>, <em>656</em>, 131571. (<a href='https://doi.org/10.1016/j.neucom.2025.131571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent subgraph mining is a fundamental task in data mining, widely applied in various domains such as biological networks, social networks, and computing networks. However, existing methods for frequent subgraph mining often rely solely on support as a single metric, considering subgraphs with higher support as more important. This approach overlooks the intrinsic value of subgraphs, such as in citation networks, where users tend to associate with structures related to their own research areas, not only the frequent ones. To address this limitation, we introduce utility pattern mining into the field of subgraph mining. This mining framework considers both the internal and external values of patterns. Additionally, traditional frequent subgraph mining is hindered by isomorphism calculations, including the computational cost of subgraph isomorphism, which is NP-complete. As a connected acyclic graph, free trees play a significant role in fields such as web mining and biology. Their relatively simple structure can significantly reduce the computational cost of subgraph isomorphism calculations. In this paper, we combine utility pattern mining with frequent free tree mining, defining the problem of frequent high utility free tree mining. We design utility upper bounds that satisfy the downward closure property and propose an algorithm, UFTM (utility free tree miner), for effectively and efficiently mining utility free trees. Furthermore, we collect and test our algorithm on four real-world datasets. The results demonstrate that UFTM can discover more valuable patterns and execute the mining task efficiently.},
  archive      = {J_NEUCOM},
  author       = {Zhaoming Chen and Xinyang Chen and Guoting Chen and Wensheng Gan},
  doi          = {10.1016/j.neucom.2025.131571},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131571},
  shortjournal = {Neurocomputing},
  title        = {Utility-driven free tree mining in graph databases},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated machine learning based on decomposition, causality and evolutionary multitask optimization for time series forecasting. <em>NEUCOM</em>, <em>656</em>, 131569. (<a href='https://doi.org/10.1016/j.neucom.2025.131569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting plays a crucial role in various practical domains, serving as a key tool for planning and control by anticipating patterns and identifying potential future anomalies. This practice enables more effective responses to the complex dynamics of systems, typically relying on the ability to predict observations based on historical data. In this regard, the continuous pursuit of ways to enhance forecasting model accuracy is of paramount importance. Working with time series forecasting demands specific technical expertise. While automation strategies exist for these tasks, the universality of such solutions remains a challenge due to the difficulty of incorporating all available models into a single application. In this context, the present study introduces a new AutoML approach based on Decomposition, Causality, and Evolutionary Multitask Optimization for time series forecasting, called AutoDCE-TS. The AutoDCE-TS is a Multiple Input Single Output system, designed with a four-layer structure that automates the processes of feature extraction and selection, model selection and generation, and prediction. It aims to create more explainable pipelines by constructing sub-pipelines to handle each variable of the multivariate time series, as well as the components produced by the decomposition process. For each variable, a causal feature graph is constructed and used as input to an ensemble model based on regression trees. AutoDCE-TS leverages the similarity among variables to simultaneously select models and their hyperparameters for each sub-pipeline, employing a multitask evolutionary optimization strategy. Experiments conducted on 18 datasets, comparing AutoDCE-TS with 10 other methods, revealed its competitiveness, demonstrating that it is a robust and general-purpose method for time series forecasting.},
  archive      = {J_NEUCOM},
  author       = {Patrícia de Oliveira e Lucas and Frederico Gadelha Guimarães and Eduardo M.A.M. Mendes},
  doi          = {10.1016/j.neucom.2025.131569},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131569},
  shortjournal = {Neurocomputing},
  title        = {Automated machine learning based on decomposition, causality and evolutionary multitask optimization for time series forecasting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-stream diffusion graph convolutional model with adaptive motion-aware attention and self-supervised pretraining for continuous sign language recognition. <em>NEUCOM</em>, <em>656</em>, 131567. (<a href='https://doi.org/10.1016/j.neucom.2025.131567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous Sign Language Recognition (CSLR) requires capturing both spatial and temporal dependencies to accurately model sign sequences. To enhance CSLR performance, we propose a Multi-Stream Diffusion Graph Convolution Network (MSD-GCN) from input skeleton data that introduces three key innovations. First, Adaptive Motion-aware Graph Convolution with Bi-level Attention (AMGC-BA) dynamically refines joint connectivity by leveraging semantic motion correlations, improving robustness to signer variations, and enhancing long-term dependencies. Second, signal-enhanced multi-stream representation learning integrates advanced signal processing techniques, including the Adaptive Ridgelet Transform (ART) for pose representation, Variational Mode Decomposition (VMD) for motion decomposition, and Empirical Wavelet Transform (EWT) for contextual feature extraction, ensuring feature robustness, reducing noise, and improving discriminability. Third, self-supervised pretraining leverages contrastive learning, graph reconstruction, and cross-stream feature alignment to mitigate data scarcity, enhance domain adaptation, and improve representation learning. These innovations enable the proposed graph to effectively capture complex motion patterns, distinguish between critical and redundant gestures, and generalize well across diverse signers and datasets. By improving recognition accuracy, robustness, and adaptability, the proposed approach provides a significant advancement in CSLR, addressing the challenges of signer variability, limited labeled data, and the need for fine-grained motion representation. Results on three datasets confirm the superiority of the proposed model compared to 35 comparative models. To the best of our knowledge, this is the first study in CSLR to employ such an extensive range of comparative models for performance evaluation.},
  archive      = {J_NEUCOM},
  author       = {Razieh Rastgoo},
  doi          = {10.1016/j.neucom.2025.131567},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131567},
  shortjournal = {Neurocomputing},
  title        = {A multi-stream diffusion graph convolutional model with adaptive motion-aware attention and self-supervised pretraining for continuous sign language recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGFCNN: A synergistic framework integrating graph-based spatial filter and lightweight CNN for SSVEP recognition. <em>NEUCOM</em>, <em>656</em>, 131561. (<a href='https://doi.org/10.1016/j.neucom.2025.131561'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing the feature representation and decoding efficiency of the steady-state visual evoked potentials (SSVEPs) is critical to enhancing the performance of neural signal decoding systems. Current deep learning models often overlook the physical topological information of EEG channels, resulting in suboptimal feature extraction and limited recognition performance. To address these challenges, this study proposes a synergistically designed SSVEP recognition framework to alleviate data insufficiency, improve the feature representation, and enhance decoding efficiency. Specifically, a slicing-and-scaling technique is adopted to improve the model generalization under limited-sample scenarios. A graph-based spatial filter leverages the topological relationships among EEG channels to suppress redundant information and enhance spatial feature quality. A lightweight convolutional neural network (CNN) with fewer parameters is developed to efficiently extract discriminative temporal–spatial features for accurate SSVEP classification. Experimental results on two public benchmark datasets and one self-collected dataset demonstrate that the proposed framework outperforms baseline deep learning models, yielding improvements of at least 6.8 %, 8.5 %, and 0.5 % in peak average classification accuracy, respectively. The maximum average information transfer rates (ITRs) achieved on the three datasets were 221.4 bits/min ,106.7 bits/min , and 133.9 bits/min , respectively. By simultaneously reducing model complexity and improving decoding performance, the proposed framework offers an effective and promising approach for efficient neural signal decoding in SSVEP recognition.},
  archive      = {J_NEUCOM},
  author       = {Rui Ma and Yu Cao and Sheng Quan Xie and Mingming Zhang and Jun Li and Zhi-Qiang Zhang},
  doi          = {10.1016/j.neucom.2025.131561},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131561},
  shortjournal = {Neurocomputing},
  title        = {LGFCNN: A synergistic framework integrating graph-based spatial filter and lightweight CNN for SSVEP recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double missing multi-view multi-label classification via an attention-guided multi-space consistency alignment framework. <em>NEUCOM</em>, <em>656</em>, 131558. (<a href='https://doi.org/10.1016/j.neucom.2025.131558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view multi-label classification (MVMLC) seeks to enhance classification by integrating diverse data views, but its practical use is hindered by missing views and labels, posing the significant challenge of incomplete MVMLC(IMVMLC). Although various IMVMLC approaches have been proposed, most of them handle multiple objectives in a single feature space and thus overlook the conflict between learning consistent common semantics and reconstructing view-specific information. In addition, existing multi-view classification methods mainly consider utilizing the features of each view, while ignoring the inconsistent contributions of each view and usually relying on static average weighting strategies. To this end, we propose our Attention-Guided MultiSpace Consistency Alignment Framework (AMCA). In Stage 1, AMCA introduces multi-space representation learning with dual-level contrastive objectives, explicitly disentangling shared and view-specific semantics to resolve the objective conflict and yield more informative embeddings. In Stage 2, AMCA employs an attention-guided fusion module that dynamically evaluates and integrates multi-view features based on their relevance to the classification task, enabling robust decision-making even with missing data. Extensive experiments validate the effectiveness and superiority of our proposal.},
  archive      = {J_NEUCOM},
  author       = {Bingyan Nie and Wulin Xie and Lian Zhao and Jiang Long and Xiaohuan Lu and Yinghao Ye},
  doi          = {10.1016/j.neucom.2025.131558},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131558},
  shortjournal = {Neurocomputing},
  title        = {Double missing multi-view multi-label classification via an attention-guided multi-space consistency alignment framework},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end transformer-based detection with density-guided query selection for small objects. <em>NEUCOM</em>, <em>656</em>, 131554. (<a href='https://doi.org/10.1016/j.neucom.2025.131554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small object detection remains a persistent challenge in transformer-based detectors due to their limited localization precision and reliance on fixed query mechanisms. In this paper, we propose Hybrid Density-Transformer (HyDeTr), a novel transformer-based object detection framework designed to improve the detection of small and densely packed objects with only a slight trade-off in inference complexity. HyDeTr introduces several key innovations: (1) a Context-Selective Hybrid Attention Encoder (CS-HAE) that distills global context from low-resolution features through efficient kernelized attention while preserving local detail via deformable attention on higher-resolution maps; (2) a Density Map Prediction module that generates a spatial prior highlighting high-object-density regions, facilitating focus on crowded scenes; (3) a Density-Guided Uncertainty-Minimal Query Selection strategy that identifies the most informative query locations based on both classification confidence and predicted density, ensuring that even low-confidence small objects in dense areas are effectively queried; and (4) an improved Query Formulation with dual embeddings, consisting of a content embedding and a 4D anchor box, refined iteratively by the decoder. Our design enables precise, density-aware query initialization and scale adaptation, leading to improved recall and accuracy for small objects. Extensive evaluations demonstrate that HyDeTr outperforms existing methods in detecting small objects, offering significant accuracy gains with only a modest increase in inference complexity, thereby maintaining near real-time performance and full end-to-end trainability.},
  archive      = {J_NEUCOM},
  author       = {Nguyen Hoanh and Tran Vu Pham},
  doi          = {10.1016/j.neucom.2025.131554},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131554},
  shortjournal = {Neurocomputing},
  title        = {End-to-end transformer-based detection with density-guided query selection for small objects},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel dynamic sparse graph attention framework for cross-domain intelligent diagnosis of rotating machinery. <em>NEUCOM</em>, <em>656</em>, 131553. (<a href='https://doi.org/10.1016/j.neucom.2025.131553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mechanical equipment prognostics, conventional graph neural networks encounter significant limitations when processing high-dimensional dynamic sensor data: inadequate modeling of complex feature interdependencies, insufficient sensitivity to transient fault signatures, and ineffective knowledge transfer in cross-domain applications. To overcome these challenges, we present a DSGA-SAGE, which stands for Dynamic Sparse Graph Attention - SAmpling and aGgrEgation framework. Our approach presents innovations in three aspects: (1) A decentralized graph construction paradigm establishes dynamic associations among multivariate time-series features, enabling precise identification of critical fault patterns through adaptive node-edge interactions. (2) A sparse attention mechanism with trainable topology constraints optimizes the structural weights of graph in the real-time scenarios, achieving 23 % overhead computational reduction while maintaining the accuracy of feature discriminability. (3) A unified cross-domain learning strategy synchronizes multi-condition knowledge transfer through hierarchical loss optimization, ensuring robust generalization across various operational scenarios. Extensive experiments on five industrial datasets demonstrate state-of-the-art performance: achieving the highest accuracy of 96.29 % in fault diagnosis, while realizing 99.87 % Macro-F1 and 99.88 % Micro-F1 scores in cross-domain tasks. Through a comprehensive performance analysis, the superiority of the efficiency and cross-domain adaptability in dynamic sparse graph attention mechanism has been convincingly validated.},
  archive      = {J_NEUCOM},
  author       = {Ying Xie and Jixiang Wang and Zhiqiang Xu and Junnan Shen and Lijie Wen and Rongbin Xu and Yun Yang},
  doi          = {10.1016/j.neucom.2025.131553},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131553},
  shortjournal = {Neurocomputing},
  title        = {A novel dynamic sparse graph attention framework for cross-domain intelligent diagnosis of rotating machinery},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient medical image encryption and attack detection using hyperchaotic fibonacci polynomial convolutional neural network in IoT healthcare networks. <em>NEUCOM</em>, <em>656</em>, 131537. (<a href='https://doi.org/10.1016/j.neucom.2025.131537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the fast expansion of IoT technology in the health-related field, secure transfer of sensitive medical data in general, and of medical images in particular, has become a major concern. Conventional detection and encryption techniques usually cannot guarantee both high security and computational efficiency under strict real-time constraints. To counter the above problems, this research proposed a novel Hyperchaotic Fibonacci Polynomial Convolutional Neural Network with Crayfish Optimization Algorithm (HFPCNN-COA) for increased medical image security in IoT environments. The medical images are first encrypted with Hyperchaotic System-Fibonacci Q Matrix Encryption (HFQE) on a standard collection. After encryption, they are sent over the network. After transmission, the HAPCNN is applied to detect and classify any potential tampering or transmission attacks. The loss function of HAPCNN is optimized with the Crayfish Optimization Algorithm (COA) to increase the detection accuracy and convergence speed. Lastly, cryptanalysis is conducted to measure the system's resilience to attack. The experimental results prove the workability of the proposed framework, with a Peak Signal-to-Noise Ratio (PSNR) of 53 dB, which corresponds to very good retention of image quality. In addition, the proposed method is quite resistant to data manipulation with a 0.4 % Bit Error Rate (BER) and has reasonable processing times with encryption times of 2.87 ms and decryption times of 2.35 ms. This shows that HFPCNN-COA holds a great deal of promise as an actual and secure means for the transfer of medical image data for IoT-based healthcare systems.},
  archive      = {J_NEUCOM},
  author       = {Bhumireddypalli Veerasekharreddy and P. Chinniah and P. Varaprasada Rao and Krishna Prakash Arunachalam},
  doi          = {10.1016/j.neucom.2025.131537},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131537},
  shortjournal = {Neurocomputing},
  title        = {Efficient medical image encryption and attack detection using hyperchaotic fibonacci polynomial convolutional neural network in IoT healthcare networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A collaborative decision framework for dynamic control of gear remaining useful life using multi-source information in active health management. <em>NEUCOM</em>, <em>656</em>, 131536. (<a href='https://doi.org/10.1016/j.neucom.2025.131536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing demand for intelligent operation and maintenance of vertical mill gearboxes in the cement industry, traditional passive maintenance methods are increasingly inadequate for supporting efficient, proactive management under complex operational conditions. In particular, sudden gear failures often result in unplanned downtime, causing significant economic losses. To address this challenge, this paper proposes a dynamic control approach for gear remaining useful life (RUL) that integrates multi-source information through collaborative decision-making to enable active health management. First, a novel RUL prediction method based on multilevel multi-source domain adaptation (MMDA) is proposed to enhance the generalization capability of the model. By minimizing discrepancies between local and global feature distributions under varying working conditions and aligning the prediction boundaries among predictors, the proposed method achieves accurate RUL predictions. Then, a gear RUL dynamic control method based on multi-information collaborative decision-making is developed. This method dynamically regulates gear RUL using a model-free adaptive control (MFAC) strategy, leveraging multi-source information such as online RUL prediction results, expected usage duration, and real-time working conditions. Finally, a collaborative decision framework for dynamic control of gear RUL is proposed, which enables active gear health management to be implemented, thereby minimizing unscheduled downtime. The effectiveness of the proposed gear RUL dynamic control method is validated on a self-made gear transmission system experimental platform, achieving a 27.6 % reduction in average RMSE compared with state-of-the-art baselines and extending the operational life of gear by approximately 61 h under dynamic control.},
  archive      = {J_NEUCOM},
  author       = {Xuegang Li and Yuanyue Pu and Nian Wu and Huajun Cao and Xiaoxi Ding and Wenbin Huang},
  doi          = {10.1016/j.neucom.2025.131536},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131536},
  shortjournal = {Neurocomputing},
  title        = {A collaborative decision framework for dynamic control of gear remaining useful life using multi-source information in active health management},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AttackTracer: Semantic-level adversarial attack location traceability via evidential diffusion model. <em>NEUCOM</em>, <em>656</em>, 131535. (<a href='https://doi.org/10.1016/j.neucom.2025.131535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks pose a significant threat to AI systems, yet existing detection methods mainly focus on image-level threats, limiting fine-grained localization of perturbations. To address this challenge, we propose AttackTracer, the first semantic-level localization framework specifically designed for instance-level adversarial attacks. Instance-level adversarial perturbations are typically sparse and localized, which aligns naturally with the capabilities of diffusion models to progressively reconstruct sparse structures from stochastic noise. Building on this property, AttackTracer models the adversarial mask as a conditional distribution given the adversarial image, allowing iterative refinement and effective recovery of attack regions. To address the inherent instability of diffusion sampling, we introduce the Temporal Evidence Fusion Strategy (TEFS). TEFS integrates Dempster–Shafer theory with a signal-to-noise-ratio (SNR)-guided temporal ensemble, aggregating multi-step predictions to mitigate conflicts and uncertainty, thus achieving robust inference. Furthermore, adversarial perturbations often manifest as subtle high-frequency and edge distortions. To capture these, AttackTracer employs two complementary modules: the Wavelet Frequency Fusion Block (WFFB), which extracts multi-scale frequency features via Discrete Wavelet Transform to enhance sensitivity to sparse perturbations, and the Edge Feature Enhancement Module (EFEM), which models multi-granularity edge structures using parallel branches and FFT to detect boundary distortions. Together, WFFB and EFEM provide complementary views of perturbation patterns. Extensive experiments demonstrate that AttackTracer achieves superior traceability of adversarial regions while maintaining robustness across stochastic sampling and varying scales, highlighting its effectiveness for instance-level attack localization.},
  archive      = {J_NEUCOM},
  author       = {Zhentong Zhang and Xinde Li and Pengfei Zhang and Kui Wang and Tianrong Gao and Tao Shen},
  doi          = {10.1016/j.neucom.2025.131535},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131535},
  shortjournal = {Neurocomputing},
  title        = {AttackTracer: Semantic-level adversarial attack location traceability via evidential diffusion model},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A prototype-guided federated learning based fault diagnosis method of mechanical transmission system under label distribution skew. <em>NEUCOM</em>, <em>656</em>, 131532. (<a href='https://doi.org/10.1016/j.neucom.2025.131532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the label distribution skew in federated learning based mechanical fault diagnosis, a federated learning based diagnosis framework combining prototypes and hybrid classifier is proposed. Firstly, prototypes are constructed based on sample feature means, and an exponential moving average strategy is introduced to smooth the aggregation of prototypes across rounds, while the prototype constraint loss function is constructed to guide the convergence of client features to the global prototype and compress the distance between similar samples. Secondly, a hybrid classifier architecture combining a local classifier with a global prototype classifier is proposed to learn local feature and global class prototypes through a two-branch structure, and a dynamic weighting strategy is used to achieve the output fusion. Finally, a prototype separation strategy is introduced on the server side, which detects pairs of confused class prototypes by Euclidean distance, increases the distance between similar prototypes, and avoids the prototype overlapping issue. In order to verify the effectiveness of the proposed method, nine kinds of faults of bearings, rotors and gears in mechanical transmission system are fabricated, and four types of fault diagnosis experiments with different degrees of label skew are designed, and the results show that the proposed method can effectively identify all the fault classes, and it still achieves an accuracy of 91.00 % in the extreme distribution skew task, which is significantly better than the other comparative methods, which provides a new feasible way for the distributed data driven federated learning based intelligent mechanical fault diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Hongwei Fan and Shenglin Liu and Xiangang Cao and Xuhui Zhang},
  doi          = {10.1016/j.neucom.2025.131532},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131532},
  shortjournal = {Neurocomputing},
  title        = {A prototype-guided federated learning based fault diagnosis method of mechanical transmission system under label distribution skew},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A predefined-time double-integral zeroing neural network model for linear equations flows and its application on dynamic position. <em>NEUCOM</em>, <em>656</em>, 131531. (<a href='https://doi.org/10.1016/j.neucom.2025.131531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving time-varying linear equation flows presents a significant challenge in dynamic systems due to the continuously evolving coefficients, which undermine the effectiveness of traditional numerical methods. Moreover, the presence of external noise further exacerbates the difficulty of obtaining accurate solutions. To address these issues, this paper proposes a predefined-time double-integral zeroing neural network (PTDIZNN) model, inspired by the enhanced robustness of the conventional DIZNN framework. Specifically, a novel time-based gain is incorporated into the design of the DIZNN, ensuring predefined-time convergence of the proposed PTDIZNN model. A comprehensive theoretical analysis is conducted to verify its stability, convergence, and robustness properties. Furthermore, comparative simulations demonstrate that the PTDIZNN outperforms existing models in terms of solution accuracy and robustness under both column-full-rank and square-array coefficient scenarios. Finally, the effectiveness of the PTDIZNN is verified through its successful application in dynamic target positioning, highlighting its potential for broader real-time applications.},
  archive      = {J_NEUCOM},
  author       = {Jialiang Chen and Linju Li and Lin Xiao},
  doi          = {10.1016/j.neucom.2025.131531},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131531},
  shortjournal = {Neurocomputing},
  title        = {A predefined-time double-integral zeroing neural network model for linear equations flows and its application on dynamic position},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAFE-TAP: Semantic-aware and fused embedding for TAP rule security detection. <em>NEUCOM</em>, <em>656</em>, 131529. (<a href='https://doi.org/10.1016/j.neucom.2025.131529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trigger-Action Programming (TAP) has emerged as a widely adopted paradigm for enabling automated interoperability among IoT devices. Despite its convenience, TAP introduces significant security vulnerabilities. To address this issue, we propose SAFE-TAP, a novel framework for detecting malicious TAP rules that integrates global semantic understanding with temporal feature analysis. To further enhance the detection performance, we introduce an innovative data augmentation strategy that leverages Large Language Models (LLMs) to generate semantically consistent rule variations. This approach improves data set balance and enhances the generalizability of the model. Experimental results demonstrate that SAFE-TAP outperforms baseline methods, and the incorporation of LLM-based data augmentation significantly improves detection performance under imbalanced data scenarios.},
  archive      = {J_NEUCOM},
  author       = {Zhejun Kuang and Yusheng Zhu and Dawen Sun and Jian Zhao and Yongheng Xing and Feng Wang and Lei Sun},
  doi          = {10.1016/j.neucom.2025.131529},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131529},
  shortjournal = {Neurocomputing},
  title        = {SAFE-TAP: Semantic-aware and fused embedding for TAP rule security detection},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bipartite contrastive multi-view clustering with singular value modulation. <em>NEUCOM</em>, <em>656</em>, 131528. (<a href='https://doi.org/10.1016/j.neucom.2025.131528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive multi-view clustering (CMvC) has attracted increasing attention for its semantic mining capacity. However, existing CMvC methods often process pairwise views to explore consistency, inevitably ignoring the joint information and inherent redundancy among multiple views. In this paper, we propose a novel Bipartite Contrastive Multi-view Clustering with Singular Value Modulation (BCMVC) that reformulates contrastive learning as a binary classification problem. Specifically, unlike existing pairwise-view sequential processing methods, we construct a correlation learning module that simultaneously mines consistent information across multiple views. This module effectively explores joint information at both the instance level and category level, with each level equipped with a dedicated correlation learner. By leveraging the concat and random shuffle strategy to encapsulate the positive and negative sample sets, the level-specific correlation learner is effectively optimized to enhance the discrimination of samples. Meanwhile, a deep singular value weighting module is introduced to refine the learned representations through a weighted singular value reconstruction strategy, mitigating the adverse effects of noisy information. Extensive experiments on seven benchmark datasets demonstrate that our method achieves substantial advancements compared with other state-of-the-art approaches. The code is available at https://github.com/zhangt-make/BCMVC .},
  archive      = {J_NEUCOM},
  author       = {Teng Zhang and Pengyuan Li and Zisen Kong and Dongxia Chang and Yao Zhao},
  doi          = {10.1016/j.neucom.2025.131528},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131528},
  shortjournal = {Neurocomputing},
  title        = {Bipartite contrastive multi-view clustering with singular value modulation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The framework and memristive circuit design for attention-regulated working memory. <em>NEUCOM</em>, <em>656</em>, 131525. (<a href='https://doi.org/10.1016/j.neucom.2025.131525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive behavior and decision-making depend on constantly selecting relevant information from the external environment and internal states. Inspired by the working memory structure and the top-down and bottom-up attention mechanisms in cognitive neuroscience, this work proposes an attention-regulated working memory model. This model provides a brain-inspired approach to integrate perception, long-term memory, and action. It processes current external multisensory stimuli and retrieves stored knowledge from internal reinforcement simultaneously, leading to adaptive and rapid executive actions. On this basis, a memristive circuit is designed to realize rich cognitive functions in an online in-situ learning and in-memory computing manner. The designed circuit consists of four main components: (1) the phonological loop and visuospatial sketchpad consider different audio-visual input patterns and varying stimulus salience, realizing the filtration, synchronization, and encoding of multimodal signals; (2) the attention control module captures and maintains attention driven by multisensory stimulation; (3) the episodic buffer achieves reward reinforcement, forming or resetting the top-down attentional bias signal; (4) the central executive control module regulates the relationships between the two attentional pathways, thus transforming the random exploration process into a learnable final action. Finally, simulation results in LTSPICE demonstrate that our circuit can be adaptively applied to the cognitive control and execution system of robots within complicated circumstances.},
  archive      = {J_NEUCOM},
  author       = {Jihong Zhang and Xiaoping Wang and Zhanfei Chen and Chao Yang},
  doi          = {10.1016/j.neucom.2025.131525},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131525},
  shortjournal = {Neurocomputing},
  title        = {The framework and memristive circuit design for attention-regulated working memory},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A temporally coded multilayer spiking neural network and its memristor-based hardware implementation. <em>NEUCOM</em>, <em>656</em>, 131523. (<a href='https://doi.org/10.1016/j.neucom.2025.131523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) have demonstrated remarkable progress in various domains. However, ANNs suffer from enormous time and energy consumption during training and inference processes. Brain-inspired spiking neural networks (SNNs) have recently attracted more attention due to their higher biological plausibility and potential cost-efficient properties. However, most existing SNNs significantly degrade in performance and efficiency when simulated on conventional CPU/GPU hardware. Therefore, a novel temporally coded multilayer SNN (TMSNN) is proposed in this study. It is a typical event-driven model, which encodes information in the relative timing of spikes rather than in firing rates and uses the leaky integrate-and-fire neuron as the basic unit to pursue high biological plausibility. Its multilayer architecture enables the model to solve complicated problems effectively. On the other hand, the proposed TMSNN can be implemented on memristor-based hardware, which uses customized weight quantization and sharing techniques to mitigate the size restrictions of the memristor crossbars. After refining the weights using the simulated annealing algorithm, the hardware implementation of TMSNN can achieve very competitive performance on benchmark datasets, outperforming state-of-the-art temporally coded SNNs in our experiments. The source code of TMSNN is available at https://github.com/jhc050998/Memristor-Crossbar-Based-SNN .},
  archive      = {J_NEUCOM},
  author       = {Haochang Jin and Xiuzhi Yang and Shuangbao Song and Zhenyu Song and Junkai Ji},
  doi          = {10.1016/j.neucom.2025.131523},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131523},
  shortjournal = {Neurocomputing},
  title        = {A temporally coded multilayer spiking neural network and its memristor-based hardware implementation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential extended dissipative synchronization control of Cohen–Grossberg neural networks with four kinds of time-varying delays. <em>NEUCOM</em>, <em>656</em>, 131522. (<a href='https://doi.org/10.1016/j.neucom.2025.131522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the exponential extended dissipative synchronization control problem of Cohen–Grossberg neural networks (CGNNs) with four kinds of time-varying delays. The types of delays involve time-varying leakage, neutral, distributed and transmission delays. Due to the increasing complexity of control requirements and time delays in practice, some performance analysis approaches and techniques cannot be directly applied, or are faced with the problem of high computational complexity. To this end, a more general and computationally efficient novel method is proposed. Firstly, a sufficient condition to guarantee the existence and uniqueness of the solution of CGNN is presented by defining a new norm, and a representation of the unique solution is first put forward. Then, the state-feedback controller and novel system solutions-based inequality are constructed to obtain exponential extended dissipative synchronization criteria. This proposed approach overcomes the difficulty of constructing a suitable Lyapunov–Krasovskii functional (LKF) under complex time delays and control requirements, and reduces computational complexity. Furthermore, to solve the nonlinear terms in the obtained criteria, an algorithm is designed. Finally, the derived results are validated for feasibility by three numerical examples, and their potential applications in image processing are showcased.},
  archive      = {J_NEUCOM},
  author       = {Kairong Tu and Yu Xue},
  doi          = {10.1016/j.neucom.2025.131522},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131522},
  shortjournal = {Neurocomputing},
  title        = {Exponential extended dissipative synchronization control of Cohen–Grossberg neural networks with four kinds of time-varying delays},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A rate-dependent coreset selector for continual learning on time-varying data distributions. <em>NEUCOM</em>, <em>656</em>, 131519. (<a href='https://doi.org/10.1016/j.neucom.2025.131519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we review the concept of “phase” defined in Class-Incremental Learning (CIL), i.e., learning new classes while not forgetting old ones. Due to this design, classic CIL algorithms are mostly offline or can handle only intensive data distribution shifts across the phases. However, real-world data streams are often online, usually with uncertain or untraceable changes in their data distributions. To this end, we design the per-step distribution shifts by modeling the class sampling weights using bell-shaped curves. Such a design respects the rise-and-fall nature and presents realistic but underexplored challenges for CIL: 1) The data non-stationarity across steps requires the models to identify the recent dynamics and adopt an appropriate learning strategy for knowledge memorization and adaptation. 2) Over all steps, the proposed streams exhibit various class-imbalance patterns , with different majority classes and time-varying imbalance ratios. To address the challenges, we propose a novel Rate-Dependent Coreset Selector (RDCS), which essentially presents an adaptive and robust sample selection criterion when constructing memory for replay. We conduct extensive experiments by generating the proposed data streams on multiple image benchmarks and implementing RDCS in an efficient approximation, showing its superior performance.},
  archive      = {J_NEUCOM},
  author       = {Zilin Luo and Zichen Tian and Yaoyao Liu and Qianru Sun},
  doi          = {10.1016/j.neucom.2025.131519},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131519},
  shortjournal = {Neurocomputing},
  title        = {A rate-dependent coreset selector for continual learning on time-varying data distributions},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MLFork: Bearing fault diagnosis via mamba-powered few-shot learning model with multi-level architecture enhanced by spatial-wise and channel-wise local vector attention. <em>NEUCOM</em>, <em>656</em>, 131518. (<a href='https://doi.org/10.1016/j.neucom.2025.131518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearings are one of the most important components of electrical machines and devices; however, they are prone to damage, leading to the lack of safety and the malfunction of machines. Some methods including deep-learning ones can be used for bearing fault diagnosis; however, in reality, the models have to adapt to the shortage of training data from clients while still maintaining good performance. To overcome this issue, the novel “MLFork” model is proposed, following the Few-shot algorithm for limited training with improvements in the feature extraction and the pre-classification steps. For feature extraction, a new Bi-Context Visual State Space Block is introduced, which excellently learns the global context of the sample in multiple ways. Before the Multi-Level classification module, separate routes for spatial-wise and channel-wise local vector attention are used to highlight the important details of the local descriptor. To evaluate the performance of the model, various experiments were done on the Case Western Reserve University dataset (CWRU) and the Paderborn University dataset (PU), where the “MLFork" model showed promising results. The code for this model will be available at: https://github.com/thzhere/MLFork .},
  archive      = {J_NEUCOM},
  author       = {Duy-Thai Nguyen and Van-Quoc-Viet Nguyen and Thi-Thao Tran and Van-Truong Pham},
  doi          = {10.1016/j.neucom.2025.131518},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131518},
  shortjournal = {Neurocomputing},
  title        = {MLFork: Bearing fault diagnosis via mamba-powered few-shot learning model with multi-level architecture enhanced by spatial-wise and channel-wise local vector attention},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). All-in-one image restoration via diffusion models with degradation perception and semantic enhancement. <em>NEUCOM</em>, <em>656</em>, 131517. (<a href='https://doi.org/10.1016/j.neucom.2025.131517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration is a fundamental task in computer vision. However, most existing methods are tailored for single-degradation scenarios, limiting their applicability in real-world conditions where multiple degradations often co-occur. To address this issue, we propose a degradation-aware image restoration framework. A bidirectional Mamba module is introduced to process fused spatial-frequency features, enabling accurate identification of degradation types via a multi-degradation encoding strategy. Based on the predicted degradation, a fine-tuned CLIP model with an attention mechanism is employed to extract semantic features. These features are then integrated with degradation representations and fed into a conditional denoising diffusion model to progressively reconstruct high-quality images. To facilitate evaluation, we construct the Multi-Degradation Perception Dataset (MDPD), specifically designed for complex degradation scenarios. Experimental results demonstrate that our method achieves over 98 % classification accuracy in identifying degradation types. On the MDPD dataset, it achieves a PSNR of 36.25 dB and improves SSIM by 0.01 to 0.04 across various degradation combinations.},
  archive      = {J_NEUCOM},
  author       = {Jiangang Jiang and Zhe Chen and Yuxin Su and Pancheng Zhang and Yihui Hu},
  doi          = {10.1016/j.neucom.2025.131517},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131517},
  shortjournal = {Neurocomputing},
  title        = {All-in-one image restoration via diffusion models with degradation perception and semantic enhancement},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural operator-based composite learning adaptive backstepping control for linear 2×2 hyperbolic PDE systems. <em>NEUCOM</em>, <em>656</em>, 131516. (<a href='https://doi.org/10.1016/j.neucom.2025.131516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel neural operator (NO)-based composite learning adaptive backstepping control scheme for stabilizing uncertain linear 2 × 2 hyperbolic PDE systems. This method addresses key challenges arising from complex PDE dynamics, model uncertainties, and high computational costs, within a backstepping design framework. Our approach integrates two main components: 1) A composite learning adaptive controller, which combines both historical and real-time data to construct informative matrices for parameter updates. This strategy enables accurate and exponential parameter convergence under finite excitation (FE) conditions, thereby improving transient performance and guaranteeing exponential system stability. 2) An efficient NO-based approximation method, where a deep operator network (DeepONet) is trained to approximate the nonlinear mapping from composite parameter estimates to backstepping kernel gains. The controller is constructed using the approximate kernels, which eliminates the need to repeatedly solve kernel PDE online, significantly improving the computational efficiency and accelerating real-time control. Furthermore, theoretical analysis proves closed-loop boundedness and exponential stability under the proposed scheme. Numerical simulations verify its effectiveness and superiority.},
  archive      = {J_NEUCOM},
  author       = {Xianhe Zhang and Yu Xiao and Xiaodong Xu and Biao Luo and Weihua Gui and Tingwen Huang},
  doi          = {10.1016/j.neucom.2025.131516},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131516},
  shortjournal = {Neurocomputing},
  title        = {Neural operator-based composite learning adaptive backstepping control for linear 2×2 hyperbolic PDE systems},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RAG-LER: Ranking adapted generation with language-model enabled regulation. <em>NEUCOM</em>, <em>656</em>, 131514. (<a href='https://doi.org/10.1016/j.neucom.2025.131514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have demonstrated impressive capabilities across diverse NLP tasks, yet they still struggle with hallucination due to limited parametric knowledge. Retrieval Augmented Generation (RAG) addresses this issue by integrating non-parametric data stores. However, straightforward integration of information retrieval or end-to-end training of these components often leads to suboptimal results or computational inefficiency. In this work, we introduce RAG-LER, a framework that enhances an LM’s context understanding and improves the quality and accuracy of provided passages through an LM-supervised re-ranker. RAG-LER fine-tunes a pre-trained LM to follow instructions and discriminately use provided information. It then leverages this fine-tuned LM to generate ranking scores, which serve as supervised labels for training the re-ranker. We also introduce a confidence-weighted objective that filters unreliable LLM supervision signals while preserving the original re-ranker capabilities. By harnessing LLMs’ strong capabilities, our approach eliminates the need for manual human labeling in re-ranker training while achieving improved performance. Experiments demonstrate that RAG-LER outperforms existing retrieval-augmented LMs on open-domain QA and fact-checking tasks, while exhibiting consistently improved performance when applied to different retrieval methods, highlighting its versatility and effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Fengwen Zhai and Wenyang Tang and Jing Jin},
  doi          = {10.1016/j.neucom.2025.131514},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131514},
  shortjournal = {Neurocomputing},
  title        = {RAG-LER: Ranking adapted generation with language-model enabled regulation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TalkingAvatar: Learning 3D talking human avatar via NeRF. <em>NEUCOM</em>, <em>656</em>, 131513. (<a href='https://doi.org/10.1016/j.neucom.2025.131513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable progress in 3D talking head generation, directly generating expressive upper-body 3D talking avatars that integrate realistic talking heads and lifelike bodies remains challenging. To address these issues, a novel TalkingAvatar is proposed to reconstruct vivid avatars from dynamic monocular videos while endowing them with expressive animation capabilities. Given audio and SMPL-X pose sequences, TalkingAvatar can animate 3D human avatars with lip-synced mouth movements and complex hand gestures. Specifically, TalkingAvatar utilizes a fast deformer for articulated neural fields (Fast-SNARF) to optimize human volumetric representations in a canonical T-pose. It also incorporates a novel Hybrid Modulation Attention Module (HMAM) that focuses on capturing dynamic movements. Additionally, a UV feature map is used for detailed static texture learning. Notably, HMAM leverages a modulation mechanism to exploit comprehensive dynamic motion information from both body pose and speech audio, ensuring expressive control of mouth and hands. Moreover, to minimize interference between different body parts, TalkingAvatar adopts a part-aware learning strategy that employs multiple regional grids to model the head, hands, and body areas separately. This strategy significantly enhances the fidelity of small-scale body regions. Experiments demonstrate that our method outperforms the state-of-the-art in both avatar reconstruction and animation of mouth and hand movements, generating high-fidelity co-speech gesture videos, while requiring significantly less training data.},
  archive      = {J_NEUCOM},
  author       = {Lingyun Yu and Chuang Chen and Chuanbin Liu and Wu Liu and Quanwei Yang and Yizhi Liu and Meng Shao},
  doi          = {10.1016/j.neucom.2025.131513},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131513},
  shortjournal = {Neurocomputing},
  title        = {TalkingAvatar: Learning 3D talking human avatar via NeRF},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental algorithms on low-rank approximation of large-scale kernel matrices based on perturbation of invariant subspaces. <em>NEUCOM</em>, <em>656</em>, 131512. (<a href='https://doi.org/10.1016/j.neucom.2025.131512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel methods are one of the most commonly used techniques in machine learning. In Mitz and Shkolnisky (2022) [27] , a framework of perturbation-based kernel matrix approximation is proposed, which is based on the tool of matrix perturbation analysis. However, there are two shortcomings in this framework. First, it requires that some dominant eigenvalues of kernel matrices are distinct in theory. However, in practical applications, when using a randomly sampled dataset, some kernel matrices generated by certain kernel functions are prone to having multiple eigenvalues due to data distribution or parameter settings. Second, from the algorithmic perspective, one has to know the error matrix of the kernel matrix in advance, which is unrealistic for real-world applications. Thus, the most common situation in practical applications is to pay attention to the case of multiple eigenvalues, and it is interesting to generalize the original perturbation-based kernel approximation framework to the scenario where there are multiple eigenvalues. In this work, we present a perturbation result on eigenvalues and eigenspaces of a kernel matrix whose dominant eigenvalues can be multiple. Based on this result, we propose a low-rank approximation to kernel matrix. On the other hand, as far as we are aware, efficient algorithms are still lacking for updating large-scale kernel matrices, and there are few algorithms addressing batch-incremental kernel methods. Based on our proposed truncated formula, we consider the incremental problem of large-scale kernel matrices and propose two incremental algorithms for updating large-scale kernel matrices. Numerical experiments demonstrate the efficiency of the proposed algorithms for solving incremental data problems and incremental kernel ridge regression.},
  archive      = {J_NEUCOM},
  author       = {Xiaxin Li and Gang Wu},
  doi          = {10.1016/j.neucom.2025.131512},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131512},
  shortjournal = {Neurocomputing},
  title        = {Incremental algorithms on low-rank approximation of large-scale kernel matrices based on perturbation of invariant subspaces},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FMSF: Future-preference modeling with similar-user features for next POI recommendation. <em>NEUCOM</em>, <em>656</em>, 131511. (<a href='https://doi.org/10.1016/j.neucom.2025.131511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abundant user check-in records in location-based social networks enhance the development of point-of-interest (POI) recommendation systems. The existing studies attempt to learn users’ past, current, and future preferences from their own sequential behaviors. Various approaches have been explored to model user visiting behaviors for the prediction of future preferences and have achieved considerable performance. However, most previous work ignores the impact of other users’ preferences on the prediction of current users’ future preferences. Thus, this work proposes a novel Future-preference Modeling with Similar-user Features (FMSF) model for next POI recommendation. It integrates the preferences of a user and those of other users to accurately model his/her multi-step future preferences. Specifically, it adopts a dynamically-updated similarity matrix to extract the information of similar users. Then, it incorporates an attention mechanism to assign distinct attention weights to the characteristics of both the current and similar users, which promotes the prediction of the future preferences of the current users. Therefore, the method proposed in this paper can offer users more precise recommendation results. Extensive experiments are conducted on three real-world datasets, which demonstrate the advantages of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Luan and Zhichao Feng and Liang Qi and Xiaoyu Sean Lu},
  doi          = {10.1016/j.neucom.2025.131511},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131511},
  shortjournal = {Neurocomputing},
  title        = {FMSF: Future-preference modeling with similar-user features for next POI recommendation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Permutation XOR cellular automata and direct stable periodic orbits. <em>NEUCOM</em>, <em>656</em>, 131510. (<a href='https://doi.org/10.1016/j.neucom.2025.131510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a permutation XOR cellular automaton (PXCA), a simple three-layer discrete-time dynamical system. The input-to-hidden layer corresponds to an elementary cellular automaton of the XOR rule and the hidden-to-output layer is the shift-type one-to-one permutation connection. The dynamics are described by an autonomous difference equation of binary state variables. Depending on the permutation connection, the PXCA generates a variety of direct stable periodic orbits (DBPOs) characterized by strong stability and fast transient phenomena. As a main result, we provide theoretical evidence that clarifies the number, period, and stability of DBPOs for general odd-dimensional PXCAs. Performing a precise numerical analysis, we have clarified that, depending on the dimension and a parameter, the period of DBPOs varies complicatedly and can become very long. Applications of the DBPOs include time series approximation and switching circuit control. As a fundamental step toward the applications, we present a simple FPGA based hardware prototype and have confirmed typical DBPOs experimentally.},
  archive      = {J_NEUCOM},
  author       = {Mikito Onuki and Yosuke Suzuki and Toshimichi Saito},
  doi          = {10.1016/j.neucom.2025.131510},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131510},
  shortjournal = {Neurocomputing},
  title        = {Permutation XOR cellular automata and direct stable periodic orbits},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal dynamic brain graph representation learning for brain disorder diagnosis via temporal sequence model. <em>NEUCOM</em>, <em>656</em>, 131509. (<a href='https://doi.org/10.1016/j.neucom.2025.131509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain network representation learning leverages graph-based algorithms to enhance understanding of functional brain organization. Recently, deep learning approaches based on graph neural network (GNN) have shown promising results in various brain network analysis tasks. Nevertheless, despite significant achievements in brain graph learning, early models still exhibit limitations in dynamic modeling and multi-modal network fusion. Dynamic modeling of brain networks entails learning sequential spatial interactions across time. Inspired by recent advances in large language model architectures, particularly RWKV, which combines the strengths of recurrent neural networks (RNNs) and Transformers. We propose an e fficient t emporal m ulti-modal g raph n eural n etwork (ET_MGNN), that captures complex temporal dependencies while integrating dynamic functional connectivity (DFC) and structural connectivity (SC) into a unified brain network representation. The proposed model demonstrates competitive performance in brain disorder classification on three datasets, outperforming several strong baselines. For instance, ET_MGNN an average classification accuracy improvement of 11.8 % on autism spectrum disorder (ASD) vs healthy controls, 32.9 % on Alzheimer's disease (AD) vs. mild cognitive impairment (MCI), compared to the well-suited STAGIN model. Furthermore, we introduce an interpretable graph reading mechanism that can identify disorder-relevant brain regions. In summary, ET_MGNN combines large-scale language sequence modeling with dynamic brain graph representation learning to improve the accuracy of brain disease diagnosis, providing insightful findings for dynamic brain network modeling.},
  archive      = {J_NEUCOM},
  author       = {Jinwei Lang and Li-Zhuang Yang and Hai Li},
  doi          = {10.1016/j.neucom.2025.131509},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131509},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal dynamic brain graph representation learning for brain disorder diagnosis via temporal sequence model},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PVFT-net: A point-voxel fusion method for self-supervised scene flow estimation with transformer. <em>NEUCOM</em>, <em>656</em>, 131508. (<a href='https://doi.org/10.1016/j.neucom.2025.131508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene flow estimation is a computer vision task that aims to estimate the 3D motion field of points from two consecutive frames of point clouds, and has a wide range of applications in various fields such as robotics and autonomous driving. Most of the existing methods estimate scene flow through point-based models, but ignore the irregularity of point clouds and the inefficiency of point-level computation. And voxel-based methods can hardly avoid the loss of detailed information. Therefore, we propose a point-voxel fusion method that contains a point branch and a voxel branch. The voxel branch projects the point cloud to regular local grids and captures coarse-grained local features from non-empty voxels through Sparse Grid Attention (SGA) with the shift window strategy. And the point branch captures fine-grained global features through dual attention consisting of Deformable Global Attention (DGA) and Channel Self-Attention (CSA), while compensating for the information loss in the voxel branch. Considering that it is difficult to directly describe the local geometric structure of complex objects in the scene with the shape of 3D objects potentially learned only through xyz coordinates, we explicitly encode the local surface information of the point cloud through the Umbrella Surface Feature Extraction (USFE) module. In addition, we introduce Density Sensitive Metric(DSM) loss to reduce the impact of outliers and density distribution mismatch problems. We validate the effectiveness of our method by performing experiments on the Flyingthings3D and KITTI datasets. Our method outperforms all other self-supervised methods and achieves highly competitive results compared to fully supervised methods. We achieve improvements in all metrics, especially EPE, which is decreased by 8.51 % on the KITTI o dataset and 15.79 % on the KITTI s dataset.},
  archive      = {J_NEUCOM},
  author       = {Xuezhi Xiang and Xi Wang and Xiaoheng Li and Xiankun Zhou and Lei Zhang and Xiantong Zhen},
  doi          = {10.1016/j.neucom.2025.131508},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131508},
  shortjournal = {Neurocomputing},
  title        = {PVFT-net: A point-voxel fusion method for self-supervised scene flow estimation with transformer},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attacking the spike: On the security of spiking neural networks to adversarial examples. <em>NEUCOM</em>, <em>656</em>, 131506. (<a href='https://doi.org/10.1016/j.neucom.2025.131506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) have attracted much attention for their high energy efficiency and for recent advances in their classification performance. However, unlike traditional deep learning approaches, the analysis and study of the robustness of SNNs to adversarial examples remain relatively underdeveloped. In this work, we focus on advancing the adversarial attack side of SNNs and make three major contributions. First, we show that successful white-box adversarial attacks on SNNs are highly dependent on the underlying surrogate gradient estimation technique, even in the case of adversarially trained SNNs. Second, using the best single surrogate gradient estimation technique, we analyze the transferability of adversarial attacks on SNNs and other state-of-the-art architectures like Vision Transformers (ViTs), as well as CNNs. Our analyzes reveal two key areas where SNN adversarial attacks can be enhanced: no white-box attack effectively exploits the use of multiple surrogate gradient estimators for SNNs, and no single model attack is effective at generating adversarial examples misclassified by both SNNs and non-SNN models simultaneously. For our third contribution, we develop a new attack, the Mixed Dynamic Spiking Estimation (MDSE) attack to address these issues. MDSE utilizes a dynamic gradient estimation scheme to fully exploit multiple surrogate gradient estimator functions. In addition, our novel attack generates adversarial examples capable of fooling both SNN and non-SNN models simultaneously. The MDSE attack is as much as 91.4 % more effective on SNN/ViT model ensembles and provides a 3 × boost in attack effectiveness on adversarially trained SNN ensembles, compared to conventional white-box attacks like Auto-PGD. Our experiments are broad and rigorous, covering three datasets (CIFAR-10, CIFAR-100 and ImageNet) and nineteen classifier models (seven for each CIFAR dataset and five models for ImageNet). We will release a fully publicly available code repository for the models and attacks upon publication.},
  archive      = {J_NEUCOM},
  author       = {Nuo Xu and Kaleel Mahmood and Haowen Fang and Ethan Rathbun and Caiwen Ding and Wujie Wen},
  doi          = {10.1016/j.neucom.2025.131506},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131506},
  shortjournal = {Neurocomputing},
  title        = {Attacking the spike: On the security of spiking neural networks to adversarial examples},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text-to-image person re-identification via collaborating pre-trained diffusion and discriminative models. <em>NEUCOM</em>, <em>656</em>, 131505. (<a href='https://doi.org/10.1016/j.neucom.2025.131505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image person re-identification (TIReID) aims to retrieve pedestrian images from a database that match given text queries. Currently, the most advanced methods involve transferring powerful multi-modal knowledge from the contrastive language-image pretraining (CLIP) model to perform cross-modal matching. However, CLIP primarily focuses on coarse-grained global contextual modeling of single image-text pairs, neglecting fine-grained compositional matching of complex visual-textual concepts. This makes it challenging to ensure fine-grained cross-modal matching between pedestrians and text queries. To address this issue, a novel framework, Collaborating Pre-trained Diffusion and Discriminative Models (CPDD), is proposed in this work. The CPDD comprises three modules: a fine-grained features learning (FFL) module, a semantic consistency alignment (SCA) module, and a masked-text interactive modeling (MIM) module. Firstly, the FFL learns feature representations containing fine-grained matching information between images and text through the reverse denoising process of a diffusion model. Next, a semantic consistency loss is designed in the SCA, which ensures the semantic consistency between the fine-grained matching information and the input image and text information. Then, the MIM propagates fine-grained matching information into the visual- textual context by a cross-modal interactive encoder, achieving fine-grained matching between images and text and enabling fine-grained cross-modal matching. Extensive experiments on the CUHK-PEDES, ICFG-PEDES, and RSTPReid datasets show that the proposed method achieves significant performance improvements compared to current research results, achieving Rank-1 accuracy of 74.87 %, 63.31 %, and 61.26 %, respectively.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Zhang and Chenyue Xu and Huajing Wu and Quange Tan and Qianli Zhou and Rong Wang},
  doi          = {10.1016/j.neucom.2025.131505},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131505},
  shortjournal = {Neurocomputing},
  title        = {Text-to-image person re-identification via collaborating pre-trained diffusion and discriminative models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Layer-wise contrastive learning BERT for sentence representation of GitHub. <em>NEUCOM</em>, <em>656</em>, 131504. (<a href='https://doi.org/10.1016/j.neucom.2025.131504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every day, on GitHub, end-users submit a large number of issues that must be addressed to ensure the success of software projects. Though BERT-based pre-trained language models achieve high performance on many downstream tasks, the sentence representation of [CLS] from the top layer of BERT has a limited ability to capture the semantic meaning of sentences. GitHub issue reports often include code snippets and user-generated terms not found in standard vocabularies. Therefore, the classification predictions of BERT are affected. To generate better sentence semantic representations of BERT for GitHub, we propose a layer-wise Contrastive Learning BERT (CLBERT), which uses contrastive learning to enhance the representation ability by contrasting the layer-by-layer representation. Further, to obtain as comprehensive information as possible, representations of each layer are extracted and learned by an attention mechanism as the final classification features. Finally, experiments conducted on two GitHub data sets show that our proposed model significantly improves classification performance.},
  archive      = {J_NEUCOM},
  author       = {Daoquan Chen and Wei Zhang and Shengyu Lu and Yuanguo Lin and Xinyu Gu and Xiuze Zhou},
  doi          = {10.1016/j.neucom.2025.131504},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131504},
  shortjournal = {Neurocomputing},
  title        = {Layer-wise contrastive learning BERT for sentence representation of GitHub},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attacking all tasks at once using adversarial examples in multi-task learning. <em>NEUCOM</em>, <em>656</em>, 131503. (<a href='https://doi.org/10.1016/j.neucom.2025.131503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual content understanding frequently relies on multi-task models to extract robust representations of a single visual input for multiple downstream tasks. However, in comparison to extensively studied single-task models, the adversarial robustness of multi-task models has received significantly less attention and many questions remain unclear: (1) How robust are multi-task models to single task adversarial attacks, (2) Can adversarial attacks be designed to simultaneously attack all tasks in a multi-task model, and (3) How does parameter sharing across tasks affect multi-task model robustness to adversarial attacks? This paper aims to answer these questions through careful analysis and rigorous experimentation. First, we analyze the inherent drawbacks of two commonly-used adaptations of single-task white-box attacks in attacking multi-task models. We then propose a novel attack framework, Dynamic Gradient Balancing Attack (DGBA). Our framework poses the problem of attacking all tasks in a multi-task model as an optimization problem that can be efficiently solved through integer linear programming. Extensive evaluation on two popular MTL benchmarks, NYUv2 and Tiny-Taxonomy, demonstrates the effectiveness of DGBA compared to baselines in attacking both clean and adversarially trained multi-task models. Our results also reveal a fundamental trade-off between improving task accuracy via parameter sharing across tasks and undermining model robustness due to increased attack transferability from parameter sharing.},
  archive      = {J_NEUCOM},
  author       = {Lijun Zhang and Xiao Liu and Kaleel Mahmood and Caiwen Ding and Hui Guan},
  doi          = {10.1016/j.neucom.2025.131503},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131503},
  shortjournal = {Neurocomputing},
  title        = {Attacking all tasks at once using adversarial examples in multi-task learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolutional neural network combined with edge complexity and channel attention mechanism for unsupervised superpixel segmentation. <em>NEUCOM</em>, <em>656</em>, 131502. (<a href='https://doi.org/10.1016/j.neucom.2025.131502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Superpixel segmentation is crucial for enhancing image processing efficiency and accuracy. To address the challenges of decreased accuracy and insufficient stability in adaptive superpixel generation faced by existing algorithms in complex image segmentation, we propose ECN, an unsupervised superpixel segmentation algorithm based on convolutional neural networks (CNN) integrating edge complexity and channel attention mechanisms. The ECN algorithm first calculates edge complexity using the Sobel operator, which guides the sequential network in determining the number of feature channels and the kernel size of the fast 1D convolution. Subsequently, low-level features with positional information are transformed into deep features through the sequential network, dynamically adjusting the weights of each feature channel using the channel attention mechanism. Finally, the target function is minimized during inference, enabling unsupervised superpixel generation. We validate ECN's applicability by combining it with Linear Discriminant Analysis (LDA) and Locality Fisher Discriminant Analysis (LFDA) to develop Superpixel Unsupervised Linear Discriminant Analysis (SULDA). Experimental results on BSDS500 and NYUv2 datasets show ECN outperforms existing methods, producing stable and higher-quality superpixel segmentation. Application tests on Indian Pines and Pavia University scenes confirm ECN's significant practical utility.},
  archive      = {J_NEUCOM},
  author       = {Fugui Luo and Shihua Li and Minghui Chang and Yuting Liu and Kaitong Liu},
  doi          = {10.1016/j.neucom.2025.131502},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131502},
  shortjournal = {Neurocomputing},
  title        = {Convolutional neural network combined with edge complexity and channel attention mechanism for unsupervised superpixel segmentation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge distillation-based object detection model focused on road scene perception and localization. <em>NEUCOM</em>, <em>656</em>, 131501. (<a href='https://doi.org/10.1016/j.neucom.2025.131501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is crucial for unmanned systems, as it enables real-time classification and localization of objects in road scenes. Besides detection accuracy, which remains robust to variations in object scales, an effective object detection algorithm also demands superior performance in processing time. To address these issues, this paper proposes a knowledge distillation-based object detection model, PLE-RepPoints-Lite, to compromise the performance of detection accuracy and speed for unmanned systems. We also design perception and localization enhancement (PLE) strategies, which consist of parallel dynamic attention, multi-scale composite localization confidence, and a feedback closed-loop structure, to enhance the capabilities of perception and localization in complex road environments. To improve the real-time performance, a hybrid lightweight approach for road scenes is designed. Experimental results on the Cityscapes and BDD100K datasets show that our approach achieves state-of-the-art results with average precision (AP) of 34.6 and 40.1, respectively. Furthermore, it operates at 34.2 frames per second (FPS) at a 1280 × 640 resolution, satisfying real-time requirements.},
  archive      = {J_NEUCOM},
  author       = {Yufei Xie and Ying Shi and Changjun Xie and Qin Hu and Yue Liu and Chaojun Lin},
  doi          = {10.1016/j.neucom.2025.131501},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131501},
  shortjournal = {Neurocomputing},
  title        = {A knowledge distillation-based object detection model focused on road scene perception and localization},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confident neural network regression with bootstrapped deep ensembles. <em>NEUCOM</em>, <em>656</em>, 131500. (<a href='https://doi.org/10.1016/j.neucom.2025.131500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise in the popularity and usage of neural networks, trustworthy uncertainty estimation is becoming increasingly essential. One of the most prominent uncertainty estimation methods is Deep Ensembles [20]. A classical parametric model has uncertainty in the parameters due to the fact that the data on which the model is built is a random sample. A modern neural network has an additional uncertainty component since the optimization of the network is random. Lakshminarayanan et al. [20] noted that Deep Ensembles do not incorporate the classical uncertainty induced by the effect of finite data. In this paper, we present a computationally cheap extension of Deep Ensembles for the regression setting, called Bootstrapped Deep Ensembles , that explicitly takes this classical effect of finite data into account using a modified version of the parametric bootstrap. We demonstrate through an experimental study that our method significantly improves upon standard Deep Ensembles. The resulting confidence intervals demonstrate superior coverage without sacrificing accuracy.},
  archive      = {J_NEUCOM},
  author       = {Laurens Sluijterman and Eric Cator and Tom Heskes},
  doi          = {10.1016/j.neucom.2025.131500},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131500},
  shortjournal = {Neurocomputing},
  title        = {Confident neural network regression with bootstrapped deep ensembles},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameter-free multi-view clustering via refined tensor learning. <em>NEUCOM</em>, <em>656</em>, 131497. (<a href='https://doi.org/10.1016/j.neucom.2025.131497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As multi-view data becomes more prevalent in real-world applications, multi-view clustering (MVC) has emerged as a powerful technique for unsupervised representation learning. To uncover the intrinsic structure, it is crucial to consider information from different spaces. Focusing solely on the sample space limits the method’s ability to effectively model multi-view data, as the informative patterns embedded in the feature space are often overlooked. Furthermore, to integrate high-order correlations, tensor-based MVC methods have been widely adopted to preserve the low rank structure of multi-view data. Traditional tensors can not achieve selective tensor rank minimization as they lack an explicit mechanism to model the retention of singular values based on their individual information contributions. Additionally, existing methods rely on hyper-parameters, undermining generalizability across different datasets. In response to these limitations, we propose a novel Parameter-free Multi-view Clustering via Refined Tensor Learning (PRTL), which is based on bidirectional regression matrices to perform data reconstruction and extract salient features. To further achieve an adaptive low-rank tensor structure, we propose a Quadratic Decay Tensor (QDT) regularization as a non-convex alternative to conventional rank minimization, which selectively retains salient information while filtering out noise dynamically, resulting in a more expressive joint representation. Meanwhile, we incorporate the hyper-Laplace graph to capture richer relationships than those modeled by conventional pairwise graphs. Notably, PRTL eliminates the need for hyper-parameters, making it more practical and robust. Experiments on diverse datasets demonstrate that PRTL consistently surpasses existing state-of-the-art clustering methods. Our code is available at https://github.com/jiaxinyang04/PRTL .},
  archive      = {J_NEUCOM},
  author       = {Jiaxin Yang and Qian Liu and Yuemeng Huang and Chunyan Yang and Wengeng Chen and Yu Lu and Jiale Wang and Wenzhe Liu and Huibing Wang},
  doi          = {10.1016/j.neucom.2025.131497},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131497},
  shortjournal = {Neurocomputing},
  title        = {Parameter-free multi-view clustering via refined tensor learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extensive multi-variant deep neural network approach to enhance genomic prediction of endometriosis. <em>NEUCOM</em>, <em>656</em>, 131496. (<a href='https://doi.org/10.1016/j.neucom.2025.131496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have shown significant advancements in modelling complex non-linear relationships in high-dimensional biomedical data. Understanding the interplay between genetic variants and disease susceptibility is still a considerable challenge that prevents certain genomic diseases to be predicted accurately for clinical interventions. In this study, we introduce the Extensive Multi-Variant Deep Neural Network (EMV-DNN), an innovative deep learning methodology designed to enhance polygenic risk prediction. Unlike conventional polygenic risk score methods, EMV-DNN incorporates single nucleotide polymorphisms (SNPs) alongside structural variants including insertions and deletions (indels), short tandem repeats (STRs), and copy number variants (CNVs) using variant-specific subnetworks to extract informative embeddings which capture a richer and holistic genomic context. Evaluated on real-world cohorts from the UK Biobank and All of Us, EMV-DNN outperforms conventional PRS methods and classic machine learning algorithms across binary and multi-class prediction tasks. Beyond predictive performance, SHapley Additive exPlanations (SHAP) analysis revealed biologically plausible variant–gene–disease associations, highlighting pathways related to endometrial cell proliferation, fibrosis, and immune regulation. Our findings underscore the value of multi-variant integration and non-linear approaches to capture the intricate genetic architecture of complex genomic diseases. Despite challenges such as dataset limitations and the complexity of diseases with multiple contributing factors, the EMV-DNN methodology presents a promising avenue for enhancing the predictive accuracy of PRS, thereby facilitating personalized healthcare interventions and advancing our understanding of genetic predispositions to disease.},
  archive      = {J_NEUCOM},
  author       = {Zelia Soo and Hua Lin and Yue Yang and Mark Grosser and Mengjia Wu and Yi Zhang and Jie Lu},
  doi          = {10.1016/j.neucom.2025.131496},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131496},
  shortjournal = {Neurocomputing},
  title        = {An extensive multi-variant deep neural network approach to enhance genomic prediction of endometriosis},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised facial expression restoration and recognition method based on improved masked auto-encoder. <em>NEUCOM</em>, <em>656</em>, 131495. (<a href='https://doi.org/10.1016/j.neucom.2025.131495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a method for reconstructing occluded facial expressions. Firstly, a self-supervised learning Masked Auto-Encoder based facial expression recognition (MAE-FER) method is introduced, which effectively reduces the computational cost and parameter count by enhancing the multi-scale local-global self-attention interaction encoder, thereby improving the training efficiency and generalization capability of the model. Secondly, to address the problem of facial expression occlusion in real-world scenarios, a MAE-based occlusion detector is designed to detect occluded parts of the face, providing effective support for subsequent reconstruction tasks. Subsequently, the Dynamic Weight Allocation Generative Adversarial Network (DWA-GAN) for facial expression occlusion recovery is proposed, which achieves precise occlusion recovery by dynamically allocating weights to reference image blocks, significantly improving the accuracy of reconstruction. Finally, feature fusion is performed on the reconstructed results and applied to the FER task to further enhance classification accuracy and stability. Utilizing the pre-trained MAE-FER model, key hidden vectors are extracted from facial expression images, containing important feature information related to expression recognition. Through this step, closely related features to expression recognition are selected while irrelevant details are discarded, optimizing the inter-class distance issue of facial expressions. Next, to address the performance degradation caused by label ambiguity, an improved Rotate Erasing Attention Consistency (REAC) method is adopted, which effectively mitigates the negative impact of label ambiguity, further improving the accuracy and stability of FER. Experimental results demonstrate that the method achieves the best performance on the RAF-DB dataset.},
  archive      = {J_NEUCOM},
  author       = {Chaolong Zhang and Yuanping Xu and Zhijie Xu and Rongqiang Gou and Weiye Wang and Jin Jin and Jian Huang},
  doi          = {10.1016/j.neucom.2025.131495},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131495},
  shortjournal = {Neurocomputing},
  title        = {A self-supervised facial expression restoration and recognition method based on improved masked auto-encoder},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TemPrompt: Multi-task prompt learning for temporal relation extraction in RAG-based crowdsourcing systems. <em>NEUCOM</em>, <em>656</em>, 131494. (<a href='https://doi.org/10.1016/j.neucom.2025.131494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal relation extraction (TRE) aims to grasp the evolution of events or actions, and thus shape the workflow of associated tasks, so it is recognized as a pivotal technology for facilitating the rational scheduling and efficient execution of crowdsourcing tasks. However, existing methods still struggle with limited and unevenly distributed annotated data. Inspired by the abundant global knowledge stored within pre-trained language models (PLMs), some studies have explored using prompts to guide PLMs in completing TRE, but their improvements are still unsatisfactory, as the model treats all the tokens equally, resulting in a limited understanding of temporal order. In this paper, we propose a multi-task prompt learning framework for TRE (TemPrompt), incorporating prompt tuning and contrastive learning to tackle these issues. In the framework, we design temporal event reasoning in the form of masked language modeling as auxiliary tasks to enable the PLM to distinguish tokens essential for temporal reasoning from those serving general contextual purposes, thereby fostering the model’s comprehension of temporal knowledge. Additionally, to elicit more effective prompts for PLMs, we introduce a task-oriented prompt construction approach that thoroughly takes the myriad factors of TRE into consideration for the automatic generation of high-quality and easy-to-interpret prompts. Contrastive learning is employed to further mitigate data issues by extracting more distinctive sample representations. Experimental results demonstrate that TemPrompt outperforms all baseline methods across most metrics and exhibits strong generalization to unseen events. Two case studies—one on designing and manufacturing printed circuit boards and the other on developing defect detection systems—are provided to validate its feasibility and effectiveness in crowdsourcing scenarios.},
  archive      = {J_NEUCOM},
  author       = {Jing Yang and Yu Zhao and Linyao Yang and Xiao Wang and Long Chen and Fei-Yue Wang},
  doi          = {10.1016/j.neucom.2025.131494},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131494},
  shortjournal = {Neurocomputing},
  title        = {TemPrompt: Multi-task prompt learning for temporal relation extraction in RAG-based crowdsourcing systems},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EHGFL: Contrastive distillation for efficient heterogeneous graph few-shot learning. <em>NEUCOM</em>, <em>656</em>, 131493. (<a href='https://doi.org/10.1016/j.neucom.2025.131493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graphs (HGs), as a general modeling paradigm for multi-typed entities and complex interactions in ubiquitous real-world networks, have attracted extensive research enthusiasm. While self-supervised learning (SSL) on heterogeneous graph neural networks (HGNNs) demonstrates promising performance, existing SSL approaches face critical limitations: (1) The inherent multiple relation types and meta-path aggregations in HGNNs create prohibitive training and inference costs that restrict scalability; (2) The local message-passing paradigm confines information propagation to immediate neighborhoods, limiting the model’s ability to capture long-range dependencies and global structural patterns essential for complex reasoning tasks; (3) Task specialization necessitates costly fine-tuning of the HGNN backbones. To address these issues, we propose Efficient Heterogeneous Graph Few-shot Learning (EHGFL) to improve HGNNs’ scalability and global-structure modeling capabilities. Specifically, EHGFL first employs instance discrimination contrastive learning for self-supervised pretraining of HGNNs. To enhance efficiency, we introduce a novel cross-model contrastive distillation mechanism that transfers HGNNs’ heterogeneous structure modeling ability to a concise, globally-structure-aware multilayer perceptron. This feature-space distillation process preserves heterogeneous structure representations while avoiding expensive neighborhood aggregation and enhancing global feature awareness. Furthermore, to bridge the gap between pretraining objectives and downstream tasks, we adopt prompt tuning techniques specifically designed for the student model, enabling effective adaptation with limited labeled data. Extensive experiments on two real-world HG datasets demonstrate that the proposed EHGFL framework substantially accelerates training and inference while achieving superior few-shot node classification accuracy compared to state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Ning Ruan and Yufei Zeng and Huan Liu and Dong Liu and Pengfei Jiao},
  doi          = {10.1016/j.neucom.2025.131493},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131493},
  shortjournal = {Neurocomputing},
  title        = {EHGFL: Contrastive distillation for efficient heterogeneous graph few-shot learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scattered data augmentation for generalization in visual reinforcement learning. <em>NEUCOM</em>, <em>656</em>, 131492. (<a href='https://doi.org/10.1016/j.neucom.2025.131492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation (DA) has shown a significant potential to enhance generalization performance in visual reinforcement learning (VRL). However, existing research on DA-based methods is predominantly empirical, and the mechanism for why DA enhances generalization remains theoretically under-explored. To bridge this gap, we derive a generalization error upper bound for VRL from the perspective of data distribution distance. Based on this bound, we provide a theoretical explanation of the mechanism by which DA improves generalization: we find that DA that satisfies certain conditions can reduce the distance between the training and test distributions, thus making the training and test samples closer. In addition, we conditionally prove that training data with higher variance can provide a higher generalization performance. Motivated by our analysis, we propose Scattered Data Augmentation (ScDA) framework. ScDA constructs a data transformation system with the agent serving as the discriminator, aiming to provide more diverse training data for agent training. Experiments are conducted across various tasks and numerous test modes in DeepMind Control Generalization Benchmark2 (DMC-GB2) and robotic tasks. Results demonstrate that our ScDA framework can be integrated with different baseline algorithms and significantly enhance policy generalization, outperforming the current state-of-the-art methods in the DMC-GB2 tests, confirming the effectiveness of the theoretical analysis in this work. The code for this work can be found at: https://github.com/scdadev/scdadev .},
  archive      = {J_NEUCOM},
  author       = {Hao Lei and Yu Zhao and Yi Xin and Zhang Shaonan and Ke Liangjun},
  doi          = {10.1016/j.neucom.2025.131492},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131492},
  shortjournal = {Neurocomputing},
  title        = {Scattered data augmentation for generalization in visual reinforcement learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monotonic convergence of adaptive caputo fractional gradient descent for temporal convolutional networks. <em>NEUCOM</em>, <em>656</em>, 131491. (<a href='https://doi.org/10.1016/j.neucom.2025.131491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fractional derivatives have gained prominence in optimization for their inherent non-locality and memory-dependent properties, effectively capturing historical dependencies. This work introduces an Adaptive Fractional-order Gradient Descent (AFGD) algorithm based on Caputo fractional derivatives, with deep integration into Temporal Convolutional Networks (TCNs). Unlike conventional fixed-order methods, AFGD employs an adaptive fractional-order mechanism to enhance optimization. Theoretically, we establish rigorous proofs for AFGD’s monotonic convergence in loss function minimization, supported by numerical simulations of its convergence behavior. Evaluated on the MIT-BIH arrhythmia five-class classification benchmark, TCNs optimized with AFGD achieve superior accuracy over established methods, demonstrating the efficacy of the proposed gradient scheme for deep learning optimization.},
  archive      = {J_NEUCOM},
  author       = {Zhiwei Xiao and Jiejie Chen and Xuewen Zhou and Bin Wei and Ping Jiang and Zhigang Zeng},
  doi          = {10.1016/j.neucom.2025.131491},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131491},
  shortjournal = {Neurocomputing},
  title        = {Monotonic convergence of adaptive caputo fractional gradient descent for temporal convolutional networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive PID-guided tensor wheel decomposition model for dynamic weighted network representation. <em>NEUCOM</em>, <em>656</em>, 131490. (<a href='https://doi.org/10.1016/j.neucom.2025.131490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Weighted Networks (DWN) usually appear in various big data-related complex systems and can describe real-time interactions between a large number of entities. As the number of entities increases dramatically, it is impossible for each entity to have complete interaction with each other, which results in such a DWN being High-Dimensional and Incomplete (HDI). Tensor Wheel Decomposition (TWD), as a novel tensor network, has powerful representation capabilities, but existing TWD-based methods require additional computational and storage costs to process an HDI DWN. To address these challenges, we propose an Adaptive integral separation PID–guided Tensor Wheel Decomposition (APTWD) model that: 1) employs a data density-oriented loss function, ensuring the representation learning is focused on the existing information in the target network to obtain more accurate low-rank embedding; and 2) develops a parameter learning scheme with error control feedback based on the integral separation PID controller to minimize the convergence iteration process. Experiments on six real-world DWN datasets demonstrate that APTWD consistently outperforms state-of-the-art methods, delivering higher representation accuracy and significantly reduced computational cost.},
  archive      = {J_NEUCOM},
  author       = {Jiqiu Chen and Qu Wang and Hao Wu},
  doi          = {10.1016/j.neucom.2025.131490},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131490},
  shortjournal = {Neurocomputing},
  title        = {An adaptive PID-guided tensor wheel decomposition model for dynamic weighted network representation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view unsupervised feature selection based on graph discrepancy learning. <em>NEUCOM</em>, <em>656</em>, 131487. (<a href='https://doi.org/10.1016/j.neucom.2025.131487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-view learning, unsupervised feature selection plays a vital role in reducing dimensionality while preserving discriminative information distributed across diverse data modalities. Despite notable progress, existing approaches frequently exhibit two key limitations: they often overlook the complementary benefits of integrating global and local structural information, and they inadequately model complex nonlinear relationships or align structural representations across views. To address these challenges, we propose a novel framework, termed Multi-view unsupervised feature selection based on graph discrepancy learning (GDFS). The proposed method jointly constructs global graph structures in a projected low-dimensional space and local graphs in a nonlinear kernel-induced space, effectively capturing both high-level semantic structures and fine-grained neighborhood dependencies. A graph discrepancy term is introduced to explicitly reduce structural discrepancies between global and local representations, thus enhancing consistency and robustness. In addition, a low-rank tensor constraint is applied to the stack of global graphs to uncover high-order correlations across views. A consensus clustering matrix is further learned to provide pseudo-label supervision, which guides the selection of discriminative features. Extensive experiments on six benchmark multi-view datasets demonstrate that GDFS consistently surpasses state-of-the-art methods in terms of clustering performance, thereby confirming its effectiveness, scalability, and generalizability. The code is available at https://github.com/xyw0111/2025-GDFS .},
  archive      = {J_NEUCOM},
  author       = {Yiwan Xu and Xijiong Xie and Xianliang Jiang and Yujie Xiong},
  doi          = {10.1016/j.neucom.2025.131487},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131487},
  shortjournal = {Neurocomputing},
  title        = {Multi-view unsupervised feature selection based on graph discrepancy learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel mixed-attribute data anomaly detection method based on granular-ball multi-kernel fuzzy rough sets. <em>NEUCOM</em>, <em>656</em>, 131486. (<a href='https://doi.org/10.1016/j.neucom.2025.131486'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rough sets have established a novel approach to anomaly detection through uncertainty handling. Nevertheless, traditional approaches are susceptible to noise. Existing kernelized methods improve feature representation via kernel transformations. However, they are typically restricted to a single-kernel framework, which limits the capacity to model the heterogeneous nature of mixed-attribute data. To address this issue, this study proposes a granular-ball generation algorithm tailored to the characteristics of mixed-attribute data. Multiple kernel functions are employed to effectively integrate the fuzzy relations of various attribute types. By integrating fuzzy rough set theory, granular-ball computing, and multi-kernel methods, a granular-ball multi-kernel fuzzy rough set model is proposed. Besides, a novel unsupervised anomaly detection method is proposed to effectively process mixed-attribute data. This method integrates kernelized fuzzy relations across various attribute types, constructs kernelized fuzzy information granules, and computes anomaly scores based on multiple granular-ball kernelized fuzzy information granules. Finally, an anomaly factor is introduced to quantify the anomaly degree of data objects. Comparative experiments were conducted on 16 public datasets. The novel approach consistently outperformed current methodologies in AUC metrics while demonstrating superior robustness across diverse data samples.},
  archive      = {J_NEUCOM},
  author       = {Cong Gao and Qiu Wang and Yanping Chen and Qingqi Pei and Zhongmin Wang},
  doi          = {10.1016/j.neucom.2025.131486},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131486},
  shortjournal = {Neurocomputing},
  title        = {A novel mixed-attribute data anomaly detection method based on granular-ball multi-kernel fuzzy rough sets},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-guided encoder-decoder network for soft sensor of copper matte grade in flash smelting process. <em>NEUCOM</em>, <em>656</em>, 131485. (<a href='https://doi.org/10.1016/j.neucom.2025.131485'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate real-time detection of copper matte grade is critical for state identification and optimization control in flash smelting, yet remains challenging due to the complex and harsh industrial environment. To address this issue, this study proposes a knowledge-guided encoder-decoder network. In this method, Bidirectional Gated Recurrent Unit serves as the backbone architecture for both the encoding and decoding processes, enabling nonlinear dynamic modeling in the temporal domain. The encoder integrates a composite variable attention mechanism, which leverages process knowledge to prioritize key variables based on their importance. A temporal decay attention mechanism is added to the decoder, endowing the model with the ability to simulate the temporal dependency between copper matte grade and process variables through prior knowledge. These knowledge-guided designs strengthen the ability of model to capture process-specific relationships between input variables and copper matte grade. Industrial experiments based on real production data from a smelting plant in China, show that the proposed model achieves optimal performance, with 96 % absolute errors not exceeding 0.5 %. It demonstrates that the proposed model not only provides accurate and real-time copper matte grade estimation but also maintains robustness in industrial environments, verifying its potential for practical application in flash smelting process.},
  archive      = {J_NEUCOM},
  author       = {Zhou Zou and Can Zhou and Chunhua Yang},
  doi          = {10.1016/j.neucom.2025.131485},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131485},
  shortjournal = {Neurocomputing},
  title        = {Knowledge-guided encoder-decoder network for soft sensor of copper matte grade in flash smelting process},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-resolution QP-adaptive generative face video compression using multi-level generator. <em>NEUCOM</em>, <em>656</em>, 131484. (<a href='https://doi.org/10.1016/j.neucom.2025.131484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a multi-resolution quantization parameter (QP)-adaptive generative face video compression (GFVC) framework to realize face video communication at an ultra-low bitrate. By leveraging deep generative models and semantic feature representation, the proposed framework achieves high perceptual quality while significantly reducing bitrate. The proposed framework dynamically adjusts feature granularity based on QP values and integrates modules such as multi-level multi-DConv head transposed attention (MDTA) and multi-level spatially adaptive denormalization (SPADE) to enhance both spatial fidelity and temporal consistency. To ensure adaptability and standardization, we further extend the proposed framework to support multi-resolution inputs and incorporate feature encoding based on Supplemental Enhancement Information (SEI) in VVC. Specifically, we introduce the flag gfv_enhancement_matrix_flag to transmit an optional 8 × 8 enhancement matrix, enabling precise refinement of inter-frame reconstruction in compliance with VVC. A multi-reference frame buffer mechanism is also implemented to improve long-term temporal coherence through attention-guided reference selection. Experimental results demonstrate that the proposed GFVC framework achieves average BD-rate gains of 63.87 % in DISTS and 61.99 % in LPIPS on benchmark datasets compared to the VVC anchor (VTM-22.2 LDB mode). Without retraining, the proposed framework operates smoothly even on face videos with a resolution of 512 × 512 , achieving 23.40 % BD-rate gain in DISTS and indicating strong scalability. These results validate the practical feasibility of the proposed GFVC framework in real-world video conferencing and telepresence scenarios, especially under ultra-low bandwidth conditions.},
  archive      = {J_NEUCOM},
  author       = {Wenbo Kang and Lu Liu and Cheolkon Jung},
  doi          = {10.1016/j.neucom.2025.131484},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131484},
  shortjournal = {Neurocomputing},
  title        = {Multi-resolution QP-adaptive generative face video compression using multi-level generator},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ST-CML: A contrastive meta learning framework for spatio-temporal graph few-shot learning with cross-city transfer. <em>NEUCOM</em>, <em>656</em>, 131483. (<a href='https://doi.org/10.1016/j.neucom.2025.131483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph learning is a critical methodology for addressing smart city computational tasks, including traffic speed prediction, vehicle trajectory analysis, and air quality forecasting. However, the scarcity of available data in many cities poses a significant constraint due to the challenges and costs associated with large-scale data collection. To overcome this limitation, leveraging data from cities with abundant data resources and enhancing model performance through knowledge transfer techniques is essential. In this study, we propose ST-CML. Our approach utilizes data from multiple source cities to train a meta-learner, which generates parameters for downstream spatio-temporal models. The meta-learner is then fine-tuned to adapt to target cities with limited data. We introduce a graph contrastive loss to improve the learning of spatio-temporal structures during meta-learning. This loss function guides the model in mitigating spatio-temporal feature deviations across cities during knowledge transfer. Experimental evaluations on real-world traffic datasets demonstrate that our framework surpasses existing methods and achieves significant effectiveness in cross-city few-shot learning scenarios.},
  archive      = {J_NEUCOM},
  author       = {Haichen Lyu and Chun Wang},
  doi          = {10.1016/j.neucom.2025.131483},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131483},
  shortjournal = {Neurocomputing},
  title        = {ST-CML: A contrastive meta learning framework for spatio-temporal graph few-shot learning with cross-city transfer},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Filter bank convolutional network with dual channel attention for multi-class fine joint motor imagery decoding. <em>NEUCOM</em>, <em>656</em>, 131480. (<a href='https://doi.org/10.1016/j.neucom.2025.131480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective Motor imagery brain-computer interface (MI-BCI) is a representative BCI system. Recent studies in MI-BCI focus on Fine Joint MI (FJMI) decoding that recognizes the motor intention of different joints from one upper limb. However, due to the low spatial difference between EEG patterns of FJMI, achieving optimal performance remains a challenge of multi-class FJMI decoding studies. Methods: We proposed a novel approach named Filter Bank Convolutional Network with Dual Channel Attention (FB-DCANet) that enables feature extraction and selection in MI-EEG across multi-class FJMI tasks. This network features a combined filter bank in frequency and time domain that simultaneously extracts spatio-temporal information from four frequency bands (alpha, beta, theta, and low gamma), accompanied with temporal convolutional modules for additional temporal information extraction. Moreover, a feature selection method based on Dual Channel Attention was proposed combining preliminary intra-band feature selection via Residual Channel Self-Attention (RCSA) and further inter-band feature selection from different frequency bands by Efficient Channel Attention (ECA). Results: We performed experiments using FJMI-EEG data from the unilateral upper limb, and FB-DCANet achieved an accuracy of 59.34 % in a 4-class classification scenario (hand MI, elbow MI, shoulder MI, and resting state), and interpretability of FB-DCANet was analyzed by visualization of Class Activation Map (CAM) and attention values. Conclusion and Significance: This work presents a novel approach with a time-frequency filter bank and Dual Channel Attention-based feature selection for multi-class FJMI decoding, which can be utilized to develop a rehabilitation system based on FJMI-BCI.},
  archive      = {J_NEUCOM},
  author       = {Jiaming Chen and Yueqi Zhang and Kaide Liu and Xinkang Hu and Meng Xu and Dan Wang and Weibo Yi},
  doi          = {10.1016/j.neucom.2025.131480},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131480},
  shortjournal = {Neurocomputing},
  title        = {Filter bank convolutional network with dual channel attention for multi-class fine joint motor imagery decoding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Output-feedback synchronization of semi-markov jump two-time-scale neural networks: Dual event-triggered scheme. <em>NEUCOM</em>, <em>656</em>, 131479. (<a href='https://doi.org/10.1016/j.neucom.2025.131479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of synchronization control for semi-Markov jump two-time-scale neural networks, in which the output-feedback mechanism is adopted and a dual event-triggered scheme is employed using a double-rate sampling method to balance system performance and communication efficiency. First, considering the two-time-scale property of the semi-Markov jump neural networks, the dual-rate sampling strategy is adopted such that two independent event-triggered conditions for different time scales can be designed, which ensure efficient resource utilization while maintaining system performance. Then, a Lyapunov–Krasovskii functional with the singular perturbation parameter is constructed to deduce sufficient conditions ensuring that the synchronization error system is stochastically stable and satisfies a given H ∞ performance index. Moreover, the solution for obtaining the controller gains is presented to guarantee synchronization of the considered system under a dual event-triggered scheme. Finally, the feasibility of the methods is demonstrated by two examples, including a numerical example and an image encryption. They show that this event-triggered mechanism provides an efficient new synchronization control scheme for semi-Markov jump two-time-scale neural network systems while reducing the network burden.},
  archive      = {J_NEUCOM},
  author       = {Wenyan Zuo and Ya-Nan Wang and Feng Li and Sangmoon Lee},
  doi          = {10.1016/j.neucom.2025.131479},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131479},
  shortjournal = {Neurocomputing},
  title        = {Output-feedback synchronization of semi-markov jump two-time-scale neural networks: Dual event-triggered scheme},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient multi-view graph condensation via gradient-flow induced graph convolutional networks. <em>NEUCOM</em>, <em>656</em>, 131478. (<a href='https://doi.org/10.1016/j.neucom.2025.131478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning based on graph convolutional networks boosts performance by incorporating diverse perspectives, leading to significant achievements and successful applications across various academic and practical fields. However, multi-view graph convolutional networks suffer from substantial computational challenges on large-scale graphs. To address this limitation, graph condensation has emerged as a promising direction by creating a smaller composite graph that allows for efficient network training while preserving performance. Furthermore, previous studies have demonstrated that encouraging performance in graph learning is achieved via graph compression. To this end, we attempt to introduce graph condensation into the multi-view learning for computation acceleration. This approach not only reduces training costs significantly but also achieves sub-linear time complexity and memory consumption during network training. Further, we propose a gradient flow induced graph convolutional network from partial differential equations, which offers theoretical guarantees and potential new insights for the graph-related network architecture construction with transparent model interpretability. Extensive experiments on seven real-world multi-view datasets demonstrate that the proposed method sharply decreases model training time while ensuring competitive multi-view semi-supervised classification.},
  archive      = {J_NEUCOM},
  author       = {Lu Liu and Yang Huang and Yueyang Pi and Zhicheng Wei and Jinbo Li and Shiping Wang},
  doi          = {10.1016/j.neucom.2025.131478},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131478},
  shortjournal = {Neurocomputing},
  title        = {Efficient multi-view graph condensation via gradient-flow induced graph convolutional networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal event-triggered control for multi-agent systems with hierarchical framework. <em>NEUCOM</em>, <em>656</em>, 131477. (<a href='https://doi.org/10.1016/j.neucom.2025.131477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the event-triggered optimal control problem for a class of linear second-order multi-agent systems (MASs) with external disturbances. A hierarchical framework is proposed to address the challenges that arise from the information of the coupled neighbors and external disturbances, integrating the communication, learning, and control layers. Specifically, the communication layer utilizes event-triggered mechanisms (ETMs) to transmit neighbor information, facilitating virtual consensus. The learning layer connects the communication and control layers, employing reinforcement learning (RL) to optimize tracking control with ETMs. The control layer achieves real consensus by aligning the agent states with the processed information from the communication layer. Moreover, this framework effectively mitigates the effects of coupled neighbor information on the controller and suppresses the transmission of external disturbances through the communication network. Finally, two simulation examples are used to verify the anti-interference of the hierarchical framework i.e., it’s still possible to achieve consensus after being disturbed and the effectiveness of considering the reinforcement learning layer via event-triggered mechanism which reduces the communication and learning burden to achieve optimal control.},
  archive      = {J_NEUCOM},
  author       = {Denghao Pang and Yechen Guo and Jinde Cao and Boxiang Li and Xiao-Wen Zhao},
  doi          = {10.1016/j.neucom.2025.131477},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131477},
  shortjournal = {Neurocomputing},
  title        = {Optimal event-triggered control for multi-agent systems with hierarchical framework},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal bayesian regression with a non-informative prior: Order-recursive and incremental learning. <em>NEUCOM</em>, <em>656</em>, 131476. (<a href='https://doi.org/10.1016/j.neucom.2025.131476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal Bayesian regression (OBR) for data generated from a multidimensional vector autoregressive process of order p , denoted as VAR ( p ) , has a closed-form analytic expression that has been previously obtained. Despite the closed-form expressions to compute the “OBR-VAR”, in certain practical scenarios the computational cost involved in training OBR-VAR is a bottleneck. From a computational perspective, two common scenarios that incur excessive computational cost are: 1) given a set of training data, estimating the unknown model order p generally entails computing the OBR-VAR from scratch for every p in a range from 1 to a maximum value; and 2) in dynamic environments where data arrives sequentially, currently one must recompute OBR-VAR from scratch for every new upcoming observation. To address the first issue, in this paper, an order-recursive OBR-VAR regressor using QR decomposition is proposed. This method efficiently updates the regressor without recalculating it from scratch for each p , significantly reducing computational complexity while preserving model accuracy. Analytical results demonstrate that the proposed order-recursive method achieves a computational complexity reduction by a factor proportional to p , making it scalable to larger datasets and higher model orders. To address the second issue, an incremental version of the OBR-VAR algorithm is developed for real-time data processing. This method updates the regressor incrementally as new data points arrive, maintaining accuracy without the need for costly recomputation of key matrices. Its capability makes it well-suited for continuous-time data acquisition and streaming applications, where timely and accurate responses are critical. In all cases we assume an improper non-informative prior to model the case of having no prior knowledge about the problem. Theoretical analysis and empirical evaluations using synthetic and real datasets demonstrate that both methods significantly outperform the standard OBR-VAR algorithm in terms of computational complexity while preserving accuracy.},
  archive      = {J_NEUCOM},
  author       = {Samira Reihanian and Amin Zollanvari and Siamac Fazli},
  doi          = {10.1016/j.neucom.2025.131476},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131476},
  shortjournal = {Neurocomputing},
  title        = {Optimal bayesian regression with a non-informative prior: Order-recursive and incremental learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-stream GCN-based action recognition framework using trustworthy fusion decision from different skeleton descriptors. <em>NEUCOM</em>, <em>656</em>, 131475. (<a href='https://doi.org/10.1016/j.neucom.2025.131475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex motion processes, different human skeleton descriptors can characterize skeletal features across various dimensions. The frequency of spatiotemporal changes in different joints is largely influenced by the type of action. This paper presents a dual-stream GCN-based action recognition framework, which involves Slow-stream and Fast-stream networks to process skeletal features of different spatiotemporal change characteristics. In the parallel processing architecture of graph convolutional layers, adaptive adjacency matrices that strengthen spatial and temporal feature extraction are proposed to learn the implicit relationships between skeletal joints. Furthermore, different skeletal features have significantly varying impacts on the accuracy of action recognition. The Dirichlet distribution and an optimized Dempster combination rule are introduced for trustworthy decision when fusing multi-branch opinions obtained from different skeleton descriptors. Extensive experiments on three authoritative datasets demonstrate that the proposed method achieves state-of-the-art performance while reducing uncertainty in action recognition.},
  archive      = {J_NEUCOM},
  author       = {Wenrui Zhu and Donghui Shi and Junqi Yu},
  doi          = {10.1016/j.neucom.2025.131475},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131475},
  shortjournal = {Neurocomputing},
  title        = {A dual-stream GCN-based action recognition framework using trustworthy fusion decision from different skeleton descriptors},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bipartite tracking consensus for fractional-order nonlinear multiagent systems with sampled-data and input saturation. <em>NEUCOM</em>, <em>656</em>, 131472. (<a href='https://doi.org/10.1016/j.neucom.2025.131472'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on the sampled-data bipartite tracking consensus (BTC) issue for a type of fractional-order (FO) nonlinear multiagent systems (FOMASs) subject to input saturation. In the network under consideration, agents exhibit both competitive (CM) and cooperative (CO) interactions simultaneously. By employing Lyapunov stability theory, the FO Halanay-type Inequality , and the linear matrix inequality (LMI) approach, several criteria are derived to guarantee that the considered MASs can attain the BTC. Moreover, by utilizing the matrix decomposition (MD) approach, the dimensions of matrix inequalities are significantly reduced, which helps alleviate computational complexity. As a result, the derived results can be effectively applied to large-scale FOMASs. Also, the controller gain matrix is clearly represented based on the solutions of a series of matrix inequalities. Besides, we present a method for estimating the maximum attraction region of BTC. Ultimately, numerical simulation is employed to substantiate our theoretical analysis.},
  archive      = {J_NEUCOM},
  author       = {Zhi Qiao and Luyang Yu and Yuman Li and Yurong Liu},
  doi          = {10.1016/j.neucom.2025.131472},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131472},
  shortjournal = {Neurocomputing},
  title        = {Bipartite tracking consensus for fractional-order nonlinear multiagent systems with sampled-data and input saturation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous federated semantic segmentation. <em>NEUCOM</em>, <em>656</em>, 131470. (<a href='https://doi.org/10.1016/j.neucom.2025.131470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) offers a promising solution for semantic segmentation in scenarios involving data distribution across isolated clients. Despite recent advances, federated semantic segmentation (FSS) continues to face key challenges. One major issue is the shift from centralized to decentralized training, where diverse and limited local data hinder consistent pixel-level representation learning. Another challenge is data heterogeneity from imbalanced class distributions across clients, which weakens feature consistency and degrades global performance. These limitations often lead to inconsistent feature learning and degraded global performance. To address the challenges of class heterogeneity and insufficient pixel-level representation learning in FSS, we propose a novel pixel-aware FSS framework that improves local adaptation and semantic consistency. Specifically, we design a fine-tuning strategy that initializes each client with a lightweight pre-trained model and performs local updates over multiple epochs. This improves model adaptability to local distributions while reducing communication overhead. To further enhance semantic consistency across heterogeneous clients, we introduce a client clustering strategy based on pixel-level semantic features. Clients with similar class distributions are grouped to encourage consistent feature learning within clusters. Cluster-level training and aggregation are then followed by a global aggregation step, promoting more robust and aligned semantic understanding. Empirical evaluation across multiple benchmark datasets confirms that our method achieves consistently high segmentation precision and enhanced model adaptability in highly heterogeneous federated scenarios.},
  archive      = {J_NEUCOM},
  author       = {Chen Zhang and Jiarui Wang and Yu Xie and Xinlei Wang and Bin Yu},
  doi          = {10.1016/j.neucom.2025.131470},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131470},
  shortjournal = {Neurocomputing},
  title        = {Heterogeneous federated semantic segmentation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized containment control for delayed fractional-order nonlinear multi-agent systems with unknown disturbances. <em>NEUCOM</em>, <em>656</em>, 131469. (<a href='https://doi.org/10.1016/j.neucom.2025.131469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the issue of generalized containment control is explored for a class of delayed fractional-order nonlinear multi-agent systems (MASs) with unknown disturbances. It is assumed that the MAS under consideration has multiple dynamic leaders, and its dynamics are governed by fractional-order differential equations, and suffers from the unknown but norm-bounded external disturbances. Also, the directed graph of the MAS is assumed to have a united directed spanning tree. Furthermore, for the sake of saving communication resources, an event-triggered mechanism is introduced to regulate the signal transmission. In the presence of the external disturbances, the generalized containment control is analyzed by means of Lyapunov stability theory, algebraic graph theory, Halanay-type inequality, etc., and sufficient conditions are established to ensure that all followers ultimately enter a certain neighborhood of the convex hull formed by the leaders. In the meanwhile, it is also proven that the Zeno phenomenon can be excluded for the concerned MAS. Finally, a numerical simulation is presented to further illustrate the effectiveness of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Zhi Qiao and Luyang Yu and Hong Lin and Yurong Liu},
  doi          = {10.1016/j.neucom.2025.131469},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131469},
  shortjournal = {Neurocomputing},
  title        = {Generalized containment control for delayed fractional-order nonlinear multi-agent systems with unknown disturbances},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CBH-YOLO: A steel surface defect detection algorithm based on cross-stage mamba enhancement and hierarchical semantic graph fusion. <em>NEUCOM</em>, <em>656</em>, 131467. (<a href='https://doi.org/10.1016/j.neucom.2025.131467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of surface defects in steel materials plays a pivotal role in ensuring industrial production quality and operational safety. However, existing deep learning-based detection methods face significant challenges in steel surface defect detection, including limited receptive field coverage, inadequate multi-scale feature integration, and insufficient feature discrimination under complex backgrounds. To address these limitations, this work introduces CBH-YOLO, a novel steel surface defect detection algorithm. The proposed framework incorporates three fundamental innovation modules: (1) Cross-stage Mamba-Enhanced Multi-scale Convolution (CMMC) module, which synergistically combines the advantages of state space models with large kernel convolutions alongside adaptive attention mechanisms, substantially expanding receptive field coverage while enhancing multi-scale feature extraction capabilities; (2) Binary Amplification Matrix (BAM) module, which innovatively integrates FlexWave (FXW) dynamic activation functions with OmniScale (OSC) multi-scale perception mechanisms to achieve adaptive nonlinear feature mapping and refined representation; (3) Hierarchical Semantic Graph Fusion Network (HSGFN), which models high-order correlations among features through hypergraph structures combined with adaptive feature fusion mechanisms, enabling more effective multi-scale feature integration. Comprehensive experimental validation on NEU-DET and GC10-DET benchmark datasets demonstrates that CBH-YOLO achieves improvements of 2.7 % and 3.2 % in mAP@50 metrics compared to the baseline YOLOv11 model, while maintaining exceptional computational efficiency. This research provides a high-precision, high-efficiency solution for steel surface defect detection, offering significant theoretical value and practical application prospects.},
  archive      = {J_NEUCOM},
  author       = {Bo Gao and Jingcheng Tong and RongRong Fu and ZhenZhen Zhang and YiLin Yuan},
  doi          = {10.1016/j.neucom.2025.131467},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131467},
  shortjournal = {Neurocomputing},
  title        = {CBH-YOLO: A steel surface defect detection algorithm based on cross-stage mamba enhancement and hierarchical semantic graph fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMNet: Incomplete multi-modal alzheimer’s disease diagnosis with dual memory network. <em>NEUCOM</em>, <em>656</em>, 131465. (<a href='https://doi.org/10.1016/j.neucom.2025.131465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the challenge of missing modality, existing multi-modal learning methods become impractical and missing modality is a serious impediment to a good multi-modal learning performance. Meanwhile, we note that the existing methods for addressing missing modality issue tend to explore complete information by using either cross-generative approaches via simply filling in missing modality data, and do not consider the specific information, resulting in a sub-optimal performance for Alzheimer’s Disease diagnosis with multi-modal data. To address this problem, we propose a novel Dual Memory Network (DMNet) that comprises the Tabular Alignment Memory bank (TAM) and Dynamic Re-optimizing Memory bank (DRM) to complement the missing modality information in multi-modal learning for Alzheimer’s disease diagnosis. More specifically, TAM stores the information aligned with clinical tabular data, and maintains the feature distribution alignment between clinical tabular data and imaging modalities. Besides, TAM is updated by a memory aligning strategy. Then, DRM stores modality specific information from complete modalities, and we design a memory optimizing strategy that incorporates Feature Consistency (FC) loss and Memory Correspondence (MC) loss to update the memory items in DRM to effectively represent specific information of modalities. This novel dual memory network enhances model performance and improves model usability in multi-modal learning with missing modality, providing a more informative feature distribution to complement the missing modality. Extensive experiments, including quantitative and qualitative analyses, as well as various ablation studies, demonstrate that our proposed method achieves state-of-the-art performance in the classification task on the ADNI dataset.},
  archive      = {J_NEUCOM},
  author       = {Nana Jia and Zhiao Zhang and Tong Jia},
  doi          = {10.1016/j.neucom.2025.131465},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131465},
  shortjournal = {Neurocomputing},
  title        = {DMNet: Incomplete multi-modal alzheimer’s disease diagnosis with dual memory network},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WDWorm: A runtime-efficient and user-friendly GUI-based toolbox for experimenting with the nerve net of c. elegans. <em>NEUCOM</em>, <em>656</em>, 131464. (<a href='https://doi.org/10.1016/j.neucom.2025.131464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nerve net simulators of C. elegans heavily support research on its nerve net functionality by offering the possibility to conduct digital experiments instead of real ones. However, current software tools are complex and difficult to use for non-programmers. With WDWorm, we offer a user-friendly toolbox with graphical user interface for simulating and experimenting with C. elegans’ nerve net. It does not require an installation and allows for several modifications of the nerve net, including parameter changes for each neuron and connection or the deactivation of individual neurons. Furthermore, a comparison with other software tools highlights that WDWorm is currently the most runtime-efficient approach for simulating and digitally experimenting with C. elegans . To invite other developers and researchers, we provide the source code in an open-access format under a CC-BY 4.0 Creative Commons license. The code is publicly available at https://github.com/dsacri/WDWorm .},
  archive      = {J_NEUCOM},
  author       = {Sebastian Jenderny and Daniel Sacristán and Philipp Hövel and Christian Albers and Isabella Beyer and Karlheinz Ochs},
  doi          = {10.1016/j.neucom.2025.131464},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131464},
  shortjournal = {Neurocomputing},
  title        = {WDWorm: A runtime-efficient and user-friendly GUI-based toolbox for experimenting with the nerve net of c. elegans},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Curriculum learning-based slimmable cross-component prediction for video coding. <em>NEUCOM</em>, <em>656</em>, 131463. (<a href='https://doi.org/10.1016/j.neucom.2025.131463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-component prediction plays an important role in video coding, which aims to eliminate redundancy between color components under the guidance of luma information. Recently, learning-based cross-component prediction has made significant strides in performance. However, current cross-component prediction methods typically train models directly on a dataset with different types of data, which generally results in overfitting for the flat textured data and underfitting for the complex textured data. To improve coding performance without excessively increasing the complexity, a cost-effective attention-based slimmable cross-component prediction network (SCCPN) is proposed. Although trained as a single model, SCCPN is capable of being executed at different levels of capacity, resulting in varying prediction results tailored to data with different characteristics. With the goal of further improving the generalization capability and prediction accuracy of the network, a curriculum learning strategy combined with slimmable convolutions is then designed, which employs the classification of prediction difficulty to represent whether the texture is flat or complex, and fits complex data with a small number of additional parameters. An adaptive search strategy is also introduced to speed up the selection of channels for slimmable convolutions. Experimental results demonstrate that when integrated into H.266/Versatile Video Coding (VVC), SCCPN achieves up to −0.62 %/−3.34 %/−2.68 % BD-rate reductions on Y/Cb/Cr components, respectively, over the H.266/VVC anchor. The performance gain outperforms the state-of-the-art learning-based cross-component prediction methods, while the increased complexity in both encoding and decoding is lower than the other compared cross-component prediction methods using neural networks. Moreover, performance gain can also be observed when SCCPN is integrated into the latest reference software of Beyond VVC, with BD-rate reductions of −0.17 %/−1.00 %/−1.02 % on Y/Cb/Cr components respectively.},
  archive      = {J_NEUCOM},
  author       = {Chengyi Zou and Shuai Wan and Marc Gorriz Blanch and Luka Murn and Juil Sock and Fei Yang and Luis Herranz},
  doi          = {10.1016/j.neucom.2025.131463},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131463},
  shortjournal = {Neurocomputing},
  title        = {Curriculum learning-based slimmable cross-component prediction for video coding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Representative negative sampling for graph positive-unlabeled learning. <em>NEUCOM</em>, <em>656</em>, 131462. (<a href='https://doi.org/10.1016/j.neucom.2025.131462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph positive-unlabeled (GPU) learning is an important task that aims to develop binary classifiers using only positive and unlabeled nodes, which are commonly encountered in real-life applications. Although selecting reliable negative samples is a highly promising approach, it typically only selects high-confidence examples, which lack representativeness and fail to fully capture the diversity of the negative example space. To address this gap, our key insight, inspired by galactic dynamics, is to model the positive prototype center as a continuously evolving gravitational center maintained via a momentum moving average, just like the stars in the universe are always moving forward rather than remaining still. This dynamic anchor allows us to robustly define a reliable negative region—its “gravitational field”—for sampling representative “planets” (negative examples). We propose StarHunter-PU (SH-PU), a framework that operationalizes this insight by unifying graph representation learning with our dynamic, prototype-guided representative sampling algorithm. This ensures the sampled negatives are both diverse and informative, providing accurate information for training a robust binary classification model. Experimental results on real-world datasets show that our StarHunter-PU method significantly outperforms existing methods and even achieves competitive performance compared to fully labeled methods.},
  archive      = {J_NEUCOM},
  author       = {Luyue Wang and Xinyuan Feng and Rui Mao and Yin Li and Chunquan Liang},
  doi          = {10.1016/j.neucom.2025.131462},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131462},
  shortjournal = {Neurocomputing},
  title        = {Representative negative sampling for graph positive-unlabeled learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance and interpretability analysis of code generation large language models. <em>NEUCOM</em>, <em>656</em>, 131461. (<a href='https://doi.org/10.1016/j.neucom.2025.131461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Large Language Models (LLMs) are increasingly getting integrated into software development workflows, understanding their reliability, error patterns and interpretability in real-world development scenarios is crucial for establishing their practical utility. This study evaluates and interprets the performance of 15 open-source LLM models, including Code LLaMa, Granite Code, DeepSeek-Coder-V2, and Yi-Coder on code translation and generation from requirements using the Rosetta Code dataset across diverse programming languages and tasks. Syntactic correctness and code quality are quantified using metrics such as CodeBLEU, chrF, and METEOR. Interpretability is explored through Feature Ablation and Shapley Value Sampling to elucidate prompt processing mechanisms. Results indicate high syntactic correctness and quality scores for models such as DeepSeek-Coder-V2 and Yi-Coder, alongside observed sensitivities to specific prompt components. This research provides quantitative and qualitative insights into the capabilities and limitations of open-source code-generating LLMs, informing model selection and the understanding of LLM-generated code.},
  archive      = {J_NEUCOM},
  author       = {Vishnu S. Pendyala and Neha B. Thakur},
  doi          = {10.1016/j.neucom.2025.131461},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131461},
  shortjournal = {Neurocomputing},
  title        = {Performance and interpretability analysis of code generation large language models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing long-term memory in federated class continual learning with lightweight adapters. <em>NEUCOM</em>, <em>656</em>, 131459. (<a href='https://doi.org/10.1016/j.neucom.2025.131459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) collaboratively trains a global model by aggregating local model parameters rather than raw data. Traditional FL frameworks assume that data classes are predefined and static. However, clients often encounter continuous data streams with dynamically emerging classes in practical applications, leading to a phenomenon known as catastrophic forgetting. Federated Class-Continual Learning (FCCL) has been introduced to address this challenge but still suffers from significant performance deterioration in scenarios with expanding task scales, particularly for tasks learned in the distant past. We propose a novel FCCL framework leveraging lightweight adapters to mitigate catastrophic forgetting as the number of tasks scales. To tackle the challenge of long-term memory decline, we developed task-specific adapters for clients to enhance memory retention. Additionally, we developed an image generation method tailored for lightweight adapters and trained task discriminators using the generated images. This enables the automatic loading of lightweight modules during inference, reducing human intervention. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet achieve significant performance improvements ranging from 1.73 to 4.07 times compared to baseline methods, effectively mitigating catastrophic forgetting in class-scaling scenarios. The complete implementation is available at https://github.com/notaerfa/FCLORA .},
  archive      = {J_NEUCOM},
  author       = {Pan Wang and Ji Wang and Zhengyi Zhong and Weidong Bao and Yaohong Zhang and Jianguo Chen},
  doi          = {10.1016/j.neucom.2025.131459},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131459},
  shortjournal = {Neurocomputing},
  title        = {Enhancing long-term memory in federated class continual learning with lightweight adapters},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive granular-ball based density peak clustering. <em>NEUCOM</em>, <em>656</em>, 131458. (<a href='https://doi.org/10.1016/j.neucom.2025.131458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of data processing, the Granular-ball (GB) provides a coarse-grained data representation, offering a novel approach to improving clustering efficiency. The Fast Density Peak Clustering Algorithm based on Granular-balls (GB-DP) reduces computational granularity, which not only decreases operation time in large-scale data processing but also produces good clustering results. However, the GB-DP algorithm faces two main issues: sensitivity to the threshold parameter for generating GB and the requirement for manually selecting clustering centers, both of which affect the algorithm's efficiency and stability. To address these challenges, this paper proposes an Adaptive Granular-ball based Density Peak Clustering Algorithm (AGB-DP). First, a weighted Distribution Measure (DM) is used to dynamically generate GB. In contrast to the fixed threshold strategy used in GB-DP, this method effectively captures the data's distribution characteristics, mitigating the problem of parameter sensitivity. Second, by integrating two factors—data volume and geometric compactness—the density of GB is redefined, enhancing the accuracy of density calculations. Finally, an automatic screening strategy is employed to select GB as clustering centers, eliminating the instability introduced by manual intervention. Experimental results on both synthetic and real-world datasets demonstrate that AGB-DP, requiring only the number of clusters to be specified, achieves superior clustering results on most datasets compared to classical clustering algorithms and recent DP-based methods and shows greater robustness and stability.},
  archive      = {J_NEUCOM},
  author       = {Xingguo Zhang and Li Xu and Weikuan Jia},
  doi          = {10.1016/j.neucom.2025.131458},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131458},
  shortjournal = {Neurocomputing},
  title        = {Adaptive granular-ball based density peak clustering},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting the connections between images and deep feature vectors in model inversion attacks. <em>NEUCOM</em>, <em>656</em>, 131457. (<a href='https://doi.org/10.1016/j.neucom.2025.131457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model inversion attack aims to reconstruct private samples from given deep neural networks. As the connections between the images and their corresponding deep feature vectors are unknown, it is difficult to utilize the information in the feature vectors during inversion. In this paper, connections between the images and their deep convolutional feature vectors are investigated. The directions of the vectors are used to represent the structures of both image vectors and feature vectors. Cosine similarity is further used to measure the structural similarity between different vectors. For a given target feature extractor, we find that the structures of the images and their feature vectors are highly correlated. Using this-property, Aug-MIA is proposed to perform model inversion with a few leaked feature vectors. In Aug-MIA, the feature vectors are first augmented by the proposed Structure Augmentation Algorithm. Then, a reconstruction model is trained using these augmented feature vectors to reconstruct images. Various experiments are performed on different datasets to validate our ideas. The results show that Aug-MIA performs better when fewer feature vectors are available. Specifically, when only 1 feature vector per class is leaked, it can improve the reconstruction rate by about 10.7 % on FaceScrub and about 4.2 % on MNIST, respectively.},
  archive      = {J_NEUCOM},
  author       = {Zeping Zhang and Jie Huang},
  doi          = {10.1016/j.neucom.2025.131457},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131457},
  shortjournal = {Neurocomputing},
  title        = {Exploiting the connections between images and deep feature vectors in model inversion attacks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent-space diffusion models for stealthy and transferable adversarial attacks on object detection. <em>NEUCOM</em>, <em>656</em>, 131456. (<a href='https://doi.org/10.1016/j.neucom.2025.131456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tons of prior works have leveraged Generative Adversarial Networks (GANs) to synthesize adversarial examples that exhibit visual fidelity. Nonetheless, the intricacy of GANs’ latent space complicates the generation of imperceptible adversarial noises, rendering the process difficult to control. The emergence of diffusion models, which iteratively refine images through a progressive denoising mechanism, offers a more tractable and interpretable solution for a controllable generation. Inspired by this, we propose a latent-space-based covert adversarial attack framework (LSDM) grounded in diffusion models to craft adversarial examples that are both visually natural and highly effective against object detection models. Central to our approach is the Latent Space Perceptual Consistency Constraint, which ensures visual-consistency by embedding perturbations into the latent space for each denoising step, while utilizing the original image as a condition guider during the de-noising pass. Moreover, to balance attack performance and the risk of overfitting, we also propose a Stepwise Prediction and Adaptive Optimization strategy, which dynamically modulates the perturbations at the current time step and determines optimal number of diffusion time steps based on the transferability of the attack against diverse black-box models. To further enhance the framework’s attacking transferability, we introduce a novel Multi-box Translation Attack strategy, which augments the spatial location diversities for each bounding box. Extensive experiments demonstrate that, compared with state-of-the-art methods, LSDM further reduces the average black-box detection mAP by 1.52 %, while improving image quality scores by 1.71 % on object detection datasets such as COCO and VOC, showcasing superior attack effectiveness and visual fidelity. The source code is publicly available at https://github.com/LSDM .},
  archive      = {J_NEUCOM},
  author       = {Wenxuan Wang and Huihui Qi and Zhixiang Huang and Bangjie Yin and Peng Wang},
  doi          = {10.1016/j.neucom.2025.131456},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131456},
  shortjournal = {Neurocomputing},
  title        = {Latent-space diffusion models for stealthy and transferable adversarial attacks on object detection},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User intent disentanglement for multi-behavior recommendation via information bottleneck principle. <em>NEUCOM</em>, <em>656</em>, 131454. (<a href='https://doi.org/10.1016/j.neucom.2025.131454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-behavior recommendation systems have advanced rapidly by leveraging users’ diverse auxiliary behavior interactions to improve recommendations for the target behavior (a.k.a. purchase). While existing methods have made strides by integrating auxiliary behaviors with purchase histories to deliver high-quality recommendations, they often fail to identify spurious correlation intents within auxiliary behaviors that conflict with users’ target intents. Indiscriminately incorporating such correlations into the prediction of target intents may lead to performance degradation. To address this issue, we propose a Multi-Behavior Intent Disentanglement framework (MBID) for multi-behavior recommendation, which focuses on disentangling spurious correlation intents via the Information Bottleneck (IB) principle. In particular, we first design a time-sensitive spurious correlation coefficient to quantify spurious correlation intents and guide the subsequent multi-intent learning. Then, to disentangle spurious correlation intents, we propose a projection-based intent extraction method to decompose the genuine and spurious correlation intents within auxiliary behaviors. Based on this, we conceive an IB-based multi-intent learning task to disentangle the spurious correlation intents and transfer the genuine correlation intents from auxiliary behaviors into the target behavior, thereby obtaining high-quality representations of the target intent. Extensive experiments on three real-world datasets demonstrate that MBID significantly outperforms the state-of-the-art baselines by effectively disentangling the spurious correlation intents. We release our model implementation at: https://github.com/LokHsu/MBID .},
  archive      = {J_NEUCOM},
  author       = {Chenzhong Bin and Tongxin Xu and Feng Zhang},
  doi          = {10.1016/j.neucom.2025.131454},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131454},
  shortjournal = {Neurocomputing},
  title        = {User intent disentanglement for multi-behavior recommendation via information bottleneck principle},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PolyModNet: Advanced positional encodings and ethical bias mitigation in adaptive multimodal fusion for multilingual language understanding. <em>NEUCOM</em>, <em>656</em>, 131450. (<a href='https://doi.org/10.1016/j.neucom.2025.131450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural Language Understanding (NLU) plays a crucial role in Natural Language Processing (NLP), enabling machines to interpret and process human language across various applications. Despite advancements, challenges remain, including variations in data types, inconsistencies in labeling, computational demands, and biases in training datasets. These challenges emphasize the need for ethical and effective NLU solutions. To address these issues, the proposed PolyModNet combines techniques from NLP and computer vision to improve both text and image understanding. The model enhances data representation and compensates for limited training data using advanced augmentation methods such as mixup, gridmask, and positional encoding, optimized for Vision Transformer. By integrating RoBERTa-BERT and Vision Transformer, PolyModNet ensures accurate alignment of text and image features through Transformer-based encoding, specialized transformations, and structured positional encodings. Additionally, it employs a universal multilingual framework that enables language-independent retrieval and flexible task adaptation. Ethical concerns are addressed through bias detection and adversarial training, ensuring fairness in multimodal analysis. Extensive evaluations demonstrate the model’s effectiveness across multiple NLP tasks, achieving 85.71 % accuracy in sentiment analysis, strong text classification performance (CoLA: 64.1 %, SST2: 96.4 %), and high accuracy in text-image retrieval (R@1: 72.00, R@5: 89.25, R@10: 92.10). The model also delivers competitive results in multimodal translation (BLEU: 45.36, METEOR: 55.62) and cross-modal retrieval (text-to-image: R@1: 67.4, image-to-text: R@1: 82.3).},
  archive      = {J_NEUCOM},
  author       = {Shaharyar Alam Ansari and Mohd Anas Wajid and Mohd Arif and Mohammad Saif Wajid},
  doi          = {10.1016/j.neucom.2025.131450},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131450},
  shortjournal = {Neurocomputing},
  title        = {PolyModNet: Advanced positional encodings and ethical bias mitigation in adaptive multimodal fusion for multilingual language understanding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wavelet attention is all you need in multimodal medical image fusion. <em>NEUCOM</em>, <em>656</em>, 131448. (<a href='https://doi.org/10.1016/j.neucom.2025.131448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the multimodal medical image fusion, the fusion method based on frequency domain features is a research hotspot. However, “how to effectively enhance the high frequency and low frequency information in frequency domain?”, “how to fully interact the cross-modal spatial features in feature fusion?” are the keys to improve the fusion performance. To solve this problem, this paper proposes a multimodal medical image fusion network (WTA-Net) based on Wavelet Attention. The main innovations are as follows: Firstly, the Encoder-Decoder fusion network WTA-Net with dual-encoder and single-decoder is proposed. The network effectively capture the frequency domain features in different modal images and enhance the ability of information flow between modalities. Secondly, a Wavelet Attention(WA) is designed in the encoder, which effectively enhance the high frequency and low frequency information of the lesion. Thirdly, the Cross Modal Information Fusion Module(CMIFM) is designed in the fusion stage, which fully interactive cross-modal spatial features. Finally, experiments are performed on the Whole Brain Atlas dataset and the PET-CT lung dataset. In brain MRI images and PET images comparison experiment, IE, AG and EN evaluation indexes are improved by 18.92 %, 14 % and 18.25 %, respectively. In CT mediastinal window images and PET images comparison experiment, IE and SF evaluation indexes are improved by 12.08 % and 49.4 %, respectively, WTA-Net highlight the lession information, which has positive significance for computer-aided diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Tao Zhou and Mingzhe Zhang and Zhe Zhang and Jiaqi Wang and Yang Liu and Huiling Lu},
  doi          = {10.1016/j.neucom.2025.131448},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131448},
  shortjournal = {Neurocomputing},
  title        = {Wavelet attention is all you need in multimodal medical image fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-domain mutual compensation network for multi-modality image fusion. <em>NEUCOM</em>, <em>656</em>, 131443. (<a href='https://doi.org/10.1016/j.neucom.2025.131443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing research has demonstrated that fusing both spatial and frequency domain information from images can enhance fusion model performance, particularly in terms of saliency preservation and texture enhancement. However, designing effective fusion strategies to coordinate complementary information from both domains, while maximizing the unique characteristics and advantages of each and avoiding information conflict or redundancy, remains a challenge that requires further exploration and optimization. To address this issue, we propose a spatial–frequency Dual-Domain Mutual Compensation Network, termed D2Fusion. In our approach, the Mamba module serves as the core component of the spatial branch, capturing long-range dependencies to enhance the focus on the global spatial structure of input features. Simultaneously, the frequency branch utilizes fast Fourier Transform and convolutional neural networks to extract local texture details from the phase and magnitude components of the input features. Unlike traditional dual-branch networks, we introduce a novel phase fusion operation within the frequency branch, which combines phase information from different modalities to generate salient target features that complement and enhance the spatial features. Furthermore, to maximize the exchange of complementary characteristics between spatial, frequency, and salient target features, we design a Mutual Compensation Block (MCB) that accounts for feature differences and a decomposition loss function based on discrete cosine distance. The MCB facilitates compensatory fusion, while the decomposition loss function reduces feature similarity prior to compensation, maximizing the complementary information between domain features. Extensive experiments validate the superiority of our method, demonstrating that D2Fusion outperforms existing state-of-the-art approaches in both multi-modal image fusion and downstream task performance. The code for this framework is available at https://github.com/hz777xx/D2Fusion .},
  archive      = {J_NEUCOM},
  author       = {Jiwei Hu and Zhen Hu and Ping Lou and Kin-Man Lam and Qiwen Jin},
  doi          = {10.1016/j.neucom.2025.131443},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131443},
  shortjournal = {Neurocomputing},
  title        = {A dual-domain mutual compensation network for multi-modality image fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchor-aware representation learning for multi-view clustering. <em>NEUCOM</em>, <em>656</em>, 131441. (<a href='https://doi.org/10.1016/j.neucom.2025.131441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anchor-based multi-view clustering has garnered considerable attention in recent years owing to its ability to reduce computational overhead and enable efficient processing of large-scale datasets. However, existing anchor-based multi-view clustering models still present limitation: while orthogonality constraints are imposed on anchors to enhance their discriminative properties, the inherent relationships among anchors are neglected. To address this limitation, a novel Anchor-Aware Representation Learning for Multi-view Clustering (AARLMC) model is proposed. Specifically, anchor-wise self-representation learning is implemented, with orthogonality constraints applied to the anchor self-representation matrices to uncover intrinsic relationships among anchors. Furthermore, enhanced anchor representations are generated through this process. The anchor graphs are stacked into a third-order tensor with tensor nuclear norm constraint to explore the high-order correlations among multi-view data. Anchor-wise self-representation learning, enhanced anchor representations, and tensor representation are integrated into a unified framework. An optimization algorithm is developed to solve the proposed model. Comparative experiments on twelve benchmark datasets against thirteen state-of-the-art multi-view clustering methods demonstrate that the proposed model achieves superior performance. The source code is available on https://github.com/guowei1314/AARLMC .},
  archive      = {J_NEUCOM},
  author       = {Haotian Zhang and Wei Guo and Ruiyin Liu and Qiang Yang and Xuefei Xiao and Jilin Li and Gang Lei and Gang Chen},
  doi          = {10.1016/j.neucom.2025.131441},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131441},
  shortjournal = {Neurocomputing},
  title        = {Anchor-aware representation learning for multi-view clustering},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft-label generator based on classifier weights. <em>NEUCOM</em>, <em>656</em>, 131436. (<a href='https://doi.org/10.1016/j.neucom.2025.131436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft labels provide rich information between classes. Classification models obtain better generalization ability when soft labels are used as training targets in addition to hard ground-truth labels. In this paper, we propose a new approach named TarSamp to derive effective soft-targets only with the model’s classifier layer. This approach offers a simple, generic, and low-cost solution for soft label generation by fully leveraging the class-level semantics captured by the classifier layer and uncertainty injection with random sampling. We apply TarSamp to both teacher-free and teacher-available scenarios by using the classifier layer from the online model and a pre-trained teacher model, respectively. Extensive experiments on five standard image datasets are provided to evaluate the proposed approach for classifier training. TarSamp achieves more than 8 % accuracy on average for the teacher-free setting with ResNet-18, and gives on par performance by getting rid of querying to the teacher model in each forward pass during distillation for the teacher-available situation. Our results demonstrate that the proposed approach makes as a fundamental yet competitive baseline for a wide range of soft label based supervised learning.},
  archive      = {J_NEUCOM},
  author       = {Xinkai Chu and Jian-Ping Mei and Hang Zhou and Jie Chen and Rui Yan and Jing Fan},
  doi          = {10.1016/j.neucom.2025.131436},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131436},
  shortjournal = {Neurocomputing},
  title        = {Soft-label generator based on classifier weights},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CESDet: Hard pedestrian object detection architecture based on the cognitive experience of structure of human body. <em>NEUCOM</em>, <em>656</em>, 131429. (<a href='https://doi.org/10.1016/j.neucom.2025.131429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional deep learning pedestrian detection methods usually only use the information of the current image itself. Incorrect results that go against common sense are prone to occur when dealing with hard objects with small size, unusual pose, or occlusions. Recent approaches try to enhance the hard objects by constructing and utilizing empirical information. However, due to an insufficient understanding of human body structure, the constructed experience exhibits poor generalization ability to diverse poses. Furthermore, when leveraging experiential features to enhance the features of hard objects, the process is susceptible to interference from occlusions and background. Inspired by human vision, we propose CESDet, a novel pedestrian detection network that constructs and utilizes Cognition Experience of Structure of human body in an unsupervised manner. The key technical innovations are three folds: (1) an unsupervised Cognition Experience of Structure construction module that addresses pose generalization by automatically forming decoupled body parts and pose semantics, (2) a part-level fine-grained verification and feature enhancement module that addresses the interference of occlusions and background with the guidance of Cognition Experience of Structure, and (3) an end-to-end pedestrian detection network for hard objects based on the two proposed modules. Experiments comparing with seven methods on three datasets demonstrate that CESDet achieves state-of-the-art performance, with highest AP on the training dataset, and lowest degradation of AP on a novel unseen dataset. The proposed framework advances the detection of hard objects by exploiting the automatically constructed Cognition Experience of Structure with decoupled part-level appearance and pose.},
  archive      = {J_NEUCOM},
  author       = {Yanglin Pu and Xiaohui Hao and Shan Yang and Hangyuan Yang and Shengxin Dai},
  doi          = {10.1016/j.neucom.2025.131429},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131429},
  shortjournal = {Neurocomputing},
  title        = {CESDet: Hard pedestrian object detection architecture based on the cognitive experience of structure of human body},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-related potential extraction workflow based on kernel density estimation. <em>NEUCOM</em>, <em>656</em>, 131425. (<a href='https://doi.org/10.1016/j.neucom.2025.131425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event-related potentials (ERPs) are a critical neuroscientific tool for investigating brain responses to external stimuli and serve as a key linking mechanism in brain–computer interface systems. Traditional ERP extraction methods rely on threshold-based trial rejection and time-locked averaging techniques, which often have limited ability to handle outlier data and are susceptible to random artifacts. To address this, we propose a novel ERP extraction workflow based on kernel density estimation. We construct trial-wise datasets at the sampling-point granularity and model the probability distribution of each trial using Gaussian kernel density estimation, effectively reducing outlier influence while preserving all trial data. The fitted probability density function serves as the objective function for ERP extraction, enabling active reconstruction of optimal ERP waveforms by incorporating inherent EEG temporal dependencies. Specifically targeting uneven noise distribution across multiple channels, we introduce an adaptively steering kernel dynamically generated from electrode covariance matrices, which optimizes the adaptive matching of inter-channel noise structures to ensure more precise density function fitting. Using two real datasets and simulated datasets, our comparative analyses of baseline root mean square error, component-level statistical metrics, and residual correlations demonstrate that, compared with the traditional trial rejection and time-locked averaging methods, our approach exhibits outstanding effectiveness in isolating ERP components from raw signals and significantly reduces the impact of outlier contamination.},
  archive      = {J_NEUCOM},
  author       = {Weizhuang Kong and Zihao Zhang and Jing Zhu and Yizhou Li and Xiaowei Li and Bin Hu},
  doi          = {10.1016/j.neucom.2025.131425},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131425},
  shortjournal = {Neurocomputing},
  title        = {Event-related potential extraction workflow based on kernel density estimation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view optimization and refinement for high-fidelity 4D gaussian splatting. <em>NEUCOM</em>, <em>656</em>, 131424. (<a href='https://doi.org/10.1016/j.neucom.2025.131424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing dynamic 3D scenes from 2D images and synthesizing temporally diverse views is challenging due to the interplay between scene complexity and temporal dynamics. While 3D Gaussian Splatting offers an efficient solution for static scene modeling, extending it to dynamic scenes faces significant challenges in motion representation and texture fidelity. We propose a novel framework based on multi-view interpolation and joint optimization to address these challenges in sparse-view dynamic scenes. This framework combines linear and spherical interpolation strategies to generate novel views, producing high-quality interpolated images from multiple fitted viewpoints. Additionally, it incorporates consistency constraints to optimize texture representation, enhancing the reconstruction performance for dynamic scenes. Experimental results demonstrate that the proposed framework significantly improves detail fidelity and motion representation in dynamic scene reconstruction.},
  archive      = {J_NEUCOM},
  author       = {Jinhui Lin and Zhenyang Wei and Silei Shen and Fang Zhou and Xiaobin Zhu and Xu-Cheng Yin},
  doi          = {10.1016/j.neucom.2025.131424},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131424},
  shortjournal = {Neurocomputing},
  title        = {Multi-view optimization and refinement for high-fidelity 4D gaussian splatting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KD-KI: Knowledge distillation with knowledge infusion for anomaly detection and localization. <em>NEUCOM</em>, <em>656</em>, 131423. (<a href='https://doi.org/10.1016/j.neucom.2025.131423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection and localization are crucial for improving product reliability in industrial quality inspection. Existing knowledge distillation methods often cause student networks to merely mimic features of teacher networks, which makes it difficult to achieve stable and generalized detection performance. This paper introduces the KD-KI framework, which uses a knowledge infusion mechanism to transfer structured hierarchical knowledge from the teacher network to the student network. This guides the student to learn more robust representations of normal samples. Additionally, a feature bias loss is used to optimize the similarity of shallow-layer features, improving detection accuracy and localization precision. KD-KI can be deployed with standard convolutional networks and is suitable for real-time industrial inspection systems. Experimental results demonstrate that the proposed KD-KI model can yield improved performance in anomaly detection and localization compared to other competing models.},
  archive      = {J_NEUCOM},
  author       = {Wei Huang and Zhaonan Xu and Rongchun Wan and Xuhua Yang and Bingyang Zhang},
  doi          = {10.1016/j.neucom.2025.131423},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131423},
  shortjournal = {Neurocomputing},
  title        = {KD-KI: Knowledge distillation with knowledge infusion for anomaly detection and localization},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFCon: Dominant frequency enhanced ultra-long time series contrastive forecasting. <em>NEUCOM</em>, <em>656</em>, 131418. (<a href='https://doi.org/10.1016/j.neucom.2025.131418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultra-long time series forecasting (ULTSF) is crucial for fields like energy management, traffic planning, and climate prediction. However, as the forecast horizon increases, concept drift becomes a major challenge, as a fixed-length historical window struggles to generalize ultra-long temporal patterns. Extending the input series length increases computational costs and demands a higher model capacity for capturing longer temporal dependencies. To address these issues, we propose DFCon, a dominant frequency enhanced contrastive learning framework for ULTSF. DFCon combines dilated convolutions for feature extraction and multi-layer perceptrons for forecasting, with a dual contrastive loss based on dominant frequency enhancement. We introduce Temporal DFCon, which enhances the model’s sensitivity to these frequency-domain features during training, thereby improving its ability to model global temporal dependencies in the input series. Furthermore, cross-window Autocorrelated DFCon is proposed, which mitigates concept drift by constructing autocorrelated relative positive and negative samples without introducing noisy data. Experiments on five benchmark datasets show that DFCon outperforms existing methods, demonstrating its effectiveness in ULTSF. The code for this work is publicly available at: https://github.com/coding4qq/DFCon .},
  archive      = {J_NEUCOM},
  author       = {Qiaoqiao Liu and Hui Liu and MingJie Yang and Yuheng Wei and Junzhao Du},
  doi          = {10.1016/j.neucom.2025.131418},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131418},
  shortjournal = {Neurocomputing},
  title        = {DFCon: Dominant frequency enhanced ultra-long time series contrastive forecasting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Breaking the alignment barrier: A spatiotemporal alignment-free RGBT tracking approach. <em>NEUCOM</em>, <em>656</em>, 131382. (<a href='https://doi.org/10.1016/j.neucom.2025.131382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-Thermal (RGBT) tracking leverages complementary information from visible and infrared modalities to improve tracking robustness in complex environments. However, its practical deployment remains constrained by the stringent requirement for precise spatiotemporal alignment between heterogeneous modalities—a condition rarely satisfied in real-world applications. To overcome this limitation, we present SAFNet, a novel Spatiotemporal Alignment-Free Network that eliminates the need for precise cross-modal alignment through innovative architectural designs. Our framework develops a spatiotemporal interaction query module incorporating cross-modal temporal attention, which re-establishes inter-modal temporal correlations for unregistered inputs by leveraging similarity learning across asynchronous data streams. For spatial discrepancy mitigation, we propose a dual-branch pre-tracking network employing deep cross-correlation analysis, combined with an adaptive feature fusion strategy under the guidance of joint response distribution. Furthermore, we devise an innovative dynamic template update mechanism that adaptively adjusts modal update rates to maintain temporal consistency across heterogeneous data streams. Comprehensive evaluations validate SAFNet’s state-of-the-art performance across four benchmark datasets (GTOT, RGBT210, RGBT234, LasHeR), demonstrating significant improvements in tracking accuracy. The proposed architecture represents a significant advancement toward practical deployment of robust RGBT tracking systems in real-world environments with asynchronous multimodal inputs.},
  archive      = {J_NEUCOM},
  author       = {Xiaodong Liu and Meibo Lv and Daming Zhou and Lingyu Si and Ruiheng Zhang and Hui Xu},
  doi          = {10.1016/j.neucom.2025.131382},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131382},
  shortjournal = {Neurocomputing},
  title        = {Breaking the alignment barrier: A spatiotemporal alignment-free RGBT tracking approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The implicit regularization of gradient flow on separable datasets in ReLU networks. <em>NEUCOM</em>, <em>656</em>, 131367. (<a href='https://doi.org/10.1016/j.neucom.2025.131367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to investigate the implicit regularization of gradient flow when training non-linearly separable multi-class datasets in ReLU networks. We prove that the gradient flow leads the directions of each layer to converge. Besides, we show that the convergent directions of different layers collectively form a Karush-Kuhn-Tucker (KKT) point of the max normalized margin problem in parameter space. In particular, for any l ∈ [ L ] , we prove that the convergent direction of the l -th layer is the local maximum of the max normalized margin problem when other directions are fixed. This indicates that the convergent directions maximize the margin for each layer separately. Moreover, we show the growth rate of weights across different layers and demonstrate their layer-balanced properties. Furthermore, we prove that the cross-entropy loss converges and we give the tight bound of the convergence rate. In addition, we present a generalization bound for ReLU networks in multi-class tasks based on Rademacher complexity. Our results demonstrate that the generalization bound is primarily influenced by the normalized margin and the number of training samples. Finally, we present a series of numerical experiments to verify our theory.},
  archive      = {J_NEUCOM},
  author       = {Xiangyun Hui and Xiaoxuan Ma and Yixuan Yang and Song Li},
  doi          = {10.1016/j.neucom.2025.131367},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131367},
  shortjournal = {Neurocomputing},
  title        = {The implicit regularization of gradient flow on separable datasets in ReLU networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring cycle cover variants: A dataless neural networks approach. <em>NEUCOM</em>, <em>656</em>, 131361. (<a href='https://doi.org/10.1016/j.neucom.2025.131361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cycle Cover, a fundamental concept in graph theory, plays a critical role in various applications, including network design, transportation optimization, and bioinformatics. A Cycle Cover is a collection of cycles covering all the vertices of a given graph, ensuring that each vertex belongs to exactly one cycle. In this paper, we explore various aspects of Cycle Cover variants. We employ the dataless neural networks framework to establish single differentiable functions for each of these variants. Recent research has demonstrated the capability of the dataless neural networks framework in representing a host of combinatorial optimization problems. Motivated by these findings, we propose dataless neural networks tailored for the Cycle Cover variants. Additionally, we present a rigorous proof of the correctness of our approach.},
  archive      = {J_NEUCOM},
  author       = {Sangram K. Jena and K. Subramani and Alvaro Velasquez},
  doi          = {10.1016/j.neucom.2025.131361},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131361},
  shortjournal = {Neurocomputing},
  title        = {Exploring cycle cover variants: A dataless neural networks approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight deep learning for visual perception: A survey of models, compression strategies, and edge deployment challenges. <em>NEUCOM</em>, <em>656</em>, 131357. (<a href='https://doi.org/10.1016/j.neucom.2025.131357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for the deployment of deep neural networks (DNNs) in edge devices has led to the development of lightweight deep learning (LDL) models designed to operate efficiently under resource constraints. Although DNNs have achieved remarkable success in various applications, their high computational requirements often limit their deployment on devices with restricted memory and processing power. This challenge has motivated researchers to develop optimized LDL models that balance accuracy, speed, and efficiency while maintaining competitive performance. Despite existing surveys covering specific aspects of LDL models, a comprehensive review encompassing image classification, object detection, and segmentation remains limited. This proposed survey systematically explores recent advancements in LDL models, highlighting their architectures, optimization techniques, and real-world applications. This survey conducts an empirical evaluation by testing latest state-of-the-art LDL models on the Jetson Orin edge device using benchmark datasets: ImageNet for classification, VisDrone for object detection, and COCO for segmentation. The experimental analysis focuses on key performance metrics, including inference speed, model accuracy, and computational efficiency, while comparing LDL models with their conventional counterparts. This study provides a holistic understanding of the role of LDL models in edge computing, providing insight into emerging trends, challenges, and future research directions in the field.},
  archive      = {J_NEUCOM},
  author       = {Syed Muhammad Raza and Syed Murtaza Hussain Abidi and Md Masuduzzaman and Soo Young Shin},
  doi          = {10.1016/j.neucom.2025.131357},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131357},
  shortjournal = {Neurocomputing},
  title        = {Lightweight deep learning for visual perception: A survey of models, compression strategies, and edge deployment challenges},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LaSNN: Layer-wise ANN-to-SNN distillation for effective and efficient training in deep spiking neural networks. <em>NEUCOM</em>, <em>656</em>, 131351. (<a href='https://doi.org/10.1016/j.neucom.2025.131351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are biologically realistic and practically promising in low-power computation because of their event-driven mechanism. Usually, the training of SNNs suffers from accuracy loss on various tasks, yielding an inferior performance compared with ANNs. A conversion scheme is proposed to obtain competitive accuracy by mapping trained ANNs’ parameters to SNNs with the same structures. However, an enormous number of time steps are required for these converted SNNs, thus losing the energy-efficient benefit. Utilizing both the accuracy advantages of ANNs and the computing efficiency of SNNs, a novel SNN training framework is proposed, namely layer-wise ANN-to-SNN knowledge distillation (LaSNN). In order to achieve competitive accuracy and reduced inference latency, LaSNN transfers the learning from a well-trained ANN to a small SNN by distilling the knowledge rather than converting the parameters of ANN. The information gap between heterogeneous ANN and SNN is bridged by introducing the attention scheme. The knowledge in an ANN is effectively compressed and then efficiently transferred by utilizing our layer-wise distillation paradigm. We conduct detailed experiments to demonstrate the effectiveness, efficacy, and scalability of LaSNN on three benchmark data sets (CIFAR-10, CIFAR-100, and Tiny ImageNet). We achieve competitive top-1 accuracy compared to ANNs and faster inference than converted SNNs with similar performance. More importantly, LaSNN is dexterous and extensible that can be effortlessly developed for SNNs with different architectures/depths and input encoding methods, contributing to their potential development.},
  archive      = {J_NEUCOM},
  author       = {Di Hong and Yu Qi and Yueming Wang},
  doi          = {10.1016/j.neucom.2025.131351},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131351},
  shortjournal = {Neurocomputing},
  title        = {LaSNN: Layer-wise ANN-to-SNN distillation for effective and efficient training in deep spiking neural networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing spatio-temporal information using supervised local low-rank correlation embedding for depression recognition. <em>NEUCOM</em>, <em>656</em>, 131350. (<a href='https://doi.org/10.1016/j.neucom.2025.131350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) signals contain rich spatio-temporal information that reflects the brain’s dynamic activity, making it widely used in depression recognition. However, effectively integrating this information to capture discriminative and complementary features remains a key challenge. To address this issue, we propose a novel Discriminative Local Low-Rank Correlation Embedding (DLLCE) to fuse spatio-temporal information of EEG. DLLCE integrates shared low-rank representation, local invariance, discriminative constraints, and enhanced correlation analysis into a unified framework. Specifically, the shared low-rank representation is used to capture the common structural patterns, while the correlation analysis aims to reduce redundancy among feature sets. In addition, the Laplacian regularization is applied to the shared representation to preserve the local geometric structure of the original data. To further enhance discriminative capability, a discriminant graph embedding term is incorporated to exploit label information. Experimental results on EEG datasets demonstrate that DLLCE achieves superior performance compared to existing methods. This work provides new insights into EEG-based mental health assessment and holds promise for early depression diagnosis and clinical decision support.},
  archive      = {J_NEUCOM},
  author       = {Lu Zhang and Peng Xu and Zhijun Yao and Xinyan Zhang and Juan Wang and Bin Hu and Gang Feng and Hong Peng},
  doi          = {10.1016/j.neucom.2025.131350},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131350},
  shortjournal = {Neurocomputing},
  title        = {Fusing spatio-temporal information using supervised local low-rank correlation embedding for depression recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-driven baseline for few-shot fine-grained visual recognition. <em>NEUCOM</em>, <em>656</em>, 131302. (<a href='https://doi.org/10.1016/j.neucom.2025.131302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot fine-grained visual recognition (FS-FGVR), a practical yet challenging task, aims to break the dilemma of having scarce training examples for new fine-grained tasks. Meta-learning-based methods target this issue by employing the learning-to-learn strategy to train a well-generalized meta-learner from seen fine-grained tasks for unseen fine-grained tasks. However, most existing works rely too much on small-scale fine-grained training tasks. Specifically, these works demand large amounts of fine-grained data to sample these training tasks, and they are unable to generalize well to new tasks. Consequently, model capacity can be highly restricted when limited training references are available. This paper presents a novel coarse-to-fine framework named Knowledge-Driven baseline for FS-FGVR by transferring knowledge from large-scale and coarse-grained datasets. This framework departs the meta-training phase into the coarse-grained meta-pretraining and fine-grained meta-finetuning phases. First, off-the-shelf coarse-grained data is introduced to build the initialization correlations as prior knowledge. Then, we use prior knowledge to infer the representational interactions and correlations of the fine-grained representations. Extensive experiments show that our method outperforms the current methods on the public few-shot fine-grained benchmarks. We also develop extensive studies to extend our method to few-shot texture visual recognition scenarios.},
  archive      = {J_NEUCOM},
  author       = {Jieqi Sun and Jian Li and Yafeng Li},
  doi          = {10.1016/j.neucom.2025.131302},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131302},
  shortjournal = {Neurocomputing},
  title        = {Knowledge-driven baseline for few-shot fine-grained visual recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BMTM-net: A rotating machinery fault diagnosis network based on 2D-1D fusion with bidirectional multi-granularity transformer-mamba. <em>NEUCOM</em>, <em>656</em>, 131293. (<a href='https://doi.org/10.1016/j.neucom.2025.131293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotating machinery plays a critical role in industrial operations, yet existing diagnostic methods often struggle with missing correlations between sensor data, weak noise immunity, and insufficient long-range feature extraction. To address these challenges, this paper proposes BMTM-Net, a fault diagnosis network based on 2D-1D fusion with Bidirectional Multi-granularity Transformer-Mamba (BMTM). The network consists of two main components: a 2D sequential information interaction network and a 1D temporal information extraction network. The 2D network captures inter-sensor sequence relationships and temporal dependencies using a Bidirectional Multi-granularity Transformer (BM-Transformer) and an embedded Sequential-Temporal Attention Module (ST-Attention), while the 1D network enhances feature completeness and extracts temporal information through a Bidirectional Multi-granularity Mamba (BM-Mamba) network, integrated with a Channel Attention-based Fusion Module (CAFM) for adaptive feature fusion. To evaluate BMTM-Net’s effectiveness and stability, experiments were conducted on datasets from Southeast University and a Self-Built bogie integrated test stand, with various levels of noise introduced to assess noise immunity. The results demonstrate that BMTM-Net achieves over 99 % accuracy across all four datasets and maintains high accuracy even under severe noise interference (SNR = −10 dB), outperforming other state-of-the-art methods with accuracy rates of 99.60 %, 99.40 %, 98.54 %, and 94.38 %, respectively. Additionally, the model exhibits low complexity, further confirming its robustness and effectiveness in noisy environments.},
  archive      = {J_NEUCOM},
  author       = {E. Xia and Yirong Liu and Jinyang Gong and Xunhua Dai and Tongyang Pan and Shiyi Wang},
  doi          = {10.1016/j.neucom.2025.131293},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131293},
  shortjournal = {Neurocomputing},
  title        = {BMTM-net: A rotating machinery fault diagnosis network based on 2D-1D fusion with bidirectional multi-granularity transformer-mamba},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancements in radiomics: A comprehensive survey of feature types and their correlation on modalities and regions. <em>NEUCOM</em>, <em>656</em>, 131192. (<a href='https://doi.org/10.1016/j.neucom.2025.131192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey paper provides an overview of different feature types used in radiomics research and their applications across various medical imaging modalities and disease domains. The paper delves into the key aspects of the radiomics workflow, including data engineering techniques for image acquisition, preprocessing, fusion, and segmentation. It then presents a comprehensive review of the most commonly employed feature categories in radiomics, such as shape-based, first-order statistical, second-order texture, and transform-based features. The paper also discusses the emerging role of deep learning features extracted using convolutional neural networks, recurrent neural networks, and transformers. The analysis of feature usage trends across different anatomical regions and imaging modalities offers valuable insights that can guide the optimization of feature engineering strategies in future radiomics research. The survey concludes by highlighting several opportunities for further advancement in the field, including the need for larger multi-center datasets, multi-modal data fusion, self-supervised learning, and the development of efficient embedded models for on-device deployment.},
  archive      = {J_NEUCOM},
  author       = {Luca Zedda and Andrea Loddo and Cecilia Di Ruberto},
  doi          = {10.1016/j.neucom.2025.131192},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131192},
  shortjournal = {Neurocomputing},
  title        = {Advancements in radiomics: A comprehensive survey of feature types and their correlation on modalities and regions},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive low-confidence pseudolabeling for semisupervised node classification. <em>NEUCOM</em>, <em>656</em>, 131166. (<a href='https://doi.org/10.1016/j.neucom.2025.131166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have demonstrated remarkable achievements in handling graph-structured data. However, the performance of GNNs is typically limited by the lack of sufficient labeled data, which are time-consuming to obtain in real-world scenarios. Pseudolabeling has been applied to GNNs by augmenting the training set data with unlabeled data. Most pseudolabeling methods on graphs assign pseudolabels to nodes based on high-confidence thresholds. However, nodes near labeled ones generally obtain high confidence scores during training. This results in an increasing number of similar nodes being assigned pseudolabels during training, which potentially leads to a distribution shift between the labeled dataset and the augmented dataset. The distribution of the augmented dataset diverges significantly from that of the entire graph data, causing the GNNs to perform poorly on test data. In this paper, we propose a progressive low-confidence pseudolabeling (PLCP) method to progressively leverage the low-confidence data. Specifically, pseudolabels are assigned to nodes within a predefined confidence-based ranking range. To alleviate distribution shift, we keep this range constant throughout the training process to prevent excessive nodes from being assigned pseudolabels. The range is designed to be sufficiently wide to leverage low-confidence nodes. Low-confidence nodes from the range propagate information to their neighbors, which helps the model capture patterns in uncertain regions. To alleviate the impact of noisy pseudolabels, a validation-based reassignment scheme is proposed to utilize validation metrics to assign more reliable pseudolabels. Numerous experiments are conducted to demonstrate that our proposed PLCP improves the performance of state-of-the-art GNNs on graph datasets in comparison with several established methods.},
  archive      = {J_NEUCOM},
  author       = {Tao Zhu and Hua Mao and Hui Liu and Jie Chen},
  doi          = {10.1016/j.neucom.2025.131166},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131166},
  shortjournal = {Neurocomputing},
  title        = {Progressive low-confidence pseudolabeling for semisupervised node classification},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep-DFVAR: Dynamic factor vector autoregression with deep learning for regional house price index forecasting. <em>NEUCOM</em>, <em>656</em>, 131103. (<a href='https://doi.org/10.1016/j.neucom.2025.131103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {House Price Index (HPI) is an indicator that reflects changes in residential house prices over time. Predicting HPI is crucial for homebuyers to determine the right time to purchase and for policymakers to formulate housing policies. Recent studies have reported that neural network approaches outperform classical methods in HPI forecasting. However, challenges remain due to limited monthly HPI data and its time-varying statistical properties. As a result, state-of-the-art time series forecasting models often respond slowly to abrupt changes and lack economic interpretability. To address these issues, we propose Deep-DFVAR, a hybrid framework that decomposes regional HPI into shared (common trends) and idiosyncratic (regional variations) components. The shared component is predicted with Vector Autoregression (VAR) based on Granger causality, which improves interpretability and responds faster to changes. The idiosyncratic component is modeled with our deep learning model, which benefits from reduced distribution shift (train–test gap). We evaluate Deep-DFVAR on South Korean and United States datasets, empirically demonstrating that our framework outperforms traditional and recent time series forecasting models. All data and code are publicly available at: https://github.com/YeoJiSu/House-Price-Index-Prediction .},
  archive      = {J_NEUCOM},
  author       = {Jisu Yeo and Artyom Stitsyuk and Jaesik Choi},
  doi          = {10.1016/j.neucom.2025.131103},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131103},
  shortjournal = {Neurocomputing},
  title        = {Deep-DFVAR: Dynamic factor vector autoregression with deep learning for regional house price index forecasting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-based triple asynchronous switching control for fuzzy neural networks: A full-information dependent lyapunov approach. <em>NEUCOM</em>, <em>656</em>, 131097. (<a href='https://doi.org/10.1016/j.neucom.2025.131097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper employs the full-information dependent Lyapunov-Krasovskii functional (LKF) analysis approach to investigate the multiple weighting adaptive event-triggered triple asynchronous switching control problem for Takagi-Sugeno fuzzy neural networks with semi-Markov jump parameters. Considering the influence of factors such as network delays and disturbances, there may be asynchronous premise variables and modes among the system, event generator and controller. Therefore, a triple asynchronous switching control framework under the multiple weighting adaptive event-triggered scheme is developed. Under this control framework, a novel full-information dependent LKF analysis approach is proposed to analyze the stability of neural networks, which fully considers the system information, such as the membership functions (MFs) information, modes information and state information. Meanwhile, a new MFs dependent optimal H ∞ performance index is introduced to achieve better disturbance attenuation ability. The proposed analysis approach is helpful in determining the controller gains and reducing the conservatism. Ultimately, four simulation examples are provided to show the effectiveness and superiority of proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Yiteng Zhang and Linchuang Zhang and Yonghui Sun and Wen Yang},
  doi          = {10.1016/j.neucom.2025.131097},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131097},
  shortjournal = {Neurocomputing},
  title        = {Event-based triple asynchronous switching control for fuzzy neural networks: A full-information dependent lyapunov approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCHF_T: A multi-dimensional adaptive compression approach for transformer-based models. <em>NEUCOM</em>, <em>656</em>, 131071. (<a href='https://doi.org/10.1016/j.neucom.2025.131071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, pre-trained language models based on the Transformer architecture have achieved significant results in many natural language processing tasks. However, the high computational cost limits their application in real-world scenarios. Previous Transformer compression methods typically focus on single-dimensional compression, which may cause over-compression and consequently degrade model performance. Additionally, these methods lack targeted optimization for specific downstream tasks. In this paper, we propose DCHF_T, a multi-dimensional adaptive compression approach that compresses Transformer models through token compression, attention head pruning, and a lightweight FFN. This approach selects the most informative tokens during training, prunes unimportant tokens, and retains their information in a compressed form, allowing the model to focus more on task-relevant inputs. Furthermore, DCHF_T combines attention head pruning and a lightweight FFN to reduce computation and parameter size across multiple dimensions. We employ multi-objective evolutionary search to optimize the trade-off between accuracy and efficiency under various computational budgets. Experimental results on the GLUE benchmark demonstrate that DCHF_T achieves the best compression–performance trade-off. While maintaining the highest accuracy, DCHF_T achieves a reduction of 3.7 × and 3.6 × in FLOPs on BERT-base and RoBERTa-base, respectively. By implementing adaptive multi-dimensional compression, DCHF_T provides a systematic solution for deploying Transformer models in resource-constrained scenarios.},
  archive      = {J_NEUCOM},
  author       = {Yaoyao Yan and Da Wang and Jing Ye and Hui Yu and Dianjie Lu and Yuang Zhang and Weizhi Xu and Fang’ai Liu},
  doi          = {10.1016/j.neucom.2025.131071},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131071},
  shortjournal = {Neurocomputing},
  title        = {DCHF_T: A multi-dimensional adaptive compression approach for transformer-based models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key-concept thinking prompting for improved reasoning in large language models. <em>NEUCOM</em>, <em>656</em>, 130986. (<a href='https://doi.org/10.1016/j.neucom.2025.130986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in large language models (LLMs) have significantly accelerated the development of natural language processing (NLP) research, demonstrating remarkable capabilities in understanding and generating human-like text. However, these models face limitations when it comes to system 2 tasks, which require slow, multi-step, and conscious reasoning. To address these limitations, we introduce a method called Key-Concept Thinking (KCT), which enhances the model’s reasoning ability by directing it to identify and prioritize key concepts within a problem. Building on the Chain-of-Thought (CoT) prompting method, KCT anchors its approach in core ideas, allowing the model to form a deeper understanding of the problem’s structure and purpose. This targeted approach aims to improve both the accuracy and efficiency of the model’s reasoning, making it better equipped to handle tasks that require precision and deep understanding. We evaluate our proposed prompting strategies using 24 reasoning tasks across four categories: arithmetic, commonsense, symbolic, and other logical reasoning tasks, with three prominent large models: ChatGLM4, Baichuan2, and DeepSeek, respectively. The results show that the Zero-shot-KCT and Zero-shot-CoT-KCT strategies outperform traditional zero-shot and few-shot prompting strategies, highlighting the effectiveness of incorporating key concept thinking into the reasoning processes of LLMs. Our findings have implications for the development of more effective prompting strategies for LLMs that can handle complex reasoning tasks with higher accuracy and coherence.},
  archive      = {J_NEUCOM},
  author       = {Minghua Tang and Chen Bian and Liming Yang and Xueling Zhong},
  doi          = {10.1016/j.neucom.2025.130986},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {130986},
  shortjournal = {Neurocomputing},
  title        = {Key-concept thinking prompting for improved reasoning in large language models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
