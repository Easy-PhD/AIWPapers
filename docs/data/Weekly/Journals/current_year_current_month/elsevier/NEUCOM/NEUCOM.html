<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NEUCOM</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="neucom">NEUCOM - 138</h2>
<ul>
<li><details>
<summary>
(2025). GDViT: Group-level decorrelation-based vision transformer for domain generalization. <em>NEUCOM</em>, <em>657</em>, 131624. (<a href='https://doi.org/10.1016/j.neucom.2025.131624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality-inspired domain generalization aims to improve model generalization by removing correlations between relevant and irrelevant features. However, a key challenge lies in effectively distinguishing the two. Existing methods, lacking explicit feature grouping, often eliminate all feature correlations indiscriminately, which disrupts the internal structure of relevant features and degrades generalization performance. In this work, we propose a group-level decorrelation-based vision Transformer that explicitly separates features (tokens) into relevant and irrelevant groups. This design preserves the internal correlations within relevant features while removing the correlations between the two groups. To achieve this, we introduce a feature grouping module that guides the separation process, followed by a grouping Transformer encoder that performs inter-group decorrelation, enabling the model to focus more on task-relevant information. Additionally, a supervised contrastive loss is employed to further enhance generalization. Extensive experiments demonstrate that our method significantly improves out-of-distribution performance. Visual analysis further shows that our model suppresses attention to irrelevant features, mitigating spurious correlations and resulting in more stable predictions. Our approach achieves strong performance in both multi-source and single-source domain generalization settings.},
  archive      = {J_NEUCOM},
  author       = {Wenqiang Tang and Zhouwang Yang and Yanzhi Song},
  doi          = {10.1016/j.neucom.2025.131624},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131624},
  shortjournal = {Neurocomputing},
  title        = {GDViT: Group-level decorrelation-based vision transformer for domain generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed GNE seeking for aggregative games under event-triggered communication: Predefined-time convergent algorithm design. <em>NEUCOM</em>, <em>657</em>, 131623. (<a href='https://doi.org/10.1016/j.neucom.2025.131623'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the context of distributed generalized Nash equilibrium (GNE) seeking in aggregative games, it is challenging yet interesting to design fast GNE seeking algorithms using energy-efficient communication strategy. However, most existing distributed GNE seeking algorithms can only achieve asymptotic convergence under continuous-time communication setting, resulting in a slower convergence rate and greater consumption of communication resources. In this paper, by exploiting two time-varying gain feedback functions, we present a new kind of distributed GNE seeking algorithm by integrating predefined-time control law with event-triggered communication strategy. It is theoretically shown that the proposed algorithm can solve the predefined-time GNE seeking problem for aggregative games with Zeno behavior being avoided during the seeking process. Compared with the existing algorithms, the present one exhibits several salient features: 1) the convergence time can be preset according to task requirements; 2) the communication resources can be significantly saved by the event-triggered mechanism; and 3) the proposed algorithms exhibit simplicity in their structures and possess the advantage of easy implementability.},
  archive      = {J_NEUCOM},
  author       = {Zhijun Guo and Lingwei Zeng and Jinlei Cheng and Pengwen Xiong and Qian Li},
  doi          = {10.1016/j.neucom.2025.131623},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131623},
  shortjournal = {Neurocomputing},
  title        = {Distributed GNE seeking for aggregative games under event-triggered communication: Predefined-time convergent algorithm design},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based multi-modal MRI analysis with probabilistic attention for stroke lesion detection. <em>NEUCOM</em>, <em>657</em>, 131620. (<a href='https://doi.org/10.1016/j.neucom.2025.131620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke lesion detection in brain MRI remains challenging as existing deep learning methods process single modalities and ignore anatomical boundaries, limiting clinical adoption. We develop a graph-based framework that integrates neuroanatomical priors and multi-modal imaging for automated stroke lesion detection. Our approach uses anatomically-constrained supervoxel generation and graph attention networks with probabilistic attention attribution for interpretable lesion detection. Evaluated on the SOOP dataset (1715 subjects including 1461 stroke patients), our method achieves a Dice coefficient, sensitivity, and ROC-AUC of 0.85 ± 0.03, 0.88, and 0.94, respectively, outperforming CNN baselines by 15 %. The framework provides clinically meaningful attention maps and accurate automated stroke analysis.},
  archive      = {J_NEUCOM},
  author       = {Luis R. Mercado-Diaz and Derek Aguiar and Hugo F. Posada-Quintero},
  doi          = {10.1016/j.neucom.2025.131620},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131620},
  shortjournal = {Neurocomputing},
  title        = {Graph-based multi-modal MRI analysis with probabilistic attention for stroke lesion detection},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LEAD: LLM-enhanced deep reinforcement learning for stable decision-making in critical autonomous driving scenarios. <em>NEUCOM</em>, <em>657</em>, 131619. (<a href='https://doi.org/10.1016/j.neucom.2025.131619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated significant potential in addressing decision-making problems in the field of autonomous driving due to their strong reasoning capabilities. However, deploying LLMs in real-world driving scenarios often encounters challenges such as high computational requirements, elevated costs, and increased latency. On the other hand, Deep Reinforcement Learning (DRL) exhibits strong adaptability to decision-making tasks in autonomous driving with a relatively smaller parameter scale. Nevertheless, DRL agents often suffer from low exploration efficiency and high sensitivity to parameter variations. To address the above issues, we propose an LLM-Enhanced Autonomous Driving (LEAD) training framework, which integrates a high-level agent based on LLMs into the training process of DRL models, effectively improving the policy learning efficiency and generalization capability of DRL models. During the early stage of training, a dynamic intervention mechanism is introduced to identify key decision points within the DRL model, and a predefined expert guidance algorithm is utilized to integrate high-level decision strategies from LLMs into these critical nodes. During the later stage of training, the DRL model transitions into an autonomous optimization phase, where the agent, enhanced with LLM priors, continuously interacts with the environment to further refine the policy network, ultimately surpassing the performance of the LLM-based agent. Experimental results demonstrate that the LEAD-PPO model, built upon the proposed framework, reduces collision rates by 49.49 % and 59.4 % in low-density and high-density scenarios, respectively, during training compared to the baseline model. In the testing phase, the DRL model optimized through LEAD achieves task completion rates that are 9.60 %, 35.94 %, and 65.63 % higher than those of the baseline model in simple, moderate, and difficult scenarios, respectively. Overall, the proposed LEAD framework significantly improves the robustness, sample efficiency, and generalization ability of DRL models.},
  archive      = {J_NEUCOM},
  author       = {Dongwei Xu and Enwen Qiao and Tongcheng Gu and Hongda Fu and Chengju Sun and Haifeng Guo and Yuqing Liu},
  doi          = {10.1016/j.neucom.2025.131619},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131619},
  shortjournal = {Neurocomputing},
  title        = {LEAD: LLM-enhanced deep reinforcement learning for stable decision-making in critical autonomous driving scenarios},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed/Preassigned-time synchronization of delayed fuzzy memristive neural networks with reaction–diffusion terms. <em>NEUCOM</em>, <em>657</em>, 131618. (<a href='https://doi.org/10.1016/j.neucom.2025.131618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to effectively handle the synchronization of reaction–diffusion fuzzy memristive neural networks (MNNs) and shorten their synchronization time has become a worthwhile and meaningful issue to study. This paper mainly studies fixed-time synchronization (FXTS) and preassigned-time synchronization (PATS) problems for delayed fuzzy memristive neural networks (DFMNNs) with reaction–diffusion terms. First, a DFMNNs model with reaction–diffusion terms is introduced, which can effectively describe the spatial distribution characteristics of the network. Second, through the Lyapunov stability theory, the FXTS criterion and the upper limit of the settling-time (ST) are obtained. Subsequently, a state feedback controller is proposed to ensure that the system achieves synchronization within a specified time, and the synchronization time is independent of initial conditions and control parameters, which gives the designed controller a wider range of applications. Finally, two examples are presented to illustrate the effectiveness of the results.},
  archive      = {J_NEUCOM},
  author       = {Hanrui Chen and Dongbing Tong and Qiaoyu Chen},
  doi          = {10.1016/j.neucom.2025.131618},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131618},
  shortjournal = {Neurocomputing},
  title        = {Fixed/Preassigned-time synchronization of delayed fuzzy memristive neural networks with reaction–diffusion terms},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond sparsity: An empirical study of structured collaboration in modular AI. <em>NEUCOM</em>, <em>657</em>, 131616. (<a href='https://doi.org/10.1016/j.neucom.2025.131616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Mixture-of-Experts (MoE) architectures, the prevailing paradigm emphasizes sparse expert activation for computational efficiency. This paper explores an alternative architectural approach centered on structured collaboration, hypothesizing that the quality and nature of inter-module interactions are as significant as computational cost. We present a series of targeted proof-of-concept experiments to validate three distinct principles of structured interaction, inspired by cognitive science. First, we demonstrate that a hierarchical fusion mechanism, modeled on the brain's segregated visual pathways, enhances compositional reasoning on the VQA v2.0 benchmark. Second, by employing a redesigned reinforcement learning task in MiniGrid, we demonstrate that a system-wide differentiated credit assignment (SDCA) mechanism, with conflict detection learned end-to-end, facilitates more robust policy learning. Third, we ascertain that integrating reasoning "tools" as co-adaptive modules offers superior out-of-distribution robustness on the DROP dataset compared to a more powerful baseline agent utilizing external LLM-based tools. Our work provides concrete validation for these principles, highlighting a series of trade-offs between performance, robustness, and efficiency, and suggesting that prioritizing cognitive synergy over simple sparsity offers a promising direction for future research in modular AI.},
  archive      = {J_NEUCOM},
  author       = {Xiaofei Zhou and Soohong Kim and Yiru Wang and Kailin Zhang},
  doi          = {10.1016/j.neucom.2025.131616},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131616},
  shortjournal = {Neurocomputing},
  title        = {Beyond sparsity: An empirical study of structured collaboration in modular AI},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph transformer-driven reinforcement learning based on popularity for mining complex network key nodes. <em>NEUCOM</em>, <em>657</em>, 131614. (<a href='https://doi.org/10.1016/j.neucom.2025.131614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Key nodes in complex networks play a crucial role in maintaining the stability, functionality, and robustness of networked systems. Accordingly, the accurate identification of such nodes is of fundamental importance. Their significance spans multiple domains, including communication systems, transportation infrastructures, life sciences, and social networks. Existing algorithms for key node identification typically rely on heuristic measures or standard deep reinforcement learning frameworks. However, these approaches often suffer from limited feature extraction capabilities, high computational complexity, and insufficient generalizability, and a lack of dynamic adaptability. To overcome these limitations, this study proposes a novel architecture, GTRP (Graph Transformer-Driven Reinforcement Learning Based on Popularity). GTRP extends Epidemic-aware Heterogeneous Graph Transformer (GT) by introducing distinct attention mechanisms for both nodes and edges, enabling the integration of local structural features and global propagation properties. In addition, GTRP incorporates Dual-dynamics Reward Optimization (DR) to identify key nodes based on a network disintegration strategy. The model is trained on randomly generated Barabási–Albert (BA) networks and evaluated on synthetic networks of varying scales as well as multiple real-world network scenarios. Comparative experiments with six representative algorithms demonstrate that GTRP achieves substantial performance improvements—outperforming existing methods by 6.30 % in unweighted networks and 15.90 % in weighted networks. These results underscore the potential of GTRP to advance key node detection in complex network analysis.},
  archive      = {J_NEUCOM},
  author       = {Kaili Wang and Muqing Wu and Min Zhao},
  doi          = {10.1016/j.neucom.2025.131614},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131614},
  shortjournal = {Neurocomputing},
  title        = {A graph transformer-driven reinforcement learning based on popularity for mining complex network key nodes},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient classification and error correction knowledge distillation framework for remaining useful life prediction of bearings in air turbine starter. <em>NEUCOM</em>, <em>657</em>, 131611. (<a href='https://doi.org/10.1016/j.neucom.2025.131611'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prognostics and Health Management (PHM) is critical for industrial equipment maintenance, whose core task is to predict the Remaining Useful Life (RUL) of a system or component accurately. However, traditional deep learning-based approaches often demand significant computational and memory resources, limiting their feasibility for edge deployment. As an effective model compression technique, Knowledge Distillation (KD) has emerged as a core strategy for enabling edge intelligence by transferring knowledge from a teacher model to a lightweight student model. However, traditional KD methods exhibit a high dependency on the teacher model's output. This dependency limits the student model's capacity for autonomous error correction, impairing its distillation performance. To solve these problems, this paper proposes a novel Classification and Error Correction Knowledge Distillation (CEKD) framework. The framework employs Gaussian kernel-based feature entropy to dynamically evaluate teacher models' predictive capabilities, facilitating comprehensive assessment and sample differentiation. Furthermore, the knowledge self-reflection learning strategy extends error correction to continuous dynamic adjustment, enabling deep optimization of complex data. Experimental results on the air turbine starter bearing datasets show that CEKD surpasses KD methods by improving MAE and RMSE by 79.8 % and 78.6 % on average, while reducing memory consumption and inference time by nearly 10 × and 8 × , respectively, enabling deployment on resource-constrained devices.},
  archive      = {J_NEUCOM},
  author       = {Runxia Guo and Jingxu Yi and Xianfeng Luo},
  doi          = {10.1016/j.neucom.2025.131611},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131611},
  shortjournal = {Neurocomputing},
  title        = {An efficient classification and error correction knowledge distillation framework for remaining useful life prediction of bearings in air turbine starter},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time lag consensus and finite-time h∞ lag consensus for nonlinear multi-agent systems under communication delay. <em>NEUCOM</em>, <em>657</em>, 131609. (<a href='https://doi.org/10.1016/j.neucom.2025.131609'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, the finite-time lag consensus (FTLC) and finite-time H ∞ lag consensus (FTHLC) problems for first-order multi-agent systems (MASs) are studied. On the one hand, a new state feedback controller considering the communication delay between agents is proposed. Besides, based on several inequality scaling techniques and finite-time stability theory, a sufficient criterion is derived to guarantee the FTLC of MASs. On the other hand, an adaptive state feedback controller and the corresponding adaptive law are put forward, which can also help MASs realize lag consensus in finite time without any additional conditions. Moreover, to address inevitable external disturbances in practice, the proposed control strategies are further enhanced to achieve FTHLC, which further expands the application range of the research results. Finally, the effectiveness of these provided FTLC and FTHLC control schemes in different scenarios is manifested through some numerical simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Song Gao and Jin-Liang Wang and Kun Ling and Shun-Yan Ren and Ming-Zhu Wei and Bei Peng},
  doi          = {10.1016/j.neucom.2025.131609},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131609},
  shortjournal = {Neurocomputing},
  title        = {Finite-time lag consensus and finite-time h∞ lag consensus for nonlinear multi-agent systems under communication delay},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed generalized nash equilibrium computing based on dynamic tracking mechanism for nonsmooth aggregative games over time-varying networks. <em>NEUCOM</em>, <em>657</em>, 131608. (<a href='https://doi.org/10.1016/j.neucom.2025.131608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the computation of generalized Nash equilibrium in aggregative games with coupling constraints over time-varying networks. The player’s cost objective comprises a differentiable function dependent on the aggregate of all players’ decisions and a possibly non-smooth term with a linear mapping. In this context, designing solution methods for such game formulation is relatively scarce. We thus develop a fully distributed equilibrium-seeking algorithm that accommodates time-varying communication networks while circumventing the need for global decision information. The proposed algorithm synergistically embeds dynamic tracking of aggregate decisions through a consensus-based mechanism with projected pseudo-gradient updates, augmented by a proximal splitting scheme to handle non-smooth components. Theoretically, we establish convergence guarantees to the variational equilibrium through a new operator splitting framework. Finally, numerical experiments are conducted to substantiate the validity of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Liang Ran and Huaqing Li and Zheng Wang and Lifeng Zheng and Jun Li and Zhe Li},
  doi          = {10.1016/j.neucom.2025.131608},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131608},
  shortjournal = {Neurocomputing},
  title        = {Distributed generalized nash equilibrium computing based on dynamic tracking mechanism for nonsmooth aggregative games over time-varying networks},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-based distributed adaptive synchronization control for multi-weighted complex networks with aperiodic intermittent coupling. <em>NEUCOM</em>, <em>657</em>, 131604. (<a href='https://doi.org/10.1016/j.neucom.2025.131604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the synchronization control for multi-weighted complex networks (MWCNs) with unknown disturbances and aperiodic intermittent coupling. Firstly, an adaptive neural network strategy is used to approximate the unknown components derived from nonlinear function, while a novel continuous function is proposed by utilizing the idea of time-varying boundary layer technique to deal with the influence of approximation errors. Secondly, different from the continuous coupling and periodic intermittent coupling mechanisms in existing works, an aperiodic intermittent coupling mechanism is taken into consideration in MWCNs. Thirdly, to synchronize MWCNs under aperiodic intermittent coupling, adaptive strategies are developed to adjust coupling strengths and coupling gains based on all edges and partial edges, respectively. Note that these two strategies are fully distributed, i.e., they do not require any global information. Finally, some numerical simulations are provided to verify the effectiveness of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Bin Zhang and Dan Liu and Binrui Wang and Kaibo Shi},
  doi          = {10.1016/j.neucom.2025.131604},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131604},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based distributed adaptive synchronization control for multi-weighted complex networks with aperiodic intermittent coupling},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective framework with hybrid augmentation for visual reinforcement learning generalization. <em>NEUCOM</em>, <em>657</em>, 131602. (<a href='https://doi.org/10.1016/j.neucom.2025.131602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current studies in Visual Reinforcement Learning focus on developing policies to acclimate to unknown environments through data augmentation. This paper aims to develop a new methodology to improve upon existing results. To this end, we first categorize existing methods into three groups based on the focus of augmentation: Task-Aware Augmentation, Image-Processing Augmentation, and Image-Scene Augmentation. Subsequently, we establish a unified framework that integrates these three augmentation categories. The core of our framework is hybrid data augmentation, which enhances data diversity. In this framework, we employ hyperspherical space and regularization techniques to address the side effects of such augmentation, specifically the discrepancy between augmented and original data, as well as the instability associated with hybrid augmentation. Finally, we evaluate the proposed framework across three benchmarks, demonstrating its significant advantages over current state-of-the-art methods. Notably, our framework outperforms existing approaches by an average of 4.59 % across 10 tasks in DMC-GB, 28.81 % across 6 tasks in Robosuite, and 20.50 % across 4 tasks in Adroit. The code for our framework will be released at https://github.com/csufangyu/MuHA .},
  archive      = {J_NEUCOM},
  author       = {Yu Fang and Xuehe Zhang and Haoshu Cheng and Xizhe Zang and Changle Li and Jie Zhao},
  doi          = {10.1016/j.neucom.2025.131602},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131602},
  shortjournal = {Neurocomputing},
  title        = {An effective framework with hybrid augmentation for visual reinforcement learning generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing robust generalization through appropriate adversarial example attack intensity. <em>NEUCOM</em>, <em>657</em>, 131599. (<a href='https://doi.org/10.1016/j.neucom.2025.131599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) are notoriously susceptible to adversarial examples. To mitigate the impact of well-designed adversarial attacks on network models, researchers have developed various defense mechanisms, among which adversarial training has emerged as one of the most effective strategies to date. Adversarial training aims to augment training data with adversarial examples, thus giving DNNs a certain degree of robustness to defend against adversarial attacks. However, while obtaining adversarial robustness, this method comes at the cost of reducing the generalization performance, manifested in the reduced classification effect of clean test datasets. Researchers have been actively seeking to counter the balance between adversarial robustness and model generalization. We believe that the key to balancing these two aspects lies in identifying appropriate adversarial examples. Overly potent examples can lead to a decline in clean accuracy, whereas weaker examples may offer limited robustness. Based on our analysis, a new adversarial example generation algorithm called Denoising Projection Gradient Descent (DPGD) was proposed. DPGD adds a purification module and a constraint in generating adversarial examples, the former is used to limit the influence of too strong adversarial examples on model training and the latter is used to ensure the necessary attack intensity. Combining DPGD with the framework of traditional adversarial training, we obtain the Diffusion Adversarial Training (DifAT) approach. To verify the effectiveness of our proposed method, we conducted extensive experiments on benchmark datasets, including CIFAR-10, CIFAR-100, and Tiny-Imagenet. Our results demonstrate the effectiveness of DifAT in improving the robustness of DNNs while maintaining or even improving their generalization performance.},
  archive      = {J_NEUCOM},
  author       = {Xiaoguo Ding and Liangjian Zhang and Qiqi Bao and Yaguan Qian and Bin Wang and Zhaoquan Gu and Yanchun Zhang},
  doi          = {10.1016/j.neucom.2025.131599},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131599},
  shortjournal = {Neurocomputing},
  title        = {Enhancing robust generalization through appropriate adversarial example attack intensity},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User identification based on the topology consistency of cross-layer common neighbors in social network. <em>NEUCOM</em>, <em>657</em>, 131591. (<a href='https://doi.org/10.1016/j.neucom.2025.131591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, it has become a common practice to create multiple accounts on various social networks for online recreation. When accounts in different networks share similar structural features, i . e . , they have topology consistency, they may belong to the same individual. However, having multiple accounts for the same person across different networks can be inconvenient and uncertain, leading to difficulties in accurate recommendations. Therefore, some researchers have focused on identifying users within single network layers, but without involving the information from various network platforms, resulting in identification confusion and reduced algorithm accuracy. This paper proposes a novel topology consistency-based link prediction algorithm (Topology Consistency: TC) for user identification, combining separate layers of a multilayer network into a single-layer network to include more layer information. TC applies topology information from the cross-layer common neighbors produced in layer combination to distinguish target node pairs and utilizes matrix computation to reduce complexity. Furthermore, to address controversial identification situations appearing after layer combination, the edges between the cross-layer common neighbors are innovatively considered. Finally, experimental results in real-world and artificial networks show that TC has superior performance to state-of-the-art algorithms and has applicability and practicality.},
  archive      = {J_NEUCOM},
  author       = {Yujie Yang and Shuai Cao and Long Wang and Dong Liu and Marcus Kaiser},
  doi          = {10.1016/j.neucom.2025.131591},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131591},
  shortjournal = {Neurocomputing},
  title        = {User identification based on the topology consistency of cross-layer common neighbors in social network},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of linear optics network for pattern recognition task via the generation of continuous variable entangled states. <em>NEUCOM</em>, <em>657</em>, 131588. (<a href='https://doi.org/10.1016/j.neucom.2025.131588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear optics neural networks or optical neural networks offer potential advantages over traditional electronic neural networks in terms of speed, energy efficiency, scalability, and improved parallelism, particularly for high-bandwidth applications. The use of photonics allows for more compact and integrated neural network designs, potentially enabling the development of larger and more complex networks. A linear optics network is developed to implement a quantum classifier. Indeed, the designed network is a quantum circuit consisting of some Gaussian gates such as displacement, noiseless linear amplification (NLA), squeezer and Green machine. At first, the classical inputs are encoded with the help of position-displacement operator to prepare single-mode coherent states. Then, the amplitudes of the coherent states are amplified by passing through NLA elements followed by squeezer gates that may transform classical coherent states into nonclassical ones. Finally, the transformed coherent states are fed into the Green machine which provides entangled states as the outcome of the network. As a primary goal of this work, the network generates a multi-mode entangled state by applying the displacement operator on the vacuum state encoded classical data. Besides, it is shown that the output state of the circuit may possess squeezing characteristics as another nonclassical feature. In the continuation, as a practical application, the network is implemented to perform some pattern recognition tasks. At first, the Bayes theorem is employed to define discriminant functions to perform a general classification task, then the outcome distribution of the network is utilized to classify some corrupted LEDs that display English letters. Finally, we show that the outcome of the circuit may be manipulated to embed classical neural networks into a continuous-variable variational quantum circuit (VQC). The network is trained via the logistic regression algorithm with the MNIST database. The results show that the digits can be recognized with relatively high accuracy. Ongoing research is focused on developing new linear optical techniques for machine learning, improving the efficiency and scalability of optical networks, and exploring new applications of linear optics in machine learning and quantum computing. Hence, such a quantum circuit may also be used to design novel high-accuracy pattern recognition devices.},
  archive      = {J_NEUCOM},
  author       = {Ebrahim Ghasemian and Mohammad Kazem Tavassoly and Habib Rostami},
  doi          = {10.1016/j.neucom.2025.131588},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131588},
  shortjournal = {Neurocomputing},
  title        = {Implementation of linear optics network for pattern recognition task via the generation of continuous variable entangled states},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning generic and specific prompts with contrastive constraints for multi-task visual scene understanding. <em>NEUCOM</em>, <em>657</em>, 131586. (<a href='https://doi.org/10.1016/j.neucom.2025.131586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning has emerged as a crucial research direction in the field of computer vision, offering improved performance and efficiency across multiple tasks. Recent studies have incorporated prompt learning into multi-task learning to enhance the interaction between prompt vectors and image representations. However, these studies fail to consider the inter-task and intra-task relations of prompt vectors under multi-task scenarios. To address this issue, we propose learning Generic and Specific Prompts (GSPrompt) with contrastive constraints for multi-task visual scene understanding. Our approach assumes that each task possesses both commonality and individuality, leading us to design two distinct types of prompt vectors: task-generic prompts and task-specific prompts. By constraining the prompt vectors through pulling task-generic prompts and pushing task-specific prompts, we enable multi-task models to learn prompts capable of adapting to multiple tasks simultaneously. Extensive experiments on NYUD-v2, PASCAL-Context, and Cityscapes show that GSPrompt learns effective prompts and achieves state-of-the-art performance. The code is publicly available at https://github.com/teeyohan/GSPrompt-main .},
  archive      = {J_NEUCOM},
  author       = {Tianyu Han and Zhimin Xu and Wanying Li and Haohao Hu and Xinxin He and Song He and Peng Zan and Xiaochen Bo},
  doi          = {10.1016/j.neucom.2025.131586},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131586},
  shortjournal = {Neurocomputing},
  title        = {Learning generic and specific prompts with contrastive constraints for multi-task visual scene understanding},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-based passenger head detection for carriage crowd density estimation. <em>NEUCOM</em>, <em>657</em>, 131584. (<a href='https://doi.org/10.1016/j.neucom.2025.131584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carriage crowd density monitoring is a key component in developing intelligent transportation systems, such as maglev transportation system. Surveillance images captured by sensors, such as carriage monitoring cameras, serve as a new solution for estimating crowd density inside the carriage due to their wide coverage and real-time updates. In this study, a passenger head detection dataset (PHD) is developed using 3717 images acquired from carriage surveillance. Based on these images, over 67,215 head instances are precisely annotated manually. To address the issue of insufficient feature fusion in existing detection algorithms, an efficient cross-scale feature enhancement (CFE) module is proposed and introduced into the advanced YoloX model. The PHD dataset is, to the best of our knowledge, the first public dataset of surveillance images for carriage crowd density estimation. To prove the usability of the PHD dataset and the validity of the proposed method, 12 different versions of detectors are applied and compared. The results demonstrate the performance of these algorithms in the detection of passenger heads. Our research offers a new approach for carriage crowd density estimation. The dataset is publicly available at: https://github.com/Xujiajing111/PHD .},
  archive      = {J_NEUCOM},
  author       = {Jiajing Xu and Mingda Zhai and Yuan Tian and Jun Wu},
  doi          = {10.1016/j.neucom.2025.131584},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131584},
  shortjournal = {Neurocomputing},
  title        = {Vision-based passenger head detection for carriage crowd density estimation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-client GAN-based backdoor attacks for asynchronous federated learning. <em>NEUCOM</em>, <em>657</em>, 131580. (<a href='https://doi.org/10.1016/j.neucom.2025.131580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) enables distributed collaborative training while preserving data privacy; however, it demonstrates significant vulnerability to backdoor attacks. Existing attack methodologies predominantly require control of numerous malicious clients to achieve efficacy and largely neglect asynchronous FL scenarios. In response to these limitations, we propose a novel GAN-based backdoor attack framework capable of injecting effective and covert backdoors with minimal malicious client participation, functioning efficiently across both synchronous and asynchronous environments. Our framework operates effectively with a single malicious client, eliminating the need for coordination among multiple adversarial participants or prior knowledge of benign client data distributions. This reduction in resource requirements enhances the framework's practicality in real-world FL implementations. The malicious client employs a Generative Adversarial Network to synthesize adversarial samples containing predefined triggers, which are subsequently incorporated into local training datasets. The concurrent training on legitimate and triggered data enhances attack effectiveness, while gradient injection—manipulating differences between local and global gradients to introduce strategic noise—facilitates backdoor embedding with improved stealth characteristics. Empirical evaluations demonstrate that in a configuration of 200 clients with a single attacker, our framework achieves attack success rates of 98.66 % on MNIST and 86.29 % on CIFAR-10 datasets. Comprehensive experimentation across both datasets substantiates the framework's effectiveness, imperceptibility, and resilience in synchronous and asynchronous FL environments. This research contributes significant insights into backdoor attack strategies in FL, particularly within asynchronous contexts, and underscores the imperative for developing robust defensive countermeasures.},
  archive      = {J_NEUCOM},
  author       = {Siyu Guan and Chunguang Huang and Hai Cheng},
  doi          = {10.1016/j.neucom.2025.131580},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131580},
  shortjournal = {Neurocomputing},
  title        = {Single-client GAN-based backdoor attacks for asynchronous federated learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UA-PDFL: A personalized approach for decentralized federated learning. <em>NEUCOM</em>, <em>657</em>, 131579. (<a href='https://doi.org/10.1016/j.neucom.2025.131579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a privacy preserving machine learning paradigm designed to collaboratively learn a global model without data leakage. Specifically, in a typical FL system, the central server solely functions as a coordinator to iteratively aggregate the collected local models trained by each client, potentially introducing single-point transmission bottleneck and security threats. To mitigate this issue, decentralized federated learning (DFL) has been proposed, where all participating clients engage in peer-to-peer communication without a central server. Nonetheless, DFL still suffers from training degradation as FL does due to the non-independent and identically distributed (non-IID) nature of client data. And incorporating personalization layers into DFL may be one of the most effective solutions to alleviate the side effects caused by non-IID data. Therefore, in this paper, we propose a novel unit representation aided personalized decentralized federated learning framework, named UA-PDFL, to deal with the non-IID challenge in DFL. By adaptively adjusting the level of personalization layers through the guidance of the unit representation, UA-PDFL is able to address the varying degrees of data skew. Based on this scheme, client-wise dropout and layer-wise personalization are proposed to further enhance the learning performance of DFL. Extensive experiments empirically prove the effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Zhu and Yuxiang Fan and Zhenping Xie},
  doi          = {10.1016/j.neucom.2025.131579},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131579},
  shortjournal = {Neurocomputing},
  title        = {UA-PDFL: A personalized approach for decentralized federated learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel two-stage hybrid feature selection: Exploiting ubiquitous intrinsic feature groups. <em>NEUCOM</em>, <em>657</em>, 131574. (<a href='https://doi.org/10.1016/j.neucom.2025.131574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) has emerged as an important data pre-processing technology to solve the challenging task of data mining. However, most existing FS methods primarily focus on exploiting the independent contributions provided by individual features, while neglecting the critical contributions inherent in ubiquitous intrinsic feature groups. As a result, they may fail to fully capture the potentially valuable information embedded in data. This issue becomes more pronounced in modern large-scale data environments, such as JointCloud, where cross-organizational collaborative data analysis over non-shared datasets is often required. To address this issue, this paper proposes a N ovel T wo- S tage H ybrid FS approach (NTSHFS) that jointly considers the informative contributions of both individual features and collaborative feature groups, enabling a comprehensive evaluation of feature relevance, redundancy and discriminative capability. In the first stage, the correlation coefficient-based co-association matrix (CC-CAM) is developed to ensemble the results obtained by different univariate and structured regularization techniques. Then, a CC-CAM-based embedded FS is proposed to select and rank representative features, achieving strong relevance prioritization and redundancy elimination. In the second stage, a quasi fuzzy-rough set (QFRS) model is designed by integrating the similarity relations at both individual-feature level and multi-feature level through the intersection operation. Based on this model, a QFRS-based filter FS is presented to determine the final feature subset with stronger discriminative capability using internal rankings of feature groups. Experimental results on 24 datasets demonstrate that the proposed approach typically outperforms the compared methods (i.e., achieving an average classification accuracy improvement ranging from 1.77 % to 7.69 %), highlighting its effectiveness, robustness and generalization in data mining.},
  archive      = {J_NEUCOM},
  author       = {Lin Qiu and Xingwei Wang and Bo Yi and Yanpeng Qu and Min Huang and Kaimin Zhang},
  doi          = {10.1016/j.neucom.2025.131574},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131574},
  shortjournal = {Neurocomputing},
  title        = {A novel two-stage hybrid feature selection: Exploiting ubiquitous intrinsic feature groups},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view semi-supervised feature selection with multi-order similarity and tensor learning. <em>NEUCOM</em>, <em>657</em>, 131573. (<a href='https://doi.org/10.1016/j.neucom.2025.131573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view data has attracted extensive attention because it can better characterize samples, and multi-view semi-supervised feature selection can not only effectively improve multi-view performance, but also maintain the original real structure of the data. To this end, many scholars have proposed various models to achieve this goal. However, most of the existing methods rely on the graph structure constructed from the original data and use the constructed graph as a guide for feature selection. This not only ignores multi-order domain knowledge, but also ignores the high-order relations between views. Therefore, this study effectively integrates multi-order domain information with graph learning, and performs tensor low-rank learning on the graph structure between multiple views. A multi-view semi-supervised feature selection method based on multi-order similarity and tensor learning is proposed, which not only integrates multi-order domain information, but also takes into account the relationship between views. Based on this, we propose an iterative method to solve the objective function and prove the superiority of our method on multiple basic datasets.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Chen and Xijiong Xie and Yujie Xiong},
  doi          = {10.1016/j.neucom.2025.131573},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131573},
  shortjournal = {Neurocomputing},
  title        = {Multi-view semi-supervised feature selection with multi-order similarity and tensor learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection via risk-bound utility maximization. <em>NEUCOM</em>, <em>657</em>, 131572. (<a href='https://doi.org/10.1016/j.neucom.2025.131572'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultimate goal of supervised feature selection is to identify a feature subset that minimizes classification risk. Contemporary methods, however, often rely on heuristic or model-dependent proxy criteria that lack a direct theoretical connection to this fundamental objective. To bridge this gap, we introduce a new feature selection framework that directly optimizes a model-agnostic utility function grounded in statistical learning theory. Our approach defines the utility of a feature subset based on the 1-Wasserstein distance between class-conditional distributions. This metric is theoretically powerful as it can be used to construct an upper bound on the Bayes classification error, allowing us to construct a utility function that is a direct surrogate for this risk bound. We instantiate this framework with a subset search strategy that effectively captures feature interactions by maximizing this risk-bound utility. Extensive experiments on real-world datasets demonstrate that our method not only achieves state-of-the-art classification performance but also demonstrates superior robustness and interpretability, providing a principled and powerful alternative to traditional feature selection methods, confirming our framework’s theoretical soundness.},
  archive      = {J_NEUCOM},
  author       = {Chunxu Cao and Qiang Zhang},
  doi          = {10.1016/j.neucom.2025.131572},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131572},
  shortjournal = {Neurocomputing},
  title        = {Feature selection via risk-bound utility maximization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projected variable three-term conjugate gradient algorithm for enhancing generalization performance in deep neural network training. <em>NEUCOM</em>, <em>657</em>, 131568. (<a href='https://doi.org/10.1016/j.neucom.2025.131568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning optimization faces a fundamental trade-off between convergence efficiency and generalization. First-order methods such as stochastic gradient descent (SGD) and adaptive moment estimation (Adam) tend to find flatter minima but converge slowly, while higher-order methods converge rapidly but are often drawn to sharp minima that generalize poorly. To address this, we introduce the projected variable three-term conjugate gradient (PVTTCG) algorithm. Motivated by the geometric instabilities in modern networks that use techniques such as batch normalization (BN), PVTTCG integrates an orthogonal projection into the higher-order optimization framework. This mechanism eliminates radial components from the search direction, inherently guiding the optimization toward flatter regions without requiring additional regularization terms or hyperparameters. The effectiveness of PVTTCG is validated across diverse tasks, including language modeling, large-scale image classification, and a real-world engineering application. In complex scenarios, PVTTCG consistently improves upon its higher-order baseline, achieving up to a 3.92 percentage point gain on CIFAR-100 while remaining competitive with leading first-order methods. A systematic analysis reveals that PVTTCG demonstrates superior robustness to batch size variations, particularly excelling at larger batch sizes. This robustness enables the algorithm to process batch sizes up to 2,048 in engineering applications, achieving a 35.9% test loss reduction compared to Adam. These findings establish PVTTCG as an effective solution for bridging the convergence-generalization trade-off.},
  archive      = {J_NEUCOM},
  author       = {Sanghyuk Kim and Hansu Kim and Namwoo Kang and Tae Hee Lee},
  doi          = {10.1016/j.neucom.2025.131568},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131568},
  shortjournal = {Neurocomputing},
  title        = {Projected variable three-term conjugate gradient algorithm for enhancing generalization performance in deep neural network training},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DVC2: Deep video cascade clustering from video structures. <em>NEUCOM</em>, <em>657</em>, 131565. (<a href='https://doi.org/10.1016/j.neucom.2025.131565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video clustering is a critical unsupervised learning task, where category labels are unavailable, unlike in supervised video classification. The primary challenge is learning meaningful video representations without annotations to effectively group similar videos. Most existing methods extract frame-level features and apply standard clustering algorithms such as K-means, but they often fail to capture temporal relationships inherent in video data. In this paper, we introduce Deep Video Cascade Clustering ( DVC 2 ), a novel unsupervised video learning paradigm. Unlike image-based clustering methods, DVC 2 first learns an initial video representation through frame clustering, which serves as guidance, and then aligns video clustering results with both long-term and short-term structures as well as nearest neighbors. We evaluate DVC 2 on benchmark datasets, including UCF101 and Kinetics-400, achieving state-of-the-art results. Notably, even in annotation-free scenarios where self-supervised learning with K-means already yields reasonable clustering, DVC 2 demonstrates significantly superior performance.},
  archive      = {J_NEUCOM},
  author       = {Zihua Wang and Siya Mi and Yu Zhang},
  doi          = {10.1016/j.neucom.2025.131565},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131565},
  shortjournal = {Neurocomputing},
  title        = {DVC2: Deep video cascade clustering from video structures},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SiFH: Siamese frequency harmonization self-supervised learning for motion forecasting. <em>NEUCOM</em>, <em>657</em>, 131563. (<a href='https://doi.org/10.1016/j.neucom.2025.131563'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion forecasting is a fundamental component of the autonomous driving system and plays an important role in ensuring safety. While supervised learning methods have achieved promising performance in many domains, their model capacity is typically limited by the availability of annotated data. Some previous works have tried to introduce this paradigm into motion forecasting. However, these early studies neglect the task-specific characteristics. To address this, we incorporate two key insights into motion forecasting tasks within the self-supervised paradigm and propose a novel self-supervised motion forecasting framework. First, we design a Frequency Information Harmonization pretext task that explicitly encourages the model to integrate frequency domain features with their time domain counterparts, making them work harmoniously. Second, we introduce an Implicit Scene Alignment task, which enables the model to learn scene-level semantics by aligning masked and unmasked views through shared prototypes. By jointly optimizing these objectives, the model is encouraged to leverage abundant unlabeled data and capture rich spatio-temporal representations. Extensive experiments conducted on the challenging Argoverse 2 and Argoverse 1 benchmarks demonstrate that our proposed model outperforms previous state-of-the-art baselines and can produce more accurate and reliable predictions.},
  archive      = {J_NEUCOM},
  author       = {Chunyu Liu and Zeyu Liu and Tiechui Yao and Shijie Li},
  doi          = {10.1016/j.neucom.2025.131563},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131563},
  shortjournal = {Neurocomputing},
  title        = {SiFH: Siamese frequency harmonization self-supervised learning for motion forecasting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RosMS-ECDBTM: Efficient channel attention enabled distributed deep learning model for mental state detection using EEG signal. <em>NEUCOM</em>, <em>657</em>, 131559. (<a href='https://doi.org/10.1016/j.neucom.2025.131559'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, mental stress is emerging as a common social problem triggering different health disorders, including nervousness, heart attacks, strokes, and depression. Specifically, the Electroencephalography (EEG) signal, capable of reflecting the variations in brain activity, is highly used for mental state detection. Despite their promising performance, the existing EEG-based detection methods fail to capture the inherent characteristics of highly intricate and nonstationary EEG signals. In order to address the drawbacks of existing methods, this research proposes the Deep Learning model namely, Rosmarus Migrative Search Optimized Efficient channel attention enabled Distributed Bi-directional Long Short-Term Memory (RosMS-ECDBTM) model for precise mental state detection. More specifically, the efficient channel attention facilitates the proposed model to dynamically highlight the important parts of the signal characteristics while suppressing the irrelevant regions. Besides, the distributed DL architecture improves the learning capability and scalability of the proposed model to process the large datasets, through the parallel processing of sequential data. Further, the proposed approach exploits the Rosmarus Migrative Search Optimization (RosMS) algorithm for optimizing the RosMS-ECDBTM architecture, resulting in improving the training process. Ultimately, the proposed model, combining efficient channel attention and distributed learning mechanism, captures the intricate patterns and reduces the computational complexity of mental state detection. In addition, the Hybrid Discrete Wavelet transform (DWT) approach decomposes the EEG signal into several frequency components for capturing the hidden patterns and anomalous states in the EEG signal, providing key insights for improving the mental state detection. Extensive experiments show that the RosMS-ECDBTM method provides superior performance, achieving a high accuracy of 96.78 %, precision of 98.99 %, recall of 95.91 %, and F1-score of 97.42 % for the Mental Stress Detection dataset compared to other state-of-the-art methods. Ultimately, these findings reveal the high learning efficiency of the proposed deep learning approach in enhancing the mental state detection accuracy, significantly contributing to advancing the field of mental health monitoring.},
  archive      = {J_NEUCOM},
  author       = {Mandar Nitin Kakade},
  doi          = {10.1016/j.neucom.2025.131559},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131559},
  shortjournal = {Neurocomputing},
  title        = {RosMS-ECDBTM: Efficient channel attention enabled distributed deep learning model for mental state detection using EEG signal},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient semantic segmentation of remote sensing images through dynamic feature enhancement and multimodal alignment fusion. <em>NEUCOM</em>, <em>657</em>, 131555. (<a href='https://doi.org/10.1016/j.neucom.2025.131555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion has shown promising applications in integrating information from different modalities. However, existing multimodal fusion approaches in remote sensing face two main challenges: First, multimodal fusion models relying on Convolutional Neural Networks (CNNs) or Visual Transformers (ViTs) have limitations in terms of remote modeling capabilities and computational complexity, while state-space model (SSM)-based fusion models are prone to feature redundancy due to the use of multiple scanning paths, and similarly suffer from high computational complexity. Second, existing methods do not fully address inter-modal heterogeneity, leading to poor multimodal data fusion. To address these issues, we propose an efficient multimodal fusion network, AFMamba, based on the state-space model (SSM) for semantic segmentation of remote sensing images. Specifically, we design the Efficient Dynamic Visual State Space (EDVSS) module, which enhances the efficiency of the standard Mamba model by dynamically improving local features and reducing channel redundancy. Furthermore, we introduce the Cross Attention Alignment Fusion (CAAFM) module, which combines cross-image attention fusion and channel interaction alignment to effectively improve the accuracy and efficiency of cross-modal feature fusion and mitigate feature inconsistency. Experimental results demonstrate that in multimodal hyperspectral image semantic segmentation, the proposed model reduces computational complexity, measured in GFLOPs, by at least 61 % while maintaining a low parameter count, achieving optimal overall accuracy (OA) of around 92 %, and effectively balancing performance and computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {Wenqian Chen and Wendie Yue and Kai Chang and Hongzhi Wang and Kaijun Tan and Xinyu Liu and Xiaoyi Cao},
  doi          = {10.1016/j.neucom.2025.131555},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131555},
  shortjournal = {Neurocomputing},
  title        = {Efficient semantic segmentation of remote sensing images through dynamic feature enhancement and multimodal alignment fusion},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-step minimax Q-learning algorithm for two-player zero-sum markov games. <em>NEUCOM</em>, <em>657</em>, 131552. (<a href='https://doi.org/10.1016/j.neucom.2025.131552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An interesting iterative procedure is proposed to solve two-player zero-sum Markov games. Under suitable assumptions, the boundedness of the proposed iterates is obtained theoretically. Using results from stochastic approximation, the almost sure convergence of the proposed multi-step minimax Q-learning is obtained theoretically. More specifically, the proposed algorithm converges to the game theoretic optimal value with probability one, when the model information is not known. Numerical simulations authenticate that the proposed algorithm is effective and easy to implement.},
  archive      = {J_NEUCOM},
  author       = {Shreyas S.R. and Antony Vijesh},
  doi          = {10.1016/j.neucom.2025.131552},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131552},
  shortjournal = {Neurocomputing},
  title        = {A multi-step minimax Q-learning algorithm for two-player zero-sum markov games},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained multi-agent evasion using deep reinforcement learning. <em>NEUCOM</em>, <em>657</em>, 131550. (<a href='https://doi.org/10.1016/j.neucom.2025.131550'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing effective evasion strategies in pursuit–evasion scenarios is challenging, particularly when the pursuer’s model is unknown and inaccessible. This limitation hinders the application of conventional evasion policy design methods. To overcome this challenge, especially when evaders have constrained maneuverability against unrestricted pursuers, we propose a novel multi-agent evasion algorithm based on deep reinforcement learning. Our approach employs a staged learning framework, progressively guiding evaders from simpler to more complex tasks to refine their evasion strategies. Crucially, our algorithm enables evaders to infer pursuers’ intentions even without prior knowledge of pursuers’ objectives, allowing for optimal decision-making despite mobility constraints. Simulation results demonstrate that our method significantly enhances evasion success, validating the effectiveness of learning-based strategies. Additionally, the algorithm exhibits strong adaptability to environmental changes, ensuring reliable performance across diverse pursuit–evasion scenarios.},
  archive      = {J_NEUCOM},
  author       = {Bowei Yan and Runle Du and Xiaojun Ban and Di Zhou},
  doi          = {10.1016/j.neucom.2025.131550},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131550},
  shortjournal = {Neurocomputing},
  title        = {Constrained multi-agent evasion using deep reinforcement learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STD-explain: Generalizing explanations for spatio-temporal graph convolutional networks based on spatio-temporal decoupled perturbation. <em>NEUCOM</em>, <em>657</em>, 131539. (<a href='https://doi.org/10.1016/j.neucom.2025.131539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph convolutional networks utilize an alternating combination of one-dimensional ordinary convolution and graph convolution to extract spatio-temporal features. This alternation intertwines temporal and spatial features closely, leading to a tight coupling between them. The presence of spatio-temporal coupling complicates the analysis of spatio-temporal data, posing challenges for existing explainability algorithms to effectively separate and interpret these intertwined features. Therefore, we propose STD-Explain, an explainable algorithm based on spatio-temporal decoupled perturbation, which employs a two-stage perturbation approach considering subgraph and node-level explanations. Firstly, targeting the spatio-temporal coupling issue in spatio-temporal graph convolutional networks, the algorithm proposes a temporal perturbation algorithm based on Slice Graph and a spatial perturbation algorithm aimed at important subgraph node features. Secondly, to avoid introducing additional semantic information when extracting temporal subgraphs, we propose a method for generating temporal subgraphs in spatio-temporal decoupling, slicing human skeleton sequences with discrete masks to ensure each subsequence maintains spatial structure integrity without introducing additional edges. Furthermore, to ensure the maximum correlation between the interpreted subgraphs and model predictions, we propose a temporal important subgraph discrimination strategy to select the most relevant subgraphs to model predictions. Experimental results demonstrate that STD-Explain performs well in qualitative and quantitative analysis.},
  archive      = {J_NEUCOM},
  author       = {Yanshan Li and Ting Shi and Suixuan He and Zhiyuan Chen and Li Zhang and Rui Yu and Weixin Xie},
  doi          = {10.1016/j.neucom.2025.131539},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131539},
  shortjournal = {Neurocomputing},
  title        = {STD-explain: Generalizing explanations for spatio-temporal graph convolutional networks based on spatio-temporal decoupled perturbation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MGSA: Enhancing transferability of multimodal adversarial attacks via multi-granularity semantic alignment. <em>NEUCOM</em>, <em>657</em>, 131534. (<a href='https://doi.org/10.1016/j.neucom.2025.131534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision–language pretraining (VLP) models have demonstrated exceptional performance across a wide range of image–text multimodal tasks. Despite their prominence, research confirms that these systems retain significant susceptibility to adversarial manipulation. Existing multimodal adversarial attack methods often fail to fully exploit sample-specific semantic structures, resulting in suboptimal cross-modal alignment and limited transferability of adversarial examples. To overcome this limitation, we propose MGSA—a Multi-Granularity Semantic Alignment Attack framework that enhances adversarial perturbation transferability by jointly disrupting cross-modal semantics at both global and fine-grained levels. MGSA captures coarse-grained alignment using overall representations and fine-grained correspondence by selectively aggregating key image regions and words based on importance. This dual-level joint optimization effectively perturbs both holistic consistency and detailed correspondences, thereby significantly enhancing attack effectiveness in white-box scenarios and transferability to black-box models. Extensive experiments conducted across diverse model architectures and multimodal tasks demonstrate that our method achieves strong performance in white-box settings while significantly improving black-box attack success rates. The results highlight the vulnerability of current VLP models and the effectiveness of our approach in generating transferable and semantically grounded adversarial examples.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Liu and Haohua Zhou and Zhidong Shen and Hui Sun},
  doi          = {10.1016/j.neucom.2025.131534},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131534},
  shortjournal = {Neurocomputing},
  title        = {MGSA: Enhancing transferability of multimodal adversarial attacks via multi-granularity semantic alignment},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Urban multi-domain mixing (UMDMix) based unsupervised domain adaptation for LiDAR semantic segmentation. <em>NEUCOM</em>, <em>657</em>, 131526. (<a href='https://doi.org/10.1016/j.neucom.2025.131526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D semantic maps generated from Light Detection and Ranging (LiDAR) point clouds enable scene understanding in diverse applications such as autonomous driving and urban planning. However, existing deep learning models struggle when tested on different domains, worsened by limited labeled data. Unsupervised Domain Adaptation (UDA) can bridge this gap, but existing UDA methods often face adaptation challenges due to domain shifts arising from variations in the physical environment, data sparsity, and sensor differences. To address these limitations, we propose UMDMix , a novel UDA architecture that operates on the mixing of multiple labeled source domains with unlabeled target domains to make the predictive model robust to cross-domain variations. UMDMix integrates a teacher–student learning scheme to produce a robust teacher model and an adaptable student model. The performance of the teacher model in the source domain is further strengthened by a position-aware loss that assigns greater significance to semantically rich neighborhoods. A combination of entropy regularization and KL-divergence loss in the target domain updates the knowledge of the teacher model to the student model during adaptation. Our extensive experiments across diverse environments show that UMDMix achieves an average improvement of 13 % on minor classes such as bicycle, traffic sign, and person in target domain datasets, outperforming previous State-Of-The-Art (SOTA) UDA methods.},
  archive      = {J_NEUCOM},
  author       = {Anurag Nihal and Pyare Lal and Vaibhav Kumar},
  doi          = {10.1016/j.neucom.2025.131526},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131526},
  shortjournal = {Neurocomputing},
  title        = {Urban multi-domain mixing (UMDMix) based unsupervised domain adaptation for LiDAR semantic segmentation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-enhanced asymmetric prescribed performance control for multi-task cooperative navigation of USVs via an adaptive formation structure. <em>NEUCOM</em>, <em>657</em>, 131521. (<a href='https://doi.org/10.1016/j.neucom.2025.131521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a prescribed performance control algorithm with asymmetric boundary for Unmanned Surface Vehicle (USV) formation to achieve cooperative navigation under marine disturbances. The proposed algorithm consists of a guidance switching mechanism and a robust adaptive control method. In the improved guidance principle, a velocity correction rule is provided to generate accurate reference signals for USVs during path following. Combined with the guidance term, the communication load between controller and actuator is significantly reduced by employing the Dynamic Event-Triggered Mechanism (DETM) with adaptive updating of threshold parameters. By integrating the initial errors into the performance boundary function, the controller can effectively adapt to different initial states. In addition, due to the smooth property of the shifting function, the error oscillation of the system before steady state is effectively suppressed. The Radial Basis Function Neural Networks (RBF-NNs) are utilized to design damping terms, enhancing the anti-interference capability in marine environments and mitigating the effects of nonlinearities in the model. Through the Lyapunov theorem, the Semi-Globally Uniformly Ultimately Bounded (SGUUB) stability of all state variables is guaranteed. Finally, quantitative validation of the algorithm is performed through numerical simulations and comparative analysis. The results demonstrate a control accuracy within 0.5 meters while showing that, compared to Static Event-Triggering Mechanisms (SETM), the DETM reduces control update frequency for surge force and yawing moment by 12.32 % and 18.78 %, respectively.},
  archive      = {J_NEUCOM},
  author       = {Guoqing Zhang and Junji Feng and Shilin Yin and Matthew Montebello},
  doi          = {10.1016/j.neucom.2025.131521},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131521},
  shortjournal = {Neurocomputing},
  title        = {Neural network-enhanced asymmetric prescribed performance control for multi-task cooperative navigation of USVs via an adaptive formation structure},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mine-SSD: Dual-threshold set abstraction and radius-adaptive grouping for 3D object detection in open-pit mines. <em>NEUCOM</em>, <em>657</em>, 131507. (<a href='https://doi.org/10.1016/j.neucom.2025.131507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient 3D object detection is essential for ensuring both safety and operational efficiency in open-pit mines. Due to complex scene structures, broad perception ranges, and significant object size variations, existing point-based 3D detection methods face challenges that limit their applicability in open-pit mines. To address these issues, Mine-SSD, a single-stage 3D object detection method, is developed with dual-threshold set abstraction (DT-SA) and a radius-adaptive grouping mechanism. Specifically, a dual-head self-correlation module is introduced to calculate comprehensive importance scores for each point, enhancing the model’s ability to prioritize key features. Using these importance scores, a dual-threshold self-correlative farthest point sampling (DTSC-FPS) method is applied to retain key non-local information points during downsampling in set abstraction (SA). Additionally, a radius-adaptive grouping mechanism is designed to dynamically adjust the candidate point aggregation radius, capturing critical features of unconventional objects and supporting multi-scale feature processing. Finally, a novel regression loss function is constructed to improve prediction accuracy and balanced performance across objects of different sizes, ensuring reliable performance of Mine-SSD in multi-scale detection. Extensive experiments on an open-pit mine dataset validate the effectiveness of Mine-SSD.},
  archive      = {J_NEUCOM},
  author       = {Zhongyu Xie and Yuqian Zhao and Fan Zhang and Biao Luo and Wenliu Hu and Tenghai Qiu},
  doi          = {10.1016/j.neucom.2025.131507},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131507},
  shortjournal = {Neurocomputing},
  title        = {Mine-SSD: Dual-threshold set abstraction and radius-adaptive grouping for 3D object detection in open-pit mines},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRDA: Self-regulating distribution alignment based on prompt learning for unsupervised domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131498. (<a href='https://doi.org/10.1016/j.neucom.2025.131498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although large-scale pre-trained vision–language models (VLMs) exhibit significant potential for cross-domain visual tasks, existing prompt-learning-based unsupervised domain adaptation (UDA) methods suffer from source domain overfitting and target domain performance degradation. This paper experimentally demonstrates that conventional prompt learning exhibits insufficient cross-domain generalization due to optimization being heavily biased toward the source distribution. To address this challenge, we propose a Self-regulating Distribution Alignment (SRDA) framework. Its core innovation is a dual-branch collaborative optimization mechanism that dynamically balances cross-domain semantic alignment with pre-trained knowledge preservation. Specifically, the self-regulating multimodal prompt branch incorporates three constraints: semantic consistency regularization, dual-domain collaborative contrastive regularization, and text semantic diversity enhancement. This design suppresses prompt overfitting to the source domain while preserving CLIP’s zero-shot generalization capability. The cross-domain alignment branch introduces dynamic dual-domain feature bank and Cross-domain Collaborative Dual Attention module, achieving fine-grained local semantic calibration through moving average prototypes and a dual-layer attention mechanism. Extensive experiments validate SRDA’s effectiveness on downstream UDA tasks. The code is available at https://github.com/QYw12/SRDA .},
  archive      = {J_NEUCOM},
  author       = {Yang Qu and Jinlong Shi and Yun Cui and Ao Zhang and Suqin Bai and Ye Lu},
  doi          = {10.1016/j.neucom.2025.131498},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131498},
  shortjournal = {Neurocomputing},
  title        = {SRDA: Self-regulating distribution alignment based on prompt learning for unsupervised domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault-tolerant synchronization of drive-response memristive competitive neural networks with multiple actuator failures. <em>NEUCOM</em>, <em>657</em>, 131489. (<a href='https://doi.org/10.1016/j.neucom.2025.131489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the synchronization of drive-response memristive competitive neural networks (MCNNs) under multiple actuator failures is studied through implementing fault-tolerant control scheme. Unlike previous studies, the actuator failures considered in this paper include both bias and effectiveness failures. To address these challenges, a proper mathematical model is first established to capture the impact of actuator failures on control inputs. Subsequently, several sufficient conditions are deduced by designing an appropriate bilayer fault-tolerant controller and constructing a Lyapunov functional to achieve the global exponential synchronization, finite-time synchronization, fixed-time synchronization and predefined-time synchronization respectively. Additionally, the settling time upper bounds for the proposed synchronization methods are determined. In the end, numerical simulations with analysis and comparison are performed to confirm the validity of the proposed results.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Duan and Yanli Huang and Quang Dan Le and Tse Chiu Wong},
  doi          = {10.1016/j.neucom.2025.131489},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131489},
  shortjournal = {Neurocomputing},
  title        = {Fault-tolerant synchronization of drive-response memristive competitive neural networks with multiple actuator failures},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double-boundary awareness of shared categories for source-free universal domain adaptation. <em>NEUCOM</em>, <em>657</em>, 131473. (<a href='https://doi.org/10.1016/j.neucom.2025.131473'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-Free Universal Domain Adaptation (SF-UniDA) aims to adapt a pre-trained source model to an unlabeled target domain without access to source data or prior knowledge of cross-domain category shifts. Existing methods focus on distinguishing target-private unknown samples and assigning pseudo-labels to known samples across the entire label space, including both shared and source-private categories as pseudo-labels, for self-training. However, this data-aware pseudo-labeling approach could mistakenly assign known samples to either source-private or target-private categories, making it sensitive to category shifts and potentially introducing errors or mislabeling. In this paper, we propose Double-boundary Awareness Domain Adaptation (DADA), a class-aware framework that partitions the target domain pseudo-label space into shared, potential source-private, and target-private categories. By labeling target-private samples as unknown and filtering out misassigned source-private samples, DADA enhances the quality of target samples and the reliability of pseudo-labels. To achieve this, we introduce Double-bounded Shared Categories Refinement (DSCR) module, which refines shared classes by identifying both source- and target-private categories based on prior class probabilities and the entropy distribution. Additionally, we incorporate Class-Aware Discriminative Learning (CADL) to enhance discrimination between shared and target-private samples across domains. Experiments on four benchmarks demonstrate the effectiveness of DADA, with overall H-score gains of 8.2 % in the OPDA scenario on Digit dataset and accuracy gains of 10.6 % in the PDA scenario on VisDA dataset. Code is available at: https://github.com/W2Wzj/DADA .},
  archive      = {J_NEUCOM},
  author       = {Zhijing Wang and Ji Guo and Xu Sun and Yi Luo and Aiguo Chen},
  doi          = {10.1016/j.neucom.2025.131473},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131473},
  shortjournal = {Neurocomputing},
  title        = {Double-boundary awareness of shared categories for source-free universal domain adaptation},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGN: Stochastic guidance network for sim-to-real generalization. <em>NEUCOM</em>, <em>657</em>, 131468. (<a href='https://doi.org/10.1016/j.neucom.2025.131468'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant domain differences between synthetic data and real data are a challenging problem for current domain generalized segmentation networks. Therefore, this paper proposes a stochastic guidance network (SGN) for sim-to-real generalization that includes the category reweighting strategy, Multi-scale Feature Fusion Guidance (MSFFG) module and multiple style perturbation modules, which improves the issues caused by the imbalance of the source domain’s sample categories as well as large domain gap. Experimental results show that our SGN can effectively enhance the model’s generalization ability to unseen data. In terms of mean intersection over union (mIoU) metric, compared with SOTA, the SGN improves by 3.86 % and 2.05 % respectively on two real scene-enhanced datasets(Rain_Cityscapes, Foggy_Cityscapes), and an average improvement of 1.48 % on four conventional datasets (BDD100k, Cityscapes, Mapillary, Synthia). Our project can be found at https://githubcom/leo-lab-511/SGN.},
  archive      = {J_NEUCOM},
  author       = {Yao Li and Jinlong Shi and Yun Cui and Dan Xu and Wei Teng and Yan Jiang},
  doi          = {10.1016/j.neucom.2025.131468},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131468},
  shortjournal = {Neurocomputing},
  title        = {SGN: Stochastic guidance network for sim-to-real generalization},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdvOT: Oblivious transfer based on generative adversarial networks against multiple attackers. <em>NEUCOM</em>, <em>657</em>, 131449. (<a href='https://doi.org/10.1016/j.neucom.2025.131449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oblivious Transfer (OT) is crucial in various security protocols, as it serves as a privacy-preserving and secure communication protocol. However, traditional OT protocols often necessitate complex encryption algorithms and involve intricate steps. Given the rapid advancements in artificial intelligence, it is imperative to explore the potential of artificial neural networks in simplifying OT protocols while still meeting stringent security and privacy requirements. To this need, we introduce the Adv ersarial O blivious T ransfer (AdvOT) protocol, which integrates OT with the adversarial learning mechanism of Generative Adversarial Network (GAN). Our approach involves training a neural network model to learn encryption techniques through end-to-end adversarial training, thereby eliminating the reliance on specific algorithms. The AdvOT protocol comprises two phases. Firstly, a Random Oblivious Transfer (ROT) protocol is employed to generate and distribute keys based on the CKKS homomorphic encryption algorithm. Subsequently, neural networks are introduced to replace specific symmetric encryption algorithms and encrypt the messages to be transferred. These neural networks undergo training using the adversarial learning mechanism to develop a symmetric encryption algorithm. Furthermore, to enhance the model, attack networks with varying capabilities are created, resulting in a more secure encryption algorithm capable of withstanding multiple attackers. Experimental results demonstrate that the execution speed of the CKKS-based ROT algorithm is significantly faster compared to the BFV and Paillier algorithms. Moreover, in adversarial network models with multiple attackers, the decryption accuracy for the recipient approaches 100 %, while the accuracy or classification error rate for attackers is approximately 50 %. These findings indicate that the proposed method effectively safeguarded communication between parties from interception.},
  archive      = {J_NEUCOM},
  author       = {Yuke Wang and Zhentian Zhong and Ninghao Liu and Xiaohui Li and Junfeng Wang},
  doi          = {10.1016/j.neucom.2025.131449},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131449},
  shortjournal = {Neurocomputing},
  title        = {AdvOT: Oblivious transfer based on generative adversarial networks against multiple attackers},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Challenges and advancements in modeling shock fronts with physics-informed neural networks: A review and benchmarking study. <em>NEUCOM</em>, <em>657</em>, 131440. (<a href='https://doi.org/10.1016/j.neucom.2025.131440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving partial differential equations (PDEs) with discontinuous solutions—such as shock waves in multiphase viscous flow in porous media—is critical for a wide range of scientific and engineering applications, as they represent sudden changes in physical quantities. Physics-Informed Neural Networks (PINNs), an approach proposed for solving PDEs, encounter significant challenges when applied to such systems. Accurately solving PDEs with discontinuities using PINNs requires specialized techniques to ensure effective solution accuracy and numerical stability. Various methods have been developed to address the challenges of modeling discontinuities within the PINNs framework. This work reviews and benchmarks these approaches across problems of varying complexity, categorizing them into three broad groups, influencing solution accuracy differently. (1) Physics-modification (PM) methods improve accuracy by modifying the system’s physics, such as adding artificial viscosity or enforcing entropy constraints. (2) Loss and training modification (LM) techniques focus on regularizing the loss landscape, often by refining the loss term in high-error regions. (3) Architecture-modification (AM) approaches, on the other hand, propose advanced network designs to handle discontinuities better. A benchmarking study was conducted on two multiphase flow problems in porous media: the classic Buckley-Leverett (BL) problem and a fully coupled system of equations involving shock waves but with varying levels of solution complexity. The findings show that PM and LM approaches can provide accurate solutions for the BL problem by effectively addressing the infinite gradients associated with shock occurrences. In contrast, AM methods failed to effectively resolve the shock waves. When applied to fully coupled PDEs (with more complex loss landscapes), the generalization error in the solutions quickly increased, highlighting the need for ongoing innovation. This study provides a comprehensive review of existing techniques for managing PDE discontinuities using PINNs, offering information on their strengths and limitations. The results underscore the necessity for further research to improve PINNs’ ability to handle complex discontinuities, particularly in more challenging problems with complex loss landscapes. This includes problems involving higher dimensions or multiphysics systems, where current methods often struggle to maintain accuracy and efficiency.},
  archive      = {J_NEUCOM},
  author       = {Jassem Abbasi and Ameya D. Jagtap and Ben Moseley and Aksel Hiorth and Pål Østebø Andersen},
  doi          = {10.1016/j.neucom.2025.131440},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131440},
  shortjournal = {Neurocomputing},
  title        = {Challenges and advancements in modeling shock fronts with physics-informed neural networks: A review and benchmarking study},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SparseSCIGaussian: Sparse snapshot compressed images 3D gaussian splatting. <em>NEUCOM</em>, <em>657</em>, 131422. (<a href='https://doi.org/10.1016/j.neucom.2025.131422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose SparseSCIGaussian, a novel method for achieving high-quality novel view synthesis under sparse input conditions. Previous methods often rely heavily on depth or neural priors, which can lead to generalization challenges and significant quality degradation on complex datasets. These limitations arise primarily from the insufficient scene information available in sparse regular images. To overcome these issues, our approach utilizes images captured through Snapshot Compressive Imaging (SCI) as input. SCI-captured images inherently encode richer scene information compared to regular images, thereby substantially improving the quality of novel view synthesis under sparse input conditions. Moreover, SCI images can be conveniently captured using a software-implemented encoder, making them as accessible as traditional images. Experimental results demonstrate that our method improves 2.65 dB (13.04 %) in PSNR compared to previous methods, and further exhibits the inherent advantages of using SCI images for sparse input novel view synthesis.},
  archive      = {J_NEUCOM},
  author       = {Haoyuan He and Xuan Wang and Nanning Zheng and Caigui Jiang},
  doi          = {10.1016/j.neucom.2025.131422},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131422},
  shortjournal = {Neurocomputing},
  title        = {SparseSCIGaussian: Sparse snapshot compressed images 3D gaussian splatting},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RehearMixup: Improving rehearsal-based continual learning. <em>NEUCOM</em>, <em>657</em>, 131404. (<a href='https://doi.org/10.1016/j.neucom.2025.131404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks often suffer from catastrophic forgetting when learning new tasks, leading to the loss of previously acquired knowledge. To address this issue, rehearsal-based methods have emerged, which involve storing a subset of data from previous tasks and accessing it during the learning of new tasks. Current rehearsal-based methods focus on selecting representative samples to store in memory. However, there is a considerable lack of exploration of how to exploit the data at hand and consider the correlation between tasks or between past and new knowledge to improve performance. Therefore, we propose a simple yet effective approach named RehearMixup that adapts the Mixup technique into rehearsal-based methods, which synthesizes new samples for learning by interpolating data from past or current tasks. Specifically, we introduce three strategies, namely Cross-Mixup , Intra-Memory-Mixup , and Intra-Current-Mixup , based on the inherent characteristics of rehearsal-based methods - involving the memory and new tasks. Through empirical evaluations under various benchmark scenarios, we compare our approach against different rehearsal-based baselines. The results demonstrate that ours, particularly Intra-Current-Mixup , improves accuracy, backward transfer, forward transfer, and enhances the model’s robustness.},
  archive      = {J_NEUCOM},
  author       = {Yan Zhang and Kaiyuan Qi and Dong Wu and Guoqiang Wu and Yilong Yin},
  doi          = {10.1016/j.neucom.2025.131404},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131404},
  shortjournal = {Neurocomputing},
  title        = {RehearMixup: Improving rehearsal-based continual learning},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A zero-shot high-performance fire detection framework based on large language models. <em>NEUCOM</em>, <em>657</em>, 131403. (<a href='https://doi.org/10.1016/j.neucom.2025.131403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire detection is crucial for minimizing economic damage and safeguarding human lives. Existing methods, including advanced AI and ML techniques, face challenges such as detecting small fires in complex environments and relying on extensive labeled data for training. This paper proposes a novel zero-shot fire detection framework leveraging large language models (LLMs) and contrastive learning-based image–text pre-training models. The framework introduces an enhanced self-attention mechanism for optimizing image embeddings, diverse prompt generation using GPT-3.5 for improved generalization, and a dynamic threshold calculation method based on statistical analysis to enhance detection accuracy and reliability. The proposed method is tested on the public FLAME dataset and a self-collected dataset. Experimental results demonstrate that the proposed method outperforms state-of-the-art models in detecting small fires within complex backgrounds, achieving better detection performance without the need for any training data. This study highlights the potential of zero-shot learning in fire detection and provides a promising solution for real-world fire detection applications.},
  archive      = {J_NEUCOM},
  author       = {Hongyang Zhao and Yi Liu and Yuhang Han and Xingdong Li and Yanan Guo and Jing Jin},
  doi          = {10.1016/j.neucom.2025.131403},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131403},
  shortjournal = {Neurocomputing},
  title        = {A zero-shot high-performance fire detection framework based on large language models},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hetero-MoE by attention: Three-plus tasks learning solver. <em>NEUCOM</em>, <em>657</em>, 131333. (<a href='https://doi.org/10.1016/j.neucom.2025.131333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) stands as a promising sub-field of machine learning, aiming to simultaneously tackle multiple tasks. By leveraging shared representations and structures across diverse tasks, MTL models often exhibit higher data efficiency compared to single-task models across various domains, including recommender system applications, multi-label classification and other AI applications. However, the efficacy of MTL models is sometimes hindered by the multi-causal task conflict problem. To address this challenge, existing research predominantly focuses on enhancing structural designs and the underlying optimizers. Nevertheless, these approaches often fall short in comprehensively mitigating task conflicts, especially in scenarios involving three or more tasks, such as recommender systems. When shared experts contend with excessive task-related information simultaneously, the effective filtration of potentially harmful knowledge becomes challenging. To this end, we propose a novel Heterogeneous Multi-Expert model with an attention layer, termed HMEA. HMEA introduces Heterogeneous Experts as shared experts to decompose signal connections among three or more tasks. Additionally, it integrates an attention layer to further decouple conflicts among mini-tasks within shared experts. The experiments and ablation studies on various standard and synthetic datasets illustrate the effectiveness of HMEA in alleviating the task conflict problem inherent in three-plus task learning systems.},
  archive      = {J_NEUCOM},
  author       = {Dandan Zhang and Guanqi Zeng and Haotian Wu and Hongwen Zhang and Zheng Ye and Yao Yang},
  doi          = {10.1016/j.neucom.2025.131333},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131333},
  shortjournal = {Neurocomputing},
  title        = {Hetero-MoE by attention: Three-plus tasks learning solver},
  volume       = {657},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting nonlinear dynamic systems by causal physics-informed neural networks with ResNet blocks. <em>NEUCOM</em>, <em>656</em>, 131589. (<a href='https://doi.org/10.1016/j.neucom.2025.131589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of data computational science, the prediction of nonlinear systems has provided effective support for investigating complex problems in the field of natural sciences. Physics-Informed Neural Networks (PINNs) are playing an increasingly prominent role in nonlinear system prediction. Although PINNs have been widely applied across various engineering domains, their utilization in chaotic system prediction remains notably scarce. This paper proposes a novel causal PINNs framework integrated with ResNet blocks. On the one hand, the framework incorporates temporal weighting into the residual loss, utilizing maximum temporal weight as the training termination criterion. Additionally, an annealing strategy is adopted to adaptively adjust the causal parameters, ensuring that the model adheres to physical causality constraints throughout the training process. On the other hand, the framework employs a ResNet-block-based network, which transforms identity mappings into residual mappings. This architectural design significantly enhances training stability when utilizing deep networks. To validate the performance of the proposed method, numerical experiments are conducted on the Lorenz system, Dadras system, and Kuramoto-Sivashinsky equation. The results demonstrate that the causal PINNs with ResNet blocks significantly outperform conventional PINNs in predicting chaotic systems.},
  archive      = {J_NEUCOM},
  author       = {Man-Hong Fan and Jun-Hao Zhao and Lin Ding and Xiao-Ying Ma and Rui-Lin Fu},
  doi          = {10.1016/j.neucom.2025.131589},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131589},
  shortjournal = {Neurocomputing},
  title        = {Predicting nonlinear dynamic systems by causal physics-informed neural networks with ResNet blocks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-aware fusion for improved video object segmentation. <em>NEUCOM</em>, <em>656</em>, 131585. (<a href='https://doi.org/10.1016/j.neucom.2025.131585'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, most mainstream memory-based semi-supervised video object segmentation (VOS) methods rely on pixel-level matching to identify target objects. However, the majority of these approaches depend solely on spatial-domain features for representation, which limits their ability to preserve fine-grained details. In addition, they typically adopt a single bottom-up matching strategy, which lacks sufficient global semantic guidance, ultimately leading to suboptimal segmentation performance. To address these issues, we propose a Frequency-Aware Fusion for Improved Video Object Segmentation algorithm (FAFVOS), which incorporates frequency-domain information enhancement and a bidirectional matching mechanism to improve segmentation accuracy. First, we design a Hierarchical Frequency-Aware Encoder (HFAE), which enhances shallow features by leveraging high-frequency components to preserve edge and texture details, and strengthens deep features via low-frequency components to maintain global structural consistency, thereby achieving multi-scale frequency–spatial feature fusion. Second, a frequency-guided bidirectional matching Transformer module is proposed to establish pixel-level and object-level dual-path interactions. By incorporating a cross-attention mechanism, the model effectively facilitates joint reasoning between local pixel-wise details and global object-level semantics. Finally, a high-order moment refinement module is introduced to integrate high-order statistical features, enhancing the model’s ability to capture object deformation and leading to high-quality segmentation results. The proposed method is evaluated on the DAVIS, YouTube-VOS, and MOSE datasets. Experimental results demonstrate that, without relying on complex pretraining strategies or additional datasets, our approach achieves a real-time inference speed of 56 FPS with a J & F score of 88.5 % on the DAVIS 2017 benchmark, surpassing existing representative methods. Moreover, it also achieves consistently superior performance on the more challenging YouTube-VOS and MOSE datasets, further validating the generalization ability and robustness of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Hou and Hao Cui and Chenxu Wang and Sugang Ma and Xiaobao Yang and Lei Pu},
  doi          = {10.1016/j.neucom.2025.131585},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131585},
  shortjournal = {Neurocomputing},
  title        = {Frequency-aware fusion for improved video object segmentation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Utility-driven free tree mining in graph databases. <em>NEUCOM</em>, <em>656</em>, 131571. (<a href='https://doi.org/10.1016/j.neucom.2025.131571'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent subgraph mining is a fundamental task in data mining, widely applied in various domains such as biological networks, social networks, and computing networks. However, existing methods for frequent subgraph mining often rely solely on support as a single metric, considering subgraphs with higher support as more important. This approach overlooks the intrinsic value of subgraphs, such as in citation networks, where users tend to associate with structures related to their own research areas, not only the frequent ones. To address this limitation, we introduce utility pattern mining into the field of subgraph mining. This mining framework considers both the internal and external values of patterns. Additionally, traditional frequent subgraph mining is hindered by isomorphism calculations, including the computational cost of subgraph isomorphism, which is NP-complete. As a connected acyclic graph, free trees play a significant role in fields such as web mining and biology. Their relatively simple structure can significantly reduce the computational cost of subgraph isomorphism calculations. In this paper, we combine utility pattern mining with frequent free tree mining, defining the problem of frequent high utility free tree mining. We design utility upper bounds that satisfy the downward closure property and propose an algorithm, UFTM (utility free tree miner), for effectively and efficiently mining utility free trees. Furthermore, we collect and test our algorithm on four real-world datasets. The results demonstrate that UFTM can discover more valuable patterns and execute the mining task efficiently.},
  archive      = {J_NEUCOM},
  author       = {Zhaoming Chen and Xinyang Chen and Guoting Chen and Wensheng Gan},
  doi          = {10.1016/j.neucom.2025.131571},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131571},
  shortjournal = {Neurocomputing},
  title        = {Utility-driven free tree mining in graph databases},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated machine learning based on decomposition, causality and evolutionary multitask optimization for time series forecasting. <em>NEUCOM</em>, <em>656</em>, 131569. (<a href='https://doi.org/10.1016/j.neucom.2025.131569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting plays a crucial role in various practical domains, serving as a key tool for planning and control by anticipating patterns and identifying potential future anomalies. This practice enables more effective responses to the complex dynamics of systems, typically relying on the ability to predict observations based on historical data. In this regard, the continuous pursuit of ways to enhance forecasting model accuracy is of paramount importance. Working with time series forecasting demands specific technical expertise. While automation strategies exist for these tasks, the universality of such solutions remains a challenge due to the difficulty of incorporating all available models into a single application. In this context, the present study introduces a new AutoML approach based on Decomposition, Causality, and Evolutionary Multitask Optimization for time series forecasting, called AutoDCE-TS. The AutoDCE-TS is a Multiple Input Single Output system, designed with a four-layer structure that automates the processes of feature extraction and selection, model selection and generation, and prediction. It aims to create more explainable pipelines by constructing sub-pipelines to handle each variable of the multivariate time series, as well as the components produced by the decomposition process. For each variable, a causal feature graph is constructed and used as input to an ensemble model based on regression trees. AutoDCE-TS leverages the similarity among variables to simultaneously select models and their hyperparameters for each sub-pipeline, employing a multitask evolutionary optimization strategy. Experiments conducted on 18 datasets, comparing AutoDCE-TS with 10 other methods, revealed its competitiveness, demonstrating that it is a robust and general-purpose method for time series forecasting.},
  archive      = {J_NEUCOM},
  author       = {Patrícia de Oliveira e Lucas and Frederico Gadelha Guimarães and Eduardo M.A.M. Mendes},
  doi          = {10.1016/j.neucom.2025.131569},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131569},
  shortjournal = {Neurocomputing},
  title        = {Automated machine learning based on decomposition, causality and evolutionary multitask optimization for time series forecasting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-stream diffusion graph convolutional model with adaptive motion-aware attention and self-supervised pretraining for continuous sign language recognition. <em>NEUCOM</em>, <em>656</em>, 131567. (<a href='https://doi.org/10.1016/j.neucom.2025.131567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous Sign Language Recognition (CSLR) requires capturing both spatial and temporal dependencies to accurately model sign sequences. To enhance CSLR performance, we propose a Multi-Stream Diffusion Graph Convolution Network (MSD-GCN) from input skeleton data that introduces three key innovations. First, Adaptive Motion-aware Graph Convolution with Bi-level Attention (AMGC-BA) dynamically refines joint connectivity by leveraging semantic motion correlations, improving robustness to signer variations, and enhancing long-term dependencies. Second, signal-enhanced multi-stream representation learning integrates advanced signal processing techniques, including the Adaptive Ridgelet Transform (ART) for pose representation, Variational Mode Decomposition (VMD) for motion decomposition, and Empirical Wavelet Transform (EWT) for contextual feature extraction, ensuring feature robustness, reducing noise, and improving discriminability. Third, self-supervised pretraining leverages contrastive learning, graph reconstruction, and cross-stream feature alignment to mitigate data scarcity, enhance domain adaptation, and improve representation learning. These innovations enable the proposed graph to effectively capture complex motion patterns, distinguish between critical and redundant gestures, and generalize well across diverse signers and datasets. By improving recognition accuracy, robustness, and adaptability, the proposed approach provides a significant advancement in CSLR, addressing the challenges of signer variability, limited labeled data, and the need for fine-grained motion representation. Results on three datasets confirm the superiority of the proposed model compared to 35 comparative models. To the best of our knowledge, this is the first study in CSLR to employ such an extensive range of comparative models for performance evaluation.},
  archive      = {J_NEUCOM},
  author       = {Razieh Rastgoo},
  doi          = {10.1016/j.neucom.2025.131567},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131567},
  shortjournal = {Neurocomputing},
  title        = {A multi-stream diffusion graph convolutional model with adaptive motion-aware attention and self-supervised pretraining for continuous sign language recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGFCNN: A synergistic framework integrating graph-based spatial filter and lightweight CNN for SSVEP recognition. <em>NEUCOM</em>, <em>656</em>, 131561. (<a href='https://doi.org/10.1016/j.neucom.2025.131561'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing the feature representation and decoding efficiency of the steady-state visual evoked potentials (SSVEPs) is critical to enhancing the performance of neural signal decoding systems. Current deep learning models often overlook the physical topological information of EEG channels, resulting in suboptimal feature extraction and limited recognition performance. To address these challenges, this study proposes a synergistically designed SSVEP recognition framework to alleviate data insufficiency, improve the feature representation, and enhance decoding efficiency. Specifically, a slicing-and-scaling technique is adopted to improve the model generalization under limited-sample scenarios. A graph-based spatial filter leverages the topological relationships among EEG channels to suppress redundant information and enhance spatial feature quality. A lightweight convolutional neural network (CNN) with fewer parameters is developed to efficiently extract discriminative temporal–spatial features for accurate SSVEP classification. Experimental results on two public benchmark datasets and one self-collected dataset demonstrate that the proposed framework outperforms baseline deep learning models, yielding improvements of at least 6.8 %, 8.5 %, and 0.5 % in peak average classification accuracy, respectively. The maximum average information transfer rates (ITRs) achieved on the three datasets were 221.4 bits/min ,106.7 bits/min , and 133.9 bits/min , respectively. By simultaneously reducing model complexity and improving decoding performance, the proposed framework offers an effective and promising approach for efficient neural signal decoding in SSVEP recognition.},
  archive      = {J_NEUCOM},
  author       = {Rui Ma and Yu Cao and Sheng Quan Xie and Mingming Zhang and Jun Li and Zhi-Qiang Zhang},
  doi          = {10.1016/j.neucom.2025.131561},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131561},
  shortjournal = {Neurocomputing},
  title        = {LGFCNN: A synergistic framework integrating graph-based spatial filter and lightweight CNN for SSVEP recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double missing multi-view multi-label classification via an attention-guided multi-space consistency alignment framework. <em>NEUCOM</em>, <em>656</em>, 131558. (<a href='https://doi.org/10.1016/j.neucom.2025.131558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view multi-label classification (MVMLC) seeks to enhance classification by integrating diverse data views, but its practical use is hindered by missing views and labels, posing the significant challenge of incomplete MVMLC(IMVMLC). Although various IMVMLC approaches have been proposed, most of them handle multiple objectives in a single feature space and thus overlook the conflict between learning consistent common semantics and reconstructing view-specific information. In addition, existing multi-view classification methods mainly consider utilizing the features of each view, while ignoring the inconsistent contributions of each view and usually relying on static average weighting strategies. To this end, we propose our Attention-Guided MultiSpace Consistency Alignment Framework (AMCA). In Stage 1, AMCA introduces multi-space representation learning with dual-level contrastive objectives, explicitly disentangling shared and view-specific semantics to resolve the objective conflict and yield more informative embeddings. In Stage 2, AMCA employs an attention-guided fusion module that dynamically evaluates and integrates multi-view features based on their relevance to the classification task, enabling robust decision-making even with missing data. Extensive experiments validate the effectiveness and superiority of our proposal.},
  archive      = {J_NEUCOM},
  author       = {Bingyan Nie and Wulin Xie and Lian Zhao and Jiang Long and Xiaohuan Lu and Yinghao Ye},
  doi          = {10.1016/j.neucom.2025.131558},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131558},
  shortjournal = {Neurocomputing},
  title        = {Double missing multi-view multi-label classification via an attention-guided multi-space consistency alignment framework},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end transformer-based detection with density-guided query selection for small objects. <em>NEUCOM</em>, <em>656</em>, 131554. (<a href='https://doi.org/10.1016/j.neucom.2025.131554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small object detection remains a persistent challenge in transformer-based detectors due to their limited localization precision and reliance on fixed query mechanisms. In this paper, we propose Hybrid Density-Transformer (HyDeTr), a novel transformer-based object detection framework designed to improve the detection of small and densely packed objects with only a slight trade-off in inference complexity. HyDeTr introduces several key innovations: (1) a Context-Selective Hybrid Attention Encoder (CS-HAE) that distills global context from low-resolution features through efficient kernelized attention while preserving local detail via deformable attention on higher-resolution maps; (2) a Density Map Prediction module that generates a spatial prior highlighting high-object-density regions, facilitating focus on crowded scenes; (3) a Density-Guided Uncertainty-Minimal Query Selection strategy that identifies the most informative query locations based on both classification confidence and predicted density, ensuring that even low-confidence small objects in dense areas are effectively queried; and (4) an improved Query Formulation with dual embeddings, consisting of a content embedding and a 4D anchor box, refined iteratively by the decoder. Our design enables precise, density-aware query initialization and scale adaptation, leading to improved recall and accuracy for small objects. Extensive evaluations demonstrate that HyDeTr outperforms existing methods in detecting small objects, offering significant accuracy gains with only a modest increase in inference complexity, thereby maintaining near real-time performance and full end-to-end trainability.},
  archive      = {J_NEUCOM},
  author       = {Nguyen Hoanh and Tran Vu Pham},
  doi          = {10.1016/j.neucom.2025.131554},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131554},
  shortjournal = {Neurocomputing},
  title        = {End-to-end transformer-based detection with density-guided query selection for small objects},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel dynamic sparse graph attention framework for cross-domain intelligent diagnosis of rotating machinery. <em>NEUCOM</em>, <em>656</em>, 131553. (<a href='https://doi.org/10.1016/j.neucom.2025.131553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mechanical equipment prognostics, conventional graph neural networks encounter significant limitations when processing high-dimensional dynamic sensor data: inadequate modeling of complex feature interdependencies, insufficient sensitivity to transient fault signatures, and ineffective knowledge transfer in cross-domain applications. To overcome these challenges, we present a DSGA-SAGE, which stands for Dynamic Sparse Graph Attention - SAmpling and aGgrEgation framework. Our approach presents innovations in three aspects: (1) A decentralized graph construction paradigm establishes dynamic associations among multivariate time-series features, enabling precise identification of critical fault patterns through adaptive node-edge interactions. (2) A sparse attention mechanism with trainable topology constraints optimizes the structural weights of graph in the real-time scenarios, achieving 23 % overhead computational reduction while maintaining the accuracy of feature discriminability. (3) A unified cross-domain learning strategy synchronizes multi-condition knowledge transfer through hierarchical loss optimization, ensuring robust generalization across various operational scenarios. Extensive experiments on five industrial datasets demonstrate state-of-the-art performance: achieving the highest accuracy of 96.29 % in fault diagnosis, while realizing 99.87 % Macro-F1 and 99.88 % Micro-F1 scores in cross-domain tasks. Through a comprehensive performance analysis, the superiority of the efficiency and cross-domain adaptability in dynamic sparse graph attention mechanism has been convincingly validated.},
  archive      = {J_NEUCOM},
  author       = {Ying Xie and Jixiang Wang and Zhiqiang Xu and Junnan Shen and Lijie Wen and Rongbin Xu and Yun Yang},
  doi          = {10.1016/j.neucom.2025.131553},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131553},
  shortjournal = {Neurocomputing},
  title        = {A novel dynamic sparse graph attention framework for cross-domain intelligent diagnosis of rotating machinery},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient medical image encryption and attack detection using hyperchaotic fibonacci polynomial convolutional neural network in IoT healthcare networks. <em>NEUCOM</em>, <em>656</em>, 131537. (<a href='https://doi.org/10.1016/j.neucom.2025.131537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the fast expansion of IoT technology in the health-related field, secure transfer of sensitive medical data in general, and of medical images in particular, has become a major concern. Conventional detection and encryption techniques usually cannot guarantee both high security and computational efficiency under strict real-time constraints. To counter the above problems, this research proposed a novel Hyperchaotic Fibonacci Polynomial Convolutional Neural Network with Crayfish Optimization Algorithm (HFPCNN-COA) for increased medical image security in IoT environments. The medical images are first encrypted with Hyperchaotic System-Fibonacci Q Matrix Encryption (HFQE) on a standard collection. After encryption, they are sent over the network. After transmission, the HAPCNN is applied to detect and classify any potential tampering or transmission attacks. The loss function of HAPCNN is optimized with the Crayfish Optimization Algorithm (COA) to increase the detection accuracy and convergence speed. Lastly, cryptanalysis is conducted to measure the system's resilience to attack. The experimental results prove the workability of the proposed framework, with a Peak Signal-to-Noise Ratio (PSNR) of 53 dB, which corresponds to very good retention of image quality. In addition, the proposed method is quite resistant to data manipulation with a 0.4 % Bit Error Rate (BER) and has reasonable processing times with encryption times of 2.87 ms and decryption times of 2.35 ms. This shows that HFPCNN-COA holds a great deal of promise as an actual and secure means for the transfer of medical image data for IoT-based healthcare systems.},
  archive      = {J_NEUCOM},
  author       = {Bhumireddypalli Veerasekharreddy and P. Chinniah and P. Varaprasada Rao and Krishna Prakash Arunachalam},
  doi          = {10.1016/j.neucom.2025.131537},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131537},
  shortjournal = {Neurocomputing},
  title        = {Efficient medical image encryption and attack detection using hyperchaotic fibonacci polynomial convolutional neural network in IoT healthcare networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A collaborative decision framework for dynamic control of gear remaining useful life using multi-source information in active health management. <em>NEUCOM</em>, <em>656</em>, 131536. (<a href='https://doi.org/10.1016/j.neucom.2025.131536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing demand for intelligent operation and maintenance of vertical mill gearboxes in the cement industry, traditional passive maintenance methods are increasingly inadequate for supporting efficient, proactive management under complex operational conditions. In particular, sudden gear failures often result in unplanned downtime, causing significant economic losses. To address this challenge, this paper proposes a dynamic control approach for gear remaining useful life (RUL) that integrates multi-source information through collaborative decision-making to enable active health management. First, a novel RUL prediction method based on multilevel multi-source domain adaptation (MMDA) is proposed to enhance the generalization capability of the model. By minimizing discrepancies between local and global feature distributions under varying working conditions and aligning the prediction boundaries among predictors, the proposed method achieves accurate RUL predictions. Then, a gear RUL dynamic control method based on multi-information collaborative decision-making is developed. This method dynamically regulates gear RUL using a model-free adaptive control (MFAC) strategy, leveraging multi-source information such as online RUL prediction results, expected usage duration, and real-time working conditions. Finally, a collaborative decision framework for dynamic control of gear RUL is proposed, which enables active gear health management to be implemented, thereby minimizing unscheduled downtime. The effectiveness of the proposed gear RUL dynamic control method is validated on a self-made gear transmission system experimental platform, achieving a 27.6 % reduction in average RMSE compared with state-of-the-art baselines and extending the operational life of gear by approximately 61 h under dynamic control.},
  archive      = {J_NEUCOM},
  author       = {Xuegang Li and Yuanyue Pu and Nian Wu and Huajun Cao and Xiaoxi Ding and Wenbin Huang},
  doi          = {10.1016/j.neucom.2025.131536},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131536},
  shortjournal = {Neurocomputing},
  title        = {A collaborative decision framework for dynamic control of gear remaining useful life using multi-source information in active health management},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AttackTracer: Semantic-level adversarial attack location traceability via evidential diffusion model. <em>NEUCOM</em>, <em>656</em>, 131535. (<a href='https://doi.org/10.1016/j.neucom.2025.131535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks pose a significant threat to AI systems, yet existing detection methods mainly focus on image-level threats, limiting fine-grained localization of perturbations. To address this challenge, we propose AttackTracer, the first semantic-level localization framework specifically designed for instance-level adversarial attacks. Instance-level adversarial perturbations are typically sparse and localized, which aligns naturally with the capabilities of diffusion models to progressively reconstruct sparse structures from stochastic noise. Building on this property, AttackTracer models the adversarial mask as a conditional distribution given the adversarial image, allowing iterative refinement and effective recovery of attack regions. To address the inherent instability of diffusion sampling, we introduce the Temporal Evidence Fusion Strategy (TEFS). TEFS integrates Dempster–Shafer theory with a signal-to-noise-ratio (SNR)-guided temporal ensemble, aggregating multi-step predictions to mitigate conflicts and uncertainty, thus achieving robust inference. Furthermore, adversarial perturbations often manifest as subtle high-frequency and edge distortions. To capture these, AttackTracer employs two complementary modules: the Wavelet Frequency Fusion Block (WFFB), which extracts multi-scale frequency features via Discrete Wavelet Transform to enhance sensitivity to sparse perturbations, and the Edge Feature Enhancement Module (EFEM), which models multi-granularity edge structures using parallel branches and FFT to detect boundary distortions. Together, WFFB and EFEM provide complementary views of perturbation patterns. Extensive experiments demonstrate that AttackTracer achieves superior traceability of adversarial regions while maintaining robustness across stochastic sampling and varying scales, highlighting its effectiveness for instance-level attack localization.},
  archive      = {J_NEUCOM},
  author       = {Zhentong Zhang and Xinde Li and Pengfei Zhang and Kui Wang and Tianrong Gao and Tao Shen},
  doi          = {10.1016/j.neucom.2025.131535},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131535},
  shortjournal = {Neurocomputing},
  title        = {AttackTracer: Semantic-level adversarial attack location traceability via evidential diffusion model},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A prototype-guided federated learning based fault diagnosis method of mechanical transmission system under label distribution skew. <em>NEUCOM</em>, <em>656</em>, 131532. (<a href='https://doi.org/10.1016/j.neucom.2025.131532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the label distribution skew in federated learning based mechanical fault diagnosis, a federated learning based diagnosis framework combining prototypes and hybrid classifier is proposed. Firstly, prototypes are constructed based on sample feature means, and an exponential moving average strategy is introduced to smooth the aggregation of prototypes across rounds, while the prototype constraint loss function is constructed to guide the convergence of client features to the global prototype and compress the distance between similar samples. Secondly, a hybrid classifier architecture combining a local classifier with a global prototype classifier is proposed to learn local feature and global class prototypes through a two-branch structure, and a dynamic weighting strategy is used to achieve the output fusion. Finally, a prototype separation strategy is introduced on the server side, which detects pairs of confused class prototypes by Euclidean distance, increases the distance between similar prototypes, and avoids the prototype overlapping issue. In order to verify the effectiveness of the proposed method, nine kinds of faults of bearings, rotors and gears in mechanical transmission system are fabricated, and four types of fault diagnosis experiments with different degrees of label skew are designed, and the results show that the proposed method can effectively identify all the fault classes, and it still achieves an accuracy of 91.00 % in the extreme distribution skew task, which is significantly better than the other comparative methods, which provides a new feasible way for the distributed data driven federated learning based intelligent mechanical fault diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Hongwei Fan and Shenglin Liu and Xiangang Cao and Xuhui Zhang},
  doi          = {10.1016/j.neucom.2025.131532},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131532},
  shortjournal = {Neurocomputing},
  title        = {A prototype-guided federated learning based fault diagnosis method of mechanical transmission system under label distribution skew},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A predefined-time double-integral zeroing neural network model for linear equations flows and its application on dynamic position. <em>NEUCOM</em>, <em>656</em>, 131531. (<a href='https://doi.org/10.1016/j.neucom.2025.131531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving time-varying linear equation flows presents a significant challenge in dynamic systems due to the continuously evolving coefficients, which undermine the effectiveness of traditional numerical methods. Moreover, the presence of external noise further exacerbates the difficulty of obtaining accurate solutions. To address these issues, this paper proposes a predefined-time double-integral zeroing neural network (PTDIZNN) model, inspired by the enhanced robustness of the conventional DIZNN framework. Specifically, a novel time-based gain is incorporated into the design of the DIZNN, ensuring predefined-time convergence of the proposed PTDIZNN model. A comprehensive theoretical analysis is conducted to verify its stability, convergence, and robustness properties. Furthermore, comparative simulations demonstrate that the PTDIZNN outperforms existing models in terms of solution accuracy and robustness under both column-full-rank and square-array coefficient scenarios. Finally, the effectiveness of the PTDIZNN is verified through its successful application in dynamic target positioning, highlighting its potential for broader real-time applications.},
  archive      = {J_NEUCOM},
  author       = {Jialiang Chen and Linju Li and Lin Xiao},
  doi          = {10.1016/j.neucom.2025.131531},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131531},
  shortjournal = {Neurocomputing},
  title        = {A predefined-time double-integral zeroing neural network model for linear equations flows and its application on dynamic position},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAFE-TAP: Semantic-aware and fused embedding for TAP rule security detection. <em>NEUCOM</em>, <em>656</em>, 131529. (<a href='https://doi.org/10.1016/j.neucom.2025.131529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trigger-Action Programming (TAP) has emerged as a widely adopted paradigm for enabling automated interoperability among IoT devices. Despite its convenience, TAP introduces significant security vulnerabilities. To address this issue, we propose SAFE-TAP, a novel framework for detecting malicious TAP rules that integrates global semantic understanding with temporal feature analysis. To further enhance the detection performance, we introduce an innovative data augmentation strategy that leverages Large Language Models (LLMs) to generate semantically consistent rule variations. This approach improves data set balance and enhances the generalizability of the model. Experimental results demonstrate that SAFE-TAP outperforms baseline methods, and the incorporation of LLM-based data augmentation significantly improves detection performance under imbalanced data scenarios.},
  archive      = {J_NEUCOM},
  author       = {Zhejun Kuang and Yusheng Zhu and Dawen Sun and Jian Zhao and Yongheng Xing and Feng Wang and Lei Sun},
  doi          = {10.1016/j.neucom.2025.131529},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131529},
  shortjournal = {Neurocomputing},
  title        = {SAFE-TAP: Semantic-aware and fused embedding for TAP rule security detection},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bipartite contrastive multi-view clustering with singular value modulation. <em>NEUCOM</em>, <em>656</em>, 131528. (<a href='https://doi.org/10.1016/j.neucom.2025.131528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive multi-view clustering (CMvC) has attracted increasing attention for its semantic mining capacity. However, existing CMvC methods often process pairwise views to explore consistency, inevitably ignoring the joint information and inherent redundancy among multiple views. In this paper, we propose a novel Bipartite Contrastive Multi-view Clustering with Singular Value Modulation (BCMVC) that reformulates contrastive learning as a binary classification problem. Specifically, unlike existing pairwise-view sequential processing methods, we construct a correlation learning module that simultaneously mines consistent information across multiple views. This module effectively explores joint information at both the instance level and category level, with each level equipped with a dedicated correlation learner. By leveraging the concat and random shuffle strategy to encapsulate the positive and negative sample sets, the level-specific correlation learner is effectively optimized to enhance the discrimination of samples. Meanwhile, a deep singular value weighting module is introduced to refine the learned representations through a weighted singular value reconstruction strategy, mitigating the adverse effects of noisy information. Extensive experiments on seven benchmark datasets demonstrate that our method achieves substantial advancements compared with other state-of-the-art approaches. The code is available at https://github.com/zhangt-make/BCMVC .},
  archive      = {J_NEUCOM},
  author       = {Teng Zhang and Pengyuan Li and Zisen Kong and Dongxia Chang and Yao Zhao},
  doi          = {10.1016/j.neucom.2025.131528},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131528},
  shortjournal = {Neurocomputing},
  title        = {Bipartite contrastive multi-view clustering with singular value modulation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The framework and memristive circuit design for attention-regulated working memory. <em>NEUCOM</em>, <em>656</em>, 131525. (<a href='https://doi.org/10.1016/j.neucom.2025.131525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive behavior and decision-making depend on constantly selecting relevant information from the external environment and internal states. Inspired by the working memory structure and the top-down and bottom-up attention mechanisms in cognitive neuroscience, this work proposes an attention-regulated working memory model. This model provides a brain-inspired approach to integrate perception, long-term memory, and action. It processes current external multisensory stimuli and retrieves stored knowledge from internal reinforcement simultaneously, leading to adaptive and rapid executive actions. On this basis, a memristive circuit is designed to realize rich cognitive functions in an online in-situ learning and in-memory computing manner. The designed circuit consists of four main components: (1) the phonological loop and visuospatial sketchpad consider different audio-visual input patterns and varying stimulus salience, realizing the filtration, synchronization, and encoding of multimodal signals; (2) the attention control module captures and maintains attention driven by multisensory stimulation; (3) the episodic buffer achieves reward reinforcement, forming or resetting the top-down attentional bias signal; (4) the central executive control module regulates the relationships between the two attentional pathways, thus transforming the random exploration process into a learnable final action. Finally, simulation results in LTSPICE demonstrate that our circuit can be adaptively applied to the cognitive control and execution system of robots within complicated circumstances.},
  archive      = {J_NEUCOM},
  author       = {Jihong Zhang and Xiaoping Wang and Zhanfei Chen and Chao Yang},
  doi          = {10.1016/j.neucom.2025.131525},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131525},
  shortjournal = {Neurocomputing},
  title        = {The framework and memristive circuit design for attention-regulated working memory},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A temporally coded multilayer spiking neural network and its memristor-based hardware implementation. <em>NEUCOM</em>, <em>656</em>, 131523. (<a href='https://doi.org/10.1016/j.neucom.2025.131523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) have demonstrated remarkable progress in various domains. However, ANNs suffer from enormous time and energy consumption during training and inference processes. Brain-inspired spiking neural networks (SNNs) have recently attracted more attention due to their higher biological plausibility and potential cost-efficient properties. However, most existing SNNs significantly degrade in performance and efficiency when simulated on conventional CPU/GPU hardware. Therefore, a novel temporally coded multilayer SNN (TMSNN) is proposed in this study. It is a typical event-driven model, which encodes information in the relative timing of spikes rather than in firing rates and uses the leaky integrate-and-fire neuron as the basic unit to pursue high biological plausibility. Its multilayer architecture enables the model to solve complicated problems effectively. On the other hand, the proposed TMSNN can be implemented on memristor-based hardware, which uses customized weight quantization and sharing techniques to mitigate the size restrictions of the memristor crossbars. After refining the weights using the simulated annealing algorithm, the hardware implementation of TMSNN can achieve very competitive performance on benchmark datasets, outperforming state-of-the-art temporally coded SNNs in our experiments. The source code of TMSNN is available at https://github.com/jhc050998/Memristor-Crossbar-Based-SNN .},
  archive      = {J_NEUCOM},
  author       = {Haochang Jin and Xiuzhi Yang and Shuangbao Song and Zhenyu Song and Junkai Ji},
  doi          = {10.1016/j.neucom.2025.131523},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131523},
  shortjournal = {Neurocomputing},
  title        = {A temporally coded multilayer spiking neural network and its memristor-based hardware implementation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential extended dissipative synchronization control of Cohen–Grossberg neural networks with four kinds of time-varying delays. <em>NEUCOM</em>, <em>656</em>, 131522. (<a href='https://doi.org/10.1016/j.neucom.2025.131522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the exponential extended dissipative synchronization control problem of Cohen–Grossberg neural networks (CGNNs) with four kinds of time-varying delays. The types of delays involve time-varying leakage, neutral, distributed and transmission delays. Due to the increasing complexity of control requirements and time delays in practice, some performance analysis approaches and techniques cannot be directly applied, or are faced with the problem of high computational complexity. To this end, a more general and computationally efficient novel method is proposed. Firstly, a sufficient condition to guarantee the existence and uniqueness of the solution of CGNN is presented by defining a new norm, and a representation of the unique solution is first put forward. Then, the state-feedback controller and novel system solutions-based inequality are constructed to obtain exponential extended dissipative synchronization criteria. This proposed approach overcomes the difficulty of constructing a suitable Lyapunov–Krasovskii functional (LKF) under complex time delays and control requirements, and reduces computational complexity. Furthermore, to solve the nonlinear terms in the obtained criteria, an algorithm is designed. Finally, the derived results are validated for feasibility by three numerical examples, and their potential applications in image processing are showcased.},
  archive      = {J_NEUCOM},
  author       = {Kairong Tu and Yu Xue},
  doi          = {10.1016/j.neucom.2025.131522},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131522},
  shortjournal = {Neurocomputing},
  title        = {Exponential extended dissipative synchronization control of Cohen–Grossberg neural networks with four kinds of time-varying delays},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A rate-dependent coreset selector for continual learning on time-varying data distributions. <em>NEUCOM</em>, <em>656</em>, 131519. (<a href='https://doi.org/10.1016/j.neucom.2025.131519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we review the concept of “phase” defined in Class-Incremental Learning (CIL), i.e., learning new classes while not forgetting old ones. Due to this design, classic CIL algorithms are mostly offline or can handle only intensive data distribution shifts across the phases. However, real-world data streams are often online, usually with uncertain or untraceable changes in their data distributions. To this end, we design the per-step distribution shifts by modeling the class sampling weights using bell-shaped curves. Such a design respects the rise-and-fall nature and presents realistic but underexplored challenges for CIL: 1) The data non-stationarity across steps requires the models to identify the recent dynamics and adopt an appropriate learning strategy for knowledge memorization and adaptation. 2) Over all steps, the proposed streams exhibit various class-imbalance patterns , with different majority classes and time-varying imbalance ratios. To address the challenges, we propose a novel Rate-Dependent Coreset Selector (RDCS), which essentially presents an adaptive and robust sample selection criterion when constructing memory for replay. We conduct extensive experiments by generating the proposed data streams on multiple image benchmarks and implementing RDCS in an efficient approximation, showing its superior performance.},
  archive      = {J_NEUCOM},
  author       = {Zilin Luo and Zichen Tian and Yaoyao Liu and Qianru Sun},
  doi          = {10.1016/j.neucom.2025.131519},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131519},
  shortjournal = {Neurocomputing},
  title        = {A rate-dependent coreset selector for continual learning on time-varying data distributions},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MLFork: Bearing fault diagnosis via mamba-powered few-shot learning model with multi-level architecture enhanced by spatial-wise and channel-wise local vector attention. <em>NEUCOM</em>, <em>656</em>, 131518. (<a href='https://doi.org/10.1016/j.neucom.2025.131518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearings are one of the most important components of electrical machines and devices; however, they are prone to damage, leading to the lack of safety and the malfunction of machines. Some methods including deep-learning ones can be used for bearing fault diagnosis; however, in reality, the models have to adapt to the shortage of training data from clients while still maintaining good performance. To overcome this issue, the novel “MLFork” model is proposed, following the Few-shot algorithm for limited training with improvements in the feature extraction and the pre-classification steps. For feature extraction, a new Bi-Context Visual State Space Block is introduced, which excellently learns the global context of the sample in multiple ways. Before the Multi-Level classification module, separate routes for spatial-wise and channel-wise local vector attention are used to highlight the important details of the local descriptor. To evaluate the performance of the model, various experiments were done on the Case Western Reserve University dataset (CWRU) and the Paderborn University dataset (PU), where the “MLFork" model showed promising results. The code for this model will be available at: https://github.com/thzhere/MLFork .},
  archive      = {J_NEUCOM},
  author       = {Duy-Thai Nguyen and Van-Quoc-Viet Nguyen and Thi-Thao Tran and Van-Truong Pham},
  doi          = {10.1016/j.neucom.2025.131518},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131518},
  shortjournal = {Neurocomputing},
  title        = {MLFork: Bearing fault diagnosis via mamba-powered few-shot learning model with multi-level architecture enhanced by spatial-wise and channel-wise local vector attention},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). All-in-one image restoration via diffusion models with degradation perception and semantic enhancement. <em>NEUCOM</em>, <em>656</em>, 131517. (<a href='https://doi.org/10.1016/j.neucom.2025.131517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration is a fundamental task in computer vision. However, most existing methods are tailored for single-degradation scenarios, limiting their applicability in real-world conditions where multiple degradations often co-occur. To address this issue, we propose a degradation-aware image restoration framework. A bidirectional Mamba module is introduced to process fused spatial-frequency features, enabling accurate identification of degradation types via a multi-degradation encoding strategy. Based on the predicted degradation, a fine-tuned CLIP model with an attention mechanism is employed to extract semantic features. These features are then integrated with degradation representations and fed into a conditional denoising diffusion model to progressively reconstruct high-quality images. To facilitate evaluation, we construct the Multi-Degradation Perception Dataset (MDPD), specifically designed for complex degradation scenarios. Experimental results demonstrate that our method achieves over 98 % classification accuracy in identifying degradation types. On the MDPD dataset, it achieves a PSNR of 36.25 dB and improves SSIM by 0.01 to 0.04 across various degradation combinations.},
  archive      = {J_NEUCOM},
  author       = {Jiangang Jiang and Zhe Chen and Yuxin Su and Pancheng Zhang and Yihui Hu},
  doi          = {10.1016/j.neucom.2025.131517},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131517},
  shortjournal = {Neurocomputing},
  title        = {All-in-one image restoration via diffusion models with degradation perception and semantic enhancement},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural operator-based composite learning adaptive backstepping control for linear 2×2 hyperbolic PDE systems. <em>NEUCOM</em>, <em>656</em>, 131516. (<a href='https://doi.org/10.1016/j.neucom.2025.131516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel neural operator (NO)-based composite learning adaptive backstepping control scheme for stabilizing uncertain linear 2 × 2 hyperbolic PDE systems. This method addresses key challenges arising from complex PDE dynamics, model uncertainties, and high computational costs, within a backstepping design framework. Our approach integrates two main components: 1) A composite learning adaptive controller, which combines both historical and real-time data to construct informative matrices for parameter updates. This strategy enables accurate and exponential parameter convergence under finite excitation (FE) conditions, thereby improving transient performance and guaranteeing exponential system stability. 2) An efficient NO-based approximation method, where a deep operator network (DeepONet) is trained to approximate the nonlinear mapping from composite parameter estimates to backstepping kernel gains. The controller is constructed using the approximate kernels, which eliminates the need to repeatedly solve kernel PDE online, significantly improving the computational efficiency and accelerating real-time control. Furthermore, theoretical analysis proves closed-loop boundedness and exponential stability under the proposed scheme. Numerical simulations verify its effectiveness and superiority.},
  archive      = {J_NEUCOM},
  author       = {Xianhe Zhang and Yu Xiao and Xiaodong Xu and Biao Luo and Weihua Gui and Tingwen Huang},
  doi          = {10.1016/j.neucom.2025.131516},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131516},
  shortjournal = {Neurocomputing},
  title        = {Neural operator-based composite learning adaptive backstepping control for linear 2×2 hyperbolic PDE systems},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RAG-LER: Ranking adapted generation with language-model enabled regulation. <em>NEUCOM</em>, <em>656</em>, 131514. (<a href='https://doi.org/10.1016/j.neucom.2025.131514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have demonstrated impressive capabilities across diverse NLP tasks, yet they still struggle with hallucination due to limited parametric knowledge. Retrieval Augmented Generation (RAG) addresses this issue by integrating non-parametric data stores. However, straightforward integration of information retrieval or end-to-end training of these components often leads to suboptimal results or computational inefficiency. In this work, we introduce RAG-LER, a framework that enhances an LM’s context understanding and improves the quality and accuracy of provided passages through an LM-supervised re-ranker. RAG-LER fine-tunes a pre-trained LM to follow instructions and discriminately use provided information. It then leverages this fine-tuned LM to generate ranking scores, which serve as supervised labels for training the re-ranker. We also introduce a confidence-weighted objective that filters unreliable LLM supervision signals while preserving the original re-ranker capabilities. By harnessing LLMs’ strong capabilities, our approach eliminates the need for manual human labeling in re-ranker training while achieving improved performance. Experiments demonstrate that RAG-LER outperforms existing retrieval-augmented LMs on open-domain QA and fact-checking tasks, while exhibiting consistently improved performance when applied to different retrieval methods, highlighting its versatility and effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Fengwen Zhai and Wenyang Tang and Jing Jin},
  doi          = {10.1016/j.neucom.2025.131514},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131514},
  shortjournal = {Neurocomputing},
  title        = {RAG-LER: Ranking adapted generation with language-model enabled regulation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TalkingAvatar: Learning 3D talking human avatar via NeRF. <em>NEUCOM</em>, <em>656</em>, 131513. (<a href='https://doi.org/10.1016/j.neucom.2025.131513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable progress in 3D talking head generation, directly generating expressive upper-body 3D talking avatars that integrate realistic talking heads and lifelike bodies remains challenging. To address these issues, a novel TalkingAvatar is proposed to reconstruct vivid avatars from dynamic monocular videos while endowing them with expressive animation capabilities. Given audio and SMPL-X pose sequences, TalkingAvatar can animate 3D human avatars with lip-synced mouth movements and complex hand gestures. Specifically, TalkingAvatar utilizes a fast deformer for articulated neural fields (Fast-SNARF) to optimize human volumetric representations in a canonical T-pose. It also incorporates a novel Hybrid Modulation Attention Module (HMAM) that focuses on capturing dynamic movements. Additionally, a UV feature map is used for detailed static texture learning. Notably, HMAM leverages a modulation mechanism to exploit comprehensive dynamic motion information from both body pose and speech audio, ensuring expressive control of mouth and hands. Moreover, to minimize interference between different body parts, TalkingAvatar adopts a part-aware learning strategy that employs multiple regional grids to model the head, hands, and body areas separately. This strategy significantly enhances the fidelity of small-scale body regions. Experiments demonstrate that our method outperforms the state-of-the-art in both avatar reconstruction and animation of mouth and hand movements, generating high-fidelity co-speech gesture videos, while requiring significantly less training data.},
  archive      = {J_NEUCOM},
  author       = {Lingyun Yu and Chuang Chen and Chuanbin Liu and Wu Liu and Quanwei Yang and Yizhi Liu and Meng Shao},
  doi          = {10.1016/j.neucom.2025.131513},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131513},
  shortjournal = {Neurocomputing},
  title        = {TalkingAvatar: Learning 3D talking human avatar via NeRF},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental algorithms on low-rank approximation of large-scale kernel matrices based on perturbation of invariant subspaces. <em>NEUCOM</em>, <em>656</em>, 131512. (<a href='https://doi.org/10.1016/j.neucom.2025.131512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel methods are one of the most commonly used techniques in machine learning. In Mitz and Shkolnisky (2022) [27] , a framework of perturbation-based kernel matrix approximation is proposed, which is based on the tool of matrix perturbation analysis. However, there are two shortcomings in this framework. First, it requires that some dominant eigenvalues of kernel matrices are distinct in theory. However, in practical applications, when using a randomly sampled dataset, some kernel matrices generated by certain kernel functions are prone to having multiple eigenvalues due to data distribution or parameter settings. Second, from the algorithmic perspective, one has to know the error matrix of the kernel matrix in advance, which is unrealistic for real-world applications. Thus, the most common situation in practical applications is to pay attention to the case of multiple eigenvalues, and it is interesting to generalize the original perturbation-based kernel approximation framework to the scenario where there are multiple eigenvalues. In this work, we present a perturbation result on eigenvalues and eigenspaces of a kernel matrix whose dominant eigenvalues can be multiple. Based on this result, we propose a low-rank approximation to kernel matrix. On the other hand, as far as we are aware, efficient algorithms are still lacking for updating large-scale kernel matrices, and there are few algorithms addressing batch-incremental kernel methods. Based on our proposed truncated formula, we consider the incremental problem of large-scale kernel matrices and propose two incremental algorithms for updating large-scale kernel matrices. Numerical experiments demonstrate the efficiency of the proposed algorithms for solving incremental data problems and incremental kernel ridge regression.},
  archive      = {J_NEUCOM},
  author       = {Xiaxin Li and Gang Wu},
  doi          = {10.1016/j.neucom.2025.131512},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131512},
  shortjournal = {Neurocomputing},
  title        = {Incremental algorithms on low-rank approximation of large-scale kernel matrices based on perturbation of invariant subspaces},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FMSF: Future-preference modeling with similar-user features for next POI recommendation. <em>NEUCOM</em>, <em>656</em>, 131511. (<a href='https://doi.org/10.1016/j.neucom.2025.131511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abundant user check-in records in location-based social networks enhance the development of point-of-interest (POI) recommendation systems. The existing studies attempt to learn users’ past, current, and future preferences from their own sequential behaviors. Various approaches have been explored to model user visiting behaviors for the prediction of future preferences and have achieved considerable performance. However, most previous work ignores the impact of other users’ preferences on the prediction of current users’ future preferences. Thus, this work proposes a novel Future-preference Modeling with Similar-user Features (FMSF) model for next POI recommendation. It integrates the preferences of a user and those of other users to accurately model his/her multi-step future preferences. Specifically, it adopts a dynamically-updated similarity matrix to extract the information of similar users. Then, it incorporates an attention mechanism to assign distinct attention weights to the characteristics of both the current and similar users, which promotes the prediction of the future preferences of the current users. Therefore, the method proposed in this paper can offer users more precise recommendation results. Extensive experiments are conducted on three real-world datasets, which demonstrate the advantages of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Luan and Zhichao Feng and Liang Qi and Xiaoyu Sean Lu},
  doi          = {10.1016/j.neucom.2025.131511},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131511},
  shortjournal = {Neurocomputing},
  title        = {FMSF: Future-preference modeling with similar-user features for next POI recommendation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Permutation XOR cellular automata and direct stable periodic orbits. <em>NEUCOM</em>, <em>656</em>, 131510. (<a href='https://doi.org/10.1016/j.neucom.2025.131510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a permutation XOR cellular automaton (PXCA), a simple three-layer discrete-time dynamical system. The input-to-hidden layer corresponds to an elementary cellular automaton of the XOR rule and the hidden-to-output layer is the shift-type one-to-one permutation connection. The dynamics are described by an autonomous difference equation of binary state variables. Depending on the permutation connection, the PXCA generates a variety of direct stable periodic orbits (DBPOs) characterized by strong stability and fast transient phenomena. As a main result, we provide theoretical evidence that clarifies the number, period, and stability of DBPOs for general odd-dimensional PXCAs. Performing a precise numerical analysis, we have clarified that, depending on the dimension and a parameter, the period of DBPOs varies complicatedly and can become very long. Applications of the DBPOs include time series approximation and switching circuit control. As a fundamental step toward the applications, we present a simple FPGA based hardware prototype and have confirmed typical DBPOs experimentally.},
  archive      = {J_NEUCOM},
  author       = {Mikito Onuki and Yosuke Suzuki and Toshimichi Saito},
  doi          = {10.1016/j.neucom.2025.131510},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131510},
  shortjournal = {Neurocomputing},
  title        = {Permutation XOR cellular automata and direct stable periodic orbits},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal dynamic brain graph representation learning for brain disorder diagnosis via temporal sequence model. <em>NEUCOM</em>, <em>656</em>, 131509. (<a href='https://doi.org/10.1016/j.neucom.2025.131509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain network representation learning leverages graph-based algorithms to enhance understanding of functional brain organization. Recently, deep learning approaches based on graph neural network (GNN) have shown promising results in various brain network analysis tasks. Nevertheless, despite significant achievements in brain graph learning, early models still exhibit limitations in dynamic modeling and multi-modal network fusion. Dynamic modeling of brain networks entails learning sequential spatial interactions across time. Inspired by recent advances in large language model architectures, particularly RWKV, which combines the strengths of recurrent neural networks (RNNs) and Transformers. We propose an e fficient t emporal m ulti-modal g raph n eural n etwork (ET_MGNN), that captures complex temporal dependencies while integrating dynamic functional connectivity (DFC) and structural connectivity (SC) into a unified brain network representation. The proposed model demonstrates competitive performance in brain disorder classification on three datasets, outperforming several strong baselines. For instance, ET_MGNN an average classification accuracy improvement of 11.8 % on autism spectrum disorder (ASD) vs healthy controls, 32.9 % on Alzheimer's disease (AD) vs. mild cognitive impairment (MCI), compared to the well-suited STAGIN model. Furthermore, we introduce an interpretable graph reading mechanism that can identify disorder-relevant brain regions. In summary, ET_MGNN combines large-scale language sequence modeling with dynamic brain graph representation learning to improve the accuracy of brain disease diagnosis, providing insightful findings for dynamic brain network modeling.},
  archive      = {J_NEUCOM},
  author       = {Jinwei Lang and Li-Zhuang Yang and Hai Li},
  doi          = {10.1016/j.neucom.2025.131509},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131509},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal dynamic brain graph representation learning for brain disorder diagnosis via temporal sequence model},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PVFT-net: A point-voxel fusion method for self-supervised scene flow estimation with transformer. <em>NEUCOM</em>, <em>656</em>, 131508. (<a href='https://doi.org/10.1016/j.neucom.2025.131508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene flow estimation is a computer vision task that aims to estimate the 3D motion field of points from two consecutive frames of point clouds, and has a wide range of applications in various fields such as robotics and autonomous driving. Most of the existing methods estimate scene flow through point-based models, but ignore the irregularity of point clouds and the inefficiency of point-level computation. And voxel-based methods can hardly avoid the loss of detailed information. Therefore, we propose a point-voxel fusion method that contains a point branch and a voxel branch. The voxel branch projects the point cloud to regular local grids and captures coarse-grained local features from non-empty voxels through Sparse Grid Attention (SGA) with the shift window strategy. And the point branch captures fine-grained global features through dual attention consisting of Deformable Global Attention (DGA) and Channel Self-Attention (CSA), while compensating for the information loss in the voxel branch. Considering that it is difficult to directly describe the local geometric structure of complex objects in the scene with the shape of 3D objects potentially learned only through xyz coordinates, we explicitly encode the local surface information of the point cloud through the Umbrella Surface Feature Extraction (USFE) module. In addition, we introduce Density Sensitive Metric(DSM) loss to reduce the impact of outliers and density distribution mismatch problems. We validate the effectiveness of our method by performing experiments on the Flyingthings3D and KITTI datasets. Our method outperforms all other self-supervised methods and achieves highly competitive results compared to fully supervised methods. We achieve improvements in all metrics, especially EPE, which is decreased by 8.51 % on the KITTI o dataset and 15.79 % on the KITTI s dataset.},
  archive      = {J_NEUCOM},
  author       = {Xuezhi Xiang and Xi Wang and Xiaoheng Li and Xiankun Zhou and Lei Zhang and Xiantong Zhen},
  doi          = {10.1016/j.neucom.2025.131508},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131508},
  shortjournal = {Neurocomputing},
  title        = {PVFT-net: A point-voxel fusion method for self-supervised scene flow estimation with transformer},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attacking the spike: On the security of spiking neural networks to adversarial examples. <em>NEUCOM</em>, <em>656</em>, 131506. (<a href='https://doi.org/10.1016/j.neucom.2025.131506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) have attracted much attention for their high energy efficiency and for recent advances in their classification performance. However, unlike traditional deep learning approaches, the analysis and study of the robustness of SNNs to adversarial examples remain relatively underdeveloped. In this work, we focus on advancing the adversarial attack side of SNNs and make three major contributions. First, we show that successful white-box adversarial attacks on SNNs are highly dependent on the underlying surrogate gradient estimation technique, even in the case of adversarially trained SNNs. Second, using the best single surrogate gradient estimation technique, we analyze the transferability of adversarial attacks on SNNs and other state-of-the-art architectures like Vision Transformers (ViTs), as well as CNNs. Our analyzes reveal two key areas where SNN adversarial attacks can be enhanced: no white-box attack effectively exploits the use of multiple surrogate gradient estimators for SNNs, and no single model attack is effective at generating adversarial examples misclassified by both SNNs and non-SNN models simultaneously. For our third contribution, we develop a new attack, the Mixed Dynamic Spiking Estimation (MDSE) attack to address these issues. MDSE utilizes a dynamic gradient estimation scheme to fully exploit multiple surrogate gradient estimator functions. In addition, our novel attack generates adversarial examples capable of fooling both SNN and non-SNN models simultaneously. The MDSE attack is as much as 91.4 % more effective on SNN/ViT model ensembles and provides a 3 × boost in attack effectiveness on adversarially trained SNN ensembles, compared to conventional white-box attacks like Auto-PGD. Our experiments are broad and rigorous, covering three datasets (CIFAR-10, CIFAR-100 and ImageNet) and nineteen classifier models (seven for each CIFAR dataset and five models for ImageNet). We will release a fully publicly available code repository for the models and attacks upon publication.},
  archive      = {J_NEUCOM},
  author       = {Nuo Xu and Kaleel Mahmood and Haowen Fang and Ethan Rathbun and Caiwen Ding and Wujie Wen},
  doi          = {10.1016/j.neucom.2025.131506},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131506},
  shortjournal = {Neurocomputing},
  title        = {Attacking the spike: On the security of spiking neural networks to adversarial examples},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text-to-image person re-identification via collaborating pre-trained diffusion and discriminative models. <em>NEUCOM</em>, <em>656</em>, 131505. (<a href='https://doi.org/10.1016/j.neucom.2025.131505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image person re-identification (TIReID) aims to retrieve pedestrian images from a database that match given text queries. Currently, the most advanced methods involve transferring powerful multi-modal knowledge from the contrastive language-image pretraining (CLIP) model to perform cross-modal matching. However, CLIP primarily focuses on coarse-grained global contextual modeling of single image-text pairs, neglecting fine-grained compositional matching of complex visual-textual concepts. This makes it challenging to ensure fine-grained cross-modal matching between pedestrians and text queries. To address this issue, a novel framework, Collaborating Pre-trained Diffusion and Discriminative Models (CPDD), is proposed in this work. The CPDD comprises three modules: a fine-grained features learning (FFL) module, a semantic consistency alignment (SCA) module, and a masked-text interactive modeling (MIM) module. Firstly, the FFL learns feature representations containing fine-grained matching information between images and text through the reverse denoising process of a diffusion model. Next, a semantic consistency loss is designed in the SCA, which ensures the semantic consistency between the fine-grained matching information and the input image and text information. Then, the MIM propagates fine-grained matching information into the visual- textual context by a cross-modal interactive encoder, achieving fine-grained matching between images and text and enabling fine-grained cross-modal matching. Extensive experiments on the CUHK-PEDES, ICFG-PEDES, and RSTPReid datasets show that the proposed method achieves significant performance improvements compared to current research results, achieving Rank-1 accuracy of 74.87 %, 63.31 %, and 61.26 %, respectively.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Zhang and Chenyue Xu and Huajing Wu and Quange Tan and Qianli Zhou and Rong Wang},
  doi          = {10.1016/j.neucom.2025.131505},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131505},
  shortjournal = {Neurocomputing},
  title        = {Text-to-image person re-identification via collaborating pre-trained diffusion and discriminative models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Layer-wise contrastive learning BERT for sentence representation of GitHub. <em>NEUCOM</em>, <em>656</em>, 131504. (<a href='https://doi.org/10.1016/j.neucom.2025.131504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every day, on GitHub, end-users submit a large number of issues that must be addressed to ensure the success of software projects. Though BERT-based pre-trained language models achieve high performance on many downstream tasks, the sentence representation of [CLS] from the top layer of BERT has a limited ability to capture the semantic meaning of sentences. GitHub issue reports often include code snippets and user-generated terms not found in standard vocabularies. Therefore, the classification predictions of BERT are affected. To generate better sentence semantic representations of BERT for GitHub, we propose a layer-wise Contrastive Learning BERT (CLBERT), which uses contrastive learning to enhance the representation ability by contrasting the layer-by-layer representation. Further, to obtain as comprehensive information as possible, representations of each layer are extracted and learned by an attention mechanism as the final classification features. Finally, experiments conducted on two GitHub data sets show that our proposed model significantly improves classification performance.},
  archive      = {J_NEUCOM},
  author       = {Daoquan Chen and Wei Zhang and Shengyu Lu and Yuanguo Lin and Xinyu Gu and Xiuze Zhou},
  doi          = {10.1016/j.neucom.2025.131504},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131504},
  shortjournal = {Neurocomputing},
  title        = {Layer-wise contrastive learning BERT for sentence representation of GitHub},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attacking all tasks at once using adversarial examples in multi-task learning. <em>NEUCOM</em>, <em>656</em>, 131503. (<a href='https://doi.org/10.1016/j.neucom.2025.131503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual content understanding frequently relies on multi-task models to extract robust representations of a single visual input for multiple downstream tasks. However, in comparison to extensively studied single-task models, the adversarial robustness of multi-task models has received significantly less attention and many questions remain unclear: (1) How robust are multi-task models to single task adversarial attacks, (2) Can adversarial attacks be designed to simultaneously attack all tasks in a multi-task model, and (3) How does parameter sharing across tasks affect multi-task model robustness to adversarial attacks? This paper aims to answer these questions through careful analysis and rigorous experimentation. First, we analyze the inherent drawbacks of two commonly-used adaptations of single-task white-box attacks in attacking multi-task models. We then propose a novel attack framework, Dynamic Gradient Balancing Attack (DGBA). Our framework poses the problem of attacking all tasks in a multi-task model as an optimization problem that can be efficiently solved through integer linear programming. Extensive evaluation on two popular MTL benchmarks, NYUv2 and Tiny-Taxonomy, demonstrates the effectiveness of DGBA compared to baselines in attacking both clean and adversarially trained multi-task models. Our results also reveal a fundamental trade-off between improving task accuracy via parameter sharing across tasks and undermining model robustness due to increased attack transferability from parameter sharing.},
  archive      = {J_NEUCOM},
  author       = {Lijun Zhang and Xiao Liu and Kaleel Mahmood and Caiwen Ding and Hui Guan},
  doi          = {10.1016/j.neucom.2025.131503},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131503},
  shortjournal = {Neurocomputing},
  title        = {Attacking all tasks at once using adversarial examples in multi-task learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolutional neural network combined with edge complexity and channel attention mechanism for unsupervised superpixel segmentation. <em>NEUCOM</em>, <em>656</em>, 131502. (<a href='https://doi.org/10.1016/j.neucom.2025.131502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Superpixel segmentation is crucial for enhancing image processing efficiency and accuracy. To address the challenges of decreased accuracy and insufficient stability in adaptive superpixel generation faced by existing algorithms in complex image segmentation, we propose ECN, an unsupervised superpixel segmentation algorithm based on convolutional neural networks (CNN) integrating edge complexity and channel attention mechanisms. The ECN algorithm first calculates edge complexity using the Sobel operator, which guides the sequential network in determining the number of feature channels and the kernel size of the fast 1D convolution. Subsequently, low-level features with positional information are transformed into deep features through the sequential network, dynamically adjusting the weights of each feature channel using the channel attention mechanism. Finally, the target function is minimized during inference, enabling unsupervised superpixel generation. We validate ECN's applicability by combining it with Linear Discriminant Analysis (LDA) and Locality Fisher Discriminant Analysis (LFDA) to develop Superpixel Unsupervised Linear Discriminant Analysis (SULDA). Experimental results on BSDS500 and NYUv2 datasets show ECN outperforms existing methods, producing stable and higher-quality superpixel segmentation. Application tests on Indian Pines and Pavia University scenes confirm ECN's significant practical utility.},
  archive      = {J_NEUCOM},
  author       = {Fugui Luo and Shihua Li and Minghui Chang and Yuting Liu and Kaitong Liu},
  doi          = {10.1016/j.neucom.2025.131502},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131502},
  shortjournal = {Neurocomputing},
  title        = {Convolutional neural network combined with edge complexity and channel attention mechanism for unsupervised superpixel segmentation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge distillation-based object detection model focused on road scene perception and localization. <em>NEUCOM</em>, <em>656</em>, 131501. (<a href='https://doi.org/10.1016/j.neucom.2025.131501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is crucial for unmanned systems, as it enables real-time classification and localization of objects in road scenes. Besides detection accuracy, which remains robust to variations in object scales, an effective object detection algorithm also demands superior performance in processing time. To address these issues, this paper proposes a knowledge distillation-based object detection model, PLE-RepPoints-Lite, to compromise the performance of detection accuracy and speed for unmanned systems. We also design perception and localization enhancement (PLE) strategies, which consist of parallel dynamic attention, multi-scale composite localization confidence, and a feedback closed-loop structure, to enhance the capabilities of perception and localization in complex road environments. To improve the real-time performance, a hybrid lightweight approach for road scenes is designed. Experimental results on the Cityscapes and BDD100K datasets show that our approach achieves state-of-the-art results with average precision (AP) of 34.6 and 40.1, respectively. Furthermore, it operates at 34.2 frames per second (FPS) at a 1280 × 640 resolution, satisfying real-time requirements.},
  archive      = {J_NEUCOM},
  author       = {Yufei Xie and Ying Shi and Changjun Xie and Qin Hu and Yue Liu and Chaojun Lin},
  doi          = {10.1016/j.neucom.2025.131501},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131501},
  shortjournal = {Neurocomputing},
  title        = {A knowledge distillation-based object detection model focused on road scene perception and localization},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confident neural network regression with bootstrapped deep ensembles. <em>NEUCOM</em>, <em>656</em>, 131500. (<a href='https://doi.org/10.1016/j.neucom.2025.131500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise in the popularity and usage of neural networks, trustworthy uncertainty estimation is becoming increasingly essential. One of the most prominent uncertainty estimation methods is Deep Ensembles [20]. A classical parametric model has uncertainty in the parameters due to the fact that the data on which the model is built is a random sample. A modern neural network has an additional uncertainty component since the optimization of the network is random. Lakshminarayanan et al. [20] noted that Deep Ensembles do not incorporate the classical uncertainty induced by the effect of finite data. In this paper, we present a computationally cheap extension of Deep Ensembles for the regression setting, called Bootstrapped Deep Ensembles , that explicitly takes this classical effect of finite data into account using a modified version of the parametric bootstrap. We demonstrate through an experimental study that our method significantly improves upon standard Deep Ensembles. The resulting confidence intervals demonstrate superior coverage without sacrificing accuracy.},
  archive      = {J_NEUCOM},
  author       = {Laurens Sluijterman and Eric Cator and Tom Heskes},
  doi          = {10.1016/j.neucom.2025.131500},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131500},
  shortjournal = {Neurocomputing},
  title        = {Confident neural network regression with bootstrapped deep ensembles},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameter-free multi-view clustering via refined tensor learning. <em>NEUCOM</em>, <em>656</em>, 131497. (<a href='https://doi.org/10.1016/j.neucom.2025.131497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As multi-view data becomes more prevalent in real-world applications, multi-view clustering (MVC) has emerged as a powerful technique for unsupervised representation learning. To uncover the intrinsic structure, it is crucial to consider information from different spaces. Focusing solely on the sample space limits the method’s ability to effectively model multi-view data, as the informative patterns embedded in the feature space are often overlooked. Furthermore, to integrate high-order correlations, tensor-based MVC methods have been widely adopted to preserve the low rank structure of multi-view data. Traditional tensors can not achieve selective tensor rank minimization as they lack an explicit mechanism to model the retention of singular values based on their individual information contributions. Additionally, existing methods rely on hyper-parameters, undermining generalizability across different datasets. In response to these limitations, we propose a novel Parameter-free Multi-view Clustering via Refined Tensor Learning (PRTL), which is based on bidirectional regression matrices to perform data reconstruction and extract salient features. To further achieve an adaptive low-rank tensor structure, we propose a Quadratic Decay Tensor (QDT) regularization as a non-convex alternative to conventional rank minimization, which selectively retains salient information while filtering out noise dynamically, resulting in a more expressive joint representation. Meanwhile, we incorporate the hyper-Laplace graph to capture richer relationships than those modeled by conventional pairwise graphs. Notably, PRTL eliminates the need for hyper-parameters, making it more practical and robust. Experiments on diverse datasets demonstrate that PRTL consistently surpasses existing state-of-the-art clustering methods. Our code is available at https://github.com/jiaxinyang04/PRTL .},
  archive      = {J_NEUCOM},
  author       = {Jiaxin Yang and Qian Liu and Yuemeng Huang and Chunyan Yang and Wengeng Chen and Yu Lu and Jiale Wang and Wenzhe Liu and Huibing Wang},
  doi          = {10.1016/j.neucom.2025.131497},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131497},
  shortjournal = {Neurocomputing},
  title        = {Parameter-free multi-view clustering via refined tensor learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extensive multi-variant deep neural network approach to enhance genomic prediction of endometriosis. <em>NEUCOM</em>, <em>656</em>, 131496. (<a href='https://doi.org/10.1016/j.neucom.2025.131496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have shown significant advancements in modelling complex non-linear relationships in high-dimensional biomedical data. Understanding the interplay between genetic variants and disease susceptibility is still a considerable challenge that prevents certain genomic diseases to be predicted accurately for clinical interventions. In this study, we introduce the Extensive Multi-Variant Deep Neural Network (EMV-DNN), an innovative deep learning methodology designed to enhance polygenic risk prediction. Unlike conventional polygenic risk score methods, EMV-DNN incorporates single nucleotide polymorphisms (SNPs) alongside structural variants including insertions and deletions (indels), short tandem repeats (STRs), and copy number variants (CNVs) using variant-specific subnetworks to extract informative embeddings which capture a richer and holistic genomic context. Evaluated on real-world cohorts from the UK Biobank and All of Us, EMV-DNN outperforms conventional PRS methods and classic machine learning algorithms across binary and multi-class prediction tasks. Beyond predictive performance, SHapley Additive exPlanations (SHAP) analysis revealed biologically plausible variant–gene–disease associations, highlighting pathways related to endometrial cell proliferation, fibrosis, and immune regulation. Our findings underscore the value of multi-variant integration and non-linear approaches to capture the intricate genetic architecture of complex genomic diseases. Despite challenges such as dataset limitations and the complexity of diseases with multiple contributing factors, the EMV-DNN methodology presents a promising avenue for enhancing the predictive accuracy of PRS, thereby facilitating personalized healthcare interventions and advancing our understanding of genetic predispositions to disease.},
  archive      = {J_NEUCOM},
  author       = {Zelia Soo and Hua Lin and Yue Yang and Mark Grosser and Mengjia Wu and Yi Zhang and Jie Lu},
  doi          = {10.1016/j.neucom.2025.131496},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131496},
  shortjournal = {Neurocomputing},
  title        = {An extensive multi-variant deep neural network approach to enhance genomic prediction of endometriosis},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised facial expression restoration and recognition method based on improved masked auto-encoder. <em>NEUCOM</em>, <em>656</em>, 131495. (<a href='https://doi.org/10.1016/j.neucom.2025.131495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a method for reconstructing occluded facial expressions. Firstly, a self-supervised learning Masked Auto-Encoder based facial expression recognition (MAE-FER) method is introduced, which effectively reduces the computational cost and parameter count by enhancing the multi-scale local-global self-attention interaction encoder, thereby improving the training efficiency and generalization capability of the model. Secondly, to address the problem of facial expression occlusion in real-world scenarios, a MAE-based occlusion detector is designed to detect occluded parts of the face, providing effective support for subsequent reconstruction tasks. Subsequently, the Dynamic Weight Allocation Generative Adversarial Network (DWA-GAN) for facial expression occlusion recovery is proposed, which achieves precise occlusion recovery by dynamically allocating weights to reference image blocks, significantly improving the accuracy of reconstruction. Finally, feature fusion is performed on the reconstructed results and applied to the FER task to further enhance classification accuracy and stability. Utilizing the pre-trained MAE-FER model, key hidden vectors are extracted from facial expression images, containing important feature information related to expression recognition. Through this step, closely related features to expression recognition are selected while irrelevant details are discarded, optimizing the inter-class distance issue of facial expressions. Next, to address the performance degradation caused by label ambiguity, an improved Rotate Erasing Attention Consistency (REAC) method is adopted, which effectively mitigates the negative impact of label ambiguity, further improving the accuracy and stability of FER. Experimental results demonstrate that the method achieves the best performance on the RAF-DB dataset.},
  archive      = {J_NEUCOM},
  author       = {Chaolong Zhang and Yuanping Xu and Zhijie Xu and Rongqiang Gou and Weiye Wang and Jin Jin and Jian Huang},
  doi          = {10.1016/j.neucom.2025.131495},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131495},
  shortjournal = {Neurocomputing},
  title        = {A self-supervised facial expression restoration and recognition method based on improved masked auto-encoder},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TemPrompt: Multi-task prompt learning for temporal relation extraction in RAG-based crowdsourcing systems. <em>NEUCOM</em>, <em>656</em>, 131494. (<a href='https://doi.org/10.1016/j.neucom.2025.131494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal relation extraction (TRE) aims to grasp the evolution of events or actions, and thus shape the workflow of associated tasks, so it is recognized as a pivotal technology for facilitating the rational scheduling and efficient execution of crowdsourcing tasks. However, existing methods still struggle with limited and unevenly distributed annotated data. Inspired by the abundant global knowledge stored within pre-trained language models (PLMs), some studies have explored using prompts to guide PLMs in completing TRE, but their improvements are still unsatisfactory, as the model treats all the tokens equally, resulting in a limited understanding of temporal order. In this paper, we propose a multi-task prompt learning framework for TRE (TemPrompt), incorporating prompt tuning and contrastive learning to tackle these issues. In the framework, we design temporal event reasoning in the form of masked language modeling as auxiliary tasks to enable the PLM to distinguish tokens essential for temporal reasoning from those serving general contextual purposes, thereby fostering the model’s comprehension of temporal knowledge. Additionally, to elicit more effective prompts for PLMs, we introduce a task-oriented prompt construction approach that thoroughly takes the myriad factors of TRE into consideration for the automatic generation of high-quality and easy-to-interpret prompts. Contrastive learning is employed to further mitigate data issues by extracting more distinctive sample representations. Experimental results demonstrate that TemPrompt outperforms all baseline methods across most metrics and exhibits strong generalization to unseen events. Two case studies—one on designing and manufacturing printed circuit boards and the other on developing defect detection systems—are provided to validate its feasibility and effectiveness in crowdsourcing scenarios.},
  archive      = {J_NEUCOM},
  author       = {Jing Yang and Yu Zhao and Linyao Yang and Xiao Wang and Long Chen and Fei-Yue Wang},
  doi          = {10.1016/j.neucom.2025.131494},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131494},
  shortjournal = {Neurocomputing},
  title        = {TemPrompt: Multi-task prompt learning for temporal relation extraction in RAG-based crowdsourcing systems},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EHGFL: Contrastive distillation for efficient heterogeneous graph few-shot learning. <em>NEUCOM</em>, <em>656</em>, 131493. (<a href='https://doi.org/10.1016/j.neucom.2025.131493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graphs (HGs), as a general modeling paradigm for multi-typed entities and complex interactions in ubiquitous real-world networks, have attracted extensive research enthusiasm. While self-supervised learning (SSL) on heterogeneous graph neural networks (HGNNs) demonstrates promising performance, existing SSL approaches face critical limitations: (1) The inherent multiple relation types and meta-path aggregations in HGNNs create prohibitive training and inference costs that restrict scalability; (2) The local message-passing paradigm confines information propagation to immediate neighborhoods, limiting the model’s ability to capture long-range dependencies and global structural patterns essential for complex reasoning tasks; (3) Task specialization necessitates costly fine-tuning of the HGNN backbones. To address these issues, we propose Efficient Heterogeneous Graph Few-shot Learning (EHGFL) to improve HGNNs’ scalability and global-structure modeling capabilities. Specifically, EHGFL first employs instance discrimination contrastive learning for self-supervised pretraining of HGNNs. To enhance efficiency, we introduce a novel cross-model contrastive distillation mechanism that transfers HGNNs’ heterogeneous structure modeling ability to a concise, globally-structure-aware multilayer perceptron. This feature-space distillation process preserves heterogeneous structure representations while avoiding expensive neighborhood aggregation and enhancing global feature awareness. Furthermore, to bridge the gap between pretraining objectives and downstream tasks, we adopt prompt tuning techniques specifically designed for the student model, enabling effective adaptation with limited labeled data. Extensive experiments on two real-world HG datasets demonstrate that the proposed EHGFL framework substantially accelerates training and inference while achieving superior few-shot node classification accuracy compared to state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Ning Ruan and Yufei Zeng and Huan Liu and Dong Liu and Pengfei Jiao},
  doi          = {10.1016/j.neucom.2025.131493},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131493},
  shortjournal = {Neurocomputing},
  title        = {EHGFL: Contrastive distillation for efficient heterogeneous graph few-shot learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scattered data augmentation for generalization in visual reinforcement learning. <em>NEUCOM</em>, <em>656</em>, 131492. (<a href='https://doi.org/10.1016/j.neucom.2025.131492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation (DA) has shown a significant potential to enhance generalization performance in visual reinforcement learning (VRL). However, existing research on DA-based methods is predominantly empirical, and the mechanism for why DA enhances generalization remains theoretically under-explored. To bridge this gap, we derive a generalization error upper bound for VRL from the perspective of data distribution distance. Based on this bound, we provide a theoretical explanation of the mechanism by which DA improves generalization: we find that DA that satisfies certain conditions can reduce the distance between the training and test distributions, thus making the training and test samples closer. In addition, we conditionally prove that training data with higher variance can provide a higher generalization performance. Motivated by our analysis, we propose Scattered Data Augmentation (ScDA) framework. ScDA constructs a data transformation system with the agent serving as the discriminator, aiming to provide more diverse training data for agent training. Experiments are conducted across various tasks and numerous test modes in DeepMind Control Generalization Benchmark2 (DMC-GB2) and robotic tasks. Results demonstrate that our ScDA framework can be integrated with different baseline algorithms and significantly enhance policy generalization, outperforming the current state-of-the-art methods in the DMC-GB2 tests, confirming the effectiveness of the theoretical analysis in this work. The code for this work can be found at: https://github.com/scdadev/scdadev .},
  archive      = {J_NEUCOM},
  author       = {Hao Lei and Yu Zhao and Yi Xin and Zhang Shaonan and Ke Liangjun},
  doi          = {10.1016/j.neucom.2025.131492},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131492},
  shortjournal = {Neurocomputing},
  title        = {Scattered data augmentation for generalization in visual reinforcement learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monotonic convergence of adaptive caputo fractional gradient descent for temporal convolutional networks. <em>NEUCOM</em>, <em>656</em>, 131491. (<a href='https://doi.org/10.1016/j.neucom.2025.131491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fractional derivatives have gained prominence in optimization for their inherent non-locality and memory-dependent properties, effectively capturing historical dependencies. This work introduces an Adaptive Fractional-order Gradient Descent (AFGD) algorithm based on Caputo fractional derivatives, with deep integration into Temporal Convolutional Networks (TCNs). Unlike conventional fixed-order methods, AFGD employs an adaptive fractional-order mechanism to enhance optimization. Theoretically, we establish rigorous proofs for AFGD’s monotonic convergence in loss function minimization, supported by numerical simulations of its convergence behavior. Evaluated on the MIT-BIH arrhythmia five-class classification benchmark, TCNs optimized with AFGD achieve superior accuracy over established methods, demonstrating the efficacy of the proposed gradient scheme for deep learning optimization.},
  archive      = {J_NEUCOM},
  author       = {Zhiwei Xiao and Jiejie Chen and Xuewen Zhou and Bin Wei and Ping Jiang and Zhigang Zeng},
  doi          = {10.1016/j.neucom.2025.131491},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131491},
  shortjournal = {Neurocomputing},
  title        = {Monotonic convergence of adaptive caputo fractional gradient descent for temporal convolutional networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive PID-guided tensor wheel decomposition model for dynamic weighted network representation. <em>NEUCOM</em>, <em>656</em>, 131490. (<a href='https://doi.org/10.1016/j.neucom.2025.131490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Weighted Networks (DWN) usually appear in various big data-related complex systems and can describe real-time interactions between a large number of entities. As the number of entities increases dramatically, it is impossible for each entity to have complete interaction with each other, which results in such a DWN being High-Dimensional and Incomplete (HDI). Tensor Wheel Decomposition (TWD), as a novel tensor network, has powerful representation capabilities, but existing TWD-based methods require additional computational and storage costs to process an HDI DWN. To address these challenges, we propose an Adaptive integral separation PID–guided Tensor Wheel Decomposition (APTWD) model that: 1) employs a data density-oriented loss function, ensuring the representation learning is focused on the existing information in the target network to obtain more accurate low-rank embedding; and 2) develops a parameter learning scheme with error control feedback based on the integral separation PID controller to minimize the convergence iteration process. Experiments on six real-world DWN datasets demonstrate that APTWD consistently outperforms state-of-the-art methods, delivering higher representation accuracy and significantly reduced computational cost.},
  archive      = {J_NEUCOM},
  author       = {Jiqiu Chen and Qu Wang and Hao Wu},
  doi          = {10.1016/j.neucom.2025.131490},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131490},
  shortjournal = {Neurocomputing},
  title        = {An adaptive PID-guided tensor wheel decomposition model for dynamic weighted network representation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view unsupervised feature selection based on graph discrepancy learning. <em>NEUCOM</em>, <em>656</em>, 131487. (<a href='https://doi.org/10.1016/j.neucom.2025.131487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-view learning, unsupervised feature selection plays a vital role in reducing dimensionality while preserving discriminative information distributed across diverse data modalities. Despite notable progress, existing approaches frequently exhibit two key limitations: they often overlook the complementary benefits of integrating global and local structural information, and they inadequately model complex nonlinear relationships or align structural representations across views. To address these challenges, we propose a novel framework, termed Multi-view unsupervised feature selection based on graph discrepancy learning (GDFS). The proposed method jointly constructs global graph structures in a projected low-dimensional space and local graphs in a nonlinear kernel-induced space, effectively capturing both high-level semantic structures and fine-grained neighborhood dependencies. A graph discrepancy term is introduced to explicitly reduce structural discrepancies between global and local representations, thus enhancing consistency and robustness. In addition, a low-rank tensor constraint is applied to the stack of global graphs to uncover high-order correlations across views. A consensus clustering matrix is further learned to provide pseudo-label supervision, which guides the selection of discriminative features. Extensive experiments on six benchmark multi-view datasets demonstrate that GDFS consistently surpasses state-of-the-art methods in terms of clustering performance, thereby confirming its effectiveness, scalability, and generalizability. The code is available at https://github.com/xyw0111/2025-GDFS .},
  archive      = {J_NEUCOM},
  author       = {Yiwan Xu and Xijiong Xie and Xianliang Jiang and Yujie Xiong},
  doi          = {10.1016/j.neucom.2025.131487},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131487},
  shortjournal = {Neurocomputing},
  title        = {Multi-view unsupervised feature selection based on graph discrepancy learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel mixed-attribute data anomaly detection method based on granular-ball multi-kernel fuzzy rough sets. <em>NEUCOM</em>, <em>656</em>, 131486. (<a href='https://doi.org/10.1016/j.neucom.2025.131486'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rough sets have established a novel approach to anomaly detection through uncertainty handling. Nevertheless, traditional approaches are susceptible to noise. Existing kernelized methods improve feature representation via kernel transformations. However, they are typically restricted to a single-kernel framework, which limits the capacity to model the heterogeneous nature of mixed-attribute data. To address this issue, this study proposes a granular-ball generation algorithm tailored to the characteristics of mixed-attribute data. Multiple kernel functions are employed to effectively integrate the fuzzy relations of various attribute types. By integrating fuzzy rough set theory, granular-ball computing, and multi-kernel methods, a granular-ball multi-kernel fuzzy rough set model is proposed. Besides, a novel unsupervised anomaly detection method is proposed to effectively process mixed-attribute data. This method integrates kernelized fuzzy relations across various attribute types, constructs kernelized fuzzy information granules, and computes anomaly scores based on multiple granular-ball kernelized fuzzy information granules. Finally, an anomaly factor is introduced to quantify the anomaly degree of data objects. Comparative experiments were conducted on 16 public datasets. The novel approach consistently outperformed current methodologies in AUC metrics while demonstrating superior robustness across diverse data samples.},
  archive      = {J_NEUCOM},
  author       = {Cong Gao and Qiu Wang and Yanping Chen and Qingqi Pei and Zhongmin Wang},
  doi          = {10.1016/j.neucom.2025.131486},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131486},
  shortjournal = {Neurocomputing},
  title        = {A novel mixed-attribute data anomaly detection method based on granular-ball multi-kernel fuzzy rough sets},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-guided encoder-decoder network for soft sensor of copper matte grade in flash smelting process. <em>NEUCOM</em>, <em>656</em>, 131485. (<a href='https://doi.org/10.1016/j.neucom.2025.131485'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate real-time detection of copper matte grade is critical for state identification and optimization control in flash smelting, yet remains challenging due to the complex and harsh industrial environment. To address this issue, this study proposes a knowledge-guided encoder-decoder network. In this method, Bidirectional Gated Recurrent Unit serves as the backbone architecture for both the encoding and decoding processes, enabling nonlinear dynamic modeling in the temporal domain. The encoder integrates a composite variable attention mechanism, which leverages process knowledge to prioritize key variables based on their importance. A temporal decay attention mechanism is added to the decoder, endowing the model with the ability to simulate the temporal dependency between copper matte grade and process variables through prior knowledge. These knowledge-guided designs strengthen the ability of model to capture process-specific relationships between input variables and copper matte grade. Industrial experiments based on real production data from a smelting plant in China, show that the proposed model achieves optimal performance, with 96 % absolute errors not exceeding 0.5 %. It demonstrates that the proposed model not only provides accurate and real-time copper matte grade estimation but also maintains robustness in industrial environments, verifying its potential for practical application in flash smelting process.},
  archive      = {J_NEUCOM},
  author       = {Zhou Zou and Can Zhou and Chunhua Yang},
  doi          = {10.1016/j.neucom.2025.131485},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131485},
  shortjournal = {Neurocomputing},
  title        = {Knowledge-guided encoder-decoder network for soft sensor of copper matte grade in flash smelting process},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-resolution QP-adaptive generative face video compression using multi-level generator. <em>NEUCOM</em>, <em>656</em>, 131484. (<a href='https://doi.org/10.1016/j.neucom.2025.131484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a multi-resolution quantization parameter (QP)-adaptive generative face video compression (GFVC) framework to realize face video communication at an ultra-low bitrate. By leveraging deep generative models and semantic feature representation, the proposed framework achieves high perceptual quality while significantly reducing bitrate. The proposed framework dynamically adjusts feature granularity based on QP values and integrates modules such as multi-level multi-DConv head transposed attention (MDTA) and multi-level spatially adaptive denormalization (SPADE) to enhance both spatial fidelity and temporal consistency. To ensure adaptability and standardization, we further extend the proposed framework to support multi-resolution inputs and incorporate feature encoding based on Supplemental Enhancement Information (SEI) in VVC. Specifically, we introduce the flag gfv_enhancement_matrix_flag to transmit an optional 8 × 8 enhancement matrix, enabling precise refinement of inter-frame reconstruction in compliance with VVC. A multi-reference frame buffer mechanism is also implemented to improve long-term temporal coherence through attention-guided reference selection. Experimental results demonstrate that the proposed GFVC framework achieves average BD-rate gains of 63.87 % in DISTS and 61.99 % in LPIPS on benchmark datasets compared to the VVC anchor (VTM-22.2 LDB mode). Without retraining, the proposed framework operates smoothly even on face videos with a resolution of 512 × 512 , achieving 23.40 % BD-rate gain in DISTS and indicating strong scalability. These results validate the practical feasibility of the proposed GFVC framework in real-world video conferencing and telepresence scenarios, especially under ultra-low bandwidth conditions.},
  archive      = {J_NEUCOM},
  author       = {Wenbo Kang and Lu Liu and Cheolkon Jung},
  doi          = {10.1016/j.neucom.2025.131484},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131484},
  shortjournal = {Neurocomputing},
  title        = {Multi-resolution QP-adaptive generative face video compression using multi-level generator},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ST-CML: A contrastive meta learning framework for spatio-temporal graph few-shot learning with cross-city transfer. <em>NEUCOM</em>, <em>656</em>, 131483. (<a href='https://doi.org/10.1016/j.neucom.2025.131483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph learning is a critical methodology for addressing smart city computational tasks, including traffic speed prediction, vehicle trajectory analysis, and air quality forecasting. However, the scarcity of available data in many cities poses a significant constraint due to the challenges and costs associated with large-scale data collection. To overcome this limitation, leveraging data from cities with abundant data resources and enhancing model performance through knowledge transfer techniques is essential. In this study, we propose ST-CML. Our approach utilizes data from multiple source cities to train a meta-learner, which generates parameters for downstream spatio-temporal models. The meta-learner is then fine-tuned to adapt to target cities with limited data. We introduce a graph contrastive loss to improve the learning of spatio-temporal structures during meta-learning. This loss function guides the model in mitigating spatio-temporal feature deviations across cities during knowledge transfer. Experimental evaluations on real-world traffic datasets demonstrate that our framework surpasses existing methods and achieves significant effectiveness in cross-city few-shot learning scenarios.},
  archive      = {J_NEUCOM},
  author       = {Haichen Lyu and Chun Wang},
  doi          = {10.1016/j.neucom.2025.131483},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131483},
  shortjournal = {Neurocomputing},
  title        = {ST-CML: A contrastive meta learning framework for spatio-temporal graph few-shot learning with cross-city transfer},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Filter bank convolutional network with dual channel attention for multi-class fine joint motor imagery decoding. <em>NEUCOM</em>, <em>656</em>, 131480. (<a href='https://doi.org/10.1016/j.neucom.2025.131480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective Motor imagery brain-computer interface (MI-BCI) is a representative BCI system. Recent studies in MI-BCI focus on Fine Joint MI (FJMI) decoding that recognizes the motor intention of different joints from one upper limb. However, due to the low spatial difference between EEG patterns of FJMI, achieving optimal performance remains a challenge of multi-class FJMI decoding studies. Methods: We proposed a novel approach named Filter Bank Convolutional Network with Dual Channel Attention (FB-DCANet) that enables feature extraction and selection in MI-EEG across multi-class FJMI tasks. This network features a combined filter bank in frequency and time domain that simultaneously extracts spatio-temporal information from four frequency bands (alpha, beta, theta, and low gamma), accompanied with temporal convolutional modules for additional temporal information extraction. Moreover, a feature selection method based on Dual Channel Attention was proposed combining preliminary intra-band feature selection via Residual Channel Self-Attention (RCSA) and further inter-band feature selection from different frequency bands by Efficient Channel Attention (ECA). Results: We performed experiments using FJMI-EEG data from the unilateral upper limb, and FB-DCANet achieved an accuracy of 59.34 % in a 4-class classification scenario (hand MI, elbow MI, shoulder MI, and resting state), and interpretability of FB-DCANet was analyzed by visualization of Class Activation Map (CAM) and attention values. Conclusion and Significance: This work presents a novel approach with a time-frequency filter bank and Dual Channel Attention-based feature selection for multi-class FJMI decoding, which can be utilized to develop a rehabilitation system based on FJMI-BCI.},
  archive      = {J_NEUCOM},
  author       = {Jiaming Chen and Yueqi Zhang and Kaide Liu and Xinkang Hu and Meng Xu and Dan Wang and Weibo Yi},
  doi          = {10.1016/j.neucom.2025.131480},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131480},
  shortjournal = {Neurocomputing},
  title        = {Filter bank convolutional network with dual channel attention for multi-class fine joint motor imagery decoding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Output-feedback synchronization of semi-markov jump two-time-scale neural networks: Dual event-triggered scheme. <em>NEUCOM</em>, <em>656</em>, 131479. (<a href='https://doi.org/10.1016/j.neucom.2025.131479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of synchronization control for semi-Markov jump two-time-scale neural networks, in which the output-feedback mechanism is adopted and a dual event-triggered scheme is employed using a double-rate sampling method to balance system performance and communication efficiency. First, considering the two-time-scale property of the semi-Markov jump neural networks, the dual-rate sampling strategy is adopted such that two independent event-triggered conditions for different time scales can be designed, which ensure efficient resource utilization while maintaining system performance. Then, a Lyapunov–Krasovskii functional with the singular perturbation parameter is constructed to deduce sufficient conditions ensuring that the synchronization error system is stochastically stable and satisfies a given H ∞ performance index. Moreover, the solution for obtaining the controller gains is presented to guarantee synchronization of the considered system under a dual event-triggered scheme. Finally, the feasibility of the methods is demonstrated by two examples, including a numerical example and an image encryption. They show that this event-triggered mechanism provides an efficient new synchronization control scheme for semi-Markov jump two-time-scale neural network systems while reducing the network burden.},
  archive      = {J_NEUCOM},
  author       = {Wenyan Zuo and Ya-Nan Wang and Feng Li and Sangmoon Lee},
  doi          = {10.1016/j.neucom.2025.131479},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131479},
  shortjournal = {Neurocomputing},
  title        = {Output-feedback synchronization of semi-markov jump two-time-scale neural networks: Dual event-triggered scheme},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient multi-view graph condensation via gradient-flow induced graph convolutional networks. <em>NEUCOM</em>, <em>656</em>, 131478. (<a href='https://doi.org/10.1016/j.neucom.2025.131478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning based on graph convolutional networks boosts performance by incorporating diverse perspectives, leading to significant achievements and successful applications across various academic and practical fields. However, multi-view graph convolutional networks suffer from substantial computational challenges on large-scale graphs. To address this limitation, graph condensation has emerged as a promising direction by creating a smaller composite graph that allows for efficient network training while preserving performance. Furthermore, previous studies have demonstrated that encouraging performance in graph learning is achieved via graph compression. To this end, we attempt to introduce graph condensation into the multi-view learning for computation acceleration. This approach not only reduces training costs significantly but also achieves sub-linear time complexity and memory consumption during network training. Further, we propose a gradient flow induced graph convolutional network from partial differential equations, which offers theoretical guarantees and potential new insights for the graph-related network architecture construction with transparent model interpretability. Extensive experiments on seven real-world multi-view datasets demonstrate that the proposed method sharply decreases model training time while ensuring competitive multi-view semi-supervised classification.},
  archive      = {J_NEUCOM},
  author       = {Lu Liu and Yang Huang and Yueyang Pi and Zhicheng Wei and Jinbo Li and Shiping Wang},
  doi          = {10.1016/j.neucom.2025.131478},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131478},
  shortjournal = {Neurocomputing},
  title        = {Efficient multi-view graph condensation via gradient-flow induced graph convolutional networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal event-triggered control for multi-agent systems with hierarchical framework. <em>NEUCOM</em>, <em>656</em>, 131477. (<a href='https://doi.org/10.1016/j.neucom.2025.131477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the event-triggered optimal control problem for a class of linear second-order multi-agent systems (MASs) with external disturbances. A hierarchical framework is proposed to address the challenges that arise from the information of the coupled neighbors and external disturbances, integrating the communication, learning, and control layers. Specifically, the communication layer utilizes event-triggered mechanisms (ETMs) to transmit neighbor information, facilitating virtual consensus. The learning layer connects the communication and control layers, employing reinforcement learning (RL) to optimize tracking control with ETMs. The control layer achieves real consensus by aligning the agent states with the processed information from the communication layer. Moreover, this framework effectively mitigates the effects of coupled neighbor information on the controller and suppresses the transmission of external disturbances through the communication network. Finally, two simulation examples are used to verify the anti-interference of the hierarchical framework i.e., it’s still possible to achieve consensus after being disturbed and the effectiveness of considering the reinforcement learning layer via event-triggered mechanism which reduces the communication and learning burden to achieve optimal control.},
  archive      = {J_NEUCOM},
  author       = {Denghao Pang and Yechen Guo and Jinde Cao and Boxiang Li and Xiao-Wen Zhao},
  doi          = {10.1016/j.neucom.2025.131477},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131477},
  shortjournal = {Neurocomputing},
  title        = {Optimal event-triggered control for multi-agent systems with hierarchical framework},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal bayesian regression with a non-informative prior: Order-recursive and incremental learning. <em>NEUCOM</em>, <em>656</em>, 131476. (<a href='https://doi.org/10.1016/j.neucom.2025.131476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal Bayesian regression (OBR) for data generated from a multidimensional vector autoregressive process of order p , denoted as VAR ( p ) , has a closed-form analytic expression that has been previously obtained. Despite the closed-form expressions to compute the “OBR-VAR”, in certain practical scenarios the computational cost involved in training OBR-VAR is a bottleneck. From a computational perspective, two common scenarios that incur excessive computational cost are: 1) given a set of training data, estimating the unknown model order p generally entails computing the OBR-VAR from scratch for every p in a range from 1 to a maximum value; and 2) in dynamic environments where data arrives sequentially, currently one must recompute OBR-VAR from scratch for every new upcoming observation. To address the first issue, in this paper, an order-recursive OBR-VAR regressor using QR decomposition is proposed. This method efficiently updates the regressor without recalculating it from scratch for each p , significantly reducing computational complexity while preserving model accuracy. Analytical results demonstrate that the proposed order-recursive method achieves a computational complexity reduction by a factor proportional to p , making it scalable to larger datasets and higher model orders. To address the second issue, an incremental version of the OBR-VAR algorithm is developed for real-time data processing. This method updates the regressor incrementally as new data points arrive, maintaining accuracy without the need for costly recomputation of key matrices. Its capability makes it well-suited for continuous-time data acquisition and streaming applications, where timely and accurate responses are critical. In all cases we assume an improper non-informative prior to model the case of having no prior knowledge about the problem. Theoretical analysis and empirical evaluations using synthetic and real datasets demonstrate that both methods significantly outperform the standard OBR-VAR algorithm in terms of computational complexity while preserving accuracy.},
  archive      = {J_NEUCOM},
  author       = {Samira Reihanian and Amin Zollanvari and Siamac Fazli},
  doi          = {10.1016/j.neucom.2025.131476},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131476},
  shortjournal = {Neurocomputing},
  title        = {Optimal bayesian regression with a non-informative prior: Order-recursive and incremental learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-stream GCN-based action recognition framework using trustworthy fusion decision from different skeleton descriptors. <em>NEUCOM</em>, <em>656</em>, 131475. (<a href='https://doi.org/10.1016/j.neucom.2025.131475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex motion processes, different human skeleton descriptors can characterize skeletal features across various dimensions. The frequency of spatiotemporal changes in different joints is largely influenced by the type of action. This paper presents a dual-stream GCN-based action recognition framework, which involves Slow-stream and Fast-stream networks to process skeletal features of different spatiotemporal change characteristics. In the parallel processing architecture of graph convolutional layers, adaptive adjacency matrices that strengthen spatial and temporal feature extraction are proposed to learn the implicit relationships between skeletal joints. Furthermore, different skeletal features have significantly varying impacts on the accuracy of action recognition. The Dirichlet distribution and an optimized Dempster combination rule are introduced for trustworthy decision when fusing multi-branch opinions obtained from different skeleton descriptors. Extensive experiments on three authoritative datasets demonstrate that the proposed method achieves state-of-the-art performance while reducing uncertainty in action recognition.},
  archive      = {J_NEUCOM},
  author       = {Wenrui Zhu and Donghui Shi and Junqi Yu},
  doi          = {10.1016/j.neucom.2025.131475},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131475},
  shortjournal = {Neurocomputing},
  title        = {A dual-stream GCN-based action recognition framework using trustworthy fusion decision from different skeleton descriptors},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bipartite tracking consensus for fractional-order nonlinear multiagent systems with sampled-data and input saturation. <em>NEUCOM</em>, <em>656</em>, 131472. (<a href='https://doi.org/10.1016/j.neucom.2025.131472'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on the sampled-data bipartite tracking consensus (BTC) issue for a type of fractional-order (FO) nonlinear multiagent systems (FOMASs) subject to input saturation. In the network under consideration, agents exhibit both competitive (CM) and cooperative (CO) interactions simultaneously. By employing Lyapunov stability theory, the FO Halanay-type Inequality , and the linear matrix inequality (LMI) approach, several criteria are derived to guarantee that the considered MASs can attain the BTC. Moreover, by utilizing the matrix decomposition (MD) approach, the dimensions of matrix inequalities are significantly reduced, which helps alleviate computational complexity. As a result, the derived results can be effectively applied to large-scale FOMASs. Also, the controller gain matrix is clearly represented based on the solutions of a series of matrix inequalities. Besides, we present a method for estimating the maximum attraction region of BTC. Ultimately, numerical simulation is employed to substantiate our theoretical analysis.},
  archive      = {J_NEUCOM},
  author       = {Zhi Qiao and Luyang Yu and Yuman Li and Yurong Liu},
  doi          = {10.1016/j.neucom.2025.131472},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131472},
  shortjournal = {Neurocomputing},
  title        = {Bipartite tracking consensus for fractional-order nonlinear multiagent systems with sampled-data and input saturation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous federated semantic segmentation. <em>NEUCOM</em>, <em>656</em>, 131470. (<a href='https://doi.org/10.1016/j.neucom.2025.131470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) offers a promising solution for semantic segmentation in scenarios involving data distribution across isolated clients. Despite recent advances, federated semantic segmentation (FSS) continues to face key challenges. One major issue is the shift from centralized to decentralized training, where diverse and limited local data hinder consistent pixel-level representation learning. Another challenge is data heterogeneity from imbalanced class distributions across clients, which weakens feature consistency and degrades global performance. These limitations often lead to inconsistent feature learning and degraded global performance. To address the challenges of class heterogeneity and insufficient pixel-level representation learning in FSS, we propose a novel pixel-aware FSS framework that improves local adaptation and semantic consistency. Specifically, we design a fine-tuning strategy that initializes each client with a lightweight pre-trained model and performs local updates over multiple epochs. This improves model adaptability to local distributions while reducing communication overhead. To further enhance semantic consistency across heterogeneous clients, we introduce a client clustering strategy based on pixel-level semantic features. Clients with similar class distributions are grouped to encourage consistent feature learning within clusters. Cluster-level training and aggregation are then followed by a global aggregation step, promoting more robust and aligned semantic understanding. Empirical evaluation across multiple benchmark datasets confirms that our method achieves consistently high segmentation precision and enhanced model adaptability in highly heterogeneous federated scenarios.},
  archive      = {J_NEUCOM},
  author       = {Chen Zhang and Jiarui Wang and Yu Xie and Xinlei Wang and Bin Yu},
  doi          = {10.1016/j.neucom.2025.131470},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131470},
  shortjournal = {Neurocomputing},
  title        = {Heterogeneous federated semantic segmentation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized containment control for delayed fractional-order nonlinear multi-agent systems with unknown disturbances. <em>NEUCOM</em>, <em>656</em>, 131469. (<a href='https://doi.org/10.1016/j.neucom.2025.131469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the issue of generalized containment control is explored for a class of delayed fractional-order nonlinear multi-agent systems (MASs) with unknown disturbances. It is assumed that the MAS under consideration has multiple dynamic leaders, and its dynamics are governed by fractional-order differential equations, and suffers from the unknown but norm-bounded external disturbances. Also, the directed graph of the MAS is assumed to have a united directed spanning tree. Furthermore, for the sake of saving communication resources, an event-triggered mechanism is introduced to regulate the signal transmission. In the presence of the external disturbances, the generalized containment control is analyzed by means of Lyapunov stability theory, algebraic graph theory, Halanay-type inequality, etc., and sufficient conditions are established to ensure that all followers ultimately enter a certain neighborhood of the convex hull formed by the leaders. In the meanwhile, it is also proven that the Zeno phenomenon can be excluded for the concerned MAS. Finally, a numerical simulation is presented to further illustrate the effectiveness of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Zhi Qiao and Luyang Yu and Hong Lin and Yurong Liu},
  doi          = {10.1016/j.neucom.2025.131469},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131469},
  shortjournal = {Neurocomputing},
  title        = {Generalized containment control for delayed fractional-order nonlinear multi-agent systems with unknown disturbances},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CBH-YOLO: A steel surface defect detection algorithm based on cross-stage mamba enhancement and hierarchical semantic graph fusion. <em>NEUCOM</em>, <em>656</em>, 131467. (<a href='https://doi.org/10.1016/j.neucom.2025.131467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of surface defects in steel materials plays a pivotal role in ensuring industrial production quality and operational safety. However, existing deep learning-based detection methods face significant challenges in steel surface defect detection, including limited receptive field coverage, inadequate multi-scale feature integration, and insufficient feature discrimination under complex backgrounds. To address these limitations, this work introduces CBH-YOLO, a novel steel surface defect detection algorithm. The proposed framework incorporates three fundamental innovation modules: (1) Cross-stage Mamba-Enhanced Multi-scale Convolution (CMMC) module, which synergistically combines the advantages of state space models with large kernel convolutions alongside adaptive attention mechanisms, substantially expanding receptive field coverage while enhancing multi-scale feature extraction capabilities; (2) Binary Amplification Matrix (BAM) module, which innovatively integrates FlexWave (FXW) dynamic activation functions with OmniScale (OSC) multi-scale perception mechanisms to achieve adaptive nonlinear feature mapping and refined representation; (3) Hierarchical Semantic Graph Fusion Network (HSGFN), which models high-order correlations among features through hypergraph structures combined with adaptive feature fusion mechanisms, enabling more effective multi-scale feature integration. Comprehensive experimental validation on NEU-DET and GC10-DET benchmark datasets demonstrates that CBH-YOLO achieves improvements of 2.7 % and 3.2 % in mAP@50 metrics compared to the baseline YOLOv11 model, while maintaining exceptional computational efficiency. This research provides a high-precision, high-efficiency solution for steel surface defect detection, offering significant theoretical value and practical application prospects.},
  archive      = {J_NEUCOM},
  author       = {Bo Gao and Jingcheng Tong and RongRong Fu and ZhenZhen Zhang and YiLin Yuan},
  doi          = {10.1016/j.neucom.2025.131467},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131467},
  shortjournal = {Neurocomputing},
  title        = {CBH-YOLO: A steel surface defect detection algorithm based on cross-stage mamba enhancement and hierarchical semantic graph fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMNet: Incomplete multi-modal alzheimer’s disease diagnosis with dual memory network. <em>NEUCOM</em>, <em>656</em>, 131465. (<a href='https://doi.org/10.1016/j.neucom.2025.131465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the challenge of missing modality, existing multi-modal learning methods become impractical and missing modality is a serious impediment to a good multi-modal learning performance. Meanwhile, we note that the existing methods for addressing missing modality issue tend to explore complete information by using either cross-generative approaches via simply filling in missing modality data, and do not consider the specific information, resulting in a sub-optimal performance for Alzheimer’s Disease diagnosis with multi-modal data. To address this problem, we propose a novel Dual Memory Network (DMNet) that comprises the Tabular Alignment Memory bank (TAM) and Dynamic Re-optimizing Memory bank (DRM) to complement the missing modality information in multi-modal learning for Alzheimer’s disease diagnosis. More specifically, TAM stores the information aligned with clinical tabular data, and maintains the feature distribution alignment between clinical tabular data and imaging modalities. Besides, TAM is updated by a memory aligning strategy. Then, DRM stores modality specific information from complete modalities, and we design a memory optimizing strategy that incorporates Feature Consistency (FC) loss and Memory Correspondence (MC) loss to update the memory items in DRM to effectively represent specific information of modalities. This novel dual memory network enhances model performance and improves model usability in multi-modal learning with missing modality, providing a more informative feature distribution to complement the missing modality. Extensive experiments, including quantitative and qualitative analyses, as well as various ablation studies, demonstrate that our proposed method achieves state-of-the-art performance in the classification task on the ADNI dataset.},
  archive      = {J_NEUCOM},
  author       = {Nana Jia and Zhiao Zhang and Tong Jia},
  doi          = {10.1016/j.neucom.2025.131465},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131465},
  shortjournal = {Neurocomputing},
  title        = {DMNet: Incomplete multi-modal alzheimer’s disease diagnosis with dual memory network},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WDWorm: A runtime-efficient and user-friendly GUI-based toolbox for experimenting with the nerve net of c. elegans. <em>NEUCOM</em>, <em>656</em>, 131464. (<a href='https://doi.org/10.1016/j.neucom.2025.131464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nerve net simulators of C. elegans heavily support research on its nerve net functionality by offering the possibility to conduct digital experiments instead of real ones. However, current software tools are complex and difficult to use for non-programmers. With WDWorm, we offer a user-friendly toolbox with graphical user interface for simulating and experimenting with C. elegans’ nerve net. It does not require an installation and allows for several modifications of the nerve net, including parameter changes for each neuron and connection or the deactivation of individual neurons. Furthermore, a comparison with other software tools highlights that WDWorm is currently the most runtime-efficient approach for simulating and digitally experimenting with C. elegans . To invite other developers and researchers, we provide the source code in an open-access format under a CC-BY 4.0 Creative Commons license. The code is publicly available at https://github.com/dsacri/WDWorm .},
  archive      = {J_NEUCOM},
  author       = {Sebastian Jenderny and Daniel Sacristán and Philipp Hövel and Christian Albers and Isabella Beyer and Karlheinz Ochs},
  doi          = {10.1016/j.neucom.2025.131464},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131464},
  shortjournal = {Neurocomputing},
  title        = {WDWorm: A runtime-efficient and user-friendly GUI-based toolbox for experimenting with the nerve net of c. elegans},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Curriculum learning-based slimmable cross-component prediction for video coding. <em>NEUCOM</em>, <em>656</em>, 131463. (<a href='https://doi.org/10.1016/j.neucom.2025.131463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-component prediction plays an important role in video coding, which aims to eliminate redundancy between color components under the guidance of luma information. Recently, learning-based cross-component prediction has made significant strides in performance. However, current cross-component prediction methods typically train models directly on a dataset with different types of data, which generally results in overfitting for the flat textured data and underfitting for the complex textured data. To improve coding performance without excessively increasing the complexity, a cost-effective attention-based slimmable cross-component prediction network (SCCPN) is proposed. Although trained as a single model, SCCPN is capable of being executed at different levels of capacity, resulting in varying prediction results tailored to data with different characteristics. With the goal of further improving the generalization capability and prediction accuracy of the network, a curriculum learning strategy combined with slimmable convolutions is then designed, which employs the classification of prediction difficulty to represent whether the texture is flat or complex, and fits complex data with a small number of additional parameters. An adaptive search strategy is also introduced to speed up the selection of channels for slimmable convolutions. Experimental results demonstrate that when integrated into H.266/Versatile Video Coding (VVC), SCCPN achieves up to −0.62 %/−3.34 %/−2.68 % BD-rate reductions on Y/Cb/Cr components, respectively, over the H.266/VVC anchor. The performance gain outperforms the state-of-the-art learning-based cross-component prediction methods, while the increased complexity in both encoding and decoding is lower than the other compared cross-component prediction methods using neural networks. Moreover, performance gain can also be observed when SCCPN is integrated into the latest reference software of Beyond VVC, with BD-rate reductions of −0.17 %/−1.00 %/−1.02 % on Y/Cb/Cr components respectively.},
  archive      = {J_NEUCOM},
  author       = {Chengyi Zou and Shuai Wan and Marc Gorriz Blanch and Luka Murn and Juil Sock and Fei Yang and Luis Herranz},
  doi          = {10.1016/j.neucom.2025.131463},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131463},
  shortjournal = {Neurocomputing},
  title        = {Curriculum learning-based slimmable cross-component prediction for video coding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Representative negative sampling for graph positive-unlabeled learning. <em>NEUCOM</em>, <em>656</em>, 131462. (<a href='https://doi.org/10.1016/j.neucom.2025.131462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph positive-unlabeled (GPU) learning is an important task that aims to develop binary classifiers using only positive and unlabeled nodes, which are commonly encountered in real-life applications. Although selecting reliable negative samples is a highly promising approach, it typically only selects high-confidence examples, which lack representativeness and fail to fully capture the diversity of the negative example space. To address this gap, our key insight, inspired by galactic dynamics, is to model the positive prototype center as a continuously evolving gravitational center maintained via a momentum moving average, just like the stars in the universe are always moving forward rather than remaining still. This dynamic anchor allows us to robustly define a reliable negative region—its “gravitational field”—for sampling representative “planets” (negative examples). We propose StarHunter-PU (SH-PU), a framework that operationalizes this insight by unifying graph representation learning with our dynamic, prototype-guided representative sampling algorithm. This ensures the sampled negatives are both diverse and informative, providing accurate information for training a robust binary classification model. Experimental results on real-world datasets show that our StarHunter-PU method significantly outperforms existing methods and even achieves competitive performance compared to fully labeled methods.},
  archive      = {J_NEUCOM},
  author       = {Luyue Wang and Xinyuan Feng and Rui Mao and Yin Li and Chunquan Liang},
  doi          = {10.1016/j.neucom.2025.131462},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131462},
  shortjournal = {Neurocomputing},
  title        = {Representative negative sampling for graph positive-unlabeled learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance and interpretability analysis of code generation large language models. <em>NEUCOM</em>, <em>656</em>, 131461. (<a href='https://doi.org/10.1016/j.neucom.2025.131461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Large Language Models (LLMs) are increasingly getting integrated into software development workflows, understanding their reliability, error patterns and interpretability in real-world development scenarios is crucial for establishing their practical utility. This study evaluates and interprets the performance of 15 open-source LLM models, including Code LLaMa, Granite Code, DeepSeek-Coder-V2, and Yi-Coder on code translation and generation from requirements using the Rosetta Code dataset across diverse programming languages and tasks. Syntactic correctness and code quality are quantified using metrics such as CodeBLEU, chrF, and METEOR. Interpretability is explored through Feature Ablation and Shapley Value Sampling to elucidate prompt processing mechanisms. Results indicate high syntactic correctness and quality scores for models such as DeepSeek-Coder-V2 and Yi-Coder, alongside observed sensitivities to specific prompt components. This research provides quantitative and qualitative insights into the capabilities and limitations of open-source code-generating LLMs, informing model selection and the understanding of LLM-generated code.},
  archive      = {J_NEUCOM},
  author       = {Vishnu S. Pendyala and Neha B. Thakur},
  doi          = {10.1016/j.neucom.2025.131461},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131461},
  shortjournal = {Neurocomputing},
  title        = {Performance and interpretability analysis of code generation large language models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing long-term memory in federated class continual learning with lightweight adapters. <em>NEUCOM</em>, <em>656</em>, 131459. (<a href='https://doi.org/10.1016/j.neucom.2025.131459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) collaboratively trains a global model by aggregating local model parameters rather than raw data. Traditional FL frameworks assume that data classes are predefined and static. However, clients often encounter continuous data streams with dynamically emerging classes in practical applications, leading to a phenomenon known as catastrophic forgetting. Federated Class-Continual Learning (FCCL) has been introduced to address this challenge but still suffers from significant performance deterioration in scenarios with expanding task scales, particularly for tasks learned in the distant past. We propose a novel FCCL framework leveraging lightweight adapters to mitigate catastrophic forgetting as the number of tasks scales. To tackle the challenge of long-term memory decline, we developed task-specific adapters for clients to enhance memory retention. Additionally, we developed an image generation method tailored for lightweight adapters and trained task discriminators using the generated images. This enables the automatic loading of lightweight modules during inference, reducing human intervention. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet achieve significant performance improvements ranging from 1.73 to 4.07 times compared to baseline methods, effectively mitigating catastrophic forgetting in class-scaling scenarios. The complete implementation is available at https://github.com/notaerfa/FCLORA .},
  archive      = {J_NEUCOM},
  author       = {Pan Wang and Ji Wang and Zhengyi Zhong and Weidong Bao and Yaohong Zhang and Jianguo Chen},
  doi          = {10.1016/j.neucom.2025.131459},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131459},
  shortjournal = {Neurocomputing},
  title        = {Enhancing long-term memory in federated class continual learning with lightweight adapters},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive granular-ball based density peak clustering. <em>NEUCOM</em>, <em>656</em>, 131458. (<a href='https://doi.org/10.1016/j.neucom.2025.131458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of data processing, the Granular-ball (GB) provides a coarse-grained data representation, offering a novel approach to improving clustering efficiency. The Fast Density Peak Clustering Algorithm based on Granular-balls (GB-DP) reduces computational granularity, which not only decreases operation time in large-scale data processing but also produces good clustering results. However, the GB-DP algorithm faces two main issues: sensitivity to the threshold parameter for generating GB and the requirement for manually selecting clustering centers, both of which affect the algorithm's efficiency and stability. To address these challenges, this paper proposes an Adaptive Granular-ball based Density Peak Clustering Algorithm (AGB-DP). First, a weighted Distribution Measure (DM) is used to dynamically generate GB. In contrast to the fixed threshold strategy used in GB-DP, this method effectively captures the data's distribution characteristics, mitigating the problem of parameter sensitivity. Second, by integrating two factors—data volume and geometric compactness—the density of GB is redefined, enhancing the accuracy of density calculations. Finally, an automatic screening strategy is employed to select GB as clustering centers, eliminating the instability introduced by manual intervention. Experimental results on both synthetic and real-world datasets demonstrate that AGB-DP, requiring only the number of clusters to be specified, achieves superior clustering results on most datasets compared to classical clustering algorithms and recent DP-based methods and shows greater robustness and stability.},
  archive      = {J_NEUCOM},
  author       = {Xingguo Zhang and Li Xu and Weikuan Jia},
  doi          = {10.1016/j.neucom.2025.131458},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131458},
  shortjournal = {Neurocomputing},
  title        = {Adaptive granular-ball based density peak clustering},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting the connections between images and deep feature vectors in model inversion attacks. <em>NEUCOM</em>, <em>656</em>, 131457. (<a href='https://doi.org/10.1016/j.neucom.2025.131457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model inversion attack aims to reconstruct private samples from given deep neural networks. As the connections between the images and their corresponding deep feature vectors are unknown, it is difficult to utilize the information in the feature vectors during inversion. In this paper, connections between the images and their deep convolutional feature vectors are investigated. The directions of the vectors are used to represent the structures of both image vectors and feature vectors. Cosine similarity is further used to measure the structural similarity between different vectors. For a given target feature extractor, we find that the structures of the images and their feature vectors are highly correlated. Using this-property, Aug-MIA is proposed to perform model inversion with a few leaked feature vectors. In Aug-MIA, the feature vectors are first augmented by the proposed Structure Augmentation Algorithm. Then, a reconstruction model is trained using these augmented feature vectors to reconstruct images. Various experiments are performed on different datasets to validate our ideas. The results show that Aug-MIA performs better when fewer feature vectors are available. Specifically, when only 1 feature vector per class is leaked, it can improve the reconstruction rate by about 10.7 % on FaceScrub and about 4.2 % on MNIST, respectively.},
  archive      = {J_NEUCOM},
  author       = {Zeping Zhang and Jie Huang},
  doi          = {10.1016/j.neucom.2025.131457},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131457},
  shortjournal = {Neurocomputing},
  title        = {Exploiting the connections between images and deep feature vectors in model inversion attacks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent-space diffusion models for stealthy and transferable adversarial attacks on object detection. <em>NEUCOM</em>, <em>656</em>, 131456. (<a href='https://doi.org/10.1016/j.neucom.2025.131456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tons of prior works have leveraged Generative Adversarial Networks (GANs) to synthesize adversarial examples that exhibit visual fidelity. Nonetheless, the intricacy of GANs’ latent space complicates the generation of imperceptible adversarial noises, rendering the process difficult to control. The emergence of diffusion models, which iteratively refine images through a progressive denoising mechanism, offers a more tractable and interpretable solution for a controllable generation. Inspired by this, we propose a latent-space-based covert adversarial attack framework (LSDM) grounded in diffusion models to craft adversarial examples that are both visually natural and highly effective against object detection models. Central to our approach is the Latent Space Perceptual Consistency Constraint, which ensures visual-consistency by embedding perturbations into the latent space for each denoising step, while utilizing the original image as a condition guider during the de-noising pass. Moreover, to balance attack performance and the risk of overfitting, we also propose a Stepwise Prediction and Adaptive Optimization strategy, which dynamically modulates the perturbations at the current time step and determines optimal number of diffusion time steps based on the transferability of the attack against diverse black-box models. To further enhance the framework’s attacking transferability, we introduce a novel Multi-box Translation Attack strategy, which augments the spatial location diversities for each bounding box. Extensive experiments demonstrate that, compared with state-of-the-art methods, LSDM further reduces the average black-box detection mAP by 1.52 %, while improving image quality scores by 1.71 % on object detection datasets such as COCO and VOC, showcasing superior attack effectiveness and visual fidelity. The source code is publicly available at https://github.com/LSDM .},
  archive      = {J_NEUCOM},
  author       = {Wenxuan Wang and Huihui Qi and Zhixiang Huang and Bangjie Yin and Peng Wang},
  doi          = {10.1016/j.neucom.2025.131456},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131456},
  shortjournal = {Neurocomputing},
  title        = {Latent-space diffusion models for stealthy and transferable adversarial attacks on object detection},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User intent disentanglement for multi-behavior recommendation via information bottleneck principle. <em>NEUCOM</em>, <em>656</em>, 131454. (<a href='https://doi.org/10.1016/j.neucom.2025.131454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-behavior recommendation systems have advanced rapidly by leveraging users’ diverse auxiliary behavior interactions to improve recommendations for the target behavior (a.k.a. purchase). While existing methods have made strides by integrating auxiliary behaviors with purchase histories to deliver high-quality recommendations, they often fail to identify spurious correlation intents within auxiliary behaviors that conflict with users’ target intents. Indiscriminately incorporating such correlations into the prediction of target intents may lead to performance degradation. To address this issue, we propose a Multi-Behavior Intent Disentanglement framework (MBID) for multi-behavior recommendation, which focuses on disentangling spurious correlation intents via the Information Bottleneck (IB) principle. In particular, we first design a time-sensitive spurious correlation coefficient to quantify spurious correlation intents and guide the subsequent multi-intent learning. Then, to disentangle spurious correlation intents, we propose a projection-based intent extraction method to decompose the genuine and spurious correlation intents within auxiliary behaviors. Based on this, we conceive an IB-based multi-intent learning task to disentangle the spurious correlation intents and transfer the genuine correlation intents from auxiliary behaviors into the target behavior, thereby obtaining high-quality representations of the target intent. Extensive experiments on three real-world datasets demonstrate that MBID significantly outperforms the state-of-the-art baselines by effectively disentangling the spurious correlation intents. We release our model implementation at: https://github.com/LokHsu/MBID .},
  archive      = {J_NEUCOM},
  author       = {Chenzhong Bin and Tongxin Xu and Feng Zhang},
  doi          = {10.1016/j.neucom.2025.131454},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131454},
  shortjournal = {Neurocomputing},
  title        = {User intent disentanglement for multi-behavior recommendation via information bottleneck principle},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PolyModNet: Advanced positional encodings and ethical bias mitigation in adaptive multimodal fusion for multilingual language understanding. <em>NEUCOM</em>, <em>656</em>, 131450. (<a href='https://doi.org/10.1016/j.neucom.2025.131450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural Language Understanding (NLU) plays a crucial role in Natural Language Processing (NLP), enabling machines to interpret and process human language across various applications. Despite advancements, challenges remain, including variations in data types, inconsistencies in labeling, computational demands, and biases in training datasets. These challenges emphasize the need for ethical and effective NLU solutions. To address these issues, the proposed PolyModNet combines techniques from NLP and computer vision to improve both text and image understanding. The model enhances data representation and compensates for limited training data using advanced augmentation methods such as mixup, gridmask, and positional encoding, optimized for Vision Transformer. By integrating RoBERTa-BERT and Vision Transformer, PolyModNet ensures accurate alignment of text and image features through Transformer-based encoding, specialized transformations, and structured positional encodings. Additionally, it employs a universal multilingual framework that enables language-independent retrieval and flexible task adaptation. Ethical concerns are addressed through bias detection and adversarial training, ensuring fairness in multimodal analysis. Extensive evaluations demonstrate the model’s effectiveness across multiple NLP tasks, achieving 85.71 % accuracy in sentiment analysis, strong text classification performance (CoLA: 64.1 %, SST2: 96.4 %), and high accuracy in text-image retrieval (R@1: 72.00, R@5: 89.25, R@10: 92.10). The model also delivers competitive results in multimodal translation (BLEU: 45.36, METEOR: 55.62) and cross-modal retrieval (text-to-image: R@1: 67.4, image-to-text: R@1: 82.3).},
  archive      = {J_NEUCOM},
  author       = {Shaharyar Alam Ansari and Mohd Anas Wajid and Mohd Arif and Mohammad Saif Wajid},
  doi          = {10.1016/j.neucom.2025.131450},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131450},
  shortjournal = {Neurocomputing},
  title        = {PolyModNet: Advanced positional encodings and ethical bias mitigation in adaptive multimodal fusion for multilingual language understanding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wavelet attention is all you need in multimodal medical image fusion. <em>NEUCOM</em>, <em>656</em>, 131448. (<a href='https://doi.org/10.1016/j.neucom.2025.131448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the multimodal medical image fusion, the fusion method based on frequency domain features is a research hotspot. However, “how to effectively enhance the high frequency and low frequency information in frequency domain?”, “how to fully interact the cross-modal spatial features in feature fusion?” are the keys to improve the fusion performance. To solve this problem, this paper proposes a multimodal medical image fusion network (WTA-Net) based on Wavelet Attention. The main innovations are as follows: Firstly, the Encoder-Decoder fusion network WTA-Net with dual-encoder and single-decoder is proposed. The network effectively capture the frequency domain features in different modal images and enhance the ability of information flow between modalities. Secondly, a Wavelet Attention(WA) is designed in the encoder, which effectively enhance the high frequency and low frequency information of the lesion. Thirdly, the Cross Modal Information Fusion Module(CMIFM) is designed in the fusion stage, which fully interactive cross-modal spatial features. Finally, experiments are performed on the Whole Brain Atlas dataset and the PET-CT lung dataset. In brain MRI images and PET images comparison experiment, IE, AG and EN evaluation indexes are improved by 18.92 %, 14 % and 18.25 %, respectively. In CT mediastinal window images and PET images comparison experiment, IE and SF evaluation indexes are improved by 12.08 % and 49.4 %, respectively, WTA-Net highlight the lession information, which has positive significance for computer-aided diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Tao Zhou and Mingzhe Zhang and Zhe Zhang and Jiaqi Wang and Yang Liu and Huiling Lu},
  doi          = {10.1016/j.neucom.2025.131448},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131448},
  shortjournal = {Neurocomputing},
  title        = {Wavelet attention is all you need in multimodal medical image fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-domain mutual compensation network for multi-modality image fusion. <em>NEUCOM</em>, <em>656</em>, 131443. (<a href='https://doi.org/10.1016/j.neucom.2025.131443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing research has demonstrated that fusing both spatial and frequency domain information from images can enhance fusion model performance, particularly in terms of saliency preservation and texture enhancement. However, designing effective fusion strategies to coordinate complementary information from both domains, while maximizing the unique characteristics and advantages of each and avoiding information conflict or redundancy, remains a challenge that requires further exploration and optimization. To address this issue, we propose a spatial–frequency Dual-Domain Mutual Compensation Network, termed D2Fusion. In our approach, the Mamba module serves as the core component of the spatial branch, capturing long-range dependencies to enhance the focus on the global spatial structure of input features. Simultaneously, the frequency branch utilizes fast Fourier Transform and convolutional neural networks to extract local texture details from the phase and magnitude components of the input features. Unlike traditional dual-branch networks, we introduce a novel phase fusion operation within the frequency branch, which combines phase information from different modalities to generate salient target features that complement and enhance the spatial features. Furthermore, to maximize the exchange of complementary characteristics between spatial, frequency, and salient target features, we design a Mutual Compensation Block (MCB) that accounts for feature differences and a decomposition loss function based on discrete cosine distance. The MCB facilitates compensatory fusion, while the decomposition loss function reduces feature similarity prior to compensation, maximizing the complementary information between domain features. Extensive experiments validate the superiority of our method, demonstrating that D2Fusion outperforms existing state-of-the-art approaches in both multi-modal image fusion and downstream task performance. The code for this framework is available at https://github.com/hz777xx/D2Fusion .},
  archive      = {J_NEUCOM},
  author       = {Jiwei Hu and Zhen Hu and Ping Lou and Kin-Man Lam and Qiwen Jin},
  doi          = {10.1016/j.neucom.2025.131443},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131443},
  shortjournal = {Neurocomputing},
  title        = {A dual-domain mutual compensation network for multi-modality image fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchor-aware representation learning for multi-view clustering. <em>NEUCOM</em>, <em>656</em>, 131441. (<a href='https://doi.org/10.1016/j.neucom.2025.131441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anchor-based multi-view clustering has garnered considerable attention in recent years owing to its ability to reduce computational overhead and enable efficient processing of large-scale datasets. However, existing anchor-based multi-view clustering models still present limitation: while orthogonality constraints are imposed on anchors to enhance their discriminative properties, the inherent relationships among anchors are neglected. To address this limitation, a novel Anchor-Aware Representation Learning for Multi-view Clustering (AARLMC) model is proposed. Specifically, anchor-wise self-representation learning is implemented, with orthogonality constraints applied to the anchor self-representation matrices to uncover intrinsic relationships among anchors. Furthermore, enhanced anchor representations are generated through this process. The anchor graphs are stacked into a third-order tensor with tensor nuclear norm constraint to explore the high-order correlations among multi-view data. Anchor-wise self-representation learning, enhanced anchor representations, and tensor representation are integrated into a unified framework. An optimization algorithm is developed to solve the proposed model. Comparative experiments on twelve benchmark datasets against thirteen state-of-the-art multi-view clustering methods demonstrate that the proposed model achieves superior performance. The source code is available on https://github.com/guowei1314/AARLMC .},
  archive      = {J_NEUCOM},
  author       = {Haotian Zhang and Wei Guo and Ruiyin Liu and Qiang Yang and Xuefei Xiao and Jilin Li and Gang Lei and Gang Chen},
  doi          = {10.1016/j.neucom.2025.131441},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131441},
  shortjournal = {Neurocomputing},
  title        = {Anchor-aware representation learning for multi-view clustering},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft-label generator based on classifier weights. <em>NEUCOM</em>, <em>656</em>, 131436. (<a href='https://doi.org/10.1016/j.neucom.2025.131436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft labels provide rich information between classes. Classification models obtain better generalization ability when soft labels are used as training targets in addition to hard ground-truth labels. In this paper, we propose a new approach named TarSamp to derive effective soft-targets only with the model’s classifier layer. This approach offers a simple, generic, and low-cost solution for soft label generation by fully leveraging the class-level semantics captured by the classifier layer and uncertainty injection with random sampling. We apply TarSamp to both teacher-free and teacher-available scenarios by using the classifier layer from the online model and a pre-trained teacher model, respectively. Extensive experiments on five standard image datasets are provided to evaluate the proposed approach for classifier training. TarSamp achieves more than 8 % accuracy on average for the teacher-free setting with ResNet-18, and gives on par performance by getting rid of querying to the teacher model in each forward pass during distillation for the teacher-available situation. Our results demonstrate that the proposed approach makes as a fundamental yet competitive baseline for a wide range of soft label based supervised learning.},
  archive      = {J_NEUCOM},
  author       = {Xinkai Chu and Jian-Ping Mei and Hang Zhou and Jie Chen and Rui Yan and Jing Fan},
  doi          = {10.1016/j.neucom.2025.131436},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131436},
  shortjournal = {Neurocomputing},
  title        = {Soft-label generator based on classifier weights},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CESDet: Hard pedestrian object detection architecture based on the cognitive experience of structure of human body. <em>NEUCOM</em>, <em>656</em>, 131429. (<a href='https://doi.org/10.1016/j.neucom.2025.131429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional deep learning pedestrian detection methods usually only use the information of the current image itself. Incorrect results that go against common sense are prone to occur when dealing with hard objects with small size, unusual pose, or occlusions. Recent approaches try to enhance the hard objects by constructing and utilizing empirical information. However, due to an insufficient understanding of human body structure, the constructed experience exhibits poor generalization ability to diverse poses. Furthermore, when leveraging experiential features to enhance the features of hard objects, the process is susceptible to interference from occlusions and background. Inspired by human vision, we propose CESDet, a novel pedestrian detection network that constructs and utilizes Cognition Experience of Structure of human body in an unsupervised manner. The key technical innovations are three folds: (1) an unsupervised Cognition Experience of Structure construction module that addresses pose generalization by automatically forming decoupled body parts and pose semantics, (2) a part-level fine-grained verification and feature enhancement module that addresses the interference of occlusions and background with the guidance of Cognition Experience of Structure, and (3) an end-to-end pedestrian detection network for hard objects based on the two proposed modules. Experiments comparing with seven methods on three datasets demonstrate that CESDet achieves state-of-the-art performance, with highest AP on the training dataset, and lowest degradation of AP on a novel unseen dataset. The proposed framework advances the detection of hard objects by exploiting the automatically constructed Cognition Experience of Structure with decoupled part-level appearance and pose.},
  archive      = {J_NEUCOM},
  author       = {Yanglin Pu and Xiaohui Hao and Shan Yang and Hangyuan Yang and Shengxin Dai},
  doi          = {10.1016/j.neucom.2025.131429},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131429},
  shortjournal = {Neurocomputing},
  title        = {CESDet: Hard pedestrian object detection architecture based on the cognitive experience of structure of human body},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-related potential extraction workflow based on kernel density estimation. <em>NEUCOM</em>, <em>656</em>, 131425. (<a href='https://doi.org/10.1016/j.neucom.2025.131425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event-related potentials (ERPs) are a critical neuroscientific tool for investigating brain responses to external stimuli and serve as a key linking mechanism in brain–computer interface systems. Traditional ERP extraction methods rely on threshold-based trial rejection and time-locked averaging techniques, which often have limited ability to handle outlier data and are susceptible to random artifacts. To address this, we propose a novel ERP extraction workflow based on kernel density estimation. We construct trial-wise datasets at the sampling-point granularity and model the probability distribution of each trial using Gaussian kernel density estimation, effectively reducing outlier influence while preserving all trial data. The fitted probability density function serves as the objective function for ERP extraction, enabling active reconstruction of optimal ERP waveforms by incorporating inherent EEG temporal dependencies. Specifically targeting uneven noise distribution across multiple channels, we introduce an adaptively steering kernel dynamically generated from electrode covariance matrices, which optimizes the adaptive matching of inter-channel noise structures to ensure more precise density function fitting. Using two real datasets and simulated datasets, our comparative analyses of baseline root mean square error, component-level statistical metrics, and residual correlations demonstrate that, compared with the traditional trial rejection and time-locked averaging methods, our approach exhibits outstanding effectiveness in isolating ERP components from raw signals and significantly reduces the impact of outlier contamination.},
  archive      = {J_NEUCOM},
  author       = {Weizhuang Kong and Zihao Zhang and Jing Zhu and Yizhou Li and Xiaowei Li and Bin Hu},
  doi          = {10.1016/j.neucom.2025.131425},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131425},
  shortjournal = {Neurocomputing},
  title        = {Event-related potential extraction workflow based on kernel density estimation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view optimization and refinement for high-fidelity 4D gaussian splatting. <em>NEUCOM</em>, <em>656</em>, 131424. (<a href='https://doi.org/10.1016/j.neucom.2025.131424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing dynamic 3D scenes from 2D images and synthesizing temporally diverse views is challenging due to the interplay between scene complexity and temporal dynamics. While 3D Gaussian Splatting offers an efficient solution for static scene modeling, extending it to dynamic scenes faces significant challenges in motion representation and texture fidelity. We propose a novel framework based on multi-view interpolation and joint optimization to address these challenges in sparse-view dynamic scenes. This framework combines linear and spherical interpolation strategies to generate novel views, producing high-quality interpolated images from multiple fitted viewpoints. Additionally, it incorporates consistency constraints to optimize texture representation, enhancing the reconstruction performance for dynamic scenes. Experimental results demonstrate that the proposed framework significantly improves detail fidelity and motion representation in dynamic scene reconstruction.},
  archive      = {J_NEUCOM},
  author       = {Jinhui Lin and Zhenyang Wei and Silei Shen and Fang Zhou and Xiaobin Zhu and Xu-Cheng Yin},
  doi          = {10.1016/j.neucom.2025.131424},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131424},
  shortjournal = {Neurocomputing},
  title        = {Multi-view optimization and refinement for high-fidelity 4D gaussian splatting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KD-KI: Knowledge distillation with knowledge infusion for anomaly detection and localization. <em>NEUCOM</em>, <em>656</em>, 131423. (<a href='https://doi.org/10.1016/j.neucom.2025.131423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection and localization are crucial for improving product reliability in industrial quality inspection. Existing knowledge distillation methods often cause student networks to merely mimic features of teacher networks, which makes it difficult to achieve stable and generalized detection performance. This paper introduces the KD-KI framework, which uses a knowledge infusion mechanism to transfer structured hierarchical knowledge from the teacher network to the student network. This guides the student to learn more robust representations of normal samples. Additionally, a feature bias loss is used to optimize the similarity of shallow-layer features, improving detection accuracy and localization precision. KD-KI can be deployed with standard convolutional networks and is suitable for real-time industrial inspection systems. Experimental results demonstrate that the proposed KD-KI model can yield improved performance in anomaly detection and localization compared to other competing models.},
  archive      = {J_NEUCOM},
  author       = {Wei Huang and Zhaonan Xu and Rongchun Wan and Xuhua Yang and Bingyang Zhang},
  doi          = {10.1016/j.neucom.2025.131423},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131423},
  shortjournal = {Neurocomputing},
  title        = {KD-KI: Knowledge distillation with knowledge infusion for anomaly detection and localization},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFCon: Dominant frequency enhanced ultra-long time series contrastive forecasting. <em>NEUCOM</em>, <em>656</em>, 131418. (<a href='https://doi.org/10.1016/j.neucom.2025.131418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultra-long time series forecasting (ULTSF) is crucial for fields like energy management, traffic planning, and climate prediction. However, as the forecast horizon increases, concept drift becomes a major challenge, as a fixed-length historical window struggles to generalize ultra-long temporal patterns. Extending the input series length increases computational costs and demands a higher model capacity for capturing longer temporal dependencies. To address these issues, we propose DFCon, a dominant frequency enhanced contrastive learning framework for ULTSF. DFCon combines dilated convolutions for feature extraction and multi-layer perceptrons for forecasting, with a dual contrastive loss based on dominant frequency enhancement. We introduce Temporal DFCon, which enhances the model’s sensitivity to these frequency-domain features during training, thereby improving its ability to model global temporal dependencies in the input series. Furthermore, cross-window Autocorrelated DFCon is proposed, which mitigates concept drift by constructing autocorrelated relative positive and negative samples without introducing noisy data. Experiments on five benchmark datasets show that DFCon outperforms existing methods, demonstrating its effectiveness in ULTSF. The code for this work is publicly available at: https://github.com/coding4qq/DFCon .},
  archive      = {J_NEUCOM},
  author       = {Qiaoqiao Liu and Hui Liu and MingJie Yang and Yuheng Wei and Junzhao Du},
  doi          = {10.1016/j.neucom.2025.131418},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131418},
  shortjournal = {Neurocomputing},
  title        = {DFCon: Dominant frequency enhanced ultra-long time series contrastive forecasting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Breaking the alignment barrier: A spatiotemporal alignment-free RGBT tracking approach. <em>NEUCOM</em>, <em>656</em>, 131382. (<a href='https://doi.org/10.1016/j.neucom.2025.131382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-Thermal (RGBT) tracking leverages complementary information from visible and infrared modalities to improve tracking robustness in complex environments. However, its practical deployment remains constrained by the stringent requirement for precise spatiotemporal alignment between heterogeneous modalities—a condition rarely satisfied in real-world applications. To overcome this limitation, we present SAFNet, a novel Spatiotemporal Alignment-Free Network that eliminates the need for precise cross-modal alignment through innovative architectural designs. Our framework develops a spatiotemporal interaction query module incorporating cross-modal temporal attention, which re-establishes inter-modal temporal correlations for unregistered inputs by leveraging similarity learning across asynchronous data streams. For spatial discrepancy mitigation, we propose a dual-branch pre-tracking network employing deep cross-correlation analysis, combined with an adaptive feature fusion strategy under the guidance of joint response distribution. Furthermore, we devise an innovative dynamic template update mechanism that adaptively adjusts modal update rates to maintain temporal consistency across heterogeneous data streams. Comprehensive evaluations validate SAFNet’s state-of-the-art performance across four benchmark datasets (GTOT, RGBT210, RGBT234, LasHeR), demonstrating significant improvements in tracking accuracy. The proposed architecture represents a significant advancement toward practical deployment of robust RGBT tracking systems in real-world environments with asynchronous multimodal inputs.},
  archive      = {J_NEUCOM},
  author       = {Xiaodong Liu and Meibo Lv and Daming Zhou and Lingyu Si and Ruiheng Zhang and Hui Xu},
  doi          = {10.1016/j.neucom.2025.131382},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131382},
  shortjournal = {Neurocomputing},
  title        = {Breaking the alignment barrier: A spatiotemporal alignment-free RGBT tracking approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The implicit regularization of gradient flow on separable datasets in ReLU networks. <em>NEUCOM</em>, <em>656</em>, 131367. (<a href='https://doi.org/10.1016/j.neucom.2025.131367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to investigate the implicit regularization of gradient flow when training non-linearly separable multi-class datasets in ReLU networks. We prove that the gradient flow leads the directions of each layer to converge. Besides, we show that the convergent directions of different layers collectively form a Karush-Kuhn-Tucker (KKT) point of the max normalized margin problem in parameter space. In particular, for any l ∈ [ L ] , we prove that the convergent direction of the l -th layer is the local maximum of the max normalized margin problem when other directions are fixed. This indicates that the convergent directions maximize the margin for each layer separately. Moreover, we show the growth rate of weights across different layers and demonstrate their layer-balanced properties. Furthermore, we prove that the cross-entropy loss converges and we give the tight bound of the convergence rate. In addition, we present a generalization bound for ReLU networks in multi-class tasks based on Rademacher complexity. Our results demonstrate that the generalization bound is primarily influenced by the normalized margin and the number of training samples. Finally, we present a series of numerical experiments to verify our theory.},
  archive      = {J_NEUCOM},
  author       = {Xiangyun Hui and Xiaoxuan Ma and Yixuan Yang and Song Li},
  doi          = {10.1016/j.neucom.2025.131367},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131367},
  shortjournal = {Neurocomputing},
  title        = {The implicit regularization of gradient flow on separable datasets in ReLU networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring cycle cover variants: A dataless neural networks approach. <em>NEUCOM</em>, <em>656</em>, 131361. (<a href='https://doi.org/10.1016/j.neucom.2025.131361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cycle Cover, a fundamental concept in graph theory, plays a critical role in various applications, including network design, transportation optimization, and bioinformatics. A Cycle Cover is a collection of cycles covering all the vertices of a given graph, ensuring that each vertex belongs to exactly one cycle. In this paper, we explore various aspects of Cycle Cover variants. We employ the dataless neural networks framework to establish single differentiable functions for each of these variants. Recent research has demonstrated the capability of the dataless neural networks framework in representing a host of combinatorial optimization problems. Motivated by these findings, we propose dataless neural networks tailored for the Cycle Cover variants. Additionally, we present a rigorous proof of the correctness of our approach.},
  archive      = {J_NEUCOM},
  author       = {Sangram K. Jena and K. Subramani and Alvaro Velasquez},
  doi          = {10.1016/j.neucom.2025.131361},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131361},
  shortjournal = {Neurocomputing},
  title        = {Exploring cycle cover variants: A dataless neural networks approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight deep learning for visual perception: A survey of models, compression strategies, and edge deployment challenges. <em>NEUCOM</em>, <em>656</em>, 131357. (<a href='https://doi.org/10.1016/j.neucom.2025.131357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for the deployment of deep neural networks (DNNs) in edge devices has led to the development of lightweight deep learning (LDL) models designed to operate efficiently under resource constraints. Although DNNs have achieved remarkable success in various applications, their high computational requirements often limit their deployment on devices with restricted memory and processing power. This challenge has motivated researchers to develop optimized LDL models that balance accuracy, speed, and efficiency while maintaining competitive performance. Despite existing surveys covering specific aspects of LDL models, a comprehensive review encompassing image classification, object detection, and segmentation remains limited. This proposed survey systematically explores recent advancements in LDL models, highlighting their architectures, optimization techniques, and real-world applications. This survey conducts an empirical evaluation by testing latest state-of-the-art LDL models on the Jetson Orin edge device using benchmark datasets: ImageNet for classification, VisDrone for object detection, and COCO for segmentation. The experimental analysis focuses on key performance metrics, including inference speed, model accuracy, and computational efficiency, while comparing LDL models with their conventional counterparts. This study provides a holistic understanding of the role of LDL models in edge computing, providing insight into emerging trends, challenges, and future research directions in the field.},
  archive      = {J_NEUCOM},
  author       = {Syed Muhammad Raza and Syed Murtaza Hussain Abidi and Md Masuduzzaman and Soo Young Shin},
  doi          = {10.1016/j.neucom.2025.131357},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131357},
  shortjournal = {Neurocomputing},
  title        = {Lightweight deep learning for visual perception: A survey of models, compression strategies, and edge deployment challenges},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LaSNN: Layer-wise ANN-to-SNN distillation for effective and efficient training in deep spiking neural networks. <em>NEUCOM</em>, <em>656</em>, 131351. (<a href='https://doi.org/10.1016/j.neucom.2025.131351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are biologically realistic and practically promising in low-power computation because of their event-driven mechanism. Usually, the training of SNNs suffers from accuracy loss on various tasks, yielding an inferior performance compared with ANNs. A conversion scheme is proposed to obtain competitive accuracy by mapping trained ANNs’ parameters to SNNs with the same structures. However, an enormous number of time steps are required for these converted SNNs, thus losing the energy-efficient benefit. Utilizing both the accuracy advantages of ANNs and the computing efficiency of SNNs, a novel SNN training framework is proposed, namely layer-wise ANN-to-SNN knowledge distillation (LaSNN). In order to achieve competitive accuracy and reduced inference latency, LaSNN transfers the learning from a well-trained ANN to a small SNN by distilling the knowledge rather than converting the parameters of ANN. The information gap between heterogeneous ANN and SNN is bridged by introducing the attention scheme. The knowledge in an ANN is effectively compressed and then efficiently transferred by utilizing our layer-wise distillation paradigm. We conduct detailed experiments to demonstrate the effectiveness, efficacy, and scalability of LaSNN on three benchmark data sets (CIFAR-10, CIFAR-100, and Tiny ImageNet). We achieve competitive top-1 accuracy compared to ANNs and faster inference than converted SNNs with similar performance. More importantly, LaSNN is dexterous and extensible that can be effortlessly developed for SNNs with different architectures/depths and input encoding methods, contributing to their potential development.},
  archive      = {J_NEUCOM},
  author       = {Di Hong and Yu Qi and Yueming Wang},
  doi          = {10.1016/j.neucom.2025.131351},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131351},
  shortjournal = {Neurocomputing},
  title        = {LaSNN: Layer-wise ANN-to-SNN distillation for effective and efficient training in deep spiking neural networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing spatio-temporal information using supervised local low-rank correlation embedding for depression recognition. <em>NEUCOM</em>, <em>656</em>, 131350. (<a href='https://doi.org/10.1016/j.neucom.2025.131350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) signals contain rich spatio-temporal information that reflects the brain’s dynamic activity, making it widely used in depression recognition. However, effectively integrating this information to capture discriminative and complementary features remains a key challenge. To address this issue, we propose a novel Discriminative Local Low-Rank Correlation Embedding (DLLCE) to fuse spatio-temporal information of EEG. DLLCE integrates shared low-rank representation, local invariance, discriminative constraints, and enhanced correlation analysis into a unified framework. Specifically, the shared low-rank representation is used to capture the common structural patterns, while the correlation analysis aims to reduce redundancy among feature sets. In addition, the Laplacian regularization is applied to the shared representation to preserve the local geometric structure of the original data. To further enhance discriminative capability, a discriminant graph embedding term is incorporated to exploit label information. Experimental results on EEG datasets demonstrate that DLLCE achieves superior performance compared to existing methods. This work provides new insights into EEG-based mental health assessment and holds promise for early depression diagnosis and clinical decision support.},
  archive      = {J_NEUCOM},
  author       = {Lu Zhang and Peng Xu and Zhijun Yao and Xinyan Zhang and Juan Wang and Bin Hu and Gang Feng and Hong Peng},
  doi          = {10.1016/j.neucom.2025.131350},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131350},
  shortjournal = {Neurocomputing},
  title        = {Fusing spatio-temporal information using supervised local low-rank correlation embedding for depression recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-driven baseline for few-shot fine-grained visual recognition. <em>NEUCOM</em>, <em>656</em>, 131302. (<a href='https://doi.org/10.1016/j.neucom.2025.131302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot fine-grained visual recognition (FS-FGVR), a practical yet challenging task, aims to break the dilemma of having scarce training examples for new fine-grained tasks. Meta-learning-based methods target this issue by employing the learning-to-learn strategy to train a well-generalized meta-learner from seen fine-grained tasks for unseen fine-grained tasks. However, most existing works rely too much on small-scale fine-grained training tasks. Specifically, these works demand large amounts of fine-grained data to sample these training tasks, and they are unable to generalize well to new tasks. Consequently, model capacity can be highly restricted when limited training references are available. This paper presents a novel coarse-to-fine framework named Knowledge-Driven baseline for FS-FGVR by transferring knowledge from large-scale and coarse-grained datasets. This framework departs the meta-training phase into the coarse-grained meta-pretraining and fine-grained meta-finetuning phases. First, off-the-shelf coarse-grained data is introduced to build the initialization correlations as prior knowledge. Then, we use prior knowledge to infer the representational interactions and correlations of the fine-grained representations. Extensive experiments show that our method outperforms the current methods on the public few-shot fine-grained benchmarks. We also develop extensive studies to extend our method to few-shot texture visual recognition scenarios.},
  archive      = {J_NEUCOM},
  author       = {Jieqi Sun and Jian Li and Yafeng Li},
  doi          = {10.1016/j.neucom.2025.131302},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131302},
  shortjournal = {Neurocomputing},
  title        = {Knowledge-driven baseline for few-shot fine-grained visual recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BMTM-net: A rotating machinery fault diagnosis network based on 2D-1D fusion with bidirectional multi-granularity transformer-mamba. <em>NEUCOM</em>, <em>656</em>, 131293. (<a href='https://doi.org/10.1016/j.neucom.2025.131293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotating machinery plays a critical role in industrial operations, yet existing diagnostic methods often struggle with missing correlations between sensor data, weak noise immunity, and insufficient long-range feature extraction. To address these challenges, this paper proposes BMTM-Net, a fault diagnosis network based on 2D-1D fusion with Bidirectional Multi-granularity Transformer-Mamba (BMTM). The network consists of two main components: a 2D sequential information interaction network and a 1D temporal information extraction network. The 2D network captures inter-sensor sequence relationships and temporal dependencies using a Bidirectional Multi-granularity Transformer (BM-Transformer) and an embedded Sequential-Temporal Attention Module (ST-Attention), while the 1D network enhances feature completeness and extracts temporal information through a Bidirectional Multi-granularity Mamba (BM-Mamba) network, integrated with a Channel Attention-based Fusion Module (CAFM) for adaptive feature fusion. To evaluate BMTM-Net’s effectiveness and stability, experiments were conducted on datasets from Southeast University and a Self-Built bogie integrated test stand, with various levels of noise introduced to assess noise immunity. The results demonstrate that BMTM-Net achieves over 99 % accuracy across all four datasets and maintains high accuracy even under severe noise interference (SNR = −10 dB), outperforming other state-of-the-art methods with accuracy rates of 99.60 %, 99.40 %, 98.54 %, and 94.38 %, respectively. Additionally, the model exhibits low complexity, further confirming its robustness and effectiveness in noisy environments.},
  archive      = {J_NEUCOM},
  author       = {E. Xia and Yirong Liu and Jinyang Gong and Xunhua Dai and Tongyang Pan and Shiyi Wang},
  doi          = {10.1016/j.neucom.2025.131293},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131293},
  shortjournal = {Neurocomputing},
  title        = {BMTM-net: A rotating machinery fault diagnosis network based on 2D-1D fusion with bidirectional multi-granularity transformer-mamba},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancements in radiomics: A comprehensive survey of feature types and their correlation on modalities and regions. <em>NEUCOM</em>, <em>656</em>, 131192. (<a href='https://doi.org/10.1016/j.neucom.2025.131192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey paper provides an overview of different feature types used in radiomics research and their applications across various medical imaging modalities and disease domains. The paper delves into the key aspects of the radiomics workflow, including data engineering techniques for image acquisition, preprocessing, fusion, and segmentation. It then presents a comprehensive review of the most commonly employed feature categories in radiomics, such as shape-based, first-order statistical, second-order texture, and transform-based features. The paper also discusses the emerging role of deep learning features extracted using convolutional neural networks, recurrent neural networks, and transformers. The analysis of feature usage trends across different anatomical regions and imaging modalities offers valuable insights that can guide the optimization of feature engineering strategies in future radiomics research. The survey concludes by highlighting several opportunities for further advancement in the field, including the need for larger multi-center datasets, multi-modal data fusion, self-supervised learning, and the development of efficient embedded models for on-device deployment.},
  archive      = {J_NEUCOM},
  author       = {Luca Zedda and Andrea Loddo and Cecilia Di Ruberto},
  doi          = {10.1016/j.neucom.2025.131192},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131192},
  shortjournal = {Neurocomputing},
  title        = {Advancements in radiomics: A comprehensive survey of feature types and their correlation on modalities and regions},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive low-confidence pseudolabeling for semisupervised node classification. <em>NEUCOM</em>, <em>656</em>, 131166. (<a href='https://doi.org/10.1016/j.neucom.2025.131166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have demonstrated remarkable achievements in handling graph-structured data. However, the performance of GNNs is typically limited by the lack of sufficient labeled data, which are time-consuming to obtain in real-world scenarios. Pseudolabeling has been applied to GNNs by augmenting the training set data with unlabeled data. Most pseudolabeling methods on graphs assign pseudolabels to nodes based on high-confidence thresholds. However, nodes near labeled ones generally obtain high confidence scores during training. This results in an increasing number of similar nodes being assigned pseudolabels during training, which potentially leads to a distribution shift between the labeled dataset and the augmented dataset. The distribution of the augmented dataset diverges significantly from that of the entire graph data, causing the GNNs to perform poorly on test data. In this paper, we propose a progressive low-confidence pseudolabeling (PLCP) method to progressively leverage the low-confidence data. Specifically, pseudolabels are assigned to nodes within a predefined confidence-based ranking range. To alleviate distribution shift, we keep this range constant throughout the training process to prevent excessive nodes from being assigned pseudolabels. The range is designed to be sufficiently wide to leverage low-confidence nodes. Low-confidence nodes from the range propagate information to their neighbors, which helps the model capture patterns in uncertain regions. To alleviate the impact of noisy pseudolabels, a validation-based reassignment scheme is proposed to utilize validation metrics to assign more reliable pseudolabels. Numerous experiments are conducted to demonstrate that our proposed PLCP improves the performance of state-of-the-art GNNs on graph datasets in comparison with several established methods.},
  archive      = {J_NEUCOM},
  author       = {Tao Zhu and Hua Mao and Hui Liu and Jie Chen},
  doi          = {10.1016/j.neucom.2025.131166},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131166},
  shortjournal = {Neurocomputing},
  title        = {Progressive low-confidence pseudolabeling for semisupervised node classification},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep-DFVAR: Dynamic factor vector autoregression with deep learning for regional house price index forecasting. <em>NEUCOM</em>, <em>656</em>, 131103. (<a href='https://doi.org/10.1016/j.neucom.2025.131103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {House Price Index (HPI) is an indicator that reflects changes in residential house prices over time. Predicting HPI is crucial for homebuyers to determine the right time to purchase and for policymakers to formulate housing policies. Recent studies have reported that neural network approaches outperform classical methods in HPI forecasting. However, challenges remain due to limited monthly HPI data and its time-varying statistical properties. As a result, state-of-the-art time series forecasting models often respond slowly to abrupt changes and lack economic interpretability. To address these issues, we propose Deep-DFVAR, a hybrid framework that decomposes regional HPI into shared (common trends) and idiosyncratic (regional variations) components. The shared component is predicted with Vector Autoregression (VAR) based on Granger causality, which improves interpretability and responds faster to changes. The idiosyncratic component is modeled with our deep learning model, which benefits from reduced distribution shift (train–test gap). We evaluate Deep-DFVAR on South Korean and United States datasets, empirically demonstrating that our framework outperforms traditional and recent time series forecasting models. All data and code are publicly available at: https://github.com/YeoJiSu/House-Price-Index-Prediction .},
  archive      = {J_NEUCOM},
  author       = {Jisu Yeo and Artyom Stitsyuk and Jaesik Choi},
  doi          = {10.1016/j.neucom.2025.131103},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131103},
  shortjournal = {Neurocomputing},
  title        = {Deep-DFVAR: Dynamic factor vector autoregression with deep learning for regional house price index forecasting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-based triple asynchronous switching control for fuzzy neural networks: A full-information dependent lyapunov approach. <em>NEUCOM</em>, <em>656</em>, 131097. (<a href='https://doi.org/10.1016/j.neucom.2025.131097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper employs the full-information dependent Lyapunov-Krasovskii functional (LKF) analysis approach to investigate the multiple weighting adaptive event-triggered triple asynchronous switching control problem for Takagi-Sugeno fuzzy neural networks with semi-Markov jump parameters. Considering the influence of factors such as network delays and disturbances, there may be asynchronous premise variables and modes among the system, event generator and controller. Therefore, a triple asynchronous switching control framework under the multiple weighting adaptive event-triggered scheme is developed. Under this control framework, a novel full-information dependent LKF analysis approach is proposed to analyze the stability of neural networks, which fully considers the system information, such as the membership functions (MFs) information, modes information and state information. Meanwhile, a new MFs dependent optimal H ∞ performance index is introduced to achieve better disturbance attenuation ability. The proposed analysis approach is helpful in determining the controller gains and reducing the conservatism. Ultimately, four simulation examples are provided to show the effectiveness and superiority of proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Yiteng Zhang and Linchuang Zhang and Yonghui Sun and Wen Yang},
  doi          = {10.1016/j.neucom.2025.131097},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131097},
  shortjournal = {Neurocomputing},
  title        = {Event-based triple asynchronous switching control for fuzzy neural networks: A full-information dependent lyapunov approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCHF_T: A multi-dimensional adaptive compression approach for transformer-based models. <em>NEUCOM</em>, <em>656</em>, 131071. (<a href='https://doi.org/10.1016/j.neucom.2025.131071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, pre-trained language models based on the Transformer architecture have achieved significant results in many natural language processing tasks. However, the high computational cost limits their application in real-world scenarios. Previous Transformer compression methods typically focus on single-dimensional compression, which may cause over-compression and consequently degrade model performance. Additionally, these methods lack targeted optimization for specific downstream tasks. In this paper, we propose DCHF_T, a multi-dimensional adaptive compression approach that compresses Transformer models through token compression, attention head pruning, and a lightweight FFN. This approach selects the most informative tokens during training, prunes unimportant tokens, and retains their information in a compressed form, allowing the model to focus more on task-relevant inputs. Furthermore, DCHF_T combines attention head pruning and a lightweight FFN to reduce computation and parameter size across multiple dimensions. We employ multi-objective evolutionary search to optimize the trade-off between accuracy and efficiency under various computational budgets. Experimental results on the GLUE benchmark demonstrate that DCHF_T achieves the best compression–performance trade-off. While maintaining the highest accuracy, DCHF_T achieves a reduction of 3.7 × and 3.6 × in FLOPs on BERT-base and RoBERTa-base, respectively. By implementing adaptive multi-dimensional compression, DCHF_T provides a systematic solution for deploying Transformer models in resource-constrained scenarios.},
  archive      = {J_NEUCOM},
  author       = {Yaoyao Yan and Da Wang and Jing Ye and Hui Yu and Dianjie Lu and Yuang Zhang and Weizhi Xu and Fang’ai Liu},
  doi          = {10.1016/j.neucom.2025.131071},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131071},
  shortjournal = {Neurocomputing},
  title        = {DCHF_T: A multi-dimensional adaptive compression approach for transformer-based models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key-concept thinking prompting for improved reasoning in large language models. <em>NEUCOM</em>, <em>656</em>, 130986. (<a href='https://doi.org/10.1016/j.neucom.2025.130986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in large language models (LLMs) have significantly accelerated the development of natural language processing (NLP) research, demonstrating remarkable capabilities in understanding and generating human-like text. However, these models face limitations when it comes to system 2 tasks, which require slow, multi-step, and conscious reasoning. To address these limitations, we introduce a method called Key-Concept Thinking (KCT), which enhances the model’s reasoning ability by directing it to identify and prioritize key concepts within a problem. Building on the Chain-of-Thought (CoT) prompting method, KCT anchors its approach in core ideas, allowing the model to form a deeper understanding of the problem’s structure and purpose. This targeted approach aims to improve both the accuracy and efficiency of the model’s reasoning, making it better equipped to handle tasks that require precision and deep understanding. We evaluate our proposed prompting strategies using 24 reasoning tasks across four categories: arithmetic, commonsense, symbolic, and other logical reasoning tasks, with three prominent large models: ChatGLM4, Baichuan2, and DeepSeek, respectively. The results show that the Zero-shot-KCT and Zero-shot-CoT-KCT strategies outperform traditional zero-shot and few-shot prompting strategies, highlighting the effectiveness of incorporating key concept thinking into the reasoning processes of LLMs. Our findings have implications for the development of more effective prompting strategies for LLMs that can handle complex reasoning tasks with higher accuracy and coherence.},
  archive      = {J_NEUCOM},
  author       = {Minghua Tang and Chen Bian and Liming Yang and Xueling Zhong},
  doi          = {10.1016/j.neucom.2025.130986},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {130986},
  shortjournal = {Neurocomputing},
  title        = {Key-concept thinking prompting for improved reasoning in large language models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
