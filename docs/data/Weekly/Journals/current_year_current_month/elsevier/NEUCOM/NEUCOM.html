<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NEUCOM</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="neucom">NEUCOM - 78</h2>
<ul>
<li><details>
<summary>
(2025). Predicting nonlinear dynamic systems by causal physics-informed neural networks with ResNet blocks. <em>NEUCOM</em>, <em>656</em>, 131589. (<a href='https://doi.org/10.1016/j.neucom.2025.131589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of data computational science, the prediction of nonlinear systems has provided effective support for investigating complex problems in the field of natural sciences. Physics-Informed Neural Networks (PINNs) are playing an increasingly prominent role in nonlinear system prediction. Although PINNs have been widely applied across various engineering domains, their utilization in chaotic system prediction remains notably scarce. This paper proposes a novel causal PINNs framework integrated with ResNet blocks. On the one hand, the framework incorporates temporal weighting into the residual loss, utilizing maximum temporal weight as the training termination criterion. Additionally, an annealing strategy is adopted to adaptively adjust the causal parameters, ensuring that the model adheres to physical causality constraints throughout the training process. On the other hand, the framework employs a ResNet-block-based network, which transforms identity mappings into residual mappings. This architectural design significantly enhances training stability when utilizing deep networks. To validate the performance of the proposed method, numerical experiments are conducted on the Lorenz system, Dadras system, and Kuramoto-Sivashinsky equation. The results demonstrate that the causal PINNs with ResNet blocks significantly outperform conventional PINNs in predicting chaotic systems.},
  archive      = {J_NEUCOM},
  author       = {Man-Hong Fan and Jun-Hao Zhao and Lin Ding and Xiao-Ying Ma and Rui-Lin Fu},
  doi          = {10.1016/j.neucom.2025.131589},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131589},
  shortjournal = {Neurocomputing},
  title        = {Predicting nonlinear dynamic systems by causal physics-informed neural networks with ResNet blocks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-stream diffusion graph convolutional model with adaptive motion-aware attention and self-supervised pretraining for continuous sign language recognition. <em>NEUCOM</em>, <em>656</em>, 131567. (<a href='https://doi.org/10.1016/j.neucom.2025.131567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous Sign Language Recognition (CSLR) requires capturing both spatial and temporal dependencies to accurately model sign sequences. To enhance CSLR performance, we propose a Multi-Stream Diffusion Graph Convolution Network (MSD-GCN) from input skeleton data that introduces three key innovations. First, Adaptive Motion-aware Graph Convolution with Bi-level Attention (AMGC-BA) dynamically refines joint connectivity by leveraging semantic motion correlations, improving robustness to signer variations, and enhancing long-term dependencies. Second, signal-enhanced multi-stream representation learning integrates advanced signal processing techniques, including the Adaptive Ridgelet Transform (ART) for pose representation, Variational Mode Decomposition (VMD) for motion decomposition, and Empirical Wavelet Transform (EWT) for contextual feature extraction, ensuring feature robustness, reducing noise, and improving discriminability. Third, self-supervised pretraining leverages contrastive learning, graph reconstruction, and cross-stream feature alignment to mitigate data scarcity, enhance domain adaptation, and improve representation learning. These innovations enable the proposed graph to effectively capture complex motion patterns, distinguish between critical and redundant gestures, and generalize well across diverse signers and datasets. By improving recognition accuracy, robustness, and adaptability, the proposed approach provides a significant advancement in CSLR, addressing the challenges of signer variability, limited labeled data, and the need for fine-grained motion representation. Results on three datasets confirm the superiority of the proposed model compared to 35 comparative models. To the best of our knowledge, this is the first study in CSLR to employ such an extensive range of comparative models for performance evaluation.},
  archive      = {J_NEUCOM},
  author       = {Razieh Rastgoo},
  doi          = {10.1016/j.neucom.2025.131567},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131567},
  shortjournal = {Neurocomputing},
  title        = {A multi-stream diffusion graph convolutional model with adaptive motion-aware attention and self-supervised pretraining for continuous sign language recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGFCNN: A synergistic framework integrating graph-based spatial filter and lightweight CNN for SSVEP recognition. <em>NEUCOM</em>, <em>656</em>, 131561. (<a href='https://doi.org/10.1016/j.neucom.2025.131561'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing the feature representation and decoding efficiency of the steady-state visual evoked potentials (SSVEPs) is critical to enhancing the performance of neural signal decoding systems. Current deep learning models often overlook the physical topological information of EEG channels, resulting in suboptimal feature extraction and limited recognition performance. To address these challenges, this study proposes a synergistically designed SSVEP recognition framework to alleviate data insufficiency, improve the feature representation, and enhance decoding efficiency. Specifically, a slicing-and-scaling technique is adopted to improve the model generalization under limited-sample scenarios. A graph-based spatial filter leverages the topological relationships among EEG channels to suppress redundant information and enhance spatial feature quality. A lightweight convolutional neural network (CNN) with fewer parameters is developed to efficiently extract discriminative temporal–spatial features for accurate SSVEP classification. Experimental results on two public benchmark datasets and one self-collected dataset demonstrate that the proposed framework outperforms baseline deep learning models, yielding improvements of at least 6.8 %, 8.5 %, and 0.5 % in peak average classification accuracy, respectively. The maximum average information transfer rates (ITRs) achieved on the three datasets were 221.4 bits/min ,106.7 bits/min , and 133.9 bits/min , respectively. By simultaneously reducing model complexity and improving decoding performance, the proposed framework offers an effective and promising approach for efficient neural signal decoding in SSVEP recognition.},
  archive      = {J_NEUCOM},
  author       = {Rui Ma and Yu Cao and Sheng Quan Xie and Mingming Zhang and Jun Li and Zhi-Qiang Zhang},
  doi          = {10.1016/j.neucom.2025.131561},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131561},
  shortjournal = {Neurocomputing},
  title        = {LGFCNN: A synergistic framework integrating graph-based spatial filter and lightweight CNN for SSVEP recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double missing multi-view multi-label classification via an attention-guided multi-space consistency alignment framework. <em>NEUCOM</em>, <em>656</em>, 131558. (<a href='https://doi.org/10.1016/j.neucom.2025.131558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view multi-label classification (MVMLC) seeks to enhance classification by integrating diverse data views, but its practical use is hindered by missing views and labels, posing the significant challenge of incomplete MVMLC(IMVMLC). Although various IMVMLC approaches have been proposed, most of them handle multiple objectives in a single feature space and thus overlook the conflict between learning consistent common semantics and reconstructing view-specific information. In addition, existing multi-view classification methods mainly consider utilizing the features of each view, while ignoring the inconsistent contributions of each view and usually relying on static average weighting strategies. To this end, we propose our Attention-Guided MultiSpace Consistency Alignment Framework (AMCA). In Stage 1, AMCA introduces multi-space representation learning with dual-level contrastive objectives, explicitly disentangling shared and view-specific semantics to resolve the objective conflict and yield more informative embeddings. In Stage 2, AMCA employs an attention-guided fusion module that dynamically evaluates and integrates multi-view features based on their relevance to the classification task, enabling robust decision-making even with missing data. Extensive experiments validate the effectiveness and superiority of our proposal.},
  archive      = {J_NEUCOM},
  author       = {Bingyan Nie and Wulin Xie and Lian Zhao and Jiang Long and Xiaohuan Lu and Yinghao Ye},
  doi          = {10.1016/j.neucom.2025.131558},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131558},
  shortjournal = {Neurocomputing},
  title        = {Double missing multi-view multi-label classification via an attention-guided multi-space consistency alignment framework},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end transformer-based detection with density-guided query selection for small objects. <em>NEUCOM</em>, <em>656</em>, 131554. (<a href='https://doi.org/10.1016/j.neucom.2025.131554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small object detection remains a persistent challenge in transformer-based detectors due to their limited localization precision and reliance on fixed query mechanisms. In this paper, we propose Hybrid Density-Transformer (HyDeTr), a novel transformer-based object detection framework designed to improve the detection of small and densely packed objects with only a slight trade-off in inference complexity. HyDeTr introduces several key innovations: (1) a Context-Selective Hybrid Attention Encoder (CS-HAE) that distills global context from low-resolution features through efficient kernelized attention while preserving local detail via deformable attention on higher-resolution maps; (2) a Density Map Prediction module that generates a spatial prior highlighting high-object-density regions, facilitating focus on crowded scenes; (3) a Density-Guided Uncertainty-Minimal Query Selection strategy that identifies the most informative query locations based on both classification confidence and predicted density, ensuring that even low-confidence small objects in dense areas are effectively queried; and (4) an improved Query Formulation with dual embeddings, consisting of a content embedding and a 4D anchor box, refined iteratively by the decoder. Our design enables precise, density-aware query initialization and scale adaptation, leading to improved recall and accuracy for small objects. Extensive evaluations demonstrate that HyDeTr outperforms existing methods in detecting small objects, offering significant accuracy gains with only a modest increase in inference complexity, thereby maintaining near real-time performance and full end-to-end trainability.},
  archive      = {J_NEUCOM},
  author       = {Nguyen Hoanh and Tran Vu Pham},
  doi          = {10.1016/j.neucom.2025.131554},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131554},
  shortjournal = {Neurocomputing},
  title        = {End-to-end transformer-based detection with density-guided query selection for small objects},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel dynamic sparse graph attention framework for cross-domain intelligent diagnosis of rotating machinery. <em>NEUCOM</em>, <em>656</em>, 131553. (<a href='https://doi.org/10.1016/j.neucom.2025.131553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mechanical equipment prognostics, conventional graph neural networks encounter significant limitations when processing high-dimensional dynamic sensor data: inadequate modeling of complex feature interdependencies, insufficient sensitivity to transient fault signatures, and ineffective knowledge transfer in cross-domain applications. To overcome these challenges, we present a DSGA-SAGE, which stands for Dynamic Sparse Graph Attention - SAmpling and aGgrEgation framework. Our approach presents innovations in three aspects: (1) A decentralized graph construction paradigm establishes dynamic associations among multivariate time-series features, enabling precise identification of critical fault patterns through adaptive node-edge interactions. (2) A sparse attention mechanism with trainable topology constraints optimizes the structural weights of graph in the real-time scenarios, achieving 23 % overhead computational reduction while maintaining the accuracy of feature discriminability. (3) A unified cross-domain learning strategy synchronizes multi-condition knowledge transfer through hierarchical loss optimization, ensuring robust generalization across various operational scenarios. Extensive experiments on five industrial datasets demonstrate state-of-the-art performance: achieving the highest accuracy of 96.29 % in fault diagnosis, while realizing 99.87 % Macro-F1 and 99.88 % Micro-F1 scores in cross-domain tasks. Through a comprehensive performance analysis, the superiority of the efficiency and cross-domain adaptability in dynamic sparse graph attention mechanism has been convincingly validated.},
  archive      = {J_NEUCOM},
  author       = {Ying Xie and Jixiang Wang and Zhiqiang Xu and Junnan Shen and Lijie Wen and Rongbin Xu and Yun Yang},
  doi          = {10.1016/j.neucom.2025.131553},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131553},
  shortjournal = {Neurocomputing},
  title        = {A novel dynamic sparse graph attention framework for cross-domain intelligent diagnosis of rotating machinery},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A collaborative decision framework for dynamic control of gear remaining useful life using multi-source information in active health management. <em>NEUCOM</em>, <em>656</em>, 131536. (<a href='https://doi.org/10.1016/j.neucom.2025.131536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing demand for intelligent operation and maintenance of vertical mill gearboxes in the cement industry, traditional passive maintenance methods are increasingly inadequate for supporting efficient, proactive management under complex operational conditions. In particular, sudden gear failures often result in unplanned downtime, causing significant economic losses. To address this challenge, this paper proposes a dynamic control approach for gear remaining useful life (RUL) that integrates multi-source information through collaborative decision-making to enable active health management. First, a novel RUL prediction method based on multilevel multi-source domain adaptation (MMDA) is proposed to enhance the generalization capability of the model. By minimizing discrepancies between local and global feature distributions under varying working conditions and aligning the prediction boundaries among predictors, the proposed method achieves accurate RUL predictions. Then, a gear RUL dynamic control method based on multi-information collaborative decision-making is developed. This method dynamically regulates gear RUL using a model-free adaptive control (MFAC) strategy, leveraging multi-source information such as online RUL prediction results, expected usage duration, and real-time working conditions. Finally, a collaborative decision framework for dynamic control of gear RUL is proposed, which enables active gear health management to be implemented, thereby minimizing unscheduled downtime. The effectiveness of the proposed gear RUL dynamic control method is validated on a self-made gear transmission system experimental platform, achieving a 27.6 % reduction in average RMSE compared with state-of-the-art baselines and extending the operational life of gear by approximately 61 h under dynamic control.},
  archive      = {J_NEUCOM},
  author       = {Xuegang Li and Yuanyue Pu and Nian Wu and Huajun Cao and Xiaoxi Ding and Wenbin Huang},
  doi          = {10.1016/j.neucom.2025.131536},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131536},
  shortjournal = {Neurocomputing},
  title        = {A collaborative decision framework for dynamic control of gear remaining useful life using multi-source information in active health management},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A prototype-guided federated learning based fault diagnosis method of mechanical transmission system under label distribution skew. <em>NEUCOM</em>, <em>656</em>, 131532. (<a href='https://doi.org/10.1016/j.neucom.2025.131532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the label distribution skew in federated learning based mechanical fault diagnosis, a federated learning based diagnosis framework combining prototypes and hybrid classifier is proposed. Firstly, prototypes are constructed based on sample feature means, and an exponential moving average strategy is introduced to smooth the aggregation of prototypes across rounds, while the prototype constraint loss function is constructed to guide the convergence of client features to the global prototype and compress the distance between similar samples. Secondly, a hybrid classifier architecture combining a local classifier with a global prototype classifier is proposed to learn local feature and global class prototypes through a two-branch structure, and a dynamic weighting strategy is used to achieve the output fusion. Finally, a prototype separation strategy is introduced on the server side, which detects pairs of confused class prototypes by Euclidean distance, increases the distance between similar prototypes, and avoids the prototype overlapping issue. In order to verify the effectiveness of the proposed method, nine kinds of faults of bearings, rotors and gears in mechanical transmission system are fabricated, and four types of fault diagnosis experiments with different degrees of label skew are designed, and the results show that the proposed method can effectively identify all the fault classes, and it still achieves an accuracy of 91.00 % in the extreme distribution skew task, which is significantly better than the other comparative methods, which provides a new feasible way for the distributed data driven federated learning based intelligent mechanical fault diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Hongwei Fan and Shenglin Liu and Xiangang Cao and Xuhui Zhang},
  doi          = {10.1016/j.neucom.2025.131532},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131532},
  shortjournal = {Neurocomputing},
  title        = {A prototype-guided federated learning based fault diagnosis method of mechanical transmission system under label distribution skew},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A predefined-time double-integral zeroing neural network model for linear equations flows and its application on dynamic position. <em>NEUCOM</em>, <em>656</em>, 131531. (<a href='https://doi.org/10.1016/j.neucom.2025.131531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving time-varying linear equation flows presents a significant challenge in dynamic systems due to the continuously evolving coefficients, which undermine the effectiveness of traditional numerical methods. Moreover, the presence of external noise further exacerbates the difficulty of obtaining accurate solutions. To address these issues, this paper proposes a predefined-time double-integral zeroing neural network (PTDIZNN) model, inspired by the enhanced robustness of the conventional DIZNN framework. Specifically, a novel time-based gain is incorporated into the design of the DIZNN, ensuring predefined-time convergence of the proposed PTDIZNN model. A comprehensive theoretical analysis is conducted to verify its stability, convergence, and robustness properties. Furthermore, comparative simulations demonstrate that the PTDIZNN outperforms existing models in terms of solution accuracy and robustness under both column-full-rank and square-array coefficient scenarios. Finally, the effectiveness of the PTDIZNN is verified through its successful application in dynamic target positioning, highlighting its potential for broader real-time applications.},
  archive      = {J_NEUCOM},
  author       = {Jialiang Chen and Linju Li and Lin Xiao},
  doi          = {10.1016/j.neucom.2025.131531},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131531},
  shortjournal = {Neurocomputing},
  title        = {A predefined-time double-integral zeroing neural network model for linear equations flows and its application on dynamic position},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAFE-TAP: Semantic-aware and fused embedding for TAP rule security detection. <em>NEUCOM</em>, <em>656</em>, 131529. (<a href='https://doi.org/10.1016/j.neucom.2025.131529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trigger-Action Programming (TAP) has emerged as a widely adopted paradigm for enabling automated interoperability among IoT devices. Despite its convenience, TAP introduces significant security vulnerabilities. To address this issue, we propose SAFE-TAP, a novel framework for detecting malicious TAP rules that integrates global semantic understanding with temporal feature analysis. To further enhance the detection performance, we introduce an innovative data augmentation strategy that leverages Large Language Models (LLMs) to generate semantically consistent rule variations. This approach improves data set balance and enhances the generalizability of the model. Experimental results demonstrate that SAFE-TAP outperforms baseline methods, and the incorporation of LLM-based data augmentation significantly improves detection performance under imbalanced data scenarios.},
  archive      = {J_NEUCOM},
  author       = {Zhejun Kuang and Yusheng Zhu and Dawen Sun and Jian Zhao and Yongheng Xing and Feng Wang and Lei Sun},
  doi          = {10.1016/j.neucom.2025.131529},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131529},
  shortjournal = {Neurocomputing},
  title        = {SAFE-TAP: Semantic-aware and fused embedding for TAP rule security detection},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The framework and memristive circuit design for attention-regulated working memory. <em>NEUCOM</em>, <em>656</em>, 131525. (<a href='https://doi.org/10.1016/j.neucom.2025.131525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive behavior and decision-making depend on constantly selecting relevant information from the external environment and internal states. Inspired by the working memory structure and the top-down and bottom-up attention mechanisms in cognitive neuroscience, this work proposes an attention-regulated working memory model. This model provides a brain-inspired approach to integrate perception, long-term memory, and action. It processes current external multisensory stimuli and retrieves stored knowledge from internal reinforcement simultaneously, leading to adaptive and rapid executive actions. On this basis, a memristive circuit is designed to realize rich cognitive functions in an online in-situ learning and in-memory computing manner. The designed circuit consists of four main components: (1) the phonological loop and visuospatial sketchpad consider different audio-visual input patterns and varying stimulus salience, realizing the filtration, synchronization, and encoding of multimodal signals; (2) the attention control module captures and maintains attention driven by multisensory stimulation; (3) the episodic buffer achieves reward reinforcement, forming or resetting the top-down attentional bias signal; (4) the central executive control module regulates the relationships between the two attentional pathways, thus transforming the random exploration process into a learnable final action. Finally, simulation results in LTSPICE demonstrate that our circuit can be adaptively applied to the cognitive control and execution system of robots within complicated circumstances.},
  archive      = {J_NEUCOM},
  author       = {Jihong Zhang and Xiaoping Wang and Zhanfei Chen and Chao Yang},
  doi          = {10.1016/j.neucom.2025.131525},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131525},
  shortjournal = {Neurocomputing},
  title        = {The framework and memristive circuit design for attention-regulated working memory},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A temporally coded multilayer spiking neural network and its memristor-based hardware implementation. <em>NEUCOM</em>, <em>656</em>, 131523. (<a href='https://doi.org/10.1016/j.neucom.2025.131523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) have demonstrated remarkable progress in various domains. However, ANNs suffer from enormous time and energy consumption during training and inference processes. Brain-inspired spiking neural networks (SNNs) have recently attracted more attention due to their higher biological plausibility and potential cost-efficient properties. However, most existing SNNs significantly degrade in performance and efficiency when simulated on conventional CPU/GPU hardware. Therefore, a novel temporally coded multilayer SNN (TMSNN) is proposed in this study. It is a typical event-driven model, which encodes information in the relative timing of spikes rather than in firing rates and uses the leaky integrate-and-fire neuron as the basic unit to pursue high biological plausibility. Its multilayer architecture enables the model to solve complicated problems effectively. On the other hand, the proposed TMSNN can be implemented on memristor-based hardware, which uses customized weight quantization and sharing techniques to mitigate the size restrictions of the memristor crossbars. After refining the weights using the simulated annealing algorithm, the hardware implementation of TMSNN can achieve very competitive performance on benchmark datasets, outperforming state-of-the-art temporally coded SNNs in our experiments. The source code of TMSNN is available at https://github.com/jhc050998/Memristor-Crossbar-Based-SNN .},
  archive      = {J_NEUCOM},
  author       = {Haochang Jin and Xiuzhi Yang and Shuangbao Song and Zhenyu Song and Junkai Ji},
  doi          = {10.1016/j.neucom.2025.131523},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131523},
  shortjournal = {Neurocomputing},
  title        = {A temporally coded multilayer spiking neural network and its memristor-based hardware implementation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential extended dissipative synchronization control of Cohen–Grossberg neural networks with four kinds of time-varying delays. <em>NEUCOM</em>, <em>656</em>, 131522. (<a href='https://doi.org/10.1016/j.neucom.2025.131522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the exponential extended dissipative synchronization control problem of Cohen–Grossberg neural networks (CGNNs) with four kinds of time-varying delays. The types of delays involve time-varying leakage, neutral, distributed and transmission delays. Due to the increasing complexity of control requirements and time delays in practice, some performance analysis approaches and techniques cannot be directly applied, or are faced with the problem of high computational complexity. To this end, a more general and computationally efficient novel method is proposed. Firstly, a sufficient condition to guarantee the existence and uniqueness of the solution of CGNN is presented by defining a new norm, and a representation of the unique solution is first put forward. Then, the state-feedback controller and novel system solutions-based inequality are constructed to obtain exponential extended dissipative synchronization criteria. This proposed approach overcomes the difficulty of constructing a suitable Lyapunov–Krasovskii functional (LKF) under complex time delays and control requirements, and reduces computational complexity. Furthermore, to solve the nonlinear terms in the obtained criteria, an algorithm is designed. Finally, the derived results are validated for feasibility by three numerical examples, and their potential applications in image processing are showcased.},
  archive      = {J_NEUCOM},
  author       = {Kairong Tu and Yu Xue},
  doi          = {10.1016/j.neucom.2025.131522},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131522},
  shortjournal = {Neurocomputing},
  title        = {Exponential extended dissipative synchronization control of Cohen–Grossberg neural networks with four kinds of time-varying delays},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MLFork: Bearing fault diagnosis via mamba-powered few-shot learning model with multi-level architecture enhanced by spatial-wise and channel-wise local vector attention. <em>NEUCOM</em>, <em>656</em>, 131518. (<a href='https://doi.org/10.1016/j.neucom.2025.131518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearings are one of the most important components of electrical machines and devices; however, they are prone to damage, leading to the lack of safety and the malfunction of machines. Some methods including deep-learning ones can be used for bearing fault diagnosis; however, in reality, the models have to adapt to the shortage of training data from clients while still maintaining good performance. To overcome this issue, the novel “MLFork” model is proposed, following the Few-shot algorithm for limited training with improvements in the feature extraction and the pre-classification steps. For feature extraction, a new Bi-Context Visual State Space Block is introduced, which excellently learns the global context of the sample in multiple ways. Before the Multi-Level classification module, separate routes for spatial-wise and channel-wise local vector attention are used to highlight the important details of the local descriptor. To evaluate the performance of the model, various experiments were done on the Case Western Reserve University dataset (CWRU) and the Paderborn University dataset (PU), where the “MLFork" model showed promising results. The code for this model will be available at: https://github.com/thzhere/MLFork .},
  archive      = {J_NEUCOM},
  author       = {Duy-Thai Nguyen and Van-Quoc-Viet Nguyen and Thi-Thao Tran and Van-Truong Pham},
  doi          = {10.1016/j.neucom.2025.131518},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131518},
  shortjournal = {Neurocomputing},
  title        = {MLFork: Bearing fault diagnosis via mamba-powered few-shot learning model with multi-level architecture enhanced by spatial-wise and channel-wise local vector attention},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). All-in-one image restoration via diffusion models with degradation perception and semantic enhancement. <em>NEUCOM</em>, <em>656</em>, 131517. (<a href='https://doi.org/10.1016/j.neucom.2025.131517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration is a fundamental task in computer vision. However, most existing methods are tailored for single-degradation scenarios, limiting their applicability in real-world conditions where multiple degradations often co-occur. To address this issue, we propose a degradation-aware image restoration framework. A bidirectional Mamba module is introduced to process fused spatial-frequency features, enabling accurate identification of degradation types via a multi-degradation encoding strategy. Based on the predicted degradation, a fine-tuned CLIP model with an attention mechanism is employed to extract semantic features. These features are then integrated with degradation representations and fed into a conditional denoising diffusion model to progressively reconstruct high-quality images. To facilitate evaluation, we construct the Multi-Degradation Perception Dataset (MDPD), specifically designed for complex degradation scenarios. Experimental results demonstrate that our method achieves over 98 % classification accuracy in identifying degradation types. On the MDPD dataset, it achieves a PSNR of 36.25 dB and improves SSIM by 0.01 to 0.04 across various degradation combinations.},
  archive      = {J_NEUCOM},
  author       = {Jiangang Jiang and Zhe Chen and Yuxin Su and Pancheng Zhang and Yihui Hu},
  doi          = {10.1016/j.neucom.2025.131517},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131517},
  shortjournal = {Neurocomputing},
  title        = {All-in-one image restoration via diffusion models with degradation perception and semantic enhancement},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural operator-based composite learning adaptive backstepping control for linear 2×2 hyperbolic PDE systems. <em>NEUCOM</em>, <em>656</em>, 131516. (<a href='https://doi.org/10.1016/j.neucom.2025.131516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel neural operator (NO)-based composite learning adaptive backstepping control scheme for stabilizing uncertain linear 2 × 2 hyperbolic PDE systems. This method addresses key challenges arising from complex PDE dynamics, model uncertainties, and high computational costs, within a backstepping design framework. Our approach integrates two main components: 1) A composite learning adaptive controller, which combines both historical and real-time data to construct informative matrices for parameter updates. This strategy enables accurate and exponential parameter convergence under finite excitation (FE) conditions, thereby improving transient performance and guaranteeing exponential system stability. 2) An efficient NO-based approximation method, where a deep operator network (DeepONet) is trained to approximate the nonlinear mapping from composite parameter estimates to backstepping kernel gains. The controller is constructed using the approximate kernels, which eliminates the need to repeatedly solve kernel PDE online, significantly improving the computational efficiency and accelerating real-time control. Furthermore, theoretical analysis proves closed-loop boundedness and exponential stability under the proposed scheme. Numerical simulations verify its effectiveness and superiority.},
  archive      = {J_NEUCOM},
  author       = {Xianhe Zhang and Yu Xiao and Xiaodong Xu and Biao Luo and Weihua Gui and Tingwen Huang},
  doi          = {10.1016/j.neucom.2025.131516},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131516},
  shortjournal = {Neurocomputing},
  title        = {Neural operator-based composite learning adaptive backstepping control for linear 2×2 hyperbolic PDE systems},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RAG-LER: Ranking adapted generation with language-model enabled regulation. <em>NEUCOM</em>, <em>656</em>, 131514. (<a href='https://doi.org/10.1016/j.neucom.2025.131514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have demonstrated impressive capabilities across diverse NLP tasks, yet they still struggle with hallucination due to limited parametric knowledge. Retrieval Augmented Generation (RAG) addresses this issue by integrating non-parametric data stores. However, straightforward integration of information retrieval or end-to-end training of these components often leads to suboptimal results or computational inefficiency. In this work, we introduce RAG-LER, a framework that enhances an LM’s context understanding and improves the quality and accuracy of provided passages through an LM-supervised re-ranker. RAG-LER fine-tunes a pre-trained LM to follow instructions and discriminately use provided information. It then leverages this fine-tuned LM to generate ranking scores, which serve as supervised labels for training the re-ranker. We also introduce a confidence-weighted objective that filters unreliable LLM supervision signals while preserving the original re-ranker capabilities. By harnessing LLMs’ strong capabilities, our approach eliminates the need for manual human labeling in re-ranker training while achieving improved performance. Experiments demonstrate that RAG-LER outperforms existing retrieval-augmented LMs on open-domain QA and fact-checking tasks, while exhibiting consistently improved performance when applied to different retrieval methods, highlighting its versatility and effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Fengwen Zhai and Wenyang Tang and Jing Jin},
  doi          = {10.1016/j.neucom.2025.131514},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131514},
  shortjournal = {Neurocomputing},
  title        = {RAG-LER: Ranking adapted generation with language-model enabled regulation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental algorithms on low-rank approximation of large-scale kernel matrices based on perturbation of invariant subspaces. <em>NEUCOM</em>, <em>656</em>, 131512. (<a href='https://doi.org/10.1016/j.neucom.2025.131512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel methods are one of the most commonly used techniques in machine learning. In Mitz and Shkolnisky (2022) [27] , a framework of perturbation-based kernel matrix approximation is proposed, which is based on the tool of matrix perturbation analysis. However, there are two shortcomings in this framework. First, it requires that some dominant eigenvalues of kernel matrices are distinct in theory. However, in practical applications, when using a randomly sampled dataset, some kernel matrices generated by certain kernel functions are prone to having multiple eigenvalues due to data distribution or parameter settings. Second, from the algorithmic perspective, one has to know the error matrix of the kernel matrix in advance, which is unrealistic for real-world applications. Thus, the most common situation in practical applications is to pay attention to the case of multiple eigenvalues, and it is interesting to generalize the original perturbation-based kernel approximation framework to the scenario where there are multiple eigenvalues. In this work, we present a perturbation result on eigenvalues and eigenspaces of a kernel matrix whose dominant eigenvalues can be multiple. Based on this result, we propose a low-rank approximation to kernel matrix. On the other hand, as far as we are aware, efficient algorithms are still lacking for updating large-scale kernel matrices, and there are few algorithms addressing batch-incremental kernel methods. Based on our proposed truncated formula, we consider the incremental problem of large-scale kernel matrices and propose two incremental algorithms for updating large-scale kernel matrices. Numerical experiments demonstrate the efficiency of the proposed algorithms for solving incremental data problems and incremental kernel ridge regression.},
  archive      = {J_NEUCOM},
  author       = {Xiaxin Li and Gang Wu},
  doi          = {10.1016/j.neucom.2025.131512},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131512},
  shortjournal = {Neurocomputing},
  title        = {Incremental algorithms on low-rank approximation of large-scale kernel matrices based on perturbation of invariant subspaces},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FMSF: Future-preference modeling with similar-user features for next POI recommendation. <em>NEUCOM</em>, <em>656</em>, 131511. (<a href='https://doi.org/10.1016/j.neucom.2025.131511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abundant user check-in records in location-based social networks enhance the development of point-of-interest (POI) recommendation systems. The existing studies attempt to learn users’ past, current, and future preferences from their own sequential behaviors. Various approaches have been explored to model user visiting behaviors for the prediction of future preferences and have achieved considerable performance. However, most previous work ignores the impact of other users’ preferences on the prediction of current users’ future preferences. Thus, this work proposes a novel Future-preference Modeling with Similar-user Features (FMSF) model for next POI recommendation. It integrates the preferences of a user and those of other users to accurately model his/her multi-step future preferences. Specifically, it adopts a dynamically-updated similarity matrix to extract the information of similar users. Then, it incorporates an attention mechanism to assign distinct attention weights to the characteristics of both the current and similar users, which promotes the prediction of the future preferences of the current users. Therefore, the method proposed in this paper can offer users more precise recommendation results. Extensive experiments are conducted on three real-world datasets, which demonstrate the advantages of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Luan and Zhichao Feng and Liang Qi and Xiaoyu Sean Lu},
  doi          = {10.1016/j.neucom.2025.131511},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131511},
  shortjournal = {Neurocomputing},
  title        = {FMSF: Future-preference modeling with similar-user features for next POI recommendation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Permutation XOR cellular automata and direct stable periodic orbits. <em>NEUCOM</em>, <em>656</em>, 131510. (<a href='https://doi.org/10.1016/j.neucom.2025.131510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a permutation XOR cellular automaton (PXCA), a simple three-layer discrete-time dynamical system. The input-to-hidden layer corresponds to an elementary cellular automaton of the XOR rule and the hidden-to-output layer is the shift-type one-to-one permutation connection. The dynamics are described by an autonomous difference equation of binary state variables. Depending on the permutation connection, the PXCA generates a variety of direct stable periodic orbits (DBPOs) characterized by strong stability and fast transient phenomena. As a main result, we provide theoretical evidence that clarifies the number, period, and stability of DBPOs for general odd-dimensional PXCAs. Performing a precise numerical analysis, we have clarified that, depending on the dimension and a parameter, the period of DBPOs varies complicatedly and can become very long. Applications of the DBPOs include time series approximation and switching circuit control. As a fundamental step toward the applications, we present a simple FPGA based hardware prototype and have confirmed typical DBPOs experimentally.},
  archive      = {J_NEUCOM},
  author       = {Mikito Onuki and Yosuke Suzuki and Toshimichi Saito},
  doi          = {10.1016/j.neucom.2025.131510},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131510},
  shortjournal = {Neurocomputing},
  title        = {Permutation XOR cellular automata and direct stable periodic orbits},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal dynamic brain graph representation learning for brain disorder diagnosis via temporal sequence model. <em>NEUCOM</em>, <em>656</em>, 131509. (<a href='https://doi.org/10.1016/j.neucom.2025.131509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain network representation learning leverages graph-based algorithms to enhance understanding of functional brain organization. Recently, deep learning approaches based on graph neural network (GNN) have shown promising results in various brain network analysis tasks. Nevertheless, despite significant achievements in brain graph learning, early models still exhibit limitations in dynamic modeling and multi-modal network fusion. Dynamic modeling of brain networks entails learning sequential spatial interactions across time. Inspired by recent advances in large language model architectures, particularly RWKV, which combines the strengths of recurrent neural networks (RNNs) and Transformers. We propose an e fficient t emporal m ulti-modal g raph n eural n etwork (ET_MGNN), that captures complex temporal dependencies while integrating dynamic functional connectivity (DFC) and structural connectivity (SC) into a unified brain network representation. The proposed model demonstrates competitive performance in brain disorder classification on three datasets, outperforming several strong baselines. For instance, ET_MGNN an average classification accuracy improvement of 11.8 % on autism spectrum disorder (ASD) vs healthy controls, 32.9 % on Alzheimer's disease (AD) vs. mild cognitive impairment (MCI), compared to the well-suited STAGIN model. Furthermore, we introduce an interpretable graph reading mechanism that can identify disorder-relevant brain regions. In summary, ET_MGNN combines large-scale language sequence modeling with dynamic brain graph representation learning to improve the accuracy of brain disease diagnosis, providing insightful findings for dynamic brain network modeling.},
  archive      = {J_NEUCOM},
  author       = {Jinwei Lang and Li-Zhuang Yang and Hai Li},
  doi          = {10.1016/j.neucom.2025.131509},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131509},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal dynamic brain graph representation learning for brain disorder diagnosis via temporal sequence model},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PVFT-net: A point-voxel fusion method for self-supervised scene flow estimation with transformer. <em>NEUCOM</em>, <em>656</em>, 131508. (<a href='https://doi.org/10.1016/j.neucom.2025.131508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene flow estimation is a computer vision task that aims to estimate the 3D motion field of points from two consecutive frames of point clouds, and has a wide range of applications in various fields such as robotics and autonomous driving. Most of the existing methods estimate scene flow through point-based models, but ignore the irregularity of point clouds and the inefficiency of point-level computation. And voxel-based methods can hardly avoid the loss of detailed information. Therefore, we propose a point-voxel fusion method that contains a point branch and a voxel branch. The voxel branch projects the point cloud to regular local grids and captures coarse-grained local features from non-empty voxels through Sparse Grid Attention (SGA) with the shift window strategy. And the point branch captures fine-grained global features through dual attention consisting of Deformable Global Attention (DGA) and Channel Self-Attention (CSA), while compensating for the information loss in the voxel branch. Considering that it is difficult to directly describe the local geometric structure of complex objects in the scene with the shape of 3D objects potentially learned only through xyz coordinates, we explicitly encode the local surface information of the point cloud through the Umbrella Surface Feature Extraction (USFE) module. In addition, we introduce Density Sensitive Metric(DSM) loss to reduce the impact of outliers and density distribution mismatch problems. We validate the effectiveness of our method by performing experiments on the Flyingthings3D and KITTI datasets. Our method outperforms all other self-supervised methods and achieves highly competitive results compared to fully supervised methods. We achieve improvements in all metrics, especially EPE, which is decreased by 8.51 % on the KITTI o dataset and 15.79 % on the KITTI s dataset.},
  archive      = {J_NEUCOM},
  author       = {Xuezhi Xiang and Xi Wang and Xiaoheng Li and Xiankun Zhou and Lei Zhang and Xiantong Zhen},
  doi          = {10.1016/j.neucom.2025.131508},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131508},
  shortjournal = {Neurocomputing},
  title        = {PVFT-net: A point-voxel fusion method for self-supervised scene flow estimation with transformer},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text-to-image person re-identification via collaborating pre-trained diffusion and discriminative models. <em>NEUCOM</em>, <em>656</em>, 131505. (<a href='https://doi.org/10.1016/j.neucom.2025.131505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image person re-identification (TIReID) aims to retrieve pedestrian images from a database that match given text queries. Currently, the most advanced methods involve transferring powerful multi-modal knowledge from the contrastive language-image pretraining (CLIP) model to perform cross-modal matching. However, CLIP primarily focuses on coarse-grained global contextual modeling of single image-text pairs, neglecting fine-grained compositional matching of complex visual-textual concepts. This makes it challenging to ensure fine-grained cross-modal matching between pedestrians and text queries. To address this issue, a novel framework, Collaborating Pre-trained Diffusion and Discriminative Models (CPDD), is proposed in this work. The CPDD comprises three modules: a fine-grained features learning (FFL) module, a semantic consistency alignment (SCA) module, and a masked-text interactive modeling (MIM) module. Firstly, the FFL learns feature representations containing fine-grained matching information between images and text through the reverse denoising process of a diffusion model. Next, a semantic consistency loss is designed in the SCA, which ensures the semantic consistency between the fine-grained matching information and the input image and text information. Then, the MIM propagates fine-grained matching information into the visual- textual context by a cross-modal interactive encoder, achieving fine-grained matching between images and text and enabling fine-grained cross-modal matching. Extensive experiments on the CUHK-PEDES, ICFG-PEDES, and RSTPReid datasets show that the proposed method achieves significant performance improvements compared to current research results, achieving Rank-1 accuracy of 74.87 %, 63.31 %, and 61.26 %, respectively.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Zhang and Chenyue Xu and Huajing Wu and Quange Tan and Qianli Zhou and Rong Wang},
  doi          = {10.1016/j.neucom.2025.131505},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131505},
  shortjournal = {Neurocomputing},
  title        = {Text-to-image person re-identification via collaborating pre-trained diffusion and discriminative models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Layer-wise contrastive learning BERT for sentence representation of GitHub. <em>NEUCOM</em>, <em>656</em>, 131504. (<a href='https://doi.org/10.1016/j.neucom.2025.131504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every day, on GitHub, end-users submit a large number of issues that must be addressed to ensure the success of software projects. Though BERT-based pre-trained language models achieve high performance on many downstream tasks, the sentence representation of [CLS] from the top layer of BERT has a limited ability to capture the semantic meaning of sentences. GitHub issue reports often include code snippets and user-generated terms not found in standard vocabularies. Therefore, the classification predictions of BERT are affected. To generate better sentence semantic representations of BERT for GitHub, we propose a layer-wise Contrastive Learning BERT (CLBERT), which uses contrastive learning to enhance the representation ability by contrasting the layer-by-layer representation. Further, to obtain as comprehensive information as possible, representations of each layer are extracted and learned by an attention mechanism as the final classification features. Finally, experiments conducted on two GitHub data sets show that our proposed model significantly improves classification performance.},
  archive      = {J_NEUCOM},
  author       = {Daoquan Chen and Wei Zhang and Shengyu Lu and Yuanguo Lin and Xinyu Gu and Xiuze Zhou},
  doi          = {10.1016/j.neucom.2025.131504},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131504},
  shortjournal = {Neurocomputing},
  title        = {Layer-wise contrastive learning BERT for sentence representation of GitHub},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attacking all tasks at once using adversarial examples in multi-task learning. <em>NEUCOM</em>, <em>656</em>, 131503. (<a href='https://doi.org/10.1016/j.neucom.2025.131503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual content understanding frequently relies on multi-task models to extract robust representations of a single visual input for multiple downstream tasks. However, in comparison to extensively studied single-task models, the adversarial robustness of multi-task models has received significantly less attention and many questions remain unclear: (1) How robust are multi-task models to single task adversarial attacks, (2) Can adversarial attacks be designed to simultaneously attack all tasks in a multi-task model, and (3) How does parameter sharing across tasks affect multi-task model robustness to adversarial attacks? This paper aims to answer these questions through careful analysis and rigorous experimentation. First, we analyze the inherent drawbacks of two commonly-used adaptations of single-task white-box attacks in attacking multi-task models. We then propose a novel attack framework, Dynamic Gradient Balancing Attack (DGBA). Our framework poses the problem of attacking all tasks in a multi-task model as an optimization problem that can be efficiently solved through integer linear programming. Extensive evaluation on two popular MTL benchmarks, NYUv2 and Tiny-Taxonomy, demonstrates the effectiveness of DGBA compared to baselines in attacking both clean and adversarially trained multi-task models. Our results also reveal a fundamental trade-off between improving task accuracy via parameter sharing across tasks and undermining model robustness due to increased attack transferability from parameter sharing.},
  archive      = {J_NEUCOM},
  author       = {Lijun Zhang and Xiao Liu and Kaleel Mahmood and Caiwen Ding and Hui Guan},
  doi          = {10.1016/j.neucom.2025.131503},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131503},
  shortjournal = {Neurocomputing},
  title        = {Attacking all tasks at once using adversarial examples in multi-task learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolutional neural network combined with edge complexity and channel attention mechanism for unsupervised superpixel segmentation. <em>NEUCOM</em>, <em>656</em>, 131502. (<a href='https://doi.org/10.1016/j.neucom.2025.131502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Superpixel segmentation is crucial for enhancing image processing efficiency and accuracy. To address the challenges of decreased accuracy and insufficient stability in adaptive superpixel generation faced by existing algorithms in complex image segmentation, we propose ECN, an unsupervised superpixel segmentation algorithm based on convolutional neural networks (CNN) integrating edge complexity and channel attention mechanisms. The ECN algorithm first calculates edge complexity using the Sobel operator, which guides the sequential network in determining the number of feature channels and the kernel size of the fast 1D convolution. Subsequently, low-level features with positional information are transformed into deep features through the sequential network, dynamically adjusting the weights of each feature channel using the channel attention mechanism. Finally, the target function is minimized during inference, enabling unsupervised superpixel generation. We validate ECN's applicability by combining it with Linear Discriminant Analysis (LDA) and Locality Fisher Discriminant Analysis (LFDA) to develop Superpixel Unsupervised Linear Discriminant Analysis (SULDA). Experimental results on BSDS500 and NYUv2 datasets show ECN outperforms existing methods, producing stable and higher-quality superpixel segmentation. Application tests on Indian Pines and Pavia University scenes confirm ECN's significant practical utility.},
  archive      = {J_NEUCOM},
  author       = {Fugui Luo and Shihua Li and Minghui Chang and Yuting Liu and Kaitong Liu},
  doi          = {10.1016/j.neucom.2025.131502},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131502},
  shortjournal = {Neurocomputing},
  title        = {Convolutional neural network combined with edge complexity and channel attention mechanism for unsupervised superpixel segmentation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge distillation-based object detection model focused on road scene perception and localization. <em>NEUCOM</em>, <em>656</em>, 131501. (<a href='https://doi.org/10.1016/j.neucom.2025.131501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is crucial for unmanned systems, as it enables real-time classification and localization of objects in road scenes. Besides detection accuracy, which remains robust to variations in object scales, an effective object detection algorithm also demands superior performance in processing time. To address these issues, this paper proposes a knowledge distillation-based object detection model, PLE-RepPoints-Lite, to compromise the performance of detection accuracy and speed for unmanned systems. We also design perception and localization enhancement (PLE) strategies, which consist of parallel dynamic attention, multi-scale composite localization confidence, and a feedback closed-loop structure, to enhance the capabilities of perception and localization in complex road environments. To improve the real-time performance, a hybrid lightweight approach for road scenes is designed. Experimental results on the Cityscapes and BDD100K datasets show that our approach achieves state-of-the-art results with average precision (AP) of 34.6 and 40.1, respectively. Furthermore, it operates at 34.2 frames per second (FPS) at a 1280 × 640 resolution, satisfying real-time requirements.},
  archive      = {J_NEUCOM},
  author       = {Yufei Xie and Ying Shi and Changjun Xie and Qin Hu and Yue Liu and Chaojun Lin},
  doi          = {10.1016/j.neucom.2025.131501},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131501},
  shortjournal = {Neurocomputing},
  title        = {A knowledge distillation-based object detection model focused on road scene perception and localization},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confident neural network regression with bootstrapped deep ensembles. <em>NEUCOM</em>, <em>656</em>, 131500. (<a href='https://doi.org/10.1016/j.neucom.2025.131500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise in the popularity and usage of neural networks, trustworthy uncertainty estimation is becoming increasingly essential. One of the most prominent uncertainty estimation methods is Deep Ensembles [20]. A classical parametric model has uncertainty in the parameters due to the fact that the data on which the model is built is a random sample. A modern neural network has an additional uncertainty component since the optimization of the network is random. Lakshminarayanan et al. [20] noted that Deep Ensembles do not incorporate the classical uncertainty induced by the effect of finite data. In this paper, we present a computationally cheap extension of Deep Ensembles for the regression setting, called Bootstrapped Deep Ensembles , that explicitly takes this classical effect of finite data into account using a modified version of the parametric bootstrap. We demonstrate through an experimental study that our method significantly improves upon standard Deep Ensembles. The resulting confidence intervals demonstrate superior coverage without sacrificing accuracy.},
  archive      = {J_NEUCOM},
  author       = {Laurens Sluijterman and Eric Cator and Tom Heskes},
  doi          = {10.1016/j.neucom.2025.131500},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131500},
  shortjournal = {Neurocomputing},
  title        = {Confident neural network regression with bootstrapped deep ensembles},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameter-free multi-view clustering via refined tensor learning. <em>NEUCOM</em>, <em>656</em>, 131497. (<a href='https://doi.org/10.1016/j.neucom.2025.131497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As multi-view data becomes more prevalent in real-world applications, multi-view clustering (MVC) has emerged as a powerful technique for unsupervised representation learning. To uncover the intrinsic structure, it is crucial to consider information from different spaces. Focusing solely on the sample space limits the method’s ability to effectively model multi-view data, as the informative patterns embedded in the feature space are often overlooked. Furthermore, to integrate high-order correlations, tensor-based MVC methods have been widely adopted to preserve the low rank structure of multi-view data. Traditional tensors can not achieve selective tensor rank minimization as they lack an explicit mechanism to model the retention of singular values based on their individual information contributions. Additionally, existing methods rely on hyper-parameters, undermining generalizability across different datasets. In response to these limitations, we propose a novel Parameter-free Multi-view Clustering via Refined Tensor Learning (PRTL), which is based on bidirectional regression matrices to perform data reconstruction and extract salient features. To further achieve an adaptive low-rank tensor structure, we propose a Quadratic Decay Tensor (QDT) regularization as a non-convex alternative to conventional rank minimization, which selectively retains salient information while filtering out noise dynamically, resulting in a more expressive joint representation. Meanwhile, we incorporate the hyper-Laplace graph to capture richer relationships than those modeled by conventional pairwise graphs. Notably, PRTL eliminates the need for hyper-parameters, making it more practical and robust. Experiments on diverse datasets demonstrate that PRTL consistently surpasses existing state-of-the-art clustering methods. Our code is available at https://github.com/jiaxinyang04/PRTL .},
  archive      = {J_NEUCOM},
  author       = {Jiaxin Yang and Qian Liu and Yuemeng Huang and Chunyan Yang and Wengeng Chen and Yu Lu and Jiale Wang and Wenzhe Liu and Huibing Wang},
  doi          = {10.1016/j.neucom.2025.131497},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131497},
  shortjournal = {Neurocomputing},
  title        = {Parameter-free multi-view clustering via refined tensor learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extensive multi-variant deep neural network approach to enhance genomic prediction of endometriosis. <em>NEUCOM</em>, <em>656</em>, 131496. (<a href='https://doi.org/10.1016/j.neucom.2025.131496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have shown significant advancements in modelling complex non-linear relationships in high-dimensional biomedical data. Understanding the interplay between genetic variants and disease susceptibility is still a considerable challenge that prevents certain genomic diseases to be predicted accurately for clinical interventions. In this study, we introduce the Extensive Multi-Variant Deep Neural Network (EMV-DNN), an innovative deep learning methodology designed to enhance polygenic risk prediction. Unlike conventional polygenic risk score methods, EMV-DNN incorporates single nucleotide polymorphisms (SNPs) alongside structural variants including insertions and deletions (indels), short tandem repeats (STRs), and copy number variants (CNVs) using variant-specific subnetworks to extract informative embeddings which capture a richer and holistic genomic context. Evaluated on real-world cohorts from the UK Biobank and All of Us, EMV-DNN outperforms conventional PRS methods and classic machine learning algorithms across binary and multi-class prediction tasks. Beyond predictive performance, SHapley Additive exPlanations (SHAP) analysis revealed biologically plausible variant–gene–disease associations, highlighting pathways related to endometrial cell proliferation, fibrosis, and immune regulation. Our findings underscore the value of multi-variant integration and non-linear approaches to capture the intricate genetic architecture of complex genomic diseases. Despite challenges such as dataset limitations and the complexity of diseases with multiple contributing factors, the EMV-DNN methodology presents a promising avenue for enhancing the predictive accuracy of PRS, thereby facilitating personalized healthcare interventions and advancing our understanding of genetic predispositions to disease.},
  archive      = {J_NEUCOM},
  author       = {Zelia Soo and Hua Lin and Yue Yang and Mark Grosser and Mengjia Wu and Yi Zhang and Jie Lu},
  doi          = {10.1016/j.neucom.2025.131496},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131496},
  shortjournal = {Neurocomputing},
  title        = {An extensive multi-variant deep neural network approach to enhance genomic prediction of endometriosis},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised facial expression restoration and recognition method based on improved masked auto-encoder. <em>NEUCOM</em>, <em>656</em>, 131495. (<a href='https://doi.org/10.1016/j.neucom.2025.131495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a method for reconstructing occluded facial expressions. Firstly, a self-supervised learning Masked Auto-Encoder based facial expression recognition (MAE-FER) method is introduced, which effectively reduces the computational cost and parameter count by enhancing the multi-scale local-global self-attention interaction encoder, thereby improving the training efficiency and generalization capability of the model. Secondly, to address the problem of facial expression occlusion in real-world scenarios, a MAE-based occlusion detector is designed to detect occluded parts of the face, providing effective support for subsequent reconstruction tasks. Subsequently, the Dynamic Weight Allocation Generative Adversarial Network (DWA-GAN) for facial expression occlusion recovery is proposed, which achieves precise occlusion recovery by dynamically allocating weights to reference image blocks, significantly improving the accuracy of reconstruction. Finally, feature fusion is performed on the reconstructed results and applied to the FER task to further enhance classification accuracy and stability. Utilizing the pre-trained MAE-FER model, key hidden vectors are extracted from facial expression images, containing important feature information related to expression recognition. Through this step, closely related features to expression recognition are selected while irrelevant details are discarded, optimizing the inter-class distance issue of facial expressions. Next, to address the performance degradation caused by label ambiguity, an improved Rotate Erasing Attention Consistency (REAC) method is adopted, which effectively mitigates the negative impact of label ambiguity, further improving the accuracy and stability of FER. Experimental results demonstrate that the method achieves the best performance on the RAF-DB dataset.},
  archive      = {J_NEUCOM},
  author       = {Chaolong Zhang and Yuanping Xu and Zhijie Xu and Rongqiang Gou and Weiye Wang and Jin Jin and Jian Huang},
  doi          = {10.1016/j.neucom.2025.131495},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131495},
  shortjournal = {Neurocomputing},
  title        = {A self-supervised facial expression restoration and recognition method based on improved masked auto-encoder},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scattered data augmentation for generalization in visual reinforcement learning. <em>NEUCOM</em>, <em>656</em>, 131492. (<a href='https://doi.org/10.1016/j.neucom.2025.131492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation (DA) has shown a significant potential to enhance generalization performance in visual reinforcement learning (VRL). However, existing research on DA-based methods is predominantly empirical, and the mechanism for why DA enhances generalization remains theoretically under-explored. To bridge this gap, we derive a generalization error upper bound for VRL from the perspective of data distribution distance. Based on this bound, we provide a theoretical explanation of the mechanism by which DA improves generalization: we find that DA that satisfies certain conditions can reduce the distance between the training and test distributions, thus making the training and test samples closer. In addition, we conditionally prove that training data with higher variance can provide a higher generalization performance. Motivated by our analysis, we propose Scattered Data Augmentation (ScDA) framework. ScDA constructs a data transformation system with the agent serving as the discriminator, aiming to provide more diverse training data for agent training. Experiments are conducted across various tasks and numerous test modes in DeepMind Control Generalization Benchmark2 (DMC-GB2) and robotic tasks. Results demonstrate that our ScDA framework can be integrated with different baseline algorithms and significantly enhance policy generalization, outperforming the current state-of-the-art methods in the DMC-GB2 tests, confirming the effectiveness of the theoretical analysis in this work. The code for this work can be found at: https://github.com/scdadev/scdadev .},
  archive      = {J_NEUCOM},
  author       = {Hao Lei and Yu Zhao and Yi Xin and Zhang Shaonan and Ke Liangjun},
  doi          = {10.1016/j.neucom.2025.131492},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131492},
  shortjournal = {Neurocomputing},
  title        = {Scattered data augmentation for generalization in visual reinforcement learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monotonic convergence of adaptive caputo fractional gradient descent for temporal convolutional networks. <em>NEUCOM</em>, <em>656</em>, 131491. (<a href='https://doi.org/10.1016/j.neucom.2025.131491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fractional derivatives have gained prominence in optimization for their inherent non-locality and memory-dependent properties, effectively capturing historical dependencies. This work introduces an Adaptive Fractional-order Gradient Descent (AFGD) algorithm based on Caputo fractional derivatives, with deep integration into Temporal Convolutional Networks (TCNs). Unlike conventional fixed-order methods, AFGD employs an adaptive fractional-order mechanism to enhance optimization. Theoretically, we establish rigorous proofs for AFGD’s monotonic convergence in loss function minimization, supported by numerical simulations of its convergence behavior. Evaluated on the MIT-BIH arrhythmia five-class classification benchmark, TCNs optimized with AFGD achieve superior accuracy over established methods, demonstrating the efficacy of the proposed gradient scheme for deep learning optimization.},
  archive      = {J_NEUCOM},
  author       = {Zhiwei Xiao and Jiejie Chen and Xuewen Zhou and Bin Wei and Ping Jiang and Zhigang Zeng},
  doi          = {10.1016/j.neucom.2025.131491},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131491},
  shortjournal = {Neurocomputing},
  title        = {Monotonic convergence of adaptive caputo fractional gradient descent for temporal convolutional networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive PID-guided tensor wheel decomposition model for dynamic weighted network representation. <em>NEUCOM</em>, <em>656</em>, 131490. (<a href='https://doi.org/10.1016/j.neucom.2025.131490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Weighted Networks (DWN) usually appear in various big data-related complex systems and can describe real-time interactions between a large number of entities. As the number of entities increases dramatically, it is impossible for each entity to have complete interaction with each other, which results in such a DWN being High-Dimensional and Incomplete (HDI). Tensor Wheel Decomposition (TWD), as a novel tensor network, has powerful representation capabilities, but existing TWD-based methods require additional computational and storage costs to process an HDI DWN. To address these challenges, we propose an Adaptive integral separation PID–guided Tensor Wheel Decomposition (APTWD) model that: 1) employs a data density-oriented loss function, ensuring the representation learning is focused on the existing information in the target network to obtain more accurate low-rank embedding; and 2) develops a parameter learning scheme with error control feedback based on the integral separation PID controller to minimize the convergence iteration process. Experiments on six real-world DWN datasets demonstrate that APTWD consistently outperforms state-of-the-art methods, delivering higher representation accuracy and significantly reduced computational cost.},
  archive      = {J_NEUCOM},
  author       = {Jiqiu Chen and Qu Wang and Hao Wu},
  doi          = {10.1016/j.neucom.2025.131490},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131490},
  shortjournal = {Neurocomputing},
  title        = {An adaptive PID-guided tensor wheel decomposition model for dynamic weighted network representation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view unsupervised feature selection based on graph discrepancy learning. <em>NEUCOM</em>, <em>656</em>, 131487. (<a href='https://doi.org/10.1016/j.neucom.2025.131487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-view learning, unsupervised feature selection plays a vital role in reducing dimensionality while preserving discriminative information distributed across diverse data modalities. Despite notable progress, existing approaches frequently exhibit two key limitations: they often overlook the complementary benefits of integrating global and local structural information, and they inadequately model complex nonlinear relationships or align structural representations across views. To address these challenges, we propose a novel framework, termed Multi-view unsupervised feature selection based on graph discrepancy learning (GDFS). The proposed method jointly constructs global graph structures in a projected low-dimensional space and local graphs in a nonlinear kernel-induced space, effectively capturing both high-level semantic structures and fine-grained neighborhood dependencies. A graph discrepancy term is introduced to explicitly reduce structural discrepancies between global and local representations, thus enhancing consistency and robustness. In addition, a low-rank tensor constraint is applied to the stack of global graphs to uncover high-order correlations across views. A consensus clustering matrix is further learned to provide pseudo-label supervision, which guides the selection of discriminative features. Extensive experiments on six benchmark multi-view datasets demonstrate that GDFS consistently surpasses state-of-the-art methods in terms of clustering performance, thereby confirming its effectiveness, scalability, and generalizability. The code is available at https://github.com/xyw0111/2025-GDFS .},
  archive      = {J_NEUCOM},
  author       = {Yiwan Xu and Xijiong Xie and Xianliang Jiang and Yujie Xiong},
  doi          = {10.1016/j.neucom.2025.131487},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131487},
  shortjournal = {Neurocomputing},
  title        = {Multi-view unsupervised feature selection based on graph discrepancy learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel mixed-attribute data anomaly detection method based on granular-ball multi-kernel fuzzy rough sets. <em>NEUCOM</em>, <em>656</em>, 131486. (<a href='https://doi.org/10.1016/j.neucom.2025.131486'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rough sets have established a novel approach to anomaly detection through uncertainty handling. Nevertheless, traditional approaches are susceptible to noise. Existing kernelized methods improve feature representation via kernel transformations. However, they are typically restricted to a single-kernel framework, which limits the capacity to model the heterogeneous nature of mixed-attribute data. To address this issue, this study proposes a granular-ball generation algorithm tailored to the characteristics of mixed-attribute data. Multiple kernel functions are employed to effectively integrate the fuzzy relations of various attribute types. By integrating fuzzy rough set theory, granular-ball computing, and multi-kernel methods, a granular-ball multi-kernel fuzzy rough set model is proposed. Besides, a novel unsupervised anomaly detection method is proposed to effectively process mixed-attribute data. This method integrates kernelized fuzzy relations across various attribute types, constructs kernelized fuzzy information granules, and computes anomaly scores based on multiple granular-ball kernelized fuzzy information granules. Finally, an anomaly factor is introduced to quantify the anomaly degree of data objects. Comparative experiments were conducted on 16 public datasets. The novel approach consistently outperformed current methodologies in AUC metrics while demonstrating superior robustness across diverse data samples.},
  archive      = {J_NEUCOM},
  author       = {Cong Gao and Qiu Wang and Yanping Chen and Qingqi Pei and Zhongmin Wang},
  doi          = {10.1016/j.neucom.2025.131486},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131486},
  shortjournal = {Neurocomputing},
  title        = {A novel mixed-attribute data anomaly detection method based on granular-ball multi-kernel fuzzy rough sets},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-guided encoder-decoder network for soft sensor of copper matte grade in flash smelting process. <em>NEUCOM</em>, <em>656</em>, 131485. (<a href='https://doi.org/10.1016/j.neucom.2025.131485'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate real-time detection of copper matte grade is critical for state identification and optimization control in flash smelting, yet remains challenging due to the complex and harsh industrial environment. To address this issue, this study proposes a knowledge-guided encoder-decoder network. In this method, Bidirectional Gated Recurrent Unit serves as the backbone architecture for both the encoding and decoding processes, enabling nonlinear dynamic modeling in the temporal domain. The encoder integrates a composite variable attention mechanism, which leverages process knowledge to prioritize key variables based on their importance. A temporal decay attention mechanism is added to the decoder, endowing the model with the ability to simulate the temporal dependency between copper matte grade and process variables through prior knowledge. These knowledge-guided designs strengthen the ability of model to capture process-specific relationships between input variables and copper matte grade. Industrial experiments based on real production data from a smelting plant in China, show that the proposed model achieves optimal performance, with 96 % absolute errors not exceeding 0.5 %. It demonstrates that the proposed model not only provides accurate and real-time copper matte grade estimation but also maintains robustness in industrial environments, verifying its potential for practical application in flash smelting process.},
  archive      = {J_NEUCOM},
  author       = {Zhou Zou and Can Zhou and Chunhua Yang},
  doi          = {10.1016/j.neucom.2025.131485},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131485},
  shortjournal = {Neurocomputing},
  title        = {Knowledge-guided encoder-decoder network for soft sensor of copper matte grade in flash smelting process},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-resolution QP-adaptive generative face video compression using multi-level generator. <em>NEUCOM</em>, <em>656</em>, 131484. (<a href='https://doi.org/10.1016/j.neucom.2025.131484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a multi-resolution quantization parameter (QP)-adaptive generative face video compression (GFVC) framework to realize face video communication at an ultra-low bitrate. By leveraging deep generative models and semantic feature representation, the proposed framework achieves high perceptual quality while significantly reducing bitrate. The proposed framework dynamically adjusts feature granularity based on QP values and integrates modules such as multi-level multi-DConv head transposed attention (MDTA) and multi-level spatially adaptive denormalization (SPADE) to enhance both spatial fidelity and temporal consistency. To ensure adaptability and standardization, we further extend the proposed framework to support multi-resolution inputs and incorporate feature encoding based on Supplemental Enhancement Information (SEI) in VVC. Specifically, we introduce the flag gfv_enhancement_matrix_flag to transmit an optional 8 × 8 enhancement matrix, enabling precise refinement of inter-frame reconstruction in compliance with VVC. A multi-reference frame buffer mechanism is also implemented to improve long-term temporal coherence through attention-guided reference selection. Experimental results demonstrate that the proposed GFVC framework achieves average BD-rate gains of 63.87 % in DISTS and 61.99 % in LPIPS on benchmark datasets compared to the VVC anchor (VTM-22.2 LDB mode). Without retraining, the proposed framework operates smoothly even on face videos with a resolution of 512 × 512 , achieving 23.40 % BD-rate gain in DISTS and indicating strong scalability. These results validate the practical feasibility of the proposed GFVC framework in real-world video conferencing and telepresence scenarios, especially under ultra-low bandwidth conditions.},
  archive      = {J_NEUCOM},
  author       = {Wenbo Kang and Lu Liu and Cheolkon Jung},
  doi          = {10.1016/j.neucom.2025.131484},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131484},
  shortjournal = {Neurocomputing},
  title        = {Multi-resolution QP-adaptive generative face video compression using multi-level generator},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Filter bank convolutional network with dual channel attention for multi-class fine joint motor imagery decoding. <em>NEUCOM</em>, <em>656</em>, 131480. (<a href='https://doi.org/10.1016/j.neucom.2025.131480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective Motor imagery brain-computer interface (MI-BCI) is a representative BCI system. Recent studies in MI-BCI focus on Fine Joint MI (FJMI) decoding that recognizes the motor intention of different joints from one upper limb. However, due to the low spatial difference between EEG patterns of FJMI, achieving optimal performance remains a challenge of multi-class FJMI decoding studies. Methods: We proposed a novel approach named Filter Bank Convolutional Network with Dual Channel Attention (FB-DCANet) that enables feature extraction and selection in MI-EEG across multi-class FJMI tasks. This network features a combined filter bank in frequency and time domain that simultaneously extracts spatio-temporal information from four frequency bands (alpha, beta, theta, and low gamma), accompanied with temporal convolutional modules for additional temporal information extraction. Moreover, a feature selection method based on Dual Channel Attention was proposed combining preliminary intra-band feature selection via Residual Channel Self-Attention (RCSA) and further inter-band feature selection from different frequency bands by Efficient Channel Attention (ECA). Results: We performed experiments using FJMI-EEG data from the unilateral upper limb, and FB-DCANet achieved an accuracy of 59.34 % in a 4-class classification scenario (hand MI, elbow MI, shoulder MI, and resting state), and interpretability of FB-DCANet was analyzed by visualization of Class Activation Map (CAM) and attention values. Conclusion and Significance: This work presents a novel approach with a time-frequency filter bank and Dual Channel Attention-based feature selection for multi-class FJMI decoding, which can be utilized to develop a rehabilitation system based on FJMI-BCI.},
  archive      = {J_NEUCOM},
  author       = {Jiaming Chen and Yueqi Zhang and Kaide Liu and Xinkang Hu and Meng Xu and Dan Wang and Weibo Yi},
  doi          = {10.1016/j.neucom.2025.131480},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131480},
  shortjournal = {Neurocomputing},
  title        = {Filter bank convolutional network with dual channel attention for multi-class fine joint motor imagery decoding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Output-feedback synchronization of semi-markov jump two-time-scale neural networks: Dual event-triggered scheme. <em>NEUCOM</em>, <em>656</em>, 131479. (<a href='https://doi.org/10.1016/j.neucom.2025.131479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of synchronization control for semi-Markov jump two-time-scale neural networks, in which the output-feedback mechanism is adopted and a dual event-triggered scheme is employed using a double-rate sampling method to balance system performance and communication efficiency. First, considering the two-time-scale property of the semi-Markov jump neural networks, the dual-rate sampling strategy is adopted such that two independent event-triggered conditions for different time scales can be designed, which ensure efficient resource utilization while maintaining system performance. Then, a Lyapunov–Krasovskii functional with the singular perturbation parameter is constructed to deduce sufficient conditions ensuring that the synchronization error system is stochastically stable and satisfies a given H ∞ performance index. Moreover, the solution for obtaining the controller gains is presented to guarantee synchronization of the considered system under a dual event-triggered scheme. Finally, the feasibility of the methods is demonstrated by two examples, including a numerical example and an image encryption. They show that this event-triggered mechanism provides an efficient new synchronization control scheme for semi-Markov jump two-time-scale neural network systems while reducing the network burden.},
  archive      = {J_NEUCOM},
  author       = {Wenyan Zuo and Ya-Nan Wang and Feng Li and Sangmoon Lee},
  doi          = {10.1016/j.neucom.2025.131479},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131479},
  shortjournal = {Neurocomputing},
  title        = {Output-feedback synchronization of semi-markov jump two-time-scale neural networks: Dual event-triggered scheme},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient multi-view graph condensation via gradient-flow induced graph convolutional networks. <em>NEUCOM</em>, <em>656</em>, 131478. (<a href='https://doi.org/10.1016/j.neucom.2025.131478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning based on graph convolutional networks boosts performance by incorporating diverse perspectives, leading to significant achievements and successful applications across various academic and practical fields. However, multi-view graph convolutional networks suffer from substantial computational challenges on large-scale graphs. To address this limitation, graph condensation has emerged as a promising direction by creating a smaller composite graph that allows for efficient network training while preserving performance. Furthermore, previous studies have demonstrated that encouraging performance in graph learning is achieved via graph compression. To this end, we attempt to introduce graph condensation into the multi-view learning for computation acceleration. This approach not only reduces training costs significantly but also achieves sub-linear time complexity and memory consumption during network training. Further, we propose a gradient flow induced graph convolutional network from partial differential equations, which offers theoretical guarantees and potential new insights for the graph-related network architecture construction with transparent model interpretability. Extensive experiments on seven real-world multi-view datasets demonstrate that the proposed method sharply decreases model training time while ensuring competitive multi-view semi-supervised classification.},
  archive      = {J_NEUCOM},
  author       = {Lu Liu and Yang Huang and Yueyang Pi and Zhicheng Wei and Jinbo Li and Shiping Wang},
  doi          = {10.1016/j.neucom.2025.131478},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131478},
  shortjournal = {Neurocomputing},
  title        = {Efficient multi-view graph condensation via gradient-flow induced graph convolutional networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal bayesian regression with a non-informative prior: Order-recursive and incremental learning. <em>NEUCOM</em>, <em>656</em>, 131476. (<a href='https://doi.org/10.1016/j.neucom.2025.131476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal Bayesian regression (OBR) for data generated from a multidimensional vector autoregressive process of order p , denoted as VAR ( p ) , has a closed-form analytic expression that has been previously obtained. Despite the closed-form expressions to compute the “OBR-VAR”, in certain practical scenarios the computational cost involved in training OBR-VAR is a bottleneck. From a computational perspective, two common scenarios that incur excessive computational cost are: 1) given a set of training data, estimating the unknown model order p generally entails computing the OBR-VAR from scratch for every p in a range from 1 to a maximum value; and 2) in dynamic environments where data arrives sequentially, currently one must recompute OBR-VAR from scratch for every new upcoming observation. To address the first issue, in this paper, an order-recursive OBR-VAR regressor using QR decomposition is proposed. This method efficiently updates the regressor without recalculating it from scratch for each p , significantly reducing computational complexity while preserving model accuracy. Analytical results demonstrate that the proposed order-recursive method achieves a computational complexity reduction by a factor proportional to p , making it scalable to larger datasets and higher model orders. To address the second issue, an incremental version of the OBR-VAR algorithm is developed for real-time data processing. This method updates the regressor incrementally as new data points arrive, maintaining accuracy without the need for costly recomputation of key matrices. Its capability makes it well-suited for continuous-time data acquisition and streaming applications, where timely and accurate responses are critical. In all cases we assume an improper non-informative prior to model the case of having no prior knowledge about the problem. Theoretical analysis and empirical evaluations using synthetic and real datasets demonstrate that both methods significantly outperform the standard OBR-VAR algorithm in terms of computational complexity while preserving accuracy.},
  archive      = {J_NEUCOM},
  author       = {Samira Reihanian and Amin Zollanvari and Siamac Fazli},
  doi          = {10.1016/j.neucom.2025.131476},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131476},
  shortjournal = {Neurocomputing},
  title        = {Optimal bayesian regression with a non-informative prior: Order-recursive and incremental learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-stream GCN-based action recognition framework using trustworthy fusion decision from different skeleton descriptors. <em>NEUCOM</em>, <em>656</em>, 131475. (<a href='https://doi.org/10.1016/j.neucom.2025.131475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex motion processes, different human skeleton descriptors can characterize skeletal features across various dimensions. The frequency of spatiotemporal changes in different joints is largely influenced by the type of action. This paper presents a dual-stream GCN-based action recognition framework, which involves Slow-stream and Fast-stream networks to process skeletal features of different spatiotemporal change characteristics. In the parallel processing architecture of graph convolutional layers, adaptive adjacency matrices that strengthen spatial and temporal feature extraction are proposed to learn the implicit relationships between skeletal joints. Furthermore, different skeletal features have significantly varying impacts on the accuracy of action recognition. The Dirichlet distribution and an optimized Dempster combination rule are introduced for trustworthy decision when fusing multi-branch opinions obtained from different skeleton descriptors. Extensive experiments on three authoritative datasets demonstrate that the proposed method achieves state-of-the-art performance while reducing uncertainty in action recognition.},
  archive      = {J_NEUCOM},
  author       = {Wenrui Zhu and Donghui Shi and Junqi Yu},
  doi          = {10.1016/j.neucom.2025.131475},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131475},
  shortjournal = {Neurocomputing},
  title        = {A dual-stream GCN-based action recognition framework using trustworthy fusion decision from different skeleton descriptors},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous federated semantic segmentation. <em>NEUCOM</em>, <em>656</em>, 131470. (<a href='https://doi.org/10.1016/j.neucom.2025.131470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) offers a promising solution for semantic segmentation in scenarios involving data distribution across isolated clients. Despite recent advances, federated semantic segmentation (FSS) continues to face key challenges. One major issue is the shift from centralized to decentralized training, where diverse and limited local data hinder consistent pixel-level representation learning. Another challenge is data heterogeneity from imbalanced class distributions across clients, which weakens feature consistency and degrades global performance. These limitations often lead to inconsistent feature learning and degraded global performance. To address the challenges of class heterogeneity and insufficient pixel-level representation learning in FSS, we propose a novel pixel-aware FSS framework that improves local adaptation and semantic consistency. Specifically, we design a fine-tuning strategy that initializes each client with a lightweight pre-trained model and performs local updates over multiple epochs. This improves model adaptability to local distributions while reducing communication overhead. To further enhance semantic consistency across heterogeneous clients, we introduce a client clustering strategy based on pixel-level semantic features. Clients with similar class distributions are grouped to encourage consistent feature learning within clusters. Cluster-level training and aggregation are then followed by a global aggregation step, promoting more robust and aligned semantic understanding. Empirical evaluation across multiple benchmark datasets confirms that our method achieves consistently high segmentation precision and enhanced model adaptability in highly heterogeneous federated scenarios.},
  archive      = {J_NEUCOM},
  author       = {Chen Zhang and Jiarui Wang and Yu Xie and Xinlei Wang and Bin Yu},
  doi          = {10.1016/j.neucom.2025.131470},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131470},
  shortjournal = {Neurocomputing},
  title        = {Heterogeneous federated semantic segmentation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CBH-YOLO: A steel surface defect detection algorithm based on cross-stage mamba enhancement and hierarchical semantic graph fusion. <em>NEUCOM</em>, <em>656</em>, 131467. (<a href='https://doi.org/10.1016/j.neucom.2025.131467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of surface defects in steel materials plays a pivotal role in ensuring industrial production quality and operational safety. However, existing deep learning-based detection methods face significant challenges in steel surface defect detection, including limited receptive field coverage, inadequate multi-scale feature integration, and insufficient feature discrimination under complex backgrounds. To address these limitations, this work introduces CBH-YOLO, a novel steel surface defect detection algorithm. The proposed framework incorporates three fundamental innovation modules: (1) Cross-stage Mamba-Enhanced Multi-scale Convolution (CMMC) module, which synergistically combines the advantages of state space models with large kernel convolutions alongside adaptive attention mechanisms, substantially expanding receptive field coverage while enhancing multi-scale feature extraction capabilities; (2) Binary Amplification Matrix (BAM) module, which innovatively integrates FlexWave (FXW) dynamic activation functions with OmniScale (OSC) multi-scale perception mechanisms to achieve adaptive nonlinear feature mapping and refined representation; (3) Hierarchical Semantic Graph Fusion Network (HSGFN), which models high-order correlations among features through hypergraph structures combined with adaptive feature fusion mechanisms, enabling more effective multi-scale feature integration. Comprehensive experimental validation on NEU-DET and GC10-DET benchmark datasets demonstrates that CBH-YOLO achieves improvements of 2.7 % and 3.2 % in mAP@50 metrics compared to the baseline YOLOv11 model, while maintaining exceptional computational efficiency. This research provides a high-precision, high-efficiency solution for steel surface defect detection, offering significant theoretical value and practical application prospects.},
  archive      = {J_NEUCOM},
  author       = {Bo Gao and Jingcheng Tong and RongRong Fu and ZhenZhen Zhang and YiLin Yuan},
  doi          = {10.1016/j.neucom.2025.131467},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131467},
  shortjournal = {Neurocomputing},
  title        = {CBH-YOLO: A steel surface defect detection algorithm based on cross-stage mamba enhancement and hierarchical semantic graph fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMNet: Incomplete multi-modal alzheimer’s disease diagnosis with dual memory network. <em>NEUCOM</em>, <em>656</em>, 131465. (<a href='https://doi.org/10.1016/j.neucom.2025.131465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the challenge of missing modality, existing multi-modal learning methods become impractical and missing modality is a serious impediment to a good multi-modal learning performance. Meanwhile, we note that the existing methods for addressing missing modality issue tend to explore complete information by using either cross-generative approaches via simply filling in missing modality data, and do not consider the specific information, resulting in a sub-optimal performance for Alzheimer’s Disease diagnosis with multi-modal data. To address this problem, we propose a novel Dual Memory Network (DMNet) that comprises the Tabular Alignment Memory bank (TAM) and Dynamic Re-optimizing Memory bank (DRM) to complement the missing modality information in multi-modal learning for Alzheimer’s disease diagnosis. More specifically, TAM stores the information aligned with clinical tabular data, and maintains the feature distribution alignment between clinical tabular data and imaging modalities. Besides, TAM is updated by a memory aligning strategy. Then, DRM stores modality specific information from complete modalities, and we design a memory optimizing strategy that incorporates Feature Consistency (FC) loss and Memory Correspondence (MC) loss to update the memory items in DRM to effectively represent specific information of modalities. This novel dual memory network enhances model performance and improves model usability in multi-modal learning with missing modality, providing a more informative feature distribution to complement the missing modality. Extensive experiments, including quantitative and qualitative analyses, as well as various ablation studies, demonstrate that our proposed method achieves state-of-the-art performance in the classification task on the ADNI dataset.},
  archive      = {J_NEUCOM},
  author       = {Nana Jia and Zhiao Zhang and Tong Jia},
  doi          = {10.1016/j.neucom.2025.131465},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131465},
  shortjournal = {Neurocomputing},
  title        = {DMNet: Incomplete multi-modal alzheimer’s disease diagnosis with dual memory network},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WDWorm: A runtime-efficient and user-friendly GUI-based toolbox for experimenting with the nerve net of c. elegans. <em>NEUCOM</em>, <em>656</em>, 131464. (<a href='https://doi.org/10.1016/j.neucom.2025.131464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nerve net simulators of C. elegans heavily support research on its nerve net functionality by offering the possibility to conduct digital experiments instead of real ones. However, current software tools are complex and difficult to use for non-programmers. With WDWorm, we offer a user-friendly toolbox with graphical user interface for simulating and experimenting with C. elegans’ nerve net. It does not require an installation and allows for several modifications of the nerve net, including parameter changes for each neuron and connection or the deactivation of individual neurons. Furthermore, a comparison with other software tools highlights that WDWorm is currently the most runtime-efficient approach for simulating and digitally experimenting with C. elegans . To invite other developers and researchers, we provide the source code in an open-access format under a CC-BY 4.0 Creative Commons license. The code is publicly available at https://github.com/dsacri/WDWorm .},
  archive      = {J_NEUCOM},
  author       = {Sebastian Jenderny and Daniel Sacristán and Philipp Hövel and Christian Albers and Isabella Beyer and Karlheinz Ochs},
  doi          = {10.1016/j.neucom.2025.131464},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131464},
  shortjournal = {Neurocomputing},
  title        = {WDWorm: A runtime-efficient and user-friendly GUI-based toolbox for experimenting with the nerve net of c. elegans},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Curriculum learning-based slimmable cross-component prediction for video coding. <em>NEUCOM</em>, <em>656</em>, 131463. (<a href='https://doi.org/10.1016/j.neucom.2025.131463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-component prediction plays an important role in video coding, which aims to eliminate redundancy between color components under the guidance of luma information. Recently, learning-based cross-component prediction has made significant strides in performance. However, current cross-component prediction methods typically train models directly on a dataset with different types of data, which generally results in overfitting for the flat textured data and underfitting for the complex textured data. To improve coding performance without excessively increasing the complexity, a cost-effective attention-based slimmable cross-component prediction network (SCCPN) is proposed. Although trained as a single model, SCCPN is capable of being executed at different levels of capacity, resulting in varying prediction results tailored to data with different characteristics. With the goal of further improving the generalization capability and prediction accuracy of the network, a curriculum learning strategy combined with slimmable convolutions is then designed, which employs the classification of prediction difficulty to represent whether the texture is flat or complex, and fits complex data with a small number of additional parameters. An adaptive search strategy is also introduced to speed up the selection of channels for slimmable convolutions. Experimental results demonstrate that when integrated into H.266/Versatile Video Coding (VVC), SCCPN achieves up to −0.62 %/−3.34 %/−2.68 % BD-rate reductions on Y/Cb/Cr components, respectively, over the H.266/VVC anchor. The performance gain outperforms the state-of-the-art learning-based cross-component prediction methods, while the increased complexity in both encoding and decoding is lower than the other compared cross-component prediction methods using neural networks. Moreover, performance gain can also be observed when SCCPN is integrated into the latest reference software of Beyond VVC, with BD-rate reductions of −0.17 %/−1.00 %/−1.02 % on Y/Cb/Cr components respectively.},
  archive      = {J_NEUCOM},
  author       = {Chengyi Zou and Shuai Wan and Marc Gorriz Blanch and Luka Murn and Juil Sock and Fei Yang and Luis Herranz},
  doi          = {10.1016/j.neucom.2025.131463},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131463},
  shortjournal = {Neurocomputing},
  title        = {Curriculum learning-based slimmable cross-component prediction for video coding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Representative negative sampling for graph positive-unlabeled learning. <em>NEUCOM</em>, <em>656</em>, 131462. (<a href='https://doi.org/10.1016/j.neucom.2025.131462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph positive-unlabeled (GPU) learning is an important task that aims to develop binary classifiers using only positive and unlabeled nodes, which are commonly encountered in real-life applications. Although selecting reliable negative samples is a highly promising approach, it typically only selects high-confidence examples, which lack representativeness and fail to fully capture the diversity of the negative example space. To address this gap, our key insight, inspired by galactic dynamics, is to model the positive prototype center as a continuously evolving gravitational center maintained via a momentum moving average, just like the stars in the universe are always moving forward rather than remaining still. This dynamic anchor allows us to robustly define a reliable negative region—its “gravitational field”—for sampling representative “planets” (negative examples). We propose StarHunter-PU (SH-PU), a framework that operationalizes this insight by unifying graph representation learning with our dynamic, prototype-guided representative sampling algorithm. This ensures the sampled negatives are both diverse and informative, providing accurate information for training a robust binary classification model. Experimental results on real-world datasets show that our StarHunter-PU method significantly outperforms existing methods and even achieves competitive performance compared to fully labeled methods.},
  archive      = {J_NEUCOM},
  author       = {Luyue Wang and Xinyuan Feng and Rui Mao and Yin Li and Chunquan Liang},
  doi          = {10.1016/j.neucom.2025.131462},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131462},
  shortjournal = {Neurocomputing},
  title        = {Representative negative sampling for graph positive-unlabeled learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance and interpretability analysis of code generation large language models. <em>NEUCOM</em>, <em>656</em>, 131461. (<a href='https://doi.org/10.1016/j.neucom.2025.131461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Large Language Models (LLMs) are increasingly getting integrated into software development workflows, understanding their reliability, error patterns and interpretability in real-world development scenarios is crucial for establishing their practical utility. This study evaluates and interprets the performance of 15 open-source LLM models, including Code LLaMa, Granite Code, DeepSeek-Coder-V2, and Yi-Coder on code translation and generation from requirements using the Rosetta Code dataset across diverse programming languages and tasks. Syntactic correctness and code quality are quantified using metrics such as CodeBLEU, chrF, and METEOR. Interpretability is explored through Feature Ablation and Shapley Value Sampling to elucidate prompt processing mechanisms. Results indicate high syntactic correctness and quality scores for models such as DeepSeek-Coder-V2 and Yi-Coder, alongside observed sensitivities to specific prompt components. This research provides quantitative and qualitative insights into the capabilities and limitations of open-source code-generating LLMs, informing model selection and the understanding of LLM-generated code.},
  archive      = {J_NEUCOM},
  author       = {Vishnu S. Pendyala and Neha B. Thakur},
  doi          = {10.1016/j.neucom.2025.131461},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131461},
  shortjournal = {Neurocomputing},
  title        = {Performance and interpretability analysis of code generation large language models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing long-term memory in federated class continual learning with lightweight adapters. <em>NEUCOM</em>, <em>656</em>, 131459. (<a href='https://doi.org/10.1016/j.neucom.2025.131459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) collaboratively trains a global model by aggregating local model parameters rather than raw data. Traditional FL frameworks assume that data classes are predefined and static. However, clients often encounter continuous data streams with dynamically emerging classes in practical applications, leading to a phenomenon known as catastrophic forgetting. Federated Class-Continual Learning (FCCL) has been introduced to address this challenge but still suffers from significant performance deterioration in scenarios with expanding task scales, particularly for tasks learned in the distant past. We propose a novel FCCL framework leveraging lightweight adapters to mitigate catastrophic forgetting as the number of tasks scales. To tackle the challenge of long-term memory decline, we developed task-specific adapters for clients to enhance memory retention. Additionally, we developed an image generation method tailored for lightweight adapters and trained task discriminators using the generated images. This enables the automatic loading of lightweight modules during inference, reducing human intervention. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet achieve significant performance improvements ranging from 1.73 to 4.07 times compared to baseline methods, effectively mitigating catastrophic forgetting in class-scaling scenarios. The complete implementation is available at https://github.com/notaerfa/FCLORA .},
  archive      = {J_NEUCOM},
  author       = {Pan Wang and Ji Wang and Zhengyi Zhong and Weidong Bao and Yaohong Zhang and Jianguo Chen},
  doi          = {10.1016/j.neucom.2025.131459},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131459},
  shortjournal = {Neurocomputing},
  title        = {Enhancing long-term memory in federated class continual learning with lightweight adapters},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive granular-ball based density peak clustering. <em>NEUCOM</em>, <em>656</em>, 131458. (<a href='https://doi.org/10.1016/j.neucom.2025.131458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of data processing, the Granular-ball (GB) provides a coarse-grained data representation, offering a novel approach to improving clustering efficiency. The Fast Density Peak Clustering Algorithm based on Granular-balls (GB-DP) reduces computational granularity, which not only decreases operation time in large-scale data processing but also produces good clustering results. However, the GB-DP algorithm faces two main issues: sensitivity to the threshold parameter for generating GB and the requirement for manually selecting clustering centers, both of which affect the algorithm's efficiency and stability. To address these challenges, this paper proposes an Adaptive Granular-ball based Density Peak Clustering Algorithm (AGB-DP). First, a weighted Distribution Measure (DM) is used to dynamically generate GB. In contrast to the fixed threshold strategy used in GB-DP, this method effectively captures the data's distribution characteristics, mitigating the problem of parameter sensitivity. Second, by integrating two factors—data volume and geometric compactness—the density of GB is redefined, enhancing the accuracy of density calculations. Finally, an automatic screening strategy is employed to select GB as clustering centers, eliminating the instability introduced by manual intervention. Experimental results on both synthetic and real-world datasets demonstrate that AGB-DP, requiring only the number of clusters to be specified, achieves superior clustering results on most datasets compared to classical clustering algorithms and recent DP-based methods and shows greater robustness and stability.},
  archive      = {J_NEUCOM},
  author       = {Xingguo Zhang and Li Xu and Weikuan Jia},
  doi          = {10.1016/j.neucom.2025.131458},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131458},
  shortjournal = {Neurocomputing},
  title        = {Adaptive granular-ball based density peak clustering},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting the connections between images and deep feature vectors in model inversion attacks. <em>NEUCOM</em>, <em>656</em>, 131457. (<a href='https://doi.org/10.1016/j.neucom.2025.131457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model inversion attack aims to reconstruct private samples from given deep neural networks. As the connections between the images and their corresponding deep feature vectors are unknown, it is difficult to utilize the information in the feature vectors during inversion. In this paper, connections between the images and their deep convolutional feature vectors are investigated. The directions of the vectors are used to represent the structures of both image vectors and feature vectors. Cosine similarity is further used to measure the structural similarity between different vectors. For a given target feature extractor, we find that the structures of the images and their feature vectors are highly correlated. Using this-property, Aug-MIA is proposed to perform model inversion with a few leaked feature vectors. In Aug-MIA, the feature vectors are first augmented by the proposed Structure Augmentation Algorithm. Then, a reconstruction model is trained using these augmented feature vectors to reconstruct images. Various experiments are performed on different datasets to validate our ideas. The results show that Aug-MIA performs better when fewer feature vectors are available. Specifically, when only 1 feature vector per class is leaked, it can improve the reconstruction rate by about 10.7 % on FaceScrub and about 4.2 % on MNIST, respectively.},
  archive      = {J_NEUCOM},
  author       = {Zeping Zhang and Jie Huang},
  doi          = {10.1016/j.neucom.2025.131457},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131457},
  shortjournal = {Neurocomputing},
  title        = {Exploiting the connections between images and deep feature vectors in model inversion attacks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent-space diffusion models for stealthy and transferable adversarial attacks on object detection. <em>NEUCOM</em>, <em>656</em>, 131456. (<a href='https://doi.org/10.1016/j.neucom.2025.131456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tons of prior works have leveraged Generative Adversarial Networks (GANs) to synthesize adversarial examples that exhibit visual fidelity. Nonetheless, the intricacy of GANs’ latent space complicates the generation of imperceptible adversarial noises, rendering the process difficult to control. The emergence of diffusion models, which iteratively refine images through a progressive denoising mechanism, offers a more tractable and interpretable solution for a controllable generation. Inspired by this, we propose a latent-space-based covert adversarial attack framework (LSDM) grounded in diffusion models to craft adversarial examples that are both visually natural and highly effective against object detection models. Central to our approach is the Latent Space Perceptual Consistency Constraint, which ensures visual-consistency by embedding perturbations into the latent space for each denoising step, while utilizing the original image as a condition guider during the de-noising pass. Moreover, to balance attack performance and the risk of overfitting, we also propose a Stepwise Prediction and Adaptive Optimization strategy, which dynamically modulates the perturbations at the current time step and determines optimal number of diffusion time steps based on the transferability of the attack against diverse black-box models. To further enhance the framework’s attacking transferability, we introduce a novel Multi-box Translation Attack strategy, which augments the spatial location diversities for each bounding box. Extensive experiments demonstrate that, compared with state-of-the-art methods, LSDM further reduces the average black-box detection mAP by 1.52 %, while improving image quality scores by 1.71 % on object detection datasets such as COCO and VOC, showcasing superior attack effectiveness and visual fidelity. The source code is publicly available at https://github.com/LSDM .},
  archive      = {J_NEUCOM},
  author       = {Wenxuan Wang and Huihui Qi and Zhixiang Huang and Bangjie Yin and Peng Wang},
  doi          = {10.1016/j.neucom.2025.131456},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131456},
  shortjournal = {Neurocomputing},
  title        = {Latent-space diffusion models for stealthy and transferable adversarial attacks on object detection},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User intent disentanglement for multi-behavior recommendation via information bottleneck principle. <em>NEUCOM</em>, <em>656</em>, 131454. (<a href='https://doi.org/10.1016/j.neucom.2025.131454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-behavior recommendation systems have advanced rapidly by leveraging users’ diverse auxiliary behavior interactions to improve recommendations for the target behavior (a.k.a. purchase). While existing methods have made strides by integrating auxiliary behaviors with purchase histories to deliver high-quality recommendations, they often fail to identify spurious correlation intents within auxiliary behaviors that conflict with users’ target intents. Indiscriminately incorporating such correlations into the prediction of target intents may lead to performance degradation. To address this issue, we propose a Multi-Behavior Intent Disentanglement framework (MBID) for multi-behavior recommendation, which focuses on disentangling spurious correlation intents via the Information Bottleneck (IB) principle. In particular, we first design a time-sensitive spurious correlation coefficient to quantify spurious correlation intents and guide the subsequent multi-intent learning. Then, to disentangle spurious correlation intents, we propose a projection-based intent extraction method to decompose the genuine and spurious correlation intents within auxiliary behaviors. Based on this, we conceive an IB-based multi-intent learning task to disentangle the spurious correlation intents and transfer the genuine correlation intents from auxiliary behaviors into the target behavior, thereby obtaining high-quality representations of the target intent. Extensive experiments on three real-world datasets demonstrate that MBID significantly outperforms the state-of-the-art baselines by effectively disentangling the spurious correlation intents. We release our model implementation at: https://github.com/LokHsu/MBID .},
  archive      = {J_NEUCOM},
  author       = {Chenzhong Bin and Tongxin Xu and Feng Zhang},
  doi          = {10.1016/j.neucom.2025.131454},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131454},
  shortjournal = {Neurocomputing},
  title        = {User intent disentanglement for multi-behavior recommendation via information bottleneck principle},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PolyModNet: Advanced positional encodings and ethical bias mitigation in adaptive multimodal fusion for multilingual language understanding. <em>NEUCOM</em>, <em>656</em>, 131450. (<a href='https://doi.org/10.1016/j.neucom.2025.131450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural Language Understanding (NLU) plays a crucial role in Natural Language Processing (NLP), enabling machines to interpret and process human language across various applications. Despite advancements, challenges remain, including variations in data types, inconsistencies in labeling, computational demands, and biases in training datasets. These challenges emphasize the need for ethical and effective NLU solutions. To address these issues, the proposed PolyModNet combines techniques from NLP and computer vision to improve both text and image understanding. The model enhances data representation and compensates for limited training data using advanced augmentation methods such as mixup, gridmask, and positional encoding, optimized for Vision Transformer. By integrating RoBERTa-BERT and Vision Transformer, PolyModNet ensures accurate alignment of text and image features through Transformer-based encoding, specialized transformations, and structured positional encodings. Additionally, it employs a universal multilingual framework that enables language-independent retrieval and flexible task adaptation. Ethical concerns are addressed through bias detection and adversarial training, ensuring fairness in multimodal analysis. Extensive evaluations demonstrate the model’s effectiveness across multiple NLP tasks, achieving 85.71 % accuracy in sentiment analysis, strong text classification performance (CoLA: 64.1 %, SST2: 96.4 %), and high accuracy in text-image retrieval (R@1: 72.00, R@5: 89.25, R@10: 92.10). The model also delivers competitive results in multimodal translation (BLEU: 45.36, METEOR: 55.62) and cross-modal retrieval (text-to-image: R@1: 67.4, image-to-text: R@1: 82.3).},
  archive      = {J_NEUCOM},
  author       = {Shaharyar Alam Ansari and Mohd Anas Wajid and Mohd Arif and Mohammad Saif Wajid},
  doi          = {10.1016/j.neucom.2025.131450},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131450},
  shortjournal = {Neurocomputing},
  title        = {PolyModNet: Advanced positional encodings and ethical bias mitigation in adaptive multimodal fusion for multilingual language understanding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wavelet attention is all you need in multimodal medical image fusion. <em>NEUCOM</em>, <em>656</em>, 131448. (<a href='https://doi.org/10.1016/j.neucom.2025.131448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the multimodal medical image fusion, the fusion method based on frequency domain features is a research hotspot. However, “how to effectively enhance the high frequency and low frequency information in frequency domain?”, “how to fully interact the cross-modal spatial features in feature fusion?” are the keys to improve the fusion performance. To solve this problem, this paper proposes a multimodal medical image fusion network (WTA-Net) based on Wavelet Attention. The main innovations are as follows: Firstly, the Encoder-Decoder fusion network WTA-Net with dual-encoder and single-decoder is proposed. The network effectively capture the frequency domain features in different modal images and enhance the ability of information flow between modalities. Secondly, a Wavelet Attention(WA) is designed in the encoder, which effectively enhance the high frequency and low frequency information of the lesion. Thirdly, the Cross Modal Information Fusion Module(CMIFM) is designed in the fusion stage, which fully interactive cross-modal spatial features. Finally, experiments are performed on the Whole Brain Atlas dataset and the PET-CT lung dataset. In brain MRI images and PET images comparison experiment, IE, AG and EN evaluation indexes are improved by 18.92 %, 14 % and 18.25 %, respectively. In CT mediastinal window images and PET images comparison experiment, IE and SF evaluation indexes are improved by 12.08 % and 49.4 %, respectively, WTA-Net highlight the lession information, which has positive significance for computer-aided diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Tao Zhou and Mingzhe Zhang and Zhe Zhang and Jiaqi Wang and Yang Liu and Huiling Lu},
  doi          = {10.1016/j.neucom.2025.131448},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131448},
  shortjournal = {Neurocomputing},
  title        = {Wavelet attention is all you need in multimodal medical image fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-domain mutual compensation network for multi-modality image fusion. <em>NEUCOM</em>, <em>656</em>, 131443. (<a href='https://doi.org/10.1016/j.neucom.2025.131443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing research has demonstrated that fusing both spatial and frequency domain information from images can enhance fusion model performance, particularly in terms of saliency preservation and texture enhancement. However, designing effective fusion strategies to coordinate complementary information from both domains, while maximizing the unique characteristics and advantages of each and avoiding information conflict or redundancy, remains a challenge that requires further exploration and optimization. To address this issue, we propose a spatial–frequency Dual-Domain Mutual Compensation Network, termed D2Fusion. In our approach, the Mamba module serves as the core component of the spatial branch, capturing long-range dependencies to enhance the focus on the global spatial structure of input features. Simultaneously, the frequency branch utilizes fast Fourier Transform and convolutional neural networks to extract local texture details from the phase and magnitude components of the input features. Unlike traditional dual-branch networks, we introduce a novel phase fusion operation within the frequency branch, which combines phase information from different modalities to generate salient target features that complement and enhance the spatial features. Furthermore, to maximize the exchange of complementary characteristics between spatial, frequency, and salient target features, we design a Mutual Compensation Block (MCB) that accounts for feature differences and a decomposition loss function based on discrete cosine distance. The MCB facilitates compensatory fusion, while the decomposition loss function reduces feature similarity prior to compensation, maximizing the complementary information between domain features. Extensive experiments validate the superiority of our method, demonstrating that D2Fusion outperforms existing state-of-the-art approaches in both multi-modal image fusion and downstream task performance. The code for this framework is available at https://github.com/hz777xx/D2Fusion .},
  archive      = {J_NEUCOM},
  author       = {Jiwei Hu and Zhen Hu and Ping Lou and Kin-Man Lam and Qiwen Jin},
  doi          = {10.1016/j.neucom.2025.131443},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131443},
  shortjournal = {Neurocomputing},
  title        = {A dual-domain mutual compensation network for multi-modality image fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchor-aware representation learning for multi-view clustering. <em>NEUCOM</em>, <em>656</em>, 131441. (<a href='https://doi.org/10.1016/j.neucom.2025.131441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anchor-based multi-view clustering has garnered considerable attention in recent years owing to its ability to reduce computational overhead and enable efficient processing of large-scale datasets. However, existing anchor-based multi-view clustering models still present limitation: while orthogonality constraints are imposed on anchors to enhance their discriminative properties, the inherent relationships among anchors are neglected. To address this limitation, a novel Anchor-Aware Representation Learning for Multi-view Clustering (AARLMC) model is proposed. Specifically, anchor-wise self-representation learning is implemented, with orthogonality constraints applied to the anchor self-representation matrices to uncover intrinsic relationships among anchors. Furthermore, enhanced anchor representations are generated through this process. The anchor graphs are stacked into a third-order tensor with tensor nuclear norm constraint to explore the high-order correlations among multi-view data. Anchor-wise self-representation learning, enhanced anchor representations, and tensor representation are integrated into a unified framework. An optimization algorithm is developed to solve the proposed model. Comparative experiments on twelve benchmark datasets against thirteen state-of-the-art multi-view clustering methods demonstrate that the proposed model achieves superior performance. The source code is available on https://github.com/guowei1314/AARLMC .},
  archive      = {J_NEUCOM},
  author       = {Haotian Zhang and Wei Guo and Ruiyin Liu and Qiang Yang and Xuefei Xiao and Jilin Li and Gang Lei and Gang Chen},
  doi          = {10.1016/j.neucom.2025.131441},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131441},
  shortjournal = {Neurocomputing},
  title        = {Anchor-aware representation learning for multi-view clustering},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft-label generator based on classifier weights. <em>NEUCOM</em>, <em>656</em>, 131436. (<a href='https://doi.org/10.1016/j.neucom.2025.131436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft labels provide rich information between classes. Classification models obtain better generalization ability when soft labels are used as training targets in addition to hard ground-truth labels. In this paper, we propose a new approach named TarSamp to derive effective soft-targets only with the model’s classifier layer. This approach offers a simple, generic, and low-cost solution for soft label generation by fully leveraging the class-level semantics captured by the classifier layer and uncertainty injection with random sampling. We apply TarSamp to both teacher-free and teacher-available scenarios by using the classifier layer from the online model and a pre-trained teacher model, respectively. Extensive experiments on five standard image datasets are provided to evaluate the proposed approach for classifier training. TarSamp achieves more than 8 % accuracy on average for the teacher-free setting with ResNet-18, and gives on par performance by getting rid of querying to the teacher model in each forward pass during distillation for the teacher-available situation. Our results demonstrate that the proposed approach makes as a fundamental yet competitive baseline for a wide range of soft label based supervised learning.},
  archive      = {J_NEUCOM},
  author       = {Xinkai Chu and Jian-Ping Mei and Hang Zhou and Jie Chen and Rui Yan and Jing Fan},
  doi          = {10.1016/j.neucom.2025.131436},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131436},
  shortjournal = {Neurocomputing},
  title        = {Soft-label generator based on classifier weights},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CESDet: Hard pedestrian object detection architecture based on the cognitive experience of structure of human body. <em>NEUCOM</em>, <em>656</em>, 131429. (<a href='https://doi.org/10.1016/j.neucom.2025.131429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional deep learning pedestrian detection methods usually only use the information of the current image itself. Incorrect results that go against common sense are prone to occur when dealing with hard objects with small size, unusual pose, or occlusions. Recent approaches try to enhance the hard objects by constructing and utilizing empirical information. However, due to an insufficient understanding of human body structure, the constructed experience exhibits poor generalization ability to diverse poses. Furthermore, when leveraging experiential features to enhance the features of hard objects, the process is susceptible to interference from occlusions and background. Inspired by human vision, we propose CESDet, a novel pedestrian detection network that constructs and utilizes Cognition Experience of Structure of human body in an unsupervised manner. The key technical innovations are three folds: (1) an unsupervised Cognition Experience of Structure construction module that addresses pose generalization by automatically forming decoupled body parts and pose semantics, (2) a part-level fine-grained verification and feature enhancement module that addresses the interference of occlusions and background with the guidance of Cognition Experience of Structure, and (3) an end-to-end pedestrian detection network for hard objects based on the two proposed modules. Experiments comparing with seven methods on three datasets demonstrate that CESDet achieves state-of-the-art performance, with highest AP on the training dataset, and lowest degradation of AP on a novel unseen dataset. The proposed framework advances the detection of hard objects by exploiting the automatically constructed Cognition Experience of Structure with decoupled part-level appearance and pose.},
  archive      = {J_NEUCOM},
  author       = {Yanglin Pu and Xiaohui Hao and Shan Yang and Hangyuan Yang and Shengxin Dai},
  doi          = {10.1016/j.neucom.2025.131429},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131429},
  shortjournal = {Neurocomputing},
  title        = {CESDet: Hard pedestrian object detection architecture based on the cognitive experience of structure of human body},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-related potential extraction workflow based on kernel density estimation. <em>NEUCOM</em>, <em>656</em>, 131425. (<a href='https://doi.org/10.1016/j.neucom.2025.131425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event-related potentials (ERPs) are a critical neuroscientific tool for investigating brain responses to external stimuli and serve as a key linking mechanism in brain–computer interface systems. Traditional ERP extraction methods rely on threshold-based trial rejection and time-locked averaging techniques, which often have limited ability to handle outlier data and are susceptible to random artifacts. To address this, we propose a novel ERP extraction workflow based on kernel density estimation. We construct trial-wise datasets at the sampling-point granularity and model the probability distribution of each trial using Gaussian kernel density estimation, effectively reducing outlier influence while preserving all trial data. The fitted probability density function serves as the objective function for ERP extraction, enabling active reconstruction of optimal ERP waveforms by incorporating inherent EEG temporal dependencies. Specifically targeting uneven noise distribution across multiple channels, we introduce an adaptively steering kernel dynamically generated from electrode covariance matrices, which optimizes the adaptive matching of inter-channel noise structures to ensure more precise density function fitting. Using two real datasets and simulated datasets, our comparative analyses of baseline root mean square error, component-level statistical metrics, and residual correlations demonstrate that, compared with the traditional trial rejection and time-locked averaging methods, our approach exhibits outstanding effectiveness in isolating ERP components from raw signals and significantly reduces the impact of outlier contamination.},
  archive      = {J_NEUCOM},
  author       = {Weizhuang Kong and Zihao Zhang and Jing Zhu and Yizhou Li and Xiaowei Li and Bin Hu},
  doi          = {10.1016/j.neucom.2025.131425},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131425},
  shortjournal = {Neurocomputing},
  title        = {Event-related potential extraction workflow based on kernel density estimation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view optimization and refinement for high-fidelity 4D gaussian splatting. <em>NEUCOM</em>, <em>656</em>, 131424. (<a href='https://doi.org/10.1016/j.neucom.2025.131424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing dynamic 3D scenes from 2D images and synthesizing temporally diverse views is challenging due to the interplay between scene complexity and temporal dynamics. While 3D Gaussian Splatting offers an efficient solution for static scene modeling, extending it to dynamic scenes faces significant challenges in motion representation and texture fidelity. We propose a novel framework based on multi-view interpolation and joint optimization to address these challenges in sparse-view dynamic scenes. This framework combines linear and spherical interpolation strategies to generate novel views, producing high-quality interpolated images from multiple fitted viewpoints. Additionally, it incorporates consistency constraints to optimize texture representation, enhancing the reconstruction performance for dynamic scenes. Experimental results demonstrate that the proposed framework significantly improves detail fidelity and motion representation in dynamic scene reconstruction.},
  archive      = {J_NEUCOM},
  author       = {Jinhui Lin and Zhenyang Wei and Silei Shen and Fang Zhou and Xiaobin Zhu and Xu-Cheng Yin},
  doi          = {10.1016/j.neucom.2025.131424},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131424},
  shortjournal = {Neurocomputing},
  title        = {Multi-view optimization and refinement for high-fidelity 4D gaussian splatting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KD-KI: Knowledge distillation with knowledge infusion for anomaly detection and localization. <em>NEUCOM</em>, <em>656</em>, 131423. (<a href='https://doi.org/10.1016/j.neucom.2025.131423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection and localization are crucial for improving product reliability in industrial quality inspection. Existing knowledge distillation methods often cause student networks to merely mimic features of teacher networks, which makes it difficult to achieve stable and generalized detection performance. This paper introduces the KD-KI framework, which uses a knowledge infusion mechanism to transfer structured hierarchical knowledge from the teacher network to the student network. This guides the student to learn more robust representations of normal samples. Additionally, a feature bias loss is used to optimize the similarity of shallow-layer features, improving detection accuracy and localization precision. KD-KI can be deployed with standard convolutional networks and is suitable for real-time industrial inspection systems. Experimental results demonstrate that the proposed KD-KI model can yield improved performance in anomaly detection and localization compared to other competing models.},
  archive      = {J_NEUCOM},
  author       = {Wei Huang and Zhaonan Xu and Rongchun Wan and Xuhua Yang and Bingyang Zhang},
  doi          = {10.1016/j.neucom.2025.131423},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131423},
  shortjournal = {Neurocomputing},
  title        = {KD-KI: Knowledge distillation with knowledge infusion for anomaly detection and localization},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFCon: Dominant frequency enhanced ultra-long time series contrastive forecasting. <em>NEUCOM</em>, <em>656</em>, 131418. (<a href='https://doi.org/10.1016/j.neucom.2025.131418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultra-long time series forecasting (ULTSF) is crucial for fields like energy management, traffic planning, and climate prediction. However, as the forecast horizon increases, concept drift becomes a major challenge, as a fixed-length historical window struggles to generalize ultra-long temporal patterns. Extending the input series length increases computational costs and demands a higher model capacity for capturing longer temporal dependencies. To address these issues, we propose DFCon, a dominant frequency enhanced contrastive learning framework for ULTSF. DFCon combines dilated convolutions for feature extraction and multi-layer perceptrons for forecasting, with a dual contrastive loss based on dominant frequency enhancement. We introduce Temporal DFCon, which enhances the model’s sensitivity to these frequency-domain features during training, thereby improving its ability to model global temporal dependencies in the input series. Furthermore, cross-window Autocorrelated DFCon is proposed, which mitigates concept drift by constructing autocorrelated relative positive and negative samples without introducing noisy data. Experiments on five benchmark datasets show that DFCon outperforms existing methods, demonstrating its effectiveness in ULTSF. The code for this work is publicly available at: https://github.com/coding4qq/DFCon .},
  archive      = {J_NEUCOM},
  author       = {Qiaoqiao Liu and Hui Liu and MingJie Yang and Yuheng Wei and Junzhao Du},
  doi          = {10.1016/j.neucom.2025.131418},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131418},
  shortjournal = {Neurocomputing},
  title        = {DFCon: Dominant frequency enhanced ultra-long time series contrastive forecasting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Breaking the alignment barrier: A spatiotemporal alignment-free RGBT tracking approach. <em>NEUCOM</em>, <em>656</em>, 131382. (<a href='https://doi.org/10.1016/j.neucom.2025.131382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-Thermal (RGBT) tracking leverages complementary information from visible and infrared modalities to improve tracking robustness in complex environments. However, its practical deployment remains constrained by the stringent requirement for precise spatiotemporal alignment between heterogeneous modalities—a condition rarely satisfied in real-world applications. To overcome this limitation, we present SAFNet, a novel Spatiotemporal Alignment-Free Network that eliminates the need for precise cross-modal alignment through innovative architectural designs. Our framework develops a spatiotemporal interaction query module incorporating cross-modal temporal attention, which re-establishes inter-modal temporal correlations for unregistered inputs by leveraging similarity learning across asynchronous data streams. For spatial discrepancy mitigation, we propose a dual-branch pre-tracking network employing deep cross-correlation analysis, combined with an adaptive feature fusion strategy under the guidance of joint response distribution. Furthermore, we devise an innovative dynamic template update mechanism that adaptively adjusts modal update rates to maintain temporal consistency across heterogeneous data streams. Comprehensive evaluations validate SAFNet’s state-of-the-art performance across four benchmark datasets (GTOT, RGBT210, RGBT234, LasHeR), demonstrating significant improvements in tracking accuracy. The proposed architecture represents a significant advancement toward practical deployment of robust RGBT tracking systems in real-world environments with asynchronous multimodal inputs.},
  archive      = {J_NEUCOM},
  author       = {Xiaodong Liu and Meibo Lv and Daming Zhou and Lingyu Si and Ruiheng Zhang and Hui Xu},
  doi          = {10.1016/j.neucom.2025.131382},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131382},
  shortjournal = {Neurocomputing},
  title        = {Breaking the alignment barrier: A spatiotemporal alignment-free RGBT tracking approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring cycle cover variants: A dataless neural networks approach. <em>NEUCOM</em>, <em>656</em>, 131361. (<a href='https://doi.org/10.1016/j.neucom.2025.131361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cycle Cover, a fundamental concept in graph theory, plays a critical role in various applications, including network design, transportation optimization, and bioinformatics. A Cycle Cover is a collection of cycles covering all the vertices of a given graph, ensuring that each vertex belongs to exactly one cycle. In this paper, we explore various aspects of Cycle Cover variants. We employ the dataless neural networks framework to establish single differentiable functions for each of these variants. Recent research has demonstrated the capability of the dataless neural networks framework in representing a host of combinatorial optimization problems. Motivated by these findings, we propose dataless neural networks tailored for the Cycle Cover variants. Additionally, we present a rigorous proof of the correctness of our approach.},
  archive      = {J_NEUCOM},
  author       = {Sangram K. Jena and K. Subramani and Alvaro Velasquez},
  doi          = {10.1016/j.neucom.2025.131361},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131361},
  shortjournal = {Neurocomputing},
  title        = {Exploring cycle cover variants: A dataless neural networks approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight deep learning for visual perception: A survey of models, compression strategies, and edge deployment challenges. <em>NEUCOM</em>, <em>656</em>, 131357. (<a href='https://doi.org/10.1016/j.neucom.2025.131357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for the deployment of deep neural networks (DNNs) in edge devices has led to the development of lightweight deep learning (LDL) models designed to operate efficiently under resource constraints. Although DNNs have achieved remarkable success in various applications, their high computational requirements often limit their deployment on devices with restricted memory and processing power. This challenge has motivated researchers to develop optimized LDL models that balance accuracy, speed, and efficiency while maintaining competitive performance. Despite existing surveys covering specific aspects of LDL models, a comprehensive review encompassing image classification, object detection, and segmentation remains limited. This proposed survey systematically explores recent advancements in LDL models, highlighting their architectures, optimization techniques, and real-world applications. This survey conducts an empirical evaluation by testing latest state-of-the-art LDL models on the Jetson Orin edge device using benchmark datasets: ImageNet for classification, VisDrone for object detection, and COCO for segmentation. The experimental analysis focuses on key performance metrics, including inference speed, model accuracy, and computational efficiency, while comparing LDL models with their conventional counterparts. This study provides a holistic understanding of the role of LDL models in edge computing, providing insight into emerging trends, challenges, and future research directions in the field.},
  archive      = {J_NEUCOM},
  author       = {Syed Muhammad Raza and Syed Murtaza Hussain Abidi and Md Masuduzzaman and Soo Young Shin},
  doi          = {10.1016/j.neucom.2025.131357},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131357},
  shortjournal = {Neurocomputing},
  title        = {Lightweight deep learning for visual perception: A survey of models, compression strategies, and edge deployment challenges},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LaSNN: Layer-wise ANN-to-SNN distillation for effective and efficient training in deep spiking neural networks. <em>NEUCOM</em>, <em>656</em>, 131351. (<a href='https://doi.org/10.1016/j.neucom.2025.131351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are biologically realistic and practically promising in low-power computation because of their event-driven mechanism. Usually, the training of SNNs suffers from accuracy loss on various tasks, yielding an inferior performance compared with ANNs. A conversion scheme is proposed to obtain competitive accuracy by mapping trained ANNs’ parameters to SNNs with the same structures. However, an enormous number of time steps are required for these converted SNNs, thus losing the energy-efficient benefit. Utilizing both the accuracy advantages of ANNs and the computing efficiency of SNNs, a novel SNN training framework is proposed, namely layer-wise ANN-to-SNN knowledge distillation (LaSNN). In order to achieve competitive accuracy and reduced inference latency, LaSNN transfers the learning from a well-trained ANN to a small SNN by distilling the knowledge rather than converting the parameters of ANN. The information gap between heterogeneous ANN and SNN is bridged by introducing the attention scheme. The knowledge in an ANN is effectively compressed and then efficiently transferred by utilizing our layer-wise distillation paradigm. We conduct detailed experiments to demonstrate the effectiveness, efficacy, and scalability of LaSNN on three benchmark data sets (CIFAR-10, CIFAR-100, and Tiny ImageNet). We achieve competitive top-1 accuracy compared to ANNs and faster inference than converted SNNs with similar performance. More importantly, LaSNN is dexterous and extensible that can be effortlessly developed for SNNs with different architectures/depths and input encoding methods, contributing to their potential development.},
  archive      = {J_NEUCOM},
  author       = {Di Hong and Yu Qi and Yueming Wang},
  doi          = {10.1016/j.neucom.2025.131351},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131351},
  shortjournal = {Neurocomputing},
  title        = {LaSNN: Layer-wise ANN-to-SNN distillation for effective and efficient training in deep spiking neural networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing spatio-temporal information using supervised local low-rank correlation embedding for depression recognition. <em>NEUCOM</em>, <em>656</em>, 131350. (<a href='https://doi.org/10.1016/j.neucom.2025.131350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) signals contain rich spatio-temporal information that reflects the brain’s dynamic activity, making it widely used in depression recognition. However, effectively integrating this information to capture discriminative and complementary features remains a key challenge. To address this issue, we propose a novel Discriminative Local Low-Rank Correlation Embedding (DLLCE) to fuse spatio-temporal information of EEG. DLLCE integrates shared low-rank representation, local invariance, discriminative constraints, and enhanced correlation analysis into a unified framework. Specifically, the shared low-rank representation is used to capture the common structural patterns, while the correlation analysis aims to reduce redundancy among feature sets. In addition, the Laplacian regularization is applied to the shared representation to preserve the local geometric structure of the original data. To further enhance discriminative capability, a discriminant graph embedding term is incorporated to exploit label information. Experimental results on EEG datasets demonstrate that DLLCE achieves superior performance compared to existing methods. This work provides new insights into EEG-based mental health assessment and holds promise for early depression diagnosis and clinical decision support.},
  archive      = {J_NEUCOM},
  author       = {Lu Zhang and Peng Xu and Zhijun Yao and Xinyan Zhang and Juan Wang and Bin Hu and Gang Feng and Hong Peng},
  doi          = {10.1016/j.neucom.2025.131350},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131350},
  shortjournal = {Neurocomputing},
  title        = {Fusing spatio-temporal information using supervised local low-rank correlation embedding for depression recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-driven baseline for few-shot fine-grained visual recognition. <em>NEUCOM</em>, <em>656</em>, 131302. (<a href='https://doi.org/10.1016/j.neucom.2025.131302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot fine-grained visual recognition (FS-FGVR), a practical yet challenging task, aims to break the dilemma of having scarce training examples for new fine-grained tasks. Meta-learning-based methods target this issue by employing the learning-to-learn strategy to train a well-generalized meta-learner from seen fine-grained tasks for unseen fine-grained tasks. However, most existing works rely too much on small-scale fine-grained training tasks. Specifically, these works demand large amounts of fine-grained data to sample these training tasks, and they are unable to generalize well to new tasks. Consequently, model capacity can be highly restricted when limited training references are available. This paper presents a novel coarse-to-fine framework named Knowledge-Driven baseline for FS-FGVR by transferring knowledge from large-scale and coarse-grained datasets. This framework departs the meta-training phase into the coarse-grained meta-pretraining and fine-grained meta-finetuning phases. First, off-the-shelf coarse-grained data is introduced to build the initialization correlations as prior knowledge. Then, we use prior knowledge to infer the representational interactions and correlations of the fine-grained representations. Extensive experiments show that our method outperforms the current methods on the public few-shot fine-grained benchmarks. We also develop extensive studies to extend our method to few-shot texture visual recognition scenarios.},
  archive      = {J_NEUCOM},
  author       = {Jieqi Sun and Jian Li and Yafeng Li},
  doi          = {10.1016/j.neucom.2025.131302},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131302},
  shortjournal = {Neurocomputing},
  title        = {Knowledge-driven baseline for few-shot fine-grained visual recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BMTM-net: A rotating machinery fault diagnosis network based on 2D-1D fusion with bidirectional multi-granularity transformer-mamba. <em>NEUCOM</em>, <em>656</em>, 131293. (<a href='https://doi.org/10.1016/j.neucom.2025.131293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotating machinery plays a critical role in industrial operations, yet existing diagnostic methods often struggle with missing correlations between sensor data, weak noise immunity, and insufficient long-range feature extraction. To address these challenges, this paper proposes BMTM-Net, a fault diagnosis network based on 2D-1D fusion with Bidirectional Multi-granularity Transformer-Mamba (BMTM). The network consists of two main components: a 2D sequential information interaction network and a 1D temporal information extraction network. The 2D network captures inter-sensor sequence relationships and temporal dependencies using a Bidirectional Multi-granularity Transformer (BM-Transformer) and an embedded Sequential-Temporal Attention Module (ST-Attention), while the 1D network enhances feature completeness and extracts temporal information through a Bidirectional Multi-granularity Mamba (BM-Mamba) network, integrated with a Channel Attention-based Fusion Module (CAFM) for adaptive feature fusion. To evaluate BMTM-Net’s effectiveness and stability, experiments were conducted on datasets from Southeast University and a Self-Built bogie integrated test stand, with various levels of noise introduced to assess noise immunity. The results demonstrate that BMTM-Net achieves over 99 % accuracy across all four datasets and maintains high accuracy even under severe noise interference (SNR = −10 dB), outperforming other state-of-the-art methods with accuracy rates of 99.60 %, 99.40 %, 98.54 %, and 94.38 %, respectively. Additionally, the model exhibits low complexity, further confirming its robustness and effectiveness in noisy environments.},
  archive      = {J_NEUCOM},
  author       = {E. Xia and Yirong Liu and Jinyang Gong and Xunhua Dai and Tongyang Pan and Shiyi Wang},
  doi          = {10.1016/j.neucom.2025.131293},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131293},
  shortjournal = {Neurocomputing},
  title        = {BMTM-net: A rotating machinery fault diagnosis network based on 2D-1D fusion with bidirectional multi-granularity transformer-mamba},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancements in radiomics: A comprehensive survey of feature types and their correlation on modalities and regions. <em>NEUCOM</em>, <em>656</em>, 131192. (<a href='https://doi.org/10.1016/j.neucom.2025.131192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey paper provides an overview of different feature types used in radiomics research and their applications across various medical imaging modalities and disease domains. The paper delves into the key aspects of the radiomics workflow, including data engineering techniques for image acquisition, preprocessing, fusion, and segmentation. It then presents a comprehensive review of the most commonly employed feature categories in radiomics, such as shape-based, first-order statistical, second-order texture, and transform-based features. The paper also discusses the emerging role of deep learning features extracted using convolutional neural networks, recurrent neural networks, and transformers. The analysis of feature usage trends across different anatomical regions and imaging modalities offers valuable insights that can guide the optimization of feature engineering strategies in future radiomics research. The survey concludes by highlighting several opportunities for further advancement in the field, including the need for larger multi-center datasets, multi-modal data fusion, self-supervised learning, and the development of efficient embedded models for on-device deployment.},
  archive      = {J_NEUCOM},
  author       = {Luca Zedda and Andrea Loddo and Cecilia Di Ruberto},
  doi          = {10.1016/j.neucom.2025.131192},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131192},
  shortjournal = {Neurocomputing},
  title        = {Advancements in radiomics: A comprehensive survey of feature types and their correlation on modalities and regions},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive low-confidence pseudolabeling for semisupervised node classification. <em>NEUCOM</em>, <em>656</em>, 131166. (<a href='https://doi.org/10.1016/j.neucom.2025.131166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have demonstrated remarkable achievements in handling graph-structured data. However, the performance of GNNs is typically limited by the lack of sufficient labeled data, which are time-consuming to obtain in real-world scenarios. Pseudolabeling has been applied to GNNs by augmenting the training set data with unlabeled data. Most pseudolabeling methods on graphs assign pseudolabels to nodes based on high-confidence thresholds. However, nodes near labeled ones generally obtain high confidence scores during training. This results in an increasing number of similar nodes being assigned pseudolabels during training, which potentially leads to a distribution shift between the labeled dataset and the augmented dataset. The distribution of the augmented dataset diverges significantly from that of the entire graph data, causing the GNNs to perform poorly on test data. In this paper, we propose a progressive low-confidence pseudolabeling (PLCP) method to progressively leverage the low-confidence data. Specifically, pseudolabels are assigned to nodes within a predefined confidence-based ranking range. To alleviate distribution shift, we keep this range constant throughout the training process to prevent excessive nodes from being assigned pseudolabels. The range is designed to be sufficiently wide to leverage low-confidence nodes. Low-confidence nodes from the range propagate information to their neighbors, which helps the model capture patterns in uncertain regions. To alleviate the impact of noisy pseudolabels, a validation-based reassignment scheme is proposed to utilize validation metrics to assign more reliable pseudolabels. Numerous experiments are conducted to demonstrate that our proposed PLCP improves the performance of state-of-the-art GNNs on graph datasets in comparison with several established methods.},
  archive      = {J_NEUCOM},
  author       = {Tao Zhu and Hua Mao and Hui Liu and Jie Chen},
  doi          = {10.1016/j.neucom.2025.131166},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131166},
  shortjournal = {Neurocomputing},
  title        = {Progressive low-confidence pseudolabeling for semisupervised node classification},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep-DFVAR: Dynamic factor vector autoregression with deep learning for regional house price index forecasting. <em>NEUCOM</em>, <em>656</em>, 131103. (<a href='https://doi.org/10.1016/j.neucom.2025.131103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {House Price Index (HPI) is an indicator that reflects changes in residential house prices over time. Predicting HPI is crucial for homebuyers to determine the right time to purchase and for policymakers to formulate housing policies. Recent studies have reported that neural network approaches outperform classical methods in HPI forecasting. However, challenges remain due to limited monthly HPI data and its time-varying statistical properties. As a result, state-of-the-art time series forecasting models often respond slowly to abrupt changes and lack economic interpretability. To address these issues, we propose Deep-DFVAR, a hybrid framework that decomposes regional HPI into shared (common trends) and idiosyncratic (regional variations) components. The shared component is predicted with Vector Autoregression (VAR) based on Granger causality, which improves interpretability and responds faster to changes. The idiosyncratic component is modeled with our deep learning model, which benefits from reduced distribution shift (train–test gap). We evaluate Deep-DFVAR on South Korean and United States datasets, empirically demonstrating that our framework outperforms traditional and recent time series forecasting models. All data and code are publicly available at: https://github.com/YeoJiSu/House-Price-Index-Prediction .},
  archive      = {J_NEUCOM},
  author       = {Jisu Yeo and Artyom Stitsyuk and Jaesik Choi},
  doi          = {10.1016/j.neucom.2025.131103},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131103},
  shortjournal = {Neurocomputing},
  title        = {Deep-DFVAR: Dynamic factor vector autoregression with deep learning for regional house price index forecasting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-based triple asynchronous switching control for fuzzy neural networks: A full-information dependent lyapunov approach. <em>NEUCOM</em>, <em>656</em>, 131097. (<a href='https://doi.org/10.1016/j.neucom.2025.131097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper employs the full-information dependent Lyapunov-Krasovskii functional (LKF) analysis approach to investigate the multiple weighting adaptive event-triggered triple asynchronous switching control problem for Takagi-Sugeno fuzzy neural networks with semi-Markov jump parameters. Considering the influence of factors such as network delays and disturbances, there may be asynchronous premise variables and modes among the system, event generator and controller. Therefore, a triple asynchronous switching control framework under the multiple weighting adaptive event-triggered scheme is developed. Under this control framework, a novel full-information dependent LKF analysis approach is proposed to analyze the stability of neural networks, which fully considers the system information, such as the membership functions (MFs) information, modes information and state information. Meanwhile, a new MFs dependent optimal H ∞ performance index is introduced to achieve better disturbance attenuation ability. The proposed analysis approach is helpful in determining the controller gains and reducing the conservatism. Ultimately, four simulation examples are provided to show the effectiveness and superiority of proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Yiteng Zhang and Linchuang Zhang and Yonghui Sun and Wen Yang},
  doi          = {10.1016/j.neucom.2025.131097},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131097},
  shortjournal = {Neurocomputing},
  title        = {Event-based triple asynchronous switching control for fuzzy neural networks: A full-information dependent lyapunov approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCHF_T: A multi-dimensional adaptive compression approach for transformer-based models. <em>NEUCOM</em>, <em>656</em>, 131071. (<a href='https://doi.org/10.1016/j.neucom.2025.131071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, pre-trained language models based on the Transformer architecture have achieved significant results in many natural language processing tasks. However, the high computational cost limits their application in real-world scenarios. Previous Transformer compression methods typically focus on single-dimensional compression, which may cause over-compression and consequently degrade model performance. Additionally, these methods lack targeted optimization for specific downstream tasks. In this paper, we propose DCHF_T, a multi-dimensional adaptive compression approach that compresses Transformer models through token compression, attention head pruning, and a lightweight FFN. This approach selects the most informative tokens during training, prunes unimportant tokens, and retains their information in a compressed form, allowing the model to focus more on task-relevant inputs. Furthermore, DCHF_T combines attention head pruning and a lightweight FFN to reduce computation and parameter size across multiple dimensions. We employ multi-objective evolutionary search to optimize the trade-off between accuracy and efficiency under various computational budgets. Experimental results on the GLUE benchmark demonstrate that DCHF_T achieves the best compression–performance trade-off. While maintaining the highest accuracy, DCHF_T achieves a reduction of 3.7 × and 3.6 × in FLOPs on BERT-base and RoBERTa-base, respectively. By implementing adaptive multi-dimensional compression, DCHF_T provides a systematic solution for deploying Transformer models in resource-constrained scenarios.},
  archive      = {J_NEUCOM},
  author       = {Yaoyao Yan and Da Wang and Jing Ye and Hui Yu and Dianjie Lu and Yuang Zhang and Weizhi Xu and Fang’ai Liu},
  doi          = {10.1016/j.neucom.2025.131071},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131071},
  shortjournal = {Neurocomputing},
  title        = {DCHF_T: A multi-dimensional adaptive compression approach for transformer-based models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key-concept thinking prompting for improved reasoning in large language models. <em>NEUCOM</em>, <em>656</em>, 130986. (<a href='https://doi.org/10.1016/j.neucom.2025.130986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in large language models (LLMs) have significantly accelerated the development of natural language processing (NLP) research, demonstrating remarkable capabilities in understanding and generating human-like text. However, these models face limitations when it comes to system 2 tasks, which require slow, multi-step, and conscious reasoning. To address these limitations, we introduce a method called Key-Concept Thinking (KCT), which enhances the model’s reasoning ability by directing it to identify and prioritize key concepts within a problem. Building on the Chain-of-Thought (CoT) prompting method, KCT anchors its approach in core ideas, allowing the model to form a deeper understanding of the problem’s structure and purpose. This targeted approach aims to improve both the accuracy and efficiency of the model’s reasoning, making it better equipped to handle tasks that require precision and deep understanding. We evaluate our proposed prompting strategies using 24 reasoning tasks across four categories: arithmetic, commonsense, symbolic, and other logical reasoning tasks, with three prominent large models: ChatGLM4, Baichuan2, and DeepSeek, respectively. The results show that the Zero-shot-KCT and Zero-shot-CoT-KCT strategies outperform traditional zero-shot and few-shot prompting strategies, highlighting the effectiveness of incorporating key concept thinking into the reasoning processes of LLMs. Our findings have implications for the development of more effective prompting strategies for LLMs that can handle complex reasoning tasks with higher accuracy and coherence.},
  archive      = {J_NEUCOM},
  author       = {Minghua Tang and Chen Bian and Liming Yang and Xueling Zhong},
  doi          = {10.1016/j.neucom.2025.130986},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {130986},
  shortjournal = {Neurocomputing},
  title        = {Key-concept thinking prompting for improved reasoning in large language models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
