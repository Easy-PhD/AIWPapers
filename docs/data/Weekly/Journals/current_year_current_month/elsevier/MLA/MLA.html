<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MLA</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mla">MLA - 22</h2>
<ul>
<li><details>
<summary>
(2025). Classification of envisioned english speech from EEG using deep learning approaches. <em>MLA</em>, <em>22</em>, 100752. (<a href='https://doi.org/10.1016/j.mlwa.2025.100752'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to use non-invasive technology to recognize imagined speech holds significant potential to enhance the well-being of individuals with motor neuron disease, especially when voluntary muscle control is limited. Despite its potential, this technology is still in its early stages of development, and there remains a significant scope for further research. Therefore, we proposed deep learning approaches to classify 26 English alphabets and 10 digits. To train and evaluate the models, we have collected electroencephalogram (EEG) signals from 20 participants in real-time while they imagined the alphabet and digits. The raw EEG data were processed using the filters, which allowed us to separate various frequency bands: δ , θ , α , β , and γ , as well as combinations of these bands δ + β + γ , and θ + α + β . The dataset was divided into training (80%), validation (10%), and testing (10%) sets and evaluated across three deep learning models: 1D CNN, BiLSTM, and a hybrid 1D CNN–BiLSTM. Among them, the BiLSTM model outperformed the other two models, achieving the highest test accuracy of 85.65% in digit classification within the δ frequency band and 83.65% in alphabet classification within the α frequency band. This research has the potential to facilitate the development of assistive communication technologies for individuals with motor neuron disorders.},
  archive      = {J_MLA},
  author       = {Arman Hossain and Tanvir Hossain Ovi and Mohammed Arif Iftakher Mahmood and Md. Fazlul Kader},
  doi          = {10.1016/j.mlwa.2025.100752},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100752},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Classification of envisioned english speech from EEG using deep learning approaches},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary AdaBoost ensemble: A machine learning framework for depression detection. <em>MLA</em>, <em>22</em>, 100748. (<a href='https://doi.org/10.1016/j.mlwa.2025.100748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is a prevalent and debilitating mental health disorder that often goes undiagnosed due to the lack of accessible, objective screening tools. This paper introduces EVAdaBoost, an Evolutionary AdaBoost ensemble framework designed for automated depression detection from voice signals. The method leverages a diverse set of signal processing techniques—including Fourier, Wavelet, Walsh, Hilbert–Huang, and OpenSmile, as well as time–frequency transformations for convolutional neural networks (CNNs). Each feature set is used to train a specialised AdaBoost ensemble, with Broad Learning Systems (BLS) serving as efficient weak learners. A key innovation of EVAdaBoost is its use of a quantum-inspired evolutionary algorithm to optimise the feature subsets assigned to each AdaBoost model. Instead of using all extracted features, which may include noise, redundancy, and irrelevant data, EVAdaBoost evolves to select diverse and high-performing subsets of features for each AdaBoost base learner, automatically discarding non-informative features. This evolutionary selection enhances both classification accuracy and computational efficiency. Additionally, an evolutionary pruning algorithm is employed to find the optimal subset of AdaBoost algorithms that offer the best performance at reduced computational cost. Experiments across nine feature types and multiple benchmark classifiers show that EVAdaBoost consistently outperforms state-of-the-art methods in accuracy, sensitivity (TPR), specificity (TNR), and precision (PPV). The results underscore the potential of hybrid evolutionary ensemble learning for non-invasive, speech-based mental health screening.},
  archive      = {J_MLA},
  author       = {Ruhollah Sayeri and Behnam Barzegar and Yaser Bozorgi rad and Nasser Mikaeilvand and Mohammad Hassan Tayarani Najaran},
  doi          = {10.1016/j.mlwa.2025.100748},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100748},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Evolutionary AdaBoost ensemble: A machine learning framework for depression detection},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization of genomic breeding value prediction for growth traits in rongchang pigs through machine learning techniques. <em>MLA</em>, <em>22</em>, 100747. (<a href='https://doi.org/10.1016/j.mlwa.2025.100747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background The increasing volume of genome sequencing data poses significant challenges for traditional genome-wide prediction methods in handling large datasets. Machine learning (ML) techniques are well-suited for processing high-dimensional data, and offer promising solutions. This study aimed to identify an optimal genome-wide prediction approach for local pig breeds using 10 datasets with varying single nucleotide polymorphism (SNP) densities, derived from imputed sequencing data of 485 Rongchang pigs and the results of genome-wide association studies (GWAS). Three growth traits, namely, backfat (BF) thickness, loin and thoracic height (LTH), and girth circumference (GC), were predicted using six traditional methods and six ML-based methods, including Kernel Ridge Regression (KRR), Support Vector Regression (SVR), Random Forest, Gradient Boosting Decision Tree, Light Gradient Boosting Machine, and Adaboost. Results The efficacy of the different methods was evaluated using a five-fold cross-validation strategy and independent tests. The predictive performance of both the traditional and ML-based methods was initially enhanced through the incorporation of significantly associated SNPs and weighted data, with the KRR method exhibiting exceptional resistance to overfitting at a SNP density of 300,000. The ML-based methods outperformed the traditional methods, with improvements of 6.6–8.1 %. The integration of GWAS data enhanced the prediction accuracy of the ML-based methods. KRR and Gradient Boosting Decision Tree demonstrated significant computational efficiency, indicating their potential as promising strategies for genomic prediction in livestock breeding. Conclusions This study provides a comprehensive analysis of genome-wide predictions in Rongchang pigs, and highlights the potential of ML-based techniques in enhancing prediction accuracy and efficiency. The study provides valuable insights into GP and holds key implications for advancing genome breeding practices in local pig breeds.},
  archive      = {J_MLA},
  author       = {Pingxian Wu and Junge Wang and Xinyou Chen and Tao Wang and Zongyi Guo and Shuqi Diao and Jinyong Wang},
  doi          = {10.1016/j.mlwa.2025.100747},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100747},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Optimization of genomic breeding value prediction for growth traits in rongchang pigs through machine learning techniques},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A laplace diffusion-based transformer model for heart rate forecasting within daily activity context. <em>MLA</em>, <em>22</em>, 100746. (<a href='https://doi.org/10.1016/j.mlwa.2025.100746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of wearable Internet of Things (IoT) devices, remote patient monitoring (RPM) emerged as a promising solution for managing heart failure. However, the heart rate can fluctuate significantly due to various factors, and without correlating it to the patient's actual physical activity, it becomes difficult to assess whether changes are significant. Although Artificial Intelligence (AI) models may enhance the accuracy and contextual understanding of remote heart rate monitoring, the integration of activity data is still rarely addressed. In this paper, we propose a Transformer model combined with a Laplace diffusion technique to model heart rate fluctuations driven by physical activity of the patient. Unlike prior models that treat activity as secondary, our approach conditions the entire modeling process on activity context using specialized embeddings and attention mechanisms to prioritize activity specific historical patents. The model captures both long-term patterns and activity-specific heart rate dynamics by incorporating contextualized embeddings and dedicated encoder. The Transformer model was validated on a real-world dataset collected from 29 patients over a 4-month period. Experimental results show that our model outperforms current state-of-the-art methods, achieving a 43 % reduction in mean absolute error compared to the considered baseline models. Moreover, the coefficient of determination R 2 is 0.97 indicating the model predicted heart rate is in strong agreement with actual heart rate values. These findings suggest that the proposed model can be a practical and effective tool for supporting both healthcare providers and remote patient monitoring systems.},
  archive      = {J_MLA},
  author       = {Andrei Mateescu and Ioana Hadarau and Ionut Anghel and Tudor Cioara and Ovidiu Anchidin and Ancuta Nemes},
  doi          = {10.1016/j.mlwa.2025.100746},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100746},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A laplace diffusion-based transformer model for heart rate forecasting within daily activity context},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting daily stock price directions with deep learning models. <em>MLA</em>, <em>22</em>, 100744. (<a href='https://doi.org/10.1016/j.mlwa.2025.100744'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, deep learning models like LSTM, CNN and RNN were explored to predict the direction of daily stock price changes. Since stocks in the same industry sector are highly correlated, we propose to replace individual stock with their corresponding Exchange Traded Sector Funds (ETFs) and S&P 500. We show that this replacement of individual stocks by the corresponding ETF can be justified due to high degree of returns correlation and small Hamming distances of trading signals across both input and output for stocks in the same sector. We considered historical daily data spanning 25 years (2000 to 2024) on major sector ETFs, some of their components and the S&P-500 index. Our results show that LSTM consistently outperformed CNN and RNN and traditional machine learning models. As a trading strategy, LSTM significantly out-performed buy-and-hold strategy for stocks in the Technology and Consumer Durables sectors, but offered very minor improvement for stocks in other sectors. Our results suggest that predicting daily stock price directions with deep learning models should not be used for most stocks unless these stocks are in Technology or Consumer Durables sectors and LSTM-based models are used.},
  archive      = {J_MLA},
  author       = {Triparna Kundu and Eugene Pinsky},
  doi          = {10.1016/j.mlwa.2025.100744},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100744},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Predicting daily stock price directions with deep learning models},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating the impact of model scale and prompting strategies on corruption allegation classification using thai-specialized typhoon2 language models. <em>MLA</em>, <em>22</em>, 100743. (<a href='https://doi.org/10.1016/j.mlwa.2025.100743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corruption complaint classification is a critical yet resource-intensive task in public sector governance, particularly in low-resource linguistic environments. This study assesses the capacity of Thai-specialized large language models (LLMs) from the Typhoon2 family to automate the classification of corruption complaints submitted to Thailand’s National Anti-Corruption Commission (NACC). Three variants—Typhoon2–3B (base), Typhoon2–3B (fine-tuned), and Typhoon2–7B (base)—were evaluated under zero-shot, one-shot, and two-shot prompting strategies and benchmarked against strong traditional machine learning models (Random Forest, XGBoost) trained on TF-IDF features. Results reaffirm the competitiveness of tree-based classifiers, which delivered consistently high and stable performance. Among the LLMs, the Typhoon2–7B model with two-shot prompting achieved the most balanced performance (Macro F1 = 0.514), highlighting emergent few-shot reasoning capabilities and improved handling of class imbalance. By contrast, fine-tuning the smaller 3B model induced severe overfitting and significant degradation on minority classes. These outcomes emphasize that model scale and prompt design are more reliable drivers of performance than direct fine-tuning in small, imbalanced settings. The study contributes practical guidance for deploying scalable and ethically aligned AI in governance, demonstrating that while traditional models remain robust benchmarks, large-scale prompted LLMs represent a promising complement for future public sector innovation.},
  archive      = {J_MLA},
  author       = {Patipan Sriphon and Pattrawut Khunwipusit and Bamisaye Mayowa Emmanuel and Issara Sereewatthanawut},
  doi          = {10.1016/j.mlwa.2025.100743},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100743},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Evaluating the impact of model scale and prompting strategies on corruption allegation classification using thai-specialized typhoon2 language models},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance evaluation of complex-valued neural networks on real and complex-valued classification and reconstruction tasks. <em>MLA</em>, <em>22</em>, 100742. (<a href='https://doi.org/10.1016/j.mlwa.2025.100742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex-Valued Neural Networks (CVNNs) are reported to be more efficient in different applications than Real-Valued Neural Networks (RVNNs) in many papers. In this study, we aim to characterize the cases when it holds true in order to assist the selection of proper tools for two specific tasks: classification and reconstruction. Among the various ways to compare CVNNs and RVNNs, we apply the one based on the number of parameters of the respective Neural Networks (NNs), assuming that a complex parameter is composed of two real ones. The performed experimentation revealed many surprising differences in the performance of CVNNs and RVNNs compared to the ones discussed in the preceding literature. This drives us to the general conclusion that the performance of RVNNs is similar or better than the performance of CVNNs in the majority of the cases, and the seldom cases when CVNNs achieve better performance are hard to characterize.},
  archive      = {J_MLA},
  author       = {Mahmood K.M. Almansoori and Miklos Telek},
  doi          = {10.1016/j.mlwa.2025.100742},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100742},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Performance evaluation of complex-valued neural networks on real and complex-valued classification and reconstruction tasks},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid machine learning model for the prediction of anaemia. <em>MLA</em>, <em>22</em>, 100741. (<a href='https://doi.org/10.1016/j.mlwa.2025.100741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In developing countries like Tanzania, despite the national intervention, the proportion of anaemic children aged 6–59 months is seen to be high, with a prevalence of 59 %. Traditional methods, such as examining paleness in the eyes and tongue, are commonly used, but are subjective and often lead to delayed or missed diagnoses. While existing Machine learning models have attempted to predict anaemia in children and offer improved accuracy, many rely on single-model strategies and a default threshold of 0.5, which tends to favour sensitivity over specificity, leading to a high number of false positives. The study used the supervised machine learning approach within the CRISP-DM framework. A stacked hybrid approach was used, integrating Random Forest (RF) and Artificial Neural Network (ANN) as base models, using XGBoost as a meta-learner. The model's performance was evaluated using metrics such as accuracy, sensitivity, specificity, precision, and Area Under the Curve (AUC) with 95 % confidence intervals (CIs) across thresholds of 0.35, 0.4, 0.45, and 0.5, optimized using Youden’s J index. The hybrid model achieved balanced performance, especially at a 0.4 threshold with a sensitivity of 0.861 and a specificity of 0.880. Compared to standalone models, the hybrid approach outperformed in reducing false positives and false negatives, offering greater reliability and clinical safety. This study concludes that the stacking ensemble approach, along with threshold optimization, provides an effective solution for early detection of anaemia in children. Integration of hybrid Machine Learning models into Tanzania’s health screening programs could improve child health outcomes.},
  archive      = {J_MLA},
  author       = {Rabia Omar Said and Mahadia Tunga},
  doi          = {10.1016/j.mlwa.2025.100741},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100741},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Hybrid machine learning model for the prediction of anaemia},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced prediction of karst spring discharge using a hybrid LSTM-XGBoost model optimized with grid search. <em>MLA</em>, <em>22</em>, 100740. (<a href='https://doi.org/10.1016/j.mlwa.2025.100740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Globally, intensifying droughts taxed water supplies, particularly in karst areas where it is difficult to predict spring discharge due to complex hydrology. Data-driven models represent a viable alternative, with the significance of karst aquifers to freshwater production. To enhance the accuracy of spring discharge prediction, this study introduces a new LSTM-XGBoost hybrid model for more accurate karst spring discharge prediction in Chaharmahal Bakhtiari Province, Iran. The hybrid model exploits the benefits of LSTM in capturing temporal dependency and the strength of XGBoost in modeling nonlinear relationships, and Grid Search is utilized for tuning hyperparameters. The performance of the LSTM-XGBoost model is compared with the optimized ML models. The study utilizes a dataset of 3,266 day, month, and spring discharge records of the Dehghara Springs. The results depict the excellence of the suggested LSTM-XGBoost hybrid model with the highest test R 2 = 0.8798, Explained Variance (EV) = 0.8857, and the lowest error metrics (MAE = 0.3355, RMSE = 0.5795, MAPE = 21.84%). The hybrid model outperforms both the baseline traditional and Deep Learning (DL). Feature importance analysis reveals that seasonal factors, particularly the month with an importance score of 0.919, have a significantly greater impact on spring discharge than daily variations. The proposed LSTM-XGBoost hybrid model provides a reliable and accurate tool for karst spring discharge prediction, offering valuable insights for water resource management in regions affected by climate change and increasing water demand.},
  archive      = {J_MLA},
  author       = {Xiaomei Liu},
  doi          = {10.1016/j.mlwa.2025.100740},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100740},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Enhanced prediction of karst spring discharge using a hybrid LSTM-XGBoost model optimized with grid search},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting political voting: A high dimensional machine learning approach. <em>MLA</em>, <em>22</em>, 100739. (<a href='https://doi.org/10.1016/j.mlwa.2025.100739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel machine learning approach to predict voting patterns in Brazil’s Chamber of Deputies. Using a high-dimensional dataset and a time-series methodology, our models aim to accurately forecast legislative decisions. Unlike prior studies that often focus on single ideological dimensions, our approach integrates a broad feature set, including party guidelines, proposition characteristics, and deputy voting history, to improve predictive power. We train time-series models for each legislature, comparing ensembles like Random Forests and Gradient Boosting, which are validated using three-fold chronological splits to ensure temporal integrity. Our analysis highlights the significant influence of party guidelines and pork-barrel politics on voting behavior. Additionally, we identify key predictors, including the theme and source of the legislative proposition, as well as the deputies’ voting history. This work demonstrates the feasibility of accurately forecasting legislative votes, offering a valuable tool for stakeholders to anticipate legislative outcomes and enhancing the transparency of the political process.},
  archive      = {J_MLA},
  author       = {Pedro Caiua Campelo Albuquerque and Daniel Oliveira Cajueiro},
  doi          = {10.1016/j.mlwa.2025.100739},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100739},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Forecasting political voting: A high dimensional machine learning approach},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing IDS performance through a comparative analysis of random forest, XGBoost, and deep neural networks. <em>MLA</em>, <em>22</em>, 100738. (<a href='https://doi.org/10.1016/j.mlwa.2025.100738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion Detection Systems (IDS) face major challenges in network security, notably the need to combine a high detection rate with reliable performance. This reliability is often affected by class imbalances and inadequate hyperparameter optimization. This article addresses the issue of improving the detection rate of IDS by evaluating and comparing three machine learning algorithms: Random Forest (RF), XGBoost, and Deep Neural Networks (DNN), using the NSL-KDD dataset. In our methodology, we integrate SMOTE (Synthetic Minority Oversampling Technique) to tackle the unbalanced nature of the data, ensuring a more balanced representation of the different classes. This approach helps optimize model performance, reduce bias, and enhance robustness. Additionally, hyperparameter optimization is performed using Optuna, ensuring that each algorithm operates at its optimal level. The results show that our model, using the Random Forest algorithm, achieves an accuracy of 99.80%, surpassing the performance of XGBoost and Deep Neural Networks (DNN). This makes our approach a true asset for intrusion detection methods in computer networks.},
  archive      = {J_MLA},
  author       = {Sow Thierno Hamidou and Adda Mehdi},
  doi          = {10.1016/j.mlwa.2025.100738},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100738},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Enhancing IDS performance through a comparative analysis of random forest, XGBoost, and deep neural networks},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source plume tracing via multi-agent reinforcement learning under common UAV-faults. <em>MLA</em>, <em>22</em>, 100737. (<a href='https://doi.org/10.1016/j.mlwa.2025.100737'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hazardous airborne gas releases from accidents, leaks, or wildfires require rapid localization of emission sources under uncertain and turbulent conditions. Traditional gradient-based or biologically inspired strategies struggle in multi-source environments where odor cues are intermittent, aliased, and partially observed. We address this challenge by formulating multi-source plume tracing in three-dimensional fields as a cooperative partially observable Markov game. To solve it, we introduce an Action-Specific Double Deep Recurrent Q-Network (ADDRQN) that conditions on action–observation pairs to improve latent-state inference, and integrates teammate information through a permutation-invariant set encoder. Training follows a randomized centralized-training and decentralized-execution regime with host randomization, team-size variation, and noise injection. This yields a policy that is robust to agent failures (hardware malfunction, battery depletion, etc.), resilient to intermittent communication blackouts, and tolerant of sensor noise. Empirical evaluation in simulated Gaussian plume environments shows that ADDRQN achieves higher success rates and shorter localization times than non-action baselines, maintains strong performance under mid-mission disruptions, and scales predictably with team size.},
  archive      = {J_MLA},
  author       = {Pedro Antonio Alarcon Granadeno and Theodore Chambers and Jane Cleland-Huang},
  doi          = {10.1016/j.mlwa.2025.100737},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100737},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Multi-source plume tracing via multi-agent reinforcement learning under common UAV-faults},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structure-aware stable diffusion for traditional architectural decoration design. <em>MLA</em>, <em>22</em>, 100735. (<a href='https://doi.org/10.1016/j.mlwa.2025.100735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intelligent generation of traditional architectural styles faces significant challenges in structural integrity and style consistency. While existing methods can generate numerous realistic images, they lack a deep understanding of structural elements in traditional architectural decorative design. This paper proposes a Structure-aware Stable Diffusion (SSD) model, which enhances the model's comprehension of architectural features through three key innovations. First, we design a structure-aware feature injection module that adaptively fuses extracted architectural structural information with original features during the U-net upsampling phase, enhancing the model's understanding of geometric structures. Second, we introduce a dual-path text enhancement strategy that combines structural descriptions with original descriptions to provide richer textual guidance signals for the generation process. Finally, we design a progressive injection strategy that dynamically controls the injection intensity of structural information through cosine scheduling, ultimately achieving effective internalization of structural knowledge. Experimental results show that compared to existing methods, our model effectively improves both the diversity of generated traditional architectural decorations and the rationality of their structures, thus providing an effective new technical approach for traditional architectural decorative design.},
  archive      = {J_MLA},
  author       = {Jianhong Yang and Guoyong Wang},
  doi          = {10.1016/j.mlwa.2025.100735},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100735},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Structure-aware stable diffusion for traditional architectural decoration design},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature importance analysis of optimized machine learning modeling for predicting customers satisfaction at the united states airlines. <em>MLA</em>, <em>22</em>, 100734. (<a href='https://doi.org/10.1016/j.mlwa.2025.100734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer experience is crucial in the airline industry, as understanding passenger satisfaction helps airlines improve service quality. This study evaluates hyperparameter optimization and feature interpretability in machine learning models for predicting airline passenger satisfaction. Support Vector Machine (SVM) and Multilayer Perceptron (MLP) models were tested for binary classification, labeling passengers as ‘Satisfied’ or ‘Neutral or Dissatisfied’ using a Kaggle dataset with ∼104,000 training and ∼26,000 test records. Hyperparameter tuning used grid search with 10-fold cross-validation. For SVM, the optimal setup included the RBF kernel, C = 10, and gamma = ‘auto’, achieving a mean score of 0.9606. For MLP, the best configuration used no regularization, "he" initialization, ReLU activation, 30 epochs, batch size of 32, two hidden layers with 32 neurons each, and a learning rate of 0.001, yielding a mean score of 0.9556. Performance metrics included accuracy, precision, recall, and F1-Score, with SVM achieving a test accuracy of 0.96, precision of 0.97, and F1-Score of 0.95, slightly outperforming MLP by <1 %, though MLP was faster at 0.3 s versus SVM’s 18 s. Both models surpassed baseline models and prior studies, benefiting from robust preprocessing and a large dataset. Permutation importance analysis identified Type of Travel, Inflight Wi-Fi Service, Customer Type, and Online Boarding as key predictors, emphasizing passenger needs for digital connectivity and personalized services. These insights guide airlines to prioritize reliable Wi-Fi and efficient online boarding to enhance satisfaction, loyalty, and competitive positioning.},
  archive      = {J_MLA},
  author       = {Hamid Mirzahossein and Soheil Rezashoar},
  doi          = {10.1016/j.mlwa.2025.100734},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100734},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Feature importance analysis of optimized machine learning modeling for predicting customers satisfaction at the united states airlines},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformal validation: A deferral policy using uncertainty quantification with a human-in-the-loop for model validation. <em>MLA</em>, <em>22</em>, 100733. (<a href='https://doi.org/10.1016/j.mlwa.2025.100733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Validating performance is a key challenge facing the adoption of machine learning models in high risk applications. Current validation methods assess performance marginally over the entire testing dataset, which can fail to identify regions in the distribution with insufficient performance. In this paper, we propose Conformal Validation, a systems-based approach with a calibrated form of uncertainty quantification using a conformal prediction framework as a part of the validation process to reduce performance gaps. Specifically, the policy defers a subset of observations for which the predictive model is most uncertain and provides a human with informative prediction sets to make the ancillary decision. We evaluate this policy on an image classification task where images are distorted with varying levels of gaussian blur for a quantifiable measure of added difficulty. The model is compared to human performance on the most difficult observations, i.e., those where the model is most uncertain, to simulate the scenario when a human is the alternative decision-maker. We evaluate performance on three arms: the model independently, humans with access to a set of classes the model is most confident in, and humans independently. The deferral policy is simple to understand, applicable to any predictive model, and easy to implement while, in this case, keeping humans in the loop for improved trustworthiness. Conformal Validation incorporates a risk assessment that is conditioned on the prediction set length and can be tuned to the needs of the application.},
  archive      = {J_MLA},
  author       = {Paul Horton and Alexandru Florea and Brandon Stringfield},
  doi          = {10.1016/j.mlwa.2025.100733},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100733},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Conformal validation: A deferral policy using uncertainty quantification with a human-in-the-loop for model validation},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining style and semantics for robust authorship verification. <em>MLA</em>, <em>22</em>, 100732. (<a href='https://doi.org/10.1016/j.mlwa.2025.100732'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Authorship Verification is a key task in Natural Language Processing, essential for applications like plagiarism detection and content authentication. This paper analyzes the use of deep learning models for Authorship Verification, focusing on combining semantic and style features to enhance model performance. We propose three models: the Feature Interaction Network, Pairwise Concatenation Network, and Siamese Network, which aim to determine if two texts are written by the same author. Each model uses RoBERTa embeddings to capture semantic content and incorporates style features such as sentence length, word frequency, and punctuation to differentiate authors based on writing style. Our results confirm that incorporating style features consistently improves model performance, with the extent of improvement varying by architecture. This demonstrates the value of combining semantic and stylistic information for Authorship Verification. While limitations such as RoBERTa’s fixed input length and the use of predefined style features exist, they do not hinder model effectiveness and point to clear opportunities for future enhancement through extended input handling and dynamic style feature extraction. In contrast to prior studies such as Bevendorff et al., (2020) and Kestemont, et al., (2022), which relied on balanced and homogeneous datasets with consistent topics and well-formed language, our work evaluates models on a more challenging, imbalanced, and stylistically diverse dataset, better reflecting real-world Authorship Verification conditions. Despite the increased difficulty, our models achieve competitive results, underscoring their robustness and practical applicability. These findings support the value of combining semantic and style features for real-world Authorship Verification.},
  archive      = {J_MLA},
  author       = {Britt van Leeuwen and Sandjai Bhulai and Rob van der Mei},
  doi          = {10.1016/j.mlwa.2025.100732},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100732},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Combining style and semantics for robust authorship verification},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of machine learning technologies in construction maintenance: A strategic analysis. <em>MLA</em>, <em>22</em>, 100731. (<a href='https://doi.org/10.1016/j.mlwa.2025.100731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current predictive maintenance systems in construction rely on static machine learning approaches that fail to adapt to evolving operational environments, achieving only 3%–7% performance improvements over individual models and suffering 15%–25% performance degradation when transferred across domains. This research develops and validates an Adaptive Ensemble Framework that dynamically optimizes algorithm selection through real-time data assessment and performance feedback. The framework’s meta-learning architecture continuously adapts ensemble weights using data complexity measures, temporal pattern analysis, and uncertainty quantification metrics. Unlike static approaches, the system integrates scikit-learn and TensorFlow models through dynamic optimization algorithms that respond to changing conditions without manual reconfiguration. The framework provides uncertainty-aware predictions with confidence intervals essential for safety-critical construction decisions. Comprehensive evaluation across four industries using 50,000+ maintenance records from major construction firms demonstrates substantial improvements. The adaptive ensemble achieves F1-score of 0.934 in construction delay prediction, representing 15.3% improvement over individual models and 8.7% enhancement over static ensembles. Cross-industry validation reveals successful knowledge transfer with minimal performance degradation ( < 5%). This research contributes three scholarly advances: (i) the first real-time adaptive ensemble framework eliminating manual hyperparameter tuning, (ii) uncertainty quantification mechanisms for safety-critical applications, and (iii) robust cross-industry transferability through systematic domain adaptation. The framework extends beyond construction to manufacturing, energy, and transportation sectors, demonstrating computational efficiency with sub-100ms latency and linear scaling characteristics. These contributions establish new benchmarks for adaptive machine learning in industrial predictive maintenance.},
  archive      = {J_MLA},
  author       = {Assane Lo and Aysha Alshehhi},
  doi          = {10.1016/j.mlwa.2025.100731},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100731},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Implementation of machine learning technologies in construction maintenance: A strategic analysis},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating deep learning and econometrics for stock price prediction: A comprehensive comparison of LSTM, transformers, and traditional time series models. <em>MLA</em>, <em>22</em>, 100730. (<a href='https://doi.org/10.1016/j.mlwa.2025.100730'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a comprehensive empirical comparison between state-of-the-art deep learning models including Long Short-Term Memory (LSTM) networks, Transformer architectures, and traditional econometric models (ARIMA and VAR) for stock price prediction, with particular focus on performance during the COVID-19 pandemic crisis. Using daily S&P 500 data from 2015 to 2020, we rigorously evaluate model performance across multiple metrics including Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE). Our findings demonstrate that while Transformer models achieve the best overall performance with an RMSE of 41.87 and directional accuracy of 69.1 %, LSTM networks provide an optimal balance between performance (RMSE: 43.25) and computational efficiency. Both deep learning approaches significantly outperform traditional econometric methods, with LSTM achieving a 53.3 % reduction in RMSE compared to ARIMA models. During the COVID-19 crisis period, deep learning models demonstrated exceptional robustness, with Transformers showing only 45 % performance degradation compared to over 100 % degradation in traditional models. Through comprehensive attention analysis, we provide insights into model interpretability, revealing adaptive behavior across market regimes. The study contributes to the growing literature on artificial intelligence applications in finance by providing rigorous empirical evidence for the superiority of modern deep learning approaches, while addressing the critical need for comparison with cutting-edge Transformer architectures that have revolutionized machine learning in recent years.},
  archive      = {J_MLA},
  author       = {Eyas Gaffar A. Osman and Faisal A. Otaibi},
  doi          = {10.1016/j.mlwa.2025.100730},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100730},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Integrating deep learning and econometrics for stock price prediction: A comprehensive comparison of LSTM, transformers, and traditional time series models},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine-learning based li-ion cell state prediction using impedance spectroscopy. <em>MLA</em>, <em>22</em>, 100729. (<a href='https://doi.org/10.1016/j.mlwa.2025.100729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable monitoring of battery state parameters is crucial for ensuring optimal battery performance, safety, and lifetime. Existing methods have limitations, such as requiring modeling of each degradation mechanism involved or relying on direct measurement techniques that impose restrictions on field studies or end-user use. In this paper, we propose a machine learning-based approach that combines the strengths of electrochemical impedance spectroscopy (EIS) and machine learning algorithms to predict battery state parameters. We have developed an efficient prediction system that can learn from EIS data and accurately predict battery state parameters. Our approach is trained on an open dataset comprising of over 30,000 spectra, generated using an automated measurement technique that outperforms current machine learning-based models, particularly in terms of generalization across different cells and measurement setups.},
  archive      = {J_MLA},
  author       = {Carl Philipp Klemm and Till Frömling},
  doi          = {10.1016/j.mlwa.2025.100729},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100729},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine-learning based li-ion cell state prediction using impedance spectroscopy},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Auxiliary evaluation of marginal ridge discrepancy in periodontal disease using deep learning on periapical radiographs. <em>MLA</em>, <em>22</em>, 100727. (<a href='https://doi.org/10.1016/j.mlwa.2025.100727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background/Objectives : Marginal Ridge Discrepancy (MRD) is an important early indicator of periodontal disease, often resulting from tooth inclination or alveolar bone loss, leading to uneven interproximal ridge height. Although periapical radiographs commonly observe bone and root structures, image overlap and angle variation often hinder accurate clinical interpretation. This study proposes a deep learning-based system integrating image segmentation and angular evaluation to assist dentists in objectively classifying MRD severity and improving diagnostic efficiency. Methods : We adopted a Mask R-CNN model with ResNet-101 as the backbone, incorporating warm-up and learning rate scheduling strategies to ensure stable convergence. Moreover, Mask R-CNN localized the cemento-enamel junction and alveolar crest by overlapping the mask image. We also introduced a novel angular measurement method to quantify the MRD between adjacent ridges and categorize periodontal disease severity. Results : ResNet-101 achieved the best segmentation performance among tested backbones with 98.11 % pixel-wise accuracy. Recall scores reached 97.60 % for teeth, 97.24 % for crowns, and 97.53 % for bone structures. The MRD classification model achieved 93.41 % accuracy with a mean angular error of only 0.85°, demonstrating strong clinical reliability. Conclusions : The proposed method effectively addresses challenges in evaluating ridge loss on periapical radiographs. Providing accurate and objective assessment enhances early periodontal diagnosis, reduces clinical workload, and supports improved medical quality and treatment planning.},
  archive      = {J_MLA},
  author       = {Yuan-Jin Lin and Chiung-An Chen and Yi-Cheng Mao and Chin-Hao Liang and Tsung-Yi Chen and Kuo-Chen Li and Shih-Lun Chen and Wei-Chen Tu},
  doi          = {10.1016/j.mlwa.2025.100727},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100727},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Auxiliary evaluation of marginal ridge discrepancy in periodontal disease using deep learning on periapical radiographs},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the cost of equity for insurance companies in the world: Evidence from machine learning approaches. <em>MLA</em>, <em>22</em>, 100726. (<a href='https://doi.org/10.1016/j.mlwa.2025.100726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the determinants of the WACC for insurance firms, integrating both financial and non-financial factors through advanced machine learning techniques. Analyzing data from 2012 to 2022 for a large sample of 190 insurance companies in the world, we compare nine ML models, revealing that XGBoost and LightGBM outperform traditional methods. Key drivers of WACC include beta, dividend yield, and earnings per share, with Emission score also showing significant influence. This study fills gaps in insurance finance literature by introducing ML-based WACC modeling, enhancing predictive accuracy, and providing policy recommendations for regulatory reporting and Emission score disclosures. From a policy perspective, the global insurance sector is at a crucial turning point, where ESG integration in granular form is found to be vital for financial stability. By mandating standardized ESG disclosures in alignment with the ISSB and TCFD frameworks, regulators can reduce insurers’ cost of equity, enabling a balance between financial sustainability and environmental responsibility, while promoting long-term value creation for both investors and society.},
  archive      = {J_MLA},
  author       = {Indranarain Ramlall and Dineshwar Ramdhony},
  doi          = {10.1016/j.mlwa.2025.100726},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100726},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Exploring the cost of equity for insurance companies in the world: Evidence from machine learning approaches},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the latent distribution of logistic regression — An empirical study on spectroscopic profiling datasets. <em>MLA</em>, <em>22</em>, 100712. (<a href='https://doi.org/10.1016/j.mlwa.2025.100712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logistic regression is a simple yet widely used classification model in spectroscopic profiling analysis. Considering the model’s output represents a probability, this paper will investigate its latent distribution assumption, i.e., its inner linear regressor unit follows a standard logistic distribution. An empirical study on five spectroscopic profiling open datasets, i.e., wine, coffee, olive oil, cheese, and milk powder, was conducted to verify this latent distribution assertion. This paper measured the GoF (Goodness of Fit) of each dataset’s latent variable from three aspects, i.e., curve fitting, P–P and Q–Q plots, and K–S test. After hyper-parameter optimization and proper training, the latent variable, as a weighted sum of the original features, has demonstrated a high level of GoF on all the five datasets. This study verifies the suitability of logistic regression in spectroscopic profiling analysis and answers why the model output can be interpreted as a conditional probability.},
  archive      = {J_MLA},
  author       = {Yinsheng Zhang and Mingming He and Haiyan Wang},
  doi          = {10.1016/j.mlwa.2025.100712},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100712},
  shortjournal = {Mach. Learn. Appl.},
  title        = {On the latent distribution of logistic regression — An empirical study on spectroscopic profiling datasets},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
