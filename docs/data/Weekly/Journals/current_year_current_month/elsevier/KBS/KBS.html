<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>KBS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="kbs">KBS - 195</h2>
<ul>
<li><details>
<summary>
(2025). Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning. <em>KBS</em>, <em>330</em>, 114483. (<a href='https://doi.org/10.1016/j.knosys.2025.114483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop knowledge graph reasoning aims to leverage the relations between multiple nodes in a knowledge graph to reason information about an event or entity. This reasoning process requires traversing multiple interconnected facts or knowledge points, which aids in understanding the model’s decision-making process. Multi-hop knowledge graph reasoning has driven the development of knowledge-based technologies, such as question-answering systems and recommendation systems. However, multi-hop reasoning relies on the connectivity between different entities in the knowledge graph. This characteristic makes multi-hop reasoning lack robustness when dealing with sparse data. To address the challenges of sparsity, recent studies pre-train knowledge graph embedding models to complete potential triples. The completion methods introduce noisy triples, which increases the risk of model selection errors and spurious paths. In this work, we propose a framework based on potential subgraph rule and reasoning context enhancement to mitigate the challenges of sparsity. On one hand, we leverage reasoning context to enhance state information and the reasoning process; on the other hand, we design an action perceptron based on the importance of reasoning context to reduce the introduction of noisy triples. Additionally, we analyze the phenomenon of data augmentation introducing spurious paths, and further utilize data augmentation-based potential subgraph rules to guide the reasoning process. This dual mechanism demonstrates stronger robustness in addressing sparsity challenges and spurious paths. Diverse experiments demonstrate that our model outperforms the existing multi-hop reasoning models across five datasets. Our implementations will be publicly available at: https://github.com/jianruichen/PreKGR .},
  archive      = {J_KBS},
  author       = {Congcong Sun and Jianrui Chen and Deguang Chen and Junjie Huang},
  doi          = {10.1016/j.knosys.2025.114483},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114483},
  shortjournal = {Knowl. Based Syst.},
  title        = {Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. <em>KBS</em>, <em>330</em>, 114482. (<a href='https://doi.org/10.1016/j.knosys.2025.114482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has emerged as a powerful self-supervised approach for learning generalized graph representations, achieving remarkable advancements in recent years. However, most existing GCL methods ignore the noise of the augmented global structure and the dynamic change in training, and lack detailed consideration in calculating local structural homogeneity. These limitations may lead to the model’s insufficient performance in capturing fine-grained semantic features at the node level, making it difficult to fully explore the potential semantic associations between adjacent nodes. Meanwhile, on a global scale, there is also a lack of the ability to model complex topological structures. To this end, we propose a new multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. This method dynamically adjusts the global structure via graph reconstruction and adaptively learns node representations; Meanwhile, a mutual rectification module is designed to predict the support scores of neighbors relative to anchors and quantify each neighbor’s contribution to view agreement. Both reconstruction and rectification are integrated into the training objective and effectively capture the graph structure information from both global and local scales, improving the quality and robustness of graph representations. We conduct extensive experiments on three downstream tasks: node classification, node clustering, and link prediction. The experimental results demonstrate that our method outperforms existing GCL methods across multiple tasks and datasets, validating the effectiveness and generalizability of the proposed model.},
  archive      = {J_KBS},
  author       = {Dengdi Sun and Zhixiang Wu and Mingwei Cao and Zhifu Tao and Zhuanlian Ding},
  doi          = {10.1016/j.knosys.2025.114482},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114482},
  shortjournal = {Knowl. Based Syst.},
  title        = {DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer. <em>KBS</em>, <em>330</em>, 114471. (<a href='https://doi.org/10.1016/j.knosys.2025.114471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are widely applied in optimization because of their flexibility and ability to address complex and high-dimensional problems. Nevertheless, they face persistent challenges, including susceptibility to local optima, limited parameter adaptability, and premature convergence. Leadership-based metaheuristics, in which leaders guide the search process, encounter additional difficulties such as limited exploration capacity, leader stagnation, and reduced diversity, often stemming from underutilization of data generated during the search. To overcome these limitations, this study proposes a reinforcement learning–based approach, RL-LGWO, which enhances the Grey Wolf Optimizer (GWO) by integrating multi-agent reinforcement learning. In RL-LGWO, agents share experiences to improve decision-making, and reinforcement learning is employed to decouple and adapt the leader update mechanism, thereby improving the exploration–exploitation balance and enabling leaders to dynamically escape local optima. The proposed method was evaluated against two GWO-enhancing algorithms, three RL-based GWO variants, PSO, WOA, and the original GWO across 23 well-known benchmark functions, in addition to the recent CEC2022 benchmark suite. Experimental results show that RL-LGWO achieved the best solutions on 17 of the 23 benchmark functions, with superior convergence speed and improved stability, while incurring only a minor runtime increase compared with the original GWO. Furthermore, on the CEC2022 suite, RL-LGWO outperformed competing algorithms on 10 of 12 test functions, underscoring its robustness and adaptability to recent and challenging benchmarks. Overall, the findings indicate that RL-LGWO delivers a substantive improvement over state-of-the-art alternatives and holds strong potential to advance leadership-based metaheuristics for a wide range of optimization problems.},
  archive      = {J_KBS},
  author       = {Afifeh Maleki and Mehdy Roayaei and Seyedali Mirjalili},
  doi          = {10.1016/j.knosys.2025.114471},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114471},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling. <em>KBS</em>, <em>330</em>, 114454. (<a href='https://doi.org/10.1016/j.knosys.2025.114454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable performance of supervised medical image segmentation models, relying on a large amount of labeled data is impractical in real-world situations. Semi-supervised learning approaches aim to alleviate this challenge using unlabeled data through pseudo-label generation. Yet, existing semi-supervised segmentation methods still suffer from noisy pseudo-labels and insufficient supervision within the feature space. To solve these challenges, this paper proposes a novel semi-supervised 3D medical image segmentation framework based on a dual-network architecture. Specifically, we investigate a Cross Consistency Enhancement module using both cross pseudo and entropy-filtered supervision to reduce the noisy pseudo-labels, while we design a dynamic weighting strategy to adjust the contributions of pseudo-labels using an uncertainty-aware mechanism (i.e., Kullback–Leibler divergence). In addition, we use a self-supervised contrastive learning mechanism to align uncertain voxel features with reliable class prototypes by effectively differentiating between trustworthy and uncertain predictions, thus reducing prediction uncertainty. Extensive experiments are conducted on three 3D segmentation datasets, Left Atrial, NIH Pancreas and BraTS-2019. The proposed approach consistently exhibits superior performance across various settings (e.g., 89.95 % Dice score on left Atrial with 10 % labeled data) compared to the state-of-the-art methods. Furthermore, the usefulness of the proposed modules is further validated via ablation experiments. The code repository is available at https://github.com/AIPMLab/Semi-supervised-Segmentation .},
  archive      = {J_KBS},
  author       = {Yunyao Lu and Yihang Wu and Ahmad Chaddad and Tareef Daqqaq and Reem Kateb},
  doi          = {10.1016/j.knosys.2025.114454},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114454},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. <em>KBS</em>, <em>330</em>, 114452. (<a href='https://doi.org/10.1016/j.knosys.2025.114452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of transfer learning strategies to solve cross-domain fault diagnosis problems has achieved significant results. However, most existing multi-source domain generalization fault diagnosis methods use a single classifier or introduce auxiliary classifiers, focusing on learning domain-invariant features or global feature distribution matching. Furthermore, since the data distributions of different source domains may be significantly different, this may lose the data distribution information specific to each source domain. In addition, how to reduce the variation in risk between samples within the same domain training is also a challenging issue. Finally, it is also crucial to balance the predictive outputs of multiple classifiers to adapt them to the data distribution of the target domain. Based on the above challenges, this paper proposes a multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. Feature weakly decoupled mechanism is achieved by employing multiple classifiers and incorporating the variance of samples within the same sample domain as a penalty term. This reduces the model’s sensitivity to changes in the extreme distribution of samples within the domain. Classifier weakly decoupled mechanism, on the other hand, reduces the inter-domain risk variance by minimizing the loss of variance in the predicted output of the source domain classifiers. This improves the robustness of the model to inter-domain distributional changes and covariate changes. Experimental results on three datasets validate the effectiveness and general applicability of the proposed approach.},
  archive      = {J_KBS},
  author       = {Yawei Sun and Hongfeng Tao and Vladimir Stojanovic},
  doi          = {10.1016/j.knosys.2025.114452},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114452},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing large language models for bitcoin time series forecasting. <em>KBS</em>, <em>330</em>, 114449. (<a href='https://doi.org/10.1016/j.knosys.2025.114449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent advancements in application of deep learning to time series forecasting, focus has shifted from training transformers end-to-end to efficiently leveraging the predictive capabilities of Large Language Models (LLMs). Models that encode the time series data to interact with a frozen LLM backbone have been shown to outperform transformers on all benchmark datasets. However, their efficiency on complex datasets, which do not show clear seasonality or trend, remains an open question. In this work, we seek to evaluate the performance of reprogrammed LLMs on the Bitcoin price chart, a financial time series known for its complexity and high volatility. We propose effective methods to improve the performance of Time-LLM, a State-of-the-art (SOTA) method, on such a time series. First, we propose structural improvements to Time-LLM. Second, we suggest an efficient way to handle the non-stationarity of the dataset. Finally, we propose an efficient method for passing additional financial information to the LLM. Our results demonstrate a 50 % improvement on the average percentage loss and a 5 % increase on accuracy of our adapted Time-LLM architecture on Bitcoin data when compared to SOTA models, including the original Time-LLM model. This highlights the impact on forecast accuracy of domain-specific decision making in data processing and feature selection.},
  archive      = {J_KBS},
  author       = {Owen Chaffard and Pablo Mollá and Marc Cavazza and Helmut Prendinger},
  doi          = {10.1016/j.knosys.2025.114449},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114449},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing large language models for bitcoin time series forecasting},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCAT: Federated causal adversarial training. <em>KBS</em>, <em>330</em>, 114440. (<a href='https://doi.org/10.1016/j.knosys.2025.114440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal inference has been proven to be a crucial technique for improving the efficacy and explainability of adversarial training (AT). However, its applicability in the decentralized adversarial training paradigm has not been fully explored. Where one potential challenge is to apply the causal inference in the settings of non-independent and identically distributed (Non-IID) federated learning. In particular, the imbalanced data distributions among various clients will unavoidably hinder the efficacy and adaptability of causal inference. To address this issue, this paper proposes a novel yet practical method dubbed Federated Causal Adversarial Training (FCAT), which seeks to improve causal models via calibrated correction information. Additionally, we introduce a lightweight slack aggregation method aimed at addressing client model disparities and minimizing the communication overhead in each iteration. Extensive experimental results demonstrate that FCAT significantly improves the efficacy of causal models in federated adversarial training, and remarkably outperforms the current state-of-the-art (SOTA) competitors on multiple widely-adopted benchmarks.},
  archive      = {J_KBS},
  author       = {Yunhao Feng and Yanming Guo and Mingrui Lao and Yulun Wu and Yishan Li and Yuxiang Xie},
  doi          = {10.1016/j.knosys.2025.114440},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114440},
  shortjournal = {Knowl. Based Syst.},
  title        = {FCAT: Federated causal adversarial training},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem. <em>KBS</em>, <em>330</em>, 114439. (<a href='https://doi.org/10.1016/j.knosys.2025.114439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The polynomial robust knapsack problem (PRKP) is a variant of the classic knapsack problem by incorporating uncertain costs and benefits from item combinations, leading to a nonlinear objective function and exponential solution space. These complexities make the PRKP suitable for real-world scenarios where interactions between items unpredictably impact outcomes. However, existing algorithms struggle to efficiently solve large instances of the PRKP due to its computational complexity. Therefore, this paper presents an iterative heuristic algorithm leveraging a neural network (NN) to address the PRKP, reducing the solution space and enabling efficient resolution of subproblems. The framework integrates an NN trained in two steps: general training and fine-tuning. The trained model is then embedded in the iterative heuristic algorithm to tackle the PRKP. A synthetic dataset comprising 2500 instances, ranging from 100 to 1500 items, is created to train the NN. Comparative evaluations are conducted using 1600 benchmark instances from the literature and 140 larger instances containing between 2000 and 15,000 items. We compare our approach against two state-of-the-art algorithms for the PRKP: a genetic algorithm and a random forest-based heuristic. Computational results demonstrate that the proposed algorithm outperforms the genetic algorithm, providing superior solution quality with significantly reduced computing times. Meanwhile, against random forest-based heuristic, it delivers better solution quality with only a moderate increase in computing time. For larger instances, it maintains its advantage in solution quality while remaining computationally efficient. These results highlight the algorithm’s scalability, effectiveness, and potential to address the PRKP.},
  archive      = {J_KBS},
  author       = {José González-Cortés and Carlos Contreras-Bolton},
  doi          = {10.1016/j.knosys.2025.114439},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114439},
  shortjournal = {Knowl. Based Syst.},
  title        = {A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TWDT: Training-free word-level controllable diffusion model for text generation. <em>KBS</em>, <em>330</em>, 114437. (<a href='https://doi.org/10.1016/j.knosys.2025.114437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing controlled text generation (CTG) methods typically require the training of additional components, whereas diffusion models have already achieved fine control in image generation by adjusting latent feature information during the inference process. However, existing diffusion models still face issues such as “attribute leakage” and “overgeneration” when applied to text generation, leading to generated texts lacking precise control. To address these problems, we propose a training-free word-level controllable diffusion language network (TWDT). This network achieves fine-grained control of text generation by adjusting latent space features during the inference process. Specifically, TWDT introduces an Alignment and Word Evaluation (AWE) module, which ensures accurate mapping of the text to a predefined set of feature words through syntactic segmentation and multi-level semantic alignment. At the same time, a similarity threshold filtering mechanism is applied to inject Gaussian noise into low-consistency nodes, ensuring semantic consistency and stability during generation. To evaluate the rigor and accuracy of the model, we have developed a high-quality multi-disease dental diagnostic dataset, all of which are annotated by experienced dental experts, serving as the benchmark for model evaluation. Experimental results show that TWDT outperforms existing diffusion models in terms of generation accuracy and rigor.},
  archive      = {J_KBS},
  author       = {Nan Gao and Yangjie Lu and Peng Chen and Guodao Sun and Ronghua Liang and Yilong Zhang},
  doi          = {10.1016/j.knosys.2025.114437},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114437},
  shortjournal = {Knowl. Based Syst.},
  title        = {TWDT: Training-free word-level controllable diffusion model for text generation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network. <em>KBS</em>, <em>330</em>, 114436. (<a href='https://doi.org/10.1016/j.knosys.2025.114436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern vehicles depend on the Controller Area Network (CAN) for electronic control unit (ECU) communication, but its inherent vulnerabilities necessitate robust intrusion detection systems (IDS). Current machine learning and deep learning IDS solutions struggle with limited labeled data, class imbalances, and costly data collection processes. Few-shot learning, effective with few labeled samples, remains underexplored for in-vehicle networks (IVNs) despite its potential in data-scarce automotive cybersecurity scenarios. To bridge this gap, we introduce the first few-shot learning approach for multi-class intrusion detection in IVNs, leveraging a novel, lightweight Convolutional Anomaly Transformer. By integrating a 1D convolutional layer with an Anomaly Transformer, our model effectively classifies diverse attack types with minimal training data, mitigating class imbalance. Experiments on the widely-used real-world Car Hacking dataset, the complex ROAD dataset, and the distinct CAN-ML dataset validate its efficacy. On the Car Hacking dataset, we achieve an exceptional F1 score of 0.9994 with only 2 % of training data, improving to 0.9999 with 10 %. On the challenging ROAD dataset, characterized by diverse attacks and high variability, the model achieves an F1 score of up to 0.9980 using just 10 % of training data. Demonstrating strong generalization capabilities, the model also attains an impressive F1 score of 0.9918 on the CAN-ML dataset, which features entirely different vehicles and attack distributions. Furthermore, the lightweight architecture of our proposed IDS enables practical deployment in resource-constrained automotive environments.},
  archive      = {J_KBS},
  author       = {Nguyen Thanh Minh Duy and Truong Hoang Bao Huy and Pham Van Phu and Tien-Dat Le and Daehee Kim},
  doi          = {10.1016/j.knosys.2025.114436},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114436},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining. <em>KBS</em>, <em>330</em>, 114434. (<a href='https://doi.org/10.1016/j.knosys.2025.114434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) algorithms have displayed their effectiveness in predicting sequence modelling compared to various systems. Nevertheless, some limitations of existing methods are the demand for enormous databases, computational expense, and the risk of overfitting. To address these problems, this study proposes a novel DL technique using knowledge distillation and sequence illness pattern recognition from medical databases. Firstly, the input data is pre-processed using the data cleaning method. The size of the sequence dataset and the duration of the sequential patterns are both considered during the process of using PREFIXSPAN to manage long sequential patterns. In the proposed strategy, a lightweight student network is employed to train a strong teacher network, which is produced by a Knowledge Distillation framework. A teacher network is assessed by the Attention Based Densely Connected Capsule Model (Attention-DC). An efficient, low-weight Depthwise Separable Convolutional Neural Network (DSCNN) model is then chosen as the student network. This study uses three datasets to solve enormous database issues. The KD helps prevent the student model from overfitting to noise or specific patterns in the training data. The Improved Coot Optimization Algorithm (ICOA) is applied to adjust the parameter. The hyperparameters used to optimize the performance of the proposed model are Epochs (300), learning rate (0.001), and batch size (32), respectively. The experiments use the resources of three different datasets, and Python is employed to analyze the results. The proposed technique achieves accuracy of 99.512 %, 99.329 % and 99.351 % for the heart disease, cardiovascular disease, and Diabetes dataset.},
  archive      = {J_KBS},
  author       = {Dinesh Kumar Bhawnani and Sunita Soni and Arpana Rawal},
  doi          = {10.1016/j.knosys.2025.114434},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114434},
  shortjournal = {Knowl. Based Syst.},
  title        = {Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural chain of thoughts for radiology education. <em>KBS</em>, <em>330</em>, 114433. (<a href='https://doi.org/10.1016/j.knosys.2025.114433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology education requires trainees to develop both perceptual and interpretive expertise. However, refinement of these skills is often impeded by the limited availability of mentorship, a consequence of the demanding schedules of experienced radiologists. This lack of personalized guidance makes it difficult for learners to recognize the mistakes they make, understand why those errors occurred and how to refine their perceptual processes. Many of these errors arise from subtle differences in visual attention, such as failing to fixate on an abnormality, allocating an insufficient fixation time, or overlooking an abnormality despite scanning the correct region. Although Large Language Models (LLMs) and Large Multimodal Models (LMMs) have been explored for radiology tasks, they often struggle to detect such fine-grained multimodal variations, particularly when comparing gaze behavior between experts and trainees. To address these limitations, we introduce Structural Chain of Thoughts (SCoT), a novel framework that enhances LLMs and LMMs sensitivity to nuanced multimodal differences by structuring gaze data and radiology report into a thought graph. By leveraging a structural prior, SCoT systematically identifies key perceptual and interpretive discrepancies, allowing models to provide targeted, context-aware feedback. This structured approach not only highlights missed findings but also explains the reasoning behind perceptual errors, turning them into learning opportunities. Applied within radiology education, SCoT bridges the gap between expert and novice performance, offering a scalable solution for AI-driven diagnostic training. We further contribute a simulated dataset of perceptual errors in chest X-ray (CXR) interpretation, facilitating future research into multimodal reasoning and AI-driven medical education. Unlike conventional Chain-of-Thought approaches, SCoT explicitly integrates gaze and textual information into a structured reasoning process, yielding interpretable, fine-grained, and personalized feedback tailored to the unique needs of radiology training. The code and data will be available here: GitHub Repository .},
  archive      = {J_KBS},
  author       = {Akash Awasthi and Brandon Chung and Anh Mai Vu and Saba Khan and Ngan Le and Zhigang Deng and Rishi Agrawal and Carol C. Wu and Hien Van Nguyen},
  doi          = {10.1016/j.knosys.2025.114433},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114433},
  shortjournal = {Knowl. Based Syst.},
  title        = {Structural chain of thoughts for radiology education},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing. <em>KBS</em>, <em>330</em>, 114431. (<a href='https://doi.org/10.1016/j.knosys.2025.114431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing enables the efficient execution of compute-intensive tasks by offloading them to edge servers. However, frequent user mobility in 5 G urban networks leads to increased latency, energy consumption, and resource wastage due to continuous handovers. To address these challenges, Energy Efficient Communication and Optimal Offloading Network, a framework is proposed that combines user mobility prediction and hybrid optimization for task offloading. Energy Efficient Communication and Optimal Offloading Network utilizes a modified Long Short-Term Memory model to predict user movement with high accuracy, achieving an accuracy improvement from 65 % to 95 % over ten iterations. Additionally, a Hybrid Grey Wolf Optimization Algorithm optimizes task allocation, resulting in a 30 % reduction in energy consumption and a 25 % improvement in server utilization compared to baseline methods. The framework achieves latency as low as 5 milliseconds for augmented reality tasks while maintaining scalability in high-traffic 5 G environments. The proposed model also outperforms baseline approaches in terms of task completion time, throughput, and communication efficiency, and it achieves a 94.5 % offloading success rate and 98 % augmented reality delay compliance. The proposed model provides a scalable and useful solution for real-time Augmented Reality by combining energy-constrained task allocation with mobility-aware predictions.},
  archive      = {J_KBS},
  author       = {Anitha Jebamani Soundararaj and Godfrey Winster Sathianesan},
  doi          = {10.1016/j.knosys.2025.114431},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114431},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified multi-subgraph pre-training framework for spatio-temporal graph. <em>KBS</em>, <em>330</em>, 114428. (<a href='https://doi.org/10.1016/j.knosys.2025.114428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph (STG) learning has shown great potential in capturing complex spatio-temporal dependencies and has achieved significant success in various fields such as traffic flow prediction, climate forecasting, and epidemiological spread research. By learning general features from spatio-temporal graphs, pre-trained graph models can capture hidden semantic information in the data, thereby enhancing the learning effect of downstream tasks and improving overall model performance. However, most existing spatio-temporal graph learning methods use the entire graph for training, which may not fully capture local structure and feature information. In addition, existing methods usually adopt sequence modeling techniques without fully considering the time decay effect, i.e., the need to apply decaying attention to distant time steps. To address these issues, this paper proposes a u nified dual-phase m ulti- s ubgraph pre-training s patio- t emporal graph framework (UMSST). Specifically, in the first phase, the framework learns the global representation of the spatio-temporal graph and locates key graph nodes, while learning the “unit representations” of these key nodes. In the second phase, multiple spatio-temporal subgraphs are constructed based on these “unit representations” to further capture the implicit encoding information of more general features around the corresponding subgraphs, thereby helping the model make full use of general features. Experimental results on real datasets show that the proposed pre-trained spatio-temporal graph framework significantly improves the performance of downstream tasks and demonstrates its effectiveness in comparison with recent strong baseline models.},
  archive      = {J_KBS},
  author       = {Mingze Zhong and Zexuan Long and Xinglei Wang and Tao Cheng and Meng Fang and Ling Chen},
  doi          = {10.1016/j.knosys.2025.114428},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114428},
  shortjournal = {Knowl. Based Syst.},
  title        = {A unified multi-subgraph pre-training framework for spatio-temporal graph},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provide explainable clues: A generative traceable method for knowledge graph completion. <em>KBS</em>, <em>330</em>, 114426. (<a href='https://doi.org/10.1016/j.knosys.2025.114426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the quality of Knowledge Graph Completion (KGC) results is an essential topic in the field of knowledge graphs. Recently, generative models (GMs) have gained widespread attention for addressing the generalization issues of traditional approaches. However, the black-box nature of generative models often leads to hallucinations, which reduce the model’s performance. Most methods attempt to mitigate this issue through retrieval enhancement and decoding constraints. However, they overlook one major cause of hallucinations–poor explainability. Based on this concept, we propose a G enerative T raceable M ethod, namely GTM, which aims to improve the KGC capability of GMs by exploring the inhibitory effect of explainability on hallucinations. In GTM, a clue tracker is used to find contextual evidence for explainability. In addition, to measure explainability clues, we propose a context-aware analyzer, which enhances the understanding of context through group analogy. In the reasoning phase, we ensure the validity of the generated results by integrating the interpretive capability of clues. Extensive experiments have demonstrated that GTM can adapt to various KGC tasks and significantly enhance the performance of KGC models.},
  archive      = {J_KBS},
  author       = {Ziqi Ma and Jinpeng Li and Hang Yu},
  doi          = {10.1016/j.knosys.2025.114426},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114426},
  shortjournal = {Knowl. Based Syst.},
  title        = {Provide explainable clues: A generative traceable method for knowledge graph completion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IRTF: A new tensor factorization for irregular multidimensional data recovery. <em>KBS</em>, <em>330</em>, 114372. (<a href='https://doi.org/10.1016/j.knosys.2025.114372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor factorizations, although serving as paramount tools for exploiting prior knowledge of multidimensional data, are unsuitable for emerging irregular multidimensional data with the arbitrary shape spatial domain (i.e., spatial-irregular tensor), such as superpixels and spatial transcriptomics. Developing new tensor factorizations suitable for spatial-irregular tensors poses a compelling challenge. To meet this challenge, we introduce a novel Irregular Tensor Factorization (IRTF), which can fully capture the intrinsic spatial and channel information behind the spatial-irregular tensor. Concretely, a spatial-irregular tensor can be decomposed into the product of an intrinsic regular tensor, learnable channel transform matrices, and a learnable spatial transform matrix. Accompanying IRTF, we suggest the Total Variation on Channel and Spatial Transforms (TV-CST) to exploit the local information of spatial-irregular tensors, which is hardly excavated by traditional total variation methods. Combining the proposed IRTF and TV-CST, we built a spatial-irregular tensor recovery model. Extensive experiments on real-world spatial-irregular tensors demonstrate the promising performance of our IRTF and its significant advantages on downstream tasks.},
  archive      = {J_KBS},
  author       = {Jin-Yu Xie and Hao Zhang and Xi-Le Zhao and Yi-Si Luo},
  doi          = {10.1016/j.knosys.2025.114372},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114372},
  shortjournal = {Knowl. Based Syst.},
  title        = {IRTF: A new tensor factorization for irregular multidimensional data recovery},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-driven deep learning network for image splicing forgery detection. <em>KBS</em>, <em>330</em>, 114365. (<a href='https://doi.org/10.1016/j.knosys.2025.114365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image splicing is a widely used technique for manipulating images in various social activities. Detecting splicing forgery is crucial in digital forensics to identify malicious image manipulation and protect information security. However, existing methods for detecting splicing forgery typically learn features in the spatial domain and struggle to effectively capture subtle features indicative of forgery, resulting in insufficient image splicing forgery detection accuracy. To address this challenge, we propose a novel deep-learning network named the frequency-driven deep-learning network (FreNet). Specifically, FreNet comprises three innovative modules: the frequency learnable module (FLM), the spatial-aware frequency learning module (SFLM), and the high-level feature-enhancement module (HFEM). The FLM effectively extracts high- and low-frequency features, thus enhancing frequency-domain representation and capturing subtle tampered features in splicing forgery images. The SFLM utilizes spatial information to guide frequency feature learning, thus enabling spatial-aware frequency feature learning. The HFEM enhances rich contextual and high-level semantic information through multilevel and multipath extraction and fusion. Extensive experiments on five benchmark datasets indicate that FreNet can achieve superior performance. Additionally, robustness experiments demonstrate the superior robustness of FreNet against various common attacks.},
  archive      = {J_KBS},
  author       = {Enji Liang and Kuiyuan Zhang and Zhongyun Hua and Xiaohua Jia},
  doi          = {10.1016/j.knosys.2025.114365},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114365},
  shortjournal = {Knowl. Based Syst.},
  title        = {Frequency-driven deep learning network for image splicing forgery detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MLDCGAN: A multimodal latent diffusion conditioned GAN model for accelerated and high-fidelity MRI-CT synthesis in radiotherapy planning. <em>KBS</em>, <em>329</em>, 114491. (<a href='https://doi.org/10.1016/j.knosys.2025.114491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) offers significant advantages in soft tissue contrast. However, it cannot directly provide electron density information for radiotherapy, relying instead on time-consuming and error-prone MRI-CT image registration. Synthetic CT (sCT) technology, which directly generates CT images from MRI, is pivotal for achieving only MRI-based radiotherapy. However, existing synthesis methods based on generative adversarial network (GAN) and diffusion models face challenges such as prolonged inference times and insufficient utilization of multimodal information, which severely hinder the clinical application of synthetic images. In this study, we propose a novel Multimodal Latent Diffusion Conditioned GAN (MLDCGAN) Model. First, we design a non-parametric non-Gaussian complex denoising distribution based on a conditional GAN, employing a multimodal distribution to achieve large-step denoising. This is combined with a pre-trained autoencoder to compress the image into a low-dimensional latent space, significantly reducing inference time. Second, we fully leverage multimodal MRI information by constructing a local refinement conditional generator with multimodal inputs, including T1-Weighted (T1W), T2-Weighted (T2W), and Mask images. The generator is enhanced by an adaptive weighted multi-sequence fusion module and an enhanced cross-attention module, significantly improving the structural consistency and detail fidelity of the generated sCT images. Finally, by jointly optimizing the style loss and content loss, we ensure the perceptual quality and clinical accuracy of the synthetic images. Experimental results demonstrate that MLDCGAN outperforms existing state-of-the-art methods on both public and private datasets, showing significant improvements in both image quality and inference speed. Subjective evaluations from multiple experienced clinicians indicate that the generated sCT images exhibit no significant difference from real CT in terms of key anatomical structure clarity and overall quality ( P > 0.05). Further assessments of clinical target delineation and dose distribution confirm that sCT retains anatomical features well and provides dose distributions consistent with real CT, ensuring the reliability of dose calculations in radiotherapy planning. This study provides a more reliable and efficient technical foundation for achieving only MRI-based radiotherapy. It is expected to assist clinicians in developing more precise radiotherapy plans, ultimately improving treatment outcomes in future clinical practice.},
  archive      = {J_KBS},
  author       = {Can Hu and Chunchao Xia and Chuanbing Wang and Xiayu Hang and Xiuhan Li and Han Zhou and Ning Cao},
  doi          = {10.1016/j.knosys.2025.114491},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114491},
  shortjournal = {Knowl. Based Syst.},
  title        = {MLDCGAN: A multimodal latent diffusion conditioned GAN model for accelerated and high-fidelity MRI-CT synthesis in radiotherapy planning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal knowledge graph forecasting query based on global-local historical information. <em>KBS</em>, <em>329</em>, 114476. (<a href='https://doi.org/10.1016/j.knosys.2025.114476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graph (TKG) queries aim to retrieve relevant facts that conform to time constraints to answer a given query by reasoning known TKG facts. The continuous development of TKG query research has extended TKG queries to the TKG forecasting domain, enabling the forecasting of answers to unknown queries by leveraging historical information from query questions. However, TKG forecasting query research is currently facing two considerable challenges. Firstly, existing TKG forecasting query methods cannot adequately capture the global historical information of query questions, which makes it difficult to effectively mine periodic features, repetitive patterns, and dynamic evolution characteristics of new events. Secondly, when modeling local historical information, existing methods fail to focus on the historical correlation of facts between adjacent timestamps, ignoring the crucial role of local information in the temporal evolution process. In this paper, a TKG forecasting query framework based on global-local historical information is proposed to solve the above challenges. Specifically, for the global historical information of the query question, the periodic and repetitive patterns of historical facts and the potential changing laws of non-historical facts are learned by modeling global historical facts and non-historical facts. Concerning the local historical information, entities and relations are aggregated in knowledge graph (KG) snapshots and their changes and evolution are simulated at adjacent timestamps to enhance the ability of the model to capture temporal dependencies. At the same time, the impact of local snapshots on query questions is quantified to capture the evolution process of local information more accurately. Finally, we design dedicated scoring functions for different types of query tasks to achieve effective query forecasting. Extensive experiments on four datasets demonstrate that the proposed model has better performances in forecasting unknown queries than other baseline models.},
  archive      = {J_KBS},
  author       = {Luyi Bai and Tongyue Zhang and Lin Zhu},
  doi          = {10.1016/j.knosys.2025.114476},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114476},
  shortjournal = {Knowl. Based Syst.},
  title        = {Temporal knowledge graph forecasting query based on global-local historical information},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proposed quaternion fractional dual-hahn moments for color image reconstruction and encryption. <em>KBS</em>, <em>329</em>, 114467. (<a href='https://doi.org/10.1016/j.knosys.2025.114467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moments are essential descriptors for capturing fundamental characteristics of a signal, such as its shape and texture, thereby enabling a compact and easily analyzable representation. This article introduces a new family of discrete fractional moments, the quaternion Cartesian fractional dual-Hahn moments (QCFrDHOMs). These moments are derived from the fractional dual-Hahn moments (FrDHOMs), which are constructed from the matrix of fractional dual-Hahn orthogonal polynomials (FrDHOPs), obtained through the spectral decomposition of the classical dual-Hahn orthogonal polynomials (DHOPs). To ensure the stability of the computations, particularly for high-degree polynomials, a recursive method is proposed to calculate the initial terms of the DHOPs, thereby reducing the risk of numerical instability. The FrDHOMs are then generalized into QCFrDHOMs for efficient analysis of color images using quaternion algebra. Experimental results demonstrate that the QCFrDHOMs outperform classical DHOMs in terms of robustness and reconstruction capability. Additionally, an encryption and decryption scheme using QCFrDHOMs and chaotic systems is presented. Tests show that this scheme provides significant resistance to various attacks while maintaining nearly intact quality in the decrypted images. This not only highlights the effectiveness of the encryption scheme but also the enhanced security and robustness of the approach. Compared to other existing methods, our scheme stands out for its exceptional reliability and robustness, making a significant contribution to the secure protection of color images.},
  archive      = {J_KBS},
  author       = {Karim El-khanchouli and Hanaa Mansouri and Ahmed Bencherqui and Hicham Karmouni and Nour-Eddine Joudar and Mhamed Sayyouri},
  doi          = {10.1016/j.knosys.2025.114467},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114467},
  shortjournal = {Knowl. Based Syst.},
  title        = {Proposed quaternion fractional dual-hahn moments for color image reconstruction and encryption},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transformer-based approach for traffic prediction with fusion spatiotemporal attention. <em>KBS</em>, <em>329</em>, 114466. (<a href='https://doi.org/10.1016/j.knosys.2025.114466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic data prediction is a crucial technology for data-driven intelligent transportation systems. This has an important impact on optimizing urban traffic management, travel efficiency, traffic experience, etc. Traffic flow prediction tasks primarily focus on mining dynamic spatiotemporal dependencies. Most existing Transformer-based methods and GNN-based methods have limitations in mining local-global spatiotemporal dependencies. To address this issue, we propose a novel traffic data prediction model called LGSTformer that can perceive local-global spatiotemporal dependencies. First, we construct an embedding layer that provides multiple types of embedding representations for the model by projecting spatiotemporal data and temporal and spatial information into different embeddings. Next, we design two modules to capture local-global temporal and spatial dependencies based on the naive spatiotemporal self-attention mechanism: the local-global temporal module and the local-global spatial module. The former incorporates multi-scale temporal convolutions to capture short-term temporal dependencies, and the latter incorporates dynamic-static graph convolutions to capture local spatial dependencies. Finally, to achieve effective fusion of local-global dependency information, a dual-path adaptive gated fusion layer based on a gating mechanism is introduced to attain adaptive fusion of information at different levels. Experimental results on four public real-world traffic datasets show that LGSTformer outperforms existing methods and has potential as an advanced solution for traffic flow prediction.},
  archive      = {J_KBS},
  author       = {Wenfeng Zhou and Guojiang Shen and Zhenzhen Zhao and Zhaolin Deng and Tao Tang and Xiangjie Kong and Amr Tolba and Osama Alfarraj},
  doi          = {10.1016/j.knosys.2025.114466},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114466},
  shortjournal = {Knowl. Based Syst.},
  title        = {A transformer-based approach for traffic prediction with fusion spatiotemporal attention},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SEER: Knowledge-driven semantic image restoration with vision-language diffusion alignment. <em>KBS</em>, <em>329</em>, 114464. (<a href='https://doi.org/10.1016/j.knosys.2025.114464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic communication is an emerging paradigm to enhance network efficiency and perceptual quality, particularly demonstrating strong potential in image generation tasks. However, existing deep learning (DL)-based single-modal reconstruction approaches often suffer from semantic distortion and image blurring under bandwidth-limited and highly noisy channel conditions, limiting their suitability in task-oriented perception scenarios. Although generative AI-based semantic communication can significantly reduce data transmission volume, its high sensitivity to channel noise and lack of dynamic adaptation mechanisms limit the stability of reconstruction. To address these challenges, this paper proposes a multi-modal semantic communication framework named SEER , designed for resource-constrained intelligent sensing terminals. Built upon a pretrained language model, SEER incorporates a channel-aware prompt control strategy, a dual-modal integrative semantic restoration mechanism (DISR), and a single-pass sequential cross-modal reconstruction pathway to achieve collaborative semantic representation and robust structural recovery between images and text. Experimental results demonstrate that SEER achieves approximately 2.08 % bandwidth compression, while outperforming existing methods under extreme channel conditions by 33.92 % in structural fidelity and 12.64 % in perceptual consistency, highlighting its strong engineering deployability.},
  archive      = {J_KBS},
  author       = {Shengliang Wu and Jun Jiang and Xin He and Yong Xu and Yujun Zhu and Weiwei Jiang and Heju Li},
  doi          = {10.1016/j.knosys.2025.114464},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114464},
  shortjournal = {Knowl. Based Syst.},
  title        = {SEER: Knowledge-driven semantic image restoration with vision-language diffusion alignment},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating structural and operational knowledge into multi-state system modeling: Application in urban infrastructures. <em>KBS</em>, <em>329</em>, 114457. (<a href='https://doi.org/10.1016/j.knosys.2025.114457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern engineering systems, with their increasing complexity driven by technological advancements and growing interdependencies among components, present a challenge to traditional binary-state models. These models, which classify components as either fully operational or failed, are insufficient for capturing the progressive degradation, redundancy mechanisms, and cascading effects observed in real-world systems. Multi-State System (MSS) modeling, which represents intermediate operability states, is a step forward. However, the current literature overlooks a crucial information source: the system’s internal dynamics. These dynamics, which play a crucial role in shaping the system’s behavior, can be leveraged to enhance the learning process in MSS modeling. This study introduces a novel hybrid MSS modeling methodology that incorporates a system’s internal dynamic - such as network topology, redundancy mechanisms, and operational constraints - within an MSS. The methodology is first applied to a Brazilian power system, demonstrating how internal system characteristics influence the state evolution of individual components over time. This evaluation highlights the ability of the model to capture nuanced operational behavior driven by system-level constraints. The methodology is tested on multiple European transmission systems in a second stage to assess its predictive performance in estimating key reliability metrics. The proposed approach consistently outperforms existing models, achieving significantly lower prediction errors by accounting for internal constraints and the system’s dynamics. This work offers a generalizable solution for critical infrastructure planning across domains, enhancing MSS reliability modeling in various engineering systems.},
  archive      = {J_KBS},
  author       = {Henrique O. Caetano and Luiz Desuó N and Marco Aiello and Carlos D. Maciel},
  doi          = {10.1016/j.knosys.2025.114457},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114457},
  shortjournal = {Knowl. Based Syst.},
  title        = {Integrating structural and operational knowledge into multi-state system modeling: Application in urban infrastructures},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stock conditional drawdown at risk portfolio optimization based on gated bidirectional temporal convolution and discrete cosine graph neural networks on hypervariable graphs. <em>KBS</em>, <em>329</em>, 114456. (<a href='https://doi.org/10.1016/j.knosys.2025.114456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of machine learning technology, the application of stock prediction in financial portfolio optimization has become increasingly important. This study proposes an intelligent portfolio optimization method that combines gated bidirectional temporal convolution-discrete cosine graph neural network (TDGNN) with the mean-conditional drawdown at risk (Mean-CDaR) model, aiming to improve the risk-return performance of the portfolio. The method consists of two main stages: first, the data is converted into a hypervariable graph through the TDGNN model, the gated bidirectional temporal convolution layer is used to capture the temporal dynamic characteristics, and the discrete cosine graph neural network is combined to effectively model the complex spatiotemporal relationship in the stock market; second, the Mean-CDaR model is used for portfolio optimization, and the maximum drawdown is used as a measurement indicator to achieve precise risk control. Experimental results show that on the CSI 300, S&P500, and Nikkei 225 data sets, TDGNN and Mean-CDaR models perform significantly better than traditional methods, with R 2 of 0.9991, 0.9991, and 0.9983, respectively. Under the assumption of no transaction costs, the cumulative returns are 0.42, 0.62, and 0.93, respectively; considering 0.05 % transaction costs, the cumulative returns are 0.1, 0.25, and 0.49, respectively. The study shows that this method not only effectively captures the spatiotemporal dependency of stock data but also effectively controls risks while improving returns, providing investors with a robust and efficient decision support system.},
  archive      = {J_KBS},
  author       = {Chia-Hung Wang and Chiwang Lin},
  doi          = {10.1016/j.knosys.2025.114456},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114456},
  shortjournal = {Knowl. Based Syst.},
  title        = {Stock conditional drawdown at risk portfolio optimization based on gated bidirectional temporal convolution and discrete cosine graph neural networks on hypervariable graphs},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Utility and occupancy driven pattern analysis for processing dynamic data streams in damped window control. <em>KBS</em>, <em>329</em>, 114453. (<a href='https://doi.org/10.1016/j.knosys.2025.114453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data analysis is suitable for data control systems by discovering hidden knowledge that is difficult for humans to perceive from huge and complex data. In various data analysis methods, high utility occupancy pattern analysis considers the utility occupancy of each pattern in the corresponding transaction in addition to the profit and quantity of patterns, which is effective for data control systems, including data science fields. However, recent data holds more insightful knowledge when processing real-time generated data. Previous occupancy-based approaches do not handle the relative significance of the latest data. To overcome the limitation, we introduce a new method for discovering high utility occupancy patterns from dynamic data streams where time-sensitive data consistently occurs. The proposed method assigns relative importance to each pattern by considering the temporal aspect of each transaction. Advanced constructing and restructuring processes are utilized in the proposed method for efficiently controlling data according to the time flow of each pattern in dynamic environments. In the pattern expansion process, a new upper bound adopting the decaying factor is suggested to efficiently reduce unnecessary searches for unpromising patterns. Experimental results demonstrate that the proposed method has superior runtime and scalability performance compared to state-of-the-art methods with comparable memory usage. The ablation study underscores how the proposed components contribute to the overall effectiveness of the proposed method. Additional evaluations indicate that the proposed method analyzes insightful result patterns compared to state-of-the-art methods, and a case study demonstrates its applicability to real-time dynamic data control systems.},
  archive      = {J_KBS},
  author       = {Taewoong Ryu and Doyoung Kim and Seungwan Park and Seongbin Park and Myungha Cho and Hanju Kim and Junyoung Park and Hyeonmo Kim and Unil Yun},
  doi          = {10.1016/j.knosys.2025.114453},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114453},
  shortjournal = {Knowl. Based Syst.},
  title        = {Utility and occupancy driven pattern analysis for processing dynamic data streams in damped window control},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel TriCore scheme for multiple RGB images in telemedicine environments. <em>KBS</em>, <em>329</em>, 114451. (<a href='https://doi.org/10.1016/j.knosys.2025.114451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scientific community is paying high attention to propose efficient solution to the open problem related to security and privacy of still visual communications. Telemedicine is one of the real world applications, experiencing such security concerns related to virtual consultation. Among the presence of already defined encryption schemes, this paper is dedicated to define TriCore, an efficient encryption scheme for multiple RGB images, inspired by three core components: σ ∃ -permutation, Laplacian matrix and 4D hyper chaotic system. The use of Secure Hash Algorithm-256 (SHA-256) in key generation assures the randomness and make it highly sensitive. Also, this paper presents a novel σ ∃ -permutation, to enhance the randomness effect in the corresponding cipher image. The scheme mainly deals with the matrices corresponding to the three channels of the merged image, undergoing σ ∃ -permutation and XOR operations with pair of channel matrices and key matrices, a single cipher image is produced corresponding to multiple RGB images. It prevents the revelation of actual number of shared images and make the scheme more strong. Obtaining the ideal values, experimental results witness the efficiency of TriCore scheme. The entropy is measured as 7.9998. The high resistance against the differential attacks is measured through the Number of Pixel Change rate (99.6158 % ) and Unified Average Changing Intensity (33.4621 % ). The execution time for 4 images each of size 256 × 256 is just 0.173470 s. The experimental results show that this paper efficiently facilitates secure communications in telemedicine providing higher security at lowest computational costs.},
  archive      = {J_KBS},
  author       = {Muhammad Tanveer Hussain and Imrana Shafique and Shamsher Ullah},
  doi          = {10.1016/j.knosys.2025.114451},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114451},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel TriCore scheme for multiple RGB images in telemedicine environments},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). G-GTNet: Gestalt-inspired graph transformer network for robust point cloud registration. <em>KBS</em>, <em>329</em>, 114450. (<a href='https://doi.org/10.1016/j.knosys.2025.114450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Removing outliers is of paramount importance in the process of feature-based point cloud registration. However, it is still extremely challenging due to the high proportion of outliers, and the estimation of the accurate transmission matrix depends on the distribution of the inliers. The effective extraction of contextual information (local view) and the acquisition of full structural information (global view) influence the identification of inliers. Inspired by Gestalt principles in handling local and global relationships, we propose a Gestalt-inspired Graph Transformer Network (G-GTNet) for robust point cloud registration. G-GTNet extracts broader and more reliable contextual information while effectively aggregating both local and global features. Specifically, adhering to Gestalt principles, we design a multi-granularity aggregation (MGA) block that refines feature maps through a cascaded expanding path to acquire contextual details and promote information exchange among correspondences. In addition, to establish a consensus mechanism between local and global information, we introduce a global consensus attention (GCA) block. Similarly, the GCA follows Gestalt principles to optimally integrate local details and information about global structure, which allows it to gather information on a larger scale. Furthermore, a dependable seed selection (DSS) block is designed to filter out reliable and evenly distributed correspondences by distinguishing outliers and inliers more efficiently. Extensive experiments demonstrate that G-GTNet achieves better performance than state-of-the-art methods. It exhibits competitive performance and robustness in both outlier removal and pose estimation tasks across various public datasets with diverse feature descriptors. Notably, our proposed G-GTNet achieves an RR of 84.36 % on the 3DMatch using FPFH descriptor, surpassing S C 2 -PCR by 1.33 %. Our code will be released at https://github.com/gwk429/G-GTNet .},
  archive      = {J_KBS},
  author       = {Weikang Gu and Mingyue Han and Li Xue and Jiaming Yu and Heng Dong and Changcai Yang and Riqing Chen and Lifang Wei},
  doi          = {10.1016/j.knosys.2025.114450},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114450},
  shortjournal = {Knowl. Based Syst.},
  title        = {G-GTNet: Gestalt-inspired graph transformer network for robust point cloud registration},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precision through progression: Empowering temporal knowledge graph reasoning with knowledge-guided chain of thought. <em>KBS</em>, <em>329</em>, 114448. (<a href='https://doi.org/10.1016/j.knosys.2025.114448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Knowledge Graphs (TKGs) have emerged as a powerful paradigm for event forecasting, owing to their ability to dynamically represent the evolving relationships between entities over time. By effectively reasoning along the temporal dimension, TKGs help address real-world data incompleteness through inference of missing facts. Recent advances in large language models (LLMs) have led to their integration with TKG reasoning tasks. However, current LLM-based approaches face three critical challenges: (1) insufficient utilization of background knowledge, (2) inadequate modeling of the evolving temporal dynamics intrinsic to TKGs, and (3) difficulty in bridging the structural mismatch between the graph structure and the sequential operation mode of LLMs. To address these challenges, we propose EV-COT, a novel EVent-aware Chain-Of-Thought reasoning framework designed to explicitly model event evolution through structured, interpretable reasoning chains. EV-COT comprises three modular, plug-and-play components – knowledge module, perception module, and thinking module – that work collaboratively to extract essential event-related cues for enhanced reasoning. Specifically, the knowledge module generates high-quality contextual knowledge to enrich entity representation, and the perception module captures intricate structural and temporal patterns inherent in TKGs. Moreover, the thinking module extracts temporal logical rules, facilitating interpretable step-by-step reasoning. By effectively integrating these diverse contextual knowledge, EV-COT delivers more accurate predictions. Extensive evaluations on three datasets demonstrate that EV-COT consistently outperforms state-of-the-art methods, highlighting its effectiveness for precise event forecasting in TKGs.},
  archive      = {J_KBS},
  author       = {Zhangtao Cheng and Shichong Li and Yichen Xin and Bin Chen and Ting Zhong and Fan Zhou},
  doi          = {10.1016/j.knosys.2025.114448},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114448},
  shortjournal = {Knowl. Based Syst.},
  title        = {Precision through progression: Empowering temporal knowledge graph reasoning with knowledge-guided chain of thought},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Taxonomy-guided routing in capsule network for hierarchical image classification. <em>KBS</em>, <em>329</em>, 114444. (<a href='https://doi.org/10.1016/j.knosys.2025.114444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical multi-label classification in computer vision presents significant challenges in maintaining consistency across different levels of class granularity while capturing fine-grained visual details. This paper presents Taxonomy-aware Capsule Network (HT-CapsNet), a novel capsule network architecture that explicitly incorporates taxonomic relationships into its routing mechanism to address these challenges. Our key innovation lies in a taxonomy-aware routing algorithm that dynamically adjusts capsule connections based on known hierarchical relationships, enabling more effective learning of hierarchical features while enforcing taxonomic consistency. Extensive experiments on six benchmark datasets, including Fashion-MNIST, Marine-Tree, CIFAR-10, CIFAR-100, CUB-200-2011, and Stanford Cars, demonstrate that HT-CapsNet significantly outperforms existing methods across various hierarchical classification metrics. Notably, on CUB-200-2011, HT-CapsNet achieves absolute improvements of 10.32 % , 10.2 % , 10.3 % , and 8.55 % in hierarchical accuracy, F1-score, consistency, and exact match, respectively, compared to the best-performing baseline. On the Stanford Cars dataset, the model improves upon the best baseline by 21.69 % , 18.29 % , 37.34 % , and 19.95 % in the same metrics, demonstrating the robustness and effectiveness of our approach for complex hierarchical classification tasks.},
  archive      = {J_KBS},
  author       = {Khondaker Tasrif Noor and Wei Luo and Antonio Robles-Kelly and Leo Yu Zhang and Mohamed Reda Bouadjenek},
  doi          = {10.1016/j.knosys.2025.114444},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114444},
  shortjournal = {Knowl. Based Syst.},
  title        = {Taxonomy-guided routing in capsule network for hierarchical image classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning with gradient norm arbitration for sample-aware few-shot learning. <em>KBS</em>, <em>329</em>, 114443. (<a href='https://doi.org/10.1016/j.knosys.2025.114443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to rapidly adapt to unseen tasks is a fundamental objective in few-shot learning. Recent advances in optimization-based meta-learning have enhanced adaptability by learning sharable prior knowledge across tasks with just a few gradient descent steps. However, we argue that this shared prior knowledge can exert an imbalanced influence on individual samples within tasks, potentially resulting in a broad loss distribution where samples closely aligned with the prior knowledge exhibit low loss values, while others display high loss values. Furthermore, our experiments show that gradients computed as the average from a broad loss distribution tend to be non-representative and low, leading to poor generalization performance since the contribution of high-loss samples is diminished by low-loss samples. To address this, we propose a novel meta-learning method that arbitrates gradient norms based on sample-aware information during task adaptation. Specifically, we first normalize the gradient vector to reduce the imbalanced influence of prior knowledge on individual samples. Subsequently, the Arbiter, a learnable network, dynamically scales the current gradient norm by analyzing the relationship between original gradient norms and weight norms, which indicates the model’s sensitivity and complexity to each sample. In this way, the proposed method, Meta-learning with Gradient Norm Arbitration (Meta-GNA), improves generalization performance by preserving more representative and higher gradients that adequately reflect high-loss samples, which are distantly aligned with prior knowledge. Experimental results show that Meta-GNA improves performance in few-shot classification, particularly in cross-domain scenarios where the imbalance in prior knowledge across samples is more pronounced.},
  archive      = {J_KBS},
  author       = {Jongmin Lim and Soobin Cha and Heesan Kong and Sungkuk Shyn and Kwangsu Kim},
  doi          = {10.1016/j.knosys.2025.114443},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114443},
  shortjournal = {Knowl. Based Syst.},
  title        = {Meta-learning with gradient norm arbitration for sample-aware few-shot learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward efficient digital twin simulation: A causal representation learning approach. <em>KBS</em>, <em>329</em>, 114442. (<a href='https://doi.org/10.1016/j.knosys.2025.114442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, digital twin (DT) technology has emerged as a focal point in the field of shaft system prognostics and health management. To reduce simulation time cost and computational overhead, data-driven intelligent data generation algorithms have been employed as surrogates for traditional finite element simulations. However, such algorithms are typically constrained to generating in-distribution data within known operational domains and fail to generalize to out-of-distribution data under unseen conditions, which significantly hindering the development of DT model under variable operating scenarios. To address this limitation, this paper proposes a novel causal factorization–recombination network (CFRN) for generating shaft vibration responses under previously unseen operating conditions. Firstly, the structural causal model (SCM) for shaft vibration response is constructed to encode the causal mechanisms linking two critical operational parameters with vibration responses. Based on the SCM, a dual-encoder architecture is developed. By optimizing causal consistency loss, causal independence loss, and reconstruction loss, the model identifies latent mediators associated with the two causal factors. Additionally, a novel bidirectional cross-attention mechanism is introduced to equitably integrate mediators corresponding to different combinations of causal factors, enabling robust feature representation under unseen operational conditions. Finally, the recombined features are utilized to synthesize vibration response data. The proposed CFRN is validated using a shaft system simulation dataset. Extensive comparative experiments demonstrate that the generated data under unseen conditions by CFRN achieves 98.06% accuracy on crucial frequency. The proposed approach offers a novel paradigm for accelerating simulation response in DT frameworks.},
  archive      = {J_KBS},
  author       = {Shuyang Luo and Jiachang Qian and Yunhan Geng and Qi Zhou and Quan Lin},
  doi          = {10.1016/j.knosys.2025.114442},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114442},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward efficient digital twin simulation: A causal representation learning approach},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning methods for chaotic time series prediction. <em>KBS</em>, <em>329</em>, 114441. (<a href='https://doi.org/10.1016/j.knosys.2025.114441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chaos is a fundamental property of nonlinear dynamical systems, characterized by sensitivity to initial conditions, aperiodicity, and long-term unpredictability. It arises in numerous real-world processes-especially in energy systems, atmospheric dynamics, financial markets, and biomedical signals-where small perturbations may lead to drastic changes. Owing to its practical importance and modeling complexity, chaotic system prediction has received increasing attention in recent years. Regarding chaotic time series forecasting, deep learning offers strong capability in capturing nonlinear dependencies and long-horizon patterns. This review provides a comprehensive summary of deep learning techniques in this area, covering five core model classes: recurrent networks, convolutional structures, attention-based models, graph neural networks, and generative architectures. It also discusses hybrid modeling schemes, input-output paradigms, evaluation strategies, and complexity analysis. In addition, challenges-such as noise, missing data, and non-stationarity-are examined, along with recent efforts to mitigate them through signal decomposition, data completion, lightweight design, and loss adaptation. Real-world applications across diverse fields are surveyed to validate model effectiveness under complex conditions. This review offers new insight into the development of reliable, efficient, and generalizable deep learning frameworks for chaotic sequence prediction-highlighting directions such as physics-informed learning, lightweight architectures, and advanced hardware architectures.},
  archive      = {J_KBS},
  author       = {Yangyang Kui and Qiang Lai},
  doi          = {10.1016/j.knosys.2025.114441},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114441},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep learning methods for chaotic time series prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust label propagation based on prior-guided cross domain data augmentation for few-shot unsupervised domain adaptation. <em>KBS</em>, <em>329</em>, 114432. (<a href='https://doi.org/10.1016/j.knosys.2025.114432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot unsupervised domain adaptation (FS-UDA) aims to leverage knowledge from an imbalanced, labeled source domain and apply it to an unlabeled target domain. The primary difficulties of FS-UDA stem from the disparity in data distributions across source and target domains, coupled with uneven class representation in the source data. Label propagation (LP) is commonly used in domain adaptation scenarios. However, in FS-UDA tasks, LP disproportionately favors the normal classes because the source domain suffers from imbalanced class distribution, which results in insufficient feature representation and a large domain gap for the few-shot classes. To tackle these problems, we introduce a new robust LP approach that leverages prior-guided cross-domain data augmentation for FS-UDA. Unlike conventional approaches that solely utilize source domain visual data for few-shot class augmentation, our proposed method employs contrastive language image pretraining-derived semantic priors to supervise visual feature extractor training and optimize few-shot prototypes. It enhances domain-invariant feature learning while mitigating cross-domain distribution mismatches. We introduce the visual information from the target domain to perform data augmentation via style transfer, obtaining more diverse class-specific information. Subsequently, we capture intradomain and interdomain relationships more accurately by constructing intradomain and interdomain graphs independently for all samples (original and augmented) from both domains, which facilitates more effective LP and makes LP robust to few-shot classes. Furthermore, we introduce an adaptive graph regularization loss to dynamically adjust class weights, enhance intraclass compactness within domains, and reduce intraclass distribution discrepancies between different domains. Comprehensive experiments validate that the proposed method achieves superior performance compared to existing state-of-the-art methods across various FS-UDA tasks. The proposed method achieves 77.3 % and 61.7 % average accuracies for few-shot classes on the Office-31 and Office-Home datasets, respectively.},
  archive      = {J_KBS},
  author       = {Peng Zhao and Jiakun Shi and Ping Ye and Huiting Liu and Xia Ji},
  doi          = {10.1016/j.knosys.2025.114432},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114432},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust label propagation based on prior-guided cross domain data augmentation for few-shot unsupervised domain adaptation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced binary particle swarm optimization for mitigating pandemic spread through passenger air traffic management. <em>KBS</em>, <em>329</em>, 114430. (<a href='https://doi.org/10.1016/j.knosys.2025.114430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study tackles a complex binary multi-objective optimization problem focused on minimizing the risk of pandemic importation through strategic passenger air traffic management. The approach involves determining whether international connections to destination airports within a specified country should be activated or deactivated over a defined time frame, considering epidemiological, economic, and socio-political impacts. We introduce a preliminary decision support system designed to assist decision-makers in the parametrization of the problem and quantify their preferences, thereby facilitating the derivation of a compromise solution via a binary particle swarm optimization (BPSO) metaheuristic. The standard BPSO is prone to particles getting trapped in local optima instead of searching for new solution and does not handle infeasible solutions properly. To overcome these inherent limitations, we propose an enhanced version of the BPSO metaheuristic. This enhanced algorithm incorporates novel mechanisms to promote solution space exploration and a robust strategy for managing infeasible solutions. A rigorous comparative analysis is conducted to evaluate the performance of the enhanced BPSO against both the original BPSO and several established state-of-the-art metaheuristics utilizing three benchmark datasets of a constrained problem. Finally, the effectiveness of the proposed enhanced metaheuristic is demonstrated in the context of the pandemic importation risk reduction problem, where it outperforms the original BPSO.},
  archive      = {J_KBS},
  author       = {Gabriel A. Peña and Antonio Jiménez-Martín and Alfonso Mateos},
  doi          = {10.1016/j.knosys.2025.114430},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114430},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced binary particle swarm optimization for mitigating pandemic spread through passenger air traffic management},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid domain based data embedding using quantization index modulation and metaheuristic optimization. <em>KBS</em>, <em>329</em>, 114429. (<a href='https://doi.org/10.1016/j.knosys.2025.114429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding additional information into digital images is an effective method of data privacy protection. A data hiding scheme needs to have a high level of imperceptibility to provide a high level of security. At the same time, it is necessary to maintain good capacity and ability to extract information in its original form. In this study, we propose an adaptive scheme for embedding data into the hybrid spatial-frequency domain of images based on the quantization index modulation (QIM) method. Information embedding is performed by small changes in pixels in the spatial domain using a change matrix. A genetic algorithm finds the optimal change matrix for each image block. The objective function combines visual invisibility, statistical invisibility, and extraction stability metrics. Information extraction is performed in the Discrete Cosine Transform (DCT) domain. Using the hybrid spatial-frequency domain reduces the number of DCTs and inverse DCTs when calculating objective function values during optimization. Additionally, we adaptively select quantization step values. Experimental results show that the proposed scheme is efficient in terms of embedding quality indicators. Moreover, the influence of additional information embedding on image histogram in the frequency domain is minimized. In terms of imperceptibility, our scheme achieves an average PSNR of 44.0920 dB, SSIM of 0.9995, and NCC of 0.9998 with an average capacity of 0.4640 bpp. The embedded information is extracted without errors in all cases and no additional information or re-optimization is required during extraction.},
  archive      = {J_KBS},
  author       = {Anna Melman and Oleg Evsutin},
  doi          = {10.1016/j.knosys.2025.114429},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114429},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hybrid domain based data embedding using quantization index modulation and metaheuristic optimization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-coordinate graph representation with temporal edge encoding for multi-agent trajectory prediction. <em>KBS</em>, <em>329</em>, 114427. (<a href='https://doi.org/10.1016/j.knosys.2025.114427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory prediction is critical in multi-agent systems, with applications in autonomous driving, surveillance, and robotic collaboration. It aims to anticipate future agent behaviors to support proactive decision-making. However, modeling the temporal evolution of agent interactions in complex environments remains challenging. This paper introduces a dual-perspective trajectory prediction framework that integrates a dual-coordinate graph representation with temporally-aware edge modeling. Agent-centric interactions are captured using graph attention networks, while global scene-level dependencies are modeled via a Transformer. A cross-perspective fusion module merges these complementary features into expressive node embeddings. To better capture dynamic interaction patterns, a temporal edge encoding module combines relative positional features with sequential information. This design improves the model’s temporal sensitivity and robustness. Experiments on Argoverse 1 and Argoverse 2 benchmarks show that the proposed method achieves strong single-modal prediction accuracy while maintaining competitive multi-modal performance. Ablation studies validate the contributions of each module, highlighting the framework’s effectiveness, generalization capability, and potential for real-world deployment in complex multi-agent scenarios.},
  archive      = {J_KBS},
  author       = {Xudong Zhang and Yingqun Liu and Jie Fan and Guodong Du and Yuan Zou and Xuan Liu},
  doi          = {10.1016/j.knosys.2025.114427},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114427},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-coordinate graph representation with temporal edge encoding for multi-agent trajectory prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DGPR: Towards privacy-preserving recommendation via bayesian data generation. <em>KBS</em>, <em>329</em>, 114425. (<a href='https://doi.org/10.1016/j.knosys.2025.114425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recommender system achieves more accurate user profile mining, the risk of user privacy disclosure increases. To address this, existing privacy protection-aware works model user interests and sensitive attributes and maintain independence between them. However, these efforts ignore the extraction of potentially interesting and similar items when modeling interest and sensitive properties. In this paper, a data generation-based privacy-aware recommendation (DGPR) is proposed to improve the modeling of interest and sensitive attributes to protect privacy. Specifically, a Bayesian data generation module is designed to construct the interaction behavior of potential interest items and potential attributes-similar items. Based on the generated data, DGPR learns representations of users/items with mutual information constraint to contain less sensitive attributes. In addition, DGPR focuses on the leakage of privacy from the recommendation list by using adversarial learning to remove sensitive attributes that were leakaged from the representation of the recommendation list of each user. A new metric RLP is designed to measure privacy leakage at the recommendation list level. Experiments are conducted on two publicly available datasets to verify the effectiveness of our proposed model in improving recommendation accuracy and privacy protection.},
  archive      = {J_KBS},
  author       = {Shenghao Liu and Guoyang Wu and Xianjun Deng and Hongwei Lu and Yuanyuan He and Minmin Cheng and Laurence Yang},
  doi          = {10.1016/j.knosys.2025.114425},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114425},
  shortjournal = {Knowl. Based Syst.},
  title        = {DGPR: Towards privacy-preserving recommendation via bayesian data generation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective optimization of sampling locations for source detection of antibiotic-resistant genes in hydrosystems. <em>KBS</em>, <em>329</em>, 114424. (<a href='https://doi.org/10.1016/j.knosys.2025.114424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Antimicrobial resistance is a growing global challenge with significant implications for public health. Wastewater surveillance offers a promising approach to monitoring and predicting the dissemination of antibiotic-resistant bacteria and genes (ARGs) in systems like sewer systems. However, current studies often lack integration between the optimization of sampling locations and the dynamic updating of predicted source locations based on continuous measurements. This paper proposes a novel data-driven framework that bridges this gap by combining multi-objective optimization for selecting optimal sampling locations with Bayesian updating for probabilistic source detection. The framework accounts for DNA degradation, sewage dilution and measurement variability to realistically simulate ARG concentrations in hydrosystems. Through iterative updates guided by detected signals at selected sampling locations, the model refines the likelihood of each sub-catchment being the main source of multiple ARGs, enabling accurate source localization. Validation was conducted using two real-world sewer systems under varying structural and sampling constraints. Across 1,000 simulated ARG scenarios and different sampler limits, results show that using only 3 and 5 samplers, the framework can achieve over 80% detection accuracy within four iterations; using 7 and 12 samplers raises accuracy to above 90%, depending on the complexity of the networks. These findings demonstrate the scalability, robustness, and practical applicability of the framework for ARG monitoring and decision support in diverse wastewater systems.},
  archive      = {J_KBS},
  author       = {Yao Yao and Regina Nogueira and Frank Klawonn and Markus Wallner},
  doi          = {10.1016/j.knosys.2025.114424},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114424},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-objective optimization of sampling locations for source detection of antibiotic-resistant genes in hydrosystems},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLAV: Clustering latent vector aggregation for whole slide image retrieval leveraging foundation models. <em>KBS</em>, <em>329</em>, 114423. (<a href='https://doi.org/10.1016/j.knosys.2025.114423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-Based Image Retrieval (CBIR) is crucial in cancer diagnosis, assisting pathologists by providing similar image data from previous records for analysis, especially when there is uncertainty in diagnosing a case. This process supports decision-making by providing valuable reference points to guide the diagnostic process. Foundation models have become increasingly important in the medical field due to their ability to generalize across various tasks and datasets, offering valuable support to pathologists by enhancing the accuracy and efficiency of diagnostic processes. In this article, a foundation model pre-trained on histopathology data is leveraged as a feature extractor without the need for task-specific training, in contrast to existing models that require extensive training to learn significant data representations. The proposed method, Clustering Latent Vector Aggregation (CLAV), condenses the significant feature vectors into a unique representative vector for the Whole Slide Image (WSI). Using a unique feature vector offers the advantage of reducing the size of the memory bank, thereby making the process of querying and retrieving similar WSIs more efficient. The experimental results presented in this study demonstrate that the proposed method enhances performance in CBIR tasks. This article highlights the potential of foundation models to achieve superior retrieval metrics compared to state-of-the-art methods specifically trained for CBIR.},
  archive      = {J_KBS},
  author       = {Alejandro Golfe and Pablo Meseguer and Valery Naranjo and Adrián Colomer},
  doi          = {10.1016/j.knosys.2025.114423},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114423},
  shortjournal = {Knowl. Based Syst.},
  title        = {CLAV: Clustering latent vector aggregation for whole slide image retrieval leveraging foundation models},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributor-centric model watermarking for image generative models. <em>KBS</em>, <em>329</em>, 114422. (<a href='https://doi.org/10.1016/j.knosys.2025.114422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an efficient watermarking method for generative models that allows the developer (distributor) to create model instances with unique watermarks that are naturally embedded in their generated images. To achieve this, we replace the convolution layers of the generator with Watermark-Informed Convolution (WIC) in the pre-trained model. WIC consists of N parallel standard convolution kernels, and a watermark encoder transforms watermarks into coefficients that modulate these parallel kernels. Once fine-tuned with WIC, the distributor only needs to generate the coefficients and use them to combine the parallel kernels in WIC to create a generator with the desired watermark. Importantly, the combined kernel is identical to a standard convolution kernel, ensuring no additional inference overhead. Our method is highly scalable and efficient, making it practical for forensic capabilities by embedding watermarks directly into model parameters, remaining robust against common attacks such as model pruning or image compression. Furthermore, we evaluate our method on scenarios with highly aggressive compression or advanced adversarial attacks, and the trade-offs between watermark capacity, robustness, and computational efficiency. Experiments on multiple generative models demonstrate that the proposed method is architecture-agnostic, achieves high fidelity, and provides superior robustness compared to the existing methods.},
  archive      = {J_KBS},
  author       = {Jianwei Fei and Yunshu Dai and Wenyuan Yang and Zhihua Xia},
  doi          = {10.1016/j.knosys.2025.114422},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114422},
  shortjournal = {Knowl. Based Syst.},
  title        = {Distributor-centric model watermarking for image generative models},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QuadAt-GAN: Quad attention enabled generative adversarial network for photorealistic image generation. <em>KBS</em>, <em>329</em>, 114421. (<a href='https://doi.org/10.1016/j.knosys.2025.114421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, photorealistic image generation has been a significant task in computer vision applications. Artificial intelligence-based generative models have attracted significant attention because they can generate samples that nearly resemble the properties of the training data. However, traditional methods leveraged for image generation tasks pose certain limitations such as model collapse, overfitting, and lack of diversity. As a result, this research aims to generate photorealistic images in the presence of adversarial attacks using the Quad Attention-enabled Generative Adversarial Networks (QuadAt-GAN) framework. The proposed QuadAt-GAN model can create photorealistic images from both text and image inputs. In addition, the incorporation of four different adversarial attacks in this research aids the system in fortifying itself against potential manipulations, thereby enhancing the robustness of the generated images. Moreover, the Quad attention (QuadAt) in the discriminator section refines the image generation process and equips the framework with a much better comprehension of the global information thus reducing the computational complexity of the model. The experimental results indicate the superiority of the proposed model for the photorealistic image generation task. When compared with the existing techniques the QuadAt-GAN model achieves a superior Structural similarity index measure (SSIM) of 0.95 for the Flickr 8k dataset with a training percentage of 80.},
  archive      = {J_KBS},
  author       = {Mohd Miskeen Ali and Mujahedullah H. Syed (S M) and Zeeshan Ahmed Mohammed and Ahmed Shahebaaz},
  doi          = {10.1016/j.knosys.2025.114421},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114421},
  shortjournal = {Knowl. Based Syst.},
  title        = {QuadAt-GAN: Quad attention enabled generative adversarial network for photorealistic image generation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-light image enhancement with luminance duality. <em>KBS</em>, <em>329</em>, 114420. (<a href='https://doi.org/10.1016/j.knosys.2025.114420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured under low-light conditions often suffer from high noise levels and a loss of details. Existing Low-light enhancement approaches often assume illumination as a global factor under Retinex theory, which may need to be more balanced with the complexities of real-world scenes with diverse lighting conditions. We propose a novel enhancement approach rooted in the Direct Perception (DP) theory. Through empirical evidence from real-world scenes, we illustrate the phenomenon of the duality of luminance in DP model, highlighting that luminance can exhibit both global and regional variations. Motivated by the above, we propose a novel low-light image enhancement framework, namely DPNet, that considers global and local luminance differences. Central to our approach is the introduction of two key modules: the Lumimator , a luminance estimator that leverages both local and global attention mechanisms, and the NLRestorer , a normal-light restoration network that effectively fuses color and luminance information for image restoration. Extensive experiments validate the efficacy of our framework, demonstrating significant enhancements in image quality metrics over state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Xingguo Lv and Xingbo Dong and Jiewen Yang and Lei Zhao and Bin Pu and Zhe Jin and Yudong Zhang},
  doi          = {10.1016/j.knosys.2025.114420},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114420},
  shortjournal = {Knowl. Based Syst.},
  title        = {Low-light image enhancement with luminance duality},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HBOFFS: Hybrid breeding optimization algorithm inspired federated feature selection for intrusion detection in IIoT. <em>KBS</em>, <em>329</em>, 114419. (<a href='https://doi.org/10.1016/j.knosys.2025.114419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection systems in the Industrial Internet of Things (IIoT) face challenges from high-dimensional, redundant data, making feature selection (FS) critical. Moreover, IIoT data is distributed across devices, creating data silos as for privacy concerns. Although federated learning (FL) has been extensively applied, existing federated FS methods based on swarm intelligence have limitations in both solution quality and convergence. To overcome these issues, we propose a hybrid breeding optimization algorithm inspired federated FS (HBOFFS) for intrusion detection in IIoT. Specifically, HBOFFS operates within a horizontal FL framework, where each client first employs a hybrid breeding optimization algorithm that integrates immune evolutionary mechanisms with cauchy distribution-based sampling (IC-HBO) to select a private optimal feature subset. IC-HBO improves both the global search capability and convergence efficiency of FS. Furthermore, a multi-client cooperative ensemble strategy (MCCES) is utilized, leveraging homomorphic encryption and secure multi-party computation to ensure the transmission of the feature weight matrix and corresponding indices of the selected feature subsets between clients and the server. The performance of HBOFFS is evaluated on several benchmark datasets, including CEC2022, UCI, NSL-KDD, HAI, and WUSTL-IIOT, using classifiers such as KNN, SVM, and XGBoost. The experimental results demonstrate that HBOFFS consistently outperforms state-of-the-art federated FS methods in terms of classification accuracy, recall, F1-score, runtime, and convergence speed, while effectively preserving data privacy.},
  archive      = {J_KBS},
  author       = {Zhiwei Ỹe and Songsong Zhang and Wen Zhou and Libing Wu and Ting Cai and Mingwu Zhang and Mingwei Wang and Jixin Zhang and Mengya Lei},
  doi          = {10.1016/j.knosys.2025.114419},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114419},
  shortjournal = {Knowl. Based Syst.},
  title        = {HBOFFS: Hybrid breeding optimization algorithm inspired federated feature selection for intrusion detection in IIoT},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge-driven deep reinforcement learning approach for dynamic scheduling of re-entrant hybrid flow shop with in-line product quality inspection. <em>KBS</em>, <em>329</em>, 114418. (<a href='https://doi.org/10.1016/j.knosys.2025.114418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time product quality inspection (QI) of products during manufacturing enables early defect detection and reduces resource waste. However, dynamic disturbances arising from QI, such as machine maintenance and rework operations, impose significant challenges to real-time production scheduling. In this study, a dynamic re-entrant hybrid flow shop scheduling problem considering in-line product quality inspection (DHFSP-QI) is investigated, where product quality variations dynamically impact production scheduling. To address this challenge, a multi-agent system (MAS) is developed to model dynamic shop-floor interactions among machines, quality detectors, products, and scheduling units. A knowledge-driven deep reinforcement learning (DRL) framework integrated with variable neighborhood search (KDRL-VNS) is proposed. The VNS-enhanced reward feedback mechanism guides agents to acquire efficient strategies. The DRL-enhanced scheduling agents use graph attention networks (GATs) to extract graph-based state representations of the workshop in real time, thereby enabling dynamic-scheduling decisions aimed at the minimizing total weighted tardiness. Experimental evaluations across multiple scenarios demonstrate that the proposed method, by incorporating VNS-based expert knowledge, outperforms various heuristic algorithms, genetic programming algorithms and DRL algorithms. It achieves accelerated convergence and delivers an average 4.6% relative improvement in performance compared to DRL methods.},
  archive      = {J_KBS},
  author       = {Youshan Liu and Jiaxin Fan and Chunjiang Zhang and Weiming Shen},
  doi          = {10.1016/j.knosys.2025.114418},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114418},
  shortjournal = {Knowl. Based Syst.},
  title        = {A knowledge-driven deep reinforcement learning approach for dynamic scheduling of re-entrant hybrid flow shop with in-line product quality inspection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WinGraphUNet: Advanced windowed graph modeling with remixed contextual learning for efficient medical image segmentation. <em>KBS</em>, <em>329</em>, 114417. (<a href='https://doi.org/10.1016/j.knosys.2025.114417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has achieved remarkable success in medical image segmentation. However, most existing methods treat images as regular grids (e.g., CNNs) or sequential structures (e.g., Transformers), which are not well-suited for the flexible extraction of irregular anatomical features in medical images. In this paper, we propose an efficient graph-based method, WinGraphUNet (Windowed Graph U-Net), for medical image segmentation. Our model innovatively integrates graph learning both within and between windows to capture local and global correlations efficiently. To merge local and global correlations across multi-scale feature maps effectively, we introduce a ReMixed Context Graph Bridge Block, which remixes multi-scale feature maps. Specifically, we use self-attention mechanisms to extract local features from non-overlapping windows, which can be treated as learning on fully connected graphs, and apply dynamic graph learning to capture long-range dependencies between windows, where inter-window connections are recomputed at each layer based on feature similarity. Our model fully leverages the flexibility of graphs to capture complex anatomical structures. Extensive experimental results on three medical image datasets ( i.e. , Synapse, Polyp, and ISIC2018 datasets) show that our approach outperforms state-of-the-art methods in segmentation accuracy. Notably, by reducing model parameters by 18 % and computational cost by 68 % compared to representative graph-based methods ( e.g. , AHGNN), our design significantly enhances the applicability of graph modeling in resource-constrained clinical scenarios, where model compactness and inference efficiency are critical. The code is publicly available at https://github.com/zndxyhn/WinGraphUNet .},
  archive      = {J_KBS},
  author       = {Xiaoyan Kui and Haonan Yan and Qinsong Li and Lingxiao Liu and Weixin Si and Wei Liang and Beiji Zou},
  doi          = {10.1016/j.knosys.2025.114417},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114417},
  shortjournal = {Knowl. Based Syst.},
  title        = {WinGraphUNet: Advanced windowed graph modeling with remixed contextual learning for efficient medical image segmentation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ScExGraph: Explainable graph neural network for predicting tumor environment components with single-cell sequencing data. <em>KBS</em>, <em>329</em>, 114416. (<a href='https://doi.org/10.1016/j.knosys.2025.114416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell RNA sequencing (scRNA-seq) enables high-resolution analysis of the tumor microenvironment (TME), yet it faces key challenges in cross-patient cell type annotation and interpretable cell interaction analysis. This study introduces scExGraph, a graph neural network framework that combines adversarial graph domain adaptation and dynamic subgraph learning. Initially, a cell-cell graph is constructed via KNN, and a dual-branch graph convolutional encoder (GCN) is used to disentangle domain-specific and shared features, with adversarial training and adjacency matrix reconstruction ensuring topological consistency. Subsequently, a random attention mechanism dynamically adjusts edge weights, and KL divergence constraints generate interpretable subgraphs to identify key cell nodes. Finally, based on experimentally validated tumor-immune interaction genes, t -tests analyze these key cell nodes to identify critical cell signaling pathways affecting immune responses. Experiments across colorectal, non-small cell lung, and breast cancer datasets (88,507 cells) show scExGraph achieves an average accuracy of 0.918 in cross-patient annotation, significantly better than the benchmark GCN, and identifies immune regulatory genes like CEACAM1 and USP15. This research offers an explainable graph learning framework for decoding TME heterogeneity, balancing computational efficiency and biological significance. The source code are available at: https://github.com/an-xing456/scExGraph .},
  archive      = {J_KBS},
  author       = {Zhihua Du and Jiale Yi and Jianqiang Li and Hai-Ru You and Zhu-Hong You and Zhi-An Huang and Yu-An Huang},
  doi          = {10.1016/j.knosys.2025.114416},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114416},
  shortjournal = {Knowl. Based Syst.},
  title        = {ScExGraph: Explainable graph neural network for predicting tumor environment components with single-cell sequencing data},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing polyp characterization in colon capsule endoscopy using ResNet9-KAN. <em>KBS</em>, <em>329</em>, 114415. (<a href='https://doi.org/10.1016/j.knosys.2025.114415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Aim: Colon capsule endoscopy (CCE) offers a minimally invasive method for imaging gastrointestinal lesions, including colorectal polyps, which may be precursors to colorectal cancer. However, its low image quality poses challenges for tasks such as polyp characterization. This work develops a low-complexity AI model, ResNet9-KAN, by integrating the Kolmogorov-Arnold network (KAN) into 9-layer residual network (ResNet9) architecture. This model efficiently characterizes polyps as neoplastic or non-neoplastic in CCE images, facilitating real-time patient management. Methods: This work utilized a CCE dataset generated from the PillCam Colon 2 system at four hospitals in the Region of Southern Denmark. It comprises 2089 CCE images of 479 polyps (317 neoplastic, 162 non-neoplastic) from a bowel cancer screening population aged 50 to 74. The proposed ResNet9-KAN and several existing AI models were trained on 1672 CCE images (221 neoplastic, 113 non-neoplastic polyps) and evaluated on 569 test images (48 neoplastic, 25 non-neoplastic polyps). Results: The evaluation revealed that our proposed ResNet9-KAN surpassed existing AI models with per-image characterization accuracy of 97.71 %, demonstrating an excellent balance between sensitivity (97.10 %) and specificity (98.17 %). It also achieved the highest F1 score of 0.9730 and a competitive area under the curve (AUC) of 0.9895. Additionally, ResNet9-KAN exhibited per-polyp characterization accuracy of 99.23 %, with a sensitivity of 99.85 %, specificity of 98.65 %, and an F1 score of 0.9912. Conclusions: This work highlights the efficacy of ResNet9-KAN in accurately characterizing polyps in low-quality CCE images, showing substantial potential for in situ characterization where histological verification currently requires a follow-up colonoscopy.},
  archive      = {J_KBS},
  author       = {Vinay Chakravarthi Gogineni and Jan-Matthias Braun and Benedicte Schelde-Olesen and Gunnar Baatrup and Esmaeil S. Nadimi},
  doi          = {10.1016/j.knosys.2025.114415},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114415},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing polyp characterization in colon capsule endoscopy using ResNet9-KAN},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential contrastive learning for progressive knowledge tracing. <em>KBS</em>, <em>329</em>, 114413. (<a href='https://doi.org/10.1016/j.knosys.2025.114413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, knowledge tracing has received significant attention in personalized education. It dynamically assesses users’ knowledge states based on their historical response sequence. User response sequences are central to knowledge tracing. While most studies focus on modeling short-term and long-term dependencies, few consider the order in which interactions occur. A recent study argues that the interaction order has little impact on users’ knowledge states (Lee et al. , The Web Conference, 2022), which contradicts both our intuition and constructivist learning theory. To address this contradiction, we propose a S equential Contrastive Learning algorithm for P rogressive K nowledge T racing, termed SPKT , to test the effectiveness of order information within the response sequences for assessing users’ knowledge states. SPKT embeds order information into the response sequence representation through a carefully designed contrastive learning module, and captures users’ monotonic memory decay patterns using a carefully designed non-symmetrical augmented view construction method. The enhanced sequence representation is subsequently utilized to decode user behavior with a progressive learning process module. Extensive experiments demonstrate that, on average, SPKT outperforms 10 baselines by up to 14 % in AUC and 8 % in ACC across 6 real-world datasets. Furthermore, the results highlight that the order information in response sequences significantly improves algorithmic performance-sometimes even more than the correctness of the responses themselves. Moreover, SPKT more accurately evaluates users with better academic performance and shorter learning sequences. For the same user, longer response sequences are more helpful in assessing a user’s knowledge state.},
  archive      = {J_KBS},
  author       = {Yi-Fei Wen and Hang Liang and Carl Yang and Tao Zhou and Jia Liu and Yajun Du and Yan-Li Lee},
  doi          = {10.1016/j.knosys.2025.114413},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114413},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sequential contrastive learning for progressive knowledge tracing},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel stochastic neural network framework for modeling and simulation of within-host chikungunya virus transmission with latency. <em>KBS</em>, <em>329</em>, 114412. (<a href='https://doi.org/10.1016/j.knosys.2025.114412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present an innovative stochastic computing framework for modeling and simulation of within-host transmission dynamics of Chikungunya virus infection, incorporating latency and randomness. We integrate a feedforward neural network with the Legendre spectral collocation method to provide accurate results for the complex nonlinear model. The stochastic model captures intrinsic randomness associated with disease progression. A rigorous theoretical analysis is conducted, establishing the stability of the disease-free equilibrium when the control reproduction number R ˜ 0 < 1 . To explore the model’s behavior under stochastic influences, we implement the spectral collocation scheme for numerical simulations and analyze the impact of key epidemiological parameters. Extensive computational experiments are performed to support the theoretical results. The effectiveness and reliability of the present neural network-enhanced scheme are assessed through multiple evaluation criteria, including regression performance, mean squared error (MSE), error distribution, and phase portrait analysis. Additionally, the developed approach is benchmarked against the standard spectral collocation method to demonstrate its improved accuracy and predictive capabilities. The present scheme can be effectively extended to simulate complex real-world systems beyond epidemic models.},
  archive      = {J_KBS},
  author       = {Shuo Li and Misbah Ullah and Saif Ullah and Taseer Muhammad and Qaiser Iqbal},
  doi          = {10.1016/j.knosys.2025.114412},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114412},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel stochastic neural network framework for modeling and simulation of within-host chikungunya virus transmission with latency},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing sentiment analysis with local and global memory in heterogeneous graph neural networks. <em>KBS</em>, <em>329</em>, 114411. (<a href='https://doi.org/10.1016/j.knosys.2025.114411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is an essential task in natural language processing (NLP) and is applicable in various areas, such as social media monitoring and consumer feedback assessment. Existing approaches, which are primarily based on transformer architectures, perform well in capturing contextual semantics; however, they often fail to model the structured relationships and long-range dependencies inherent in complex text, especially when multiple granularities (e.g., words, aspects, sentences) interact. To address this, we propose LGM-HGNN , a unique hybrid model that utilizes heterogeneous graph neural networks enhanced with hierarchical memory tracking through dynamic GRU gating. The proposed model uses rich graph representations to capture inter-word and inter-aspect relationships. Additionally, it incorporates a dual-level memory module, with local memory for instance-level detail and global memory for corpus-level sentiment trends, which are dynamically updated and fused for better sentiment tracking. Experiments using Twitter airline reviews and financial sentiment analysis datasets demonstrate that LGM-HGNN consistently outperforms transformer-based models, highlighting its effectiveness in aspect-based sentiment analysis (ABSA). Furthermore, LGM-HGNN combines structured graph representations with dynamic memory updates to improve sentiment tracking skills in many real-world applications.},
  archive      = {J_KBS},
  author       = {Md. Mithun Hossain and Sanjara and Md. Shakil Hossain and Sudipto Chaki and Md. Saifur Rahman and A B M Shawkat Ali},
  doi          = {10.1016/j.knosys.2025.114411},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114411},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing sentiment analysis with local and global memory in heterogeneous graph neural networks},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking interactive image matting as incremental gaussian process regression problems. <em>KBS</em>, <em>329</em>, 114410. (<a href='https://doi.org/10.1016/j.knosys.2025.114410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive Image Matting (IIM) aims to predict alpha mattes through user interaction. Traditional methods often depend on user experience to interact at the regions where the alpha matte are inaccurate. However, regions with inaccurate model predictions do not necessarily correspond to areas of high model uncertainty, so these methods are unable to effectively reduce model uncertainty, resulting in low interaction efficiency. To address this issue, we observe a commonality between IIM tasks and Gaussian Process (GP) regression: the former predicts alpha values of unlabeled pixels based on user-labeled information, while the latter predicts observations of unknown data based on known data and provides uncertainty estimation for predictions. Based on this observation, we model IIM as an incremental GP regression problem and propose a novel IIM paradigm, IIM-GP. First, IIM-GP is the first model to incrementally utilize model-predicted uncertainty to guide user interaction and update matting results, significantly enhancing interaction efficiency and prediction reliability. Second, an incremental update strategy is implemented within the GP framework, overcoming traditional GP models’ inefficiency in updating results for IIM tasks. Additionally, IIM-GP employs a strategy of selecting p inducing points from n labeled pixels to perform variational inference on GP, reducing computational complexity from O ( n 3 ) to O ( n p 2 ) ( p ≪ n ). Comprehensive experiments on five widely-used datasets (Composition-1k, AIM-500, Distinctions-646, HIM2K and AM-2K) demonstrate that IIM-GP achieves competitive performance.},
  archive      = {J_KBS},
  author       = {Bingjie Guo and Wenhui Huang},
  doi          = {10.1016/j.knosys.2025.114410},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114410},
  shortjournal = {Knowl. Based Syst.},
  title        = {Rethinking interactive image matting as incremental gaussian process regression problems},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physical imaging model-guided deep variational despeckling framework for ultrasound images. <em>KBS</em>, <em>329</em>, 114409. (<a href='https://doi.org/10.1016/j.knosys.2025.114409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despeckling is essential for enhancing the clinical interpretability of ultrasound (US) images, as speckle noise can obscure tissue details and complicate diagnoses. Traditional despeckling methods, which rely on physical models of US imaging, have proven effective but often suffer from parameter sensitivity, low computational efficiency, and a tendency to over-smooth images. In contrast, deep learning (DL) approaches excel at learning from large datasets and can significantly reduce speckle noise with high efficiency and flexibility. However, DL methods face two key challenges: the scarcity of ground-truth clean US images, which requires the use of simulated clean images that might not accurately reflect real-world conditions, and the lack of integration with prior knowledge, leading to reduced interpretability and generalizability. In this paper, we propose a novel deep Variational US Image Despeckling (VUID) framework that addresses these limitations. VUID integrates the strengths of model-based methods by incorporating prior knowledge of US imaging physics and statistical distributions of relevant parameters into a variational DL architecture. Unlike previous methods, VUID treats simulated clean US images as the mode of the distribution of ground-truth clean images, serving as a guide rather than as absolute ground truth for training, which thereby enables a more accurate representation. The framework employs two distinct deep convolutional networks to predict the parameters of variational posterior distributions for speckle noise variance and ground-truth clean images. These networks are jointly optimized using a hybrid loss function that combines an Evidence Lower Bound (ELBO) loss with an image reconstruction loss guided by the US imaging model. We conducted extensive experiments comparing VUID with state-of-the-art traditional and DL despeckling methods. Our tests included assessing overall despeckling performance on three synthetic and two real US datasets, evaluating robustness and generalizability on two unseen real US datasets, and demonstrating clinical value through diagnostic quality assessments by medical experts. The results demonstrate that VUID surpasses existing methods across multiple metrics, highlighting its potential to improve the diagnostic accuracy and clinical utility of ultrasonic imaging. The code is available at https://github.com/blackpearl2021/VUID .},
  archive      = {J_KBS},
  author       = {Wenchao Cui and Zhihong Pan and Xiaolong Li and Yongheng Tang and Shuifa Sun},
  doi          = {10.1016/j.knosys.2025.114409},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114409},
  shortjournal = {Knowl. Based Syst.},
  title        = {Physical imaging model-guided deep variational despeckling framework for ultrasound images},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust contrastive knowledge distillation for long-tailed noisy class labels. <em>KBS</em>, <em>329</em>, 114408. (<a href='https://doi.org/10.1016/j.knosys.2025.114408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training robust models on datasets with both long-tailed class imbalance and label noise is critical for real-world applications. Existing methods often fail to holistically address feature-space disentanglement and the synergy between noise robustness and imbalance mitigation. We propose Robust Contrastive Knowledge Distillation (RCKD) to bridge this gap. RCKD innovates in two aspects: (1) Diverse Multi-Expert Distillation: Peer networks with self-attention-driven weight diversification yield complementary feature/logit insights, coupled with synchronized logit calibration and feature disentanglement; (2) Dual-Mode Contrastive Learning: Unsupervised contrastive learning captures intrinsic geometry for pseudo-clean samples, while reweighted supervised contrastive learning enforces discriminative features for pseudo-noise samples using class-balanced queues. Extensive experiments show RCKD achieves state-of-the-art performance, e.g., +6.66 % over the best baseline on CIFAR-100-NLT (100:1 imbalance, 50 % noise).},
  archive      = {J_KBS},
  author       = {Shao-Yuan Li and Jinpeng Zheng and Mingguang Zhang and Dong Liang and Shaofang Li and Kangkan Wang},
  doi          = {10.1016/j.knosys.2025.114408},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114408},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust contrastive knowledge distillation for long-tailed noisy class labels},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density clustering hypersphere-based self-adaptively oversampling algorithm for imbalanced datasets. <em>KBS</em>, <em>329</em>, 114407. (<a href='https://doi.org/10.1016/j.knosys.2025.114407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalances are a common issue in machine learning. Oversampling, one of the most prevalently adopted strategies, is utilized to address this issue. However, the currently available oversampling techniques suffer from certain limitations when handling complex imbalanced datasets, such as introducing noisy samples that result in class overlap and failing to effectively tackle within-class imbalances caused by low-density and small disjuncts etc. To address these limitations, a Density Clustering Hypersphere-based Self-Adaptively Oversampling Algorithm (DCHO) is introduced in this paper. The approach first dynamically determines the clustering centers through calculating the density of minority class instances, constructs hyperspheres for clustering on each determined center and then adaptively adjusts the radius of the hypersphere according to the imbalance ratio. Finally, oversampling is performed within the hyperspheres to avoid class overlap. Additionally, it adaptively assigns oversampling weights based on local densities and the radius of the hyperspheres, thereby addressing within-class imbalances. To further enhance the boundary distribution of the minority class and explore the unknown minority class area, a new boundary-biased random oversampling technique is developed to conduct oversampling inside each hypersphere. Evaluation results show that DCHO significantly outperforms other popular oversampling algorithms in handling classification problems in imbalanced datasets.},
  archive      = {J_KBS},
  author       = {Tao Xinmin and Xu Annan and Shi Lihang and Li Junxuan and Guo Xinyue and Tao Sirui},
  doi          = {10.1016/j.knosys.2025.114407},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114407},
  shortjournal = {Knowl. Based Syst.},
  title        = {Density clustering hypersphere-based self-adaptively oversampling algorithm for imbalanced datasets},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated vulnerability score prediction through lightweight generative AI. <em>KBS</em>, <em>329</em>, 114406. (<a href='https://doi.org/10.1016/j.knosys.2025.114406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the constantly increasing number of newly published vulnerabilities, manually assessing their scores (e.g., under the Common Vulnerability Scoring System) has become unfeasible. Recently, learning-based systems have been proposed to automatically predict vulnerability scores. Such systems use vulnerability indexing databases to train deep learning algorithms. However, their practical applicability has important limitations, including a high dependency on the quality and diversity of training data, and high computational requirements. In addition, vulnerability descriptions often do not follow the standard templates and are not rich enough with respect to the expected features. In this paper, we propose a novel architecture that takes advantage of both generative artificial intelligence and lightweight deep learning techniques to provide an efficient and effective solution for automated vulnerability scoring. Data extracted from the National Vulnerability Dataset is fed into a large language model layer, whose output (i.e., an augmented dataset) is then used in a lightweight fine-tuned BERTsmall layer. We provide the results of an extensive experimental assessment of the effect of both each layer of the architecture and end-to-end performances. The results suggest that the combination of GPT3.5-Turbo and BERTsmall provides the most effective accuracy-time trade-off. We also compare the performance of the proposed architecture with other LLMs, BERT models, and cutting-edge approaches. The results show good improvements in prediction quality also when compared to a recent technique that incorporates data from 66 different sources, including the NVD.},
  archive      = {J_KBS},
  author       = {Seyedeh Leili Mirtaheri and Andrea Pugliese and Valerio Pascucci},
  doi          = {10.1016/j.knosys.2025.114406},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114406},
  shortjournal = {Knowl. Based Syst.},
  title        = {Automated vulnerability score prediction through lightweight generative AI},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Query-efficient and dataset-independent red teaming for LLMs content safety evaluation. <em>KBS</em>, <em>329</em>, 114404. (<a href='https://doi.org/10.1016/j.knosys.2025.114404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) are widely used for their remarkable ability to understand and generate natural language. Nevertheless, LLMs can also produce unintended outputs that pose significant social risks. Red teaming can identify potential security vulnerabilities in LLMs and support mitigating such risks. However, existing red teaming approaches struggle to balance query efficiency and generalizability due to their complex search processes or reliance on pre-existing datasets. To address these issues, we present RAPT, a query-efficient and dataset-independent red teaming approach. RAPT employs an adaptive generate-select framework that consists of four cyclic steps: generating test cases by an LLM-based generator, selecting test cases by an reinforcement learning (RL)-based selector, testing the target model, and refining the generator and the selector. In this framework, the generator is used to generate test cases, and the selector is used to select test cases. We introduce a contrast prompt template and diversity demonstration extraction method to guide the generator, incorporating previous test feedback as demonstrations to generate more effective and diverse test cases. For the selector, we formalize the test case selection process as a Markov decision process (MDP), allowing us to design a reinforcement learning-based agent to continuously optimize the selection policy, which is able to balance the effectiveness and diversity of test cases according to a compound reward function. Experimental results show that RAPT can effectively discover more successful and diverse test cases than existing methods within a limited number of queries without relying on any pre-existing dataset.},
  archive      = {J_KBS},
  author       = {Shuo Liu and Xiang Cheng and Sen Su},
  doi          = {10.1016/j.knosys.2025.114404},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114404},
  shortjournal = {Knowl. Based Syst.},
  title        = {Query-efficient and dataset-independent red teaming for LLMs content safety evaluation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-assisted explainable decision traces (BAXDT): An approach for transparency and accountability in artificial intelligence systems. <em>KBS</em>, <em>329</em>, 114402. (<a href='https://doi.org/10.1016/j.knosys.2025.114402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing opacity and lack of verifiable audit trails in AI decision-making systems pose significant challenges to establishing trust and accountability, particularly in high-impact domains. This paper introduces Blockchain-Assisted Explainable Decision Traces (BAXDT), a novel architecture designed to enhance the transparency and auditability of AI systems. BAXDT creates comprehensive, immutable records for each AI decision by integrating model outputs, SHAP-based XAI summaries, a novel Explanation Density Metric, and detailed model/data context into a unified JSON trace. The 0.80 threshold for the Explanation Density Metric was empirically supported by Kneedle-based automatic threshold detection. The BAXDT architecture leverages blockchain by recording a cryptographic hash of each decision trace on-chain, while the full trace is stored off-chain. The system's effectiveness was demonstrated through a multi-faceted evaluation: simulations across three diverse public datasets (medical, financial, educational) confirmed its domain-agnostic applicability; a scalability analysis of up to 20,000 traces demonstrated its efficient and linear performance; and a successful deployment on the Ethereum Sepolia public testnet verified its real-world viability. A case study on text data further underscored the framework's flexibility. BAXDT provides a robust framework for documenting AI decisions - what, why, based on what, and when - thereby fostering trustworthy AI and supporting regulatory compliance.},
  archive      = {J_KBS},
  author       = {İsmail Enes Parlak},
  doi          = {10.1016/j.knosys.2025.114402},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114402},
  shortjournal = {Knowl. Based Syst.},
  title        = {Blockchain-assisted explainable decision traces (BAXDT): An approach for transparency and accountability in artificial intelligence systems},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDGC: Fuzzy deep clustering with dual-granularity contrastive learning. <em>KBS</em>, <em>329</em>, 114401. (<a href='https://doi.org/10.1016/j.knosys.2025.114401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep clustering has garnered considerable attention in data mining and computer vision due to its effectiveness in handling high-dimensional data. However, traditional deep clustering methods face notable limitations. Real-world data often exhibit complex feature distributions and ambiguous boundaries. Fixed network architectures struggle to capture both global and local dependencies among data samples and are inadequate for managing fuzzy boundaries. Additionally, contrastive learning methods commonly used in deep clustering suffer from inefficient negative sample selection, where many positive samples are mistakenly treated as negative, thereby hindering training. To address these challenges, this paper proposes a fuzzy deep clustering method with dual-granularity contrastive learning (FDGC). The method extracts features and clusters them to generate pseudo-labels, retaining only the reliable ones through a confidence screening mechanism for use as supervision signals. By integrating data augmentation strategies with a self-attention fuzzy network, FDGC effectively captures both context and local details while dynamically adapting to feature fuzziness. Furthermore, a dual-granularity contrastive loss function is introduced to enhance feature representation. This loss improves sample discriminability at both the cluster and instance levels, significantly mitigating the issue of inaccurate negative sampling in traditional contrastive learning. Experimental results across multiple benchmark datasets demonstrate that FDGC outperforms existing method, validating the effectiveness of the proposed approach.},
  archive      = {J_KBS},
  author       = {Hengrong Ju and Jing Guo and Weiping Ding and Witold Pedrycz and Xiaotian Cheng and Xibei Yang},
  doi          = {10.1016/j.knosys.2025.114401},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114401},
  shortjournal = {Knowl. Based Syst.},
  title        = {FDGC: Fuzzy deep clustering with dual-granularity contrastive learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmented decoding method using semantic diverse beam search for language generation model. <em>KBS</em>, <em>329</em>, 114400. (<a href='https://doi.org/10.1016/j.knosys.2025.114400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning, the task of automatically generating natural language descriptions from visual content, has achieved remarkable accuracy in recent years. However, current approaches face a critical limitation in semantic diversity. Most diversity-oriented methods evaluate similarity at the surface lexical level, incorrectly treating lexically different but semantically equivalent phrases (e.g., 'dog runs' vs 'canine sprints') as meaningfully diverse outputs. This superficial approach fails to capture true semantic variation. Consequently, generated captions appear different but convey essentially identical meanings. To address this fundamental limitation, we propose Semantic Diverse Beam Search (SDBS), an augmented decoding algorithm that operates in semantic space rather than surface lexical space. SDBS integrates four key innovations: knowledge graph-based semantic similarity scoring, adaptive thresholding for important word focus, statistics-based stratified top-k sampling, and beam size normalization. Additionally, we introduce an early-stop strategy that significantly reduces computational complexity while maintaining generation quality, making SDBS practically viable for real-world applications. Comprehensive experiments demonstrate that SDBS achieves superior performance on both traditional metrics and modern evaluation approaches (BARTScore++, LLM-based assessment), generating captions with genuine semantic diversity while maintaining high accuracy and computational efficiency.},
  archive      = {J_KBS},
  author       = {HyungSun Na and Hee-Gook Jun and Jinhyun Ahn and Dong-Hyuk Im},
  doi          = {10.1016/j.knosys.2025.114400},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114400},
  shortjournal = {Knowl. Based Syst.},
  title        = {Augmented decoding method using semantic diverse beam search for language generation model},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent space refinement for unsupervised cyber threat text classification. <em>KBS</em>, <em>329</em>, 114399. (<a href='https://doi.org/10.1016/j.knosys.2025.114399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification plays a critical role in Cyber Threat Intelligence (CTI) applications, where open-source text data is mined to identify patterns such as Indicators of Compromise (IoC), Tactics, Techniques and Procedures (TTPs), Named Entities and more. However, the dynamic nature of CTI makes traditional supervised machine learning classifiers impractical due to their reliance on large number of labelled training datasets. To address this, we propose Latent Space Refinement (LSR), an unsupervised method designed for CTI text classification. LSR introduces a posterior regularisation strategy where an auxiliary distribution derived from a TF-IDF feature space serves as signals to refine latent representations derrived from Pretrained Language Models (PLMs). By iteratively refining this latent space with clustering signals, LSR enables efficient similarity-based classification using only a few user-provided seed keywords. Extensive experiments on diverse CTI tasks, including both binary and multi-class classification, demonstrate that LSR consistently outperforms state-of-the-art unsupervised and zero-shot/few-shot methods in Accuracy and Weighted F1 score, all without tuning internal PLM parameters. This makes LSR a lightweight and PLM-agnostic solution for real-world CTI applications.},
  archive      = {J_KBS},
  author       = {Yue Wang and Richi Nayak and Md Abul Bashar and Mahinthan Chandramohan},
  doi          = {10.1016/j.knosys.2025.114399},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114399},
  shortjournal = {Knowl. Based Syst.},
  title        = {Latent space refinement for unsupervised cyber threat text classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-gate self-distillation network for efficient image super-resolution. <em>KBS</em>, <em>329</em>, 114398. (<a href='https://doi.org/10.1016/j.knosys.2025.114398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The balanced extraction of both non-local and local features represents a critical requirement for effective image super-resolution (SR). While transformer-based self-attention (SA) mechanisms demonstrate superior non-local modeling capabilities, their substantial computational demands limit practical deployment. To address this efficiency-performance trade-off, the Spatial-Gate Self-Distillation Network (SGSDN) implements a dual-capacity architecture combining: an SA-like (SAL) module employing strategically dilated 1D depthwise convolutions in horizontal and vertical orientations for efficient non-local feature extraction, and a lightweight local spatial-gate (LKG) block optimized for local detail preservation. Moreover, the proposed spatial-gate self-distillation block (SGSDB) further enhances performance through an optimized distillation structure that simultaneously processes both feature types while minimizing memory overhead. Experimental results demonstrate SGSDN’s superior performance-complexity balance, with benchmark evaluations showing comparable accuracy to SwinIR-light while requiring only 25% of the computational resources (FLOPs) and 25% of parameters, attributable to its avoidance of computationally intensive matrix operations.},
  archive      = {J_KBS},
  author       = {Yinggan Tang and Mengjie Su and Quansheng Xu},
  doi          = {10.1016/j.knosys.2025.114398},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114398},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatial-gate self-distillation network for efficient image super-resolution},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Like or dislike? capturing heterogeneity in social recommendation via motif-induced capsules. <em>KBS</em>, <em>329</em>, 114397. (<a href='https://doi.org/10.1016/j.knosys.2025.114397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many trust-based social recommender systems have focused on heterogeneity in trust relations, but this heterogeneity is considered only for explicit neighbors. Most of the existing works overlook heterogeneity in the high-order network structure of user-user social networks. Most of them assume that the power of trust relationship of a neighbor on a target user is constant and applies the same value when considering different categories of recommendations. To overcome the above challenges, we propose a model architecture named Motif-induced attention-based Capsule Graph Convolutional Networks ( mCGCNs ). To the best of our knowledge, this is the first study in which the capsule network extracts multiple latent social-aware user vectors and latent preference-based user vectors of a target user, which vary from item to item based on the recommendation. To extract multiple latent social-aware user vectors, we not only consider explicit neighbors but also consider implicit neighbors, and regarding this the motif networks capture the complex higher-level pattern of interactivities among users. The investigations and empirical analyses on publicly available real-world datasets (Ciao, Epinions, and Library Thing) illustrate the effectiveness of our model compared to 13 popular baselines. It outperforms the best baseline model by margins ranging from 9.86 % to 12.78 % in HR@10, 13.07 % to 13.55 % in NDCG@10, 7.63 % to 8.97 % in MAE, 6.05 % to 7.24 % in RMSE for three datasets of product recommendations. Through ablation study, key components in mCGCNs are validated to benefit the recommendation performance improvement.},
  archive      = {J_KBS},
  author       = {Supriyo Mandal and Ralf Krestel},
  doi          = {10.1016/j.knosys.2025.114397},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114397},
  shortjournal = {Knowl. Based Syst.},
  title        = {Like or dislike? capturing heterogeneity in social recommendation via motif-induced capsules},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCWANet: A hyperspectral anomaly detection network with multi-stage collaborative optimization of wavelet convolution and attention mask. <em>KBS</em>, <em>329</em>, 114396. (<a href='https://doi.org/10.1016/j.knosys.2025.114396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral anomaly detection (HAD), a key research area in remote sensing, aims to efficiently identify and localize anomalous targets. However, challenges such as the high dimensionality of hyperspectral data, the sparse and complex distribution of anomalous targets, and the strong diversity of backgrounds make it difficult to distinguish anomalies from the background, thereby affecting detection accuracy. Existing methods often rely on background reconstruction for anomaly detection, but this approach tends to weaken the expression of the anomalous targets themselves, neglecting the core task of detection–accurate identification and localization of anomalous regions. To address this issue, this paper proposes a Multi-stage Cooperative Wavelet Convolution and Attention Mask Network (MCWANet), which aims to simultaneously enhance anomaly enhancement and background reconstruction capabilities, thereby effectively amplifying the differences between anomalies and the background. MCWANet employs a wavelet-based multi-spectral feature extractor, using low-frequency information for background modeling and high-frequency information for anomaly enhancement and boundary refinement. Meanwhile, a progressive attention refinement module, based on a spatial attention mechanism, dynamically generates adaptive masks to highlight potential anomalous regions and suppress background interference. Finally, a spectral-spatial residual fusion module integrates multi-source information, balancing anomaly enhancement and background modeling. Extensive experimental results on six public datasets show that, compared to ten state-of-the-art methods, MCWANet demonstrates superior anomaly detection performance and stronger generalization ability in complex backgrounds.},
  archive      = {J_KBS},
  author       = {Yuquan Gan and Xingyu Li and Siyu Wu and Ji Zhang and Ying Liu},
  doi          = {10.1016/j.knosys.2025.114396},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114396},
  shortjournal = {Knowl. Based Syst.},
  title        = {MCWANet: A hyperspectral anomaly detection network with multi-stage collaborative optimization of wavelet convolution and attention mask},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PADetBench: Towards benchmarking texture- and patch-based physical attacks against object detection. <em>KBS</em>, <em>329</em>, 114395. (<a href='https://doi.org/10.1016/j.knosys.2025.114395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical attacks against object detection have gained significant attention due to their practical implications. However, conducting physical experiments is time-consuming and labor-intensive, and controlling physical dynamics and cross-domain transformations in the real world is challenging, leading to inconsistent evaluations and hindering the development of robust models. To address these issues, we rigorously explore realistic simulations to benchmark physical attacks under controlled conditions. This approach ensures fairness and resolves the problem of capturing strictly aligned adversarial images, which is challenging in the real world. Our benchmark includes 23 physical attacks, 48 object detectors, comprehensive physical dynamics, and evaluation metrics. We provide end-to-end pipelines for dataset generation, detection, evaluation, and analysis. The benchmark is flexible and scalable, allowing easy integration of new objects, attacks, models, and vision tasks. Based on this benchmark, we generate comprehensive datasets and perform over 8000 evaluations, including overall assessments and detailed ablation studies. These experiments provide detailed analyses from detection and attack perspectives, highlight limitations of existing algorithms, and offer revealing insights. The code and datasets are publicly available at https://github.com/JiaweiLian/PADetBench .},
  archive      = {J_KBS},
  author       = {Jiawei Lian and Jianhong Pan and Lefan Wang and Yi Wang and Shaohui Mei and Lap-Pui Chau},
  doi          = {10.1016/j.knosys.2025.114395},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114395},
  shortjournal = {Knowl. Based Syst.},
  title        = {PADetBench: Towards benchmarking texture- and patch-based physical attacks against object detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot temporal knowledge graph completion based on query-adaptive mamba-enhanced temporal relation learning. <em>KBS</em>, <em>329</em>, 114394. (<a href='https://doi.org/10.1016/j.knosys.2025.114394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot Temporal Knowledge Graph Completion (FTKGC) aims to predict missing facts when only a few instances are available for each relation. The shared relation between known few-shot instances and the query quadruple is highly time-dependent, while existing approaches model it as static. Static relation modeling faces two key challenges: First, neighbor aggregation relies on fully connected attention mechanisms, ignoring the sequential nature of neighbor quadruples. Second, relation learning treats support set knowledge as static, overlooking its dynamic temporal relations with the query. In this paper, we propose a novel F TKGC framework based on query- A daptive M amba- E nhanced temporal relation learning ( FAME ) to address above challenges. Specifically, our approach presents a three-stage relation representation learning strategy. It integrates neighbor-aware modeling for sequential neighbor aggregation, instance-aggregated modeling for relation learning across instances, and time-sensitive modeling to capture query-adaptive temporal dynamics. Experiments demonstrate the effectiveness of FAME on three benchmark datasets and validate the contribution of the proposed strategies.},
  archive      = {J_KBS},
  author       = {Xingyue Guo and Ying Zhang and Yu Zhao and Baohang Zhou and Xuhui Sui and Xinying Qian and Xiaojie Yuan},
  doi          = {10.1016/j.knosys.2025.114394},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114394},
  shortjournal = {Knowl. Based Syst.},
  title        = {Few-shot temporal knowledge graph completion based on query-adaptive mamba-enhanced temporal relation learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting online order satisfaction with lagged data using WGAIN-GP. <em>KBS</em>, <em>329</em>, 114393. (<a href='https://doi.org/10.1016/j.knosys.2025.114393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce has grown a lot in recent years and so has the research performed in this field. In this paper we estimate order satisfaction by predicting outcomes of relevant variables at the moment an order is made, such that companies can act on this signal. In order to deal with data that is not known at the order date (i.e., lagged missing data), we propose an extension of an existing generative imputation method. The Generative Adversarial Imputation Network (GAIN) is suitable for data imputation on tabular datasets. A more stable method is the Wasserstein GAIN (WGAIN). In this paper, we propose to improve this method by adding the Gradient Penalty to WGAIN resulting in WGAIN-GP. We perform experiments on a large dataset from a Dutch online retailer. Using WGAIN-GP we obtain a better accuracy of 61 % at the order date compared to 54 % and 53 % obtained by GAIN and WGAIN, respectively.},
  archive      = {J_KBS},
  author       = {Bette Donker and Evita Hoogeveen and Lars Hurkmans and Daan Schopmeijer and Flavius Frasincar and Enzo Ido and Jasmijn Klinkhamer},
  doi          = {10.1016/j.knosys.2025.114393},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114393},
  shortjournal = {Knowl. Based Syst.},
  title        = {Predicting online order satisfaction with lagged data using WGAIN-GP},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Virtual regularized bipartite graph learning for multi-view subspace clustering. <em>KBS</em>, <em>329</em>, 114392. (<a href='https://doi.org/10.1016/j.knosys.2025.114392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MVSC) has been widely studied for its ability to effectively capture the underlying structural information of multi-view data and achieve impressive clustering performance. As the volume of real-world data continues to grow, existing multi-view subspace clustering algorithms are unable to effectively tackle large-scale datasets. Therefore, multi-view subspace clustering methods based on bipartite graphs have been proposed to effectively solve the time complexity problem. Moreover, existing bipartite graph methods inevitably cause information loss due to the use of anchor points instead of the original data, leading to degradation of clustering performance. To address the above problems, we propose a virtual regularized bipartite graph learning for multi-view subspace clustering (VRBGL-MVSC) method, which utilizes anchors and bipartite graph learning to deal with the complexity associated with large-scale datasets. Specifically, we incorporate projection learning to generate discriminative anchor graphs in potentially low-dimensional spaces. Additionally, we propose a novel virtual regularization (VR) technique to guide bipartite graph learning, which explores multi-view data information faster and more efficiently. Furthermore, we develop an algorithm with good convergence to optimize VRBGL-MVSC. Experimental data show that in tests on four large-scale datasets, the VRBGL-MVSC algorithm outperformed all comparison algorithms, with improvements in the NMI metric of 0.17 %, 1.79 %, 1.13 %, and 3.24 % compared to the next-best results. This result clearly demonstrates that the VRBGL-MVSC algorithm excels in handling large-scale multi-view subspace clustering tasks and possesses a significant performance advantage.},
  archive      = {J_KBS},
  author       = {Linlin Ma and Wenke Zang and Xincheng Liu and Yuzhen Zhao and Xiyu Liu and Zhenni Jiang and Baoqiang Yan and Yawen Chen},
  doi          = {10.1016/j.knosys.2025.114392},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114392},
  shortjournal = {Knowl. Based Syst.},
  title        = {Virtual regularized bipartite graph learning for multi-view subspace clustering},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Target-guided dialog generation with dynamic knowledge path by commonsense knowledge graph and relation prediction. <em>KBS</em>, <em>329</em>, 114390. (<a href='https://doi.org/10.1016/j.knosys.2025.114390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational AI has been rapidly advancing with the development of large language models and has shown excellent performance. However, one of its limitations is a passive system that cannot ask or guide users back to ambiguous questions. To overcome this, we have implemented an active dialog system that can smoothly transition from previous conversations. Our system is a target-guided system, which means it can guide the conversation by asking the user to provide a desired response or target. This approach is knowledge-rich and challenging, as it requires achieving the target while maintaining contextual consistency. To generate responses, we dynamically construct knowledge paths through knowledge graphs and relation predictors. These play an essential role in generating diverse and logically connected responses. To achieve this, we follow a global planning method that systematically conducts conversations with a target, and constructs knowledge paths based on common sense. We perform multi-hop reasoning and bi-directional search simultaneously to increase diversity and logical connectivity. We have overcome the limitations of existing works that rely solely on knowledge graphs by reflecting the results of relation predictors along with each object’s WIKI data in the path. Therefore, the consideration of the knowledge graph and the performance of the relation predictor, compared to the existing system, in completing the dynamic knowledge path and generating transition responses allowed conversations to transition more naturally. We have verified the proposed model through experiments.},
  archive      = {J_KBS},
  author       = {Hayoung Lee and Soyeop Yoo and Woong-Kee Loh and Ok-Ran Jeong},
  doi          = {10.1016/j.knosys.2025.114390},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114390},
  shortjournal = {Knowl. Based Syst.},
  title        = {Target-guided dialog generation with dynamic knowledge path by commonsense knowledge graph and relation prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward transformer-compatible multivariate time series learning via visibility graph-based structural encoding. <em>KBS</em>, <em>329</em>, 114389. (<a href='https://doi.org/10.1016/j.knosys.2025.114389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series (MTS) modeling plays a crucial role in understanding complex systems. However, existing Transformer-based approaches often struggle to capture essential temporal structures, leading to information loss and even attention dispersion. To address these challenges, we propose MVGFormer , a novel Trans former -compatible M ultivariate Time Series framework guided by V isibility G raph principles. By explicitly establishing connections between time points based on visibility criteria, we introduce a graph-based sparse Attention (VG-Attention) mechanism, which selectively focuses on crucial temporal dependencies while filtering out irrelevant noise. This sparse Attention significantly mitigates the impact of quadratic complexity, improving scalability for larger time series data. Moreover, considering existing models often overlook the global dependencies within MTS, we extract consensus information across channels and aggregate the multiplex visibility graph into a consensus graph, revealing potential cross-layer patterns. Compared to single-channel models, MSE decreases by 2.82 %, classification accuracy increases by 9.73 %, and training speed improves by 67.48 %. Experimental results across 25 real-world datasets demonstrate that MVGFormer outperforms most existing models in four main tasks, including forecasting, classification, imputation, and anomaly detection. Overall, our approach provides a fresh perspective on adapting Transformers to better understanding temporal dependencies within time series data.},
  archive      = {J_KBS},
  author       = {Ting Chen and Xinyue Ren and Jinzhou Lai and Hongming Tan and Fangming Liu and Wai Kin Victor Chan},
  doi          = {10.1016/j.knosys.2025.114389},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114389},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward transformer-compatible multivariate time series learning via visibility graph-based structural encoding},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic partial person embedding for visible-infrared person re-identification with twin noise labels. <em>KBS</em>, <em>329</em>, 114388. (<a href='https://doi.org/10.1016/j.knosys.2025.114388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twin Noise Labels (TNL) in Visible-Infrared Person Re-identification (VI-ReID) introduce annotation errors, severely impacting identity consistency. Besides, these misannotations contaminate identity correspondences and increase feature uncertainty, leading to degraded retrieval performance. Existing methods predominantly rely on point-based feature representations, which extract isolated identity features but struggle to capture the distributional variations caused by noise. To address these issues, we propose Probabilistic Partial Person Embedding ( P 3 E ), which introduces a multi-probabilistic embedding strategy that models local body regions as Gaussian distributions, capturing regional uncertainty. Additionally, we propose a probabilistic embedding fusion for Re-ID, which adaptively integrates local probabilistic embeddings to form a more robust identity representation. Furthermore, a Probabilistic Embedding Triplet loss is introduced to ensure distributional consistency and enhance cross-modal identity discrimination. Extensive experiments on SYSU-MM01 and RegDB demonstrate that P 3 E significantly outperforms state-of-the-art methods. Particularly in noisy-label scenarios, it achieves superior robustness and Re-ID accuracy, effectively mitigating the impact of TNL.},
  archive      = {J_KBS},
  author       = {Wen Guo and Manyu Wei and Jing Sun and Tuo Zhou and Junling Gao},
  doi          = {10.1016/j.knosys.2025.114388},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114388},
  shortjournal = {Knowl. Based Syst.},
  title        = {Probabilistic partial person embedding for visible-infrared person re-identification with twin noise labels},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing sparse triplet overlapping relation extraction using triaxial syntactic fusion approach. <em>KBS</em>, <em>329</em>, 114387. (<a href='https://doi.org/10.1016/j.knosys.2025.114387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation Extraction (RE) is a crucial component of information extraction, with the challenge of overlapping RE presenting considerable complexity. In this overlapping scenario, text often contains multiple relation triplets involving shared entities, requiring advanced methods to disentangle the complex semantics. Some existing works or large language models cannot address the nuances of overlapping semantics in special low information density cases with longer text but sparse triplets. To address this, we introduce the Triaxial Syntactic Fusion Approach (TSFA), which leverages shortest dependency paths (SDP) to fuse semantics and capture their nuance. By identifying candidate SDPs for overlapping entity pairs and transforming these into a comprehensive fusion SDP token set, TSFA grasps contextual clues to resolve overlapping RE more effectively. Subsequently, the TSFA integrates two attention mechanisms in three dimensions to direct the attention weights toward semantically significant tokens. This method facilitates the efficient interaction of all entities in a single step, thereby enhancing the model to capture nuance semantics in sparse triplet scenarios. Our extensive experiments on the widely recognized overlapping datasets demonstrate TSFA’s superior performance, achieving an excellent improvement in the F1-score over most of the leading baselines. 1},
  archive      = {J_KBS},
  author       = {Hailin Wang and Ran Tao and Xiufen Fang and Guisong Liu and Ke Qin},
  doi          = {10.1016/j.knosys.2025.114387},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114387},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing sparse triplet overlapping relation extraction using triaxial syntactic fusion approach},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel data-driven input shaping method using residual impulse vector via unscented kalman filter. <em>KBS</em>, <em>329</em>, 114385. (<a href='https://doi.org/10.1016/j.knosys.2025.114385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by escalating demands for precision and speed in modern industrial applications, residual vibrations in flexible structures and underactuated systems have emerged as a critical technical challenge, particularly during high-speed emergency braking scenarios. Input shaping has proven to be an effective technique for vibration control. However, existing input shapers commonly encounter challenges with time delay and inaccurate parameters, leading to suboptimal control performance. To address these critical issues, this paper proposes an Unscented Kalman filter-based Residual negative equal-magnitude Shaping (URS) model with two-fold ideas: a) reducing the time delay and compensating the modeling error via the consideration of negative and residual impulse vector; and b) identifying system parameters using a data-driven unscented Kalman filter to enhance control effectiveness. To validate its performance, four experimental datasets from laboratory systems have been established and publicly released. Empirical studies demonstrate that the proposed URS model has achieved a significant vibration suppression effect over several state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Weiyi Yang and Yuqi Li and Mingsheng Shang and Shuai Li and Shiping Wen},
  doi          = {10.1016/j.knosys.2025.114385},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114385},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel data-driven input shaping method using residual impulse vector via unscented kalman filter},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An explainable multi-task similarity measure: Integrating accumulated local effects and weighted fréchet distance. <em>KBS</em>, <em>329</em>, 114384. (<a href='https://doi.org/10.1016/j.knosys.2025.114384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many machine learning contexts, tasks are often treated as interconnected components with the goal of leveraging knowledge transfer between them, which is the central aim of Multi-Task Learning (MTL). Consequently, this multi-task scenario requires addressing critical questions: which tasks are similar, and how and why do they exhibit similarity? In this work, we propose a multi-task similarity measure based on Explainable Artificial Intelligence (XAI) techniques, specifically Accumulated Local Effects (ALE) curves. ALE curves are compared using the Fréchet distance, weighted by the data distribution, and the resulting similarity measure incorporates the importance of each feature. The measure is applicable in both single-task learning scenarios, where each task is trained separately, and multi-task learning scenarios, where all tasks are learned simultaneously. The measure is model-agnostic, allowing the use of different machine learning models across tasks. A scaling factor is introduced to account for differences in predictive performance across tasks, and several recommendations are provided for applying the measure in complex scenarios. We validate this measure using four datasets, one synthetic dataset and three real-world datasets. The real-world datasets include a well-known Parkinson’s dataset and a bike-sharing usage dataset — both structured in tabular format — as well as the CelebA dataset, which is used to evaluate the application of concept bottleneck encoders in a multitask learning setting. The results demonstrate that the measure aligns with intuitive expectations of task similarity across both tabular and non-tabular data, making it a valuable tool for exploring relationships between tasks and supporting informed decision-making.},
  archive      = {J_KBS},
  author       = {Pablo Hidalgo and Daniel Rodriguez},
  doi          = {10.1016/j.knosys.2025.114384},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114384},
  shortjournal = {Knowl. Based Syst.},
  title        = {An explainable multi-task similarity measure: Integrating accumulated local effects and weighted fréchet distance},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prostate cancer forecasting in small samples based on lightweight neural networks using ensemble learning. <em>KBS</em>, <em>329</em>, 114383. (<a href='https://doi.org/10.1016/j.knosys.2025.114383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prostate cancer is the most common malignancy among Australian men, with over 20 000 new diagnoses each year. Accurate forecasts of its incidence and mortality inform stakeholder decision-making and help mitigate its public health impact. In this context, we introduce cutting-edge lightweight neural networks into the domain of prostate cancer data forecasting with edge intelligence for the first time. To address the issue of overfitting in coarse-grained and small-scale prostate cancer datasets, we employ structurally streamlined models: the Gated Recurrent Unit (GRU) and Temporal Convolutional Network (TCN), representing two predominant branches of neural networks. The GRU’s simplified gating mechanism maintains excellent long-term dependencies capturing capability while drastically reducing parameter count, and the TCN combines sparse connections, parameter sharing, and causal dilated convolutions for efficient temporal modeling. To further bolster generalization, we integrate multiple regularization strategies, including the snapshot ensemble method. Comparative experiments on three real-world prostate cancer datasets demonstrate that our improved lightweight, high-performance neural networks achieve over 40 % higher accuracy than linear time series forecasting suitable for small-scale datasets.},
  archive      = {J_KBS},
  author       = {Yuting Cao and Ziyu Sheng and Haibin Zhu and Tingwen Huang and Shiping Wen},
  doi          = {10.1016/j.knosys.2025.114383},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114383},
  shortjournal = {Knowl. Based Syst.},
  title        = {Prostate cancer forecasting in small samples based on lightweight neural networks using ensemble learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating the validity of structure learning algorithms in identifying risk factors for intervention in patients with diabetes. <em>KBS</em>, <em>329</em>, 114382. (<a href='https://doi.org/10.1016/j.knosys.2025.114382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes, a pervasive and enduring health challenge, imposes significant global implications on health, financial healthcare systems, and societal well-being. This study undertakes a comprehensive exploration of various structural learning algorithms to discern causal pathways amongst potential risk factors influencing diabetes progression. This study evaluates a diverse set of structure learning algorithms to discern causal pathways amongst potential risk factors influencing diabetes progression. The methodology involves the application of these algorithms to relevant diabetes data, followed by the conversion of their output graphs into Causal Bayesian Networks (CBNs), enabling predictive analysis and the evaluation of discrepancies in the effect of hypothetical interventions within our context-specific case study. This study highlights the substantial impact of algorithm selection on intervention outcomes. To consolidate insights from diverse algorithms, we employ a model-averaging technique that helps us obtain a unique causal model for diabetes derived from a varied set of structural learning algorithms.We also investigate how each of those individual graphs, as well as the average graph, compare to the structures elicited by a domain expert who categorised graph edges into high confidence, moderate, and low confidence types, leading into three individual graphs corresponding to the three levels of confidence. The resulting causal model and data are made available online, and serve as a valuable resource and a guide for informed decision-making by healthcare practitioners. Our applied work integrates and evaluates existing causal structure learning methods for decision support in patients with diabetes. It offers a comprehensive understanding of the interactions between relevant risk factors for intervention, and enables us to simulate the effect of hypothetical interventions before implementation. Therefore, this research not only contributes to the academic discussion on diabetes, but also provides practical guidance for healthcare professionals in developing efficient intervention and risk management strategies.},
  archive      = {J_KBS},
  author       = {Sheresh Zahoor and Anthony C. Constantinou and Tim M. Curtis and Mohammed Hasanuzzaman},
  doi          = {10.1016/j.knosys.2025.114382},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114382},
  shortjournal = {Knowl. Based Syst.},
  title        = {Investigating the validity of structure learning algorithms in identifying risk factors for intervention in patients with diabetes},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained multimodal molecular pretraining via prompt learning. <em>KBS</em>, <em>329</em>, 114381. (<a href='https://doi.org/10.1016/j.knosys.2025.114381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the advancement of pretraining models has revolutionized artificial intelligence, driving significant progress across various domains. In drug discovery, these models have shown remarkable potential by leveraging large-scale data to learn generalizable molecular representations, accelerating the identification of promising drug candidates. However, existing models often rely on atom-based reconstruction techniques to handle molecular structures, yet they frequently overlook substructural details such as functional groups and rings—elements that are critical for drug design and discovery. Furthermore, these models exhibit limitations in task adaptability, which impedes their precision in interpreting and predicting complex chemical environments. To address these challenges, we introduce MolFinePrompt, a fine-grained multimodal molecular pretraining model designed to enhance the representational capacity of molecular structures by integrating functional group data into their topological framework. Employing a contrastive learning approach, MolFinePrompt is pre-trained on a dataset of 316K molecular structure-text pairs and features bespoke task prompt texts for optimized fine-tuning, thereby improving its task-specific comprehension. The effectiveness of MolFinePrompt is validated through exemplary experimental results on cross-modal retrieval, molecular property prediction, and drug interaction prediction tasks.},
  archive      = {J_KBS},
  author       = {Yang Li and Zhengxin Wei and Chang Liu and Guohua Wang},
  doi          = {10.1016/j.knosys.2025.114381},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114381},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fine-grained multimodal molecular pretraining via prompt learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PK-net: A prior knowledge-driven dual-path network for enhanced glaucoma screening. <em>KBS</em>, <em>329</em>, 114374. (<a href='https://doi.org/10.1016/j.knosys.2025.114374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma is a chronic ocular disease that often remains undiagnosed until advanced stages, highlighting the need for early detection. Current state-of-the-art methods mainly adapt attention mechanisms into classification networks designed for natural images via transfer learning, but they fail to capture domain-specific features and show weak cross-dataset generalization. In this paper, we propose a prior knowledge-driven dual-path network (PK-Net) that integrates medical knowledge into model architecture for glaucoma screening. First, based on the diagnostic importance of the optic disc, we introduce the Global and Local Fusion Network (GloLocNet), which combines high-resolution local optic disc images with global fundus images and applies a triple-loss strategy to improve feature extraction. Second, to leverage the strong inter-eye correlation of glaucoma, we propose the Binocular Fusion Network (BFNet), where paired eye images are processed through parallel GloLocNet encoders and fused to yield joint screening results. PK-Net was validated on multiple datasets, achieving superior intra- and cross-dataset results. For PAPILA, AUC, BAcc, Sen, and Spe were 95.67 %, 91.18 %, 88.72 %, and 93.63 %; for OIA-ODIR, 92.43 %, 85.64 %, 84.62 %, and 86.67 %. Trained on ORIGA and tested on REFUGE, the values were 90.00 %, 82.29 %, 81.25 %, and 83.33 %, demonstrating strong generalization. On GAMMA, results were 95.16 %, 83.37 %, 75.49 %, and 91.29 %. These findings indicate that PK-Net effectively enhances glaucoma screening by embedding prior medical knowledge into network design.},
  archive      = {J_KBS},
  author       = {Xiaoyan Kui and Zeru Hai and Beiji Zou and Yang Li and Wei Liang and Zuheng Ming and Liming Chen},
  doi          = {10.1016/j.knosys.2025.114374},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114374},
  shortjournal = {Knowl. Based Syst.},
  title        = {PK-net: A prior knowledge-driven dual-path network for enhanced glaucoma screening},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label feature selection based on positive sample information weighting. <em>KBS</em>, <em>329</em>, 114373. (<a href='https://doi.org/10.1016/j.knosys.2025.114373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection has garnered significant attention due to its capacity to reduce data dimensionality while effectively eliminating noise and irrelevant features. Information-theoretic methods are predominant in this domain, as they aim to quantify the relevance and redundancy among features, as well as between features and labels. However, existing information-theoretic methods frequently disregard the inherent distributional differences between positive and negative samples when assessing relevance and redundancy among variables. In multi-label data sets, positive samples associated with the same label tend to be more concentrated in the feature space, whereas negative samples exhibit a more dispersed distribution. This disparity is particularly evident in datasets characterized by label sparsity. The dispersed distribution of feature values for negative samples often results in reduced discriminative power and increased susceptibility to noise. To mitigate this limitation, we propose a novel feature selection method termed Multi-label Feature Selection based on Positive Sample Information Weighting (PSIWFS). PSIWFS assigns higher weights to features that demonstrate strong correlations with positive samples during the feature selection process, thereby enhancing the identification and prioritization of the less frequent positive samples. Experimental evaluations conducted on 14 datasets with 7 comparison methods underscore the superior classification performance of the proposed method.},
  archive      = {J_KBS},
  author       = {Qingqi Han and Ruikai Shi and Liang Hu and Wanfu Gao},
  doi          = {10.1016/j.knosys.2025.114373},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114373},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-label feature selection based on positive sample information weighting},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing pre-training via target-aware source data selection. <em>KBS</em>, <em>329</em>, 114371. (<a href='https://doi.org/10.1016/j.knosys.2025.114371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, due to the explosive popularity of large-scale pre-trained models such as large language models, pre-training approaches that use a massive amount of source data and can be applied to various target tasks are becoming more popular. Pre-trained models allow us to learn highly accurate target models by fine-tuning them with target data, even when their volume is insufficient. However, the source data used to train a pre-training model is generally a large and miscellaneous data set obtained in the wild without being aware of the target task, and it highly possibly contains much data that does not contribute to relearning the target task. This study defines a novel paradigm as “target-aware source data selection,” which uses the source data itself instead of a pre-training model and selects source data for pre-training and aims to increase its quality, effectiveness, and robustness. Our proposal fundamentally differs from the current studies addressing the lack of target data and conventional transfer learning approaches, improving source data quality using the novel Domain Adaptation Information Gain criteria. Specifically, the target model is pre-trained while actively selecting only informative data from the source data using the “rough-prior knowledge” obtained from the target data training before the pre-training. Finally, fine-tuning the model with the target data results in a highly accurate model for the target (downstream) task. The effectiveness of our proposed paradigm has been demonstrated through multifaceted experiments using multiple pairs of target data and source data with different strengths of their relevance.},
  archive      = {J_KBS},
  author       = {Kanyu Miyoshi and Ryotaro Shimizu and Linxin Song and Masayuki Goto},
  doi          = {10.1016/j.knosys.2025.114371},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114371},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimizing pre-training via target-aware source data selection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TSH-FCNet: Triple-source heterogeneous remote sensing images fusion classification network based on feature propagation and perception. <em>KBS</em>, <em>329</em>, 114370. (<a href='https://doi.org/10.1016/j.knosys.2025.114370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the diversification of remote sensing (RS) sensor types, the accessibility and availability of various RS data types are continuously improving. The collaborative use of multi-source RS data can comprehensively and effectively improve the accuracy of RS for earth observation. However, current research on multi-source RS image fusion classification primarily focuses on only two types of RS data. The heterogeneous characteristics of three or more types of RS data significantly complicate the data fusion process. In particular, how to effectively explore the correlations among the inherent characteristics of three or more heterogeneous RS data remains a critical challenge that has not been effectively addressed. This greatly affects the accuracy of RS land classification and other earth observation tasks. To address this issue, a TSH-FCNet based on feature propagation and perception for collaborative classification of hyperspectral (HS), multispectral (MS), and radar images is proposed. This network thoroughly explores the intrinsic correlations among the three heterogeneous data sources and employs an innovative feature interaction mechanism to leverage their complementary advantages. It overcomes the interference of heterogeneous characteristics between different data sources on fusion, effectively enhancing the final classification accuracy. Specifically, a distance similarity attention guides the mutual perception and fusion of triple-source RS information, promoting the flow of complementary features among the triple-source and improving the final classification accuracy. Additionally, the shared information from the triple-source RS data is injected into the features to be fused through a domain alignment mechanism, enhancing the spatial and semantic consistency of the features, thereby strengthening the classification model’s ability to recognize complex surface features. We tested the algorithm on three triple-source RS datasets. The experimental results indicate that the proposed algorithm achieves significant improvements over existing mainstream methods, exhibiting greater stability and reliability when handling highly heterogeneous and diverse data sources. The implementation code of this algorithm will be available from https://github.com/cwlnnu/TSH-FCNet .},
  archive      = {J_KBS},
  author       = {Wei Cheng and Yining Feng and Yuting Zhao and Xianghai Wang},
  doi          = {10.1016/j.knosys.2025.114370},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114370},
  shortjournal = {Knowl. Based Syst.},
  title        = {TSH-FCNet: Triple-source heterogeneous remote sensing images fusion classification network based on feature propagation and perception},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced prototype network with gated point recyclable feature mining for few-shot 3D point cloud classification. <em>KBS</em>, <em>329</em>, 114369. (<a href='https://doi.org/10.1016/j.knosys.2025.114369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the high annotation cost of 3D point cloud and the natural long-tail distribution across categories, 3D Point Cloud Few-shot Learning (3DPC-FSL) has arisen and attracted wide attention. However, as a core step of representation, max-pooling results in a substantial loss of point information and, thereby, leads to unsatisfactory performance, particularly with limited training data. The current solution for addressing this issue is to project 3D data into a series of 2D views and then aggregate the resulting 2D features for sufficient mining of point information. However, such a solution unavoidably neglects the internal 3D structure of point clouds. Herein, we propose a pure 3D approach named Enhanced Prototype Network with Gated Point Recyclable Feature Mining (EPN-GPRFM) for 3DPC-FSL. EPN-GPRFM follows the prototype-based FSL paradigm and enhances this paradigm from the perspectives of feature learning and prototype representation. In terms of feature learning, EPN-GPRFM enhances the 3DPC features by cyclically and adaptively mining the beneficial information from discarded points via a gating mechanism in each stage. In terms of prototype representation, EPN-GPRFM sufficiently exploits query samples to compensate the prototypes via a query-guided prototype enhancement strategy. Experiments on three well-known 3DPC benchmarks validate the effectiveness of our method and its prominent performance advantages over baselines.},
  archive      = {J_KBS},
  author       = {Hailin Wang and Sheng Huang and Luwen Huangfu and Ma Rui and Bo Liu},
  doi          = {10.1016/j.knosys.2025.114369},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114369},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced prototype network with gated point recyclable feature mining for few-shot 3D point cloud classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal prompting and masking strategy for video-grounded dialogue. <em>KBS</em>, <em>329</em>, 114367. (<a href='https://doi.org/10.1016/j.knosys.2025.114367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-Grounded Dialogue (VGD) is a challenging vision-language task aimed at engaging in multi-turn dialogues with humans based on video and audio content. Despite significant progress in improving AI-generated responses has been made, several challenges remain: 1) A significant amount of computing resources and time are required during training; 2) Current dominant approaches, utilizing T5 or GPT2 as base models, exhibit limited ability to understand video and audio features due to their text-based pre-training paradigms; 3) Existing studies have not addressed the robustness of models in real-world scenarios where dialog history is often missing. To address these issues, we propose VPM, a Video-Grounded Dialogue framework employing prompt-based tuning and a masking strategy. Firstly, to reduce computation resources, inspired by prompt learning, we are the first to employ prompt-based tuning in Video-Grounded Dialogue task by using only 20 % of the training set while maintaining proximal accuracy. Secondly, to enhance the model’s understanding of video and audio, we propose a slicing-based visual mapping network, integrating learnable visual prompts and video-audio slice features sequentially through a series of operations. Finally, we put forward an exponentially masking strategy for dialogue history to improve cross-modal understanding and robustness. Extensive experiments validate the effectiveness of our proposed framework, achieving state-of-the-art performance on the AVSD@DSTC7 and AVSD@DSTC8 datasets.},
  archive      = {J_KBS},
  author       = {Feifei Xu and Wang Zhou and Fumiaoyue Jia},
  doi          = {10.1016/j.knosys.2025.114367},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114367},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multimodal prompting and masking strategy for video-grounded dialogue},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data preprocessing using banded structure and image morphology enhancing boolean matrix factorization. <em>KBS</em>, <em>329</em>, 114366. (<a href='https://doi.org/10.1016/j.knosys.2025.114366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boolean Matrix Factorization (BMF) is a widely used method for revealing underlying patterns, called factors, in data. In the paper, we propose a novel data preprocessing method that makes patterns more visible, thus simplifying the overall BMF process. The method first reorders the data to reveal a banded structure. Then, it applies image morphology to enhance this structure by emphasizing important information and suppressing less relevant information. We demonstrate the efficacy of our approach through various experimental evaluations, showing that it effectively modifies the data, resulting in fewer, more interpretable factors. The proposed method also allows using more straightforward and faster BMF algorithms while maintaining high-quality results.},
  archive      = {J_KBS},
  author       = {Klara Brazdilova and Martin Trnecka and Marketa Trneckova},
  doi          = {10.1016/j.knosys.2025.114366},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114366},
  shortjournal = {Knowl. Based Syst.},
  title        = {Data preprocessing using banded structure and image morphology enhancing boolean matrix factorization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MTSL-TimesNet: A multi-task self-supervised learning model based on TimesNet for EEG emotion recognition. <em>KBS</em>, <em>329</em>, 114364. (<a href='https://doi.org/10.1016/j.knosys.2025.114364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, electroencephalogram (EEG)-based emotion recognition tasks have attracted considerable interest. Current approaches predominantly rely on single-task learning to extract latent features and construct general models, which can result in overfitting and weak generalization of the model. To resolve this issue, we propose a Multi-Task Self-Supervised Emotion Recognition Method (MTSL-ERM). This method first eliminates the baseline signal from the raw EEG data and maps the processed signals onto a brain electrode map. The processed data is input into MTSL-TimesNet, a novel deep learning model based on TimesNet architecture. The model enables cross-task knowledge sharing and multi-task optimization through spatial jigsaw and contrastive learning tasks. Specifically, the spatial jigsaw task aims to capture spatial patterns across different brain regions, while the contrastive learning task introduces a time-frequency enhancement method and generates instance-level hard negative samples to preserve key temporal relationships in the time series, thereby enhancing the model’s discriminative capability. Through enhancing the resemblance of similar samples and reconstructing time sequences, the model better regularizes feature learning and improves its ability to learn the data’s inherent patterns. Results on the DEAP and DREAMER datasets show MTSL-ERM’s superiority over current approaches. The classification accuracy for arousal and valence in subject-dependent experiments on the DEAP dataset are 96.30 % and 95.92 % , respectively. Meanwhile, on the DREAMER dataset, the accuracies are 90.76 % and 90.66 % , respectively.},
  archive      = {J_KBS},
  author       = {Yongqi Li and Qiuhong Hong and Jibin Yin and Luyao Han and Shoulin Wei and Xiangliang Zhang},
  doi          = {10.1016/j.knosys.2025.114364},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114364},
  shortjournal = {Knowl. Based Syst.},
  title        = {MTSL-TimesNet: A multi-task self-supervised learning model based on TimesNet for EEG emotion recognition},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiplane depth image for view-consistent light field depth estimation. <em>KBS</em>, <em>329</em>, 114363. (<a href='https://doi.org/10.1016/j.knosys.2025.114363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light field cameras capture both spatial and angular information of light rays, offering rich data that has made center-view depth estimation a topic of significant interest in recent years. However, the limited flexibility of center-view depth estimation presents substantial challenges for real-world applications, underscoring the need for full-view depth estimation. A primary challenge in this domain is ensuring view consistency. Multiplane Image is a widely used technique for view synthesis, which represents a 3D scene as a series of parallel 2D image planes. Inspired by this structure, we propose a novel approach called Multiplane Depth Image (MDI), which leverages the consistency of density features across multiple views to represent depth information more effectively. To accurately capture the spatial relationships of occluded objects, we introduce a scene-wide hierarchical density update mechanism, which renders depth from the foreground to background, facilitating a more coherent depth representation. Additionally, it corrects visible holes during propagation by focusing on the evident missing regions in the updated density. Finally, we develop an LF full-view depth estimation framework based on these techniques, which enables simultaneous depth prediction across all views. This framework incorporates a comprehensive loss function to supervise depth errors, view consistency, and edge blurring. Experimental results demonstrate that our method predicts high-quality depth maps across all views and achieves state-of-the-art performance compared to center-view methods.},
  archive      = {J_KBS},
  author       = {Tun Wang and Hao Sheng and Rongshan Chen and Ruixuan Cong and Mingyuan Zhao and Da Yang},
  doi          = {10.1016/j.knosys.2025.114363},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114363},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multiplane depth image for view-consistent light field depth estimation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing text adversarial example generation using large language models. <em>KBS</em>, <em>329</em>, 114361. (<a href='https://doi.org/10.1016/j.knosys.2025.114361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in Natural Language Processing (NLP) are highly based on black-box score-based models that provide only final predictions along with their score. This opacity impedes the comprehension of their internal decision-making processes, complicating the identification of potential weaknesses. A powerful strategy for analyzing model vulnerabilities is the generation of text adversarial examples. These attacks introduce subtle text perturbations that cause victim models to make incorrect predictions while preserving the original semantic meaning. This paper presents a novel method for generating text adversarial examples through Large Language Models (LLMs). The proposed method uses the outstanding text generation capabilities of LLMs to modify the original input text at multiple granularities: character-, word-, and sentence-level. First, sentence-level perturbations are introduced by generating paraphrases with an LLM instruction prompt. Next, further character- and word-level perturbations are introduced to words that most affect predictions using another set of LLM instruction prompts. In particular, vulnerable words are perturbed by replacing them with their synonyms or misspelled variants, or by inserting additional neutral words adjacent to them. Experiments were conducted to assess the proposal’s viability on two sentiment classification tasks: sentence-level reviews and full-length reviews. The proposal demonstrates an advantage over many well-known approaches based on LLMs. It preserves the original semantics to a similar extent, while increasing the deception of victim models by 29–85 % over the best-analyzed state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Natalia Madrueño and Alberto Fernández-Isabel and Rubén R. Fernández and Isaac Martín de Diego},
  doi          = {10.1016/j.knosys.2025.114361},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114361},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advancing text adversarial example generation using large language models},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect-level sentiment-aware mining of inter-review relations for detecting fake reviews. <em>KBS</em>, <em>329</em>, 114360. (<a href='https://doi.org/10.1016/j.knosys.2025.114360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of fake reviews poses a significant challenge in e-commerce, undermining consumer trust and market integrity. Recently, graph-based approaches have emerged as promising solutions. However, most existing approaches focus primarily on modeling the strong relationships among reviewers, reviews, and products. They often neglect inter-review relationships that are critical for accurate fake review detection. Additionally, their reliance on coarse-grained features limits the detection of subtle, context-aware signals in fake reviews. To address these limitations, we propose a novel method called A spect- L evel S entiment- A ware M ining of I nter- R eview relations ( ALSAMIR ) for effective fake review detection. The method comprises four key components: (1) Aspect-level sentiment-aware graph to aggregate reviews sharing similar aspect-specific sentiments based on uniformity and similarity in aspect-level sentiments. This component helps reveal abnormal spammer behavior patterns; (2) A graph-based oversampling technique to mitigate imbalanced class distribution; (3) A Graph Convolutional Network (GCN) to aggregate semantics of inter-review relation embeddings with strong relations; and (4) An attention mechanism to capture non-linear, higher-order dependencies among latent features. Extensive experiments on publicly available datasets demonstrate that ALSAMIR outperforms state-of-the-art baseline methods.},
  archive      = {J_KBS},
  author       = {Ramadhani A. Duma and Zhendong Niu and Ally S. Nyamawe and Ali Asghar Manjotho and Augustino Deve},
  doi          = {10.1016/j.knosys.2025.114360},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114360},
  shortjournal = {Knowl. Based Syst.},
  title        = {Aspect-level sentiment-aware mining of inter-review relations for detecting fake reviews},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSFormer: Dynamic size attention with enhanced long-range dependency modeling for artery/vein classification. <em>KBS</em>, <em>329</em>, 114359. (<a href='https://doi.org/10.1016/j.knosys.2025.114359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal artery/vein (A/V) classification plays a crucial role in retinal disease screening and diagnosis, serving as a key biomarker for the early detection of various systemic diseases. Despite progress in automatic A/V classification, existing methods often suffer from high computational cost and the impact of irrelevant background information, limiting their practical application. To alleviate these limitations, we propose a hierarchical dynamic size transformer network (DSFormer), which integrates dynamic context-aware (DCA) blocks to improve the ability of the network to capture long-range dependencies while reducing computational complexity. The DCA block, comprising dynamic size self-attention and a dual fusion feed-forward network, is designed to emphasize crucial information in global feature representation, aggregate relevant features, and reduce the quadratic complexity of attention calculations. Additionally, a mixed shallow-deep context bridge integrates shallow and deep features across multiple scales, preserving spatial details at different scales and enhancing feature fusion. Extensive experiments on DRIVE, HRF, and IOSTAR datasets demonstrate that DSFormer outperforms state-of-the-art methods, achieving superior A/V classification performance. Code is available at https://github.com/juzi01-smallju/DSFormer .},
  archive      = {J_KBS},
  author       = {Zeyuan Ju and Chouyu Chen and Zhipeng Liu and Lijun Guo and Zhenyu Lei and Masaaki Omura and Shangce Gao},
  doi          = {10.1016/j.knosys.2025.114359},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114359},
  shortjournal = {Knowl. Based Syst.},
  title        = {DSFormer: Dynamic size attention with enhanced long-range dependency modeling for artery/vein classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond text: Fusing multi-modal legal knowledge for legal judgment prediction. <em>KBS</em>, <em>329</em>, 114358. (<a href='https://doi.org/10.1016/j.knosys.2025.114358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of the Legal Judgment Prediction (LJP) task is to predict judgment outcomes based on the fact description texts within legal cases. Existing LJP methods are confined to leveraging knowledge inherent only within the dataset itself, often failing to achieve satisfactory performance when factual descriptions contain text prone to causing erroneous judgments. Consequently, extracting and utilizing external legal knowledge represents a critical challenge that the LJP task urgently needs to overcome. To address the aforementioned issues, this study proposes a legal judgment framework named MLK-LJP, which pioneers the integration of multi-granularity, multi-modal legal knowledge into the LJP task. MLK-LJP comprises two primary modules: Multimodal Legal Knowledge Extraction (MLKE) and Multi-modal Legal Knowledge Fusion (MLKF). Specifically: 1) In the MLKE module, we devise distinct methods to acquire five types of multi-modal legal knowledge: Legal article knowledge, legal event knowledge, legal relation knowledge, quantitative evidence knowledge, and image evidence knowledge. 2) In the MLKF module, we first design a Legal Knowledge Experts Fusion mechanism. This mechanism leverages a Graph Neural Network to capture collaborative signals among the five legal knowledge expert types. Subsequently, the fused multi-modal legal knowledge is allocated across different layers of a Transformer model. This legal knowledge enhanced Transfomer model, combined with LJP prompts, is used to predict the LJP outcomes. Extensive experiments conducted on the three LJP datasets demonstrate the effectiveness and validity of MLK-LJP in comparison to state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Qihui Zhao and Tianhan Gao and Nan Guo},
  doi          = {10.1016/j.knosys.2025.114358},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114358},
  shortjournal = {Knowl. Based Syst.},
  title        = {Beyond text: Fusing multi-modal legal knowledge for legal judgment prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual constraint based semi-supervised nonnegative matrix factorization for multi-view clustering. <em>KBS</em>, <em>329</em>, 114357. (<a href='https://doi.org/10.1016/j.knosys.2025.114357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised nonnegative matrix factorization (NMF) has attracted considerable attentions in multi-view clustering applications. However, existing semi-supervised methods only adopt either pointwise (i.e., label) or pairwise constraints as supervisory information, without considering taking full advantage of both to further enhance the effectiveness of clustering performance. To this end, a novel dual constraint based semi-supervised nonnegative matrix factorization (DSNMF) method is proposed in this paper for multi-view clustering tasks. Concretely, a new multi-view based dual constraint (MDC) algorithm is developed in DSNMF, which simultaneously utilizes both the pointwise and pairwise supervisory information to promote the performance of multi-view clustering. Specifically, when the limited label information is obtained, the MDC algorithm not only constructs the label regularization to guide the learning of the indicator matrices, but also adopts the hypergraph based pairwise constraint propagation algorithm to construct the graph regularization. Moreover, an alternating multiplicative iterative method is developed for solving the optimization problem of DSNMF, as well as analyzing its convergence, supervisory information effect and computational complexity. Finally, numerous experimental results over five multi-view datasets conclude that DSNMF has better performance than several state-of-the-art semi-supervised multi-view clustering methods.},
  archive      = {J_KBS},
  author       = {Siyuan Peng and Zimeng Huangfu and Wenyun Xie and Zhijing Yang and Feiping Nie},
  doi          = {10.1016/j.knosys.2025.114357},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114357},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual constraint based semi-supervised nonnegative matrix factorization for multi-view clustering},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view clustering with privileged information based on probabilistic tensor factorization. <em>KBS</em>, <em>329</em>, 114356. (<a href='https://doi.org/10.1016/j.knosys.2025.114356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) is a powerful technique for analyzing multi-feature datasets by integrating multiple views to enhance clustering performance. Traditional MVC methods focus mainly on the consensus principle, aiming for consistency across views, but often neglects the complementary information that can be leveraged from different views. In this paper, we propose a novel probabilistic framework for tensor-based MVC that effectively incorporates both the consensus and complementarity principles. Our approach adopts the Learning Using Privileged Information (LUPI) paradigm, where one view is used as the primary learning source while the remaining views serve as privileged information. This enables the views to complement one another, thereby improving clustering results. The proposed framework utilizes probabilistic tensor factorization to capture high-order correlations between views and incorporates a max-margin constraint to enhance robustness. The proposed approach provides an interpretable generative process for tensor factorization within a probabilistic Bayesian context. Notably, our proposed framework is highly flexible and can be naturally integrated with existing anchor graph or deep learning paradigms to construct the view-specific representations. Experimental results on benchmark multi-view datasets demonstrate that our method outperforms existing MVC counterparts.},
  archive      = {J_KBS},
  author       = {Xu Tan and Haidong Gao and Yang Yu},
  doi          = {10.1016/j.knosys.2025.114356},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114356},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-view clustering with privileged information based on probabilistic tensor factorization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedAGHN: Personalized federated learning with attentive graph hypernetworks. <em>KBS</em>, <em>329</em>, 114355. (<a href='https://doi.org/10.1016/j.knosys.2025.114355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized Federated Learning (PFL) aims to address the statistical heterogeneity of data across clients by learning the personalized model for each client. Among various PFL approaches, the personalized aggregation-based approach conducts parameter aggregation in the server-side aggregation phase to generate personalized models, and focuses on learning appropriate collaborative relationships among clients for aggregation. However, the collaborative relationships vary in different scenarios and even at different stages of the FL process. To this end, we propose Personalized Federated Learning with Attentive Graph HyperNetworks (FedAGHN), which employs Attentive Graph HyperNetworks (AGHNs) to dynamically capture fine-grained collaborative relationships and generate client-specific personalized initial models. Specifically, AGHNs empower graphs to explicitly model the client-specific collaborative relationships, construct collaboration graphs, and introduce tunable attentive mechanism to derive the collaboration weights, so that the personalized initial models can be obtained by aggregating parameters over the collaboration graphs. Extensive experiments can demonstrate the superiority of FedAGHN. Moreover, a series of visualizations are presented to explore the effectiveness of learned collaboration graphs.},
  archive      = {J_KBS},
  author       = {Jiarui Song and Yunheng Shen and Chengbin Hou and Pengyu Wang and Jinbao Wang and Ke Tang and Hairong Lv},
  doi          = {10.1016/j.knosys.2025.114355},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114355},
  shortjournal = {Knowl. Based Syst.},
  title        = {FedAGHN: Personalized federated learning with attentive graph hypernetworks},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PromptAL: Sample-aware dynamic soft prompts for few-shot active learning. <em>KBS</em>, <em>329</em>, 114354. (<a href='https://doi.org/10.1016/j.knosys.2025.114354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning (AL) aims to optimize model training and reduce annotation costs by selecting the most informative samples for labeling. Typically, AL methods rely on the empirical distribution of labeled data to define the decision boundary and perform uncertainty or diversity estimation, subsequently identifying potential high-quality samples. In few-shot scenarios, the empirical distribution often diverges significantly from the target distribution, causing the decision boundary to shift away from its optimal position. However, existing methods overlook the role of unlabeled samples in enhancing the empirical distribution to better align with the target distribution, resulting in a suboptimal decision boundary and the selection of samples that inadequately represent the target distribution. To address this, we propose a hybrid AL framework, termed PromptAL (Sample-Aware Dynamic Soft Prompts for Few-Shot A ctive L earning). This framework accounts for the contribution of each unlabeled data point in aligning the current empirical distribution with the target distribution, thereby optimizing the decision boundary. Specifically, PromptAL first leverages unlabeled data to construct sample-aware dynamic soft prompts that adjust the model’s predictive distribution and decision boundary. Subsequently, based on the adjusted decision boundary, it integrates uncertainty estimation with both global and local diversity to select high-quality samples that more accurately represent the target distribution. Experimental results on six in-domain and three out-of-domain datasets show that PromptAL achieves superior performance over nine baselines. Our codebase is openly accessible.},
  archive      = {J_KBS},
  author       = {Hui Xiang and Jinqiao Shi and Ting Zhang and Xiaojie Zhao and Yong Liu and Yong Ma},
  doi          = {10.1016/j.knosys.2025.114354},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114354},
  shortjournal = {Knowl. Based Syst.},
  title        = {PromptAL: Sample-aware dynamic soft prompts for few-shot active learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EFNet-CSM: EfficientNet with a modified attention mechanism for effective fire detection. <em>KBS</em>, <em>329</em>, 114353. (<a href='https://doi.org/10.1016/j.knosys.2025.114353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire is considered one of the major threats to life, property, ecosystems, global warming, and the economy. Recent advancements in convolution neural networks have shown potential for vision-based fire detection; however, several challenges are associated with these techniques, such as limited model performance and high computational complexity. To address these issues, we present an efficient CNN-based model in which EfficientNetV2B0 is employed as a backbone feature extractor and is integrated with a channel and modified spatial attention mechanism to extract deeper spatial details, thereby weighting important features appropriately. The spatial attention is modified by introducing two depth-separable convolution layers to control computational complexity without affecting the performance. The proposed model is assessed on four benchmark datasets in the domain of remote sensing and CCTV-based systems for effective fire detection. Experimental analysis reveals that our model outperforms existing methods in terms of higher accuracy and inference speed, with lower model size and computational burden, indicating its suitability for deployment on resource-constrained devices in real time. To explain the predictions made by the proposed model, we use explainable artificial intelligence methods called Grad-CAM, guided backpropagation, and guided Grad-CAM to provide visualizations by localizing the most salient regions in the image, as emphasized by the attention mechanism.},
  archive      = {J_KBS},
  author       = {Hikmat Yar and Fath U Min Ullah and Zulfiqar Ahmad Khan and Min Je Kim and Sung Wook Baik},
  doi          = {10.1016/j.knosys.2025.114353},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114353},
  shortjournal = {Knowl. Based Syst.},
  title        = {EFNet-CSM: EfficientNet with a modified attention mechanism for effective fire detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cross-city spatio-temporal prediction via dynamic multi-scale hypergraph learning with domain adversarial training. <em>KBS</em>, <em>329</em>, 114352. (<a href='https://doi.org/10.1016/j.knosys.2025.114352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal prediction is vital for enabling intelligent urban services. However, due to newly deployed infrastructure, developing cities often suffer from data scarcity, which significantly limits the applicability of deep learning models that rely on large volumes of historical data. Moreover, most existing methods focus solely on pairwise spatial interactions, overlooking complex high-order spatial dependencies that are crucial for accurate prediction. To address these challenges, we propose D2MHyper, a cross-city spatio-temporal prediction framework that integrates high-order spatial information through a D ynamic M ulti-scale Hyper graph neural network enhanced by D omain adversarial training. Specifically, we design a shared-private representation learning strategy that captures both city-invariant and city-specific spatial features through inter-city shared and intra-city private hypergraphs. To effectively model complex dependencies, we develop a dynamic multi-scale hypergraph generation module based on learnable incidence matrices, which captures implicit time-varying high-order interactions at multiple granularities. To enhance generalization to data-scarce target cities, a cross-city knowledge transfer module is introduced to transfer global information from source cities. Furthermore, a domain adversarial training strategy is incorporated to enforce the disentanglement of shared and private representations. Extensive experiments on four real-world benchmark datasets consistently validate the effectiveness of D2MHyper, which outperforms state-of-the-art methods in cross-city prediction under data scarcity scenarios.},
  archive      = {J_KBS},
  author       = {Xiaocao Ouyang and Yanhua Li and Jie Zhang and Xin Yang and Yan Yang and Junbo Zhang and Wei Huang and Tianrui Li and Zhiquan Liu},
  doi          = {10.1016/j.knosys.2025.114352},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114352},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing cross-city spatio-temporal prediction via dynamic multi-scale hypergraph learning with domain adversarial training},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unleashing powerful generalization for point cloud registration. <em>KBS</em>, <em>329</em>, 114351. (<a href='https://doi.org/10.1016/j.knosys.2025.114351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep learning-based point cloud registration have significantly enhanced performance on in-domain data. However, an ideal point cloud registration method should not only excel in same-domain scenarios but also demonstrate robust generalization to achieve the goal of ”train once, apply anywhere.” To this end, existing patch-based methods employ keypoint sampling to identify matchable local 3D patches, thereby improving generalization. Nevertheless, viewpoint variations due to changes in sensor pose, coupled with uneven density and scale issues in point clouds acquired by different sensors, hinder reliable keypoint detection, consequently complicating the identification of matching local 3D patches. To address these challenges, we propose UPG, a point cloud registration method with powerful generalization performance. First, we design an equivariant network architecture based on PPF features to detect keypoints that are rotation-equivariant. Additionally, we present a multi-level patch-wise embedding technique and a joint-level inliers generator to mitigate density and scale variations and improve both registration performance and generalization. Extensive experiments on multiple datasets demonstrate that the proposed UPG achieves state-of-the-art generalization performance.},
  archive      = {J_KBS},
  author       = {Yejun Shou and Haocheng Wang and Lingfeng Shen and Shuai Li and Yanlong Cao},
  doi          = {10.1016/j.knosys.2025.114351},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114351},
  shortjournal = {Knowl. Based Syst.},
  title        = {Unleashing powerful generalization for point cloud registration},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LFE-PointMamba: Point cloud learning via local feature enhancement and state space model. <em>KBS</em>, <em>329</em>, 114350. (<a href='https://doi.org/10.1016/j.knosys.2025.114350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud learning has important application value in autonomous driving and robot navigation. To address the limitations of existing approaches-Transformer’s high quadratic complexity and Mamba’s insufficient local geometric capture, as well as its unidirectional modeling bias conflicting with the non-causal nature of point clouds-this paper proposes LFE-PointMamba. This framework co-optimizes a local feature enhancement module and an improved Mamba architecture, enabling fine-grained geometric perception and efficient global modeling. First, it employs a composite representation that integrates explicit geometric structures and implicit semantic features, alongside a three-level cascading graph convolution for multi-scale context fusion, which enhances local feature capture and provides a more robust semantic basis for global modeling. Second, it replaces causal convolution with non-causal grouping convolution, thereby resolving the conflict between Mamba’s one-way modeling and the non-causal relations inherent in point clouds. At the same time, local and global features are dynamically aggregated through dual-path feature fusion, allowing the model to better balance the capture of local details and modeling of long-range dependencies. Third, utilizing the Hilbert curve’s spatial proximity property and multi-variant dynamic rearrangement, it enables efficient global modeling and spatial topology adaptation without significantly increasing computation. Experiments show that LFE-PointMamba performs well in various downstream tasks. On ModelNet40 and the most challenging PB-T50-RS variant of ScanObjectNN, the classification accuracy achieved 93.0 % and 89.3 %, respectively. In the ShapeNetPart segmentation task, the mean IoU for all instances is 86.1 %. Additionally, the model significantly reduces the number of parameters and computational complexity, offering an efficient solution for point cloud learning.},
  archive      = {J_KBS},
  author       = {Bowen Zhou and Lixin Zhan and Jie Jiang},
  doi          = {10.1016/j.knosys.2025.114350},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114350},
  shortjournal = {Knowl. Based Syst.},
  title        = {LFE-PointMamba: Point cloud learning via local feature enhancement and state space model},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parsilo-CDR: Privacy-aware cross-domain recommendation for data silo. <em>KBS</em>, <em>329</em>, 114349. (<a href='https://doi.org/10.1016/j.knosys.2025.114349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain recommendation is a significant topic to alleviate the data sparsity issue in the target domain by leveraging source domain information. However, cross-domain recommendation usually falls into the effect of data silo, since data of the source domain and target domain are generally isolated in different platforms. Intuitively, there are two limits on cross-domain recommendation for data silo. Firstly, data sharing across different domains is difficult, due to the concern of privacy breaching. Secondly, the noise of shared information during cross-platform interactions negatively impacts recommendation in target domain with limited cross-domain knowledge exchange, especially domain-specific noise (the domain information of source domain which is harmful to target domain) on cross-domain recommendation. To tackle these issues, this paper proposes a privacy-aware cross-domain recommendation framework for data silo, known as Parsilo-CDR. Parsilo-CDR introduces the pre-training module and the decoupling regularizers into cross-domain recommendation. The pre-training module is designed to convert raw data into synthetic privacy-preserving data, dynamically balancing privacy and usability based on user privacy preferences. The regularizers further enhance recommendation accuracy by separating user information into domain-common knowledge and domain-specific features, preserving common information while filtering out the domain-specific noise of the shared knowledge. Experimental results validate Parsilo-CDR’s effectiveness in improving recommendation accuracy while overcoming the privacy concern posed by data silo.},
  archive      = {J_KBS},
  author       = {Shanpeng Liu and Buqing Cao and Sheng Lin and Wenyu Zhao and Jianxun Liu and Xiong Li},
  doi          = {10.1016/j.knosys.2025.114349},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114349},
  shortjournal = {Knowl. Based Syst.},
  title        = {Parsilo-CDR: Privacy-aware cross-domain recommendation for data silo},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-matching framework for visual entity linking enhanced by large language models. <em>KBS</em>, <em>329</em>, 114348. (<a href='https://doi.org/10.1016/j.knosys.2025.114348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal entity linking (MEL) accurately links ambiguous textual mentions in a multimodal context to unambiguous entities within a knowledge graph (KG) or knowledge base (KB). It plays a substantial role in various application domains, such as KG construction and semantic retrieval. However, currently, this task primarily aims to enhance the textual semantic level and fails to fully leverage multimodal context to enrich the semantic depth of a KG. We address this limitation by proposing a new task called visual entity linking (VEL), which is similar to traditional MEL. The key difference is that VEL aims to jointly map ambiguous textual mentions and their corresponding visual objects to entities in the KG. To this end, we introduce DMVEL, a dual-matching framework for VEL. (1) The optimal visual object can be obtained by utilizing a multi-instance feature alignment and classification mechanism that fully leverages both coarse-grained (textual and image) and fine-grained (textual and visual object) information. (2) Pre-designed prompt templates are employed to guide large language models (LLMs) in generating entity-focused descriptions for all entities in the KG, minimizing noise from irrelevant information. (3) A dual matching strategy comprising two key components is proposed. The first component entails applying an innovative filter to align ambiguous mentions with entities at the macro level of the overall semantics. The second component is the re-ranker, which performs fine-grained matching between local features and enhanced entity feature representations at the granular level, ensuring global semantic alignment while emphasizing local semantics. Extensive experiments on three public benchmarks demonstrate that the proposed method achieves state-of-the-art performance, paving the way toward an efficient and general solution to utilize LLMs to perform VEL.},
  archive      = {J_KBS},
  author       = {Dijing Pan and Runhe Qiu and Xueqin Jiang and Shaohua Tao},
  doi          = {10.1016/j.knosys.2025.114348},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114348},
  shortjournal = {Knowl. Based Syst.},
  title        = {A dual-matching framework for visual entity linking enhanced by large language models},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information bottleneck-guided KNN contrastive hashing for unsupervised cross-modal retrieval. <em>KBS</em>, <em>329</em>, 114347. (<a href='https://doi.org/10.1016/j.knosys.2025.114347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised cross-modal hashing (UCMH) has emerged as a promising solution for scalable multi-modal retrieval without costly annotations. However, existing methods often rely on rigid pairwise contrastive learning and fixed-size neighborhood selection, which suffer from false negatives and semantic noise, respectively—limiting their ability to model complex semantic structures in open-world scenarios. In this paper, we propose a novel framework, I nformation B ottleneck-guided K NN C ontrastive H ashing ( IBKCH ), which introduces a flexible and semantically adaptive contrastive paradigm for UCMH. Specifically, we design an information-aware neighbor sampling strategy that integrates: (1) a Hard-negative and Soft-positive (HN-SP) mechanism to adaptively distinguish informative negatives and softly aggregate latent positives; (2) an information bottleneck loss to retain task-relevant semantics while suppressing redundancy; and (3) an entropy sparsity regularizer to mitigate noisy neighbor interference. Furthermore, we develop an adaptive KNN contrastive learning scheme that unifies intra-modal and inter-modal alignment, enabling robust and discriminative hash code learning. Extensive experiments on three benchmark datasets demonstrate that IBKCH consistently outperforms state-of-the-art methods, especially under noisy or semantically diverse conditions—highlighting its effectiveness and generalizability in real-world UCMH applications.},
  archive      = {J_KBS},
  author       = {Lei Zhu and Zhengchang Yuan and Zeqian Yi and Chengyuan Zhang and Lin Wu and Ying Zhang and Farid Boussaid and Mohammed Bennamoun and Shichao Zhang},
  doi          = {10.1016/j.knosys.2025.114347},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114347},
  shortjournal = {Knowl. Based Syst.},
  title        = {Information bottleneck-guided KNN contrastive hashing for unsupervised cross-modal retrieval},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TIJERE: A novel threat intelligence joint extraction model based on analyst expert knowledge. <em>KBS</em>, <em>329</em>, 114346. (<a href='https://doi.org/10.1016/j.knosys.2025.114346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraction of entities and relationships from threat intelligence reports into structured formats, such as cybersecurity knowledge graphs, is essential for automated threat analysis, detection, and mitigation. However, existing joint extraction methods struggle with feature confusion, language ambiguity, noise propagation, and overlapping relations, resulting in low accuracy and poor model performance. This paper presents TIJERE, an innovative joint entity and relation extraction framework that formulates joint extraction as a multisequence labeling representation (MSLR) problem. Specifically, separate sequences are generated for each entity pair. Unlike prior tagging schemes, MSLR integrates expert domain features to enrich positional, contextual, and semantic representations of entities, thereby enhancing feature distinction and classification accuracy. Additionally, TIJERE reduces language ambiguity and enhances domain-specific generalization by leveraging SecureBERT+, a contextual language model fine-tuned on cybersecurity text. This improves both named entity recognition (NER) and relation extraction (RE). This paper also introduces DNRTI-JE, the first publicly available jointly labeled dataset for cybersecurity entity and RE, filling a crucial gap in cyber threat intelligence automation. Empirical evaluations on the curated DNRTI-JE dataset demonstrate that TIJERE achieves state-of-the-art performance, with F1-scores exceeding 0.93 for NER and 0.98 for RE, outperforming existing methods. Together, TIJERE and the standardized benchmarking DNRTI-JE dataset enable high-performance cybersecurity intelligence extraction, with transferable applications in healthcare, finance, and bioinformatics.},
  archive      = {J_KBS},
  author       = {Inoussa Mouiche and Sherif Saad},
  doi          = {10.1016/j.knosys.2025.114346},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114346},
  shortjournal = {Knowl. Based Syst.},
  title        = {TIJERE: A novel threat intelligence joint extraction model based on analyst expert knowledge},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-cause deconfounding for recommender systems with latent confounders. <em>KBS</em>, <em>329</em>, 114345. (<a href='https://doi.org/10.1016/j.knosys.2025.114345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effectiveness of modern recommender systems is often undermined by various biases, such as popularity bias, that stem from multi-causal latent confounders inherent in user-item interaction data. However, existing approaches to mitigate these confounding effects often fail to distinguish between user-side and item-side latent confounders, treating them indiscriminately and thereby limiting their effectiveness. To address this issue, a m ulti- c ause d e c on f ounding method for recommender systems with latent confounders (MCDCF) is proposed. MCDCF leverages multi-cause causal effect estimation to learn substitutes for latent confounders at the user and item sides, respectively, using user behaviour data. Specifically, MCDCF treats the multiple items that users interact with and the multiple users that interact with items as treatment variables, and then uses a variational inference model to learn substitutes for latent confounders that influence the estimation of causality between users and user feedback, as well as between items and user feedback. Additionally, this research theoretically demonstrate the soundness of the MCDCF method. Extensive experiments on four real-world datasets demonstrate that the MCDCF method effectively recovers latent confounders related to users and items, reducing bias and thereby improving recommendation accuracy. Compared with the best-performing baselines, MCDCF achieves up to a 38.61 % improvement in recommendation metrics.},
  archive      = {J_KBS},
  author       = {Zhirong Huang and Yuxuan Hu and Debo Cheng and Jiuyong Li and Lin Liu and Guixian Zhang and Shichao Zhang},
  doi          = {10.1016/j.knosys.2025.114345},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114345},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-cause deconfounding for recommender systems with latent confounders},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topological insights into heterogeneous information networks: A systematic review on biological data association. <em>KBS</em>, <em>329</em>, 114344. (<a href='https://doi.org/10.1016/j.knosys.2025.114344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interactions and associations among biomolecules, such as proteins, RNA, metabolites, and genes, form the foundation of the biological process. Systematic analysis of these associations is crucial for uncovering biological mechanisms and enabling more precise bioengineering applications. Given the complexity and diversity of biological entities and their interrelationships, biological networks are inherently heterogeneous, comprising multiple types of nodes and edges. This complexity has driven the growing adoption of heterogeneous information networks (HINs) for biological data association analysis. To the best of our knowledge, the influence of topological properties has been largely disregarded in previous studies, which have focused on the classification and analytical stages of HIN-based biological data association. A search was conducted across five scientific databases, and with the assistance of the guidance for systematic review and PRISMA framework, 53 articles from 2020 to 2024 were selected for analysis. The reviewed articles highlight the crucial roles of topological properties in biological HINs, such as dynamics of random walks, network completion, and path sampling. The miRNA-disease database, HMDDv4.0, is examined as a case study to identify the challenges that result from node degrees imbalances and the ambiguity of meta-paths in biological networks. Two preliminary research frameworks are proposed, one of which on modeling based on HIN and Markov model and the other on the improvement of meta-path induction ability based on this model. These findings can augment the representation capacity of HINs and to assist future research on biological data association analysis based on HINs.},
  archive      = {J_KBS},
  author       = {Di-Wen Kang and Khairunnisa Hasikin and Anis Salwa Mohd Khairuddin and Kai-Qing Zhou},
  doi          = {10.1016/j.knosys.2025.114344},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114344},
  shortjournal = {Knowl. Based Syst.},
  title        = {Topological insights into heterogeneous information networks: A systematic review on biological data association},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCINet: Multimodal context-aware network for RGBT tracking. <em>KBS</em>, <em>329</em>, 114343. (<a href='https://doi.org/10.1016/j.knosys.2025.114343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional RGBT tracking methods rely heavily on visual feature extraction and fusion, but often fail in real-world conditions where visual inputs are degraded by occlusion, illumination changes, or thermal crossover. Additionally, limited dataset scale constrains model generalization. To address these challenges, we propose MCINet, a novel multimodal tracking framework that shifts from vision-centric modeling to a multi-cue collaborative paradigm for enhanced robustness. MCINet integrates historical motion patterns, frequency-domain structure, and language-driven semantics, and employs a staged and decoupled fusion strategy to build a fault-tolerant target representation. Its long-short range attention mechanism captures both temporal dynamics and spatial variations, while a frequency-guided semantic alignment module enhances visual-textual consistency. Crucially, even when visual signals deteriorate, MCINet maintains reliable tracking by leveraging auxiliary cues. This weakly supervised multi-cue design also mitigates the dependence on large-scale labeled data, improving adaptability under modality imbalance or failure. Experimental results on RGBT210, RGBT234, and LasHeR benchmarks demonstrate that MCINet achieves competitive performance in both accuracy and robustness, highlighting its practical potential in challenging real-world environments. The code of the proposed method will be available at https://github.com/ysqidong-dotcon/MCINet .},
  archive      = {J_KBS},
  author       = {Zhao Gao and Dongming Zhou and Zhiyong Wu and Yisong Liu and Qingqing Shan},
  doi          = {10.1016/j.knosys.2025.114343},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114343},
  shortjournal = {Knowl. Based Syst.},
  title        = {MCINet: Multimodal context-aware network for RGBT tracking},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active source-free open-set domain adaptation. <em>KBS</em>, <em>329</em>, 114342. (<a href='https://doi.org/10.1016/j.knosys.2025.114342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-free open-set domain adaptation (SFODA) aims to transfer a source model to an unlabeled target domain without explicit class restrictions. However, the SFODA setting faces a challenge in accurately identifying true labels for novel class samples. In this paper, we introduce a new research problem termed Active SFODA (ASFODA). By labeling a small budget of active samples, ASFODA aims to not only identify common class samples but also detect and identify novel class samples. Our investigations reveal that the targeted active samples should exhibit characteristics of abnormal uncertainty and diversity, which are not captured by existing active learning strategies. To remedy these shortcomings, we propose a method known as Diverse Structure Learning (DSL) comprised of Local Diversity Annotation (LDA) and Local Consistency Learning (LCL). Driven by the observation that both common and novel classes tend to form distinct clusters initially, LDA is designed to exploit this structural property. It annotates reliable samples situated in high-density regions of clusters, thereby facilitating the exploration of targeted active samples. Concurrently, LCL tackles the challenge of novel class clusters that may bear the same label but are located disparately by constructing interconnected samples between these clusters. This effectively learns the uncertain novel samples that reside between these clusters. Extensive experiments have validated the effectiveness of DSL, achieving over 15 % enhancements in the context of ASFODA.},
  archive      = {J_KBS},
  author       = {Fan Wang and Zhongyi Han and Hao Sun and Yilong Yin},
  doi          = {10.1016/j.knosys.2025.114342},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114342},
  shortjournal = {Knowl. Based Syst.},
  title        = {Active source-free open-set domain adaptation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning adaptive frequency-prompt denoising transformer for UAV nighttime tracking. <em>KBS</em>, <em>329</em>, 114341. (<a href='https://doi.org/10.1016/j.knosys.2025.114341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art (SOTA) visual tracking techniques have significantly advanced unmanned aerial vehicle (UAV) autonomy. However, their performance remains hindered by on-board camera hardware limitations and prevalent noise and blurring in complex environments, particularly under low-light conditions. Existing low-light enhancement methods frequently introduce overexposure, detail loss, and inadequate noise suppression, further degrading nighttime tracking performance. To address these challenges, we propose a Frequency Domain Prompt-based Denoising Transformer Network (FPDT). Specifically, we design a lightweight Adaptive Frequency Prompt Learning Module (AFP-LM), comprising a Frequency Learning Block (FLB) and a Prompt Block (PB). FLB leverages frequency domain analysis to achieve adaptive separation and interaction between high- and low-frequency features. PB dynamically generates frequency prompts to guide the model in suppressing high-frequency noise, thereby improving the feature extraction capabilities of the tracker. To further strengthen cross-domain feature representation, we introduce a Bidirectional Cross-Fusion Module (BCFM) that enables bidirectional interaction between frequency-domain and spatial-domain information. Additionally, a novel Multi-Dconv Head Transposed Cross-Attention (MDCA) is integrated into the decoder to facilitate multi-scale feature cross-fusion. Extensive experiments demonstrate that FPDT achieves superior performance on multiple UAV nighttime tracking benchmarks.},
  archive      = {J_KBS},
  author       = {Lihua Qi and Haijun Wang and Haoyu Qu and Zihao Su},
  doi          = {10.1016/j.knosys.2025.114341},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114341},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning adaptive frequency-prompt denoising transformer for UAV nighttime tracking},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised pretraining model for time series classification based on data preprocessing. <em>KBS</em>, <em>329</em>, 114340. (<a href='https://doi.org/10.1016/j.knosys.2025.114340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, time series have been widely applied and made great progress in the industrial field, including pretrained models. By training models with a large amount of data similar to a certain field and fine-tuning them with a small number of samples, high-precision models, which have great value in the industrial field, can be obtained. However, the current models have two main problems. First, they mostly use supervised classification. Although the accuracy is high, it is not practical for various real-world data with a small number of labeled samples. Second, recent research has mainly focused on contrastive learning, which has higher requirements for data form and regularity. To address these two problems, we propose a self-supervised preprocessing classification model for time series. First, based on the inherent characteristics of the data, we determined the data preprocessing method by judging the properties of the time series. Second, we proposed a self-supervised contrastive learning-based sorting similarity method using coarse similarity in the pretraining stage and our sorting loss function in the fine-tuning stage to improve overall performance. Subsequently, we conducted extensive experiments on 8 different real-world datasets from various domains. The experimental results indicated that the proposed model improved over existing methods by at least 1.1 % , 2.7 % , 6.9 % , and 2 % in terms of ACC, Precision, Recall, and AUPRC, respectively.},
  archive      = {J_KBS},
  author       = {Hanlin Zhang},
  doi          = {10.1016/j.knosys.2025.114340},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114340},
  shortjournal = {Knowl. Based Syst.},
  title        = {A self-supervised pretraining model for time series classification based on data preprocessing},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic spatiotemporal graph convolutional network collaborative pre-training learning for traffic flow prediction. <em>KBS</em>, <em>329</em>, 114339. (<a href='https://doi.org/10.1016/j.knosys.2025.114339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction constitutes a fundamental pillar for intelligent transportation systems (ITS) optimization. However, the intricate spatiotemporal correlations within traffic networks pose significant challenges to precise prediction. Existing methods often rely on static relational assumptions, inadequately capturing global temporal correlations and struggling to model the complex trends and periodic patterns present in long-term traffic data. To surmount these limitations, we present a novel d ynamic spatiotemporal g raph c onvolutional n etwork collaborative p re- t raining l earning (DGCN-PTL). Our methodology incorporates a dual stage architecture: initially, a pre-training stage employs masked autoencoder mechanisms coupled with Transformer architectures to effectively extract temporal representations from extensive historical time series data. Subsequently, the prediction stage executes downstream forecasting through several pivotal components. We develop a dynamic graph learning module that adaptively captures evolving spatial interdependencies among network nodes across temporal intervals. Additionally, we integrate gating mechanisms with self-attention operations to augment the model’s capability in characterizing both local and global temporal correlations. A dedicated feature transformation module facilitates channel adaptation and representation refinement. Comprehensive experiments across four real-world datasets substantiate DGCN-PTL’s superior performance against 23 state-of-the-art baselines, achieving remarkable improvements of 5.49 % over the most competitive existing method.},
  archive      = {J_KBS},
  author       = {Haiyang Chi and Yuhuan Lu and Yirong Zhu and Wei Ke and Hanbin Mao},
  doi          = {10.1016/j.knosys.2025.114339},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114339},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic spatiotemporal graph convolutional network collaborative pre-training learning for traffic flow prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new feature selection method using deep learning and graph representation in high-dimensional datasets. <em>KBS</em>, <em>329</em>, 114338. (<a href='https://doi.org/10.1016/j.knosys.2025.114338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, advances in data collection and storage have led to high-dimensional datasets containing numerous, often redundant features, which can negatively affect machine learning algorithms. Feature selection has emerged as a key solution to reduce dataset dimensionality, thereby improving computational efficiency and minimizing overfitting. Traditional feature selection models have limitations in effectively handling high-dimensional data and often overlook intricate relationships between features. Therefore, they may not fully optimize model performance and may be prone to overfitting. To address these challenges, we propose a novel feature selection method based on deep learning that can better capture complex patterns and dependencies among features in high-dimensional data. This method, which uses a deep similarity measure and graph representation, involves three phases. First, the problem is modeled as a graph using the deep similarity measure. Next, primary features are clustered through a community detection model. Finally, the most influential feature within each cluster is selected using node centrality and feature appropriateness measures. Notably, the feature selection step adopts a filter-based approach rather than relying on a learning algorithm, as is common in wrapper models. This design significantly reduces computational complexity and minimizes parameter requirements compared to previous methods. By avoiding reliance on a learning algorithm, the proposed method overcomes challenges such as high computational costs while improving accuracy. Experimental results across multiple datasets demonstrate that the proposed supervised model outperforms state-of-the-art approaches, achieving average improvements of 1.5 % in accuracy and 1.77 %, 1.87 %, and 1.81 % in precision, recall, and F1-score, respectively.},
  archive      = {J_KBS},
  author       = {Matin Chiregi and Mahdi Mazinani and Mitra Mirzarezaee},
  doi          = {10.1016/j.knosys.2025.114338},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114338},
  shortjournal = {Knowl. Based Syst.},
  title        = {A new feature selection method using deep learning and graph representation in high-dimensional datasets},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STCKGE: Continual knowledge graph embedding based on spatial transformation. <em>KBS</em>, <em>329</em>, 114337. (<a href='https://doi.org/10.1016/j.knosys.2025.114337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current Continual Knowledge Graph Embedding (CKGE) methods primarily rely on translation-based embedding approaches, leveraging previously acquired knowledge to initialize new facts. While these methods often integrate fine-tuning or continual learning strategies to enhance efficiency, they compromise prediction accuracy and lack support for complex relational structures (e.g., multi-hop relations). To address these limitations, we propose STCKGE, a novel CKGE framework based on spatial transformation. In this framework, entity positions are jointly determined by base position vectors and offset vectors, enabling the model to represent complex relations more effectively while supporting efficient embedding updates for both new and existing knowledge through simple spatial operations, without relying on traditional continual learning techniques. Furthermore, we introduce a bidirectional collaborative update strategy and a balanced embedding method to guide parameter updates, effectively minimizing training costs while improving model accuracy. We comprehensively evaluate our model on seven public datasets and a newly constructed dataset (MULTI) focusing on multi-hop relationships. Experimental results confirm STCKGE’s strong performance in multi-hop relationship learning and prediction accuracy, with an average MRR improvement of 5.4 %. Our code and dataset are available at https://github.com/Wxy13131313131/STCKGE},
  archive      = {J_KBS},
  author       = {Xinyan Wang and Jinshuo Liu and Kaijian Xie and Meng Wang and Cheng Bi and Juan Deng and Donghong Ji and Jeff Z. Pan},
  doi          = {10.1016/j.knosys.2025.114337},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114337},
  shortjournal = {Knowl. Based Syst.},
  title        = {STCKGE: Continual knowledge graph embedding based on spatial transformation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge attention via radial basis functions for temporal knowledge graphs completion. <em>KBS</em>, <em>329</em>, 114336. (<a href='https://doi.org/10.1016/j.knosys.2025.114336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, leveraging Large Language Models (LLMs) for Temporal Knowledge Graph Completion (TKGC) based on given queries and corresponding knowledge sequences has emerged as a novel architecture. The quality of knowledge sequences plays a decisive role in prediction performance. Previous studies directly generated knowledge sequences through manually defined rules, which we term Original Knowledge Sequences (OKS). However, due to the inherent complexity of Temporal Knowledge Graphs (TKGs), OKS tend to be overly cumbersome. In contrast, a comprehensive yet concise knowledge sequence (CCKS) proves crucial. To address this challenge, we propose a knowledge ranking model. First, we use the target training quadruples, along with the OKS corresponding to the head and tail entities in those quadruples, as the training samples for the model. Then, the model considers the global graph structure and temporal context of the knowledge in the OKS using a Relational Graph Convolutional Network (R-GCN) and a Transformer Encoder. Finally, the model uses Knowledge Attention via Radial Basis Functions (KA-RBF) to calculate the overall weighted similarity of all knowledge pairs in the OKS corresponding to the head and tail entities, and simplifies the OKS into CCKS by sorting the weights. We conducted experimental analysis from four different perspectives on five datasets, and the experimental results demonstrated the feasibility and effectiveness of the model. Code is available at https://github.com/foundation000/KA-RBF .},
  archive      = {J_KBS},
  author       = {Enqiang Wang and Jin Liu and Xiao Liu and Bo Huang and Xu Huang},
  doi          = {10.1016/j.knosys.2025.114336},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114336},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge attention via radial basis functions for temporal knowledge graphs completion},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient feature points detector for full and partial palmprint recognition. <em>KBS</em>, <em>329</em>, 114335. (<a href='https://doi.org/10.1016/j.knosys.2025.114335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decade, biometrics has witnessed significant advancements in various forensic and security applications for human identification and authentication, with growing interest in effective and discriminative traits such as palmprints. However, practical applications still face challenges, especially when palmprints are collected in portions, such as at crime scenes, or partially acquired for authentication in uncontrolled environments. This paper presents a novel method that incorporates the local binary patterns (LBP) operator into the conventional scale-invariant feature transform (SIFT) algorithm to detect and extract robust keypoint features. While SIFT employs a Gaussian filter to detect keypoints on the palmprint, the proposed method leverages the multi-scale LBP operator to detect stable points prior to computing the corresponding descriptors. Furthermore, an efficient method for filtering keypoints, namely the Self-Geometric Relationship (SGR) filter, is introduced to eliminate potential false matches. The proposed palmprint recognition system, LBPSIFT-SGR, demonstrates competitive performance on full palmprints compared to state-of-the-art techniques and exhibits clear superiority on partial palmprint images, where competing systems fail, across different datasets.},
  archive      = {J_KBS},
  author       = {Fouad Khelifi and Jumma Almaghtuf and Ahmed Bouridane},
  doi          = {10.1016/j.knosys.2025.114335},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114335},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient feature points detector for full and partial palmprint recognition},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InDReCT: Intra-domain dual reconstruction for cross-domain transfer in camouflaged object detection. <em>KBS</em>, <em>329</em>, 114334. (<a href='https://doi.org/10.1016/j.knosys.2025.114334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current Camouflaged Object Detection (COD) methods primarily rely on a direct mapping from image to mask. However, due to the inherent semantic and structural gap between the image and its corresponding mask, the learned feature representations often exhibit poor generalization ability. To address this issue, we propose a novel intra-domain dual reconstruction framework, termed InDReCT, which reformulates the image-to-mask prediction as a cross-domain transfer task by simultaneously reconstructing both the input image and its corresponding mask. Within this framework, semantic knowledge is transferred through two reconstruction processes from different domains: image reconstruction (appearance domain) and mask reconstruction (structure domain), and is eventually integrated back into the image-to-mask prediction task. This dual reconstruction mechanism implicitly guides the network to extract hidden appearance semantics from image-to-image reconstruction and explicit structural information from mask-to-mask reconstruction, thereby enhancing the model’s generalization capability. Extensive experiments on three benchmark COD datasets and four downstream tasks demonstrate that InDReCT consistently outperforms state-of-the-art methods in both detection accuracy and generalization ability. Notably, on the widely-used COD10K dataset, InDReCT achieves a Mean E-measure ( E m ) of 95.6 %, surpassing the latest state-of-the-art model CamoDiffusion by 1.6 %. Code and models will be publicly available at: https://github.com/KungFuProgrammerle/InDReCT .},
  archive      = {J_KBS},
  author       = {Guowen Yue and Ge Jiao and Fangyan Wang},
  doi          = {10.1016/j.knosys.2025.114334},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114334},
  shortjournal = {Knowl. Based Syst.},
  title        = {InDReCT: Intra-domain dual reconstruction for cross-domain transfer in camouflaged object detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An accurate quantitative analysis model for martian-like mineral elements using bi-LSTM coupled with whale optimization algorithm. <em>KBS</em>, <em>329</em>, 114333. (<a href='https://doi.org/10.1016/j.knosys.2025.114333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser-induced breakdown spectroscopy (LIBS) is an analytical method derived from atomic emission spectroscopy that enables the rapid acquisition of chemical composition information from samples. Due to the susceptibility of the LIBS signal to interference from the self-absorption phenomena, sample matrix, and various other factors, the accuracy of both quantitative and qualitative analyses may be compromised without appropriate data mining techniques. In this work, LIBS is integrated with multivariate analysis algorithms to analyze the major element contents of minerals quantitatively. Using a dataset of geological reference samples made available by the ChemCam and SuperCam teams, an innovative modeling approach is introduced that incorporates a bidirectional long short-term memory (Bi-LSTM) network refined through a whale optimization algorithm (WOA). The findings from the dataset indicate that WOA-Bi-LSTM achieves superior accuracy in the quantitative analysis of in-situ and Martian-like LIBS data, surpassing state-of-the-art models. Compared with those of standalone implementations of Bi-LSTM and the partial least squares (PLS) model, the WOA-Bi-LSTM model yielded average reductions in the root mean square error of prediction (RMSEP) by 15.1 %. The method also achieved an average coefficient of determination (R²) of 0.936, reflecting a close alignment between the actual sample measurements and predicted values. The WOA-Bi-LSTM algorithm achieves high accuracy and strong generalizability, its prediction results are better than those of traditional quantitative regression analysis algorithms. The model established in this paper may significantly enhance the quantitative analysis of LIBS spectral data in future Mars exploration missions.},
  archive      = {J_KBS},
  author       = {Junhui Cheng and Meibao Yao and Yan Yu},
  doi          = {10.1016/j.knosys.2025.114333},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114333},
  shortjournal = {Knowl. Based Syst.},
  title        = {An accurate quantitative analysis model for martian-like mineral elements using bi-LSTM coupled with whale optimization algorithm},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantically enhanced community detection in social networks: Integrating BERT with a comprehensive ontology and SWRL rules. <em>KBS</em>, <em>329</em>, 114332. (<a href='https://doi.org/10.1016/j.knosys.2025.114332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection in social networks is crucial for understanding online interactions. Traditional methods often overlook semantic information. This paper introduces a novel framework that significantly enhances community detection accuracy and interpretability by integrating deep semantic representation with formal knowledge and logical reasoning. Our primary contributions are threefold: (1) a synergistic framework combining fine-tuned BERT embeddings, a comprehensive domain-specific ontology, and SWRL rules; (2) an ontology-guided attention mechanism that directs BERT to focus on semantically relevant concepts during fine-tuning; and (3) the application of logical inference via SWRL to refine community boundaries and identify implicit user relationships. We evaluated our framework on diverse datasets from Facebook, Twitter, and Reddit. Experiments demonstrate significant improvements in modularity, NMI, and F1-score over strong baselines, including Louvain, graph attention networks (GAT), and other embedding-based methods. An ablation study confirms the critical contributions of both the ontology-guided attention and the SWRL rules. A case study on Twitter political discussions further illustrates the framework’s ability to uncover semantically coherent communities, influential users, and fine-grained thematic structures. This research establishes a new paradigm for community detection that effectively merges structural analysis with semantic knowledge, delivering more accurate, interpretable, and scalable results.},
  archive      = {J_KBS},
  author       = {Abdelweheb Gueddes and Borhen Louhichi and Mohamed Ali Mahjoub},
  doi          = {10.1016/j.knosys.2025.114332},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114332},
  shortjournal = {Knowl. Based Syst.},
  title        = {Semantically enhanced community detection in social networks: Integrating BERT with a comprehensive ontology and SWRL rules},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-perspective knowledge graph embedding model fusing structural features and textual descriptions of entities. <em>KBS</em>, <em>329</em>, 114331. (<a href='https://doi.org/10.1016/j.knosys.2025.114331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In knowledge graph, both the structural features and the textual descriptions of entities carry rich content, where structural features can be subdivided into local and global features. However, existing methods find it challenging to fully utilize entities’ structural features and textual descriptions,failing to effectively capture the multiscale interaction between entities and relations.To tackle the problems mentioned, this paper proposes a multi-perspective knowledge graph embedding model fusing structural features and textual descriptions of entities (MPST). This paper solves the problem of insufficiently rich structural features of entities by learning local and global features of entities through relational graph neural network and Transformer, respectively. Then, this paper proposes a structure-text interaction module to capture the interaction between structural features and textual descriptions to fill the missing semantic information in different structural features. Finally, this paper proposes a collaborative structural decoder that fully integrates entities’ local and global features, effectively capturing the deep connections between different structural features of entities and their relations. Experimental results show that the MPST model achieves MRR scores of 0.387 and 0.509 on the FB15k-237 and WN18RR datasets for the link prediction task, respectively, both surpassing mainstream baseline models and demonstrating its remarkable performance.},
  archive      = {J_KBS},
  author       = {Song Li and Guantong Chen and Liping Zhang and Haipeng Jin and Guanglu Sun},
  doi          = {10.1016/j.knosys.2025.114331},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114331},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-perspective knowledge graph embedding model fusing structural features and textual descriptions of entities},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-view temporal knowledge graph reasoning. <em>KBS</em>, <em>329</em>, 114330. (<a href='https://doi.org/10.1016/j.knosys.2025.114330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Knowledge Graph (TKG) reasoning has attracted significant attention for completing missing knowledge over time. Recent graph neural network (GNN) -based approaches that explore the temporal evolution of graph topological structures from either continuous-time or discrete-time, which offer distinct perspectives on modeling event associations in TKG. Two GNN-based approaches with different perspectives are supposed to be complementary, but effective integration has not been thoroughly explored in existing research. In addition, capturing the repetitive nature of events during GNN message passing poses a challenge in the continuous-time view, while the complex associations among co-occurring events in KG snapshots cannot be efficiently modeled in the discrete-time view. In this paper, we propose a new D ual- v iew TK G r easoning network, namely DV-TKR, which comprehensively models the temporal semantic information by integrating the strengths of both types of graph structure encoding representation for reasoning. In DV-TKR, we decompose the quadruple neighbors of each entity into triples and times in the continuous-time TKG. A time-aware event recurring modeling (TERM) module incorporating multiple attention mechanisms in the continuous-time view, is proposed to effectively distinguish the importance of the same triple at different times. For the discrete-time view, we propose a relation-aware graph evolving modeling (RGEM) module to learn the temporal evolution of entities among successive KG snapshots. The relation-aware graph attention mechanism in the RGEM module captures significant correlations among co-occurring events within the overall KG snapshot. Extensive experimental results on three public datasets demonstrate the superiority of our proposed model compared to the state-of-the-art baselines.},
  archive      = {J_KBS},
  author       = {Wei Chen and Yuting Wu and Shengnan Guo and Shuhan Wu and Zhishu Jiang and Youfang Lin and Huaiyu Wan},
  doi          = {10.1016/j.knosys.2025.114330},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114330},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-view temporal knowledge graph reasoning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective two-dimensional code instance dollmaker masked convolutional network for QR code beautification. <em>KBS</em>, <em>329</em>, 114329. (<a href='https://doi.org/10.1016/j.knosys.2025.114329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid proliferation of internet applications has made Quick Response (QR) codes indispensable in domains such as electronic ticketing, warehouse management, and online payments. However, enhancing QR code visual quality for advertising and branding purposes remains challenging due to the trade-off between aesthetic appeal and scanning reliability, as well as the inefficiency of existing beautification methods. To solve these issues, this research introduces a 2-Dimensional Code Instance Improved Dollmaker Masked Convolutional Network (2DMCN) that integrates segmentation-based region of interest extraction, an Improved Dollmaker Optimization (IDO) algorithm for visual quality enhancement, and a VGG-19-based style transfer module for customizable designs. Codeword adjustment and discrete cosine transform-based embedding are employed to maintain both data integrity and visual quality. Experimental results demonstrate that 2DMCN attains a PSNR of 55.38 dB, SSIM of 0.60, FSIM of 0.70, GMSD of 0.30, noise tolerance of 87.04%, error correction capability of 91.23%, a decoding rate of 0.87, and an average processing time of 6.2 seconds. These results confirm the proposed framework’s greater efficiency, strength, and aesthetic performance associated to prevailing approaches, making it highly suitable for practical, visually appealing, and reliable QR code applications.},
  archive      = {J_KBS},
  author       = {Jyoti Rathi and Surender Kumar Grewal},
  doi          = {10.1016/j.knosys.2025.114329},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114329},
  shortjournal = {Knowl. Based Syst.},
  title        = {An effective two-dimensional code instance dollmaker masked convolutional network for QR code beautification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DNMDR: Dynamic networks and multi-view drug representations for safe medication recommendation. <em>KBS</em>, <em>329</em>, 114327. (<a href='https://doi.org/10.1016/j.knosys.2025.114327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medication Recommendation (MR) is a promising research topic which booms diverse applications in healthcare and clinical domains. However, existing methods mainly rely on sequential modelling and static graphs for representation learning, which ignore the dynamic correlations in diverse medical events of a patient’s sequential visits, leading to insufficient global structural exploration on nodes. Additionally, mitigating drug-drug interactions (DDIs) is another issue determining the utility of the MR systems. To address the challenges mentioned above, this paper proposes a novel MR method with the integration of dynamic networks and multi-view drug representations (DNMDR). Specifically, weighted snapshot sequences for dynamic heterogeneous networks are constructed based on discrete visits in sequential EHRs, and all the dynamic networks are jointly trained to capture both structural correlations in diverse medical events and sequential dependency in historical health conditions, aiming to achieve comprehensive patient representations with both semantic features and structural relationships. Moreover, by combining the drug co-occurrences and adverse DDIs in the internal view of drug molecule structure and the interactive view of drug pairs, safe drug representations are available to obtain high-quality medication combination recommendations. Finally, extensive experiments on real-world datasets are conducted for performance evaluation, and the experimental results demonstrate that the proposed DNMDR method outperforms the state-of-the-art baseline models with a large margin on various metrics such as PRAUC, Jaccard, DDI rates and so on. The DNMDR model’s code is available at https://github.com/Liuguanlin818/DNMDR .},
  archive      = {J_KBS},
  author       = {Guanlin Liu and Xiaomei Yu and Zihao Liu and Shucheng Liu and Xue Li and Xingxu Fan and Xiangwei Zheng},
  doi          = {10.1016/j.knosys.2025.114327},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114327},
  shortjournal = {Knowl. Based Syst.},
  title        = {DNMDR: Dynamic networks and multi-view drug representations for safe medication recommendation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Operator transfer learning for physics field prediction on complex geometries with limited labelled data. <em>KBS</em>, <em>329</em>, 114326. (<a href='https://doi.org/10.1016/j.knosys.2025.114326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many engineering applications and scientific discoveries involve predicting physics fields, which are usually functions that operate on complex geometries. The recently proposed neural operator, which is a new machine learning paradigm that can directly learn mappings between functions, has succeeded remarkably in solving physics field prediction problems. However, optimal performance of the neural operators relies heavily on a large amount of labelled data. Collecting sufficient labelled data is expensive and time-consuming for most engineering scenarios. However, transfer learning can leverage the knowledge of relevant domains to reduce data requirements. In this study, a novel operator transfer learning framework based on neural operators on Riemannian manifolds (OTL-NORM) is proposed, which can predict physics fields on complex geometries with limited labelled data. OTL-NORM encodes physics fields on complex geometries by the Laplace–Beltrami operator (LBO) eigenfunctions of the geometries. Additionally, a hybrid loss function is constructed using conditional embedding operator discrepancy to solve the conditional distribution adaptation problem. Experiments on multiple physics field prediction problems involving complex 2D and 3D geometries demonstrate that the proposed operator transfer learning method can accurately predict high-dimensional physics fields with only limited labelled data.},
  archive      = {J_KBS},
  author       = {Lin Hu and Lu Chen and Yingguang Li and Xu Liu and Gengxiang Chen and Qinglu Meng and Xiaozhong Hao and Changqing Liu},
  doi          = {10.1016/j.knosys.2025.114326},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114326},
  shortjournal = {Knowl. Based Syst.},
  title        = {Operator transfer learning for physics field prediction on complex geometries with limited labelled data},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge distillation with predicted depth for robust and lightweight face presentation attack detection. <em>KBS</em>, <em>329</em>, 114325. (<a href='https://doi.org/10.1016/j.knosys.2025.114325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face Presentation Attack Detection (FacePAD) is critical for safeguarding face recognition systems against spoofing attempts, including printed photos, video replays, and 3D masks. However, many existing approaches struggle with generalization across diverse attack types and real-world conditions. In this study, we propose a dual-branch deep learning framework that leverages both RGB images and synthetically predicted depth maps to improve anti-spoofing robustness and accuracy. A monocular depth estimation network is used to generate depth cues from a single RGB image, which are then processed in parallel with the original image through two distinct branches of a convolutional neural network. The extracted features-texture-based from RGB and structure-aware from depth-are fused via concatenation to facilitate more discriminative spoof detection. Extensive experiments on four benchmark datasets demonstrate that our method achieves state-of-the-art performance, reducing HTER to 0 % on Replay-Attack and Replay-Mobile, and 1.023 % on ROSE-Youtu. Similarly, an ACER of 0.56 % is achieved on OULU-NPU, while maintaining computational efficiency. Furthermore, we introduce a knowledge distillation scheme to compress the dual-branch model into a lightweight single-branch variant suitable for real-time deployment in mobile authentication, surveillance, and biometric access control scenarios.},
  archive      = {J_KBS},
  author       = {Muhammad Shahid Jabbar and Taha Hasan Masood Siddique and Kejie Huang and Shujaat Khan},
  doi          = {10.1016/j.knosys.2025.114325},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114325},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge distillation with predicted depth for robust and lightweight face presentation attack detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient pseudo-label screening for entity alignment: Contrastive learning and cross-entropy joint optimization. <em>KBS</em>, <em>329</em>, 114324. (<a href='https://doi.org/10.1016/j.knosys.2025.114324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For entity alignment in the knowledge graph, pseudo-label iteration is an important way to address the problem of limited prior aligned entities. It is impacted by the speed, quantity, and accuracy of pseudo-label screening. However, existing methods often have some inadequacy in three factors, leading to the “buckets effect”. In this paper, the TSJO (Two Stages Joint Optimization) model is established for obtaining entity embedding representation. DR-T (Dynamic Relative Threshold) and D-Rot (Datasets Rotation) algorithms are proposed for efficiently screening and utilizing pseudo-labels. Specifically, TSJO simultaneously uses cross-entropy loss and contrastive loss to optimize the embedding layer. The joint execution of two stages allows TSJO to learn more precise entity semantics. DR-T algorithm accurately and rapidly screens a large number of pseudo-labels by comparing a ratio to a dynamically relaxed threshold. This ratio is the result of the second nearest neighbor similarity divided by nearest neighbor similarity. D-Rot algorithm generates a new dataset using prior aligned entities augmented with pseudo-labels. Then it selects either the new dataset or the inital one as the input for TSJO to learn better entity embedding representation. Extensive experiments show that, in contrast to other commonly used pseudo-label methods, the TSJO model achieves a comprehensive optimum in the speed, quantity, and accuracy of pseudo-label screening, and delivers the best entity alignment performance, demonstrating competitive performance.},
  archive      = {J_KBS},
  author       = {Haoran Xu and Wei Huang and Wenjing Xie and Le Yin and Yixin Zhao},
  doi          = {10.1016/j.knosys.2025.114324},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114324},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient pseudo-label screening for entity alignment: Contrastive learning and cross-entropy joint optimization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFUSegNet: Boundary-aware hierarchical attentive fusion network with adaptive preprocessing for diabetic foot ulcer segmentation. <em>KBS</em>, <em>329</em>, 114323. (<a href='https://doi.org/10.1016/j.knosys.2025.114323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic Foot Ulcers (DFUs) are a severe complication of diabetes, often leading to lower limb amputation and increased patient morbidity. Accurate segmentation of DFUs is essential for effective wound assessment, treatment planning, and healing monitoring. This paper introduces a novel deep learning framework, DFUSegNet, for accurate segmentation of DFUs and other chronic wounds. The proposed architecture seamlessly integrates a learnable image preprocessor (LIP) to enhance input quality and a hierarchical encoder for capturing multiscale and multiresolution wound features. A boundary enhancer (BE) sharpens ulcer edges, while the multiresolution positional attention (MPA) module emphasizes critical spatial details. Extracted features by the encoder are refined through a local-global feature aggregation (LGFA) module before being processed by a dual-mode attention-guided hierarchical decoder, ensuring precise and robust segmentation. Extensive quantitative and qualitative evaluations on the DFUC, FUSeg, and AZH Wound datasets showcase the superior performance of DFUSegNet, achieving state-of-the-art IoU/F1-scores (in %) of 60.06/70.78 on DFUC, 79.06/85.76 on FUSeg, and 81.21/87.28 on AZH. Interpretability analysis further highlights the effectiveness of our MPA, BE modules, and dual-mode attention-guided decoder in progressively extracting intricate ulcer features. Despite encountering some anomalies in the datasets, DFUSegNet demonstrates immense potential for integration into knowledge-based systems within clinical workflows and telemedicine, enabling automated, high-precision DFU segmentation to support early diagnosis and effective wound management. While promising results validate its effectiveness, successful clinical deployment will require large, accurately annotated DFU datasets, laying the foundation for future advancements in automated DFU segmentation. Source code: https://github.com/tushartalukder/DFUSegNet},
  archive      = {J_KBS},
  author       = {Tushar Talukder Showrav and Muhammad Zubair Hasan and Md Kamrul Hasan},
  doi          = {10.1016/j.knosys.2025.114323},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114323},
  shortjournal = {Knowl. Based Syst.},
  title        = {DFUSegNet: Boundary-aware hierarchical attentive fusion network with adaptive preprocessing for diabetic foot ulcer segmentation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced network security through an intelligent deep learning-based intrusion detection system with optimized performance. <em>KBS</em>, <em>329</em>, 114322. (<a href='https://doi.org/10.1016/j.knosys.2025.114322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network security is increasingly critical with the growth of networks and sophisticated cyberattacks. Existing Intrusion Detection Systems (IDS) face slow training, poor scalability with high-dimensional data, and overfitting, especially in IoT and smart infrastructures. This paper presents an Enhanced Network Security approach through an Intelligent Deep Learning-Based IDS with Optimized Performance (ENS-IDS-HGWNN). Data from CICIDS-2017 and WSN-DS datasets undergo cleaning, missing value handling, and redundancy removal using Neural Correlation Integrated Adaptive Point Process Filtering (NCIAPPF). SMOTE balances datasets, while Weighted Leader Search Algorithm (WLSA) selects features. Intrusion detection and classification is done by using Hyperbolic Graph Wavelet Neural Network (HGWNN), and is optimized by Triangulation Topology Aggregation Optimizer (TTAO). ENS-IDS-HGWNN achieves 98.12 % accuracy for Brute Force (CICIDS-2017) and 96.72 % for Blackhole (WSN-DS), outperforming baselines in precision, recall, F-score, ROC-AUC, MCC, and computational efficiency across all attack categories.},
  archive      = {J_KBS},
  author       = {Siva Subramanian R and Nithya T and Sudha K and Dinesh M G},
  doi          = {10.1016/j.knosys.2025.114322},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114322},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced network security through an intelligent deep learning-based intrusion detection system with optimized performance},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ECMRN: Efficient cross-modal reparameterization network for RGB-D tasks via prompt tuning. <em>KBS</em>, <em>329</em>, 114321. (<a href='https://doi.org/10.1016/j.knosys.2025.114321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D semantic segmentation has shown notable progress by leveraging the complementary characteristics of RGB and depth modalities, substantially enhancing scene understanding. However, existing approaches often depend on dual-encoder architectures, leading to high computational overhead and limited inference efficiency. To overcome these limitations, we propose an Efficient Cross-Modal Reparameterization Network (ECMRN), which integrates prompt tuning with dynamic frequency-domain structural reparameterization for efficient and accurate segmentation. Specifically, we introduce a hybrid RGB-D block that combines a frozen attention branch and a trainable CNN branch, facilitating collaborative modeling of global context and local structures. A Cross-layer Prompt Adapter (CPA) is devised to bridge the modality gap via learnable attention fusion and token interaction, enabling effective semantic alignment across modalities. Moreover, we propose a unified structural reparameterization framework, instantiated in both the stem module and the Dynamic Frequency-domain Reparameterization Module (DFRM), which facilitates expressive multi-branch feature learning during training and is equivalently transformed into a compact single-branch structure at inference for efficient deployment. Additionally, a Multi-scale Feature Optimization Module (MFOM) applies grouped attention at multiple scales to further enhance feature representation. Extensive experiments demonstrate that ECMRN achieves competitive performance in RGB-D semantic segmentation with nearly half the parameters of state-of-the-art methods and also sets new benchmarks on RGB-D salient object detection. The code will be made available at https://github.com/alkaidzc/ECMRN .},
  archive      = {J_KBS},
  author       = {Di Jia and Chen Zhao and Huilun Song and Huaxiu Zhang and Wei Li},
  doi          = {10.1016/j.knosys.2025.114321},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114321},
  shortjournal = {Knowl. Based Syst.},
  title        = {ECMRN: Efficient cross-modal reparameterization network for RGB-D tasks via prompt tuning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HSAE: Hierarchical structure augment embedding for various knowledge graph completion. <em>KBS</em>, <em>329</em>, 114320. (<a href='https://doi.org/10.1016/j.knosys.2025.114320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph Completion (KGC) addresses the task of reasoning over existing facts to predict missing relationships, serving as a fundamental component for downstream applications including question answering systems and personalized recommendation engines. Over the years, the KGC field has evolved into specialized tasks, including static KGC, temporal KGC, hyper KGC, and few-shot KGC, each requiring specialized methodologies. Although previous methods have utilized Generative Language Models (GLMs) to theoretically support multi task compatibility, their performance remains suboptimal compared to task-specific models. This limitation stems from their inability to effectively integrate structural and textual information, leading to a fine-grained structure-text gap. To address this challenge, we propose HSAE, a novel two-stage framework that hierarchically aligns structural and textual modalities, first at the coarse-grained entity level and then at the fine-grained token level. In the first stage, Entity-Level Structure Augment, we transform structural embeddings into tree-shaped entity classifications, enriching entity representations with explicit structural information. This augmentation provides global structural guidance during beam search, ensuring that generated sequences adhere to the underlying knowledge graph topology. In the second stage, Token-Level Structure Augment, we introduce a cross-modal alignment module that dynamically fuses structural embeddings with token-level predictions. By aligning structural and textual representations at the token level, HSAE ensures that each decoding step is informed by both structural and textual coherence. Experiments on eight benchmarks demonstrate that HSAE outperforms competitive baselines across multiple KGC tasks. The data and code are released at https://anonymous.4open.science/r/HSAE-main/README.md .},
  archive      = {J_KBS},
  author       = {Yifan Xue and Wanqiang Cai and Yingyao Ma and Lotfi Senhadji and Huazhong Shu and Jiasong Wu},
  doi          = {10.1016/j.knosys.2025.114320},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114320},
  shortjournal = {Knowl. Based Syst.},
  title        = {HSAE: Hierarchical structure augment embedding for various knowledge graph completion},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancement of single candidate optimizer for weighted feature fusion and dilation-based cascaded RNN in learning-based recommendation system. <em>KBS</em>, <em>329</em>, 114319. (<a href='https://doi.org/10.1016/j.knosys.2025.114319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation System (RS) plays a vital role in supporting decision-making processes, particularly in the context of online learning, which has gained substantial reputation in recent years. Although various advanced techniques have been proposed for RS, many still fall short of achieving optimal performance due to limitations in handling complex data formats and preprocessing challenges. Existing RS techniques often struggle with managing missing values, ensuring consistent data formatting, and capturing complex non-linear relationships within the input data. To address these issues, this work proposes an intelligent deep learning-based recommendation approach. First, input text data is collected from benchmark datasets and undergoes comprehensive pre-processing. The processed data is then passed through Multi-scale Bidirectional Encoder Representations from Transformers (BERT) and Transformer models to extract complementary and contextualized features. These features are effectively fused using a Weighted Feature Fusion (WFF) technique, where the optimal weight factor is determined by the Modified Alpha in Single Candidate Optimizer (MASCO) . The performance of the proposed model is evaluated across three benchmark datasets. The accuracy of the DCRNN framework reaches 94.4 %, 95.35 %, and 94.82 % for Datasets 1, 2, and 3, indicating consistent and high-performance results. The experimental results demonstrate that the proposed deep learning-based RS significantly outperforms existing techniques, offering improved recommendation accuracy and robustness, particularly in online learning applications.},
  archive      = {J_KBS},
  author       = {Balaji V and Anupam Das and Vishnupriya G and Safak Kayikci},
  doi          = {10.1016/j.knosys.2025.114319},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114319},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancement of single candidate optimizer for weighted feature fusion and dilation-based cascaded RNN in learning-based recommendation system},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ProDG: A proxy-domain-guiding strategy for multi-source-free domain adaptation in EEG emotion recognition. <em>KBS</em>, <em>329</em>, 114318. (<a href='https://doi.org/10.1016/j.knosys.2025.114318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subject-independent Electroencephalogram (EEG) emotion recognition has underperformed due to significant disparities among subjects. Domain adaptation (DA) is a common solution, but traditional methods require access to target domain data, raising privacy concerns. Source-free domain adaptation offers a viable solution, however, researches on it remains unexplored. Moreover, existing methods overlooked the complementary information across source domains. To overcome this challenge, we focus on exploring the inter-domain complementarity. Our core insight is that higher-confidence predictions from source models indicate regions closer to the target domain’s distribution. Based upon, we propose Pro xy- D omain- G uiding ( ProDG ) strategy, which pioneers confidence-guidance to achieve privacy-preserving recognition. First, we propose a Proxy Guiding theory validating that predictions of source models with higher confidence exhibit closer distributional proximity to the target domain. Then, we propose two modules: Pr oxy M utual I nformation Alignment ( PrMI ) constructs a proxy domain by aggregating high-confidence predictions from source models, approximating the target-overlapping region, then each source model is aligned with proxy domain via mutual information maximization; Pr oxy P seudo- L abel Alignment ( PrPL ) refines clustering-based pseudo-labels using cross source confidence evaluation, enhancing supervised loss quality. The whole training process utilize only the source domain model and target data, with source data being inaccessible, ensuring privacy-preserving. Our method attains state-of-the-art accuracy on DEAP(65.3 %), SEED (85.9 %) and SEED-IV (70.4 %), surpassing privacy-preserving methods by a large margin and rivaling non-privacy-preserving approaches. ProDG validates the efficacy of confidence-based proxy guiding in multi-source-free domain adaptation. This work was conducted at the College of Electronics and Information Engineering, Sichuan University in May 2025.},
  archive      = {J_KBS},
  author       = {Bingtao Zhou and Mian Xiang and Qian Ning},
  doi          = {10.1016/j.knosys.2025.114318},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114318},
  shortjournal = {Knowl. Based Syst.},
  title        = {ProDG: A proxy-domain-guiding strategy for multi-source-free domain adaptation in EEG emotion recognition},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-target object detection and classification for cloud based surveillance in smart internet of things using multi-component attention graph convolutional neural network. <em>KBS</em>, <em>329</em>, 114317. (<a href='https://doi.org/10.1016/j.knosys.2025.114317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud-based surveillance in smart Internet of Things (IoT) systems uses object detection and classification to enhance security and monitoring by processing data in the cloud, providing scalability and analysis. In this manuscript, Multi-Target Object Detection and Classification for Cloud-Based Surveillance in Smart Internet of Things using Multi-Component Attention Graph Convolutional Neural Network (MTO-IoT-MCAGCNN) is proposed. Firstly, input images are collected from PASCAL VOC Dataset. The input imagesare fed to pre-processing using Interaction-Aware Labled Multi-Bernoulli Filter (IALMBF)to remove noise from the collected input images; then the Pre-processed images are fed to feature extraction using Spatial-Temporal Knowledge-Embedded Transform (STKET)to extract Semantic features such as colour, shape and object. Then, the extracted images are fed to Multi-Component Attention Graph Convolutional Neural Network (MAGCNN) for object detection and classification. In general, MAGCNN does not express adapting optimization strategies to establish the ideal variables to guarantee the detection and classification the collected image. Hence, the Brown Bear Optimization Algorithm (BBOA) is used to optimize the weight parameter of MAGCNNused to classify the collected images. Then the proposed MTO-IoT-MCAGCNNis implemented in Python. Performance of the MTO-IoT-MCAGCNNapproach attains higher Specificity of 99.12 %, higher Accuracy of 99.55 % and higher (Mean Average Precision (maP)of 99.1 % when analysed through existing techniques like Research of multi-object detection and tracking using machine learning based on knowledge for video surveillance system(MODT-SS-CNN), a feature‐optimized Faster regional convolutional neural network for complex background objects detection (CBOD-RCNN) and deep-learning-enhanced multimarket detection for end–edge–cloud surveillance in smart IoT (MD- IoT-YONet),methods respectively.},
  archive      = {J_KBS},
  author       = {Rajasekaran A and T. Dinesh Kumar and M.A. Archana and S. Malathi and K. Saraswathi},
  doi          = {10.1016/j.knosys.2025.114317},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114317},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-target object detection and classification for cloud based surveillance in smart internet of things using multi-component attention graph convolutional neural network},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-guided distribution alignment for cross-domain few-shot learning. <em>KBS</em>, <em>329</em>, 114316. (<a href='https://doi.org/10.1016/j.knosys.2025.114316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain few-shot learning (CD-FSL) aims to recognize novel categories with minimal labeled samples in target domains that differ from source domains. However, difficulty in obtaining valid domain bias guidance leads to negative transfer challenges because the target domain samples are unknown during source domain training. Inspired by human reliance on prior knowledge when adapting to new domains, we propose a knowledge-guided distribution alignment network (KDANet). In contrast to earlier CD-FSL approaches that primarily focus on visual alignment alone, KDANet incorporates textual priors in both the training and adaptation stages, thereby enhancing domain transferability. Specifically, KDANet integrates textual priors as knowledge guidance for visual representation learning during pretraining in the source domain with sufficient samples to establish an initial learning foundation. To tackle the scarcity of target domain samples, available samples and construct pseudo-episodes are expanded through critical region detection. Leveraging the pretrained model and pseudo-episodes, a two-stage progressive finetuning method is employed to refine feature extraction and calibrate prototypes for target domain tasks, with prior knowledge guiding the learning process continuously. Moreover, adaptive distribution alignment is proposed throughout cross-domain training and finetuning to suppress distribution bias interference by utilizing multi-source domain alignment and triplet supervision. Quantitative and qualitative experiments demonstrate the superior performance of proposed method, particularly in challenging 1-shot tasks. Under the CD-FSL benchmark, proposed method achieves an average accuracy improvement of 3 % across all target domains, outperforming state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Jiale Chen and Feng Xu and Xin Lyu and Tao Zeng and Xin Li and Shangjing Chen},
  doi          = {10.1016/j.knosys.2025.114316},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114316},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge-guided distribution alignment for cross-domain few-shot learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning with integration of decision making method and various machine learning algorithms for alzheimer’s prediction. <em>KBS</em>, <em>329</em>, 114315. (<a href='https://doi.org/10.1016/j.knosys.2025.114315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease, a progressive and debilitating neurodegenerative disorder, presents considerable challenges in early diagnosis and treatment planning. Given the sensitive nature of patient health records and the diversity of medical data sources, there is a pressing need for diagnostic tools that are not only accurate and robust but also privacy-preserving. Federated learning offers a promising solution by enabling collaborative model training across multiple decentralized institutions, allowing each to contribute to a shared global model without exposing raw data. This approach safeguards patient confidentiality while ensuring compliance with data protection regulations. To further enhance the efficiency and effectiveness of federated systems, this research integrates multi-criteria decision-making methods into the federated learning framework. The use of these facilitates informed client selection, balanced model aggregation, and the prioritization of key factors such as accuracy, data distribution, volume, and computational capacity. This integration enables performance-driven decision-making under heterogeneous data conditions and enhances the scalability and personalization of collaborative learning. Various machine learning algorithms are incorporated within this federated decision-making framework to evaluate client contributions, optimize model training, and ensure the selection of top-performing clients based on multiple criteria. These algorithms play a crucial role in constructing accurate, robust and privacy-preserving models across distributed data sources, enabling effective collaboration without compromising data privacy. Together, federated learning and decision-making methods form a powerful paradigm for building intelligent, secure and high-performance diagnostic systems tailored to the complexities of Alzheimer’s disease. This research study provides an in-depth exploration of the working mechanism of federated learning combined with decision-making method. It includes the evaluation metrics calculated by these methods, a comparison of various machine learning algorithms utilized in this federated learning decision-making framework, as well as a discussion of their limitations and future directions.},
  archive      = {J_KBS},
  author       = {Maheen Sultan and Muhammad Akram and Shaista Habib and Cengiz Kahraman},
  doi          = {10.1016/j.knosys.2025.114315},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114315},
  shortjournal = {Knowl. Based Syst.},
  title        = {Federated learning with integration of decision making method and various machine learning algorithms for alzheimer’s prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Question answering over spatio-temporal knowledge graph. <em>KBS</em>, <em>329</em>, 114314. (<a href='https://doi.org/10.1016/j.knosys.2025.114314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal knowledge graphs (STKGs) enhance traditional KGs by integrating temporal and spatial annotations, enabling precise reasoning over questions with spatio-temporal dependencies. Despite their potential, research on spatio-temporal knowledge graph question answering (STKGQA) remains limited. This is primarily due to the lack of datasets that simultaneously contain spatio-temporal information, as well as methods capable of handling implicit spatio-temporal reasoning. To bridge this gap, we introduce the spatio-temporal question answering dataset (STQAD), the first comprehensive benchmark comprising 10,000 natural language questions that require both temporal and spatial reasoning. STQAD is constructed with real-world facts containing spatio-temporal information, ensuring that the dataset reflects practical scenarios. Furthermore, our experiments reveal that existing KGQA methods underperform on STQAD, primarily due to their inability to model spatio-temporal interactions. To address this, we propose the spatio-temporal complex question answering (STCQA) method, which jointly embeds temporal and spatial features into KG representations and dynamically filters answers through constraint-aware reasoning. STCQA achieves state-of-the-art performance, significantly outperforming existing baselines. Our work not only provides a valuable resource for future research but also advances the field by offering a robust baseline for answering complex spatio-temporal questions.},
  archive      = {J_KBS},
  author       = {Xinbang Dai and Huiying Li and Nan Hu and Yongrui Chen and Rihui Jin and Huikang Hu and Guilin Qi},
  doi          = {10.1016/j.knosys.2025.114314},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114314},
  shortjournal = {Knowl. Based Syst.},
  title        = {Question answering over spatio-temporal knowledge graph},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CTIUFuse: A CNN-transformer-based iterative feature universal fusion algorithm for multimodal images. <em>KBS</em>, <em>329</em>, 114313. (<a href='https://doi.org/10.1016/j.knosys.2025.114313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal image fusion is designed to combine the complementary features of different image modalities, thereby improving data quality. It has numerous applications in medical imaging, industrial inspection, and autonomous driving. To explore detailed information within image scenes in detail and effectively integrate complementary information from images, we propose a universal multimodal image fusion algorithm based on the CNN-Transformer iterative feature fusion (CTIUFuse). We improve a dual-branch CNN-Transformer encoder by incorporating the Residual Gradient Dense Block (RGDB) and a lightweight attention mechanism, which collaboratively extract fine-grained and global features while reducing computational cost. Furthermore, we present an iterative feature fusion network that progressively refines cross-modal complementary features. For self-supervised training, we derive a dynamic texture loss function that adaptively adjusts weights based on the importance of information in each modality, thereby ensuring optimal fusion performance. The experimental results reveal that CTIUFuse achieves superior performance on six datasets composed of infrared-visible and medical images. It outperforms existing methods in terms of both fusion accuracy and computational efficiency, significantly enhancing downstream infrared-visible object detection tasks and demonstrating strong generalizability. The source code of the CTIUFuse algorithm is available at https://github.com/L1nCyk/CTIUFuse .},
  archive      = {J_KBS},
  author       = {Chenyoukang Lin and Tao Liu and Zixi Wang and Bo Wang},
  doi          = {10.1016/j.knosys.2025.114313},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114313},
  shortjournal = {Knowl. Based Syst.},
  title        = {CTIUFuse: A CNN-transformer-based iterative feature universal fusion algorithm for multimodal images},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ConEm: A novel framework for integrating external factors with inner and outer correlations in time series forecasting. <em>KBS</em>, <em>329</em>, 114312. (<a href='https://doi.org/10.1016/j.knosys.2025.114312'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is pivotal in both academic research and practical applications across diverse industries. However, effectively leveraging external factors to enhance forecasting performance remains a significant challenge, necessitating further investigation. Current frameworks exhibit notable limitations in modeling the impact of external factors on both intrinsic and extrinsic correlations within time series data. To address these challenges, we propose a novel mechanism that systematically integrates contextual information from external factors with temporal dependencies, while maintaining compatibility with various encoder-decoder algorithms. This approach enables backbone models to embed dependent patterns from external factors across multiple correlated time series, effectively capturing their influence on both prior and adjacent timesteps. Our study centered on the application of time series forecasting for demand prediction, as sales forecasting poses unique challenges stemming from the complexity and variability of market conditions influenced by numerous external factors. We conducted extensive experiments on three real-world retail datasets, showcasing the substantial performance enhancement of backbone models when integrated with our proposed contextual embedding mechanism. Specifically, our approach achieves improvements of up to 26 % in Mean Squared Error (MSE) and 15 % in Mean Absolute Error (MAE) compared to both the original backbone models and other state-of-the-art (SOTA) baseline methods. The proposed mechanism is also evaluated on Weather and Energy datasets to further verify its generalization capability. We will release the source codes and experimental datasets at our GitHub 1 .},
  archive      = {J_KBS},
  author       = {Hoang Nguyen Nguyen and Wei Xiang and Lianhua Chi and Mike Da Gama and Sanjeevani Avashi and Michael Treloar and Lu Yu},
  doi          = {10.1016/j.knosys.2025.114312},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114312},
  shortjournal = {Knowl. Based Syst.},
  title        = {ConEm: A novel framework for integrating external factors with inner and outer correlations in time series forecasting},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VCE: Visual concept embedding for open-set fine-grained image retrieval. <em>KBS</em>, <em>329</em>, 114311. (<a href='https://doi.org/10.1016/j.knosys.2025.114311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image retrieval (FGIR) aims to accurately distinguish highly similar subclasses from a large collection of visually similar images. In open-set scenarios, local features of unseen categories often exhibit significant overlap with those of seen categories. Therefore, the model must extract transferable local semantics from seen classes to enable compositional reasoning. However, existing approaches primarily rely on holistic feature association within seen categories, resulting in highly entangled representations that hinder generalization to novel classes in open-set conditions. To address this, we propose a FGIR framework named Visual Concept Embedding (VCE), inspired by the human cognitive process where objects are decomposed into distinct concepts to achieve a better understanding. The VCE consists of two key components: Visual Concept Decoupling (VCD) and Concept-Enhanced Representation (CER). Specifically, the VCD represents objects as a composition of multiple independent concepts by leveraging a set of learnable concept vectors and a cross-attention mechanism. This decoupling allows the model to independently analyze the discriminability of each local feature, rather than relying on entangled global representations. Furthermore, the CER models the structural relationships among concepts, enabling the model to precisely attend to critical regions that reflect fine-grained differences and ensuring alignment between feature dimensions and discriminative local semantics. Extensive experiments demonstrate that VCE effectively learns different visual concepts and validates its effectiveness across three datasets.},
  archive      = {J_KBS},
  author       = {Yuetian Wang and Shuo Ye and Wenjin Hou and Shuhuang Chen},
  doi          = {10.1016/j.knosys.2025.114311},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114311},
  shortjournal = {Knowl. Based Syst.},
  title        = {VCE: Visual concept embedding for open-set fine-grained image retrieval},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing dyslexia intervention through an adaptive sequential recommender system. <em>KBS</em>, <em>329</em>, 114309. (<a href='https://doi.org/10.1016/j.knosys.2025.114309'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Children with dyslexia face significant learning difficulties that require personalized and intensive interventions. Although computer-based support programs exist, they often fail to adapt to the unique needs of each child, representing a major challenge in the field of educational intervention. This article presents a new adaptive sequential guidance system for personalized dyslexia intervention that addresses these limitations. The proposed methodology incorporates several key innovations: (1) a dynamic word generator that creates phonetically modified words and pseudowords from seed words, (2) a three-dimensional matrix structure ( E , W ,and F ) to effectively manage word difficulty and user performance, and (3) a recommendation algorithm based on matrix factorization. To mitigate cold-start problems, the system implements a heuristic initiation process and uses an extension technique to detect difficulties in specific derived words. Additionally, the concept of “virtual children” generated from real data and based on Bayesian Knowledge Tracking is introduced, allowing thorough testing and optimization of the system prior to its actual implementation. The evaluation of the system demonstrates three main results: (1) the use of heat maps and 3D visualization of the E matrix allows identifying specific areas of difficulty for each user, facilitating more targeted interventions; (2) extensive testing confirms the robustness of the system to reduce error rates in multiple trials; and (3) a parametric study evidences the ability of the system to adapt through adjustable parameters, keeping each child in his or her optimal learning zone.},
  archive      = {J_KBS},
  author       = {J. Ignacio Mateo Trujillo and Ignacio Rodríguez-Rodríguez and Diego Castillo-Barnes and Andrés Ortiz and Auxiliadora Sánchez and Juan L. Luque},
  doi          = {10.1016/j.knosys.2025.114309},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114309},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimizing dyslexia intervention through an adaptive sequential recommender system},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noise-free prototype guided representation calibration under label noise. <em>KBS</em>, <em>329</em>, 114308. (<a href='https://doi.org/10.1016/j.knosys.2025.114308'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world datasets inevitably suffer from label noise, which misleads deep networks and disrupts the underlying representation structures, resulting in poor generalization. As category representatives, prototypes are widely adopted in learning with noisy labels due to their strong semantic expressiveness. Existing works typically obtain prototypes by averaging representations within each class and update them during training. However, prototypes achieved by such label-dependent procedures may deviate from their optimal positions under noisy labels, thereby failing to guide the model towards stable and accurate predictions. In this paper, to mitigate noise-induced prototype deviation, and further learn more robust representations, we propose a novel method called Noise-Free Prototype guided Representation Calibration (NFPRC), which introduces fundamentally different, label-independent prototype construction and utilization. Specifically, NFPRC first leverages unsupervised contrastive learning to extract representations and then applies clustering to assign the nearest prototype to each instance. These noise-free prototypes are then fixed to impose directional constraints and guide robust representation learning. Additionally, NFPRC introduces a dynamic weighting strategy that assigns higher importance to instances with larger cross-entropy losses, thereby prioritizing potentially mislabeled instances and enhancing the model’s adaptability to more complex noisy label scenarios. Extensive experiments on both synthetic and real-world noisy label benchmarks validate the effectiveness of our method in improving representation learning and combating noisy labels. The code is available at: https://github.com/Huiting-hub/NFPRC .},
  archive      = {J_KBS},
  author       = {Huiting Yuan and Tingjin Luo and Xinghao Wu and Jie Jiang},
  doi          = {10.1016/j.knosys.2025.114308},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114308},
  shortjournal = {Knowl. Based Syst.},
  title        = {Noise-free prototype guided representation calibration under label noise},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-powered explanations: Unraveling recommendations through subgraph reasoning. <em>KBS</em>, <em>329</em>, 114307. (<a href='https://doi.org/10.1016/j.knosys.2025.114307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems (RecSys) are pivotal in enhancing user experiences across various web applications by analyzing the complicated relationships between users and items. An explainable RecSys is crucial for the product development and subsequent decision-making. Knowledge graphs (KGs) have been widely used to enhance the performance of RecSys. However, KGs are known to be noisy and incomplete, making it hard to provide reliable explanations for recommendation results. We introduce a novel recommender that synergies Large Language Models (LLMs) and KGs to enhance the recommendation and provide interpretable results. We first harness the power of LLMs to augment KG reconstruction, where LLMs analyze and extract information from user reviews to generate new triples. In this way, we can enrich KGs with explainable paths that express user preferences. In addition, we introduce a novel subgraph reasoning module that effectively measures the importance of nodes and discovers reasoning for recommendation. Finally, these reasoning paths are fed into the LLMs to generate interpretable explanations of the recommendation results. Our approach significantly enhances both the effectiveness and interpretability of RecSys, especially in cross-selling scenarios where traditional methods falter. The effectiveness of our approach has been rigorously tested on four open real-world datasets, with our methods demonstrating a superior performance over contemporary state-of-the-art techniques by an average improvement of 12 %. The application of our model in a cross-selling RecSys for a multinational engineering and technology company further underscores its practical utility and potential to redefine recommendation practices through improved accuracy and user trust.},
  archive      = {J_KBS},
  author       = {Guangsi Shi and Xiaofeng Deng and Linhao Luo and Lijuan Xia and Lei Bao and Bei Ye and Fei Du and Shirui Pan and Yuxiao Li},
  doi          = {10.1016/j.knosys.2025.114307},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114307},
  shortjournal = {Knowl. Based Syst.},
  title        = {LLM-powered explanations: Unraveling recommendations through subgraph reasoning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QC2-VQG: Question context complement for visual question generation. <em>KBS</em>, <em>329</em>, 114306. (<a href='https://doi.org/10.1016/j.knosys.2025.114306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Generation (VQG) is a critical vision-language understanding task that involves generating human-like questions from given images and associated textual information. Most of the existing works are answer-aware and focus on modeling the complex relationship between the answer and its relevant object regions. However, we observe that these approaches disregard question context (e.g., the image description and visual entities) which is indispensable for a large number of questions, making it difficult to generate the desired questions. To address this issue, we present a novel strategy to generate questions by supplementing image-related question context. The key motivation is that the question context can bridge the task gap between visual understanding and question generation. Thus, we propose QC 2 -VQG which can automatically capture the visual information and convert it to the textual question context for the answer-aware QG. Extensive experiments on two widely used datasets demonstrate that QC 2 -VQG outperforms SOTA methods across various evaluation metrics, highlighting its effectiveness in generating high-quality, contextually grounded questions.},
  archive      = {J_KBS},
  author       = {Ying Zhang and Xubo Liu and Ziyu Lu and Wenya Guo and Xumeng Liu and Ruxue Yan},
  doi          = {10.1016/j.knosys.2025.114306},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114306},
  shortjournal = {Knowl. Based Syst.},
  title        = {QC2-VQG: Question context complement for visual question generation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal electric load portrait method for multi-microgrids based on clustering-granulation-clustering. <em>KBS</em>, <em>329</em>, 114305. (<a href='https://doi.org/10.1016/j.knosys.2025.114305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microgrids (MGs) are transforming urban energy management to sustainability by enabling flexible operation and efficient renewable integration. Facilitating electricity exchange among multiple MGs with differentiated demand structures in dual space and time dimensions is of great significance for promoting renewable energy utilization. The feasibility of such coordination for a given region is highly reliant on the characteristics of local demand. However, a systematic analysis of electricity user types and their demand profiles at high spatial and temporal resolution remains absent. Most spatial load forecasting studies only focus on the load quantities or densities at specific nodes. To address this research gap, this paper proposes a multi-source data-driven spatial-temporal electric load portrait method for multi-microgrids (MMGs). First, the functional areas are clustered into multiple MGs with different regional types. Then, typical load curve (TLC) of each functional area is extracted via information granulation. Finally, secondary clustering is performed on TLCs within each MG to reveal user types and their consumption patterns. Rough k-means (RKM) is selected as the clustering algorithm and some improvements are proposed. Case studies in a Chinese city demonstrate that the proposed approach not only outperforms existing methods in terms of clustering performance and computational efficiency, but also uncovers significant spatial and temporal heterogeneity in the user compositions and demand profiles across different MGs. These insights provide actionable references for optimizing demand response (DR) mechanisms, supporting spatial-temporal energy complementarity, and promoting renewable energy consumption.},
  archive      = {J_KBS},
  author       = {Yiling Cheng and Tengfei Zhang and Si Lv and Fumin Ma and Minghao Fan and Gregory M.P. O’hare},
  doi          = {10.1016/j.knosys.2025.114305},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114305},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatial-temporal electric load portrait method for multi-microgrids based on clustering-granulation-clustering},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic graph-based multi-task learning model for cut-in intention and trajectory prediction. <em>KBS</em>, <em>329</em>, 114304. (<a href='https://doi.org/10.1016/j.knosys.2025.114304'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cut-in intention and trajectory prediction of the target vehicle in front of the autonomous vehicle (AV) are two major concerns relating to the safety of passengers. For both of them, it is important to consider the spatial-temporal information of the neighboring vehicles. It is a challenging task to capture this information precisely from the narrow-ranged neighbor vehicles. In such a scenario, a dynamically prioritized correlated connection is required based on the cut-in scenario of the target vehicle. Therefore, a multi-task learning framework consisting of a shared layer and a task-specific layer is proposed to capture detailed information using the prior trajectory data of vehicles as input for cut-in intention and trajectory forecasting of the target vehicle. The shared layer incorporates graph structure learning for effective graph representation, a graph neural network (GNN) with skip connections that efficiently captures spatial data, and an attentive encoder-decoder that records the sequential information. The task-specific layer utilizes fully connected neural networks with different activation functions to forecast two well-defined related tasks. The performance of the proposed model is evaluated on NGSIM and highD datasets. The experimental results show that the proposed model achieves 2.89–9.53 % more F1 score and 25.92–30.99 % lower Root Mean Square Error (RMSE) than the baseline models in predicting the cut-in intention and trajectory of the target vehicle, respectively. Furthermore, the model demonstrates the effectiveness and generalizability for real-time cut-in trajectory forecasting.},
  archive      = {J_KBS},
  author       = {Pritam Bikram and Shubhajyoti Das and Arindam Biswas},
  doi          = {10.1016/j.knosys.2025.114304},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114304},
  shortjournal = {Knowl. Based Syst.},
  title        = {A dynamic graph-based multi-task learning model for cut-in intention and trajectory prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning enhanced filter and response reliability regularization for aerial object tracking. <em>KBS</em>, <em>329</em>, 114303. (<a href='https://doi.org/10.1016/j.knosys.2025.114303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) tracking is critical in the transport and security sectors, and recent years have seen significant progress in this field. To address the limited computational resources and stringent real-time requirements of aerial platforms, numerous UAV tracking algorithms based on Discriminative Correlation Filters (DCFs) have been developed, aiming to strike a balance between accuracy and efficiency. However, the limited discriminative power of the filters, along with complex appearance variations such as background clutter, occlusion, and camera motion, continues to pose significant challenges and degrade tracking performance. To tackle these issues, we propose an Enhanced Filter and Response Reliability Correlation Filter (EFRCF). This method introduces an Enhanced Filter Reliability (EFR) regularization module, which employs a response map quality evaluation mechanism to guide the self-adaptive learning of regularization coefficients, thereby enhancing discriminative capability. Furthermore, an Enhanced Response Reliability (ERR) regularization module is incorporated to suppress abrupt fluctuations in the response map. Extensive experiments on four popular UAV tracking benchmarks demonstrate that the proposed EFRCF outperforms several mainstream trackers. Notably, it achieves a real-time processing speed of 62.5 frames per second on a low-cost CPU. The source code will be made available at https://github.com/marico2020/EFRCF here.},
  archive      = {J_KBS},
  author       = {Zhi Chen and Lijun Liu and Zhen Yu},
  doi          = {10.1016/j.knosys.2025.114303},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114303},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning enhanced filter and response reliability regularization for aerial object tracking},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing inductive knowledge graph completion with contextual relation topology learning. <em>KBS</em>, <em>329</em>, 114302. (<a href='https://doi.org/10.1016/j.knosys.2025.114302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion (KGC) plays a crucial role in inferring missing triples within knowledge graphs (KGs), while inductive KGC extends this by enabling predictions for previously unseen entities, allowing dynamic updates in KGs. Recent methods define entity-independent features and utilize Graph Neural Networks (GNNs) to extract them from subgraphs surrounding the target triplet, which are then used to represent relational semantics and logical rules for reasoning. However, the inductive capabilities of existing work is limited as they consider limited entity-independent features. To address this issue, we introduce a novel C ontextual R elation T opology L earning-based GNN framework for inductive KGC, namely CRTL , which considers a broader range of entity-independent features. We observe that subgraph structural features, relation correlation patterns , and entity-relation interactions are crucial entity-independent features for inductive KGC. Moreover, relation correlation patterns and entity-relation interactions are complementary. Specifically, we construct enclosing subgraphs to extract subgraph structural features, relational graphs to model the correlations between relations, and context subgraphs to capture the interactions between entities and relations. In addition, we design a scoring function that dynamically adjusts the contributions of these features. Our extensive experiments on benchmark datasets reveal that CRTL surpasses current state-of-the-art methods, demonstrating improvements of 9.68 % on WN18RR v1 and 12.86 % on FB15K-237 v1 when compared to the suboptimal results.},
  archive      = {J_KBS},
  author       = {Yuxuan Lu and Guojie Ma and Shiyu Yang and Junxiao Wang},
  doi          = {10.1016/j.knosys.2025.114302},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114302},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing inductive knowledge graph completion with contextual relation topology learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cascade stacked autoencoder neural network for intrusion detection in CAN-FD vehicular network. <em>KBS</em>, <em>329</em>, 114301. (<a href='https://doi.org/10.1016/j.knosys.2025.114301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, an Intrusion Detection System (IDS) for Controller Area Network with Flexible Data Rate (CAN-FD) Vehicle Networks based on hybrid Deep Learning (DL) is proposed. Initially, the CAN-FD vehicular network simulation is carried out, and then, the authentication protocol is utilized to increase the existing security of in-vehicle applications that verify the authenticity of the participating entities. Later, inter-service communication and external communication are established. Finally, IDS is performed, and the proposed IDS in CAN-FD In-Vehicle Networks is developed in the following manner. Initially, the input data undergoes normalization using z-score normalization. After that, feature selection is performed by a hybrid similarity measure based on Tanimoto and Jeffreys similarity to select the relevant features in the input data. Finally, intrusion detection is performed based on a hybrid DL model named Cascade Stacked Autoencoder Neural Network (CSANN). The proposed CSANN is developed using a Deep Stacked Autoencoder (DSA) and Deep Neuro Fuzzy Network (DNFN). Additionally, the performance of the implemented technique is evaluated using metrics such as accuracy, True Positive Rate (TPR), and True Negative Rate (TNR). The method achieved a maximum accuracy of 0.921, a TPR of 0.935, and a TNR of 0.921.},
  archive      = {J_KBS},
  author       = {V. Anjana Devi and P.V. Bhaskar Reddy and Sreenu Ponnada and K. Suresh Kumar},
  doi          = {10.1016/j.knosys.2025.114301},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114301},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cascade stacked autoencoder neural network for intrusion detection in CAN-FD vehicular network},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AutoEnergy: An automated feature engineering algorithm for energy consumption forecasting with AutoML. <em>KBS</em>, <em>329</em>, 114300. (<a href='https://doi.org/10.1016/j.knosys.2025.114300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature engineering (FE) plays a crucial role in Machine Learning pipelines, yet it remains a time-consuming process requiring heavy domain expertise. While Automated Machine Learning (AutoML) has automated model selection and hyperparameter tuning, it often overlooks FE, which is particularly needed in specialised domains such as Energy Consumption Forecasting (ECF). To address this limitation, we introduce AutoEnergy, a novel, domain-aware FE algorithm tailored for ECF. AutoEnergy automatically generates interpretable features from timestamps and past consumption values through rule-based transformations, integrating them with AutoML for fully automated ECF modelling while reducing human intervention. The performance of AutoEnergy was evaluated using eighteen diverse real-world energy consumption datasets spanning residential, commercial, industrial, and grid power domains. Through extensive benchmarking against baseline AutoML without FE and established FE methods, namely TSFresh (with TSEfficient and TSMinimal configurations) and FeatureTools (FT), AutoEnergy demonstrated significant improvements in both predictive accuracy and computational efficiency. AutoEnergy achieved forecasting error reductions of 19.52 % to 84.72 % compared to benchmarking methods, with strong performance on smaller datasets and statistical validation via Friedman and Wilcoxon tests. AutoEnergy demonstrated notable computational efficiency by running 1.31 and 4.41 times faster than FT and TSEff, respectively. Although 1.58 times slower than TSMin, AutoEnergy achieved 82.38 % lower forecasting errors. Integrating AutoEnergy with the state-of-the-art Tabular Prior Data Fitted Network (TabPFN) resulted in significant forecasting error reductions across test sets. These findings highlight AutoEnergy’s potential to improve AutoML performance while reducing reliance on domain expertise for FE, paving the way for fully automated ML pipelines in ECF applications.},
  archive      = {J_KBS},
  author       = {Nasser Alkhulaifi and Alexander L. Bowler and Direnc Pekaslan and Nicholas J. Watson and Isaac Triguero},
  doi          = {10.1016/j.knosys.2025.114300},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114300},
  shortjournal = {Knowl. Based Syst.},
  title        = {AutoEnergy: An automated feature engineering algorithm for energy consumption forecasting with AutoML},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAKEE: Multi-view attribute network and sequence embedding approach for predictive process monitoring. <em>KBS</em>, <em>329</em>, 114299. (<a href='https://doi.org/10.1016/j.knosys.2025.114299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive business process monitoring can help detect and solve problems on time by monitoring the execution of business processes in real time, thereby improving overall business efficiency and performance. Current deep learning-based studies have found that embedding structural information of process models helps neural networks learn the deep logic behind business processes. However, they mainly focus on the control-flow perspective, while other perspectives behind the business process, such as organizational structure, social network, and resource behavior, have been largely overlooked. To address this issue, this study proposes a multi-view learning prediction approach that integrates complementary information from both multiple attribute networks and sequences. We carefully design a deep learning model framework to integrate multi-view structural and sequential information for the next-activity prediction of the running trace. On the one hand, a simple and efficient process mining algorithm is designed to model multiple attribute network graphs, and a graph convolutional network is integrated to learn their multi-view structural information, helping understand the deep features of business scenarios. For this, a node feature enhancement method is proposed to integrate global information from historical business executions to help the proposed neural network understand the structure of a complete business scenario. On the other hand, we construct the feature representation of attribute sequences and integrate the Transformer to capture the dependency relations and sequential features within attribute sequences. Experimental evaluation of twelve real-life event logs shows that the proposed approach performs well in prediction accuracy and robustness.},
  archive      = {J_KBS},
  author       = {Binbin Chen and Shuangyao Zhao and Leilei Lin and Qiang Zhang},
  doi          = {10.1016/j.knosys.2025.114299},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114299},
  shortjournal = {Knowl. Based Syst.},
  title        = {MAKEE: Multi-view attribute network and sequence embedding approach for predictive process monitoring},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAGE-fend: Multimodal adaptive fusion with guidance from LLM expertise for fake news detection on short video platforms. <em>KBS</em>, <em>329</em>, 114298. (<a href='https://doi.org/10.1016/j.knosys.2025.114298'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of fake news on short-video social media platforms presents significant challenges to public awareness and social stability. While prior research has largely concentrated on text-image fake news, fake news in video format remains underexplored due to limited dataset availability and the complexities of multimodal analytical techniques. To bridge these gaps, we introduce TikCron , a large-scale, open-source dataset of short videos collected from Douyin (TikTok China). TikCron provides news videos and rich social context, specifically curated for studying pandemic-related misinformation in the health and political domains. Furthermore, we propose MAGE-fend (Multimodal Adaptive Fusion Guided by LLM Expertise), a novel framework that utilizes Large Language Models (LLMs) to extract high-level semantic information from images and provide inferential reasoning to enhance fake news detection. MAGE-fend integrates an adaptive attention-based fusion mechanism to dynamically integrate multiple modalities, effectively capturing cross-modal consistency and complementary cues. Comprehensive experiments conducted on the TikCron dataset and the publicly available FakeSV dataset demonstrate that MAGE-fend outperforms state-of-the-art methods in various evaluation metrics. This detection framework makes a substantial contribution to addressing potential future pandemic misinformation crises.},
  archive      = {J_KBS},
  author       = {Lingtong Hu and Zituo Wang and Jiayi Zhu and Yifan Hu and Xianbing Wang},
  doi          = {10.1016/j.knosys.2025.114298},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114298},
  shortjournal = {Knowl. Based Syst.},
  title        = {MAGE-fend: Multimodal adaptive fusion with guidance from LLM expertise for fake news detection on short video platforms},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trustworthy knowledge distillation via anchor-guided distribution learning. <em>KBS</em>, <em>329</em>, 114297. (<a href='https://doi.org/10.1016/j.knosys.2025.114297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing knowledge distillation methods typically do not adequately account for the representativeness of sampled training data or the adverse effects of missing classes within mini-batches, both of which can lead to suboptimal knowledge transfer. In this paper, we introduce A nchor-based K nowledge D istillation (AKD), a method that leverages the most informative and representative samples, referred to as anchors , during the transfer process, and matches the representation distribution of the data in the feature space rather than their actual representations. Anchors are strategically chosen based on their ability to encapsulate critical features of the data distribution, ensuring that the student model focuses on the most informative aspects of the teacher’s knowledge. The proposed method enables the introduction of information from a wider variety of classes at each mini-batch iteration, ensuring a more balanced data distribution and thereby improving the knowledge transfer process. Furthermore, by leveraging the static nature of anchors, we enhance the student model’s representation learning through attention maps, improving both convergence and generalization. The proposed approach is extensively evaluated across various datasets and tasks, demonstrating that the incorporation of anchors into the knowledge distillation process improving the accuracy and trustworthiness of the resulting models.},
  archive      = {J_KBS},
  author       = {Dimitrios Spanos and Nikolaos Passalis and Anastasios Tefas},
  doi          = {10.1016/j.knosys.2025.114297},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114297},
  shortjournal = {Knowl. Based Syst.},
  title        = {Trustworthy knowledge distillation via anchor-guided distribution learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative evaluation of machine learning models for predicting clad bead geometry in gas metal arc welding. <em>KBS</em>, <em>329</em>, 114296. (<a href='https://doi.org/10.1016/j.knosys.2025.114296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas metal arc welding (GMAW) is widely utilized for depositing corrosion-resistant austenitic stainless steel claddings on low-carbon steel substrates, where the bead geometry directly influences the structural integrity and service life of the component. The objective of this study is to develop a predictive framework for accurately estimating clad bead geometry parameters, namely bead width, penetration depth, reinforcement height, and percentage dilution, based on key GMAW process variables. To achieve this, five supervised machine learning (ML) models—linear regression (LR), K-Nearest Neighbors (KNN), decision tree (DT), random forest (RF), and support vector regression (SVR)— were trained on experimentally obtained datasets and evaluated using performance metrics including the R² score, the mean absolute error (MAE), the mean squared error (MSE), and the root mean squared error (RMSE). Among the models, the DT demonstrated the best predictive performance, achieving an R² score of 0.959, an MAE of 0.134, an MSE of 0.150, and an RMSE of 0.388. The SVR model also performed exceptionally well, with an R² score of 0.952. This study identified the welding gun angle and wire feed rate as the most influential parameters affecting clad bead geometry. The use of these advanced ML models considerably improves the prediction accuracy of clad bead dimensions in GMAW, enabling intelligent process optimization and consistent production of high-quality weld cladding.},
  archive      = {J_KBS},
  author       = {Kannan Thankappan and Jayaram Radhakrishnan Santhi and Thanammal Indu Vijayalakshmi},
  doi          = {10.1016/j.knosys.2025.114296},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114296},
  shortjournal = {Knowl. Based Syst.},
  title        = {Comparative evaluation of machine learning models for predicting clad bead geometry in gas metal arc welding},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified attacks to large language model watermarks: Spoofing and scrubbing in unauthorized knowledge distillation. <em>KBS</em>, <em>329</em>, 114295. (<a href='https://doi.org/10.1016/j.knosys.2025.114295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Watermarking has emerged as a critical technique for combating misinformation and protecting intellectual property in large language models (LLMs). A particularly promising property, known as watermark radioactivity, offers potential for preventing the unauthorized use of LLM outputs in downstream distillation pipelines. However, the robustness of watermarking against scrubbing attacks and its unforgeability under spoofing attacks in unauthorized knowledge distillation settings remain underexplored. Existing attack methods either assume access to model internals or fail to support both attack types simultaneously. In our work, we propose Contrastive Decoding-guided Knowledge Distillation ( CDG-KD ), a unified framework that enables dual-path attacks under unauthorized knowledge distillation. At the core of CDG-KD is a novel contrastive decoding mechanism with token-level constraint fusion, which integrates a learned watermark discriminator and probability-based constraint component to selectively manipulate watermark-relevant logits. This allows for fine-grained control of watermark strength during generation without compromising fluency or semantics. Our approach employs contrastive decoding to extract corrupted or amplified watermark texts via comparing outputs, followed by dual-path distillation to train new student models capable of watermark removal and watermark forgery, respectively. Extensive experiments show that CDG-KD effectively performs attacks while preserving the general performance of the distilled model. Our findings underscore critical need for developing watermarking schemes that are robust and unforgeable. Our code is available at https://github.com/xinykou/CDG-KD .},
  archive      = {J_KBS},
  author       = {Xin Yi and Yue Li and Shunfan Zheng and Linlin Wang and Xiaoling Wang and Liang He},
  doi          = {10.1016/j.knosys.2025.114295},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114295},
  shortjournal = {Knowl. Based Syst.},
  title        = {Unified attacks to large language model watermarks: Spoofing and scrubbing in unauthorized knowledge distillation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STP-net: Spatiotemporal graph neural network incorporating global brain functional network partitioning for driver fatigue monitoring. <em>KBS</em>, <em>329</em>, 114294. (<a href='https://doi.org/10.1016/j.knosys.2025.114294'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fatigue driving is a leading cause of traffic accidents, underscoring the critical need for effective driver fatigue monitoring to enhance road safety. Electroencephalogram (EEG) signals are widely considered as the gold standard for detecting fatigue. However, many existing methods struggle to comprehensively capture and integrate EEG features across multiple dimensions and scales, resulting in suboptimal monitoring performance. To address this challenge, we propose a spatiotemporal graph neural network with global brain functional network partitioning (STP-Net). STP-Net facilitates the comprehensive extraction and deep fusion of both short-term and long-term temporal features, along with global and local spatial features from EEG signals, producing rich hybrid representations that effectively capture the intrinsic dynamics of EEG activity. Evaluated on the public SEED-VLA dataset, STP-Net achieves superior performance, with an accuracy of 94.09 %, recall of 94.00 %, precision of 89.55 %, and an F1 score of 0.917, outperforming existing mainstream models. Ablation studies demonstrate that the spatiotemporal interaction module, which integrates graph convolutional networks and a transformer, plays a pivotal role in enhancing network performance. Additionally, interpretability analysis of the partitioned brain regions reveals that the perceptual–motor network shows the strongest correlation with fatigue. These results highlight STP-Net’s potential for accurate driver fatigue monitoring and its broader implications for enhancing driving safety.},
  archive      = {J_KBS},
  author       = {Jinglong Zhu and Qiang Liu and Hui Liu and Zeping Chen and Zhangzhen Zhao and Junchen Liao and Qing Li},
  doi          = {10.1016/j.knosys.2025.114294},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114294},
  shortjournal = {Knowl. Based Syst.},
  title        = {STP-net: Spatiotemporal graph neural network incorporating global brain functional network partitioning for driver fatigue monitoring},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated deep learning-based IRACE and convolutional neural networks for chest X-ray image classification. <em>KBS</em>, <em>329</em>, 114293. (<a href='https://doi.org/10.1016/j.knosys.2025.114293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When pre-trained models are applied directly to chest X-ray (CXR) images without appropriate adaptation, they frequently show problems like overfitting, limited generalization, or decreased SE to clinically relevant features because of the unique characteristics of medical data, such as class imbalance and domain-specific noise. Due to the discrepancy between natural image features (used during pre-training) and radiological image characteristics, studies have shown that such models may perform well on training data but poorly on unseen clinical samples. This study comprehensively evaluates the performance of the fine-tuning method using the Iterated Race for Automatic Algorithm Configuration (IRACE) technique on pre-trained models for several medical imaging CXRs. We select five well-known CNN architectures: MobileNet-v2, EfficientNet-b0, ResNet-50, DenseNet-121, and VGG-19, utilizing the IRACE technique for HPT classification of three CXR datasets. The experimental results indicate that the IRACE technique was generally effective across CXR images, producing noticeable improvements on all models. DenseNet-121 outperformed the other architectures across all metrics, achieving accuracies of 99.83 %, 99.98 %, and 99.87 % on the three CXR datasets, respectively. Additionally, we explored the model detection mechanism by interpreting the classification of radiological images using the Gradient-weighted Class Activation Mapping (Grad-CAM) with Layer-wise Relevance Propagation (LRP) approach for CXR imaging. The results obtained have provided information on how the model classifies CXR images, which can assist radiologists in identifying and evaluating visual characteristics.},
  archive      = {J_KBS},
  author       = {Nagwan Abdel Samee and Essam H. Houssein and Eman Saber and Gang Hu and Mingjing Wang},
  doi          = {10.1016/j.knosys.2025.114293},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114293},
  shortjournal = {Knowl. Based Syst.},
  title        = {Integrated deep learning-based IRACE and convolutional neural networks for chest X-ray image classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdaVAM: Adaptive variance-aware momentum for accelerating deep neural network training. <em>KBS</em>, <em>329</em>, 114292. (<a href='https://doi.org/10.1016/j.knosys.2025.114292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive optimization methods are fundamental to training deep neural networks, yet their effectiveness is often limited by noisy gradient estimates and unstable learning dynamics. To overcome these challenges, we introduce AdaVAM (Adaptive Variance-Aware Momentum), a novel optimizer that decouples gradient momentum from variance-based normalization. Unlike conventional approaches (e.g., Adam, Adan), AdaVAM employs a delayed variance term computed from historical gradients to dynamically normalize stochastic gradients. This design simultaneously reduces momentum bias and preserves robustness against gradient noise. Theoretically, we prove that AdaVAM attains an optimal O ( 1 / K ) convergence rate for non-convex objectives without requiring bounded gradient assumptions. Comprehensive experiments on image classification and language modeling benchmarks demonstrate that AdaVAM surpasses existing methods in both convergence speed and final task accuracy. By bridging theoretical guarantees with empirical efficacy, our work advances the development of reliable optimizers for deep learning. The PyTorch implementation is available at: https://github.com/xudp100/AdaVAM.git .},
  archive      = {J_KBS},
  author       = {Jinlan Liu and Wenhan Jiang and Xin Deng and Dongpo Xu},
  doi          = {10.1016/j.knosys.2025.114292},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114292},
  shortjournal = {Knowl. Based Syst.},
  title        = {AdaVAM: Adaptive variance-aware momentum for accelerating deep neural network training},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-typed multi-relational heterogeneous graph neural network model for complex networks. <em>KBS</em>, <em>329</em>, 114291. (<a href='https://doi.org/10.1016/j.knosys.2025.114291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networks are a prevalent relationship in real-world society, and the use of graphs and graph neural networks (GNNs) to model these networks and capture their characteristic relationships has shown tremendous development potential. Due to the inherent complexity of node and edge relationships within networks, heterogeneous graph neural networks (HGNNs) have become the preferred modeling approach. However, existing HGNNs primarily focus on heterogeneous graphs with only single relationships between nodes, which limits their ability to handle complex network graphs with multiple relational interactions. To effectively capture the complex node objects and multi-relational interactions in networks, this paper proposes a neural network model for multi-class multi-relational heterogeneous graphs (MMHGNN), consisting of three modules: structural feature encoding, weighted multi-relation path aggregation, and feature fusion. In the structural feature encoding module, MMHGNN employs the Four Color Theorem to color the graph and generates type encodings of edge relationships along paths, merging color features with path encodings to serve as structural features for different paths, thereby enhancing the distinguishability of nodes under complex relationships and structures. In the weighted multi-relation path aggregation module, MMHGNN aggregates neighbors along paths based on the number of edge relationships between nodes as weights and implements a balancing strategy to prevent excessive weights on long paths. In the feature fusion module, MMHGNN combines the structural features from the structural feature encoding with the embeddings from the relation aggregation module, leveraging a graph-level attention mechanism to fuse node features across different paths and generate the final node embeddings. Experiments conducted on real-world complex network datasets demonstrate the significant advantages of MMHGNN across multiple tasks.},
  archive      = {J_KBS},
  author       = {Yufei Zhao and Junyue Dong and Wenhao Wang and Hua Duan},
  doi          = {10.1016/j.knosys.2025.114291},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114291},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-typed multi-relational heterogeneous graph neural network model for complex networks},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SSGNN: Simple siamese graph neural networks for out-of-distribution generalization. <em>KBS</em>, <em>329</em>, 114290. (<a href='https://doi.org/10.1016/j.knosys.2025.114290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have proven effective for analyzing relational data in a variety of domains. Nevertheless, their performance tends to deteriorate significantly under distribution shifts between training and test datasets, presenting a central challenge for real-world machine learning applications. This work proposes the Simple Siamese Graph Neural Network (SSGNN), a Self-supervised Learning (SSL) method aimed at improving Out-of-Distribution (OOD) generalization in node classification tasks. In contrast to many existing SSL approaches that depend on data augmentation and the creation of positive and negative sample pairs, SSGNN adopts a simplified framework based on a Siamese GNN architecture with integrated dropout, thus avoiding the need for explicit pair generation. The method addresses common shortcomings in graph representation learning—particularly the tendency to capture spurious correlations—by introducing a three-stage training procedure utilizing dual Graph Convolutional Network (GCN) encoders with shared parameters. Furthermore, SSGNN incorporates a composite loss function whose components optimize node representation similarity, label prediction consistency, and overall prediction accuracy. Through this approach, SSGNN learns stable graph representations that demonstrate improved generalization across varying data distributions. Experimental results show that SSGNN outperforms existing methods and enhances generalization by reducing the GAP metric, which quantifies the relative performance difference between IID and OOD settings.},
  archive      = {J_KBS},
  author       = {Seyedeh Hamideh Erfani and Mohammad Javad Fadaeieslam and Reza Mortazavi and Mohammad Rahmanimanesh},
  doi          = {10.1016/j.knosys.2025.114290},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114290},
  shortjournal = {Knowl. Based Syst.},
  title        = {SSGNN: Simple siamese graph neural networks for out-of-distribution generalization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging out-of-distribution unlabeled images: Semi-supervised semantic segmentation with an open-vocabulary model. <em>KBS</em>, <em>329</em>, 114289. (<a href='https://doi.org/10.1016/j.knosys.2025.114289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semi-supervised semantic segmentation, existing studies have shown promising results in academic settings with controlled splits of benchmark datasets. However, the potential benefits of leveraging significantly larger sets of unlabeled images remain unexplored. In real-world scenarios, abundant unlabeled images are often available from online sources (web-scraped images) or large-scale datasets. However, these images may have different distributions from those of the target dataset, a situation known as out-of-distribution (OOD). Using these images as unlabeled data in semi-supervised learning can lead to inaccurate pseudo-labels, potentially misguiding network training. In this paper, we propose a new semi-supervised semantic segmentation framework with an open-vocabulary segmentation model (SemiOVS) to effectively utilize unlabeled OOD images. Extensive experiments on Pascal VOC and Context datasets demonstrate two key findings: (1) using additional unlabeled images improves the performance of semi-supervised learners in scenarios with few labels, and (2) using the open-vocabulary segmentation (OVS) model to pseudo-label OOD images leads to substantial performance gains. In particular, SemiOVS outperforms existing PrevMatch and SemiVL methods by +3.5 and +3.0 mIoU, respectively, on Pascal VOC with a 92-label setting, achieving state-of-the-art performance. These findings demonstrate that our approach effectively utilizes abundant unlabeled OOD images for semantic segmentation tasks. We hope this work can inspire future research and real-world applications. The code is available at https://github.com/wooseok-shin/SemiOVS .},
  archive      = {J_KBS},
  author       = {Wooseok Shin and Jisu Kang and Hyeonki Jeong and Jin Sob Kim and Sung Won Han},
  doi          = {10.1016/j.knosys.2025.114289},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114289},
  shortjournal = {Knowl. Based Syst.},
  title        = {Leveraging out-of-distribution unlabeled images: Semi-supervised semantic segmentation with an open-vocabulary model},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refining graph representation: Hyperbolic cross-space diffusion for hierarchical structure preservation. <em>KBS</em>, <em>329</em>, 114288. (<a href='https://doi.org/10.1016/j.knosys.2025.114288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has gained significant traction as an effective approach for learning representations across diverse domains. However, current methods confined to Euclidean space face a fundamental limitation: they struggle to preserve the complex topological structures inherent in hierarchical graph data. Existing graphical representation learning methods face three interrelated challenges. Specifically, embedding hierarchical graph structures into Euclidean space inevitably results in topological distortion. Conventional contrastive methods rely heavily on negative samples. In particular, the limited transformation capabilities restrict the model's ability to capture complex hierarchical relationships. To address these challenges, we propose the Hy perbolic Cro ss-space D iffusion ( HyCroD ), which seamlessly integrates hyperbolic geometric diffusion within a multi-scale contrastive learning architecture. It enhances information preservation through a dual-space augmentation strategy, where transformations are performed independently in both Euclidean and Hyperbolic spaces. By incorporating cross-grid and cross-view contrastive objectives alongside carefully designed spatial transformation modules, HyCroD effectively captures and preserves the rich hierarchical information present in graph data. Experiments across five benchmark datasets demonstrate improvements over state-of-the-art methods on node classification tasks. Our findings show that combining dual-space representation learning with self-supervised objectives effectively preserves hierarchical information in graph data, offering a promising direction for learning representations of complex multi-level structures.},
  archive      = {J_KBS},
  author       = {Zhirui Chen and Qiancheng Yu and Xiao Chen and Xuchu Jiang},
  doi          = {10.1016/j.knosys.2025.114288},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114288},
  shortjournal = {Knowl. Based Syst.},
  title        = {Refining graph representation: Hyperbolic cross-space diffusion for hierarchical structure preservation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized multimodal sentiment analysis under uncertain modalities missing via pretraining and online learning. <em>KBS</em>, <em>329</em>, 114287. (<a href='https://doi.org/10.1016/j.knosys.2025.114287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, multimodal sentiment analysis (MSA) for personalized users under uncertain modalities missing has become a new challenging problem. To address this issue, we propose a two-step idea. First, we propose an effective MSA model under uncertain modalities missing and train it with some public datasets, thus to enable the model to possess better preliminary MSA ability. Then, we make the pretrained model to continuously learn user’s personalized characteristics with online learning methods, thereby enable the model grow into a robust model for personalized MSA. Based on this idea, we propose a Personalized MSA model under uncertain modalities missing via Pretraining and Online Learning (termed as PMSAPO). For Personalized MSA under uncertain modalities missing, PMSAPO firstly generates the fused modality and allocate weights for each modality with a Fully Connected Neural Network Evaluation Module. Then, PMSAPO completes the final sentiment classification based on the fusion modality with a Joint feature optimization module. For the pretrained PMSAPO, we make it autonomously learn the personalized users via our proposed online learning techniques, including an online meta-learning method, a learning rate adaptive adjustment strategy, and a dynamic weight assignment strategy for sample data. Finally, based on three public benchmark datasets (IEMOCAP, MELD and CMU-MOSI), we conduct extensive experiments and prove that PMSAPO completely outperforms the Twelve state-of-the-art baseline models. (Code is available at https://github.com/SHX-AI/PMSAPO .)},
  archive      = {J_KBS},
  author       = {Hongxiang Sun and Zhizhong Liu and Dianhui Chu and Quan Z. Sheng and Zhaowei Liu and Jian Yu},
  doi          = {10.1016/j.knosys.2025.114287},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114287},
  shortjournal = {Knowl. Based Syst.},
  title        = {Personalized multimodal sentiment analysis under uncertain modalities missing via pretraining and online learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AGA: An adaptive group alignment framework for structured medical cross-modal representation learning. <em>KBS</em>, <em>329</em>, 114286. (<a href='https://doi.org/10.1016/j.knosys.2025.114286'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning medical visual representations directly from paired medical images and reports has emerged as a promising direction in representation learning. However, existing vision-language pretraining (VLP) methods in the medical domain often oversimplify clinical reports into single entities or fragmented tokens, overlooking their inherent structured nature. Moreover, contrastive learning paradigms typically rely on large quantities of hard negative samples, which poses challenges when dealing with small scale medical datasets. To address these issues, we propose Adaptive Grouped Alignment (AGA), a novel framework for learning structured information from paired medical images and reports. Specifically, we design a bidirectional grouping mechanism based on a sparse similarity matrix. Given an image-report pair, we first compute a fine-grained similarity matrix between each text token and each image patch. For each token, we select the top-matching patches to form a visual group, and conversely, for each patch, we select the most semantically related tokens to form a language group. To enable adaptive grouping, we introduce two threshold gating modules, Language-grouped Threshold Gate and Vision-grouped Threshold Gate, which dynamically learn similarity thresholds for group construction. The group representation corresponding to each token or patch is computed as a weighted average over the elements in its group, where the weights are given by their similarity scores. To align each token representation with its corresponding group representations, we propose an Instance-aware Group Alignment (IGA) loss, which operates solely within individual image-text pairs, eliminating the need for external negative samples and thereby alleviating the reliance on large scale hard negatives. Finally, we employ a Bidirectional Cross-modal Grouped Alignment (BCGA) module to facilitate fine-grained alignment between visual and linguistic group representations. Extensive experiments on both public and private datasets across various downstream tasks, including image-text retrieval and classification (in both fine-tuning and zero-shot settings), demonstrate the effectiveness of our proposed framework.},
  archive      = {J_KBS},
  author       = {Wei Li and Xun Gong and Jiao Li and Xiaobin Sun},
  doi          = {10.1016/j.knosys.2025.114286},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114286},
  shortjournal = {Knowl. Based Syst.},
  title        = {AGA: An adaptive group alignment framework for structured medical cross-modal representation learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CT-SSSA: Malicious traffic augmentation based on classifier transGAN and spatial-channel synergistic self-attention. <em>KBS</em>, <em>329</em>, 114285. (<a href='https://doi.org/10.1016/j.knosys.2025.114285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing number of network attacks poses serious challenges to device security and data privacy. As an important mean, malicious traffic detection method converts the raw traffic into intermediate representations (such as CSV format or gray-scale images) for feature analysis and protects network devices by identifying malicious traffic. These representations have following limitations: CSV format is difficult to capture the spatiotemporal correlations of traffic sequences, the single channel characteristics of gray-scale images result in the loss of multidimensional features. In addition, existing methods are prone to pattern collapse in imbalanced category scenarios. To solve these problems, this paper proposes a malicious traffic augmentation model called CT-SSSA based on the c lassifier T ransGAN and s patial-channel s ynergistic s elf- a ttention (SCSSA). Its innovations are reflected in: 1) We propose a key feature extraction method based on mutual information, it converts original traffic into RGB images and preserves multidimensional semantic features through three channel superposition; 2) We introduce the SCSSA mechanism into TransGAN to jointly capture the global context dependencies and local fine-grained features, thereby reducing the complexity of generator; 3) We design the auxiliary classifier and dynamic adaptive loss function to constrain the class consistency of generated samples, and alleviate the pattern collapse problem caused by class imbalance. Experiments on three publicly available datasets show that CT-SSSA achieves a 40.5 % and 88.35 % reduction in FID value and FPR compared to advanced baselines, and the accuracy, TPR and F1-score are improved by 1.01 %, 2.4 % and 13.85 %, respectively.},
  archive      = {J_KBS},
  author       = {Saihua Cai and Xingyu Zhao and Jinfu Chen and Yige Zhao and Junyi Chen and Lizhou Chen},
  doi          = {10.1016/j.knosys.2025.114285},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114285},
  shortjournal = {Knowl. Based Syst.},
  title        = {CT-SSSA: Malicious traffic augmentation based on classifier transGAN and spatial-channel synergistic self-attention},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust stock trend prediction via volatility detection and hierarchical multi-relational hypergraph attention. <em>KBS</em>, <em>329</em>, 114283. (<a href='https://doi.org/10.1016/j.knosys.2025.114283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock trend prediction is challenging due to the nonlinear dynamics of financial markets. Existing approaches often neglect extreme price fluctuations (outliers) and complex inter-stock relationships, limiting predictive performance. In this paper, we propose a novel framework integrating an abnormal volatility point detection mechanism with a multi-relational hypergraph hierarchical attention network. Specifically, we first employ a convolutional LSTM enhanced with an overnight gap price criterion to detect and down-weight abnormal price fluctuations, effectively reducing errors in stock temporal feature extraction. Second, we use temporal attention to emphasize influential historical time steps. Third, to model complex inter-stock dependencies, we construct a multi-relational hypergraph capturing both industry and supply-chain relations. Finally, we develop a hierarchical attention mechanism to adaptively weight stocks within relation groups (intra-hyperedge attention) and assess the relative importance of different relation types (inter-hypergraph attention). Extensive experiments on seven years of NYSE and NasdaqGS data show that our approach significantly outperforms state-of-the-art baselines in prediction accuracy and risk-return performance, demonstrating the effectiveness of capturing abnormal volatility and higher-order stock interactions.},
  archive      = {J_KBS},
  author       = {Suochao Yi and Jing Chi and Yandi Shi and Caiming Zhang},
  doi          = {10.1016/j.knosys.2025.114283},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114283},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust stock trend prediction via volatility detection and hierarchical multi-relational hypergraph attention},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced temporal graph neural network for predicting future citations on academic graphs: A dual clustering-driven and centrality-guided approach. <em>KBS</em>, <em>329</em>, 114282. (<a href='https://doi.org/10.1016/j.knosys.2025.114282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the volume of scientific publications grows, predicting the future citation counts of research papers is crucial for identifying influential studies and promising research directions. Existing graph neural network methods often rely solely on neighbor aggregation, which neglects the global heterogeneous nature of academic networks, thereby limiting their ability to fully capture the intricate relationships between different types of nodes and edges. This paper proposes a novel model, named C entrality-guided and D ual C lustering driven H eterogeneous G raph N etwork (CDCHGN) that addresses these limitations. CDCHGN captures both global and local structural dynamics of a dynamic academic graph using node centrality information, dual clustering techniques, and edge-type encoding to enrich semantic representation and effectively model heterogeneous relationships among various node types. Additionally, it incorporates time-injected attention to capture the temporal evolution of node features. Extensive experiments on real-world datasets demonstrate that our model achieves superior performance. Notably, on the APS dataset, CDCHGN achieves a 5.88 % improvement in Mean Absolute Log Error (MALE) and a 6.87 % improvement in Root Mean Squared Log Error (RMSLE) compared to the second-best models.},
  archive      = {J_KBS},
  author       = {Tianming Zhang and Junkai Fang and Xuanyu Chen and Zhengyi Yang and Bin Cao},
  doi          = {10.1016/j.knosys.2025.114282},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114282},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced temporal graph neural network for predicting future citations on academic graphs: A dual clustering-driven and centrality-guided approach},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Task assignment strategies for capacitated agents engaged in lifelong pickup and delivery tasks. <em>KBS</em>, <em>329</em>, 114281. (<a href='https://doi.org/10.1016/j.knosys.2025.114281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we tackled the task assignment problem in the capacity-enhanced version of Multi-Agent Pickup and Delivery (MAPD), a lifelong variant of the classical Multi-Agent Path Finding (MAPF) problem. Capacity-enhanced agents can carry multiple items, allowing them to operate several tasks simultaneously by visiting a sequence of pickup and delivery locations (i.e. waypoints) to fulfill their assignments. When determining the next task of the agent from the available options, a method encountered in the literature is to select the task with the nearest pickup location to the agent’s current location. In this research, we suggest that improving task assignments of capacitated agents can significantly enhance the solution quality of multi-agent route plans in lifelong pickup and delivery scenarios. We propose novel task assignment strategies that incorporate waypoints as a factor in the task selection process. We devised three groups of task assignment methods based on Closeness Centrality, Hausdorff Distance, and Cost Estimation within the context of the complete Token Passing with Multiple Capacity (TPMC) algorithm. We evaluated the methods in small and large-scale automated warehouse simulations, assessing their effectiveness in terms of makespan against the contemporary task selection method and one another. As a result of our experiments, the Closeness Centrality class of heuristics failed to enhance solution quality in large majority of cases. The Average Hausdorff Distance heuristic achieved good outcomes in scenarios with higher capacity agents. The Cost-Based Estimation method demonstrated significant improvements across all scenarios.},
  archive      = {J_KBS},
  author       = {Evren Çilden and Faruk Polat},
  doi          = {10.1016/j.knosys.2025.114281},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114281},
  shortjournal = {Knowl. Based Syst.},
  title        = {Task assignment strategies for capacitated agents engaged in lifelong pickup and delivery tasks},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). You only need haze: Bidirectional disentangled translation network for unsupervised image dehazing. <em>KBS</em>, <em>329</em>, 114279. (<a href='https://doi.org/10.1016/j.knosys.2025.114279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, learning-based methods have achieved notable progress in image dehazing through supervised training on synthetically paired datasets. However, the substantial domain gap between synthetic and real-world hazy images often impairs generalization performance, thereby limiting their effectiveness in practical applications where target domains differ significantly from the training data. Even worse, acquiring sufficient pixel-aligned hazy-clear image pairs in real-world scenarios is costly and challenging. To this end, we introduce a novel Bidirectional Disentangled Translation Network (BDT-Net) for unsupervised dehazing, which regards haze removal as a feature disentanglement task, i.e., separating content-relevant information from the clean factor and haze-related information from the fuzzy factor. Specifically, we design a dual-branch disentanglement framework comprising a Content Recovery Branch (CRB) for extracting structural content information and a Parameter Estimation Branch (PEB) dedicated to capturing haze-related characteristics. Among them, we leverage forward dehazing and reverse rehazing physics-based models to establish haze cycle consistency, thus our BDT-Net can be optimized only needing the hazy image itself. To better distinguish the haze information from the clean content in the latent space, we design an effective Feature-wise Contrastive Representation (FCR), which can not only consider the inherent self-similarity within each information flow but also exploit the mutual exclusivity between different components. Furthermore, a two-way Pixel-wise Contrastive Representation (PCR) is incorporated to enhance the capability of restoring clear image clarity and content. Extensive experimental results on benchmark datasets demonstrate the superiority of our BDT-Net over other compared state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Weichao Yi and Liquan Dong and Ming Liu and Lingqin Kong and Yue Yang and Xuhong Chu and Yuejin Zhao},
  doi          = {10.1016/j.knosys.2025.114279},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114279},
  shortjournal = {Knowl. Based Syst.},
  title        = {You only need haze: Bidirectional disentangled translation network for unsupervised image dehazing},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAFNet: Circular attention fusion for medical image segmentation. <em>KBS</em>, <em>329</em>, 114277. (<a href='https://doi.org/10.1016/j.knosys.2025.114277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of medical images is crucial for clinical diagnosis and treatment planning. Recently, Transformers have demonstrated promising performance in medical image segmentation tasks, yet the quadratic complexity of the attention mechanism presents difficulties. Various methods attempt to reduce this complexity by constraining the range of attention to local regions, thereby improving efficiency. However, these methods often result in receptive fields that are not large enough, leading to insufficient context modeling. To address this issue, we propose an attention mechanism called Circular Attention (CA), which confines the attention region within a circular window through polar coordinate transformation, and apply it to the Circular Attention Fusion (CAF) module for feature fusion. CAF integrates feature information from both CNNs and Transformers to improve the accuracy of medical image segmentation. The CAF module consists of a circular attention block, a multi-scale convolution module, and a residual block with deep convolution. Furthermore, adjusting the radius and edge width of the circular attention in various CAFs allows CAFNet to perform multi-scale feature fusion by covering different regions during the fusion process. The proposed method achieves state-of-the-art segmentation performance on multiple datasets. The code is available at: https://github.com/EchoSixHIYA/CAFNet},
  archive      = {J_KBS},
  author       = {Xudong Wu and Baohua Yuan and Ning Li and Lin Shi and Mingjie Jiang and Juxiao Zhang and Rui Tang and Qile Qin and Jin Ma and Shoukun Xu},
  doi          = {10.1016/j.knosys.2025.114277},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114277},
  shortjournal = {Knowl. Based Syst.},
  title        = {CAFNet: Circular attention fusion for medical image segmentation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KDDA-balance: Knowledge-driven domain adaptation with correlated gait information for elderly balance assessment. <em>KBS</em>, <em>329</em>, 114276. (<a href='https://doi.org/10.1016/j.knosys.2025.114276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decline in balance function is a major contributor to falls among older adults. Assessing balance function can facilitate early detection of potential issues, and reduce the risk of falls and related injuries. However, a significant challenge is the lack of sufficient data on older adults, which leads to poor model evaluation performance and limits its application in daily life. To address this issue, we propose KDDA, a knowledge-driven semi-supervised domain adaptation method that leverages relevant gait information to improve balance assessment across age domains.The KDDA-Balance model incorporates multidimensional features through a gait knowledge computation module to enrich the feature space. A domain adversarial module with dual classifiers is used to reduce feature discrepancies between the target and source domains. Additionally, an alternative loss function integrates the dual classifier module with a multi-source domain adaptation module, further improving evaluation performance in the target domain. Extensive experiments on the Falling Risk Assessment (FRA) dataset and the Impaired Gait Ground Reaction Force (GaitRec) dataset demonstrate the superiority of our proposed model. On the FRA dataset, KDDA-Balance achieved an evaluation accuracy of 90.07 %, representing an average improvement of 7.83 %. On the GaitRec dataset, the model reached an evaluation accuracy of 83.02 %, with an average accuracy gain of 5.46 %. These results validate the effectiveness of KDDA-Balance in cross-domain evaluation, providing a novel approach for assessing fall risk among older adults.},
  archive      = {J_KBS},
  author       = {Zhaoyang Ge and Shujie Huang and Huiqing Cheng and Jingzhe Ma and Zhuang Tong and Liying Zhang and Mingliang Xu},
  doi          = {10.1016/j.knosys.2025.114276},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114276},
  shortjournal = {Knowl. Based Syst.},
  title        = {KDDA-balance: Knowledge-driven domain adaptation with correlated gait information for elderly balance assessment},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MMGCL: Multi-scale and multi-channel graph contrastive learning for flight anomaly detection. <em>KBS</em>, <em>329</em>, 114275. (<a href='https://doi.org/10.1016/j.knosys.2025.114275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With commercial air traffic’s increasing complexity, intelligent flight anomaly detection becomes crucial in ensuring flight safety. Existing solutions usually aggregate multiple sensor records of one flight to a flat and indivisible atomic sample to be classified. It is hard for them to incorporate outer information from similar flights and identify inner mechanisms between sensors. However, the degree of deviation from similar normal flights can evaluate the flight risks, and the modeling of sensors can reveal where the risk comes from. To this end, we propose MMGCL, a flight anomaly detection model based on m ulti-scale and m ulti-channel g raph c ontrastive l earning. MMGCL first constructs two types of graphs regarding flight similarity and sensor correlations to model the relations between flights and sensors, respectively. Then, multi-channel contrastive learning is proposed to differentiate normal and abnormal flights from different sensor aspects, where each type of sensor is related to one channel and has one normal center. The learnable representations of sensors are further applied to train a classifier judging the risk score. Finally, the risk score and the distances of sensors from their normal centers are combined to determine whether the flight is abnormal. Extensive experiments validate that our model outperforms the compared ones and has good interpretability of identified anomalies. Our code is publicly available at: anonymous.4open.science/r/MMGCL-6768 .},
  archive      = {J_KBS},
  author       = {Nengjun Zhu and Yuqiang Ren and Yu Liu and Hang Yu and Xinzhi Wang and Xiangfeng Luo},
  doi          = {10.1016/j.knosys.2025.114275},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114275},
  shortjournal = {Knowl. Based Syst.},
  title        = {MMGCL: Multi-scale and multi-channel graph contrastive learning for flight anomaly detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust unsupervised method for outlier set detection. <em>KBS</em>, <em>329</em>, 114274. (<a href='https://doi.org/10.1016/j.knosys.2025.114274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a robust method that identifies sets of points that collectively deviate from typical patterns in a dataset, which it calls “outlier sets”, while excluding individual points from detection. This new methodology, Outlier Set Two-step Identification (OSTI) employs a two-step approach to detect and label these outlier sets. First, it uses Gaussian Mixture Models for probabilistic clustering, identifying candidate outlier sets based on cluster weights below a hyperparameter threshold. Second, OSTI measures the Inter-cluster Mahalanobis distance between each candidate outlier set’s centroid and the overall dataset mean. OSTI then tests the null hypothesis that this distance does not significantly differ from its theoretical chi-square distribution, enabling the formal detection of outlier sets. We test OSTI systematically on 8000 synthetic 2D datasets across various inlier configurations and thousands of possible outlier set characteristics. Results show OSTI robustly and consistently detects outlier sets with an average F1 score of 0.92 and an average purity (the degree to which outlier sets identified correspond to those generated synthetically, i.e., our ground truth) of 98.58 %. We also compare OSTI with state-of-the-art outlier detection methods, to illuminate how OSTI fills a gap as a tool for the exclusive detection of outlier sets.},
  archive      = {J_KBS},
  author       = {Amal Sarfraz and Abigail Birnbaum and Flannery Dolan and Jonathan Lamontagne and Lyudmila Mihaylova and Charles Rougé},
  doi          = {10.1016/j.knosys.2025.114274},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114274},
  shortjournal = {Knowl. Based Syst.},
  title        = {A robust unsupervised method for outlier set detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel loan eligibility prediction model with effective use of data transformation methods. <em>KBS</em>, <em>329</em>, 114272. (<a href='https://doi.org/10.1016/j.knosys.2025.114272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A loan eligibility prediction model (LEP) determines the eligibility of an applicant for a loan based on the applicant’s data. A novel loan eligibility prediction model has been presented in this research work. To improve the prediction performance, we experimented with several data transformation (DT) methods on the data before feeding it to machine learning models. At the end, we chose the adaptive Weight-of-Evidence (aWOE) DT method, which preserves data privacy. Before applying DT, we preprocessed the data (e.g., cleaning, missing value replacement, categorical encoding) to ensure data quality. To mitigate feature redundancy, Pearson correlation was applied. In order to select the most relevant features from the datasets, the Chi-square feature selection technique was employed. Additionally, the Grid Search method was used to identify the optimal hyperparameters for the classifiers. The experiments have been carried out on seven publicly available datasets. Subsequently, the proposed models were evaluated based on standard evaluation metrics. We also conducted a non-parametric statistical test to examine the statistical significance of our results. Our experimental analysis and statistical tests reveal that the proposed aWOE based approach outperforms its counterparts. The privacy assessment demonstrates that the aWOE based model preserves data privacy. To explain our model, we conducted a SHAP analysis, which demonstrated that aWOE prioritizes features which are more aligned with loan eligibility in practice. Our proposed methodology enhanced the prediction performance by as much as 6.3 % and 3.8 % in terms of accuracy and F-measure, respectively. Moreover, the proposed methodology achieved 100 % prediction performance on two datasets across all evaluation metrics. Through comprehensive experimental analysis, the merits of data transformation methods in conjunction with feature selection and optimal hyperparameters have been illustrated for loan eligibility prediction in the context of the lending industry.},
  archive      = {J_KBS},
  author       = {Joydeb Kumar Sana and M. Sohel Rahman and M. Saifur Rahman},
  doi          = {10.1016/j.knosys.2025.114272},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114272},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel loan eligibility prediction model with effective use of data transformation methods},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel framework for effective phishing URL detection using an LSTM-based siamese network. <em>KBS</em>, <em>329</em>, 114271. (<a href='https://doi.org/10.1016/j.knosys.2025.114271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting phishing attacks in the era of generative AI presents a significant challenge due to the increasing sophistication of AI-generated phishing schemes. Neural network-driven approaches, including deep learning-based detection techniques, face notable limitations such as vulnerability to adversarial perturbations, reliance on large labeled datasets, poor generalization to novel attack patterns, and an over-dependence on shallow lexical features that fail to capture deeper semantic patterns. To address these limitations, we propose a pioneering approach leveraging a Siamese network that integrates twin LSTM subnetworks with shared weights, transforming URL sequences into robust feature representations. The Siamese Network effectively distinguishes between phishing and legitimate URLs by comparing the latent representations of URL pairs. Central to this approach is a specially curated pairwise dataset of phishing and legitimate URLs meticulously designed to facilitate fine-grained similarity analysis. This paired dataset enables the model to capture subtle distinctions between the two URL classes. Rigorous evaluation, including a dedicated test set of traditional and AI-generated URLs, demonstrates the model’s robust generalization capability. This innovative twin LSTM-based framework sets a new benchmark in phishing detection, providing a scalable, adaptive solution to combat increasingly sophisticated attacks.},
  archive      = {J_KBS},
  author       = {Sruthi K and Manohar Naik S},
  doi          = {10.1016/j.knosys.2025.114271},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114271},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel framework for effective phishing URL detection using an LSTM-based siamese network},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Style mamba-transformer: A hybrid mamba-transformer unsupervised framework for text style transfer. <em>KBS</em>, <em>329</em>, 114270. (<a href='https://doi.org/10.1016/j.knosys.2025.114270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-style transfer aims to rewrite source texts into a target style while preserving their core content. However, challenges such as the lack of parallel training data and the difficulty in balancing style transfer with content preservation remain significant. To address these issues, we propose a novel unsupervised text-style transfer framework, the Style Mamba Transformer, based on the adversarial generative network (GAN) architecture. This framework includes a hybrid encoder that combines Transformer and Mamba blocks, leverages skip connections to enhance feature reuse, and focuses on the style intensity of individual tokens. This design enables high-precision style transfer while preserving the text content. Our model outperforms other similar style-transfer models, such as MSSRNet, in terms of both style transfer accuracy and content preservation. On two benchmark datasets, the Yelp Review Dataset and IMDb Movie Review Dataset, our model achieved a transfer accuracy of 97.5 % and a BLEU score of 59.3, as well as a transfer accuracy of 95.1 % and a BLEU score of 64.2, respectively.},
  archive      = {J_KBS},
  author       = {Deyu Meng and Ziheng Wang and Wenhao Yan and Tshewang Phuntsho and Tad Gonsalves},
  doi          = {10.1016/j.knosys.2025.114270},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114270},
  shortjournal = {Knowl. Based Syst.},
  title        = {Style mamba-transformer: A hybrid mamba-transformer unsupervised framework for text style transfer},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-based anomaly representation enhancement on graphs. <em>KBS</em>, <em>329</em>, 114268. (<a href='https://doi.org/10.1016/j.knosys.2025.114268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection is significantly challenged by information loss during graph embedding, label scarcity, and intricate structural patterns. While graph neural networks (GNNs) have advanced the field, their efficacy is often limited by sensitivity to data quality and oversmoothing. This paper introduces DARE-G, a novel diffusion-based anomaly detection framework that leverages conditional and unconditional diffusion models to mitigate these limitations. Our approach features a dual-phase diffusion process: conditional anomaly augmentation to synthesize realistic anomalous patterns, and unconditional graph denoising to alleviate information loss and enhance the distinction between normal and anomalous node representations. Extensive experiments on both synthetic and real-world datasets demonstrate DARE-G’s significant superiority over state-of-the-art methods, achieving an 8.76 percentage point increase in AUC-ROC compared to the best-performing baselines. Ablation studies further validate the framework’s robustness across various GNN backbones, highlighting the critical role of denoising steps in capturing multi-hop structural anomalies. The proposed method establishes new benchmarks for graph anomaly detection, particularly in scenarios with extreme label sparsity and adversarial camouflage.},
  archive      = {J_KBS},
  author       = {Jian Zhang and Yitong Li and Zhen Wang},
  doi          = {10.1016/j.knosys.2025.114268},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114268},
  shortjournal = {Knowl. Based Syst.},
  title        = {Diffusion-based anomaly representation enhancement on graphs},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OTMA: Optimal transfer modality alignment for visible-thermal person re-identification. <em>KBS</em>, <em>329</em>, 114267. (<a href='https://doi.org/10.1016/j.knosys.2025.114267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible thermal person re-identification (VT-ReID) is a crucial task in real-world surveillance systems, primarily challenged by significant cross-modality discrepancies and intra-class variations. While numerous methodologies have been developed to address this issue by optimizing instance similarity across modalities, they often overlook the impact of intra-class variations on cross-modality alignment. To handle this issue, we propose Optimal Transfer Modality Alignment (OTMA), a method designed to mitigate the impact of intra-class variations during cross-modality alignment. Specifically, OTMA utilizes the Earth Mover’s Distance (EMD) to establish an initial transfer strategy between the two modalities. To avoid the unintended alignment of cross-modality negative pairs, OTMA further refines the EMD-based transfer weights by suppressing excessively high weights assigned to negative pairs and enhancing insufficient weights of positive pairs. In this manner, OTMA mitigates the adverse effects of intra-class variations during modality alignment and reduces the risk of aligning cross-modality negative pairs, thereby achieving a better balance between alignment and discriminative optimization. Additionally, two complementary techniques are introduced to further enhance the effectiveness of OTMA. First, Cross-Modality Discrimination Learning (CM-DL) is proposed to alleviate the degradation of feature discrimination caused by OTMA by regulating the variance ratio between intra-class and inter-class distributions. Second, a Multi-Granularity Structure (MGS) is designed to facilitate modality alignment at both coarse and fine levels, enabling OTMA to capture more comprehensive cross-modality correspondences. Extensive experiments conducted on two datasets demonstrate the effectiveness and advantages of the proposed OTMA method, along with its supplementary techniques, in significantly improving cross-modality matching performance.},
  archive      = {J_KBS},
  author       = {Yongguo Ling and Zihao Hu and Gangzhu Lin and Shaozi Li and Min Jiang},
  doi          = {10.1016/j.knosys.2025.114267},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114267},
  shortjournal = {Knowl. Based Syst.},
  title        = {OTMA: Optimal transfer modality alignment for visible-thermal person re-identification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain pedestrian trajectory prediction via behavioral pattern-aware multi-instance GCN. <em>KBS</em>, <em>329</em>, 114266. (<a href='https://doi.org/10.1016/j.knosys.2025.114266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain pedestrian trajectory prediction is crucial in fields such as autonomous driving, robotics and video surveillance. Due to the inherent diversity and uncertainty of pedestrian trajectories, they exhibit various behavioral patterns. However, most existing cross-domain methods neglect these behavioral differences by employing a unified network with shared parameters, modeling all trajectories in the same manner. This often results in biased knowledge transfer and reduced prediction accuracy. To address this, a model based on behavioral pattern-aware multi-instance graph convolutional networks, called PMITra, is proposed for cross-domain pedestrian trajectory prediction. PMITra consists of three core modules. The trajectory embedding module uses a pretrained micro-model to extract spatiotemporal features from trajectories. The pattern-aware interaction module extracts and aggregates behavioral patterns through deep clustering, and employs a multi-instance graph convolutional network to enable fine-grained knowledge transfer among trajectories exhibiting the same behavioral patterns. The pattern alignment module constructs an attention-based pattern loss to align the pedestrian feature representations weighted by pattern probabilities. PMITra achieves state-of-the-art performance on the ETH/UCY pedestrian trajectory datasets, with comprehensive ablation studies validating the effectiveness of each module.},
  archive      = {J_KBS},
  author       = {Haifeng Yang and Yi Chen and Jianghui Cai and Yuqing Yang and Lichan Zhou and Jianing Tian and Yan Li and Yaling Xun and Xujun Zhao},
  doi          = {10.1016/j.knosys.2025.114266},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114266},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-domain pedestrian trajectory prediction via behavioral pattern-aware multi-instance GCN},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFOcc: Enhanced 3D occupancy perception based on scene flow and class-guided sampling. <em>KBS</em>, <em>329</em>, 114265. (<a href='https://doi.org/10.1016/j.knosys.2025.114265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving relies on high-precision 3D perception. Multi-camera 3D object detection is limited by long-tail distribution issues, making it difficult to comprehensively recognize all object categories. In contrast, 3D occupancy prediction unifies the perception of foreground and background by partitioning the 3D space into semantically labeled voxel grids, thereby providing more effective support for driving safety. This paper proposes an innovative panoramic semantic occupancy perception model, DFOcc, designed to enhance the 3D scene understanding capability of autonomous driving systems. DFOcc takes multi-camera images as input and first constructs a 3D voxel feature space through multi-scale feature extraction and the Lift-Splat-Shoot (LSS) method. It then employs an occupancy decoder to predict the occupancy state of each voxel in the scene. To further improve perception accuracy and computational efficiency, ELANet is adopted as the backbone network to enhance 2D visual feature extraction and accelerate model training. Additionally, an improved class-guided sampling strategy combined with the Focal Loss function is proposed to alleviate class imbalance issues, thereby enhancing detection performance for sparse objects and low-frequency categories. Furthermore, an automatic annotation method based on scene flow estimation is introduced, which generates high-quality dense occupancy labels and velocity ground truth labels, eliminating the reliance on 3D bounding box annotations and significantly reducing data construction costs. Experimental results on the nuScenes dataset demonstrate that DFOcc achieves significant improvements in both accuracy and generalization for 3D occupancy perception. Compared to the recently proposed TPVFormer and OccFormer models, DFOcc improves the mean Intersection over Union (mIoU) by 2.1 and 0.9, respectively, and attains performance comparable to state-of-the-art LiDAR-based methods.},
  archive      = {J_KBS},
  author       = {Ruijie Shan and Yanchun Zhang and Jian Zeng},
  doi          = {10.1016/j.knosys.2025.114265},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114265},
  shortjournal = {Knowl. Based Syst.},
  title        = {DFOcc: Enhanced 3D occupancy perception based on scene flow and class-guided sampling},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CogniAlign: Word-level multimodal speech alignment with gated cross-attention for alzheimer’s detection. <em>KBS</em>, <em>329</em>, 114264. (<a href='https://doi.org/10.1016/j.knosys.2025.114264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection of cognitive disorders such as Alzheimer’s disease is critical for enabling timely clinical intervention and improving patient outcomes. In this work, we introduce CogniAlign, a multimodal architecture for Alzheimer’s detection that integrates audio and textual modalities, two non-intrusive sources of information that offer complementary insights into cognitive health. Unlike prior approaches that fuse modalities at a coarse level, CogniAlign leverages a word-level temporal alignment strategy that synchronizes audio embeddings with corresponding textual tokens based on transcription timestamps. This alignment supports the development of token-level fusion techniques, enabling more precise cross-modal interactions. To fully exploit this alignment, we propose a Gated Cross-Attention Fusion mechanism, where audio features attend over textual representations, guided by the superior unimodal performance of the text modality. In addition, we incorporate prosodic cues, specifically interword pauses, by inserting pause tokens into the text and generating audio embeddings for silent intervals, further enriching both streams. We evaluate CogniAlign on the ADReSSo dataset, where it achieves an accuracy of 87.35 % over a Leave-One-Subject-Out setup and of 90.36 % over a 5 fold Cross-Validation, outperforming existing state-of-the-art methods. A detailed ablation study confirms the advantages of our alignment strategy, attention-based fusion, and prosodic modeling. Finally, we perform a corpus analysis to assess the impact of the proposed prosodic features and apply Integrated Gradients to identify the most influential input segments used by the model in predicting cognitive health outcomes.},
  archive      = {J_KBS},
  author       = {David Ortiz-Perez and Manuel Benavent-Lledo and Javier Rodriguez-Juan and Jose Garcia-Rodriguez and David Tomás},
  doi          = {10.1016/j.knosys.2025.114264},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114264},
  shortjournal = {Knowl. Based Syst.},
  title        = {CogniAlign: Word-level multimodal speech alignment with gated cross-attention for alzheimer’s detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BiMT-TCN: A cutting-edge hybrid model for enhanced stock price prediction. <em>KBS</em>, <em>329</em>, 114263. (<a href='https://doi.org/10.1016/j.knosys.2025.114263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the face of the rapid evolution and escalating complexity of financial markets, precise stock price prediction has become a critical area of research for scholars and practitioners alike. Stock markets are subject to a vast array of influencing factors, both internal and external, which complicates prediction efforts. This study proposes BiMT-TCN, a novel model combining Bidirectional Long Short-Term Memory (BiLSTM), a modified Transformer, and Temporal Convolutional Network (TCN), aimed at enhancing the accuracy and stability in stock price prediction. BiLSTM facilitates the capture of bidirectional dependencies, which aids in decoding the intricate patterns within time-series data. The modified Transformer integrates global information, enhancing the model’s capacity to manage long-range dependencies effectively. TCN, known for its parallel processing and proficiency in capturing deep historical patterns, further bolsters model stability and generalizability. Empirical evaluations on major indices such as SSE, HSI, and NASDAQ demonstrate that BiMT-TCN consistently outperforms state-of-the-art models, achieving R 2 scores of 0.9779, 0.9776, and 0.9969 respectively, along with significantly lower RMSE, MAE, and MAPE values. The implications of this work extend to practical investment decision-making, where improved forecast precision can enhance risk management, optimize trading strategies, and inform financial planning in volatile markets.},
  archive      = {J_KBS},
  author       = {Guangyang Tian and Tingwen Huang and Chengyu Peng and Yin Yang and Shiping Wen},
  doi          = {10.1016/j.knosys.2025.114263},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114263},
  shortjournal = {Knowl. Based Syst.},
  title        = {BiMT-TCN: A cutting-edge hybrid model for enhanced stock price prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cardiac disease detection utilizing temporal attention recurrent graph convolutional neural network based smart wearable system. <em>KBS</em>, <em>329</em>, 114261. (<a href='https://doi.org/10.1016/j.knosys.2025.114261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of people affected by cardiac diseases is increasing extremely. Heart attacks are most common and painful disease. According to the World Health Organization, this disease kills around 17.5 million people each year. In this paper, Cardiac Disease Detection using Temporal Attention Recurrent Graph Convolutional Neural Network based Smart Wearable System (CDD-SWS-TRGCNN) is proposed. The proposed method uses to monitor and signal a patient's current heart status based on necessary heart diagnosis signal. Initially, input data are collected from cardiovascular disease dataset and cardio health risk assessment dataset. The collected dataset are pre-processed with the nonlinear adaptive backscatter filter (NABF) is employed for normalizing the data. After preprocessing, the Lifted Euler Characteristic Transform (LECT) is used to extract statistical features like Mean, Standard Deviation, Kurtosis, Skewness, entropy. These features are then used by TARGCNN for classifying cardiac disease as cardiac and healthy in the cardiovascular disease dataset and presence and absence in the cardio health risk assessment dataset. To enhance accuracy, the Wolf-Bird Optimizer (WBO) is utilized to optimize TARGCNN parameters, ensuring precise cardiac disease classification. The proposed CDD-SWS-TRGCNN method is implemented in Python. The proposed method achieves 23.11%, 24.96%, 25.23% higher accuracy; 31.10%, 33.02% and 29.98% higher precision when compared with existing techniques like SWS-CAM-RFA, PHD-WD-CNN, and WMD-HDD-IoT respectively.},
  archive      = {J_KBS},
  author       = {Mr Jibin E P ( Research Scholar ) and Dr Menaka D ( Associate Professor )},
  doi          = {10.1016/j.knosys.2025.114261},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114261},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cardiac disease detection utilizing temporal attention recurrent graph convolutional neural network based smart wearable system},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DM3diff: A novel multi-center, multi-modality and multi-source medical image segmentation framework based on DWT embeded diffusion model. <em>KBS</em>, <em>329</em>, 114260. (<a href='https://doi.org/10.1016/j.knosys.2025.114260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of medical images from multi-center, multi-modality, and multi-source datasets (3M Datasets) is critical for clinical applications such as diagnosis and image-guided intervention. However, existing models often struggle with image heterogeneity, blurry boundaries, and low contrast, which severely affect segmentation accuracy. Diffusion Probabilistic Models (DPMs) have shown promise in modeling complex data distributions and capturing fine-grained structures. Yet, their generalization capability and detail recovery remain limited when applied to 3M Datasets. To address these challenges, we propose D M 3 diff, a novel medical image segmentation framework that integrates Discrete Wavelet Transform (DWT) with DPMs. Specifically, we introduce a Self-adaptive Wavelet Transform Feature Aggregation Module (SWT-FAM) to serve as a high-pass filter that preserves high-frequency details while suppressing noise and redundancy. Furthermore, we design a Multi-Stage Detail Control Block (MS-DCB) that utilizes Kullback-Leibler divergence to align the distributions of generated and target images, enabling multi-scale control of structure and detail during the denoising process. We evaluate our method on three benchmark anatomical datasets. D M 3 diff achieves consistent improvements over state-of-the-art methods, with Dice scores reaching up to 92.4 % on ISIC, and notable gains in IOU, sensitivity, and Hausdorff distance across all datasets.},
  archive      = {J_KBS},
  author       = {Dong Sui and Xiao Tian and Yacong Li and Maozu Guo and Xiangyu Li and Kuanquan Wang and Gongning Luo},
  doi          = {10.1016/j.knosys.2025.114260},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114260},
  shortjournal = {Knowl. Based Syst.},
  title        = {DM3diff: A novel multi-center, multi-modality and multi-source medical image segmentation framework based on DWT embeded diffusion model},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lag selection in feature-based clustering of time series. <em>KBS</em>, <em>329</em>, 114258. (<a href='https://doi.org/10.1016/j.knosys.2025.114258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature-based time series clustering methods typically involve extracting vectors of statistical quantities that capture the serial dependence structure of each time series in the dataset. These feature vectors are then used as input to a standard clustering algorithm. In the feature extraction step, the user usually selects a set of lags of interest in advance, a choice that can significantly affect clustering accuracy. This article addresses this limitation by introducing a natural approach in which the set of lags is automatically selected as part of the clustering optimization process. The effectiveness of the proposed methodology is demonstrated through simulations and real data applications.},
  archive      = {J_KBS},
  author       = {Ángel López-Oriona and Ying Sun},
  doi          = {10.1016/j.knosys.2025.114258},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114258},
  shortjournal = {Knowl. Based Syst.},
  title        = {Lag selection in feature-based clustering of time series},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel model to deal with ambiguous and complex time series: Application to sunspots forecasting. <em>KBS</em>, <em>329</em>, 114257. (<a href='https://doi.org/10.1016/j.knosys.2025.114257'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sunspots, the dark patches observed on the surface of the Sun, exhibit cyclical behavior with significant implications for various terrestrial phenomena. Forecasting sunspots accurately is crucial for understanding solar activity and its impact on Earth’s climate and technology-dependent systems. In this study, we propose a novel approach for sunspots forecasting utilizing ambiguous set theory. Using ambiguous set theory, a time series forecasting model is proposed, called ambiguous time series forecasting model (ATSFM) . We begin by collecting historical sunspots spanning from 1700 to 2023. Next, apply ATSFM, which incorporates the ambiguity inherent in sunspots. The ATSFM begins with the partitioning the sunspots with equal-length intervals. For this purpose, this study employs Riemann integration that assists for partitioning the universe of discourse of the sunspots into various equal-length intervals. Then, ambiguous entropy (AE) is calculated for each of the distributed sunspots in equal-length intervals. Ambiguous entropy relationships (AERs) and ambiguous entropy relationship groups (AERGs) are formulated to describe the relationships between previous and current sunspots. Finally, unambiguousness process is applied to obtain forecasted values from the AERGs. To evaluate the ATSFM’s performance, we compare its forecasting accuracy with existing methods, including traditional statistical and machine learning methods. Various statistical measures are used to assess the ATSFM’s forecasting capability. Our experimental results demonstrate that the ATSFM outperforms existing methods, yielding more accurate forecasting results of sunspots. To enhance reproducibility, the source code will be made available upon request by contacting the corresponding author via email.},
  archive      = {J_KBS},
  author       = {Pritpal Singh},
  doi          = {10.1016/j.knosys.2025.114257},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114257},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel model to deal with ambiguous and complex time series: Application to sunspots forecasting},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing federated learning model adversarial robustness in autonomous vehicles: A lightweight framework with contrastive learning and spatial clustering. <em>KBS</em>, <em>329</em>, 114253. (<a href='https://doi.org/10.1016/j.knosys.2025.114253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated Vehicles (AVs) promise safer and more efficient transportation but remain vulnerable to security threats when trained using Federated Learning (FL). While FL preserves privacy by enabling decentralized training, it is particularly exposed to model poisoning (Byzantine attacks) and adversarial threats (evasion attacks). Traditional defenses, such as robust aggregation and adversarial training (AT), often degrade accuracy under Non-Independent and Identically Distributed data (non-IID). To overcome these challenges, we propose a lightweight defense framework that combines AT, supervised contrastive learning (SCL), and spatial robust aggregation. It includes (1) Pre-Defense Training , using Wasserstein-based Projected Gradient Descent (PGD) adversarial samples; (2) Robust AT with SCL , extending Model-Contrastive (MOON) with a second contrastive objective to improve model resilience and alignment for both local and FL versions; and (3) Spatial Robust Aggregation , using pairwise Wasserstein distance and 2-median clustering to filter outliers. FL pretraining was applied to accelerate convergence and enhance performance. Extensive experiments conducted with three benchmark datasets confirmed that our defense consistently outperforms other state-of-the-art methods. Our approach effectively defends against stealthy model poisoning and adversarial attacks, with only minor accuracy drops observed under extreme attack scenarios. For instance, in CIFAR-10, the clean accuracy drops from 93 % to 82 % in the IID setting and from 88 % to 75 % in the non-IID setting. This demonstrates that the proposed design represents a new benchmark for secure and reliable FL in adversarial environments. We also aim to demonstrate the practical benefits of our approach in reducing traffic accidents and congestion when deployed in AV systems.},
  archive      = {J_KBS},
  author       = {Suzan Almutairi and Ahmed Barnawi},
  doi          = {10.1016/j.knosys.2025.114253},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114253},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing federated learning model adversarial robustness in autonomous vehicles: A lightweight framework with contrastive learning and spatial clustering},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge distillation and enhanced subdomain adaptation using graph convolutional network for resource-constrained fault diagnosis. <em>KBS</em>, <em>329</em>, 114251. (<a href='https://doi.org/10.1016/j.knosys.2025.114251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearing fault diagnosis under varying working conditions faces challenges, including lack of labeled data, distribution discrepancies, and resource constraints. To address these issues, we propose a progressive knowledge distillation framework that transfers knowledge from a complex teacher model, utilizing a Graph Convolutional Network (GCN) with Autoregressive moving average (ARMA) filters, to a compact and efficient student model. To mitigate distribution discrepancies and labeling uncertainty, we introduce Enhanced Local Maximum Mean Square Discrepancy (ELMMSD), which leverages mean and variance statistics in the Reproducing Kernel Hilbert Space (RKHS) and incorporates a priori probability distributions between labels. This approach increases the distance between clustering centers, bridges subdomain gaps, and enhances subdomain alignment reliability. Experimental results on benchmark datasets (CWRU and JNU) demonstrate that the proposed method achieves superior diagnostic accuracy while significantly reducing computational costs. Comprehensive ablation studies validate the effectiveness of each component, highlighting the robustness and adaptability of the approach across diverse working conditions.},
  archive      = {J_KBS},
  author       = {Mohammadreza Kavianpour and Parisa Kavianpour and Amin Ramezani and Mohammad Th Beheshti},
  doi          = {10.1016/j.knosys.2025.114251},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114251},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge distillation and enhanced subdomain adaptation using graph convolutional network for resource-constrained fault diagnosis},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CUOM: A causal unbiased optimization method for federated domain generalization. <em>KBS</em>, <em>329</em>, 114249. (<a href='https://doi.org/10.1016/j.knosys.2025.114249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Domain Generalization (FedDG) aims to develop robust models for multi-domain discrete data, enabling generalization to unseen domains while ensuring data privacy. It facilitates collaborative training among multiple institutions, producing efficient models that generalize across diverse contexts. Existing methods emphasize extracting global domain-invariant features but frequently neglect client-specific data biases, resulting in models that learn non-causal, biased feature prototypes with limited generalization. To address this challenge, we propose a Causal Unbiased Optimization Method (CUOM) for FedDG, aimed at achieving unbiased feature learning both within and across domains. Specifically, we introduce a Structural Causal Model (SCM) based on a novel causal inference framework to analyze both data and prototype biases. Leveraging this SCM, we design the Generalization Compensation Module (GCM) and the Unbiased Prototype Learning Module (UPLM). The Generalization Compensation Module facilitates intra- and cross-domain data augmentation separately, distinguishing itself from traditional single perspective approaches. It aims to simulate domain diversity, thereby mitigating data bias more effectively. The Unbiased Prototype Learning Module integrates representation alignment loss and prototype contrastive loss to guide the model in learning instance-level unbiased features robust to prototype bias in both original and augmented data. Extensive experiments show that our method outperforms existing state-of-the-art methods in generalization across multiple benchmarks. Our code is available at https://github.com/dhaksndg/CUOM .},
  archive      = {J_KBS},
  author       = {Mi Wen and Kang Han and DongYang Li and QiYe Cai and HaiLun Shen},
  doi          = {10.1016/j.knosys.2025.114249},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114249},
  shortjournal = {Knowl. Based Syst.},
  title        = {CUOM: A causal unbiased optimization method for federated domain generalization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive active learning framework for sparsely labeled multi-label drifting data streams. <em>KBS</em>, <em>329</em>, 114248. (<a href='https://doi.org/10.1016/j.knosys.2025.114248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label data streams consist of sequential instances, each associated with multiple labels, continuously arriving for classification. This setting presents several challenges, including dynamic data distributions, limited labeled data, high labeling costs, and the computational burden of continuous model updates in the presence of concept drift. Although various solutions have been proposed for multi-label data stream classification, they often exhibit a notable limitation in addressing online learning from sparsely labeled data streams and adapting to concept drift with competitive performance. To approach this gap, this paper introduces Multi-Label Active Learning for Drifting Data Streams (MLALDDS), a novel framework tailored for multi-label drifting streams, tackling key issues through single-pass active learning, incremental updates, and effective adaptation to concept drift. MLALDDS employs a self-adjusting k-nearest neighbor classifier within a binary relevance architecture to decompose the multi-label classification problem into simpler tasks. A budget-aware selective sampling strategy is used to query only the most informative instances, minimizing labeling costs while maintaining classification performance. Model updates are conducted incrementally, and a reflective mechanism leverages ADWIN to deliver precise warnings of potential data distribution changes, ensuring individual label-specific classifiers adapt efficiently to concept drift within their respective subspaces. The proposed framework was evaluated on 30 diverse multi-label datasets against 20 state-of-the-art classifiers using 12 performance metrics. Results from nonparametric statistical analysis demonstrate that MLALDDS consistently outperforms competing methods, confirming the effectiveness of its key components in improving classification performance.},
  archive      = {J_KBS},
  author       = {Reza Rahimian and Hoda Mashayekhi and Maryam Khodabakhsh},
  doi          = {10.1016/j.knosys.2025.114248},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114248},
  shortjournal = {Knowl. Based Syst.},
  title        = {An adaptive active learning framework for sparsely labeled multi-label drifting data streams},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive anchor-based attention networks for large-scale sparse bipartite graph embedding. <em>KBS</em>, <em>329</em>, 114242. (<a href='https://doi.org/10.1016/j.knosys.2025.114242'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipartite graph embedding aims to map each node into compact, low-dimensional vectors that preserve the intrinsic properties of the graph. The effectiveness of these embeddings is crucial for capturing structural information and node relationships, which directly impacts the performance of downstream applications such as recommender systems and bioinformatics. However, due to the inherent sparsity and large scale of many real-world bipartite graphs, existing methods often suffer from missing contextual information and excessive feature smoothing. In this paper, we take the first step toward systematically addressing the challenges of embedding large and sparse bipartite graphs. To this end, we propose Adaptive Anchor-based Graph Attention Networks (A 2 GAT), a novel framework that integrates entropy regularization to ensure a balanced distribution of attention weights, preserve feature distinctiveness, and mitigate over-smoothing. In addition, we design an adaptive anchor node generation mechanism and introduce a fully connected attention (FCA) module that dynamically adjusts interaction weights, effectively addressing sparse connectivity and enhancing representation learning in low-density regions. Extensive experiments on eight benchmark datasets demonstrate the effectiveness and generalizability of our model across both recommendation and link prediction tasks.},
  archive      = {J_KBS},
  author       = {Linlin Ding and Yiming Han and Mo Li and Ningning Cui and Xin Wang and Renata Borovica-Gajic},
  doi          = {10.1016/j.knosys.2025.114242},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114242},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive anchor-based attention networks for large-scale sparse bipartite graph embedding},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LoRA dropout as a sparsity regularizer for overfitting reduction. <em>KBS</em>, <em>329</em>, 114241. (<a href='https://doi.org/10.1016/j.knosys.2025.114241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter-efficient fine-tuning methods, represented by LoRA, play an essential role in adapting large-scale pre-trained models to downstream tasks. However, fine-tuning LoRA-series models also faces the risk of overfitting on small training datasets, and there’s still a lack of theoretical guidance and practical mechanisms to control overfitting on LoRA-based PEFT methods. This paper introduces a novel dropout-based sparsity regularizer for LoRA, dubbed LoRA Dropout, which mitigates overfitting by applying refined dropout to LoRA’s low-rank matrices. We establish a theoretical framework that models dropout in LoRA as a sparse fine-tuning process and derive a generalization error bound under this sparsity regularization. Theoretical results show that appropriate sparsity can tighten the gap between empirical and generalization risks and thereby control overfitting. We further enhance the sparsity patterns in conventional dropout methods and propose an innovative LoRA Dropout method for more precise sparsity regularization to achieve better overfitting reduction. Furthermore, we introduce a test-time ensemble strategy and provide theoretical evidence demonstrating that the ensemble method can further compress the error bound and lead to better performance. Extensive experiments on various tasks validate the effectiveness of our LoRA Dropout framework in improving the model’s performance.},
  archive      = {J_KBS},
  author       = {Yang Lin and Xinyu Ma and Xu Chu and Yujie Jin and Zhibang Yang and Yasha Wang},
  doi          = {10.1016/j.knosys.2025.114241},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114241},
  shortjournal = {Knowl. Based Syst.},
  title        = {LoRA dropout as a sparsity regularizer for overfitting reduction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential hash representation for deep hashing-based image retrieval. <em>KBS</em>, <em>329</em>, 114229. (<a href='https://doi.org/10.1016/j.knosys.2025.114229'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In computer vision, convolutional neural networks have significantly improved the effectiveness of deep hashing-based image retrieval. However, existing deep hashing techniques often regard hash codes as spatial features. It leads to insensitivity of existing hash representations to spatial shifts in real number space which can be explained by mismatch between the real number space and the Hamming space. In response to these limitations, this paper introduces SeqHash, a novel approach grounded in sequential hash representation. Diverging from existing deep hashing methods, SeqHash treats hash codes as hash sequences. Benefiting from the sequential properties of chaos theory and the robust fitting capabilities of Kolmogorov-Arnold Networks (KANs), SeqHash constructs a hash-coding layer called sequence-KAN layer to produce hash codes as sequential outputs in the processes of hash encoding and category hash centers generation. Furthermore, SeqHash devises a loss function that facilitates convergence of the sequential outputs to reach the stable states of the predefined sequence in temporal domain. The error propagation of sequential hash representation and the randomness of chaos mapping facilitate each hash code bit to be contingent upon its previous bits, and endow hashing with higher sensitivity to spatial shifts in real number space. This property aligns the shifts in Hamming space and real number space during training and capture the differences among samples effectively. The quantitative and qualitative experiments demonstrate that SeqHash offers remarkable performance in image retrieval tasks and yields more discernible hash codes compared to other cutting-edge deep hashing algorithms.},
  archive      = {J_KBS},
  author       = {Yinqi Chen and Yangting Zheng and Zhiyi Lu and Peiwen Li and Wenbin He and Shuo Kang and Xiang Gao},
  doi          = {10.1016/j.knosys.2025.114229},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114229},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sequential hash representation for deep hashing-based image retrieval},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADR-net: Attention-oriented detail recovery network for document image shadow removal. <em>KBS</em>, <em>329</em>, 114228. (<a href='https://doi.org/10.1016/j.knosys.2025.114228'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods based on deep learning have extensively explored the problem of document image shadow removal. However, most of them seldom consider the key regions of complex shadows and ignore detail preservation. Moreover, they usually have large model parameters that limit the potential values in real-world applications. To address these issues, we propose a simple but effective Attention-oriented Detail Recovery Network (ADR-Net) to remove complex shadows while preserving details in low complexity. In particular, on one hand, we explore the properties of shadows in color space and use luminance information to guide and generate shadow attention maps, which can accurately capture complex shadow distributions. For this purpose, we further design a Shadow Attention Generation Sub-Network (SAGN) that uses Multi-scale Large Kernel Attention (MLKA) mechanism to obtain long-range dependencies of shadows at various granularity levels. On the other hand, we propose a Dynamic Fusion (DF) strategy to avoid the ambiguity issues from wrong attention map during the learning process. In addition, we propose a Detail Refinement Sub-Network (DRN) that adopts Lightweight Spatial-Channel Convolution (LSCC) to facilitate recover details while decreasing redundant computing. Extensive experiments on public benchmarks and Optical Character Recognition (OCR) performance validate the effectiveness of our proposed ADR-Net and its superiority over state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Fan Yang and Nanfeng Jiang and Da-Han Wang and Xu-Yao Zhang and Yun Wu and Shunzhi Zhu},
  doi          = {10.1016/j.knosys.2025.114228},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114228},
  shortjournal = {Knowl. Based Syst.},
  title        = {ADR-net: Attention-oriented detail recovery network for document image shadow removal},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic interaction and router selection network for multi-modality biometric recognition. <em>KBS</em>, <em>329</em>, 114223. (<a href='https://doi.org/10.1016/j.knosys.2025.114223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modality biometric recognition has attracted significant attention owing to its benefits of convenient acquisition, high security, and accurate recognition. However, most existing modality-fusion methods are static and rely on expert experience or knowledge to design interaction models, which limits their flexibility. Additionally, these interaction models fail to adaptively respond to the evolving and complex intra- and inter-modal relationships, thereby limiting the ability of the model to capture diverse and intricate patterns. To address these issues, we propose a dynamic interaction and router selection network, enabling the adaptive learning of previously unexplored interaction patterns. We designed three progressive interaction units, which are responsible for preserving unique modality information, aligning and enhancing modality features, and dynamically reinforcing inter-modality channel and intra-modality spatial interactions. Dynamic soft router is incorporated into each interaction unit, enabling the generation of an adaptive interaction path that is determined by sample complexity. In addition, within the interaction units, we propose a novel inter-channel and intra-spatial modality interaction fusion unit, which incorporates a dynamic inter-modality linear channel interaction unit and an intra-modality bidirectional multiscale attention unit. By leveraging dynamically reconstructed inter-modality channel features, the unit progressively guides intra-modality spatial features, thereby enhancing the complementarity of inter-modality features and improving the discriminability of intra-modality features. In contrast to nonextensible methods, which suffer from limitations in constrained by limited flexibility, our approach enables simultaneous integration of data across multiple modalities. Extensive experiments conducted on four databases demonstrate that the proposed model significantly outperforms current state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Xiao Yang and Hai Yuan and Jie Hu and Zaiyu Pan and Zhengwen Shen and Jun Wang},
  doi          = {10.1016/j.knosys.2025.114223},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114223},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic interaction and router selection network for multi-modality biometric recognition},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ontology-based data federation and query optimization. <em>KBS</em>, <em>329</em>, 114216. (<a href='https://doi.org/10.1016/j.knosys.2025.114216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontology-based data access (OBDA), also known as virtual knowledge graphs (VKG), is a well-established approach to information management that facilitates the access to a (single) relational data source through the mediation of a high-level ontology, and the use of a declarative mapping linking the data layer to the ontology. In order to integrate multiple, possibly distributed and heterogeneous, data sources, in this work we formally introduce an extension of OBDA, called ontology-based data federation (OBDF), by combining OBDA with a data federation layer, which can expose multiple data sources as a single relational database. We discuss opportunities and challenges of OBDF, and provide techniques to deliver efficient query answering in OBDF by exploiting inter-source relations (called data hints) in the federated sources. Such techniques are validated through an extensive experimental evaluation based on the Berlin SPARQL Benchmark.},
  archive      = {J_KBS},
  author       = {Zhenzhen Gu and Davide Lanti and Francesco Corcoglioniti and Marco Di Panfilo and Alessandro Mosca and Diego Calvanese and Guohui Xiao},
  doi          = {10.1016/j.knosys.2025.114216},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114216},
  shortjournal = {Knowl. Based Syst.},
  title        = {Ontology-based data federation and query optimization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pinpointing visual content: Disentangled features in multimodal model for EEG representation learning and decoding. <em>KBS</em>, <em>329</em>, 114212. (<a href='https://doi.org/10.1016/j.knosys.2025.114212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding how humans process visual information is one of the key steps in revealing the underlying mechanisms of the brain. Recent research has significantly progressed in brain signal decoding and visual content reconstruction. However, due to complex noise and insufficient alignment accuracy, methods for extracting effective information from electroencephalogram (EEG) are still limited. Existing decoding strategies often fail to adequately represent the fine-grained information of visual embeddings and struggle to deal with data scarcity. To address these issues, we propose the PinVC ( P inpointing V isual C ontent) framework, which aims to integrate fine-grained multimodal information in EEG signals and represent similar activation patterns cross-subject to enhance the accuracy of EEG representation and visual decoding. This method introduces a feature adaptation mechanism that mitigates individual differences and noise effects by masking attention, thus ensuring cross-subject generalizability. In addition, we align the EEG with the implicit target semantic embedding of the LLM and construct a spatial information attention (SIA) module to extract spatial features, thus further improving the quality of the multilevel reconstructed images. PinVC provides accurate multimodal guidance for the pre-trained generative model. We conducted rigorous experimental evaluations on different datasets as well as downstream tasks including visual reconstruction and caption generation, demonstrating PinVC’s excellent performance and generalization. Our project is available at https://github.com/HolderXJTU/PinVC .},
  archive      = {J_KBS},
  author       = {Haodong Jing and Yongqiang Ma and Panqi Yang and Haibo Hua and Nanning Zheng},
  doi          = {10.1016/j.knosys.2025.114212},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114212},
  shortjournal = {Knowl. Based Syst.},
  title        = {Pinpointing visual content: Disentangled features in multimodal model for EEG representation learning and decoding},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Citrus plant classification using gated fusion adaptive graph neural network with harbor seal whiskers optimization algorithm. <em>KBS</em>, <em>329</em>, 114093. (<a href='https://doi.org/10.1016/j.knosys.2025.114093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Citrus is vital for vitamin C production, but existing disease classification methods struggle with low accuracy due to poor feature representation, limited complex pattern handling and weak fusion under varied textures and lighting. To overcome these complications, Citrus Plant Classification using Gated Fusion Adaptive Graph Neural Network with Harbor Seal Whiskers Optimization Algorithm (CPC-GFAGNN HSWOA) is proposed. Here, the images are taken from Citrus leaf dataset. Afterwards the images are fed into the pre-processing stage. In preprocessing, Unsharp Structure Guided Filtering (USGF) is applied to eliminate noise from the input images. The pre-processed images are given to the Semantic Invariant Multi-view Clustering (SIMVC) for segmenting region of interest from the citrus leaf images. Next, the segmented images are supplied to the feature extraction process. By using Feature Affine Residual Network (FA-ResNet), the features are extracted, like shapes, colors and textures. The extracted features are fed into the Gated Fusion Adaptive Graph Neural Network (GFAGNN) to classify the citrus leaf images as Black Spot, Canker, Greening, Healthy and Melanose. Finally, Harbor Seal Whiskers Optimization Algorithm (HSWOA) is employed to improve the weight parameter of GFAGNN. This combination effectively mitigates issues such as over fitting, class imbalance and suboptimal feature learning, resulting in robust and accurate classification of citrus leaf diseases. The proposed CPC-GFAGNN HSWOA method is implemented and performance is evaluated using metrics. The experimental results shows that the proposed CPC-GFAGNN HSWOA method achieves 18.75 %, 26.89 %, 32.57 % better accuracy, 18.43 %, 25.64 %, 31.40 % better sensitivity when compared with existing AD-CPL-DNN, SA-DNN CDD and CL-DC CNN models respectively.},
  archive      = {J_KBS},
  author       = {Aswini E and C. Vijayakumaran},
  doi          = {10.1016/j.knosys.2025.114093},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114093},
  shortjournal = {Knowl. Based Syst.},
  title        = {Citrus plant classification using gated fusion adaptive graph neural network with harbor seal whiskers optimization algorithm},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Embedding word positions with polar coordinates. <em>KBS</em>, <em>329</em>, 113903. (<a href='https://doi.org/10.1016/j.knosys.2025.113903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Word positions provide grammatical information and help identify linguistic structures. Recent works have shown that the positions of words in a sentence play an important role in natural language processing (NLP). In this paper, we propose a novel method using polar coordinates to embed word positions. The main idea is to decouple a position embedding into a semantic component and a sequential order component, which are implemented by the polar radius and the polar angle respectively. We further propose a Polar-Fix module and plug it in the conventional Transformer encoder. This module (1) enables the stacked Transformer networks to maintain the polarized representation and (2) avoids the danger of over tuning the context-free parameters that are independent on the contexts. Experimental results on three classic NLP tasks, i.e., language modeling, text classification and semantic similarity, show that our method achieves significant improvements over the state-of-the-art Transformer based models. The visualization of polar embeddings indicates that our model is highly interpretable.},
  archive      = {J_KBS},
  author       = {Xiaotang Wen and Chen Yan and Huimin Huang and Hong Shen},
  doi          = {10.1016/j.knosys.2025.113903},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {113903},
  shortjournal = {Knowl. Based Syst.},
  title        = {Embedding word positions with polar coordinates},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Redundancy reduction penalty term of loss function in deep neural network. <em>KBS</em>, <em>329</em>, 113776. (<a href='https://doi.org/10.1016/j.knosys.2025.113776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel regularization algorithm that is introduced as a penalty term to the loss function. Differing from conventional L1 and L2 regularization methods, our approach does not aim to diminish the weights of individual neurons or enforce sparsity by driving certain neurons to zero. Instead, it functions by increasing the differences between neurons and enhancing the diversity of neurons within each layer. Our method incorporates ensemble learning techniques by treating the layer weight matrix as a collective learning model, where each neuron serving as a weak learner within the layer. The proposed algorithm improves the performance of DCNN by simultaneously considering the distance between multiple filters in the same layer. This algorithm reduces the redundancy of the parameter layer filters in DCNN and enhances its robustness. The penalty term proposed by our algorithm dynamically adjusts its value in a cyclical manner, compelling the neural network to navigate away from its current gradient state. In the parameter space, different weights correspond to different locations. The proposed algorithm quantifies the distance between neurons and iteratively increases the distance between neurons during thereby encouraging greater diversity within the network. Experimental evaluations demonstrate the effectiveness of our algorithm in enhancing neural network performance without requiring adjustments to other hyper-parameters.},
  archive      = {J_KBS},
  author       = {Xueheng Hu and Shuhuan Wen and H.K. Lam},
  doi          = {10.1016/j.knosys.2025.113776},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {113776},
  shortjournal = {Knowl. Based Syst.},
  title        = {Redundancy reduction penalty term of loss function in deep neural network},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
