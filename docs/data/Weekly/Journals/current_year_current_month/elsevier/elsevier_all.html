<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>elsevier</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aij">AIJ - 21</h2>
<ul>
<li><details>
<summary>
(2025). Minimax off-policy evaluation and learning with subgaussian and differentiable importance weighting. <em>AIJ</em>, <em>348</em>, 104419. (<a href='https://doi.org/10.1016/j.artint.2025.104419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the statistical properties of the off-policy estimation problem, i.e., estimating expectations under a target policy using samples collected from a different policy. We begin by presenting a novel minimax concentration lower bound that highlights the fundamental limits of off-policy estimation. We then analyze two well-known importance weighting (IW) techniques: vanilla IW and self-normalized importance weighting (SN). For both methods, we derive concentration and anti-concentration results, showing that their concentration rates are provably suboptimal compared to our lower bound. Observing that this undesired behavior arises from the heavy-tailed nature of the IW and SN estimators, we propose a new class of parametric estimators based on a transformation using the power mean (PM), which is no longer heavy-tailed. We study the theoretical properties of the PM estimator in terms of bias and variance. We show that, with suitable (possibly data-driven) tuning of its parameters, the PM estimator satisfies two key properties under certain conditions: ( i ) it achieves a subgaussian concentration rate that matches our lower bound and ( ii ) it maintains differentiability with respect to the target policy. Finally, we validate our approach through numerical simulations on both synthetic datasets and contextual bandits, comparing it against standard off-policy evaluation and learning baselines. 1},
  archive      = {J_AIJ},
  author       = {Alberto Maria Metelli and Alessio Russo and Marcello Restelli},
  doi          = {10.1016/j.artint.2025.104419},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104419},
  shortjournal = {Artif. Intell.},
  title        = {Minimax off-policy evaluation and learning with subgaussian and differentiable importance weighting},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the disjunctive rational closure of a conditional knowledge base. <em>AIJ</em>, <em>348</em>, 104418. (<a href='https://doi.org/10.1016/j.artint.2025.104418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most widely investigated decision problems in symbolic AI is that of which conditional sentences of the form “if α , then normally β ” should follow from a knowledge base containing this type of statements. Probably, the most notable approach to this problem is the rational closure construction put forward by Lehmann and Magidor in the'90s, which has been adapted to logical languages of various expressive powers since then. At the core of rational closure is the Rational Monotonicity property, which allows one to retain existing (defeasible) conclusions whenever new information cannot be negated by existing conclusions. As it turns out, Rational Monotonicity is not universally accepted, with many researchers advocating the investigation of weaker versions thereof leading to a larger class of consequence relations. A case in point is that of the Disjunctive Rationality property, which states that if one may draw a (defeasible) conclusion from a disjunction of premises, then one should be able to draw this conclusion from at least one of the premises taken alone. While there are convincing arguments that the rational closure forms the ‘simplest’ rational consequence relation extending a given set of conditionals, the question of what the simplest disjunctive consequence relation in this setting is has not been explored in depth. In this article, we do precisely that by motivating and proposing a concrete construction of the disjunctive rational closure of a conditional knowledge base, of which the properties and consequences of its adoption we also investigate in detail. (Previous versions of this work have been selected for presentation at the 18th International Workshop on Nonmonotonic Reasoning (NMR 2020) [1] and at the 35th AAAI Conference on Artificial Intelligence (AAAI 2021) [2] . The present submission extends and elaborates on both papers.)},
  archive      = {J_AIJ},
  author       = {Richard Booth and Ivan Varzinczak},
  doi          = {10.1016/j.artint.2025.104418},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104418},
  shortjournal = {Artif. Intell.},
  title        = {On the disjunctive rational closure of a conditional knowledge base},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking visual prompt learning as masked visual token modeling. <em>AIJ</em>, <em>348</em>, 104417. (<a href='https://doi.org/10.1016/j.artint.2025.104417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt learning has achieved great success in efficiently exploiting large-scale pre-trained models in natural language processing (NLP). It reformulates the downstream tasks as the generative pre-training ones to achieve consistency, thus improving the performance stably. However, when transferring it to the vision area, current visual prompt learning methods are almost designed on discriminative pre-trained models, and there is also a lack of careful design to unify the forms of pre-training and downstream tasks. To explore prompt learning on the generative pre-trained visual model, as well as keeping the task consistency, we propose Visual Prompt learning as masked visual Token Modeling (VPTM) to transform the downstream visual classification task into the pre-trained masked visual token prediction task. In addition, we develop the prototypical verbalizer for mapping the predicted visual token with implicit semantics to explicit downstream labels. To our best knowledge, VPTM is the first visual prompt method on the generative pre-trained visual model, which achieves consistency between pre-training and downstream visual classification by task reformulation. Experiments show that VPTM outperforms other visual prompt methods and achieves excellent efficiency. Moreover, the task consistency of VPTM contributes to the robustness against prompt location, prompt length and prototype dimension, and could be deployed uniformly.},
  archive      = {J_AIJ},
  author       = {Ning Liao and Bowen Shi and Xiaopeng Zhang and Min Cao and Junchi Yan and Qi Tian},
  doi          = {10.1016/j.artint.2025.104417},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104417},
  shortjournal = {Artif. Intell.},
  title        = {Rethinking visual prompt learning as masked visual token modeling},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Planning for temporally extended goals in pure-past linear temporal logic. <em>AIJ</em>, <em>348</em>, 104409. (<a href='https://doi.org/10.1016/j.artint.2025.104409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study planning for temporally extended goals expressed in Pure-Past Linear Temporal Logic ( ppltl ) in the context of deterministic (i.e., classical) and fully observable nondeterministic (FOND) domains. ppltl is the variant of Linear-time Temporal Logic on finite traces ( ltl f ) that refers to the past rather than the future. Although ppltl is as expressive as ltl f , we show that it is computationally much more effective for planning. In particular, we show that checking the validity of a plan for a ppltl formula is Markovian. This is achieved by introducing a linear number of additional propositional variables that capture the validity of the entire formula in a modular fashion. The solution encoding introduces only a linear number of new fluents proportional to the size of the ppltl goal and does not require any additional spurious action. We implement our solution technique in a system called Plan4Past , which can be used alongside state-of-the-art classical and FOND planners. Our empirical analysis demonstrates the practical effectiveness of Plan4Past in both classical and FOND problems, showing that the resulting planner performs overall better than other planning approaches for ltl f goals.},
  archive      = {J_AIJ},
  author       = {Luigi Bonassi and Giuseppe De Giacomo and Marco Favorito and Francesco Fuggitti and Alfonso Emilio Gerevini and Enrico Scala},
  doi          = {10.1016/j.artint.2025.104409},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104409},
  shortjournal = {Artif. Intell.},
  title        = {Planning for temporally extended goals in pure-past linear temporal logic},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incentives for responsiveness, instrumental control and impact. <em>AIJ</em>, <em>348</em>, 104408. (<a href='https://doi.org/10.1016/j.artint.2025.104408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce three concepts that describe an agent's incentives: response incentives indicate which variables in the environment, such as sensitive demographic information, affect the decision under the optimal policy. Instrumental control incentives indicate whether an agent's policy is chosen to manipulate part of its environment, such as the preferences or instructions of a user. Impact incentives indicate which variables an agent will affect, intentionally or otherwise. For each concept, we establish sound and complete graphical criteria, and discuss general classes of techniques that may be used to produce incentives for safe and fair agent behaviour. Finally, we outline how these notions may be generalised to multi-decision settings. This journal paper extends our conference publication “Agent Incentives: A Causal Perspective”: the material on response incentives and instrumental control incentives is updated, while the work on impact incentives and multi-decision settings is entirely new.},
  archive      = {J_AIJ},
  author       = {Ryan Carey and Eric Langlois and Chris van Merwijk and Shane Legg and Tom Everitt},
  doi          = {10.1016/j.artint.2025.104408},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104408},
  shortjournal = {Artif. Intell.},
  title        = {Incentives for responsiveness, instrumental control and impact},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Abstracting situation calculus action theories. <em>AIJ</em>, <em>348</em>, 104407. (<a href='https://doi.org/10.1016/j.artint.2025.104407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a general framework for agent abstraction based on the situation calculus and the ConGolog agent programming language. We assume that we have a high-level specification and a low-level specification of the agent, both represented as basic action theories. A refinement mapping specifies how each high-level action is implemented by a low-level ConGolog program and how each high-level fluent can be translated into a low-level formula. We define a notion of sound abstraction between such action theories in terms of the existence of a suitable bisimulation between their respective models. Sound abstractions have many useful properties that ensure that we can reason about the agent's actions (e.g., executability, projection, and planning) at the abstract level, and refine and concretely execute them at the low level. We also characterize the notion of complete abstraction where all actions (including exogenous ones) that the high level thinks can happen can in fact occur at the low level. To facilitate verifying that one has a sound/complete abstraction relative to a mapping, we provide a set of necessary and sufficient conditions. Finally, we identify a set of basic action theory constraints that ensure that for any low-level action sequence, there is a unique high-level action sequence that it refines. This allows us to track/monitor what the low-level agent is doing and describe it in abstract terms (i.e., provide high-level explanations, for instance, to a client or manager).},
  archive      = {J_AIJ},
  author       = {Bita Banihashemi and Giuseppe De Giacomo and Yves Lespérance},
  doi          = {10.1016/j.artint.2025.104407},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104407},
  shortjournal = {Artif. Intell.},
  title        = {Abstracting situation calculus action theories},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards optimal subsidy bounds for envy-freeable allocations. <em>AIJ</em>, <em>348</em>, 104406. (<a href='https://doi.org/10.1016/j.artint.2025.104406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the fair division of indivisible items with subsidies among n agents, where the absolute marginal valuation of each item is at most one. Under monotone nondecreasing valuations (where each item is a good), Brustle et al. [9] demonstrated that a maximum subsidy of 2 ( n − 1 ) and a total subsidy of 2 ( n − 1 ) 2 are sufficient to guarantee the existence of an envy-freeable allocation. In this paper, we improve upon these bounds, even in a wider model. Namely, we show that, given an EF1 allocation, we can compute in polynomial time an envy-free allocation with a subsidy of at most n − 1 per agent and a total subsidy of at most n ( n − 1 ) / 2 . Moreover, when the valuations are monotone nondecreasing, we provide a polynomial-time algorithm that computes an envy-free allocation with a subsidy of at most n − 1.5 per agent and a total subsidy of at most ( n 2 − n − 1 ) / 2 .},
  archive      = {J_AIJ},
  author       = {Yasushi Kawase and Kazuhisa Makino and Hanna Sumita and Akihisa Tamura and Makoto Yokoo},
  doi          = {10.1016/j.artint.2025.104406},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104406},
  shortjournal = {Artif. Intell.},
  title        = {Towards optimal subsidy bounds for envy-freeable allocations},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local-MIP: Efficient local search for mixed integer programming. <em>AIJ</em>, <em>348</em>, 104405. (<a href='https://doi.org/10.1016/j.artint.2025.104405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixed Integer Programming (MIP) is a fundamental model in operations research with broad industrial applications. Local search is a powerful methodology for solving complex optimization problems; however, the development of local search algorithms for MIP still needs exploration. In this work, we propose Local-MIP , an efficient local search algorithm tailored for MIP that integrates novel operators and employs a two-mode architecture to adaptively apply operators based on the current solution's feasibility. For the feasible mode, we propose the lift move operator and a corresponding lift process to improve the objective value while maintaining feasibility. For the infeasible mode, we propose the breakthrough move and mixed tight move operators to respectively optimize the objective function and satisfy constraints. To apply operators intelligently, we develop a dynamic weighting scheme that balances the priorities of the objective function and constraints. Furthermore, we propose a two-level scoring function structure that hierarchically selects operations, guiding the search toward high-quality feasible solutions. Experiments are conducted on public benchmarks to compare Local-MIP with state-of-the-art MIP solvers in finding high-quality solutions. The results show that Local-MIP significantly outperforms CPLEX , HiGHS , SCIP , and Feasibility Jump while remaining competitive with the commercial solver Gurobi on challenging problems within short time limits. Moreover, Local-MIP establishes 10 new records on MIPLIB open instances.},
  archive      = {J_AIJ},
  author       = {Peng Lin and Shaowei Cai and Mengchuan Zou and Jinkun Lin},
  doi          = {10.1016/j.artint.2025.104405},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104405},
  shortjournal = {Artif. Intell.},
  title        = {Local-MIP: Efficient local search for mixed integer programming},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Centralized training with hybrid execution in multi-agent reinforcement learning via predictive observation imputation. <em>AIJ</em>, <em>348</em>, 104404. (<a href='https://doi.org/10.1016/j.artint.2025.104404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study hybrid execution in multi-agent reinforcement learning (MARL), a paradigm where agents aim to complete cooperative tasks with arbitrary communication levels at execution time by taking advantage of information-sharing among the agents. Under hybrid execution, the communication level can range from a setting in which no communication is allowed between agents (fully decentralized), to a setting featuring full communication (fully centralized), but the agents do not know beforehand which communication level they will encounter at execution time. We contribute MARO, an approach that makes use of an auto-regressive predictive model, trained in a centralized manner, to estimate missing agents' observations at execution time. We evaluate MARO on standard scenarios and extensions of previous benchmarks tailored to emphasize the impact of partial observability in MARL. Experimental results show that our method consistently outperforms relevant baselines, allowing agents to act with faulty communication while successfully exploiting shared information.},
  archive      = {J_AIJ},
  author       = {Pedro P. Santos and Diogo S. Carvalho and Miguel Vasco and Alberto Sardinha and Pedro A. Santos and Ana Paiva and Francisco S. Melo},
  doi          = {10.1016/j.artint.2025.104404},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104404},
  shortjournal = {Artif. Intell.},
  title        = {Centralized training with hybrid execution in multi-agent reinforcement learning via predictive observation imputation},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algebras of actions in an agent's representations of the world. <em>AIJ</em>, <em>348</em>, 104403. (<a href='https://doi.org/10.1016/j.artint.2025.104403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning efficient representations allows robust processing of data, data that can then be generalised across different tasks and domains, and it is thus paramount in various areas of Artificial Intelligence, including computer vision, natural language processing and reinforcement learning, among others. Within the context of reinforcement learning, we propose in this paper a mathematical framework to learn representations by extracting the algebra of the transformations of worlds from the perspective of an agent. As a starting point, we use our framework to reproduce representations from the symmetry-based disentangled representation learning (SBDRL) formalism proposed by [1] and prove that, although useful, they are restricted to transformations that respond to the properties of algebraic groups. We then generalise two important results of SBDRL –the equivariance condition and the disentangling definition– from only working with group-based symmetry representations to working with representations capturing the transformation properties of worlds for any algebra, using examples common in reinforcement learning and generated by an algorithm that computes their corresponding Cayley tables. Finally, we combine our generalised equivariance condition and our generalised disentangling definition to show that disentangled sub-algebras can each have their own individual equivariance conditions, which can be treated independently, using category theory. In so doing, our framework offers a rich formal tool to represent different types of symmetry transformations in reinforcement learning, extending the scope of previous proposals and providing Artificial Intelligence developers with a sound foundation to implement efficient applications.},
  archive      = {J_AIJ},
  author       = {Alexander Dean and Eduardo Alonso and Esther Mondragón},
  doi          = {10.1016/j.artint.2025.104403},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104403},
  shortjournal = {Artif. Intell.},
  title        = {Algebras of actions in an agent's representations of the world},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cooperativity in controlled query evaluation over ontologies. <em>AIJ</em>, <em>348</em>, 104402. (<a href='https://doi.org/10.1016/j.artint.2025.104402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlled Query Evaluation (CQE) is a methodology designed to maintain confidentiality by either rejecting specific queries or adjusting responses to safeguard sensitive information. In this investigation, our focus centers on CQE within Description Logic ontologies, aiming to ensure that queries are answered truthfully as long as possible before resorting to deceptive responses, a cooperativity property which is called the “longest honeymoon”. Our work introduces new semantics for CQE, denoted as MC-CQE, which enjoys the longest honeymoon property and outperforms previous methodologies in terms of cooperativity. We study the complexity of query answering in this new framework for ontologies expressed in the Description Logic DL-Lite R . Specifically, we establish data complexity results under different maximally cooperative semantics and for different classes of queries. Our results identify both tractable and intractable cases. In particular, we show that the evaluation of Boolean unions of conjunctive queries is the same under all the above semantics and its data complexity is in . This result makes query answering amenable to SQL query rewriting. However, this favorable property does not extend to open queries, even with a restricted query language limited to conjunctions of atoms. While, in general, answering open queries in the MC-CQE framework is intractable, we identify a sub-family of semantics under which answering full conjunctive queries is tractable.},
  archive      = {J_AIJ},
  author       = {Piero Bonatti and Gianluca Cima and Domenico Lembo and Francesco Magliocca and Lorenzo Marconi and Riccardo Rosati and Luigi Sauro and Domenico Fabio Savo},
  doi          = {10.1016/j.artint.2025.104402},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104402},
  shortjournal = {Artif. Intell.},
  title        = {Enhancing cooperativity in controlled query evaluation over ontologies},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BATED: Learning fair representation for pre-trained language models via biased teacher-guided disentanglement. <em>AIJ</em>, <em>348</em>, 104401. (<a href='https://doi.org/10.1016/j.artint.2025.104401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Pre-trained Language Models (PLMs) and their widespread deployment in various real-world applications, social biases of PLMs have attracted increasing attention, especially the fairness of downstream tasks, which potentially affects the development and stability of society. Among existing debiasing methods, intrinsic debiasing methods are not necessarily effective when applied to downstream tasks, and the downstream fine-tuning process may introduce new biases or catastrophic forgetting. Most extrinsic debiasing methods rely on sensitive attribute words as prior knowledge to supervise debiasing training. However, it is difficult to collect sensitive attribute information of real data due to privacy and regulation. Moreover, limited sensitive attribute words may lead to inadequate debiasing training. To this end, this paper proposes a debiasing method to learn fair representation for PLMs via B i A sed TE acher-guided D isentanglement (called BATED ). Specific to downstream tasks, BATED performs debiasing training under the guidance of a biased teacher model rather than relying on sensitive attribute information of the training data. First, we leverage causal contrastive learning to train a task-agnostic general biased teacher model. We then employ Variational Auto-Encoder (VAE) to disentangle the PLM-encoded representation into the fair representation and the biased representation. The Biased representation is further decoupled via biased teacher-guided disentanglement, while the fair representation learn downstream tasks. Therefore, BATED guarantees the performance of downstream tasks while improving the fairness. Experimental results on seven PLMs testing three downstream tasks demonstrate that BATED outperforms the state-of-the-art overall in terms of fairness and performance on downstream tasks.},
  archive      = {J_AIJ},
  author       = {Yingji Li and Mengnan Du and Rui Song and Mu Liu and Ying Wang},
  doi          = {10.1016/j.artint.2025.104401},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104401},
  shortjournal = {Artif. Intell.},
  title        = {BATED: Learning fair representation for pre-trained language models via biased teacher-guided disentanglement},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On preference learning based on sequential bayesian optimization with pairwise comparison. <em>AIJ</em>, <em>348</em>, 104400. (<a href='https://doi.org/10.1016/j.artint.2025.104400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User preference learning is generally a hard problem. Individual preferences are typically unknown even to users themselves, while the space of choices is infinite. Here we study user preference learning from information-theoretic perspective. We model preference learning as a system with two interacting sub-systems, one representing a user with his/her preferences and another one representing an agent that has to learn these preferences. The user with his/her behavior is modeled by a parametric preference function. To efficiently learn the preferences and reduce search space quickly, we propose the agent that interacts with the user to collect the most informative data for learning. The agent presents two proposals to the user for evaluation, and the user rates them based on his/her preference function. We show that the optimum agent strategy for data collection and preference learning is a result of maximin optimization of the normalized weighted Kullback-Leibler (KL) divergence between true and agent-assigned predictive user response distributions. The resulting value of the KL-divergence, which we also call of a remaining system uncertainty (RSU), provides an efficient performance metric in the absence of the ground truth. This metric characterizes how well the agent can predict user and, thus, the quality of the underlying learned user (preference) model. Our proposed agent comprises sequential mechanisms for user model inference and proposal generation. To infer the user model (preference function), Bayesian approximate inference is used in the agent. The data collection strategy is to generate proposals, responses to which help resolving uncertainty associated with prediction of the user responses the most. The efficiency of our approach is validated by numerical simulations. Also a real-life example of preference learning application is provided.},
  archive      = {J_AIJ},
  author       = {Tanya Ignatenko and Kirill Kondrashov and Marco Cox and Bert de Vries},
  doi          = {10.1016/j.artint.2025.104400},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104400},
  shortjournal = {Artif. Intell.},
  title        = {On preference learning based on sequential bayesian optimization with pairwise comparison},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Choosing abstraction levels for model-based software debugging: A theoretical and empirical analysis for spreadsheet programs. <em>AIJ</em>, <em>348</em>, 104399. (<a href='https://doi.org/10.1016/j.artint.2025.104399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based diagnosis is a generally applicable, principled approach to the systematic debugging of a wide range of system types such as circuits, knowledge bases, physical devices, or software. Based on a formal description of the system, it enables precise and deterministic reasoning about potential faults responsible for observed misbehavior. In software, such a formal system description can often even be extracted from the buggy program fully automatically. As logical reasoning is central to diagnosis, the performance of model-based debuggers is largely influenced by reasoning efficiency, which in turn depends on the complexity and expressivity of the system description. Since highly detailed models capturing exact semantics often exceed the capabilities of current reasoning tools, researchers have proposed more abstract representations. In this work, we thoroughly analyze system modeling techniques with a focus on fault localization in spreadsheets—one of the most widely used end-user programming paradigms. Specifically, we present three constraint model types characterizing spreadsheets at different abstraction levels, show how to extract them automatically from faulty spreadsheets, and provide theoretical and empirical investigations of the impact of abstraction on both diagnostic output and computational performance. Our main conclusions are that (i) for the model types, there is a trade-off between the conciseness of generated fault candidates and computation time, (ii) the exact model is often impractical, and (iii) a new model based on qualitative reasoning yields the same solutions as the exact one in up to more than half the cases while being orders of magnitude faster. Due to their ability to restrict the solution space in a sound way, the explored model-based techniques, rather than being used as standalone approaches, are expected to realize their full potential in combination with iterative sequential diagnosis or indeterministic but more performant statistical debugging methods.},
  archive      = {J_AIJ},
  author       = {Patrick Rodler and Birgit Hofer and Dietmar Jannach and Iulia Nica and Franz Wotawa},
  doi          = {10.1016/j.artint.2025.104399},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104399},
  shortjournal = {Artif. Intell.},
  title        = {Choosing abstraction levels for model-based software debugging: A theoretical and empirical analysis for spreadsheet programs},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Argus: Programming with communication protocols in a belief-desire-intention architecture. <em>AIJ</em>, <em>348</em>, 104398. (<a href='https://doi.org/10.1016/j.artint.2025.104398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protocols model multiagent systems (MAS) by capturing the communications between its agents. Belief-Desire-Intention (BDI) architectures provide an attractive way for organizing an agent in terms of cognitive concepts. Current BDI approaches, however, lack adequate support for engineering protocol-based agents. We describe Argus, an approach that melds recent advances in flexible, declarative communication protocols with BDI architectures. For concreteness, we adopt Jason as an exemplar of the BDI paradigm and show how to support protocol-based reasoning in it. Specifically, Argus contributes (1) a novel architecture and formal operational semantics combining protocols and BDI; (2) a code generation-based programming model that guides the implementation of agents; and (3) integrity checking for incoming and outgoing messages that help ensure that the agents are well-behaved. The Argus conceptual architecture builds quite naturally on top of Jason. Thus, Argus enables building more flexible multiagent systems while using a BDI architecture than is currently possible.},
  archive      = {J_AIJ},
  author       = {Samuel H. Christie V and Munindar P. Singh and Amit K. Chopra},
  doi          = {10.1016/j.artint.2025.104398},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104398},
  shortjournal = {Artif. Intell.},
  title        = {Argus: Programming with communication protocols in a belief-desire-intention architecture},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Social behavior as a key to learning-based multi-agent pathfinding dilemmas. <em>AIJ</em>, <em>348</em>, 104397. (<a href='https://doi.org/10.1016/j.artint.2025.104397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-agent Path Finding (MAPF) problem involves finding collision-free paths for a team of agents in a known, static environment, with important applications in warehouse automation, logistics, or last-mile delivery. To meet the needs of these large-scale applications, current learning-based methods often deploy the same fully trained, decentralized network to all agents to improve scalability. However, such parameter sharing typically results in homogeneous behaviors among agents, which may prevent agents from breaking ties around symmetric conflict (e.g., bottlenecks) and might lead to live-/deadlocks. In this paper, we propose SYLPH, a novel learning-based MAPF framework aimed to mitigate the adverse effects of homogeneity by allowing agents to learn and dynamically select different social behaviors (akin to individual, dynamic roles), without affecting the scalability offered by parameter sharing. Specifically, SYLPH offers a novel hierarchical mechanism by introducing Social Value Orientation (SVO) as a temporally extended latent variable that plays a central role in both policy generation and reward assignment. To support this hierarchical decision-making process, we introduce Social-aware Multi-Policy PPO (SMP3O), a reinforcement learning method that ensures stable and effective training through a mechanism for the cross-utilization of advantages. Moreover, we design an SVO-based learning tie-breaking algorithm, allowing agents to proactively avoid collisions, rather than relying solely on post-processing techniques. As a result of this hierarchical decision-making and exchange of social preferences, SYLPH endows agents with the ability to reason about the MAPF task through more latent spaces and nuanced contexts, leading to varied responses that can help break ties around symmetric conflicts. Our comparative experiments show that SYLPH achieves state-of-the-art performance, surpassing other learning-based MAPF planners in random, room-like, and maze-like maps, while our ablation studies demonstrate the advantages of each component in SYLPH. We finally experimentally validate our trained policies on hardware in three types of maps, showing how SYLPH allows agents to find high-quality paths under real-life conditions. Our code and videos are available at: marmotlab.github.io/mapf_sylph .},
  archive      = {J_AIJ},
  author       = {Chengyang He and Tanishq Duhan and Parth Tulsyan and Patrick Kim and Guillaume Sartoretti},
  doi          = {10.1016/j.artint.2025.104397},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104397},
  shortjournal = {Artif. Intell.},
  title        = {Social behavior as a key to learning-based multi-agent pathfinding dilemmas},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MATE: Masked optimal transport with dynamic selection for partial label graph learning. <em>AIJ</em>, <em>348</em>, 104396. (<a href='https://doi.org/10.1016/j.artint.2025.104396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of partial label graph learning, in which every graph is associated with a set of candidate labels. Previous methods for weakly supervised graph classification often provide pseudo-labels for graph samples that could be overconfident and biased towards the dominant classes, thus resulting in substantial error accumulation. In this paper, we introduce a new framework named M asked Optim a l T ransport with Dynamic S e lection (MATE) for partial label graph learning, which improves the quality of graph assignments from the perspectives of class balancing and uncertainty mining. In particular, our MATE masks probabilities out of candidate sets and then adopts optimal transport to optimize the assignments without class biases. This design is based on the assumption that the true label distribution is class-balanced or nearly balanced, which is common in various training datasets and real-world scenarios. To further reduce potential noise, we propose a novel scoring metric termed partial energy discrepancy (PED) to evaluate the uncertainty of assignments, and then introduce a dynamic selection strategy that modifies the sample-specific thresholds via momentum updating. Finally, these samples are divided into three levels, i.e., confident, less-confident, and unconfident and each group is trained separately in our collaborative optimization framework. Extensive experiments on various benchmarks demonstrate the superiority of our MATE compared to various state-of-the-art baselines.},
  archive      = {J_AIJ},
  author       = {Yiyang Gu and Binqi Chen and Zihao Chen and Ziyue Qiao and Xiao Luo and Junyu Luo and Zhiping Xiao and Wei Ju and Ming Zhang},
  doi          = {10.1016/j.artint.2025.104396},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104396},
  shortjournal = {Artif. Intell.},
  title        = {MATE: Masked optimal transport with dynamic selection for partial label graph learning},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpreting capsule networks for image classification by routing path visualization. <em>AIJ</em>, <em>348</em>, 104395. (<a href='https://doi.org/10.1016/j.artint.2025.104395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks are popular for computer vision as they often give state-of-the-art performance, but are difficult to interpret because of their complexity. This black box modeling is especially troubling when the application concerns human well-being such as in medical image analysis or autonomous driving. In this work, we propose a technique called routing path visualization for capsule networks, which reveals how much of each region in an image is routed to each capsule. In turn, this technique can be used to interpret the entity that a given capsule detects, and speculate how the network makes a prediction. We demonstrate our new visualization technique on several real world datasets. Experimental results suggest that routing path visualization can precisely localize the predicted class from an image, even though the capsule networks are trained using just images and their respective class labels, without additional information defining the location of the class in the image.},
  archive      = {J_AIJ},
  author       = {Amanjot Bhullar and Michael Czomko and R. Ayesha Ali and Douglas L. Welch},
  doi          = {10.1016/j.artint.2025.104395},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104395},
  shortjournal = {Artif. Intell.},
  title        = {Interpreting capsule networks for image classification by routing path visualization},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relaxed core stability in hedonic games. <em>AIJ</em>, <em>348</em>, 104394. (<a href='https://doi.org/10.1016/j.artint.2025.104394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core is a well-known and fundamental notion of stability in games intended to model coalition formation such as hedonic games: an outcome is core stable if there exists no blocking coalition , i.e., no set of agents that may profit by forming a coalition together. The fact that the cardinality of a blocking coalition, i.e., the number of deviating agents that have to coordinate themselves, can be arbitrarily high, and the fact that agents may benefit only by a tiny amount from their deviation, while they could incur in a higher cost for deviating, suggest that the core is not able to suitably model practical scenarios in large and highly distributed multi-agent systems. For this reason, we consider relaxed core stable outcomes where the notion of permissible deviations is modified along two orthogonal directions: the former takes into account the size q of the deviating coalition, and the latter the amount of utility gain, in terms of a multiplicative factor k , for each member of the deviating coalition. These changes result in two different notions of stability, namely, the q-size core and k-improvement core . We consider fractional hedonic games, that is a well-known subclass of hedonic games for which core stable outcomes are not guaranteed to exist and it is computationally hard to decide non-emptiness of the core; we investigate these relaxed concepts of stability with respect to their existence, computability and performance in terms of price of anarchy and price of stability, by providing in many cases tight or almost tight bounds. Interestingly, the considered relaxed notions of core also possess the appealing property of recovering, in some notable cases, the convergence, the existence and the possibility of computing stable solutions in polynomial time.},
  archive      = {J_AIJ},
  author       = {Angelo Fanelli and Gianpiero Monaco and Luca Moscardelli},
  doi          = {10.1016/j.artint.2025.104394},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104394},
  shortjournal = {Artif. Intell.},
  title        = {Relaxed core stability in hedonic games},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provably efficient information-directed sampling algorithms for multi-agent reinforcement learning. <em>AIJ</em>, <em>348</em>, 104392. (<a href='https://doi.org/10.1016/j.artint.2025.104392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work designs and analyzes a novel set of algorithms for multi-agent reinforcement learning (MARL) based on the principle of information-directed sampling (IDS). These algorithms draw inspiration from foundational concepts in information theory, and are proven to be sample efficient in MARL settings such as two-player zero-sum Markov games (MGs) and multi-player general-sum MGs. For episodic two-player zero-sum MGs, we present three sample-efficient algorithms for learning Nash equilibrium. The basic algorithm, referred to as MAIDS , employs an asymmetric learning structure where the max-player first solves a minimax optimization problem based on the joint information ratio of the joint policy, and the min-player then minimizes the marginal information ratio with the max-player's policy fixed. Theoretical analyses show that it achieves a Bayesian regret of O ˜ ( K ) for K episodes. To reduce the computational load of MAIDS , we develop an improved algorithm called Reg-MAIDS , which has the same Bayesian regret bound while enjoying less computational complexity. Moreover, by leveraging the flexibility of IDS principle in choosing the learning target, we propose two methods for constructing compressed environments based on rate-distortion theory, upon which we develop an algorithm Compressed-MAIDS wherein the learning target is a compressed environment. Finally, we extend Reg-MAIDS to multi-player general-sum MGs and prove that it can learn either the Nash equilibrium or coarse correlated equilibrium in a sample-efficient manner.},
  archive      = {J_AIJ},
  author       = {Qiaosheng Zhang and Chenjia Bai and Shuyue Hu and Zhen Wang and Xuelong Li},
  doi          = {10.1016/j.artint.2025.104392},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104392},
  shortjournal = {Artif. Intell.},
  title        = {Provably efficient information-directed sampling algorithms for multi-agent reinforcement learning},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the design of truthful mechanisms for the capacitated facility location problem with two and more facilities. <em>AIJ</em>, <em>348</em>, 104390. (<a href='https://doi.org/10.1016/j.artint.2025.104390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we explore the Mechanism Design aspects of the m -Capacitated Facility Location Problem ( m -CFLP) on a line, focusing on two frameworks. In the first framework, the number of facilities is arbitrary, all facilities share the same capacity, and the number of agents matches the total capacity of the facilities. In the second framework, we need to locate two facilities, each with a capacity equal to at least half the number of agents. For both frameworks, we propose truthful mechanisms with bounded approximation ratios in terms of Social Cost (SC) and Maximum Cost (MC). When m > 2 , our results stand in contrast to the impossibility results known for the classical m -Facility Location Problem, where capacity constraints are absent. Moreover, all the proposed mechanisms are optimal with respect to MC and either optimal or near-optimal with respect to the SC among anonymous mechanisms. We then establish lower bounds on the approximation ratios that any truthful and deterministic mechanism achieves with respect to SC and MC for both frameworks. Lastly, we run several numerical experiments to empirically evaluate the performances of our mechanisms with respect to the SC or the MC. Our empirical analysis shows that our proposed mechanisms outperform all previously proposed mechanisms applicable in this setting.},
  archive      = {J_AIJ},
  author       = {Gennaro Auricchio and Zihe Wang and Jie Zhang},
  doi          = {10.1016/j.artint.2025.104390},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104390},
  shortjournal = {Artif. Intell.},
  title        = {On the design of truthful mechanisms for the capacitated facility location problem with two and more facilities},
  volume       = {348},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="amc">AMC - 50</h2>
<ul>
<li><details>
<summary>
(2026). Integrating emotion and expectation improves cooperation. <em>AMC</em>, <em>511</em>, 129736. (<a href='https://doi.org/10.1016/j.amc.2025.129736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperation is a key issue attracting widespread attention across various fields. Emotions and expectations jointly participate in the decision-making process, and are key factors influencing the evolution of cooperation. Therefore, this paper proposes a game evolution model that considers the dual influences of emotions and expectations. In the model, a player’s initial strategy depends on their emotions. Subsequently, expectations influence the decision-making process, altering the player’s initial strategy to the current strategy. Specifically, high expectations lead players to maintain their initial strategy, whereas low expectations prompt them to change strategies. Furthermore, the paper analyzes the evolution of cooperation in the prisoner’s dilemma and the influence of expectations. Simulation results show that under high betrayal temptation, players with loneliness and defection would change their initial strategy to cooperation due to low expectations, while those players who initially gather with cooperation strategies maintain the cooperation strategies due to higher expectations, ultimately increasing the cooperation fraction and payoff of the population. Therefore, expectations effectively enhance the cooperation level and payoff of the population. When the scale of individuals changing their strategies based on expectations (ICSE) is large, the effect of expectations on enhancing cooperation and payoff is more pronounced. Frequent consideration of anticipated initial strategy changes also yields the same effect. Additionally, mechanisms of the influence of emotion on payoff, direct emotion interaction and the influence of strategy on emotion collectively contribute to enhancing the significantly evolutionary advantage of friendly emotions and cooperation strategies. This paper contributes to a deeper understanding of the role of expectations in the evolution of emotions and cooperation, laying the groundwork for enhancing social cooperation through expectation management.},
  archive      = {J_AMC},
  author       = {Wen Lu and Shu Liang},
  doi          = {10.1016/j.amc.2025.129736},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129736},
  shortjournal = {Appl. Math. Comput.},
  title        = {Integrating emotion and expectation improves cooperation},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On sketch-and-project methods for solving tensor equations. <em>AMC</em>, <em>511</em>, 129735. (<a href='https://doi.org/10.1016/j.amc.2025.129735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a regular sketch-and-project method for solving linear tensor equations based on the t-product and present its equivalent Fourier domain version, along with several special cases corresponding to existing classical matrix equation methods. Furthermore, we extend this framework via a hierarchical approach to solve generalized Sylvester tensor equations. All the methods are proved to converge linearly in expectation. Finally, numerical experiments demonstrate the efficiency and effectiveness of the proposed approach.},
  archive      = {J_AMC},
  author       = {Ling Tang and Yanjun Zhang and Hanyu Li},
  doi          = {10.1016/j.amc.2025.129735},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129735},
  shortjournal = {Appl. Math. Comput.},
  title        = {On sketch-and-project methods for solving tensor equations},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sampling patterns for zernike-like bases in non-standard geometries. <em>AMC</em>, <em>511</em>, 129727. (<a href='https://doi.org/10.1016/j.amc.2025.129727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zernike polynomials are widely used in optics and ophthalmology due to their direct connection to classical optical aberrations. While orthogonal on the unit disk, their application to discrete data or non-circular domains–such as ellipses, annuli, and hexagons–presents challenges in terms of numerical stability and accuracy. In this work, we extend Zernike-like orthogonal functions to these non-standard geometries using diffeomorphic mappings and construct sampling patterns that preserve favorable numerical conditioning. We provide theoretical bounds for the condition numbers of the resulting collocation matrices and validate them through extensive numerical experiments. As a practical application, we demonstrate accurate wavefront interpolation and reconstruction in segmented mirror telescopes composed of hexagonal facets. Our results show that appropriately transferred sampling configurations, especially Optimal Concentric Sampling and Lebesgue points , allow stable high-order interpolation and effective wavefront modeling in complex optical systems. Moreover, the Optimal Concentric Samplings can be computed with an explicit expression, which is a significant advantage in practice.},
  archive      = {J_AMC},
  author       = {S. Díaz-Elbal and A. Martínez-Finkelshtein and D. Ramos-López},
  doi          = {10.1016/j.amc.2025.129727},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129727},
  shortjournal = {Appl. Math. Comput.},
  title        = {Sampling patterns for zernike-like bases in non-standard geometries},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal information spreading strategy for containing epidemic spreading on higher-order multiplex networks. <em>AMC</em>, <em>511</em>, 129725. (<a href='https://doi.org/10.1016/j.amc.2025.129725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When an epidemic spreads through a population, related information also spreads concurrently, prompting individuals to adopt protective behaviours (e.g., washing hands). Collective behaviour has been shown to play a critical role in shaping the dynamics of epidemic spreading, and higher-order networks offer a natural framework to describe such group interactions in social contact networks. Yet, the interplay between epidemic and information dynamics on higher-order structures is not fully understood, further limiting our understanding of the optimal information spreading strategy for containing epidemic spreading.In this study, we first construct a higher-order multiplex network framework based on simplicial complexes. Then, a coevolutionary spreading model is proposed, integrating epidemic spreading and information spreading on simplicial complexes. The epidemic spreads through both lower-order (pairwise) and higher-order (group) interactions, while information spreads through lower-order interactions in a degree-preferential manner. Using an extended Microscopic Markov Chain Approach, we analytically derive the dynamical equations of the system and compute the basic reproduction number using the next-generation matrix method. Finally, we conduct extensive numerical simulations of the spreading process across various parameter regimes. Our results demonstrate the role of higher-order infections in promoting epidemics. Although information spreading generally suppresses the spread of most epidemics, it can paradoxically enhance the spread of certain epidemics with a very low spreading capacity. Increases in the recovery probabilities of both the disease and the information can weaken the promoting effect of higher-order infection and enhance the suppressive effect of the information. For certain epidemics with weak spreading capabilities but strong recovery capabilities, the spread of information can completely suppress the outbreak of the disease, while the enhancement of higher-order infections can promote the outbreak of these diseases. By analysing the effects of different information spreading strategies on epidemic spreading, we find that the optimal strategy for containing the epidemic is to allow information to spread without degree preference.},
  archive      = {J_AMC},
  author       = {Jiayi Song and Wenjie Li and Yunzhu Xiao and Ling Chen and Chun Yang and Li Qi and Wei Wang},
  doi          = {10.1016/j.amc.2025.129725},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129725},
  shortjournal = {Appl. Math. Comput.},
  title        = {Optimal information spreading strategy for containing epidemic spreading on higher-order multiplex networks},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the fairness and cooperation among free-riders. <em>AMC</em>, <em>511</em>, 129724. (<a href='https://doi.org/10.1016/j.amc.2025.129724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the free-rider problem in peer-to-peer (P2P) systems, where agents enjoy the group effort without contributing their share. We introduce the Free-Rider Game (FRG), a non-cooperative game incorporating a fairness-aware profit allocation rule based on the Robin Hood index. We show that FRG admits strong structural properties. First, making a non-zero contribution is a dominant strategy for any player. Second, a player contributes positively whenever at least one other player does so. Third, FRG admits a unique Nash equilibrium in which each player contributes the fullest, eliminating free riding. Fourth, equilibrium outcomes are proportionally fair, ensuring balanced allocation across agents. Finally, FRG guarantees full participation by embedding fairness directly into the payoff structure, differentiating it from classical public goods games, which often yield zero or partial contributions.},
  archive      = {J_AMC},
  author       = {Avadh Kishor},
  doi          = {10.1016/j.amc.2025.129724},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129724},
  shortjournal = {Appl. Math. Comput.},
  title        = {On the fairness and cooperation among free-riders},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Equilibrium analysis of edge-heterogeneous binary network games. <em>AMC</em>, <em>511</em>, 129723. (<a href='https://doi.org/10.1016/j.amc.2025.129723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies on the equilibrium of binary network games have primarily focused on scenarios characterized by agent heterogeneity, where agents exhibit unique attributes but their interactions with different neighbors remain uniform. In this paper, we investigate the edge-heterogeneous binary network game, a more general framework that incorporates heterogeneity into agent interactions. We establish two sufficient equilibrium conditions under asynchronous best-response dynamics from different perspectives. The first condition requires underlying symmetry in interactions between neighboring agents, integrating and generalizing three classical convergence situations in binary network games. The second condition focuses on network balance, positing that equilibrium is achievable if the coordination value network of a game is structurally balanced. Additionally, for games meeting this condition, we develop a method to predict the final state based on initial state information. These results reveal factors that steer edge-heterogeneous binary network games towards equilibrium, providing valuable insights for controlling such highly nonlinear systems. Lastly, we extend the analysis to higher-order network games and propose an equilibrium condition for edge-heterogeneous 2-order network games.},
  archive      = {J_AMC},
  author       = {Jiawen Wang and Yangyang Luan and Xiaoqun Wu},
  doi          = {10.1016/j.amc.2025.129723},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129723},
  shortjournal = {Appl. Math. Comput.},
  title        = {Equilibrium analysis of edge-heterogeneous binary network games},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Theory and numerics of subspace approximation of eigenvalue problems. <em>AMC</em>, <em>511</em>, 129722. (<a href='https://doi.org/10.1016/j.amc.2025.129722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale eigenvalue problems arise in various fields of science and engineering and demand computationally efficient solutions. In this study, we investigate the subspace approximation for parametric linear eigenvalue problems, aiming to mitigate the computational burden associated with high-fidelity systems. We provide general error estimates under non-simple eigenvalue conditions, establishing some theoretical foundations for understanding the convergence behavior of subspace approximations. Numerical examples, including problems with one-dimensional to three-dimensional spatial domain and one-dimensional to two-dimensional parameter domain, are presented to demonstrate the efficacy of reduced basis method in handling parametric variations in boundary conditions and coefficient fields to achieve significant computational savings while maintaining high accuracy, making them promising tools for practical applications in large-scale eigenvalue computations.},
  archive      = {J_AMC},
  author       = {Siu Wun Cheung and Youngsoo Choi and Seung Whan Chung and Jean-Luc Fattebert and Coleman Kendrick and Daniel Osei-Kuffuor},
  doi          = {10.1016/j.amc.2025.129722},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129722},
  shortjournal = {Appl. Math. Comput.},
  title        = {Theory and numerics of subspace approximation of eigenvalue problems},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Numerical approximation for a stochastic time-fractional cable equation. <em>AMC</em>, <em>511</em>, 129709. (<a href='https://doi.org/10.1016/j.amc.2025.129709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient numerical method is proposed to address a stochastic time-fractional cable equation driven by fractionally integrated additive noise. Under the reasonable assumptions, we rigorously establish for the first time, the existence, uniqueness, and regularity of the mild solution for this equation. For spatial discretization, a semi-discrete scheme is constructed employing the Galerkin FEM, and the optimal spatial error estimate is derived based on the semigroup approach. In temporal discretization, a piecewise constant function is introduced to approximate the noise, leading to the formulation of a regularized stochastic time-fractional cable equation. A detailed proof of the temporal error estimates is provided via the semigroup approach. Numerical experiments demonstrate that the temporal convergence order attains O ( τ 1 / 2 ) for initial data of either smooth or non-smooth type. The order is independent of the parameters α 1 ∈ ( 0 , 1 ) , α 2 ∈ ( 0 , 1 ) , and β ∈ ( 0 , 1 ) in the equation. These results perfectly align with the theoretical predictions.},
  archive      = {J_AMC},
  author       = {Qimin Li and Yubin Yan and Leijie Qiao and Yu Zhang},
  doi          = {10.1016/j.amc.2025.129709},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129709},
  shortjournal = {Appl. Math. Comput.},
  title        = {Numerical approximation for a stochastic time-fractional cable equation},
  volume       = {511},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Neuro-adaptive optimized control for stochastic systems with state constraints: The non-affine faults case. <em>AMC</em>, <em>510</em>, 129720. (<a href='https://doi.org/10.1016/j.amc.2025.129720'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the issue of neuro-adaptive optimal control for stochastic nonlinear systems with state constraints under the presence of non-affine faults. The presence of non-affine faults poses considerable challenges to the stability and performance of the system. To address these challenges, in this article, an adaptive neural network (NN) control scheme is devised within the identifier-critic-actor architecture, enabling the approximation of unknown dynamics and the design of both virtual and actual optimal controllers. In addition, Barrier Lyapunov Functions (BLFs) are utilized to ensure stability while handling state constraints, and a Butterworth low-pass filter is introduced to compensate for high-frequency noise and non-affine nonlinear faults, enhancing system robustness. Furthermore, a novel hybrid event-triggered control (HETC) strategy is proposed to reduce communication and computation demands while optimizing resource utilization. The suggested control strategy guarantees the boundedness of closed-loop signals and keeps all state variables within predefined compact sets. Lastly, the efficacy of the proposed optimal control method is demonstrated through simulation results.},
  archive      = {J_AMC},
  author       = {Tong Zhang and Yiyan Han and Ling Wang and Xin Wang},
  doi          = {10.1016/j.amc.2025.129720},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129720},
  shortjournal = {Appl. Math. Comput.},
  title        = {Neuro-adaptive optimized control for stochastic systems with state constraints: The non-affine faults case},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An entropy stable and well-balanced scheme for an augmented blood flow model with variable geometrical and mechanical properties. <em>AMC</em>, <em>510</em>, 129719. (<a href='https://doi.org/10.1016/j.amc.2025.129719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flow of blood through a vessel can be described by a hyperbolic system of balance equations for the cross-sectional area and averaged velocity as functions of axial spatial position and time. The variable arterial wall rigidity and the equilibrium cross-sectional area are incorporated within the so-called tube law that gives rise to an internal pressure term. This system can be written as a conservative hyperbolic system for five unknowns. An entropy stable scheme for this augmented one-dimensional blood flow model is developed based on entropy conservative numerical flux. It is proved that the proposed scheme is well-balanced in the sense that it preserves both trivial (zero velocity) and non-trivial (non-zero velocity) steady-state solutions. Several demanding numerical tests show that the scheme can handle various kinds of shocks and preserves stationary solutions when geometrical and mechanical properties of the vessel are variable.},
  archive      = {J_AMC},
  author       = {Raimund Bürger and Andrés Guerra and Carlos A. Vega},
  doi          = {10.1016/j.amc.2025.129719},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129719},
  shortjournal = {Appl. Math. Comput.},
  title        = {An entropy stable and well-balanced scheme for an augmented blood flow model with variable geometrical and mechanical properties},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Switching event-triggered control for mean-square exponential synchronization of complex-valued delayed memristive neural networks under hybrid attacks. <em>AMC</em>, <em>510</em>, 129715. (<a href='https://doi.org/10.1016/j.amc.2025.129715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the mean-square exponential synchronization (MSES) of complex-valued delayed memristive neural networks (CVDMNNs) under complex-valued hybrid attacks. Considering the discontinuous right-hand sides of CVDMNNs, the systems are analyzed based on Filippov differential inclusion theory, and the interval matrix method is used to handle the memristive connection weights, thereby constructing error systems that are amenable to analysis. To utilize limited communication resources, a complex-valued switching event-triggered mechanism is introduced. Furthermore, to mitigate the effects of complex-valued hybrid attacks, consisting of complex-valued replay attacks and deception attacks following the Bernoulli distribution, a secure controller is designed that can simultaneously counteract the interference caused by residual terms in the error systems. On this basis, a piecewise Lyapunov functional is constructed, and the sufficient condition for achieving MSES under complex-valued hybrid attacks is derived using Lyapunov stability theory and inequality techniques. Based on the derived synchronization criterion, algorithms are proposed to determine the maximum allowable replay and deception attack rates of the system. Finally, a numerical example is provided to validate the effectiveness and superiority of the proposed scheme.},
  archive      = {J_AMC},
  author       = {Shuai Xiao and Zhen Wang and Hongjue Wang and Yueying Liu and Xia Huang},
  doi          = {10.1016/j.amc.2025.129715},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129715},
  shortjournal = {Appl. Math. Comput.},
  title        = {Switching event-triggered control for mean-square exponential synchronization of complex-valued delayed memristive neural networks under hybrid attacks},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Research on the resilience of reputation mechanism to the cooperative environment in the face of external shocks. <em>AMC</em>, <em>510</em>, 129713. (<a href='https://doi.org/10.1016/j.amc.2025.129713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social development is changing rapidly, and the assumed stability of the cooperative environment is only an ideal state. In the majority of prior research concerning evolutionary games, it is commonly posited that external influences are absent, thereby allowing for an exclusive examination of the system’s intrinsic evolution. However, the situation in the real world is complex, dynamic, and unstable. Therefore, this paper proposes introducing an external shock that compels a change in the rate of cooperation during the evolutionary process. This approach aims to simulate environmental changes in the real world and to observe how these changes impact the rate of cooperation. When facing external shocks, the reputation mechanism has a certain degree of recovery ability, which provides certain support for the reputation theory. This paper also adds the mechanism of learning from historical strategies to the traditional reputation model, optimizing the resilience of the reputation mechanism in the face of external shocks. Simulation results show that history learning can promote the recovery of a cooperative environment faster and more stably, short memory length strengthens the role of temptation to defect, long memory amplifies the impact of the initial state, and the joint effect of history learning rate and memory length is complex.},
  archive      = {J_AMC},
  author       = {Jiaoyuan Wang and Yanlong Yang},
  doi          = {10.1016/j.amc.2025.129713},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129713},
  shortjournal = {Appl. Math. Comput.},
  title        = {Research on the resilience of reputation mechanism to the cooperative environment in the face of external shocks},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evolutionary multigame with perception competition between conformists and imitators. <em>AMC</em>, <em>510</em>, 129712. (<a href='https://doi.org/10.1016/j.amc.2025.129712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perceptual heterogeneity reflects individuals’ different perspectives on the same thing, and competition among individuals with different perceptions of either social dilemmas or payoffs can independently promote cooperation. In this article, we construct a coupled competition mechanism to explore the impact of competition between the two types of perceptions. Specifically, individuals’ differing perceptions of social dilemmas are modeled by the snowdrift game ( S D G ) and the prisoner’s dilemma game ( P D G ), differing perceptions of payoffs are captured by conformists and imitators. Extensive simulations show that the coupled competition mechanism markedly promotes cooperation. P D G players are substantially less competitive than S D G players, which dominate the population. Conformists act as an amplifier, inclined to choose cooperation when cooperators are dominant, thus further promoting cooperation levels. When defectors are dominant, conformists may temporarily choose to defect in the short term, but defection is unsustainable due to lower average accumulated payoffs. We further find that intensified competition among imitators weakens the competitiveness of conformists and diminishes their positive impact on cooperation. Finally, we demonstrate the impact of different proportions of conformists, network structures, and noise levels on the main results to verify the robustness of the model.},
  archive      = {J_AMC},
  author       = {Tianbo An and Ran Zhang and Jian Zhao and Huizhen Zhang and Zhen Wang},
  doi          = {10.1016/j.amc.2025.129712},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129712},
  shortjournal = {Appl. Math. Comput.},
  title        = {Evolutionary multigame with perception competition between conformists and imitators},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prescribed-time reinforcement learning formation control of nonlinear MASs with an unknown dynamic leader. <em>AMC</em>, <em>510</em>, 129711. (<a href='https://doi.org/10.1016/j.amc.2025.129711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the prescribed-time optimal formation control problem for nonlinear multi-agent systems (MASs) with an unknown dynamic leader. The agents need to not only form a predefined formation pattern but also track the leader’s trajectory in a prescribed time. A hierarchical control framework, which includes the communication layer and the tracking control layer, is established to address the formulated issue. In the communication layer, a distributed prescribed-time observer is established to accurately estimate the leader’s information, which can make observation error convergences to zero in a prescribed time. In particular, the leaders’ uncertainties are solved by constructing a novel adaptive law. With the estimated results, a novel transformation relationship and the prescribed-time adjustment function are constructed to guarantee that formation tracking error converges to the predefined accuracy in a prescribed time. Subsequently, the reinforcement learning (RL) algorithm with the fuzzy logic systems (FLSs) is devised to optimize system performance. Based on the Lyapunov stability theory, it is shown that the formation errors ξ i , 1 = x i , 1 − y ^ 0 , i − η i , d are consistently confined within an interval ( tan ( − π 2 μ 2 ) , tan ( π 2 μ 2 ) ) , while all signals of the closed-loop system are bounded. Ultimately, the superiority of the devised algorithm is demonstrated by a representative example.},
  archive      = {J_AMC},
  author       = {Benxin Zhao and Yuan-Xin Li and Zhongsheng Hou},
  doi          = {10.1016/j.amc.2025.129711},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129711},
  shortjournal = {Appl. Math. Comput.},
  title        = {Prescribed-time reinforcement learning formation control of nonlinear MASs with an unknown dynamic leader},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Visualization of escher-like hyperbolic tessellations. <em>AMC</em>, <em>510</em>, 129710. (<a href='https://doi.org/10.1016/j.amc.2025.129710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By combining mathematical principles, modern computer graphics techniques, and the efforts of mathematically inclined artists, we present a visualization method for generating aesthetic patterns in hyperbolic space. To this end, we first establish fast algorithms to construct hyperbolic tilings in the Poincaré disk model. Then, using templates designed by graphic artists, we specify computer techniques to render hyperbolic tilings, which results in Escher-like patterns. Moreover, we present a simple method to realize novel hyperbolic kaleidoscopic effect. To obtain more diverse patterns, we introduce several conformal mappings to create visually appealing tessellations on the other spaces. The proposed methods can be easily implemented using shaders to obtain high-quality tessellations, which have good potential for application in the field of artistic decoration.},
  archive      = {J_AMC},
  author       = {Peichang Ouyang and Kwok Wai Chung and Alain Nicolas and Robert W. Fathauer and David Bailey and Krzysztof Gdawiec},
  doi          = {10.1016/j.amc.2025.129710},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129710},
  shortjournal = {Appl. Math. Comput.},
  title        = {Visualization of escher-like hyperbolic tessellations},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Trapezoid and trapezoidal prism for the maximum relative drawdown: Probability, crash options pricing, and risk. <em>AMC</em>, <em>510</em>, 129708. (<a href='https://doi.org/10.1016/j.amc.2025.129708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximum drawdown (MDD) and maximum relative drawdown (MrDD) are well-known in portfolio management and performance evaluations. They can also form the basis of a stop-loss strategy. But there is no closed-form formula for the probability that the MrDD (MDD) ever reaches some positive threshold over a period of time. This paper focuses on MrDD and employs a random walk to approximate the underlying geometric Brownian motion (GBM) for the price, taking care to match the threshold for faster convergence. Let n be the number of time steps. This paper proposes an O ( n 1.5 ) -sized trapezoid to calculate the above-mentioned probability. The trapezoid can price the crash option with a digital payoff accurately. This paper further proposes an O ( n 2.5 ) -sized trapezoidal prism to price the crash option with a resetting payoff accurately and calculate the expected return rate and common risk measures of an MrDD-based stop-loss strategy.},
  archive      = {J_AMC},
  author       = {Jia-Hao Syu and Yuh-Dauh Lyuu},
  doi          = {10.1016/j.amc.2025.129708},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129708},
  shortjournal = {Appl. Math. Comput.},
  title        = {Trapezoid and trapezoidal prism for the maximum relative drawdown: Probability, crash options pricing, and risk},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The chromatic number of {P2∪P3,banner}-free graphs. <em>AMC</em>, <em>510</em>, 129707. (<a href='https://doi.org/10.1016/j.amc.2025.129707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Borodin and Kostochka conjectured that for any graph G with maximum degree Δ ( G ) ≥ 9 , the chromatic number satisfies χ ( G ) ≤ max { Δ ( G ) − 1 , ω ( G ) } , where ω ( G ) denotes the clique number. While this conjecture remains open for general graphs, we prove its validity for the class of { P 2 ∪ P 3 , banner } -free graphs. Here, P 2 ∪ P 3 represents the disjoint union of a two-vertex path and a three-vertex path, and a banner refers to the graph formed by attaching a pendant vertex to a cycle with four vertices. Our result extends the recent work of Lan and Lin [1], establishing the conjecture for a strictly larger class of graphs.},
  archive      = {J_AMC},
  author       = {Jiali Long and Kaiyang Lan and Yan Wang},
  doi          = {10.1016/j.amc.2025.129707},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129707},
  shortjournal = {Appl. Math. Comput.},
  title        = {The chromatic number of {P2∪P3,banner}-free graphs},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning a robust shape parameter for RBF approximation. <em>AMC</em>, <em>510</em>, 129706. (<a href='https://doi.org/10.1016/j.amc.2025.129706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radial basis functions (RBFs) play an important role in function interpolation, in particular, when considering an arbitrary set of interpolation nodes. The accuracy of the interpolation depends on a parameter called the shape parameter . There are many approaches in the literature on how to appropriately choose it to increase the accuracy of interpolation while avoiding stability issues. However, finding the optimal shape parameter remains a challenge in general. We introduce a new method for determining the shape parameter in RBFs. First, we construct an optimization problem to obtain a shape parameter that leads to a bounded condition number for the interpolation matrix, then, we introduce a data-driven method that controls the condition number of the interpolation matrix to avoid numerically unstable interpolations, while keeping good accuracy. In addition, a fallback procedure is proposed to enforce a strict upper bound on the condition number, as well as a learning strategy to improve the performance of the data-driven method by learning from previously run simulations. Several numerical results are presented to demonstrate the robustness of our strategy in both 1- and 2-dimensional spaces.},
  archive      = {J_AMC},
  author       = {Maria Han Veiga and Faezeh Nassajian Mojarrad and Fatemeh Nassajian Mojarrad},
  doi          = {10.1016/j.amc.2025.129706},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129706},
  shortjournal = {Appl. Math. Comput.},
  title        = {Learning a robust shape parameter for RBF approximation},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gravitational least squares twin support vector machine based on optimal angle for class imbalance learning. <em>AMC</em>, <em>510</em>, 129705. (<a href='https://doi.org/10.1016/j.amc.2025.129705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Gravitational Least Squares Twin Support Vector Machine for Class Imbalance Learning (GLSTSVM-CIL), a novel binary classification method designed to address critical limitations in existing approaches for imbalanced large-scale datasets. Traditional methods like Fuzzy TSVM and KNN-based weighting fail to simultaneously capture both global positional relationships and local density characteristics of data points. Our proposed gravitational weighting function innovatively models data samples as masses influenced by their distance from class centroids and neighborhood density, effectively prioritizing representative points while suppressing outliers. The optimization framework uniquely incorporates angular constraints between hyperplanes to enhance structural risk control and generalization capability. For scalability, we reformulate the solution into a linear system solvable via conjugate gradient methods, avoiding computationally expensive matrix inversions. Comprehensive evaluations on 92 datasets (including synthetic, noisy, medical, text, and large-scale NDC benchmarks) demonstrate GLSTSVM-CIL’s superior performance, particularly in minority-class recognition where it achieves average F1-Score improvements over baseline methods. The model maintains robust Accuracy under high noise (20 %) and extreme class imbalance (ratio 20:1) while ables to process datasets up to 50,000 samples.},
  archive      = {J_AMC},
  author       = {Abdullah Mohammadi and Jalal A. Nasiri and Sohrab Effati},
  doi          = {10.1016/j.amc.2025.129705},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129705},
  shortjournal = {Appl. Math. Comput.},
  title        = {Gravitational least squares twin support vector machine based on optimal angle for class imbalance learning},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Convergence of a positivity preserving logarithmic truncated EM method for SDEs with discontinuous drift coefficients. <em>AMC</em>, <em>510</em>, 129704. (<a href='https://doi.org/10.1016/j.amc.2025.129704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a class of nonlinear stochastic differential equations with positive solutions and discontinuous drift coefficients is studied, considering both theoretical and computational aspects. The theoretical results focus on the existence of a unique positive solution for such SDEs via the approach introduced by Müller-Gronbach et al. (2022), and the computational aspect utilises the truncated Euler-Maruyama method proposed by Li et al. (2023) together with a logarithmic transformation that ensures a positive approximation to the original solution. The convergence of the numerical method is investigated, and the boundedness of the p -th moment is obtained. Finally, the proposed method is used to verify the convergence with the help of some numerical examples.},
  archive      = {J_AMC},
  author       = {Amir Haghighi},
  doi          = {10.1016/j.amc.2025.129704},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129704},
  shortjournal = {Appl. Math. Comput.},
  title        = {Convergence of a positivity preserving logarithmic truncated EM method for SDEs with discontinuous drift coefficients},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enumerating the number of k-matchings in successively amalgamated graphs. <em>AMC</em>, <em>510</em>, 129703. (<a href='https://doi.org/10.1016/j.amc.2025.129703'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the transfer matrix technique using the k -matching vector is developed to compute the number of k -matchings in an arbitrary graph which can be constructed by successive amalgamations over sets of cardinality two. This widely extends known methods from the literature developed for computing the number of k -matchings in benzenoid chains, octagonal chains, cyclooctatetraene chains, and arbitrary cyclic chains. Two examples demonstrating how the present method can be applied are given, one of them being an elaborated chemical example.},
  archive      = {J_AMC},
  author       = {Simon Grad and Sandi Klavžar},
  doi          = {10.1016/j.amc.2025.129703},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129703},
  shortjournal = {Appl. Math. Comput.},
  title        = {Enumerating the number of k-matchings in successively amalgamated graphs},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Community detection methods for GBF-PUM signal approximation on graphs. <em>AMC</em>, <em>510</em>, 129702. (<a href='https://doi.org/10.1016/j.amc.2025.129702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph signal approximation plays a key role in processing irregularly distributed data on graphs, where achieving smooth and computationally efficient interpolation is essential. In this work, we introduce a new approach that combines a spectral community detection technique with the partition of unity method (PUM) applied to signal approximation on graphs. The PUM provides an effective technique for handling irregularly distributed data by dividing the graph into smaller subgraphs, constructing local interpolants and combining them to produce a global approximation. Since the first step in the PUM consists in dividing the graph into disjoint communities, we focus in particular on exploring and testing some community detection algorithms based on the maximization of the modularity. Then, we integrate the PUM with a local graph basis function approximation scheme, resulting in an accurate and computationally efficient approach for graph signal approximation.},
  archive      = {J_AMC},
  author       = {Roberto Cavoretto and Chiara Comoglio and Alessandra De Rossi},
  doi          = {10.1016/j.amc.2025.129702},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129702},
  shortjournal = {Appl. Math. Comput.},
  title        = {Community detection methods for GBF-PUM signal approximation on graphs},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamics of two-strain disease transmission with negative vaccine information and vaccination on multiplex networks. <em>AMC</em>, <em>510</em>, 129701. (<a href='https://doi.org/10.1016/j.amc.2025.129701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the disease transmission, the virus may mutate and novel strains appear. That causes the reduction of the immune effect of the vaccine against the original strain, and the vaccinated individuals may also be infected, which would lead to the generation and dissemination of negative vaccine information. However, the coupled dynamics of multi-strain disease and negative vaccine information has not yet been comprehensively investigated. In this paper, we consider both the original and mutant strains of the disease and introduce vaccination behavior in the propagation process to expand the classic susceptible-infectious-susceptible (SIS) model into five states: susceptible, vaccinated, infected by original strain, infected by mutant strain and recovered. Then, a two-layer network model is proposed to describe the coupled propagation dynamics of the negative vaccine information and the two-strain disease, and the epidemic outbreak thresholds of the two-strain disease are derived by using the Microscopic Markov Chain Approach (MMCA). Subsequently, the numerical results derived from the MMCA are compared with those from Monte-Carlo (MC) simulation to validate the correctness of the former. Finally, the phase diagrams and time history curves are presented to conduct parametric studies on the epidemic thresholds and information-disease transmission dynamics, such as the vaccination cost, vaccine effectiveness and the negative vaccine information. This research demonstrates that reducing the vaccination cost and enhancing the positive publicity of vaccine can effectively prevent the disease spreading when the infection rate of the mutant strain is low. If this infection rate is large, the effective measure is developing specific vaccines against the mutant strain to improve the vaccination efficacy. Those findings provide valuable strategies for the authorities to make appropriate disease prevention measures.},
  archive      = {J_AMC},
  author       = {Lun Liu and Shaorui Geng and Lilin Wei and Zhenyong Lu and Yinghong Ma},
  doi          = {10.1016/j.amc.2025.129701},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129701},
  shortjournal = {Appl. Math. Comput.},
  title        = {Dynamics of two-strain disease transmission with negative vaccine information and vaccination on multiplex networks},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Induced cycles vertex number and (1,2)-domination in cubic graphs. <em>AMC</em>, <em>510</em>, 129700. (<a href='https://doi.org/10.1016/j.amc.2025.129700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A (1,2)-dominating set in a graph G is a set S such that every vertex outside S has at least one neighbor in S , and each vertex in S has at least two neighbors in S . The (1,2)-domination number, γ 1 , 2 ( G ) , is the minimum size of such a set, while c i n d ( G ) is the cardinality of the largest vertex set in G that induces one or more cycles. In this paper, we initiate the study of a relationship between these two concepts and discuss how establishing such a connection can contribute to solving a conjecture on the lower bound of c i n d ( G ) for cubic graphs. We also establish an upper bound on c i n d ( G ) for cubic graphs and characterize graphs that achieve this bound.},
  archive      = {J_AMC},
  author       = {Rija Erveš and Aleksandra Tepeh},
  doi          = {10.1016/j.amc.2025.129700},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129700},
  shortjournal = {Appl. Math. Comput.},
  title        = {Induced cycles vertex number and (1,2)-domination in cubic graphs},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A c++ implementation of the discrete adjoint sensitivity analysis method for explicit adaptive runge-kutta methods enabled by automatic adjoint differentiation and SIMD vectorization. <em>AMC</em>, <em>510</em>, 129699. (<a href='https://doi.org/10.1016/j.amc.2025.129699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A C++ library for sensitivity analysis of optimisation problems involving ordinary differential equations (ODEs) enabled by automatic differentiation (AD) and SIMD (Single Instruction, Multiple data) vectorization is presented. The discrete adjoint sensitivity analysis method is implemented for adaptive explicit Runge-Kutta (ERK) methods. Automatic adjoint differentiation (AAD) is employed for efficient evaluations of products of vectors and the Jacobian matrix of the right hand side of the ODE system. This approach avoids the low-level drawbacks of the black box approach of employing AAD on the entire ODE solver and opens the possibility to leverage parallelization. SIMD vectorization is employed to compute the vector-Jacobian products concurrently. We study the performance of other methods and implementations of sensitivity analysis and we find that our algorithm presents a small advantage compared to equivalent existing software.},
  archive      = {J_AMC},
  author       = {Rui Martins and Evgeny Lakshtanov},
  doi          = {10.1016/j.amc.2025.129699},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129699},
  shortjournal = {Appl. Math. Comput.},
  title        = {A c++ implementation of the discrete adjoint sensitivity analysis method for explicit adaptive runge-kutta methods enabled by automatic adjoint differentiation and SIMD vectorization},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Components of flip graphs of domino tilings in quadriculated cylinder and torus. <em>AMC</em>, <em>510</em>, 129697. (<a href='https://doi.org/10.1016/j.amc.2025.129697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let R be a quadriculated surface, possibly with boundary, consisting of unit squares, and each interior vertex being surrounded by 4 squares. A tiling of R is a placement of dominoes (a pair of adjacent squares) so that there are no gaps or overlaps. The flip graph of R is a graph whose vertices are all tilings of R and two tilings are adjacent if we can obtain one from another by a flip ( 90 ∘ rotation of a pair of side-by-side dominoes). By using graph-theoretical approach, we prove that the flip graph of 2 m × ( 2 n + 1 ) quadriculated cylinder is still connected, but that of 2 m × ( 2 n + 1 ) quadriculated torus consists of two isomorphic components. For a tiling t , we associate an integer, called forcing number, as the minimum number of dominoes in t that is contained in no other tilings. As a consequence, we obtain that the forcing numbers of all tilings in 2 m × ( 2 n + 1 ) quadriculated cylinder and torus form respectively an integer interval whose maximum value is ( n + 1 ) m .},
  archive      = {J_AMC},
  author       = {Qianqian Liu and Jingfeng Wang and Chunmei Li and Heping Zhang},
  doi          = {10.1016/j.amc.2025.129697},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129697},
  shortjournal = {Appl. Math. Comput.},
  title        = {Components of flip graphs of domino tilings in quadriculated cylinder and torus},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An equitable partition based construction of graphs with the same spectral radius. <em>AMC</em>, <em>510</em>, 129696. (<a href='https://doi.org/10.1016/j.amc.2025.129696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An equitable partition of a graph is a remarkable tool that provides valuable spectral information. Among other properties, it is known that the spectral radius of the divisor matrix of any equitable partition equals the spectral radius of the graph. Recently, several methods for construction of families of graphs with the same spectral radius emerged in the literature. In this paper, we develop a unified approach to cyclic-graph constructions by formulating a general method for generating families of connected graphs with a common spectral radius, grounded in the theory of equitable partitions.},
  archive      = {J_AMC},
  author       = {Milica Anđelić and Carlos M. da Fonseca and Zoran Stanić},
  doi          = {10.1016/j.amc.2025.129696},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129696},
  shortjournal = {Appl. Math. Comput.},
  title        = {An equitable partition based construction of graphs with the same spectral radius},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On reduced hamilton walks. <em>AMC</em>, <em>510</em>, 129695. (<a href='https://doi.org/10.1016/j.amc.2025.129695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Hamilton walk in a finite graph is a walk, either open or closed, that traverses every vertex at least once. Here, we introduce Hamilton walks that are reduced in the sense that they avoid immediate backtracking: a reduced Hamilton walk never traverses the same edge forth and back consecutively. While every connected graph admits a Hamilton walk, existence of a reduced Hamilton walk is not guaranteed for all graphs. However, we prove that a reduced Hamilton walk does exist in a connected graph with minimal valency at least 2. Furthermore, given such a graph on n vertices, we present an O ( n 2 ) -time algorithm that constructs a reduced Hamilton walk of length at most n ( n + 3 ) / 2 . Specifically, for a graph belonging to a family of regular expander graphs, we can find a reduced Hamilton walk of length at most c ( 6 n − 2 ) log n + 2 n , where c is a constant independent of n .},
  archive      = {J_AMC},
  author       = {Aleksander Malnič and Rok Požar},
  doi          = {10.1016/j.amc.2025.129695},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129695},
  shortjournal = {Appl. Math. Comput.},
  title        = {On reduced hamilton walks},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Šoltés problem for the kirchhoff index of a graph. <em>AMC</em>, <em>510</em>, 129694. (<a href='https://doi.org/10.1016/j.amc.2025.129694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Kirchhoff index K f ( G ) of a connected graph G is defined as the sum of resistance distances between all pairs of vertices in G . We say that v ∈ V ( G ) is a good vertex if the Kirchhoff index remains unchanged when v is removed, i.e. K f ( G ) = K f ( G − v ) . In 1991, Šoltés studied the Wiener index of a graph and posed the problem of identifying graphs for which the removal of an arbitrary vertex preserves the Wiener index. In this paper, we explore a similar concept: identifying Kirchhoff Šoltés graphs , i.e. graphs in which all vertices are good vertices. We show that the cycle C 5 is a Kirchhoff Šoltés graph. Due to the challenge of finding more examples of such graphs, we shift our focus to several relaxed versions of the Kirchhoff Šoltés problem, where the primary objective is to identify graphs containing at least one good vertex. One of them is the β - Kirchhoff Šoltés problem , which seeks to find an infinite family of graphs in which the proportion of good vertices is at least β , with β ∈ ( 0 , 1 ] being a specified rational number. Another one involves constructing infinite families of graphs where the proportion of good vertices increases and asymptotically approaches a given real number γ ∈ ( 0 , 1 ] as the order of the graph grows. We demonstrate that both relaxed versions have infinitely many solutions. In particular, we prove the existence of infinitely many graphs for which the proportion β of good vertices, 1 / 7 ≤ β < 1 / 5 tends to a certain irrational number. Furthermore, we prove the existence of infinitely many graphs with half good vertices, and for each s ∈ N , we construct an infinite family of graphs whose proportion of good vertices tends to s + 1 2 s + 1 . These findings could be pivotal in addressing the original problem of determining whether there are additional solutions beyond C 5 .},
  archive      = {J_AMC},
  author       = {Kurt Klement Gottwald and Snježana Majstorović Ergotić and Tomislav Došlić},
  doi          = {10.1016/j.amc.2025.129694},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129694},
  shortjournal = {Appl. Math. Comput.},
  title        = {Šoltés problem for the kirchhoff index of a graph},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Secure observer-driven synchronization for complex networks constrained by partial information exchange and limited communication bandwidth. <em>AMC</em>, <em>510</em>, 129693. (<a href='https://doi.org/10.1016/j.amc.2025.129693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the observer-driven secure synchronization control issue for partial information-based complex networks (CNs) subject to bandwidth constraints. Firstly, given that the complete data transmission between CN nodes can not be always realized in practice, the system model of CNs with partial information exchange is specifically introduced. Then, considering the limitation of communication bandwidth, weighted try-once-discard (WTOD) protocol is utilized to enhance the signal transmission efficiency within each node. The delivery of the data adhered to WTOD protocol is further assumed to be compromised by false-data-injection (FDI) attack, which is a well-recognized risk in communication networks. Afterward, distributed secure observer-based synchronization controllers are designed accordingly. Based on defining the observation and synchronization errors, an augmented system model is then established, and the gain matrices for observers and controllers are obtained through an analysis of the stability conditions of the augmented system. Lastly, a numerical example is provided to validate the proposed method’s effectiveness.},
  archive      = {J_AMC},
  author       = {Yan Li and Qirun Hang and Lijuan Zha and Jinliang Liu},
  doi          = {10.1016/j.amc.2025.129693},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129693},
  shortjournal = {Appl. Math. Comput.},
  title        = {Secure observer-driven synchronization for complex networks constrained by partial information exchange and limited communication bandwidth},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Causal state feedback representation for infinite horizon LQ problems of fractional systems. <em>AMC</em>, <em>510</em>, 129692. (<a href='https://doi.org/10.1016/j.amc.2025.129692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the feedback representation problem of the optimal control for infinite horizon linear quadratic optimal control problems of fractional systems. By employing the characterization of the optimal control pair and a family of projection operators, we derive the causal state feedback representations which depend only on the history value of the state and does not rely on further state value. Finally, two illustrative examples are included.},
  archive      = {J_AMC},
  author       = {Jianping Huang and Huacheng Zhou},
  doi          = {10.1016/j.amc.2025.129692},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129692},
  shortjournal = {Appl. Math. Comput.},
  title        = {Causal state feedback representation for infinite horizon LQ problems of fractional systems},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Observer-based leader-follower bipartite consensus for linear multiagent systems with communication link faults. <em>AMC</em>, <em>510</em>, 129690. (<a href='https://doi.org/10.1016/j.amc.2025.129690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the observer-based leader-follower bipartite consensus (LFBC) problem for linear multiagent systems (MASs) with unknown communication link faults. Firstly, by designing the corresponding leader state observers for the leader and each follower respectively, and adaptively adjusting the coupling strength, the weight changes due to unknown communication link faults are solved. Secondly, novel double event-triggered mechanisms (DETMs) based on observers are proposed, which can realize communication and observers updating asynchronously and help to save communication resources. The triggering threshold is designed based on the adaptive leader state error, avoiding the need for continuous information exchange with neighboring agents. Afterwards, our proposed leader state observer-based approaches are applied to the control, aiming to ensure system performance and stabilize the handling of system faults. Finally, two simulation examples are presented to verify the effectiveness of the proposed control strategy.},
  archive      = {J_AMC},
  author       = {Dongsheng Yang and Jing He and Jiayue Sun and Juan Zhang},
  doi          = {10.1016/j.amc.2025.129690},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129690},
  shortjournal = {Appl. Math. Comput.},
  title        = {Observer-based leader-follower bipartite consensus for linear multiagent systems with communication link faults},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bipartite containment control of multi-agent systems under channel imperfections: When bit-flips meet packet-losses. <em>AMC</em>, <em>510</em>, 129689. (<a href='https://doi.org/10.1016/j.amc.2025.129689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates bipartite containment control of linear multi-agent systems under channel imperfections using source binary coding schemes with bit-flips and packet-losses. The communication channels are allocated through an average allocation protocol. The source binary coding scheme for measurement outputs is employed, and a finite-length bit stream is designed to satisfy the requirement of channel capacity. The paper aims to establish mean-square bipartite containment conditions under communication constraints such that the containment error is bounded. First, the statistical properties of the aggregated error are derived. Then, a sufficient condition is obtained to ensure bipartite containment in the mean-square sense. Furthermore, with the free matrix approach and the matrix inequality method, the control gain is obtained to ensure the existence of a desired controller. Finally, two examples are provided to illustrate the effectiveness of the results.},
  archive      = {J_AMC},
  author       = {Shaobo Zheng and Lei Zhou},
  doi          = {10.1016/j.amc.2025.129689},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129689},
  shortjournal = {Appl. Math. Comput.},
  title        = {Bipartite containment control of multi-agent systems under channel imperfections: When bit-flips meet packet-losses},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Asymptotic analysis of the first eigenvalue for the sturm-liouville problems with coupled boundary conditions. <em>AMC</em>, <em>510</em>, 129688. (<a href='https://doi.org/10.1016/j.amc.2025.129688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper is concerned with the asymptotic behavior of the first eigenvalue on the jump set of the Sturm-Liouville eigenvalue problems with coupled boundary conditions. By transforming the original problem into two problems with separated boundary conditions, we obtain the asymptotic formula of the first eigenvalue and the first normalized eigenfunction in terms of the coefficients in the equations. Particularly, we prove that the unique zero of the first eigenfunction tends to the zero of the first eigenfunction of the corresponding Laplace problem. The results indicate that the asymptotic behavior is only related to the values of the coefficients in the neighborhood of the endpoints.},
  archive      = {J_AMC},
  author       = {Xinyu Zhang and Jiangang Qi and Chunyan Sun},
  doi          = {10.1016/j.amc.2025.129688},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129688},
  shortjournal = {Appl. Math. Comput.},
  title        = {Asymptotic analysis of the first eigenvalue for the sturm-liouville problems with coupled boundary conditions},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stokes–Brinkman–Darcy models for fluid–porous systems: Derivation, analysis and validation. <em>AMC</em>, <em>510</em>, 129687. (<a href='https://doi.org/10.1016/j.amc.2025.129687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flow interaction between a plain-fluid region in contact with a porous layer attracted significant attention from modelling and analysis sides due to numerous applications in biology, environment and industry. In the most widely used coupled model, fluid flow is described by the Stokes equations in the free-flow domain and Darcy’s law in the porous medium, and complemented by the appropriate interface conditions. However, traditional coupling concepts are restricted, with a few exceptions, to one-dimensional flows parallel to the fluid–porous interface. In this work, we use an alternative approach to model interaction between the plain-fluid domain and porous medium by considering a transition zone, and propose the full- and hybrid-dimensional Stokes–Brinkman–Darcy models. In the first case, the equi-dimensional Brinkman equations are considered in the transition region, and the appropriate interface conditions are set on the top and bottom of the transition zone. In the latter case, we perform a dimensional model reduction by averaging the Brinkman equations in the normal direction and using the proposed transmission conditions. The well-posedness of both coupled problems is proved, and some numerical simulations are carried out in order to validate the concepts.},
  archive      = {J_AMC},
  author       = {Linheng Ruan and Iryna Rybak},
  doi          = {10.1016/j.amc.2025.129687},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129687},
  shortjournal = {Appl. Math. Comput.},
  title        = {Stokes–Brinkman–Darcy models for fluid–porous systems: Derivation, analysis and validation},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamics of cooperative evolution with leader-follower hierarchy under information uncertainty in two-layer grid networks. <em>AMC</em>, <em>510</em>, 129686. (<a href='https://doi.org/10.1016/j.amc.2025.129686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drawing on the idea of leader-follower game theory, this paper investigates the evolution of cooperative behavior in two-layer grid networks. The two-layer network is divided into a leader layer (upper layer) and a follower layer (lower layer), where the snowdrift game (SDG) and the prisoner’s dilemma game (PDG) are conducted, respectively. Based on an updating mechanism of the modified Fermi probability function that incorporates strategy alignment, the leader layer first completes strategy update, and the follower layer then updates its strategy after acquiring information from the upper layer via perception probability. Numerical simulations reveal that the cost-benefit ratio significantly influences the differences in perception strategies between layers. Specifically, at lower ratios, there is a positive correlation between followers’ cooperation and their perception probability, whereas leaders exhibit a negative correlation. The opposite trends are observed at higher ratios. Compared with single-layer networks, the leader-follower structure with two-layer networks significantly enhances the cooperation in the follower layer and also lightly fosters the cooperation in leader layer. Additionally, factors such as inter-layer coupling strength, rewards and punishments for strategy consistency, and selection intensity all promote the emergence of cooperation to varying degrees. This leader-follower hierarchical game offers a new research paradigm for interaction mechanisms in complex social systems.},
  archive      = {J_AMC},
  author       = {Bolin Yang and Guanghui Yang},
  doi          = {10.1016/j.amc.2025.129686},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129686},
  shortjournal = {Appl. Math. Comput.},
  title        = {Dynamics of cooperative evolution with leader-follower hierarchy under information uncertainty in two-layer grid networks},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforcement learning in evolutionary game theory: A brief review of recent developments. <em>AMC</em>, <em>510</em>, 129685. (<a href='https://doi.org/10.1016/j.amc.2025.129685'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid progress of artificial intelligence, the integration of evolutionary game theory and reinforcement learning has become a hot research frontier in the last years. Evolutionary game theory provides a mathematical framework for depicting the strategy interaction among individuals, traditionally based on pre-defined, rule-based strategy update protocols. In contrast, reinforcement learning enables agents to adaptively select optimal actions through trial-and-error learning, hence better reflecting real-world decision-making. These complementary features create the foundation for their convergence. Our paper presents a didactic review of contemporary reinforcement learning applications in evolutionary game theory, focusing on those recently published works which open novel research paths to enrich our understanding of mutualistic cooperation. We summarize major concepts and terms, including the basic problem of collective cooperation, modeling of complex population dynamics, influence of algorithmic parameters, and the combination of deep learning. Finally, we discuss prospects for this interdisciplinary field, emphasizing the importance of intelligent learning through the lens of evolutionary game.},
  archive      = {J_AMC},
  author       = {Kai Xie and Attila Szolnoki},
  doi          = {10.1016/j.amc.2025.129685},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129685},
  shortjournal = {Appl. Math. Comput.},
  title        = {Reinforcement learning in evolutionary game theory: A brief review of recent developments},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Observer-based reachable set synthesis for multi-agent systems: A sampling-based distributed event-triggered strategy. <em>AMC</em>, <em>510</em>, 129683. (<a href='https://doi.org/10.1016/j.amc.2025.129683'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of reachable set synthesis for a class of multi-agent systems. Considering the limited resources for communication between agents, a dual-end sampling mechanism is introduced to reduce the communication load. For the sampled signals at the output end, the cubic spline interpolation method is used to construct a fitting function to approximate the dynamic output signals, and a state observer is constructed according to the fitting function to estimate the system state of each agent. At the input side, the sampling distributed event triggering mechanism is used to design an event-based distributed observation control strategy to ensure that the tracking error is bounded. Finally, the results of the simulations substantiate the validity of the conclusions.},
  archive      = {J_AMC},
  author       = {Mingde Liu and Liang Zhang and Ning Zhao and Xinjun Wang and Yongchao Liu},
  doi          = {10.1016/j.amc.2025.129683},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129683},
  shortjournal = {Appl. Math. Comput.},
  title        = {Observer-based reachable set synthesis for multi-agent systems: A sampling-based distributed event-triggered strategy},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Energy-conserving kansa methods for hamiltonian wave equations. <em>AMC</em>, <em>510</em>, 129682. (<a href='https://doi.org/10.1016/j.amc.2025.129682'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a fast, constrained meshfree solver designed specifically to inherit energy conservation (EC) in second-order time-dependent Hamiltonian wave equations. For discretization, we adopt the Kansa method, also known as the kernel-based collocation method, combined with time-stepping. This approach ensures that the critical structural feature of energy conservation is maintained over time by embedding a quadratic constraint into the definition of the numerical solution. To address the computational challenges posed by the nonlinearity in the Hamiltonian wave equations and the EC constraint, we propose a fast iterative solver based on the Newton method with successive linearization. This novel solver significantly accelerates the computation, making the method highly effective for practical applications. Numerical comparisons with the traditional secant methods highlight the competitive performance of our scheme. These results demonstrate that our method not only conserves the energy but also offers a promising new direction for solving Hamiltonian wave equations more efficiently. While we focus on the Kansa method and corresponding convergence theories in this study, the proposed solver is based solely on linear algebra techniques and has the potential to be applied to EC constrained optimization problems arising from other PDE discretization methods.},
  archive      = {J_AMC},
  author       = {Xiaobin Li and Meng Chen and Zhengjie Sun and Leevan Ling and Siqing Li},
  doi          = {10.1016/j.amc.2025.129682},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129682},
  shortjournal = {Appl. Math. Comput.},
  title        = {Energy-conserving kansa methods for hamiltonian wave equations},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High order nonstandard finite-difference methods. <em>AMC</em>, <em>510</em>, 129681. (<a href='https://doi.org/10.1016/j.amc.2025.129681'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonstandard finite difference (NSFD) methods have been considered to overcome some issues of standard methods, particularly when the numerical solution must preserve important properties of the exact solution. These issues increase for high order methods. In this paper we first derive a general procedure to obtain unconditionally positive second order NSFD methods. Furthermore, by suitably adding some parameters α i within these schemes, we show that it is still possible to get positivity, and also to preserve other qualitative properties of the exact solution. In fact, for each particular problem we can get optimal values of α i that guarantee positivity, elementary stability and the minimization of the local truncation error, being possible to achieve also third order nonstandard schemes, which are not present in the literature. As an example of use, we employ the developed theory to derive positive and elementary stable NSFD methods of order one, two and three for a predator-prey model, showing their advantages over other nonstandard methods from the literature.},
  archive      = {J_AMC},
  author       = {D. Conte and G. Pagano and T. Roldán},
  doi          = {10.1016/j.amc.2025.129681},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129681},
  shortjournal = {Appl. Math. Comput.},
  title        = {High order nonstandard finite-difference methods},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Consensus control for multi-agent systems with unknown fading channels and limited bandwidth. <em>AMC</em>, <em>510</em>, 129680. (<a href='https://doi.org/10.1016/j.amc.2025.129680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the consensus of multi-agent systems (MASs) in the presence of fading channels and limited communication bandwidth. These issues will lead to inaccurate and energy constraints of communication data respectively, which will not be possible for MASs to achieve consensus. To this end, this paper proposes a variable structure encoding-decoding scheme (VS-EDS), which includes an encoder with a unitary signal generator and a corresponding decoder with an adaptive activation module. The advantages of the proposed VS-EDS are mainly in three aspects. First, it avoids the need for existing methods to perform a large amount of statistical work on the statistics of fading gains before the system runs. Second, it can eliminate the communication errors caused by fading. At the same time, it can adapt to the changing communication network environment. In addition, in order to achieve consensus control, a distributed protocol based on the VS-EDS is designed. Finally, the feasibility and effectiveness of the VS-EDS are demonstrated through comparative simulations.},
  archive      = {J_AMC},
  author       = {Caibin Yao and Yiwen Qi and Ziyu Qu and Wu Wang and Zonghua Zheng},
  doi          = {10.1016/j.amc.2025.129680},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129680},
  shortjournal = {Appl. Math. Comput.},
  title        = {Consensus control for multi-agent systems with unknown fading channels and limited bandwidth},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On deep learning for computing the dynamic initial margin and margin value adjustment. <em>AMC</em>, <em>510</em>, 129679. (<a href='https://doi.org/10.1016/j.amc.2025.129679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work addresses the challenge of training neural networks for Dynamic Initial Margin (DIM) computation in counterparty credit risk, a task traditionally burdened by the high costs associated with generating training datasets through nested Monte Carlo (MC) simulations. By condensing the initial market state variables into an input vector, determined through an interest rate model and a parsimonious parameterization of the current interest rate term structure, we construct a training dataset where the labels are future realizations, generated with a single MC path, of the Initial Margin (IM) variable. Since DIM is defined as the conditional expectation of IM, the latter can be understood as noisy and unbiased samples of DIM, allowing the application of deep learning regression techniques to its computation. To this end, a multi-output neural network structure is employed to handle DIM as a time-dependent function, facilitating training across a mesh of monitoring times. This methodology offers significant advantages: it reduces the dataset generation cost to a single MC execution and parameterizes the neural network by initial market state variables, obviating the need for repeated training. Experimental results demonstrate the approach’s convergence properties and robustness across different interest rate models (Hull-White and Cox-Ingersoll-Ross) and portfolio complexities, validating its general applicability and efficiency in more realistic scenarios.},
  archive      = {J_AMC},
  author       = {Joel P. Villarino and Alvaro Leitao},
  doi          = {10.1016/j.amc.2025.129679},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129679},
  shortjournal = {Appl. Math. Comput.},
  title        = {On deep learning for computing the dynamic initial margin and margin value adjustment},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On solutions of a coupled system of quantum integral equations in banach spaces. <em>AMC</em>, <em>510</em>, 129678. (<a href='https://doi.org/10.1016/j.amc.2025.129678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This attempt studies the existence of solutions for a coupled system of quantum integral and quadratic integral equations via generalized Darbo’s fixed point theorem, namely, Petryshyan’s fixed point theorem. Finally, we conclude with a concrete numerical example, which confirms that our results can apply to a wide range of quantum integral equations.},
  archive      = {J_AMC},
  author       = {Hamid Reza Sahebi and Manochehr Kazemi and Mohamed M.A. Metwali},
  doi          = {10.1016/j.amc.2025.129678},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129678},
  shortjournal = {Appl. Math. Comput.},
  title        = {On solutions of a coupled system of quantum integral equations in banach spaces},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Arbitrary-order sensitivity analysis of frequency response functions using hypercomplex automatic differentiation and spectral finite elements. <em>AMC</em>, <em>510</em>, 129677. (<a href='https://doi.org/10.1016/j.amc.2025.129677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately computing sensitivities of Frequency Response Functions (FRFs) is crucial for analyzing the dynamic behavior of structures by enabling quantifying the impact that variations in geometry, material properties, and boundary conditions have on their dynamic response. However, one of the primary challenges in calculating accurate sensitivities lies in the numerical differentiation required to estimate the sensitivities of the FRFs. This paper presents a new method called the Hypercomplex Spectral Finite Elements Method (HYPAD-SFEM). HYPAD-SFEM combines the HYPercomplex Automatic Differentiation method (HYPAD) with the Spectral Finite Elements Method (SFEM) to compute highly accurate arbitrary-order sensitivities of the FRFs. To demonstrate and verify the method's performance and accuracy, we analyzed a truss structure under a harmonic axial load and compared the results with analytical equations, Finite Differences (FD), and traditional Automatic Differentiation (AD). Excellent agreement was observed between the computed displacements and their sensitivities, considering material properties, geometry, and boundary conditions. The application of HYPAD-SFEM was then extended to a more complex problem by performing shape sensitivity analysis of the dynamic behavior of a phononic lattice. Again, excellent agreement was found between HYPAD, FD and AD. In general, the proposed HYPAD-SFEM ensures high accuracy independent of the perturbation step selection, alleviating FD’s fundamental issues. Moreover, HYPAD-SFEM delivers superior computational performance when compared with traditional AD. Hence, HYPAD-SFEM provides an effective approach for FRF sensitivity analysis, facilitating design optimization, parameter tuning, robustness analysis, and model updating and validation in structural dynamics.},
  archive      = {J_AMC},
  author       = {Juan David Navarro and Juan C. Velasquez-Gonzalez and Mauricio Aristizabal and Arturo Montoya and Harry R. Millwater and David Restrepo},
  doi          = {10.1016/j.amc.2025.129677},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129677},
  shortjournal = {Appl. Math. Comput.},
  title        = {Arbitrary-order sensitivity analysis of frequency response functions using hypercomplex automatic differentiation and spectral finite elements},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hinderance of cooperation by individual solutions: Evolutionary dynamics of three-strategy games combining the prisoner’s dilemma and stag hunt. <em>AMC</em>, <em>510</em>, 129676. (<a href='https://doi.org/10.1016/j.amc.2025.129676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study analyzes a three-strategy game that integrates elements of the prisoner’s dilemma and stag hunt. The framework builds upon recent research that determines the impact of individual solutions. Individuals adopting such solutions do not free ride on the cooperative efforts of others; rather, they act just sufficiently to prevent adverse consequences for themselves. We hypothesize that individual solutions function analogously to the defection strategy in the stag hunt game. This study examines the effects of orthodox free riding and individual solutions on the evolution of cooperation. Our analysis reveals that in well-mixed populations, the only stable rest point is the one in which all players opt for individual solutions. When interactions are structured on a square lattice, cooperation levels exhibit modest improvements, primarily sustained through cyclic dominance. Payoff values favorable to cooperation result in full cooperation; however, rare mutations can disrupt the cooperative equilibrium, promoting the adoption of individual solutions. Our analysis aligns with experimental observations and illustrates the importance of overcoming reliance on individual solutions to better understand the emergence of cooperation.},
  archive      = {J_AMC},
  author       = {Hirofumi Takesue},
  doi          = {10.1016/j.amc.2025.129676},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129676},
  shortjournal = {Appl. Math. Comput.},
  title        = {Hinderance of cooperation by individual solutions: Evolutionary dynamics of three-strategy games combining the prisoner’s dilemma and stag hunt},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stability analysis of Runge–Kutta methods for nonlinear delay-integro-differential-algebraic equations. <em>AMC</em>, <em>510</em>, 129675. (<a href='https://doi.org/10.1016/j.amc.2025.129675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to examining the stability of Runge–Kutta methods for solving nonlinear delay-integro-differential-algebraic equations (DIDAEs). The stability of exact solution for nonlinear DIDAEs is obtained by using the Halanay’s inequality. Hybrid numerical schemes combining Runge–Kutta methods and compound quadrature rules are analyzed for nonlinear DIDAEs. Criteria for ensuring the global and asymptotic stability of the proposed schemes are established. Several numerical examples are provided to validate the theoretical findings.},
  archive      = {J_AMC},
  author       = {Gehao Wang and Yuexin Yu},
  doi          = {10.1016/j.amc.2025.129675},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129675},
  shortjournal = {Appl. Math. Comput.},
  title        = {Stability analysis of Runge–Kutta methods for nonlinear delay-integro-differential-algebraic equations},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sine-transform-based fast solvers for riesz fractional nonlinear schrödinger equations with attractive nonlinearities. <em>AMC</em>, <em>510</em>, 129674. (<a href='https://doi.org/10.1016/j.amc.2025.129674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents fast solvers for linear systems arising from the discretization of fractional nonlinear Schrödinger equations with Riesz derivatives and attractive nonlinearities. These systems exhibit complex symmetry, indefiniteness, and a d -level diagonal-plus-Toeplitz structure. We propose a Toeplitz-based anti-symmetric and normal splitting iteration method for the equivalent real block linear systems, ensuring unconditional convergence. By integrating this iteration method with sine-transform-based preconditioning, we introduce a novel preconditioner that enhances the convergence rate of Krylov subspace methods. Both theoretical and numerical analyses demonstrate that the new preconditioner exhibits a parameter-free property, and favorable eigenvalue clustering nature of the corresponding preconditioned coefficient matrix, and the associated preconditioned GMRES method converges independently of the mesh size in space and the order of Riesz fractional derivatives.},
  archive      = {J_AMC},
  author       = {Chao Chen and Xi Yang and Fei-Yan Zhang},
  doi          = {10.1016/j.amc.2025.129674},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129674},
  shortjournal = {Appl. Math. Comput.},
  title        = {Sine-transform-based fast solvers for riesz fractional nonlinear schrödinger equations with attractive nonlinearities},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A meshless point collocation solver for elliptic boundary value problems. <em>AMC</em>, <em>510</em>, 129673. (<a href='https://doi.org/10.1016/j.amc.2025.129673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a strong-form meshless point collocation (MPC) solver for the Poisson equation. The Poisson equation allows us to compute approximate pressure corrections and ensure the incompressibility of the velocity field or to solve for the stream function and vorticity. We discretize the spatial domain using quadratic triangular elements in 2D and tetrahedral elements in 3D. The element nodes, including the vertices and edge midpoints, define the point cloud used in the MPC method. We determine the support domain for each using the mesh’s connectivity. When constructing the stiffness matrix, the resulting algebraic systems have the same bandwidth as those generated by the finite element (FE) method. We use direct and iterative solvers to assess the accuracy and efficiency of the MPC method. Our solution strategy enables automatic mesh generation, as nodes are utilized directly in the interpolation construction, eliminating the need to evaluate mesh quality. Finally, we investigate the efficiency of the MPC method in solving linear systems in 3D with a large number of nodes.},
  archive      = {J_AMC},
  author       = {G.C. Bourantas and A. Sakellarios and N. Malamos and V.C. Loukopoulos and V.N. Burganos and D.I. Fotiadis and V.M. Calo},
  doi          = {10.1016/j.amc.2025.129673},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129673},
  shortjournal = {Appl. Math. Comput.},
  title        = {A meshless point collocation solver for elliptic boundary value problems},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Solving fuzzy non-homogeneous linear differential systems with piecewise constant arguments involving the short-memory variable-order caputo fractional derivative. <em>AMC</em>, <em>510</em>, 129672. (<a href='https://doi.org/10.1016/j.amc.2025.129672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish an explicit solution formula for a linear class of fractional differential systems with piecewise constant arguments (FDSs-PCA), incorporating generalized variable-order fractional derivatives (VO-FDs) of order in the interval (0,1). The effectiveness and practical relevance of our result are demonstrated through several illustrative examples.},
  archive      = {J_AMC},
  author       = {Nguyen Dinh Phu and Lai Van Phut and Ngo Van Hoa},
  doi          = {10.1016/j.amc.2025.129672},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129672},
  shortjournal = {Appl. Math. Comput.},
  title        = {Solving fuzzy non-homogeneous linear differential systems with piecewise constant arguments involving the short-memory variable-order caputo fractional derivative},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Basket options with volatility skew: Calibrating a local volatility model by sample rearrangement. <em>AMC</em>, <em>510</em>, 129669. (<a href='https://doi.org/10.1016/j.amc.2025.129669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pricing of derivatives tied to baskets of assets demands a sophisticated framework that aligns with the available market information to capture the intricate non-linear dependency structure among the assets. We describe the dynamics of the multivariate process of constituents with a copula model and propose an efficient method to extract the dependency structure from the market. The proposed method generates coherent sets of samples of the constituents process through systematic sampling rearrangement. These samples are then utilized to calibrate a local volatility model (LVM) of the basket process, which is used to price basket derivatives. We show that the method is capable of efficiently pricing basket options based on a large number of basket constituents, accomplishing the calibration process within a matter of seconds, and achieving near-perfect calibration to the index options of the market.},
  archive      = {J_AMC},
  author       = {Nicola F. Zaugg and Lech A. Grzelak},
  doi          = {10.1016/j.amc.2025.129669},
  journal      = {Applied Mathematics and Computation},
  month        = {2},
  pages        = {129669},
  shortjournal = {Appl. Math. Comput.},
  title        = {Basket options with volatility skew: Calibrating a local volatility model by sample rearrangement},
  volume       = {510},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="artmed">ARTMED - 9</h2>
<ul>
<li><details>
<summary>
(2025). The interpretable deep learning framework and validation for seizure detection in pediatric electroencephalography: An improved accuracy and performance analysis. <em>ARTMED</em>, <em>170</em>, 103276. (<a href='https://doi.org/10.1016/j.artmed.2025.103276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes an interpretable deep learning framework and compares the two novel models. A fully convolutional network with squeeze-and-excitation modules (SE-FCN) is designed to enhance spatial sensitivity and retain temporal resolution. In addition, a transformer-based model (TransNet) is developed to capture temporal and channel-wise dependencies via self-attention. These two models output channel saliency weights to the EEG electrode space and generate heatmaps for inferring potential epileptogenic zones. Deep learning primarily adopts convolutional neural networks (CNNs) or sequence generation networks (SGNs) and faces the limitations. For instance, CNN-based models often lack hierarchical modeling and fail to quantify channel-wise contributions, hindering spatial localization. SGN-based models struggle to capture complex spatiotemporal dependencies and typically lack adaptive attention tailored to electroencephalography (EEG) characters. Epileptic seizure detection is vital for effective clinical intervention and existing methods operated as black boxes, limiting clinical interpretability. This study evaluates the models on the CHB-MIT pediatric EEG dataset using a subject-independent cross-validation protocol. SE-FCN achieves an AUC of 0.89 and accuracy of 86.7 %, while TransNet achieves an AUC of 0.92 and accuracy of 86.4 %. Saliency maps from both models demonstrate high consistency and enable categorization of 22 patients into five groups based on inferred seizure origins.},
  archive      = {J_ARTMED},
  author       = {Yu Zhou and Yuxin Gao and Qiang Li and Ruiheng Wu and Aiping Yang and Ming-Lang Tseng},
  doi          = {10.1016/j.artmed.2025.103276},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103276},
  shortjournal = {Artif. Intell. Med.},
  title        = {The interpretable deep learning framework and validation for seizure detection in pediatric electroencephalography: An improved accuracy and performance analysis},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding the cortical responses to mechanical wrist perturbations: A two-step shared structure NARX method. <em>ARTMED</em>, <em>170</em>, 103273. (<a href='https://doi.org/10.1016/j.artmed.2025.103273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shared structure nonlinear autoregressive with exogenous input (NARX) model is a promising tool for exploring cortical responses mechanism to external stimuli, essential for advancing our understanding of brain function and developing methods for direct brain information encoding. In this paper, we proposed a two-step method to overcome limitations in existing method, which neglect data relationships and rely on a greedy search for regression terms, leading to less accurate models. In our approach, data from multiple trials are concatenated, and then the orthogonal forward regression (OFR) algorithm identifies model terms in first step, enhancing inter-trial connections and establishing a preliminary model for each subject. Shared model terms across subjects are then used to construct a general target model. Next, non-shared regression terms that best represent population-level information are identified, using adaptive multi-population genetic algorithms, and use to enhance the target models' descriptive power. Simulations results show significant competitiveness in terms of accuracy as compared to other state-of-the-art methods. When applied to real electroencephalography signals under mechanical disturbance, structural and parameter analysis revealed consistent neural response patterns across subjects, with subject-specific responses likely stemming from muscle feedback. Frequency response analysis further suggests that the brain may generate motor inhibition signals based on sensory inputs to maintain a pre-disturbance resting state. These findings provide valuable insights into cortical response mechanisms and have potential implications for future brain information encoding research.},
  archive      = {J_ARTMED},
  author       = {Nan Zheng and Yurong Li and Wuxiang Shi and Jiyu Tan},
  doi          = {10.1016/j.artmed.2025.103273},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103273},
  shortjournal = {Artif. Intell. Med.},
  title        = {Decoding the cortical responses to mechanical wrist perturbations: A two-step shared structure NARX method},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven dynamic grouping for adaptive clinical trials: Rethinking randomization in precision medicine. <em>ARTMED</em>, <em>170</em>, 103272. (<a href='https://doi.org/10.1016/j.artmed.2025.103272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating artificial intelligence into biomedical human subjects research is transforming traditional experimental paradigms. This perspective introduces the concept of “dynamic grouping,” wherein artificial intelligence (AI) systems continuously reassign participants across experimental conditions based on real-time biomarker data and clinical response patterns. Unlike traditional biomedical research designs that rely on fixed treatment and control groups, dynamic grouping allows participant assignments to evolve throughout the study. We examine the ethical implications, methodological challenges, and research opportunities associated with this paradigm, particularly in clinical trials, precision medicine, and digital therapeutics. To support this analysis, we present three computational simulations that quantify its impact: (i) a heterogeneity simulation demonstrating how patient variability affects the advantage of dynamic grouping, (ii) a statistical power analysis showing potential sample size reductions in adaptive designs, and (iii) a clinical outcome distribution analysis highlighting how dynamic grouping reduces negative treatment outcomes and optimizes patient responses. Our findings suggest that dynamic grouping can improve treatment effectiveness, enhance resource allocation, and increase statistical efficiency, although it also raises new challenges for causal inference, informed consent, and regulatory oversight. As AI continues to reshape medical research, adapting ethical and methodological frameworks will be essential for its responsible implementation.},
  archive      = {J_ARTMED},
  author       = {Madhur Mangalam},
  doi          = {10.1016/j.artmed.2025.103272},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103272},
  shortjournal = {Artif. Intell. Med.},
  title        = {AI-driven dynamic grouping for adaptive clinical trials: Rethinking randomization in precision medicine},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining multi-electrode and multi-wave electroencephalogram based time-interval temporal patterns for improved classification capabilities and explainability. <em>ARTMED</em>, <em>170</em>, 103269. (<a href='https://doi.org/10.1016/j.artmed.2025.103269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-computer interface (BCI) systems, and particularly electroencephalogram (EEG) based BCI systems, have become more widely used in recent years and are utilized in various applications and domains ranging from medicine and marketing to games and entertainment. While different algorithms have been used to analyze EEG data and enable its classification, existing algorithms have two main drawbacks; both their classification and explainability capabilities are limited. Lacking in explainability, they cannot indicate which electrodes and waves led to a classification decision or explain how areas and frequencies of the brain's activity correlate to a specific task. In this study, we propose a novel extension for the time-interval temporal patterns mining algorithms aimed at enhancing the data mining process by enabling a richer set of patterns to be learned from the EEG data, thereby contributing to improved classification and explainability capabilities. The extended algorithm is designed to capture and leverage the unique nature of EEG data by decomposing it into different brain waves and modeling the relations among them and between different electrodes. Our evaluation of the proposed extended algorithm on multiple learning tasks and three EEG datasets demonstrated the extended algorithm's ability to mine richer patterns that improve the classification performance by 4–11 % based on the Area-Under the receiver operating characteristic Curve (AUC) metric, compared to the original version of the algorithm. Moreover, the algorithm was shown to shed light on the areas and frequencies of the brain's activity that are correlated with specific tasks.},
  archive      = {J_ARTMED},
  author       = {Ofir Landau and Nir Nissim},
  doi          = {10.1016/j.artmed.2025.103269},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103269},
  shortjournal = {Artif. Intell. Med.},
  title        = {Mining multi-electrode and multi-wave electroencephalogram based time-interval temporal patterns for improved classification capabilities and explainability},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medical multimodal foundation models in clinical diagnosis and treatment: Applications, challenges, and future directions. <em>ARTMED</em>, <em>170</em>, 103265. (<a href='https://doi.org/10.1016/j.artmed.2025.103265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in deep learning have significantly revolutionized the field of clinical diagnosis and treatment, offering novel approaches to improve diagnostic precision and treatment efficacy across diverse clinical domains, thus driving the pursuit of precision medicine. The growing availability of multi-organ and multimodal datasets has accelerated the development of large-scale Medical Multimodal Foundation Models (MMFMs). These models, known for their strong generalization capabilities and rich representational power, are increasingly being adapted to address a wide range of clinical tasks, from early diagnosis to personalized treatment strategies. This review offers a comprehensive analysis of recent developments in MMFMs, focusing on three key aspects: datasets, model architectures, and clinical applications. We also explore the challenges and opportunities in optimizing multimodal representations and discuss how these advancements are shaping the future of healthcare by enabling improved patient outcomes and more efficient clinical workflows.},
  archive      = {J_ARTMED},
  author       = {Kai Sun and Siyan Xue and Fuchun Sun and Haoran Sun and Yu Luo and Ling Wang and Siyuan Wang and Na Guo and Lei Liu and Tian Zhao and Xinzhou Wang and Lei Yang and Shuo Jin and Jun Yan and Jiahong Dong},
  doi          = {10.1016/j.artmed.2025.103265},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103265},
  shortjournal = {Artif. Intell. Med.},
  title        = {Medical multimodal foundation models in clinical diagnosis and treatment: Applications, challenges, and future directions},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end solution for out-of-hospital emergency medical dispatch triage based on multimodal and continual deep learning. <em>ARTMED</em>, <em>170</em>, 103264. (<a href='https://doi.org/10.1016/j.artmed.2025.103264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this study was to build a multimodal, multitask predictive model—named E2eDeepEMC 2 —to improve out-of-hospital emergency incident severity assessments while coping with shifts in data distributions over time. We drew on 2 054 694 independent incidents recorded by the Valencian emergency medical dispatch service between 2009 and 2019 (excluding 2013), combining demographic, temporal, clinical and free-text inputs. To handle temporal drift, our model integrates continual learning strategies and comprises three encoder modules (for context, clinical data and text), whose outputs are merged to predict the life-threatening level, admissible response delay and emergency system jurisdiction. Compared with the Valencian Region’s existing in-house triage protocol, E2eDeepEMC 2 achieved absolute F1-score gains of 18.46% for life-threatening level, 25.96% for response delay and 3.63% for jurisdiction. Compared to non-continual learning baselines, it also outperformed them by 3.04%, 9.66% and 0.58%, respectively. Deployment of E2eDeepEMC 2 is currently underway in the Valencian Region, underscoring its practical impact on real-world emergency dispatch decision-making.},
  archive      = {J_ARTMED},
  author       = {Pablo Ferri and Carlos Sáez and Antonio Félix-De Castro and Purificación Sánchez-Cuesta and Juan M. García-Gómez},
  doi          = {10.1016/j.artmed.2025.103264},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103264},
  shortjournal = {Artif. Intell. Med.},
  title        = {An end-to-end solution for out-of-hospital emergency medical dispatch triage based on multimodal and continual deep learning},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LoRA-PT: Low-rank adapting UNETR for hippocampus segmentation using principal tensor singular values and vectors. <em>ARTMED</em>, <em>170</em>, 103254. (<a href='https://doi.org/10.1016/j.artmed.2025.103254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hippocampus is an important brain structure involved in various psychiatric disorders, and its automatic and accurate segmentation is vital for studying these diseases. Recently, deep learning-based methods have made significant progress in hippocampus segmentation. However, training deep neural network models requires substantial computational resources, time, and a large amount of labeled training data, which is frequently scarce in medical image segmentation. To address these issues, we propose LoRA-PT, a novel parameter-efficient fine-tuning (PEFT) method that transfers the pre-trained UNETR model from the BraTS2021 dataset to the hippocampus segmentation task. Specifically, LoRA-PT divides the parameter matrix of the transformer structure into three distinct sizes, yielding three third-order tensors. These tensors are decomposed using tensor singular value decomposition to generate low-rank tensors consisting of the principal singular values and vectors, with the remaining singular values and vectors forming the residual tensor. During fine-tuning, only the low-rank tensors (i.e., the principal tensor singular values and vectors) are updated, while the residual tensors remain unchanged. We validated the proposed method on three public hippocampus datasets, and the experimental results show that LoRA-PT outperformed state-of-the-art PEFT methods in segmentation accuracy while significantly reducing the number of parameter updates. Our source code is available at https://github.com/WangangCheng/LoRA-PT/tree/LoRA-PT .},
  archive      = {J_ARTMED},
  author       = {Guanghua He and Wangang Cheng and Hancan Zhu and Gaohang Yu},
  doi          = {10.1016/j.artmed.2025.103254},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103254},
  shortjournal = {Artif. Intell. Med.},
  title        = {LoRA-PT: Low-rank adapting UNETR for hippocampus segmentation using principal tensor singular values and vectors},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MMSupcon: An image fusion-based multi-modal supervised contrastive method for brain tumor diagnosis. <em>ARTMED</em>, <em>170</em>, 103253. (<a href='https://doi.org/10.1016/j.artmed.2025.103253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diagnosis of brain tumors is pivotal for effective treatment, with MRI serving as a commonly used non-invasive diagnostic modality in clinical practices. Fundamentally, brain tumor diagnosis is a type of pattern recognition task that requires the integration of information from multi-modal MRI images. However, existing fusion strategies are hindered by the scarcity of multi-modal imaging samples. In this paper, we propose a new training paradigm tailored for the scenario of multi-modal imaging in brain tumor diagnosis, called multi-modal supervised contrastive learning method (MMSupcon). This method significantly enhances diagnostic accuracy through two key components: multi-modal medical image fusion and multi-modal supervised contrastive loss. First, the fusion component integrates complementary imaging modalities to generate information-rich samples. Second, by introducing fused samples to guide original samples in learning feature consistency or inconsistency among classes, our loss component effectively preserves the integrity of cross-modal information while maintaining the distinctiveness of individual modalities. Finally, MMSupcon is validated on a real-world brain tumor dataset collected from Beijing Tiantan Hospital, achieving state-of-the-art performance. Furthermore, additional experiments on two public BraTS glioma classification datasets also demonstrate our substantial performance improvements. The source code is released at https://github.com/hywang02/MMSupcon .},
  archive      = {J_ARTMED},
  author       = {Haoyu Wang and Jing Zhang and Siying Wu and Haoran Wei and Xun Chen and Yunwei Ou and Xiaoyan Sun},
  doi          = {10.1016/j.artmed.2025.103253},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103253},
  shortjournal = {Artif. Intell. Med.},
  title        = {MMSupcon: An image fusion-based multi-modal supervised contrastive method for brain tumor diagnosis},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pathway information on methylation analysis using deep neural network (PROMINENT): An interpretable deep learning method with pathway prior for phenotype prediction using gene-level DNA methylation. <em>ARTMED</em>, <em>170</em>, 103236. (<a href='https://doi.org/10.1016/j.artmed.2025.103236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background DNA methylation is a key epigenetic marker that influences gene expression and phenotype regulation, and is affected by both genetic and environmental factors. Traditional linear regression methods such as elastic nets have been employed to assess the cumulative effects of multiple DNA methylation markers on phenotypes. However, these methods often fail to capture the complex nonlinear nature of the data. Recent deep learning approaches, such as MethylNet, have improved the prediction accuracy but lack interpretability and efficiency. Findings To address these limitations, we introduced P athway Info r mati o n on M ethylat i on Analysis using a Deep Ne ural N e t work (PROMINENT), a novel interpretable deep learning method that integrates gene-level DNA methylation data with biological pathway information for phenotype prediction. PROMINENT enhances interpretability and prediction accuracy by incorporating gene- and pathway-level priors from databases such as Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG). It employs SHapley Additive exPlanations (SHAP) to prioritize significant genes and pathways. Evaluated across various datasets, childhood asthma, idiopathic pulmonary fibrosis (IPF), and first-episode psychosis (FEP)—PROMINENT consistently outperformed existing methods in terms of prediction accuracy and computational efficiency. PROMINENT also identified crucial genes and pathways involved in disease mechanisms. Conclusions PROMINENT represents a significant advancement in leveraging DNA methylation data for phenotype prediction, offering both high accuracy and interpretability within reasonable computational time. This method holds promise for elucidating the epigenetic underpinnings of complex diseases and enhancing the utility of DNA methylation data in biomedical research.},
  archive      = {J_ARTMED},
  author       = {Soyeon Kim and Laizhi Zhang and Yidi Qin and Rebecca I. Caldino Bohn and Hyun Jung Park},
  doi          = {10.1016/j.artmed.2025.103236},
  journal      = {Artificial Intelligence in Medicine},
  month        = {12},
  pages        = {103236},
  shortjournal = {Artif. Intell. Med.},
  title        = {Pathway information on methylation analysis using deep neural network (PROMINENT): An interpretable deep learning method with pathway prior for phenotype prediction using gene-level DNA methylation},
  volume       = {170},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="asoc">ASOC - 189</h2>
<ul>
<li><details>
<summary>
(2025). Detail-aware semantic segmentation network for brain tumor MRI images combining multi-frequency directional filtering and lifting wavelets. <em>ASOC</em>, <em>185</em>, 113969. (<a href='https://doi.org/10.1016/j.asoc.2025.113969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors segmentation in Magnetic Resonance Imaging (MRI) images poses significant challenges owing to the uncertain location and size of the tumors, the difficulty in describing their boundaries, and the fuzzy demarcation of diseased tissues. Although U-Net and its recent variants have emerged as leading models for semantic segmentation in medical imaging, they still face structural limitations. These limitations cause the erosion of detail information during downsampling and poor performance in segmenting small lesions when handling targets of varying sizes, indicating a lack of detail handling capability. To counteract these issues, we designed a segmentation model that enhances detail features using frequency information. To reduce the loss of feature information during downsampling, we developed a downsampling module based on lifting wavelets. By lifting wavelets to group and integrate features according to frequency from high to low, we reduce feature resolution while enhancing information transmission and minimizing feature information loss. In our designed multi-frequency directional filtering edge feature extraction module, we extract low-frequency and high-frequency features and construct a dual-channel multi-directional filtering combination. This combination extracts directional information from low-frequency and high-frequency features separately, increasing the multi-angle directional information of the features and enriching the detailed information such as direction and position within the features. On the BraTS2018, BraTS2020, and BraTS2024 brain tumor datasets, our model demonstrated optimal results compared to 14 other advanced models. The average Dice Similarity Coefficients are 78.48 %, 79.80 %, and 74.35 %, while the 95th percentile Hausdorff Distances are 5.75, 6.60, and 7.72. Our code link is https://github.com/Eric-H8/BraTS_Seg_Model .},
  archive      = {J_ASOC},
  author       = {Xin Hua and Zhijiang Du and Hongjian Yu and Zibo Li and Qiaohui Lu and Hui Zhao},
  doi          = {10.1016/j.asoc.2025.113969},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113969},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Detail-aware semantic segmentation network for brain tumor MRI images combining multi-frequency directional filtering and lifting wavelets},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DT and LLM driven intelligent maintenance system for L-DED and DAG-based LLM fault diagnosis evaluation framework. <em>ASOC</em>, <em>185</em>, 113942. (<a href='https://doi.org/10.1016/j.asoc.2025.113942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal additive manufacturing (AM) has revolutionized industries such as aerospace and automotive manufacturing due to its ability to rapidly prototype complex structures. Laser Directed Energy Deposition (L-DED) is a key AM technique, offering high deposition rates and superior mechanical properties. However, the inherent complexity and high cost of L-DED equipment demand reliable maintenance management to minimize downtime. Traditional maintenance approaches struggle to keep pace with escalating production demands and to cope with growing equipment complexity. To address this, we propose a dual-driven intelligent maintenance system for L-DED, integrating Digital Twins (DT) and Large Language Models (LLMs). The system features a comprehensive DT framework that synchronizes the virtual entity with the physical one in real time, it also incorporates an intelligent maintenance Q&A assistant powered by Retrieval-Augmented Generation (RAG), leveraging L-DED maintenance knowledge bases to provide accurate operational support. Additionally, we propose a Directed Acyclic Graphs (DAG)-based framework to assess LLMs’ ability to guide users through complete fault diagnosis. Our work aims to enhance the reliability and efficiency of L-DED maintenance through advanced digital technologies, ultimately improving productivity and reducing downtime in additive manufacturing.},
  archive      = {J_ASOC},
  author       = {Jian Tang and Shitong Peng and Jianan Guo and Danya Song and Dongna Gao and Weiwei Liu and Fengtao Wang},
  doi          = {10.1016/j.asoc.2025.113942},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113942},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DT and LLM driven intelligent maintenance system for L-DED and DAG-based LLM fault diagnosis evaluation framework},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new large model with multi-scale feature fusion for fault diagnosis based on unified time series model. <em>ASOC</em>, <em>185</em>, 113941. (<a href='https://doi.org/10.1016/j.asoc.2025.113941'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large model technology exemplified by large language models has been applied in the field of industrial fault diagnosis. However, existing large models are optimized for specific equipment types and have yet to fully exploit the potential of time-series monitoring data to enable widespread application across diverse mechanical equipment in various industrial scenarios. To address this challenge, a fault diagnosis large model (UniTS-FD) is designed based on unified time series model (UniTS). First, a multi-scale feature fusion backbone network is developed based on UniTS backbone to capture general mechanical fault features. Second, the fault classification head integrates the Pearson correlation coefficient to assess the similarity of class information within linear space for enabling adaptive classification. Third, P-LoRA fine-tuning approach incorporating LoRA and prompt technology is proposed to fine-tune the fault classification head, which enhances the generalization ability of the UniTS-FD model for fault diagnosis tasks of various mechanical equipment. Finally, the UniTS-FD model is pre-trained on 11 fault datasets and fine-tuning experiments were conducted on four different fault datasets to achieve cross-machine fault diagnosis. Experimental results demonstrate the effectiveness of the UniTS-FD in fault diagnosis tasks.},
  archive      = {J_ASOC},
  author       = {Zhiwei Zhang and Chengbin Wei and Weimin Zhang and Long Wen},
  doi          = {10.1016/j.asoc.2025.113941},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113941},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A new large model with multi-scale feature fusion for fault diagnosis based on unified time series model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling. <em>ASOC</em>, <em>185</em>, 113920. (<a href='https://doi.org/10.1016/j.asoc.2025.113920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agentic workflows, powered by Industrial Large Models (ILMs), represent a significant development emphasizing collaboration between humans and intelligent systems. This paper presents a structured perspective on the role of agentic workflows for smart design and manufacturing, grounded in integrating ILMs. We define an agentic workflow as a labeled Activity-on-Vertex (AOV) graph, where each node represents a functionally closed subtask and is executed by an ILM-based agent, a human operator, or an automated system. This formalism supports analyzable, modular, and hybrid execution, offering a foundation for modeling complex, mixed-initiative processes in manufacturing environments. To support real-world deployment, we introduce a set of reusable agentic workflow patterns that describe how ILM agents perceive, plan, and act in coordination with other components. Besides, a proof-of-concept case study illustrates the practical application of the human-in-the-loop framework through the agentic generation of CAD models. The study covers task decomposition, workflow implementation, and benchmarking, providing evidence for the feasibility of agentic workflows. Building upon these findings, this work contributes to advancing the development and application of agentic workflows in smart manufacturing contexts.},
  archive      = {J_ASOC},
  author       = {Keyou Zheng and Yuanwei Zhong and Xuyang Su and Jiewu Leng and Qiang Liu and Xin Chen},
  doi          = {10.1016/j.asoc.2025.113920},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113920},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Towards agentic smart design: An industrial large model-driven human-in-the-loop agentic workflow for geometric modelling},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time traffic flow optimization using large language models and reinforcement learning for smart urban mobility. <em>ASOC</em>, <em>185</em>, 113917. (<a href='https://doi.org/10.1016/j.asoc.2025.113917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of metropolitan populations causes transportation network congestion, which increases fuel usage, travel time, and environmental damage. Traditional traffic management systems (TMS) seldom handle these issues in real time. Recently developed Large Language Models (LLMs), especially those using Reinforcement Learning (RL), may enhance urban transportation systems. Traffic management technology's real-time flexibility and shifting congestion patterns provide improved potential. Traditional approaches cannot estimate traffic flow or adapt to urban settings. A strong AI-driven method is needed to improve urban mobility and traffic flow. This paper introduces the LLM-RL Traffic Optimization Framework (LLM-RL-TOF). LLMs analyze real-time traffic data and give predictive insights in this context. Due to these new insights, the RL algorithm can improve traffic flow in real time and reduce congestion via dynamic traffic management. IoT sensors and urban traffic cameras capture real-time traffic data, including traffic volume and incidents. This data helps the LLM estimate bottlenecks, accidents, and traffic congestion. An RL agent uses LLM outputs to adjust traffic signal timing and suggest alternate routes. With real-time alternatives, traffic flow and urban mobility may be optimized. The junction throughput rate rose 17.5 %, the queue length accumulation index fell 22.3 %, and the average vehicle delay fell 18.6 %. The decrease in average vehicle delay enabled all these gains.},
  archive      = {J_ASOC},
  author       = {Arvind R. Singh and Muhammad Wasim Abbas Ashraf and Rajkumar Singh Rathore and Bin Li and M.S. Sujatha},
  doi          = {10.1016/j.asoc.2025.113917},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113917},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Real-time traffic flow optimization using large language models and reinforcement learning for smart urban mobility},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wind turbine blades defect detection based on global and local attention with multi-feature fusion. <em>ASOC</em>, <em>185</em>, 113914. (<a href='https://doi.org/10.1016/j.asoc.2025.113914'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind turbine blades are prone to small-scale defects—such as cracks, corrosion, and contamination—during long-term operation. Accurate detection of these defects is essential for ensuring the safety and efficiency of wind power systems. However, small-object detection remains challenging due to limited feature representation and weak discriminative cues. To address this, an enhanced YOLOX-s-based framework called Global-Frequency Dual-aware YOLOX (GFD-YOLOX) is proposed. GFD-YOLOX introduces three main improvements. First, the Path Aggregation Feature Pyramid Network (PAFPN) in the neck is replaced with Dual-Frequency Fused Bidirectional Feature Pyramid Network (DFF-BiFPN) to strengthen multi-scale contextual representation. Second, the backbone bottleneck is redesigned with a lightweight structure, improving computational efficiency and convergence speed. Third, a Hierarchical Frequency-Adaptive Fusion (HFAF) module is integrated to enhance cross-scale feature interaction by combining fine-grained and global information. On the self-constructed WTBlade-Defect dataset (3570 annotated images, five defect types: corrosion, hide-craze, surface-eye, thunderstrike, dirt), GFD-YOLOX achieves mAP@0.5 and mAP@0.5:0.95 scores of 94.5 % and 68.9 %, respectively, with 44.3 FPS inference—improving by 13.6 % and 14.4 % over state-of-the-art models. On the public dataset of Ashley Foster et al., it achieves 94.8 % and 69.3 %, with gains of 10.4 % and 10.9 %. These results demonstrate that GFD-YOLOX delivers substantial accuracy gains while maintaining real-time speed and strong cross-dataset generalization, indicating high potential for deployment in operational wind turbine inspection systems.},
  archive      = {J_ASOC},
  author       = {Dandan Liu and Mingjie Liu},
  doi          = {10.1016/j.asoc.2025.113914},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113914},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Wind turbine blades defect detection based on global and local attention with multi-feature fusion},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval multi-feature sparse transformer-CNN: A synergistic approach to precise and efficient spatio-temporal wind speed interval-value prediction. <em>ASOC</em>, <em>185</em>, 113910. (<a href='https://doi.org/10.1016/j.asoc.2025.113910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable wind speed prediction is critical for stabilizing wind power integration. However, current methods are limited by accuracy and stability issues, hindering their large-scale application in wind farms. To overcome these problems, this study innovatively proposes an IMFSformer-CNN model integrating three core components. First, the spatio-temporal and multi-factor feature extraction technology comprehensively captures the spatio-temporal patterns and complex dependencies of wind speed dynamics, incorporating multiple factors such as meteorological variables and spatial correlation. Second, the multi-feature sparse attention mechanism reduces computational complexity by combining sparse attention with multi-feature attention, enhancing representation ability and scalability for precise interval value prediction. Finally, the enhanced interval spatio-temporal prediction fusion model combines the global dependency modeling capabilities of the improved Transformer architecture with the local receptive field advantages of CNN. This hybrid design facilitates the simultaneous capture of both macro-scale atmospheric patterns and micro-scale wind speed fluctuations. The model achieved prediction interval coverage probabilities of 0.921 and 0.899, and coverage width criteria of 1.493 and 3.776, outperforming other models on both datasets. This significantly enhances accuracy and practical value for wind farm cluster forecasting, supporting more reliable and efficient wind energy integration into power grids.},
  archive      = {J_ASOC},
  author       = {Weiyi Jiang and Jujie Wang and Xuecheng He},
  doi          = {10.1016/j.asoc.2025.113910},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113910},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Interval multi-feature sparse transformer-CNN: A synergistic approach to precise and efficient spatio-temporal wind speed interval-value prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity spatiotemporal fusion neural network with denoising reconstruction for human motion prediction. <em>ASOC</em>, <em>185</em>, 113909. (<a href='https://doi.org/10.1016/j.asoc.2025.113909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction has significant application value in many fields. However, existing methods often fail to fully capture the spatial relationships between joints and the temporal flow of information when modeling complex spatiotemporal dependencies. Additionally, these methods are prone to overfitting dominant features while neglecting other important aspects, and struggle with perceiving contour features effectively. To address these issues, this study introduces a novel encoder-decoder framework. The encoder generates a dual-layer adaptive adjacency matrix using a distance partition strategy to parameterize joint relationships, while incorporating a gating mechanism to control the temporal flow of information. The decoder then employs separate spatiotemporal attention modules to decode temporal and spatial features independently. These features are subsequently reconstructed through a spatiotemporal fusion strategy, effectively decoupling and modeling complex spatiotemporal dependencies. To address the issue of overfitting to dominant features, we introduce a denoising reconstruction strategy that allows the model to learn richer combinations of spatiotemporal features under multiple constraints. Furthermore, a multi-granularity information adaptive fusion module is incorporated to achieve adaptive fusion of both local and contour features. Experimental results across several benchmark datasets demonstrate that our method significantly outperforms the state-of-the-art approaches, showcasing its effectiveness in human motion prediction tasks.},
  archive      = {J_ASOC},
  author       = {Yong Li and Linfeng Zhu and Haofei Xie and Xinchang Yi},
  doi          = {10.1016/j.asoc.2025.113909},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113909},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-granularity spatiotemporal fusion neural network with denoising reconstruction for human motion prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the risk level of saltwater intrusion in the modaomen waterway of the pearl river estuary based on the deep temporal clustering model. <em>ASOC</em>, <em>185</em>, 113897. (<a href='https://doi.org/10.1016/j.asoc.2025.113897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, extreme events caused by global climate change have intensified the phenomenon of saltwater intrusion (SWI) in estuaries. The nonlinear and non-stationary characteristics of estuarine SWI have led to an exponential decline in the timeliness of traditional regression prediction models, making it difficult to meet the operational needs of SWI forecasting. To address this, this study proposed a technical framework for SWI risk level forecasting based on temporal clustering, with its core innovation lying in algorithmic improvements for accurately characterizing complex disaster systems. The key challenges in forecasting SWI risk levels involved capturing the dynamic nonlinear relationships between multidimensional disaster factors (such as runoff, tide level, and wind) and SWI severity, as well as enhancing feature discriminability in label-limited scenarios. Accordingly, this study optimized algorithms through dual-path supervised and unsupervised learning: In the supervised learning framework, LightGBM, RF, XGBoost, and Extra trees were introduced as base learners into the Deep Forest (DF) model. The complementary feature-space partitioning of diverse learners was leveraged to improve the model’s ability to distinguish risk -level boundaries, achieving an average performance gain of 7.8 %. In the unsupervised learning framework, discriminative regularization was incorporated into the Extreme Learning Machine-Autoencoder (ELM-AE) model. By forcing features of samples from the same class to cluster toward the class center, the model’s feature separability for rare events (e.g., severe SWI) was enhanced, leading to an average performance improvement of 11 %. Finally, the optimal model was used to extract dynamic evolution patterns between multidimensional disaster factors and SWI risk levels, with interpretability analysis conducted for real-world forecasting. Notably, upstream flow sequences exhibited high distinguishability between no-SWI and severe-SWI, while mild and moderate SWI showed similar flow patterns, with tidal sequences being the primary differentiator. The algorithmic advancements not only enhanced the accuracy and efficiency of SWI forecasting but also provided a generalizable framework for risk classification in nonlinear hydrological systems.},
  archive      = {J_ASOC},
  author       = {Qingqing Tian and Hongyu Yang and Yu Tian and Peiyao Weng},
  doi          = {10.1016/j.asoc.2025.113897},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113897},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of the risk level of saltwater intrusion in the modaomen waterway of the pearl river estuary based on the deep temporal clustering model},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning with mirror-task for multimodal sentiment analysis. <em>ASOC</em>, <em>185</em>, 113896. (<a href='https://doi.org/10.1016/j.asoc.2025.113896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Task Learning (MTL) in Multimodal Sentiment Analysis (MSA) involves implementing various parameter-sharing strategies among tasks. Currently, MSA primarily focuses on hard parameter-sharing mechanisms based on encoder sharing, while soft parameter-sharing is often neglected. To explore a reasonable combination of soft and hard mechanisms in MSA and optimize multimodal representations, along with multimodal contrastive learning, we propose D 3 MSA. It consists of D ouble network (primaryNet and MirrorNet), D ouble parameter-sharing strategies and D ouble contrastive learning modes for multimodal sentiment analysis. D 3 MSA utilizes hard-sharing to consolidate correlations between positive samples of intra-sample contrastive learning. In soft-sharing, we propose a pre-trained MirrorNet (MN) that generates negative samples by the learned inverse distributions. This optimizes the feature space of negative samples. MN interacts with the MSA task through soft-sharing during inter-sample contrastive learning. Experimental results demonstrate that our proposed method can achieve advanced performance on the CMU-MOSI and CMU-MOSEI datasets with lightweight training that requires only a small number of parameters.},
  archive      = {J_ASOC},
  author       = {Hang Shi and Lianmin Zhou and Yuanyuan Pu and Zhengpeng Zhao and Jinjing Gu and Dan Xu},
  doi          = {10.1016/j.asoc.2025.113896},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113896},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Contrastive learning with mirror-task for multimodal sentiment analysis},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nearest-best neighbors optimization algorithm for constrained multimodal multiobjective problems. <em>ASOC</em>, <em>185</em>, 113895. (<a href='https://doi.org/10.1016/j.asoc.2025.113895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multimodal multiobjective problems (CMMOPs) have multiple equivalent constrained Pareto optimal sets in the decision space corresponding to the identical constrained Pareto front in the objective space. The key to solving CMMOPs is how to balance feasibility, convergence, and diversity of solutions in both the decision and objective spaces. In view of this, this paper proposes a Nearest-Best neighbors optimization algorithm with constraint-based fitness (NBNOA) to solve CMMOPs. First, a constraint-based fitness assignment scheme is designed to assign specific fitness values to individuals in the population. Then, the Nearest-better-neighbor clustering method is adopted to identify the nearest-better neighbor and best neighbor of each individual according to the specific fitness values. On this basis, a Nearest-Best neighbors guided strategy is developed to guide the search direction of individuals, striking a better balance between exploration and exploitation capabilities. Moreover, a CDP-density elite selection mechanism is constructed to obtain feasible Pareto optimal solutions with higher precision and better diversity. Extensive experiments on two CMMOPs test suites demonstrated that the proposed NBNOA significantly outperforms nine state-of-the-art algorithms. Notably, NBNOA ranks first among all ten algorithms and achieves the best values for 23 out of 31 benchmark functions regarding the reciprocal of Pareto sets proximity and inverted generational distance. Furthermore, NBNOA is applied to a real-world CMMOP, verifying its effective practical application capability. Additionally, NBNOA is tested on two high-dimensional constrained multiobjective optimization problems test suites, further proving its competitive performance in solving complex problems.},
  archive      = {J_ASOC},
  author       = {Xuming Han and Ting Zhou and Limin Wang and Yali Chu},
  doi          = {10.1016/j.asoc.2025.113895},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113895},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A nearest-best neighbors optimization algorithm for constrained multimodal multiobjective problems},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency decomposition and patch modeling framework for time-series forecasting. <em>ASOC</em>, <em>185</em>, 113890. (<a href='https://doi.org/10.1016/j.asoc.2025.113890'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is widely applied across diverse fields, including finance, transportation, and energy, and has made significant contributions in these areas. However, in real-world applications, time series data can be complex and dynamic. Current methodologies still encounter several challenges in managing high-dimensional data, extracting intricate features, and making long-term forecasts. In this study, we propose a Frequency Decomposition and Patch Modeling Framework (FPF). Our FPF consists of the Frequency Domain Decomposition Block (FDB) and the Dual Patch Modeling Block (DPMB). DPMB consists of Patch Enhancement Block and Patch Mixing Block. First, FDB transforms the input sequence to the frequency domain through the Fast Fourier Transform and designs frequency masks to decompose the data into high-frequency and low-frequency components, to extract fast-changing patterns and trend information respectively. Subsequently, DPMB divides the components into patches, where the high-frequency components are modeled by MLP-based Patch Enhancement Block to capture local features, and the low-frequency components are modeled by Transformer-based Patch Mixing Block to capture global dependencies and cross-patch correlations. We conducted comprehensive experiments using seven real-world time series forecasting datasets, including ETT, Traffic, Electricity, and Weather. The findings indicate that this method demonstrates superior performance in the field of time series forecasting.},
  archive      = {J_ASOC},
  author       = {Denghui Xu and Hua Wang and Fan Zhang},
  doi          = {10.1016/j.asoc.2025.113890},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113890},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Frequency decomposition and patch modeling framework for time-series forecasting},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density peak clustering algorithm based on boundary elimination and backbone construction. <em>ASOC</em>, <em>185</em>, 113880. (<a href='https://doi.org/10.1016/j.asoc.2025.113880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peak clustering (DPC) is an effective clustering algorithm, but it still has some problems and faces some challenges. For instance, it cannot identify the variable density datasets, the assignment strategy is easy to produce domino phenomenon, and the clustering results of DPC and its improved algorithms are easily affected by the intersection points between clusters. To solve these problems, in this paper, we propose a novel density peak clustering algorithm based on boundary elimination and backbone construction, called BEBC-DPC. A new local density is defined based on the natural neighbor search, and the boundary degree is defined by the position relationship between each point and its neighbors, which accurately describes the local distribution information of the point. The boundary points of clusters are eliminated by fusing the density and the boundary degree, which reduces the influence of the intersection points on the cluster division. In addition, the cluster backbone construction method based on representative points and representative sets is proposed. The density relationship among non-boundary points is used to form representative sets, and the similarity between representative sets is used to construct the cluster backbones, which can effectively describe the overall distribution structure characteristics of the clusters. Moreover, the adjacency degree of each boundary point is defined by using the neighbor information and distance information, and the boundary points are gradually assigned to the most appropriate cluster backbone based on it to complete the clustering. Finally, sufficient experiments are performed on synthetic, UCI and image datasets, and the proposed BEBC-DPC is compared with DPC and its improved algorithms. Experimental results show the effectiveness of the proposed BEBC-DPC on various types of datasets.},
  archive      = {J_ASOC},
  author       = {Zhizhong Zhao and Sugen Chen and Cong Hu},
  doi          = {10.1016/j.asoc.2025.113880},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113880},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Density peak clustering algorithm based on boundary elimination and backbone construction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliable type 2 fuzzy Min–Max neural networks for pattern classification. <em>ASOC</em>, <em>185</em>, 113875. (<a href='https://doi.org/10.1016/j.asoc.2025.113875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fuzzy Min–Max (FMM) algorithm is a powerful classification method capable of handling non-linear class boundaries and making both hard and soft decisions while learning from online data. However, it faces significant challenges, including sensitivity to the expansion coefficient, information loss during the contraction stage, and the overlap problem. To address these limitations, we propose a Reliable Type-2 Fuzzy Min–Max (RT2FMM) algorithm, which incorporates type-2 fuzzy logic to consider hyperbox uncertainty and effectively resolve the overlap problem. By assigning distinct certainties to overlapping regions, RT2FMM eliminates the need for the contraction stage and the overlap test. Additionally, we introduce weighted factors for hyperboxes, which enhances the reliability of membership values and models their mutual effects. Our comprehensive experimental evaluation across twenty datasets demonstrates that RT2FMM significantly outperforms existing FMM-based models in terms of robustness and accuracy. The Friedman test further confirms the superior performance of RT2FMM compared to commonly used classifiers, highlighting its potential as a robust solution for complex classification tasks.},
  archive      = {J_ASOC},
  author       = {Ali Nik-Khorasani and Mohammad-R. Akbarzadeh-T.},
  doi          = {10.1016/j.asoc.2025.113875},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113875},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Reliable type 2 fuzzy Min–Max neural networks for pattern classification},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fortifying vision models: A comprehensive survey of defences against adversarial examples. <em>ASOC</em>, <em>185</em>, 113874. (<a href='https://doi.org/10.1016/j.asoc.2025.113874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence and Machine learning (ML) have seen many advancements in the past two decades. It has led to the creation of several techniques, including Deep Neural Networks (DNN), Convolution Neural Networks (CNN), Autoencoders, Generative Adversarial Networks (GAN) and Diffusion models. These techniques have been applied to various real-world applications, such as self-driving cars, medical diagnosis and voice assistants. Despite these advancements, a carefully crafted input can fool the ML model. Such attacks are known as adversarial examples. It is a serious threat to safety critical systems. This survey provides a comprehensive review of defences against adversarial examples by tracing their evolution from early empirical methods to more principled, theoretically grounded approaches. We systematically categorise defences based on their underlying mechanisms. In addition to surveying state-of-the-art techniques, we spotlight emerging trends such as generative defences and diffusion-based purification. Finally, we identify persistent vulnerabilities and outline promising directions for future research towards building truly resilient vision models. This work aims to equip researchers and practitioners with a deep understanding of current defences and inspire innovation in adversarial robustness for the next generation of vision applications.},
  archive      = {J_ASOC},
  author       = {Siddheshwar Kumar and Shashank Srivastava and Shashwati Banerjea},
  doi          = {10.1016/j.asoc.2025.113874},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113874},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fortifying vision models: A comprehensive survey of defences against adversarial examples},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AOT-PixelNet: Lightweight and interpretable detection of forged images via adaptive orthogonal transform. <em>ASOC</em>, <em>185</em>, 113873. (<a href='https://doi.org/10.1016/j.asoc.2025.113873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative image detection faces persistent challenges in terms of generalization and interpretability, limiting its reliability in complex scenarios. To address these issues, we propose AOT-PixelNet, a lightweight and interpretable detection framework that integrates an Adaptive Orthogonal Transform (AOT) module with a streamlined 1 × 1 convolution-based PixelNet architecture. The AOT module leverages diverse orthogonal transforms, such as FFT and DCT, to extract informative frequency-domain features, thereby enhancing sensitivity to medium- and high-frequency artifacts. Meanwhile, PixelNet minimizes parameter count (only 0.98 million) while effectively capturing cross-channel inconsistencies and mitigating overfitting. Experimental evaluations on multiple unseen GAN and diffusion-based datasets demonstrate that AOT-PixelNet achieves superior performance with minimal computational cost. Specifically, it outperforms the NPR method by 0.6% and 11.76% on the ForenSynths and GenImage datasets, respectively, validating the framework’s robustness, effectiveness, and interpretability.},
  archive      = {J_ASOC},
  author       = {Dengtai Tan and Deyi Yang and Boao Tan and Chengyu Niu and Yang Yang and Shichao Li},
  doi          = {10.1016/j.asoc.2025.113873},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113873},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AOT-PixelNet: Lightweight and interpretable detection of forged images via adaptive orthogonal transform},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Status prediction using attentive and cascaded deep network by fault tolerant and priority-based scheduling for load balancing in cloud. <em>ASOC</em>, <em>185</em>, 113872. (<a href='https://doi.org/10.1016/j.asoc.2025.113872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cloud facilitates the user to complete their work utilizing the cost strategy of pay-as-you-go, which is based on the consumed Virtual Machine (VM) hours. Thus, the scheduler must offer the highest throughput to attain efficient allocation of resources in the cloud paradigm. Cloud services are dependent on characteristics such as fault tolerance, security, scalability, and availability. Hence, an effective scheduler is necessary to arrange the scheduling tasks and adjust the server loads. Typically, a load-balancing task focuses on detecting the overloaded and under-loaded nodes and adjusting the load between them. When considering the significant role of fault-tolerance in load-balancing algorithms, it seems to suffer from poor organization and a lack of in-depth experiments in this sector. This paper proposes a new task for the load-balancing operation. Initially, task scheduling is performed where the fault tolerance and the priority-aided scheduling approach are adopted. Furthermore, resource optimization is carried out in the scheduling task using Randomly Improved Electric Fish Optimization (RIEFO). To validate the load balancing operation, several multi-objective functions such as resource utilization, delay, time, makespan, active servers, throughput, success rate, fault tolerance rate, and energy consumption are derived. Moreover, because of the system’s dynamic environment, the status of the server varies simultaneously. The server status prediction is significant in allocating the tasks to the server or the VM resources. Thus, the Attention-based Cascaded Residual Bidirectional Long Short-Term Memory (ACRes-BiLSTM) is employed to predict the server status before performing the resource allocation. Finally, the tasks are scheduled effectively using the predicted server status. The performance is estimated using numerous performance metrics.},
  archive      = {J_ASOC},
  author       = {Gudivada Lokesh and Kasarapu Ramani and K.K. Baseer},
  doi          = {10.1016/j.asoc.2025.113872},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113872},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Status prediction using attentive and cascaded deep network by fault tolerant and priority-based scheduling for load balancing in cloud},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid deep learning framework for detecting grape leaf diseases by integrating ResNeSt-50 and CBAM attention into DeepLabv3 +. <em>ASOC</em>, <em>185</em>, 113871. (<a href='https://doi.org/10.1016/j.asoc.2025.113871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grape leaf diseases, such as black rot, powdery mildew, and downy mildew, pose a significant threat to global viticulture, leading to substantial yield losses and reduced fruit quality. Early and accurate identification of these diseases is essential for precision agriculture and sustainable crop management. This study presents a comprehensive comparison of traditional and deep learning-based image segmentation methods for detecting grape leaf lesions. A series of classical segmentation techniques, including Mean Shift, Fuzzy C-Means (FCM), Normalized Cut, K-Means, and Fuzzy K-Means (FKM), were evaluated alongside an advanced DeepLabv3 + model. The baseline DeepLabv3 + architecture was further enhanced by integrating a ResNeSt-50 backbone with various attention mechanisms, including Squeeze-and-Excitation (SE) Block, Convolutional Block Attention Module (CBAM), Bottleneck Attention Module (BAM), Self-Attention, and Dual Attention Network (DANet). Among all models, DeepLabv3 + with ResNeSt-50 and CBAM achieved the highest performance, attaining 98.2 % accuracy, 97.1 % precision, 96.7 % recall, 96.6 % mean Intersection over Union (mIoU), and a 96.8 % Dice Score. The results demonstrate that attention-augmented deep networks significantly outperform classical methods, especially in handling complex lesion structures under diverse environmental conditions. While traditional algorithms remain useful in resource-constrained scenarios, deep learning models, particularly those enhanced with spatial and channel-wise attention, offer greater accuracy and robustness, making them ideal for integration into intelligent agricultural platforms such as drones, mobile scanners, and automated disease monitoring systems. Future work will focus on incorporating temporal and multimodal data, expanding dataset diversity, and optimizing lightweight models for real-time deployment on edge devices.},
  archive      = {J_ASOC},
  author       = {Kittipol Wisaeng},
  doi          = {10.1016/j.asoc.2025.113871},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113871},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A hybrid deep learning framework for detecting grape leaf diseases by integrating ResNeSt-50 and CBAM attention into DeepLabv3 +},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic proportional–differential TLBO algorithm and its applications for wafer transfer finger. <em>ASOC</em>, <em>185</em>, 113870. (<a href='https://doi.org/10.1016/j.asoc.2025.113870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Teaching-Learning-Based optimization (TLBO) algorithm, which includes teacher phase and learner phase, is a widely used method for global optimization. However, TLBO will experience premature convergence and get stuck in local optimum when faced with complex optimization challenges. Especially when tackling complex problems in practical engineering applications, which involves multiple variables and numerous constraints. To address this issue, a new variant termed Stochastic Proportional–Differential TLBO (SPD-TLBO) has been developed. The SPD phase allows students to learn not only from the current population but also from previous stochastic errors and their generation differences using adaptive random operators. By incorporating an SPD operator into the original TLBO framework, the algorithm’s search diversity is enhanced, reducing the likelihood of premature convergence to local optimum. The experimental results conducted at the IEEE Conference on Evolutionary Computation 2014 (CEC 2014) indicated that the proposed SPD-TLBO algorithm achieved an effective balance between exploration and exploitation capabilities. Specifically, the SPD-TLBO algorithm achieves the highest ranking in 21 out of 30 cases (70%) for 30-dimensional problems and 18 out of 30 cases (60%) for 50-dimensional problems. Statistical tests and convergence analyses show that the SPD-TLBO algorithm outperforms other algorithms in solving global optimization problems. Additionally, when applied to engineering optimization problems, the SPD-TLBO algorithm shows significant advantages over other algorithms. Therefore, the SPD-TLBO algorithm is further applied to optimize the structure of a wafer transfer finger in semiconductor manufacturing.},
  archive      = {J_ASOC},
  author       = {Jinfeng Sun and Yunlang Xu and Haibo Zhou},
  doi          = {10.1016/j.asoc.2025.113870},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113870},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A stochastic proportional–differential TLBO algorithm and its applications for wafer transfer finger},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the health effects of COVID using hybrid classifier with attention-based LSTM-deep temporal convolution network. <em>ASOC</em>, <em>185</em>, 113867. (<a href='https://doi.org/10.1016/j.asoc.2025.113867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus Disease 2019 (COVID-19) is an infectious illness that affects both humans and animals. Individuals infected with COVID-19 are prone to lung complications during the recovery phase . Radiography and Computed Tomography (CT) are the most commonly used methods for diagnosing lung-related diseases. The primary aim of this paper is to assess the impact of COVID-19 on patients’ lungs, heart, and blood sugar levels using a deep learning-based approach. Initially, data related to the heart, blood sugar levels, and lungs of COVID-19-infected individuals are collected. From this dataset, three types of features are extracted. Deep features are obtained using Iterated Dilated Convolutional Neural Networks (IDCNN). From these deep features, which are obtained from the IDCNN, the optimal weighted features are derived by implementing the Hybrid Dolphin Pod Cuttlefish Optimization (HDPCO) algorithm. Subsequently, the HDPCO algorithm is also employed for optimal feature extraction. In addition, dimensionality reduction is performed using Principal Component Analysis (PCA). These three sets of features from the IDCNN, HDPCO, and PCA, are then fused into a single feature set . This fused feature set is fed into a hybrid classifier composed of a Deep Temporal Convolutional Network (DTCN) and an Attention-based Long Short-Term Memory (ALSTM) network . The classifier parameters are optimized using the HDPCO algorithm. The output from the hybrid classifier provides the final prediction result. Experimental results demonstrate that the proposed COVID-19 impact prediction model significantly outperforms existing models in terms of prediction accuracy and efficiency.},
  archive      = {J_ASOC},
  author       = {Sadanandam Kalvala and B. Baranidharan},
  doi          = {10.1016/j.asoc.2025.113867},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113867},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prediction of the health effects of COVID using hybrid classifier with attention-based LSTM-deep temporal convolution network},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum fuzzy logic for edge detection: A demonstration on NISQ hardware. <em>ASOC</em>, <em>185</em>, 113866. (<a href='https://doi.org/10.1016/j.asoc.2025.113866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing offers the potential to enhance computational efficiency beyond classical methods, but practical implementation remains challenging due to the limitations of Noisy Intermediate-Scale Quantum (NISQ) hardware, namely, restricted qubit counts, limited connectivity, and the presence of noise and decoherence. This study presents a novel approach to edge detection by leveraging a recently developed Quantum Fuzzy Inference Engine, implemented on a NISQ device. We introduce an optimized quantum circuit for its implementation, reducing qubit requirements and gate depth to improve execution on NISQ hardware. To overcome constraints related to large-scale image processing, a hybrid quantum–classical lookup table approach is employed. Edge detection performance is evaluated on the Berkeley Segmentation Data Set and Benchmarks 500 dataset under different conditions, including classical execution, ideal quantum simulation, noisy quantum simulation, and NISQ hardware calculation. Results demonstrate that the quantum fuzzy logic-based edge detection achieves outcomes comparable to classical methods by using fewer operations, marking a step toward practical quantum-enhanced image processing.},
  archive      = {J_ASOC},
  author       = {G. Nunziata and S. Crisci and G. De Gregorio and R. Schiattarella and G. Acampora and L. Coraggio and N. Itaco},
  doi          = {10.1016/j.asoc.2025.113866},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113866},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Quantum fuzzy logic for edge detection: A demonstration on NISQ hardware},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompted complex context generation guided fine-grained ship recognition. <em>ASOC</em>, <em>185</em>, 113856. (<a href='https://doi.org/10.1016/j.asoc.2025.113856'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained ship recognition in complex marine environments is challenged by background interference, high inter-class similarity, and limited labeled data. Existing methods often rely on inefficient cascades or holistic feature extraction, which limits both accuracy and efficiency. To address these issues, we propose a Prompted Complex Context Generation Guided Fine-Grained Ship Recognition framework, consisting of two core modules. The Cross-Attention Context Generation Module utilizes a diffusion model to generate diverse background images from prompts, maintaining target consistency and enriching the training data to mitigate data scarcity. It also employs a cross-attention map to highlight target-relevant regions, guiding the Attention Map Guided Fusion Module. The Attention Map Guided Fusion Module adopts a dual-branch transformer architecture: one branch extracts global features from background-enhanced images, and the other captures local features through attention-guided cropping of target-specific regions. By integrating both global and local features, our method effectively identifies key target characteristics. Experimental results demonstrate that our approach achieves 97.04% accuracy on the publicly available MAR-ships dataset and 84.57% accuracy on the challenging GCS dataset, outperforming state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Runtian Wang and Kejun Wu and Renjie Qiao and Chunsheng Yang and Chengtao Cai},
  doi          = {10.1016/j.asoc.2025.113856},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113856},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Prompted complex context generation guided fine-grained ship recognition},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-granularity decision tree algorithm based on variable precision rough sets and zentropy. <em>ASOC</em>, <em>185</em>, 113851. (<a href='https://doi.org/10.1016/j.asoc.2025.113851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing decision tree algorithms often use a single-layer measure to process data, which cannot fully consider the complex interactions and dependencies between different granularity levels. In addition, decision tree algorithms inevitably face the issue of multi-value preference, which may lead to the selection of unreasonable attributes in the process of partition, thereby affecting the performance of the algorithms. Therefore, this paper proposes an improved decision tree algorithm, called Ze-VNDT, which combines variable precision rough sets with Zentropy. First, to avoid the information loss caused by data discretization, this paper introduces variable precision neighborhood rough sets for data processing. Second, by analyzing the granularity level structure within the variable precision neighborhood rough set model, knowledge uncertainty is analyzed from three granularity levels: decision classes, approximate relations, and similarity classes. We describe the uncertain knowledge from the overall to the internal using the idea of going from coarse to fine, and design a Zentropy to measure uncertainty. To address the issue of multi-value preference, an adaptive weighted Zentropy uncertainty measure is designed based on the definition of uncertainty measure based on Zentropy. Third, when constructing the improved decision tree algorithm, the optimal attributes are selected based on the designed uncertainty measure. Finally, numerical experiments on 18 UCI datasets validated the effectiveness and rationality of the proposed algorithm. The experimental results showed that, compared to traditional algorithms and the latest improved algorithms, the proposed algorithm achieved an average accuracy of 94.79%, an average precision of 85.77%, an average recall rate of 84.68%, and an F1-score of 84.97% across the 18 datasets. It ranked first in all five evaluation metrics, demonstrating higher stability and accuracy.},
  archive      = {J_ASOC},
  author       = {Hui Dong and Caihui Liu and Xiying Chen and Duoqian Miao},
  doi          = {10.1016/j.asoc.2025.113851},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113851},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-granularity decision tree algorithm based on variable precision rough sets and zentropy},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skin lesion classification with mini-batch sampling and deep metric learning. <em>ASOC</em>, <em>185</em>, 113850. (<a href='https://doi.org/10.1016/j.asoc.2025.113850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin lesion image classification based on deep learning has recently garnered significant attention. However, directly applying methods that perform well in general computer vision tasks to skin lesion image classification is not ideal, as skin lesion image datasets possess intrinsic characteristics, such as class imbalance, intra-class variability, and inter-class similarity. To tackle these challenges simultaneously, we propose a novel unified learning framework, named mBSML, which integrates mini-batch sampling and deep metric learning. In this framework, mini-batch sampling re-samples data in real-time during each iteration of learning, while a new loss function combines mini-batch distance metric-based loss with cross-entropy loss. Through the alternating training procedure on both imbalanced training data and balanced re-sampling data, mBSML effectively learns from global distribution information and local similarity information, not only from the original dataset but also from the minority classes. Extensive experiments conducted on two publicly available datasets demonstrate the effectiveness of mBSML for skin lesion image classification.},
  archive      = {J_ASOC},
  author       = {Shengdan Hu and Zhifei Zhang and Li Ying and Guangming Lang},
  doi          = {10.1016/j.asoc.2025.113850},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113850},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Skin lesion classification with mini-batch sampling and deep metric learning},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AOD-YOLO: A self-modulating multi-scale feature aggregation mechanism for small object detection in airport surface scenes. <em>ASOC</em>, <em>185</em>, 113849. (<a href='https://doi.org/10.1016/j.asoc.2025.113849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in airport surface scenes is crucial for enhancing safety. However, the coexistence of objects with significant scale disparities within the same region complicates feature representation, limiting existing models’ ability to capture fine-grained details, especially for small objects. To address this challenge, we propose AOD-YOLO, an Airport Object Detection (AOD) model incorporating a Self-Modulating Multi-Scale Feature Aggregation Mechanism. This model introduces two key innovations: (1) Enhanced Context Modeling: By leveraging large-kernel convolution, frequency-domain modulation, and statistical feature analysis, our approach effectively adjusts feature contributions across different object scales, improving contextual understanding in complex scenes; (2) Optimized Small Object Representation: A dynamic gradient gain allocation strategy refines small-object features, enhancing detection accuracy and overall feature presentation. AOD-YOLO consistently improves performance across model scales. On our self-constructed Airport dataset and the public VisDrone-DET2019 dataset, it achieves mean Average Precision (mAP 0.5 ) of 87.9% and 44.9%, respectively—outperforming state-of-the-art models like YOLOv11 and Gold-YOLO by substantial margins. Additionally, through optimized network module placement, AOD-YOLO achieves 112 FPS, striking a balance between computational efficiency and accuracy, making it well-suited for real-time airport object detection.},
  archive      = {J_ASOC},
  author       = {Yingqing Wang and Weili Zeng and Ziyu Zhao and Baogeng Li and Zhibin Quan},
  doi          = {10.1016/j.asoc.2025.113849},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113849},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AOD-YOLO: A self-modulating multi-scale feature aggregation mechanism for small object detection in airport surface scenes},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient mathematical-based optimization method to optimize multi-hydropower operating rules. <em>ASOC</em>, <em>185</em>, 113846. (<a href='https://doi.org/10.1016/j.asoc.2025.113846'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing hydropower multi-reservoir systems requires both effective operating rules and efficient optimization techniques. The main contribution of this paper is offering a unique approach that elegantly combines two important parts: creating an efficient optimization method and developing hydropower operating rules. In this regard, a nonlinear rule curve (NLRC) and a linear rule curve (LRC), are tailored for the coordination of a hydropower multi-reservoir system (HMRS) in Iran. To optimize operating rules, the study fabricates a novel algorithm termed the multi-operator weighted mean of vectors (MINFO). The algorithm combines a powerful global search strategy (GSS) that thoroughly searches the solution space with an efficient local search (LS), striking a balance between solution diversity and convergence speed. To fine-tune this balance, an adaptive parameter-tuning strategy is applied. Furthermore, the active-set sequential quadratic programming (ASQP) serves as a localized escaping operator to enhance the algorithm's convergence speed. The effectiveness of the proposed MINFO algorithm is first evaluated through a nonlinear five-reservoir problem. The findings indicate that the MINFO algorithm outperforms a set of 14 distinct optimization methods. Subsequently, the MINFO algorithm is applied to identify optimal NLRC and LRC for a six-reservoir hydropower system. The results underscore the superiority of optimized NLRC, yielding a potential power augmentation of up to 17 % in comparison to the LRC approach. In summation, this study constitutes a seminal contribution by cultivating an efficient rule curve framework for the management of HMRSs.},
  archive      = {J_ASOC},
  author       = {Shuguang Li and Iman Ahmadianfar and Aitazaz A. Farooque and Zaher Mundher Yaseen},
  doi          = {10.1016/j.asoc.2025.113846},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113846},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An efficient mathematical-based optimization method to optimize multi-hydropower operating rules},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced YOLOv4 for real-time underwater object detection: An application-oriented approach. <em>ASOC</em>, <em>185</em>, 113837. (<a href='https://doi.org/10.1016/j.asoc.2025.113837'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting debris and monitoring marine life in sea aquaculture face challenges due to limited visibility and the presence of diverse. Underwater object detection by Autonomous Unmanned Vehicle(AUV) is inherently more challenging than land due to light attenuation and water turbidity, especially for small and dense objects in murky images, where extracting high-quality features is hindered. In this paper, we present an efficient approach for real-time underwater object detection through improvements in image enhancement, data augmentation, and feature aggregation. Initially, U-Shape Transformer is applied to enhance the original images. For data augmentation, it is observable that while Mosaic data augmentation enhances complex images but fails to improve small-object detection due generation of less number of images with small objects. To address this limitation, we propose Underwater-Mosaic (U-Mosaic), a modified Mosaic data augmentation technique designed to enhance small-object detection. Additionally, it was noted that existing YOLOv4 struggles with detecting small and densely populated objects in underwater images as unable to get sufficient features for small objects due to downsampling, image quality and also found difficulty in selecting anchor box size. Therefore, we propose a model called Advanced YOLOv4, tailored for underwater object detection. The proposed Advanced YOLOv4 aims to improve object detection efficiency by altering the neck and prediction layers of YOLOv4. Moreover, we introduce an additional spatial pyramid pooling layer to aggregate features and reduce feature dimensions thereby improving object detection rates. Also, the proposed work concentrates on very large object detection and for this purpose used downsampling during the detection of large objects. The proposed approach is validated through two distinct application areas: (i) detecting and locating debris (ii) detecting fish from underwater images. For validation, the Trash ICRA19 dataset is used for debris detection, while the Brackish dataset is employed for fish detection. UIQM and UCIQE, image enhancement assessment metrics are used to measure quality of enhanced images and found more than 20% better result for both the datasets. The proposed real-time underwater object detection model outperformed single-stage object detectors like YOLOv3, YOLOv4, YOLOv5, YOLOv7, and KPE-YOLOv5 by 5% in terms of mean Average Precision(mAP). Also proposed work compared with two-stage detector RCNN and found 8% better mAP than RCNN.},
  archive      = {J_ASOC},
  author       = {Pratima Sarkar and Sourav De and Prasenjit Dey and Sandeep Gurung},
  doi          = {10.1016/j.asoc.2025.113837},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113837},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advanced YOLOv4 for real-time underwater object detection: An application-oriented approach},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniCon: Unified image-guiding generation with noise consistency. <em>ASOC</em>, <em>185</em>, 113832. (<a href='https://doi.org/10.1016/j.asoc.2025.113832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have demonstrated remarkable capabilities in image-to-image tasks. However, existing methods typically focus either on structural (e.g., layout, content) or stylistic guidance, with few approaches effectively excel at both. On the other hand, many methods require time-consuming fine-tuning or high inference latency, making interactive generation applications challenging to realize. To address these issues, we propose a two-stage framework referred as UniCon ( Uni fied Image-guiding Generation with Noise Con sistency). To improve time efficiency, we follow the paradigm of inversion-based image manipulation and introduce a novel method called Noise Consistency Inversion . Leveraging the nature of Consistency Models, this inversion process is highly efficient, requiring only a single neural function evaluation (NFE) in the inversion process. To achieve high consistency and finer control, we introduce a unified attention-based guidance mechanism that supports structural, stylistic, or joint reference inputs, without any additional fine-tuning. Experiments with structure- and style-specific methods show that our approach performs competitively or better in each individual aspect. In comparison of style transfer tasks that demand both structure and style, our method outperforms state-of-the-art baselines, confirming the effectiveness of our union control strategy. And overall, our approach also achieves the best efficiency in terms of runtime performance.},
  archive      = {J_ASOC},
  author       = {Yuanjun Liao and Yuning Gong and Yanci Zhang},
  doi          = {10.1016/j.asoc.2025.113832},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113832},
  shortjournal = {Appl. Soft. Comput.},
  title        = {UniCon: Unified image-guiding generation with noise consistency},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of the financial performance of the textile and apparel industry in interval type-2 fuzzy environment. <em>ASOC</em>, <em>185</em>, 113830. (<a href='https://doi.org/10.1016/j.asoc.2025.113830'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Turkish textile and apparel sector plays a crucial role in the national economy through employment, exports, and investment. The financial performance of companies is a key determinant of their sustainability and competitiveness, especially in global markets. The Turkish textile and apparel sector is one of the essential industries in terms of macro-economic indicators such as net foreign exchange inflow, employment and investment. This sector is also one of the critical actors in world trade. A robust performance evaluation model is essential for stakeholders such as investors, creditors, and managers. However, the assessment of firms is a very critical decision involving uncertainty due to various conflicting criteria based on judgements. In this study, an integrated multi-criteria decision-making (MCDM) model including interval type-2 fuzzy hierarchy process (IT2FAHP) and Compromise Ranking of Alternatives from Distance to Ideal Solution (CRADIS) approaches are proposed to assess the financial performance of Turkish textile and clothing firms that are traded in Borsa İstanbul (BİST) in the period from 2006 to 2020. In line with the determined purpose, the arithmetic average of the determined financial ratios during the analysis period covering 15 years is computed to obtain long-term performance indicators. The importance weights of the selected financial criteria for the performance evaluation model are identified by employing the IT2FAHP approach. Then, the firms are ranked according to their financial performances with the CRADIS method. In addition, the results from the sensitivity analysis validate the proposed approach and prove that it is practical. Moreover, practical and managerial implications are discussed based on the results. The results offer valuable insights for strategic decision-making and can support efforts to enhance financial stability in the textile and apparel sector. According to the results, "LUKSK" had the highest long-term financial performance among the 11 companies discussed. This company is followed by BOSSA, YATAS, and ATEKS companies. The alternatives confirm the robustness of the proposed model in maintaining its place in the ranking in 190 scenarios. In addition, the comparative analysis confirms the consistency of the proposed ranking framework.},
  archive      = {J_ASOC},
  author       = {Ömer Faruk Görçün and Mohsin Shabir and Ahmet Çalık and Özcan Işık},
  doi          = {10.1016/j.asoc.2025.113830},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113830},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluation of the financial performance of the textile and apparel industry in interval type-2 fuzzy environment},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interpretable dual-output multivariate wind speed interval prediction scheme using hyper-heuristic optimization algorithm and deep neural networks. <em>ASOC</em>, <em>185</em>, 113829. (<a href='https://doi.org/10.1016/j.asoc.2025.113829'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty analysis of wind speed forecasting using the Lower Upper Bound Estimation (LUBE) represents an advanced interval prediction method that does not require assumptions about data distribution. Previous studies, however, have exclusively focused on univariate prediction models, neglecting the information from other variables, and have not fully exploited the prediction errors in their loss function during training. To address these issues, an interpretable dual-output multivariate wind speed interval prediction scheme (IMWSIPS) that utilizes a hyper-heuristic optimization algorithm and a deep neural network is proposed, along with a novel loss function for training. The system initially takes multiple inputs such as historical wind speed and other influencing factors including wind direction, density, temperature, and pressure into a deep neural network. The actual wind speeds are then scaled up and down by factors of 1 + θ 1 (0 <θ 1 <1) and 1 + θ 2 (-1 <θ 2 <0), respectively, to produce two outputs from the network. On this basis, an optimization problem to minimize interval width under a given coverage probability is formulated and solved using the developed hyper-heuristic algorithm, yielding optimal values for θ 1 and θ 2 and the prediction intervals for sub-models. Subsequently, the advantages of five deep neural network models are leveraged to construct an ensemble model, with weights optimized by the hyper-heuristic algorithm to derive the final prediction intervals. Ultimately, the system's interpretability is analyzed at both variable and sub-model levels. Experimental and discussion results demonstrate that the introduction of IMWSIPS not only signifies enhancements in forecasting performance but also implies improvements in wind energy utilization efficiency and reductions in operational costs for power systems.},
  archive      = {J_ASOC},
  author       = {Mengzheng Lv and Jianzhou Wang and Shuai Wang and Yang Zhao and Jialu Gao and Yuansheng Qian},
  doi          = {10.1016/j.asoc.2025.113829},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113829},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An interpretable dual-output multivariate wind speed interval prediction scheme using hyper-heuristic optimization algorithm and deep neural networks},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging the semantic-numerical gap: A numerical reasoning method of cross-modal knowledge graph for material property prediction. <em>ASOC</em>, <em>185</em>, 113776. (<a href='https://doi.org/10.1016/j.asoc.2025.113776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Material properties are illustrated by numerical data and semantic factors. In general, existing methods typically adopt machine learning (ML) algorithms to regress numerical properties or transfer other pre-trained knowledge graphs (KGs) to the material, due to the limitations of small-sample datasets. However, integrating semantic and numerical information from multi-modal data which across diverse experimental conditions remains a significant challenge in materials science. In this paper, a numerical reasoning method for material KGs (NR-KG) 1 was proposed, which constructs a cross-modal KG using semantic nodes and numerical proxy nodes. Both types of information by projecting KG into a canonical KG were captured and a graph neural network to predict material properties was utilized. In process, a novel projection prediction loss is proposed to extract semantic features from numerical information. NR-KG facilitates end-to-end processing of cross-modal data, mining relationships and cross-modal information in small-sample datasets, and fully utilizes effective experimental data to enhance the accuracy of material prediction. We propose two new high-entropy alloys (HEA) property datasets with semantic descriptions. NR-KG outperforms state-of-the-art (SOTA) methods on two material datasets, with MSE values of 3520 and 2.210, and achieving relative improvements of 25.9% and 16.1%, respectively, over the second-best methods, KANO and PCHMLP (semantic). It also achieves RMSE values of 0.584 and 0.521 on the FreeSolv and ESOL public molecular datasets, surpassing SOTA methods by 48.8% and 22.2% over KANO, highlighting its potential application and generalizability.},
  archive      = {J_ASOC},
  author       = {Guangxuan Song and Dongmei Fu and Zhongwei Qiu and Zijiang Yang and Jiaxin Dai and Lingwei Ma and Dawei Zhang},
  doi          = {10.1016/j.asoc.2025.113776},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113776},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Bridging the semantic-numerical gap: A numerical reasoning method of cross-modal knowledge graph for material property prediction},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based actor–critic for adaptive cryptocurrency portfolio rebalancing. <em>ASOC</em>, <em>185</em>, 113697. (<a href='https://doi.org/10.1016/j.asoc.2025.113697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-frequency trading in volatile markets, such as cryptocurrencies, requires portfolio models that can swiftly adapt to regime shifts while controlling risk. We propose a novel approach that frames portfolio management as a dynamic strategy-selection problem. Instead of directly predicting asset weights, our agent selects from a pool of expert strategies based on recent market trends. We introduce a Transformer-based Variational Autoencoder (VAE) to extract disentangled trend representations, and a trend-aware actor–critic model to perform expert selection. Experiments demonstrate that this modular, strategy-level control mechanism outperforms existing methods in risk-sensitive crypto portfolio management.},
  archive      = {J_ASOC},
  author       = {Ahmad Asadi and Reza Safabakhsh},
  doi          = {10.1016/j.asoc.2025.113697},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113697},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transformer-based actor–critic for adaptive cryptocurrency portfolio rebalancing},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustainable bridge management using refined feature selection for machine learning-aided bridge condition prediction: Incorporation of pareto distribution in MRMR method. <em>ASOC</em>, <em>184</em>, 113878. (<a href='https://doi.org/10.1016/j.asoc.2025.113878'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the critical phases of bridge management is condition prediction, which was enhanced after machine learning emerged. Researchers have used feature selection (FS) methods to reduce the predictors and optimise the prediction models. Prior studies have either explored a unified feature set for the overall bridge condition or focused solely on the deck, leading to limited predictions. This study proposes a refined feature selection method highlighting the importance of specific predictors for different bridge elements’ conditions using the California State inspection database from 1983 to 2021. The implemented FS approach consists of a verified Minimum-Redundancy Maximum-Relevance (MRMR) method followed by a Pareto analysis that identifies the most contributory factors in predicting the condition of bridges’ decks, superstructures, and substructures. The applied experiment on the US National Bridge Inventory database reveals that 28–33 predictor variables, out of more than 140 available features, contribute the most to each component’s health prediction with a cumulative importance score of over 95 %. Additionally, 22 mutual data items among the selected features are proposed as the minimum required predictors to be gathered by the asset management authorities. This study’s achievements help both researchers reduce the running costs of their prediction models and asset managers with data gathering and registration optimisation and, consequently, whole-of-life cycle cost reduction for sustainable asset management.},
  archive      = {J_ASOC},
  author       = {Vandad Dayan and Nicholas Chileshe and Reza Hassanli and Amin Parvaneh},
  doi          = {10.1016/j.asoc.2025.113878},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113878},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sustainable bridge management using refined feature selection for machine learning-aided bridge condition prediction: Incorporation of pareto distribution in MRMR method},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of fuzzy rule-based models in the presence of the big data environment. <em>ASOC</em>, <em>184</em>, 113869. (<a href='https://doi.org/10.1016/j.asoc.2025.113869'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a series of methods to build fuzzy rule-based models (FRBMs) in the presence of the big data environment such that the formed predictive models are more accurate, efficient, and robust. We follow two major steps to realize this target. In the first step, we build numeric FRBMs with the big data set such that the formed predictive models are more accurate and efficient. Specifically, based on the divide-and-conquer strategy, the big data set is divided into subsets through either the hyperplane division-based method or the K -Means clustering-based method; then either a global-based strategy or a local-based strategy is used to build numeric FRBMs. As a result, four Options are generated to develop numeric FRBMs. In the second step, we build the granular FRBMs based on the four Options developing the numeric FRBMs. Specifically, given a certain Option, based on the Principle of Justifiable Granularity (PJG), we granulate both condition parts and conclusion parts of the rules, forming the granular FRBMs; then the predictive models are further evaluated based on the PJG and optimized based on the Particle Swarm Optimization (PSO) algorithm to enhance the robustness. Finally, experimental studies on both synthetic datasets and publicly available datasets are conducted to prove the effectiveness of the proposed methods.},
  archive      = {J_ASOC},
  author       = {Yinghua Shen and Dan Zhao and Yan Li and Xingchen Hu and Yuan Chen and Bingsheng Liu},
  doi          = {10.1016/j.asoc.2025.113869},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113869},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Development of fuzzy rule-based models in the presence of the big data environment},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CMFF: A cross-modal multi-layer feature fusion network for multimodal sentiment analysis. <em>ASOC</em>, <em>184</em>, 113868. (<a href='https://doi.org/10.1016/j.asoc.2025.113868'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis seeks to interpret speaker sentiment by integrating information from multiple modalities, typically text and audio. While existing methods often focus on fusing deep-layer features extracted from the final stages of unimodal encoders, they may overlook crucial fine-grained information present in shallow-layer features (e.g., subtle phonetic variations or basic syntactic structures) relevant for nuanced sentiment understanding. Furthermore, effectively fusing features from different modalities presents the dual challenges of dynamically weighting each modality’s contribution and accommodating their inherent data heterogeneity. To address these limitations, we propose a novel Cross-modal Multi-layer Feature Fusion (CMFF) network. CMFF explicitly leverages the hierarchical information contained in both shallow-layer and deep-layer features from text and audio modalities. It employs multi-head cross-modal attention mechanisms within its fusion layers to facilitate interaction across feature layers and modalities. Crucially, CMFF incorporates a Mixture of Gated Experts (MoGE) network within these fusion layers. The MoGE utilizes modality-specific expert sub-networks, each tailored to process the distinct characteristics of text or audio data, thereby directly addressing data heterogeneity. Concurrently, each expert employs an internal gated feed-forward mechanism. This allows the model to dynamically control the information flow for each feature vector, effectively learning to weigh the importance of different feature dimensions from each layer and modality based on the input context. Extensive experiments conducted on the benchmark CMU-MOSI and CMU-MOSEI datasets demonstrate that the proposed CMFF model achieves competitive or superior performance compared to state-of-the-art methods across various standard evaluation metrics.},
  archive      = {J_ASOC},
  author       = {Shuting Zheng and Jingling Zhang and Yuanzhao Deng and Lanxiang Chen},
  doi          = {10.1016/j.asoc.2025.113868},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113868},
  shortjournal = {Appl. Soft. Comput.},
  title        = {CMFF: A cross-modal multi-layer feature fusion network for multimodal sentiment analysis},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating over-squashing in graph few-shot learning by leveraging local and global similarities. <em>ASOC</em>, <em>184</em>, 113863. (<a href='https://doi.org/10.1016/j.asoc.2025.113863'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised machine learning models, particularly neural networks, often fail to deliver satisfactory results in scenarios with insufficient data. This becomes even more challenging when dealing with inherently complex data, such as graph data. This paper addresses the issue of learning with a limited number of samples, known as n -way k -shot learning, within the context of graph data. Our research extends the concept of similarity from neighboring nodes to the entire graph by leveraging transitivity relations. By employing edges and strong transitivity relations, we utilize a bipartite graph neural network that capitalizes on both local neighborhoods and distant, yet similar, nodes to generate node embeddings. This approach has demonstrated effectiveness in tasks such as node classification. Our proposed model’s ability to mitigate the over-squashing problem enhances its generalizability, resulting in a task-invariant model. Experimental results on various graph datasets show that the embeddings produced by our model are not task-specific. Consequently, our model outperforms other models in few-shot learning scenarios, where only a limited number of labeled nodes are available for each distinct downstream task.},
  archive      = {J_ASOC},
  author       = {Yassin Mohamadi and Mostafa Haghir Chehreghani},
  doi          = {10.1016/j.asoc.2025.113863},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113863},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Mitigating over-squashing in graph few-shot learning by leveraging local and global similarities},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal intervention for feedback information in fairness recommendation. <em>ASOC</em>, <em>184</em>, 113862. (<a href='https://doi.org/10.1016/j.asoc.2025.113862'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, users’ feedback information is greatly affected by individual differences between users and usually interferes with the interaction between users and items, causing unfairness in the recommendation results. To alleviate the problem of unfair recommendation results caused by the confounding of feedback information, we propose a novel causal intervention for feedback information in fairness recommendation (CIFair). First, we construct a causal graph based on the interaction between users and items and analyze the reasons for unfair recommendation results caused by feedback information as the confounding factor through the causal graph. Then, we design a two-phase predicted rating generation, namely, the elimination and reconstruction phases. In the elimination phase, we analyze the dual effects of the confounding factor on the recommender system and eliminate it through causal intervention to improve the fairness of the recommendation results and obtain a fair predicted rating. In the reconstruction phase, we design personalized feedback information based on user and item attributes to ensure recommendation performance and obtain a personalized predicted rating. Finally, we combine the predicted ratings generated in the elimination and reconstruction phases and provide users with personalized recommendation results with fairness. We conduct experiments on three publicly available datasets (MovieLens-1M, Last.fm, and Yelp) to verify the significance of the CIFair. The ablation experiment confirms that the CIFair model can achieve relatively fair recommendations from both the user and item sides while ensuring recommendation performance.},
  archive      = {J_ASOC},
  author       = {Chenyu Wang and Guanxi Wang and Guowei Yang and Dun Li},
  doi          = {10.1016/j.asoc.2025.113862},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113862},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Causal intervention for feedback information in fairness recommendation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixing deep early exit ensembles for sensor-based human activity recognition through uncertainty quantification. <em>ASOC</em>, <em>184</em>, 113861. (<a href='https://doi.org/10.1016/j.asoc.2025.113861'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic deep neural networks (DNNs) have recently achieved outstanding success on a wide range of resource-constrained human activity recognition (HAR) tasks. However, prior most works are deterministic and could not provide any uncertainty estimate. Though an early exit can facilitate adaptive activity inference by producing intermediate predictions at multiple stages during forward pass, these predictions are only meaningful in real-world while complemented with reliable uncertainty estimates. Until now, the quality of uncertainty estimates has always been ignored in the context of early exit HAR. How to quantify predictive uncertainty in dynamic DNNs still remains challenging and yet unsolved. To address this issue, this paper introduces a new framework of early exit ensembles, which provides a probabilistic treatment of such dynamic DNNs to capture uncertainty estimates through an implicit ensemble of sub-networks sharing weights. We evaluate the proposed approach using three strong state-of-the-art DNN backbones on several mainstream HAR benchmarks, i.e., UCI-HAR, UniMib-SHAR and WISDM. Depending on the backbones and datasets, our approach can lower calibration error up to around 11 × , while increasing accuracy by up to 0.588% over its single counterpart. Both theoretical computational efficiency and practical runtime latency are analyzed. We provide an intuitive illustration of accounting for both aleatoric and epistemic uncertainty, which validates that such probabilistic treatment can adequately capture uncertainty estimates to aid decision-making while varying the computational budgets.},
  archive      = {J_ASOC},
  author       = {Xin Liu and Lei Zhang and Wenbo Huang and Dongzhou Cheng and Hao Wu and Aiguo Song},
  doi          = {10.1016/j.asoc.2025.113861},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113861},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fixing deep early exit ensembles for sensor-based human activity recognition through uncertainty quantification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transformer-based water quality prediction model with mixed fractional brownian features and multi-feature bottleneck transformation. <em>ASOC</em>, <em>184</em>, 113860. (<a href='https://doi.org/10.1016/j.asoc.2025.113860'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven water-quality model inference typically depends on large datasets. In emergency or resource-constrained settings, however, small sample sizes hinder a model’s ability to faithfully capture the complex nonlinear and multiscale dynamics of water quality. To address this challenge, we propose an improved Transformer. First, we enrich the inputs with features from mixed fractional Brownian motion with a perturbation factor (rMFBM). The rMFBM module captures heterogeneous temporal dependencies via multiple Hurst exponents and applies a Cholesky-based covariance sampler with a diagonal perturbation to ensure numerical stability. Second, a multi-feature bottleneck layer performs compression and dimensionality reduction to yield compact yet information-dense representations. Finally, the optimized features are modeled by a lightweight Transformer trained with the AMSGrad optimizer and an early-stopping strategy. On the task of predicting the N S F W Q I water-quality index, the proposed model reduces root-mean-square error (RMSE) by approximately 43.1% relative to a standard Transformer and improves the coefficient of determination ( R 2 ) by 1.89% across four small-sample datasets. It also outperforms widely used alternatives, including GNNs and PINNs. These results suggest that certain water-quality parameters exhibit mixed fractional Brownian-motion characteristics, enabling rapid and reliable prediction under data scarcity and in emergency scenarios.},
  archive      = {J_ASOC},
  author       = {Genghao Cui and Zhiyao Zhao and Li Wang and Huiyan Zhang and Jiabin Yu},
  doi          = {10.1016/j.asoc.2025.113860},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113860},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A transformer-based water quality prediction model with mixed fractional brownian features and multi-feature bottleneck transformation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MPCMamba: Privacy-preserving inference for mamba models via secure multi-party computation. <em>ASOC</em>, <em>184</em>, 113859. (<a href='https://doi.org/10.1016/j.asoc.2025.113859'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is increasingly critical across high-stakes domains, but privacy risks during model inference remain a major concern. Secure multi-party computation (SMPC) offers a promising solution by enabling privacy-preserving collaborative inference without exposing sensitive data. The recently proposed Mamba model, which outperforms Transformer in certain tasks, presents unique challenges for SMPC due to its state-space architecture and nonlinear operations. This paper introduces a framework for executing Mamba model inference under SMPC while preserving privacy. The framework natively supports linear operations and securely computes nonlinear functions – including square roots, exponentials, logarithms, and SiLU activations – without altering the original model architecture. Experimental results demonstrate that the proposed method achieves accuracy improvements of 2.4%, 2.84%, and 8.23% on CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets, respectively, compared to existing SMPC-based vision Transformer approaches, MPCViT. Additionally, inference latency is reduced by factors of 2.14 × , 2.14 × , and 26.13 × on these benchmarks, significantly advancing efficient and secure deployment of state-space models in privacy-sensitive scenarios.},
  archive      = {J_ASOC},
  author       = {Yongqiang Yu and Yuliang Lu and Xuehu Yan and Wei Yan and Shengyang Luo},
  doi          = {10.1016/j.asoc.2025.113859},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113859},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MPCMamba: Privacy-preserving inference for mamba models via secure multi-party computation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A depth-estimation-based method for multi-view synthesis applied to chinese landscape paintings. <em>ASOC</em>, <em>184</em>, 113858. (<a href='https://doi.org/10.1016/j.asoc.2025.113858'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenging task of novel view synthesis for traditional Chinese landscape paintings, which typically offer only a single perspective and lack clear depth information. To overcome the limitations of existing methods that rely on multi-view input and depth estimation, we propose a multi-view synthesis method for Chinese landscape paintings, termed MVSM-CLP. The proposed CLPDepth Module employs a high-low resolution fusion mechanism to enhance detail expression while preserving the original scene structure. We introduce an image restoration technique guided by landscape ink lines, termed LInpainting, to improve edge extraction and the accuracy of painting inpainting Additionally, our method tackles the issue of scarce 3D data in current view synthesis efforts by constructing multi-view data from a single ancient painting. Our approach effectively bridges the gap between 2D art and 3D visualization, creating vivid and realistic virtual environments while preserving the traditional style and essence of Chinese paintings. Experimental results demonstrate the effectiveness of our method in achieving high-quality multi-view synthesis, offering new possibilities for the digital preservation of cultural heritage. A preprint has previously been published (Peng et al., 2024 [1] ). The code and dataset is available at https://github.com/LPDLG/DepCLP_Dataset .},
  archive      = {J_ASOC},
  author       = {Xianlin Peng and Wanlin Zhou and Qiyao Hu and Tengfei Li and Dong Zhang and Rui Cao},
  doi          = {10.1016/j.asoc.2025.113858},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113858},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A depth-estimation-based method for multi-view synthesis applied to chinese landscape paintings},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGBA: Subspace guidance backdoor attack with feature alignment in image classification. <em>ASOC</em>, <em>184</em>, 113857. (<a href='https://doi.org/10.1016/j.asoc.2025.113857'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widely use of deep neural networks (DNNs) in a variety of classification and generation tasks with remarkable performance, the security of DNN models has attracted further attention. Recently, backdoor attacks have made a significant threat to DNN models, where attackers intentionally introduce malicious patterns into the model and manipulate the behavior of the model upon encountering the specific trigger. In this paper, we analyze the workflow of backdoor attacks with feature-guide classifier, and propose a novel method to conduct the backdoor attack based on feature alignment. We find that using samples with adversarial perturbation for training can mislead the model during the inference stage. Inspired by this observation, we leverage the intrinsic distribution of target class features in the latent space to generate effective and invisible triggers by adding directional perturbations to target images. We evaluate the attack under three widely used datasets and results show that our method can achieve considerable performance in comparison with other four state-of-the-art attacks. Furthermore, we also make extensive experiment to emphasize the robustness and stealthiness of our attack method.},
  archive      = {J_ASOC},
  author       = {Hao Luo and Zhi Qin and Lin Wang and Ziyue Wu and Min Yang},
  doi          = {10.1016/j.asoc.2025.113857},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113857},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SGBA: Subspace guidance backdoor attack with feature alignment in image classification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based kiwifruit flower recognition method to facilitate automated pollination. <em>ASOC</em>, <em>184</em>, 113855. (<a href='https://doi.org/10.1016/j.asoc.2025.113855'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate flowering-stage recognition is vital for intelligent orchard management, automated pollination, and yield forecasting. However, in complex natural scenes, existing models struggle to balance detection accuracy with inference speed. To bridge this gap, we propose the Kiwifruit Recognition Network (KiwiRecNet), a lightweight yet high-performance framework tailored to kiwifruit blossoms in the wild. KiwiRecNet first employs the Kiwifruit Generative Adversarial Network for Low-light Improvement (KiwiGAN-LI) to enhance under-exposed images. We then design a novel backbone, the Multi-Scale Shuffle Block (MSBlock), which combines structural re-parameterisation with channel–spatial shuffling to shrink the network footprint. Next, we propose the Partial-Mixing Vision Transformer (PMVIT), a convolution-Transformer hybrid that captures fine-grained features and remains robust to occlusion. Finally, we devise a Bidirectional Cross-Scale Fusion module (Bi-CSF) to enrich multiscale perception. Evaluated on the NWAFU Kiwifruit_F dataset, KiwiRecNet achieves 94.07 % mAP at 82.67 FPS with only 0.93 million parameters, outperforming existing lightweight detectors while approaching heavyweight baselines at a fraction of their cost. Consistent gains across multiple flower datasets confirm its generalisation ability. These results demonstrate an effective route to high-accuracy, real-time flowering-phase recognition on resource-constrained devices, paving the way for scalable agricultural automation.},
  archive      = {J_ASOC},
  author       = {Xiaopeng Li and Jinzhi Du and Xiaoyu Chen and Fuxi Shi and Shuqin Li},
  doi          = {10.1016/j.asoc.2025.113855},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113855},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep learning-based kiwifruit flower recognition method to facilitate automated pollination},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Searching for local pareto fronts based on the non-dominance range in the decision space. <em>ASOC</em>, <em>184</em>, 113853. (<a href='https://doi.org/10.1016/j.asoc.2025.113853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal multi-objective optimisation problems (MMOPs) involve multiple equivalent Pareto sets that share the same Pareto front, and a special subclass is known as MMOPs with local Pareto fronts (MMOPLs). Conventional multi-modal multi-objective optimisation evolutionary algorithms (MMOEAs) struggle to effectively identify local Pareto fronts, and existing methods tailored for MMOPLs exhibit notable limitations. Additionally, commonly used performance metrics lack systematic evaluation and suffer from inherent shortcomings. A simple yet effective MMOEA that leverages the non-dominance range in the decision space is proposed to address these challenges. By prioritising individuals with above-average non-dominance ranges, the algorithm enhances the identification and retention of both global and local optima. Convergence is further improved using the local outlier factor method. The limitations of existing performance metrics are analysed and six new performance metrics tailored for MMOPLs are introduced. To facilitate evaluation, benchmark problems are modified to create scenarios in which global and local optima coexist on the same Pareto set. Extensive experimental results confirm that the proposed algorithm achieves competitive performance, effectively identifying global and local optima while ensuring well-distributed solutions.},
  archive      = {J_ASOC},
  author       = {Yimin Shen and Yu Guo and Shaohua Huang and Weiwei Qian and Shengbo Wang and Litong Zhang},
  doi          = {10.1016/j.asoc.2025.113853},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113853},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Searching for local pareto fronts based on the non-dominance range in the decision space},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Normalizing flow defect detection model based on similar self-supervision. <em>ASOC</em>, <em>184</em>, 113847. (<a href='https://doi.org/10.1016/j.asoc.2025.113847'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome the limitations in unsupervised industrial anomaly detection, such as poor modeling of the appearance differences between synthetic and real defects and the failure to capture multi-scale feature relationships, this paper proposes a Normalizing Flow Defect Detection Model Based on Similar Self-Supervision (NF-SS). First, a feature-level defect generation method is introduced. It synthesizes realistic defect samples by fusing defect background features, known defect features from related domains, and other auxiliary features. This enhances the model's understanding of defect characteristics and reduces the gap between synthetic and real defects. Second, a multi-scale joint Normalizing Flow decoder is proposed. It replaces independent NF layers with progressive multi-scale fusion, allowing the model to integrate features hierarchically across scales. This preserves spatial relationships, reduces edge blurring, and improves defect localization accuracy. Extensive experiments on the MVTec AD dataset show that NF-SS outperforms state-of-the-art models, achieving an average image-level AUC of 99.54 % and pixel-level AUC of 98.76 %. It significantly improves the detection of subtle and ambiguous defects. NF-SS combines unsupervised and self-supervised learning, providing a robust solution for industrial quality inspection with limited defect samples.},
  archive      = {J_ASOC},
  author       = {Zhenlian Miao and Guangzhu Chen and Herui Cao and Yuan Tang and Xiaojuan Liao},
  doi          = {10.1016/j.asoc.2025.113847},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113847},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Normalizing flow defect detection model based on similar self-supervision},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refined vision to obtain the vibration trajectory of rotating body. <em>ASOC</em>, <em>184</em>, 113845. (<a href='https://doi.org/10.1016/j.asoc.2025.113845'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-contact vision technology has been widely used in many fields, but it still has limited accuracy in dealing with complex motion, small displacement and boundary recognition, especially in the rotating body scene, where it is difficult to balance global robustness and local sensitivity. To achieve high-precision visual measurement of rotating structure vibration, this paper proposes a detection-guided target tracking method to address the shortcomings of existing visual algorithms in target identity preservation and temporal consistency. In the face of the above challenges, this paper constructs lightweight encoder–decoder network to extract multi-scale semantic information to enhance the target edge modeling capability, and designs a multidimensional regression mechanism to predict the target boundary from the center point and extract sub-pixel vibration signals. At the same time, a guide term is introduced to optimize trajectory association and improve the temporal continuity and spatial consistency of tracking. Experimental results show that the average performance of the proposed method is improved by about 51.2% on the basis of multiple mainstream visual algorithms, and the main frequency recognition error is reduced to 0.32 Hz, which effectively suppresses high-frequency vibration errors. Ablation experiments verify the contribution of each module to the measurement accuracy, and low-quality image tests further show that the method has good generalization ability and application prospects.},
  archive      = {J_ASOC},
  author       = {Rongliang Yang and Tao Liu and Sen Wang},
  doi          = {10.1016/j.asoc.2025.113845},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113845},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Refined vision to obtain the vibration trajectory of rotating body},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving lightweight semi-supervised text classification via teacher intervention. <em>ASOC</em>, <em>184</em>, 113844. (<a href='https://doi.org/10.1016/j.asoc.2025.113844'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most recent semi-supervised text classification frameworks have focused on pre-trained models like BERT. While effective, their large-scale parameters and slow inference speed hinder deployment in many practical scenarios. In this work, we develop a general Li ghtweight S emi-supervised T ext classification framework (LiST), which significantly enhances the performance of lightweight models in semi-supervised settings, thus improving inference efficiency. LiST employs a teacher intervention strategy, where pseudo-labels initially rely on the teacher model and gradually shift to the lightweight model’s own predictions, progressively correcting the teacher’s incorrect predictions over time. Experimental results on multiple benchmark datasets demonstrate the generality and effectiveness of LiST. It not only approaches or exceeds the performance of the teacher model (UDA) at a 20 × faster inference speed but also outperforms existing lightweight methods in both performance and efficiency. Notably, LiST achieves significant performance improvements even with extremely few labeled samples, such as a 36.4% increase in accuracy on AG News with only 2 labeled samples per class.},
  archive      = {J_ASOC},
  author       = {Shaohuan Cheng and Wenyu Chen and Wanlong Liu and Hong Qu},
  doi          = {10.1016/j.asoc.2025.113844},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113844},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Improving lightweight semi-supervised text classification via teacher intervention},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chaotic property based multi-interval informer modeling method for long-term photovoltaic power generation prediction. <em>ASOC</em>, <em>184</em>, 113843. (<a href='https://doi.org/10.1016/j.asoc.2025.113843'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The long-term prediction of photovoltaic (PV) power generation capacity can significantly enhance the maintenance planning of photovoltaic power stations and support the long-term development strategies of power supply and distribution networks. Currently, two major challenges hinder the realization of effective long-term prediction for PV power generation: First, PV power generation data is heavily influenced by environmental factors, leading to high randomness and significant volatility in long-term data sequences; Second, the temporal continuity of long-term data must be considered, which complicates the construction of an accurate predictive model. To address these issues, this paper proposes a long-term PV power generation prediction method based on interval division, modeled using an improved Informer architecture with a modified activation function. Initially, by analyzing the fluctuation characteristics of PV power generation data, the K-nearest neighbors algorithm is applied for data interpolation, while the moving average (MA) method is employed for data smoothing, effectively reducing data randomness while preserving the overall trend. Subsequently, the Kmeans＋＋ clustering algorithm is utilized to group the generation data into multiple intervals, thereby enhancing feature similarity within each cluster. Finally, the activation function of the Informer model is replaced with ReLU to improve its adaptability to photovoltaic data characteristics. Additionally, this study introduces evaluation metrics such as the Hurst exponent and the Maximum Lyapunov Exponent (MLE) to assess the predictability of partitioned data and identify the interval to which predicted values belong. Simulation experiments demonstrate that, compared to several commonly used prediction models, the proposed interval-based approach achieves superior performance in long-term PV power generation prediction.},
  archive      = {J_ASOC},
  author       = {Ying Han and Xinggang Hu and Kun Li},
  doi          = {10.1016/j.asoc.2025.113843},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113843},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Chaotic property based multi-interval informer modeling method for long-term photovoltaic power generation prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A noisy multi-objective evolutionary optimization algorithm based on elman neural network. <em>ASOC</em>, <em>184</em>, 113842. (<a href='https://doi.org/10.1016/j.asoc.2025.113842'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks have emerged as potent tools for tackling multi-objective optimization problems with remarkable success. This research delves into the performance of dynamic neural networks in resolving noisy multi-objective optimization problems (NMOPs). The local regression structure of the Elman neural network enables it to deal with the dynamic noise problem well. This paper integrates the Elman neural network into the framework of the non-dominated sorting genetic algorithm II (NSGA-II) to solve NMOP, called E-NSGA-II. In this method, the Elman neural network is employed for modeling, estimating the fitness value of each individual. Simultaneously, a hybrid selection solution strategy is implemented to select individuals for modeling, providing more diverse solutions in the modeling process to improve the convergence. Furthermore, E-NSGA-II incorporates a noise-driven sampling mechanism that intelligently adapts the sampling frequency based on the noise intensity. This feature could not only enhance the accuracy of neural network modeling, but also minimize the amount of calculation. Notably, the embedding of neural network does not impose much additional evaluation overheads, thereby bolstering the overall efficiency of E-NSGA-II. Experimental results prove the superiority of E-NSGA-II over four state-of-the-art noisy multi-objective optimization algorithms on dealing with NMOPs.},
  archive      = {J_ASOC},
  author       = {Jianxia Li and Ruochen Liu and Wanfeng Chen and Weibin Li},
  doi          = {10.1016/j.asoc.2025.113842},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113842},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A noisy multi-objective evolutionary optimization algorithm based on elman neural network},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective detection algorithm for small UAV based on lightweight you-only-look-once (YOLOv4-l) approach. <em>ASOC</em>, <em>184</em>, 113841. (<a href='https://doi.org/10.1016/j.asoc.2025.113841'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control and monitoring of small Unmanned Aerial Vehicles (UAV) plays a crucial role in national defense and security. However, due to their compact size and high mobility, the detection of small UAV across diverse scenarios remains a significant challenge. To address this issue, this study proposes an improved detection algorithm tailored for small UAV. The model is initially trained on a virtual dataset, and the learned parameters are transferred to real-world data through a transfer learning framework. To optimize anchor box generation, clustering analysis is performed on bounding box dimensions, resulting in anchor boxes with appropriate scales and aspect ratios. Furthermore, the Ghost module is introduced to replace conventional convolutions in CSPDarknet53, enhancing feature extraction efficiency. An Efficient Channel Attention (ECA) mechanism is also incorporated to strengthen output feature representations and improve the capture of texture details critical for small target detection. Through experiments, the proposed algorithm can achieve the mAP0.5 of 82.2 %. Experimental results demonstrate the effectiveness of the proposed small UAV detection method.},
  archive      = {J_ASOC},
  author       = {Guoning Li and Jianghao Cheng and Yanyan Liu and Jin Li and Zengming Lv and Qiang Li},
  doi          = {10.1016/j.asoc.2025.113841},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113841},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An effective detection algorithm for small UAV based on lightweight you-only-look-once (YOLOv4-l) approach},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TPLLM: A traffic prediction framework based on pretrained large language models. <em>ASOC</em>, <em>184</em>, 113840. (<a href='https://doi.org/10.1016/j.asoc.2025.113840'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction constitutes a critical component in sustainable urban data analysis, playing a pivotal role in optimizing transportation systems for reduced carbon emissions and improved energy efficiency. The precision of prevailing deep learning-driven traffic prediction models typically improves as the volume of training data increases. However, the procurement of comprehensive spatiotemporal datasets for traffic is often fraught with challenges, primarily stemming from the substantial costs associated with data collection and retention. This limitation severely hinders the deployment of models in regions with insufficient historical data. Consequently, developing a model that can achieve accurate predictions and good generalization ability in areas with limited historical traffic data is a challenging problem. It is noteworthy that the rapidly advancing pretrained Large Language Models (LLMs) of recent years demonstrate exceptional proficiency in cross-modality knowledge transfer and few-shot learning. Recognizing the sequential nature of traffic data, similar to language, we introduce TPLLM, a novel traffic prediction framework leveraging LLMs. In this framework, we construct a sequence embedding layer based on Convolutional Neural Networks (CNNs) and a graph embedding layer based on Graph Convolutional Networks (GCNs) to extract sequence features and spatial features, respectively. These are subsequently integrated to form inputs that are suitable for LLMs. A Low-Rank Adaptation (LoRA) fine-tuning approach is applied to TPLLM, thereby facilitating efficient learning and minimizing computational demands. Experiments on two real-world datasets demonstrate that TPLLM exhibits commendable performance in both full-sample and few-shot prediction scenarios.},
  archive      = {J_ASOC},
  author       = {Tian Ma and Yixuan Zhao and Minda Li and Yue Chen and Fangshu Lei and Yanan Zhao and Maazen Alsabaan},
  doi          = {10.1016/j.asoc.2025.113840},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113840},
  shortjournal = {Appl. Soft. Comput.},
  title        = {TPLLM: A traffic prediction framework based on pretrained large language models},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-linguistic fusion for brain tumor classification: A cross-modal attention framework with clinical interpretability. <em>ASOC</em>, <em>184</em>, 113839. (<a href='https://doi.org/10.1016/j.asoc.2025.113839'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate classification of brain tumors is a key challenge in medical image analysis, and existing methods mainly rely on static MRI images, which are difficult to capture the dynamic evolutionary features of tumors. In addition, the lack of descriptive clinical text and efficient multimodal feature fusion limits the classification accuracy and generalization. To overcome these limitations, this paper proposes a new dynamic language fusion (DLF) framework. The framework (1) utilizes ResNet18 in conjunction with LSTM for time series modeling to capture the temporal evolution of tumor morphology, (2) uses BioGPT and BERT for clinical text processing for semantic understanding, and (3) applies an interpretable cross-modal attentional mechanism for feature fusion to optimize dynamic perception and semantic alignment. Experiments on 10,287 images (from four publicly available datasets) show that the proposed framework achieves an overall accuracy of 98.96 %, a precision of 99.58 %, and an AUC higher than 0.998 for all categories on the test set, which is significantly better than the existing SOTA models, and especially exhibits stronger robustness and discriminative ability in boundary ambiguity and feature overlap samples. This study validates the synergistic effect of temporal modeling and semantic understanding in brain tumor diagnosis, providing clinicians with interpretable classification outputs to assist in decision-making for complex cases, while establishing a scalable framework for medical AI systems based on large language models.},
  archive      = {J_ASOC},
  author       = {Jiancong Fan and Fangyuan Chen and Yang Li and Jiehan Zhou},
  doi          = {10.1016/j.asoc.2025.113839},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113839},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic-linguistic fusion for brain tumor classification: A cross-modal attention framework with clinical interpretability},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Path planning for flexible needle puncture based on multi-objective particle swarm optimization. <em>ASOC</em>, <em>184</em>, 113838. (<a href='https://doi.org/10.1016/j.asoc.2025.113838'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a mixed-parameter MOPSO algorithm designed to address the puncture problem of flexible needles in obstacle environments. The algorithm incorporates the damage caused by the pivotal angle to soft tissues as an objective function, marking the first time this has been applied to the MOPSO algorithm. In comparison with four classical algorithms through simulation experiments, the path deviation is reduced to just 0.1 mm, significantly lower than the CPSO algorithm. The final path score achieves 35 points, surpassing the performance of other algorithms. A self-built FPAA hybrid control platform was employed for puncture experiments using a gelatin prosthesis. The experimental results confirm that the flexible needle successfully avoids obstacles and reaches the target, demonstrating the feasibility of the proposed puncture algorithm.},
  archive      = {J_ASOC},
  author       = {Ting Yang and Beibei Liu and Ru Sun and Bi Chen and Guijuan Ji},
  doi          = {10.1016/j.asoc.2025.113838},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113838},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Path planning for flexible needle puncture based on multi-objective particle swarm optimization},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-goal reinforcement learning framework for motion planning of a quadrotor UAV in 3D cluttered environment with unseen random goals. <em>ASOC</em>, <em>184</em>, 113836. (<a href='https://doi.org/10.1016/j.asoc.2025.113836'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The standard reinforcement learning (RL) approaches render an optimal solution for a specific task by learning an optimal policy. Therefore, these RL approaches are suitable for single goal problems only. However, there exist numerous practical challenges that involve multiple goals to be achieved in a specific environment. For example, navigation of an unmanned aerial vehicle (UAV) to achieve multiple random targets in a specific three-dimensional (3D) cluttered space is a multi-goal problem. Using the standard RL approaches, the UAV agent needs to learn a separate optimal policy for each target. Thus, a multi-goal problem with random unseen goal allocations, especially in the 3D space of UAVs, increases computational effort substantially. To solve this issue, this paper presents a relatively generalized approach that learns the optimal state values and related optimal policies considering various regions of the robot environment. The proposed approach transforms the 3D robot environment into a Markov decision process (MDP) and further divides it into various virtual sub-spaces. For every initial goal position in a sub-space, value iteration algorithm enables the aerial agent to learn the optimal state values and the relevant policy. These optimal state values and policies are then stored in a replay buffer for later use. Once the initial state values for every sub-space are learned, the proposed approach allows the agent to use them from replay buffer and run a local search algorithm to connect every new goal position to any feasible state in the existing state values. Our proposed framework significantly reduces the computational effort for multiple unseen goal targets by restricting the re-computation of state values for each new goal. To validate the proposed method, a simulator is designed and an RL-based motion planning approach for a quadrotor UAV is presented. The results under various scenarios confer the superior performance of our anticipated multi-goal RL framework.},
  archive      = {J_ASOC},
  author       = {Ghulam Farid and Lanyong Zhang and Talha Younas and Muhammad Ilyas and Asma Iqbal},
  doi          = {10.1016/j.asoc.2025.113836},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113836},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-goal reinforcement learning framework for motion planning of a quadrotor UAV in 3D cluttered environment with unseen random goals},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wind speed prediction based on U-shaped 2D multi-scale model. <em>ASOC</em>, <em>184</em>, 113835. (<a href='https://doi.org/10.1016/j.asoc.2025.113835'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind speed forecasting is essential for enhancing energy efficiency and reducing maintenance costs in wind power systems. However, existing CNN-LSTM and Transformer-based models face limitations in capturing periodic features, modeling long-term dependencies, and preserving information during multi-layer encoding. To overcome these challenges, this paper proposes a novel U-shaped 2D multi-scale model that integrates Bi-RLSTM encoding, wavelet transform, and multi-scale 2D convolution. The proposed model first encodes input sequences into a high-dimensional space via feature embedding and Bi-RLSTM, effectively capturing long-term dependencies. Subsequently, a wavelet transform extracts primary fluctuation patterns and their periods, converting 1D sequences into 2D feature maps to enhance periodic feature representation while preserving temporal information. Multi-scale convolutional layers are then employed to extract fine-grained spatial–temporal features from these maps. Finally, a Bi-RLSTM decoding layer, augmented with skip connections, mitigates information loss during deep encoding and reinforces long-range correlation modeling. Extensive experiments on two real-world wind speed datasets demonstrate that the proposed model significantly outperforms CNN-LSTM and attention-based approaches achieving superior performance in terms of MAE, RMSE, and R 2 , confirming its effectiveness and application potential.},
  archive      = {J_ASOC},
  author       = {Yue Gao and Zhongda Tian},
  doi          = {10.1016/j.asoc.2025.113835},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113835},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Wind speed prediction based on U-shaped 2D multi-scale model},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing multi-task learning-based tornado identification using spatial and temporal information from weather radar images. <em>ASOC</em>, <em>184</em>, 113834. (<a href='https://doi.org/10.1016/j.asoc.2025.113834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tornadoes, as dynamic weather phenomena, exhibit unique spatial and temporal evolution characteristics that reflect their formation and development. Existing tornado detection algorithms often struggle with high false alarm rates, primarily due to insufficient capture of temporal correlations in tornado development. As an improvement, we propose a multi-task tornado identification network with three-dimensional temporal and spatial information (TS-MTINet). Taking continuous three-frame radar data as input, the Multi-frame Temporal Interaction Block (MTIB) utilizes multi-head attention to model the dynamic interaction information between the radar data, thus exploring in-depth the temporal features during tornado development. Further, we design a Spatial-Temporal Enhancement Module (STEM), which analyzes the difference information between continuous data to extract local and global spatial and temporal feature variations about tornadoes. Based on this architecture, TS-MTINet incorporates a multi-task learning framework to perform tornado detection and number estimation tasks simultaneously, thus extracting comprehensive information related to tornadoes. To validate the performance of the proposed model, we construct the first Chinese tornado identification dataset with fine radar features. The experimental results show that the proposed method shows significant advantages in several evaluation metrics, especially in reducing false alarms. In practical case studies, compared to the traditional TVS method, TS-MTINet achieves an increase in POD of approximately 30% and a decrease in FAR of about 20% in several typical tornado events. Particularly in environments with strong interference, TS-MTINet demonstrates higher detection accuracy, reflecting greater robustness and practical value.},
  archive      = {J_ASOC},
  author       = {Jinyang Xie and Kanghui Zhou and Lei Han and Liang Guan and Maoyu Wang and Yongguang Zheng and Hongjin Chen and Jiaqi Mao},
  doi          = {10.1016/j.asoc.2025.113834},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113834},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhancing multi-task learning-based tornado identification using spatial and temporal information from weather radar images},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating regional green industry competitiveness in china: A CoSOGR-MABAC-sort framework. <em>ASOC</em>, <em>184</em>, 113831. (<a href='https://doi.org/10.1016/j.asoc.2025.113831'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of concepts such as the green economy and sustainable development, the development of green industry has become increasingly urgent. Regional green industry competitiveness, as a key indicator reflecting the development status and competitive advantages of regional green industry, has not yet received sufficient attention and research. To fill this research gap, this paper proposes an evaluation framework, CoSOGR-MABAC-Sort (Combined Subjective-Objective, Grey Relational analysis-Multi-Attributive Border Approximation area Comparison-Sort), to assess the green industry competitiveness in 31 regions of China. In the proposed framework, the MABAC-Sort method is a novel multi-criteria decision sorting method with six classification rules. Compared to other MCDS methods, this method does not require predefined profile boundaries and can provide more detailed classification results. Furthermore, we propose an optimal model , called CoSOGR, to determine the weights of each indicator. Finally, by collecting subjective and objective data, we use the proposed framework to assess the green industry competitiveness in the 31 provinces of China. The main findings are as follows: 1) The CoSOGR demonstrates the highest consistency (99.33 %) in regions ranking compared to existing weight methods (CRITIC, EWM, ROCOSD, and MEREC). 2) The CoSOGR addresses the weight determination issues that ROCOSD (a mixed-integer linear programming model) cannot resolve. 3) The CoSOGR-MABAC-Sort method exhibit strong robustness and stability. 4) The green industry competitiveness in each region shows a positive correlation with the sustainable development of that region.},
  archive      = {J_ASOC},
  author       = {Jiafu Su and Baojian Xu and Lvcheng Li and Yijun Chen and Hongyu Liu and Na Zhang},
  doi          = {10.1016/j.asoc.2025.113831},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113831},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluating regional green industry competitiveness in china: A CoSOGR-MABAC-sort framework},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AutoTandemML: Active learning enhanced tandem neural networks for inverse design problems. <em>ASOC</em>, <em>184</em>, 113828. (<a href='https://doi.org/10.1016/j.asoc.2025.113828'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse design in science and engineering involves determining optimal design parameters that achieve desired performance outcomes, a process often hindered by the complexity and high dimensionality of design spaces, leading to significant computational costs. To tackle this challenge, we propose a novel hybrid approach that combines active learning with Tandem Neural Networks to enhance the efficiency and effectiveness of solving inverse design problems. Active learning allows to selectively sample the most informative data points, reducing the required dataset size without compromising accuracy. We investigate this approach using three benchmark problems: airfoil inverse design, photonic surface inverse design, and scalar boundary condition reconstruction in diffusion partial differential equations. We demonstrate that integrating active learning with Tandem Neural Networks outperforms standard approaches across the benchmark suite, achieving better accuracy with fewer training samples.},
  archive      = {J_ASOC},
  author       = {Luka Grbcic and Juliane Müller and Wibe Albert de Jong},
  doi          = {10.1016/j.asoc.2025.113828},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113828},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AutoTandemML: Active learning enhanced tandem neural networks for inverse design problems},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized cross-domain recommendation with meta networks and contrastive learning. <em>ASOC</em>, <em>184</em>, 113827. (<a href='https://doi.org/10.1016/j.asoc.2025.113827'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel cross-domain recommendation (CDR) model that integrates matrix factorization (MF), attention networks, meta-networks, and contrastive learning (CL) to address the challenges of data sparsity and cold-start problems in recommender systems. Our model consists of five modules: the MF module extracts user and item embeddings from rating matrices in both information-rich and information-scarce domains; the transferable feature extraction module uses an attention network to identify and extract transferable features from users’ interactions in the information-rich domain; the cross-domain meta-knowledge transfer module employs a meta-network to transfer these features across domains while preserving users’ personalized preferences; the intra-domain CL module ensures temporal consistency of users’ preferences by learning from their interaction sequences in the information-rich domain; and the inter-domain CL module leverages feedback from users’ interactions in the information-scarce domain to refine the transferable features. We conduct extensive experiments on the Amazon and Douban datasets, evaluating our model across three different CDR tasks. The results demonstrate that our proposed model outperforms other prevalent CDR models in terms of MAE and RMSE. Additionally, our model shows the robust performance in cold-start scenarios, effectively utilizing both intradomain and interdomain knowledge to enhance the recommendation accuracy.},
  archive      = {J_ASOC},
  author       = {Shudong Liu and Xiping Hao and Xu Chen and Wenming Ma and Feng Gu},
  doi          = {10.1016/j.asoc.2025.113827},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113827},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Personalized cross-domain recommendation with meta networks and contrastive learning},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient real-time visual anomaly detection via frequency-aware diffusion model and information fusion. <em>ASOC</em>, <em>184</em>, 113826. (<a href='https://doi.org/10.1016/j.asoc.2025.113826'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time visual anomaly detection is always a big challenge since advanced techniques usually suffer from intensive computation, while simple methods cannot obtain desirable performance. To address this issue, an Efficient Real-time Anomaly Detection method via frequency-aware diffusion model and information fusion (ERAD) is proposed, which uses the diffusion model to achieve a nice reconstruction for the frequency information obtained by Discrete Wavelet Transform (DWT) and utilizes the information fusion technique to take full consideration of local and global various features. First, the input image is fed into the DWT module to produce one low-frequency and three high-frequency coefficient images, in this way, data dimensions can be reduced by 75% but the important information can be greatly retained. Then, a diffusion model with one-step denoising is developed rather than the traditional iterative denoising to accelerate the reconstruction speed. As well, information fusion in the framework of selective fusion is embedded into the reconstruction process to improve the model performance. Furthermore, during the segmentation, a wavelet-based upsampling module is put forward to seamlessly combine global semantic context with detailed edge information, achieving both consistent semantics and high-resolution feature reconstruction. Finally, extensive experiments conducted on a variety of benchmark datasets demonstrate the remarkable superiority of our method in both model performance and time efficiency. Specifically, the proposed method achieves an Image AUROC of 99.7 and a Pixel AUROC of 99.5, with an inference time of only 0.04 s.},
  archive      = {J_ASOC},
  author       = {Xianzhe Yao and Ping Kong and Quanquan Li and Yan Song},
  doi          = {10.1016/j.asoc.2025.113826},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113826},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Efficient real-time visual anomaly detection via frequency-aware diffusion model and information fusion},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-splitting conformal prediction for multi-step time series forecasting. <em>ASOC</em>, <em>184</em>, 113825. (<a href='https://doi.org/10.1016/j.asoc.2025.113825'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is crucial for applications like resource scheduling and risk management, where multi-step predictions provide a comprehensive view of future trends. Uncertainty Quantification (UQ) is a mainstream approach for addressing forecasting uncertainties, with Conformal Prediction (CP) gaining attention due to its model-agnostic nature and statistical guarantees. However, most variants of CP are designed for single-step predictions and face challenges in multi-step scenarios, such as reliance on real-time data and limited scalability. This highlights the need for CP methods specifically tailored to multi-step forecasting. We propose the Dual-Splitting Conformal Prediction (DSCP) method, a novel CP approach designed to capture inherent dependencies within time-series data for multi-step forecasting. Experimental results on real-world datasets from four different domains demonstrate that DSCP significantly outperforms existing CP variants in terms of the Winkler Score, improving performance by up to 23.59% compared to state-of-the-art methods. Furthermore, the deployment of DSCP for renewable energy generation and IT load forecasting in the power management of a real-world trajectory-based application achieves an 11.25% reduction in carbon emissions through predictive optimization of data center operations and control strategies.},
  archive      = {J_ASOC},
  author       = {Qingdi Yu and Zhiwei Cao and Ruihang Wang and Zhen Yang and Lijun Deng and Min Hu and Yong Luo and Xin Zhou},
  doi          = {10.1016/j.asoc.2025.113825},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113825},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual-splitting conformal prediction for multi-step time series forecasting},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDP-net: Fourier transform guided lightweight depthwise and pointwise dynamic pooling based neural network for medical image classification. <em>ASOC</em>, <em>184</em>, 113824. (<a href='https://doi.org/10.1016/j.asoc.2025.113824'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, deep learning-based medical image classification has become essential, especially in developing countries because of the high volume of patients with less medical professionals as well as required infrastructures. Deep learning models often help in the early detection of diseases; however, it require a high amount of processing power, and sometimes it becomes less scalable for various computer-aided diagnosis. To this end, in this paper, a lightweight Fourier Transform guided Depth and Pointwise Dynamic Pooling based Neural Network (FDP-Net), has been proposed for medical image classification. This paper introduces a Depth and Pointwise Feature Fusion (DPFF) block for learning the important features with less computation and without increasing the model parameters. It also proposes a dynamic pooling technique, an alternative to traditional max-pooling, which dynamically selects the important features. The proposed FDP-Net model is trained to classify medical images with the guidance of Fourier Transformation and multitask loss function, which makes the model converge faster and reduces overfitting. The proposed model has been tested on Acute Lymphoblastic Leukemia (ALL) dataset, Peripheral Blood Cell (PBC) dataset, and Raabin White blood Cell (Raabin-WBC) dataset, and it outperforms the state-of-the-art models with 100%, 98.13% and 96.79% classification accuracies, respectively. Additionally, the proposed model is made with only 0.349 million parameters, thereby enabling faster processing. Code will be avilabe at https://github.com/asfakali/FDP-Net .},
  archive      = {J_ASOC},
  author       = {Asfak Ali and Rajdeep Pal and Aishik Paul and Ram Sarkar},
  doi          = {10.1016/j.asoc.2025.113824},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113824},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FDP-net: Fourier transform guided lightweight depthwise and pointwise dynamic pooling based neural network for medical image classification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explicit cooperation mechanism and multimodal fusion prediction model empower DouDizhu agents. <em>ASOC</em>, <em>184</em>, 113823. (<a href='https://doi.org/10.1016/j.asoc.2025.113823'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imperfect information games require agents to make decisions under uncertainty, presenting significant challenges yet offering broad applicability in real-world scenarios. DouDizhu, a representative example, features complex cooperative-competitive dynamics, imperfect information, and a large strategy space. To address these challenges, a strategic decision-making algorithm is developed by integrating multi-agent credit allocation with information prediction. Specifically, an explicit credit allocation mechanism based on team reward decomposition improves cooperative behavior among peasant agents by enabling more stable and targeted policy updates. Meanwhile, combining long short-term memory networks and multi-head attention enhances the prediction of hidden opponent information through multimodal feature fusion. Moreover, convolutional neural networks are incorporated into the DouZero framework to extract high-level features and reduce the policy solution space. The resulting CAPRE_DMC significantly improves agent performance in adversarial settings. Extensive evaluations demonstrate that CAPRE_DMC outperforms baseline DouDizhu agents, achieving substantial gains in point margin and win percentage. Additionally, evaluations on benchmark multi-agent cooperative tasks demonstrate the framework’s scalability and generality in large-scale imperfect-information environments.},
  archive      = {J_ASOC},
  author       = {Jiao Wang and Longyue Fu and Xiang Li and Hongchen Luo and Zhifen Guo},
  doi          = {10.1016/j.asoc.2025.113823},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113823},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Explicit cooperation mechanism and multimodal fusion prediction model empower DouDizhu agents},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight detection method for X-ray security inspection based on YOLOV8. <em>ASOC</em>, <em>184</em>, 113822. (<a href='https://doi.org/10.1016/j.asoc.2025.113822'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of public safety, the prohibited items detection during X-ray security inspection is crucial for preventing potential threats. The recent advances in artificial intelligence, particularly deep learning, have achieved success in this area. However, the high number of parameters and computational load of these deep learning-based object detection methods result in significant hardware requirements limiting their practical application. To address these issues, a lightweight method for detecting prohibited items in X-ray security inspections, utilizing the YOLOV8 framework, is proposed in this paper. The key innovations of this method are threefold. First, a lightweight convolution module is designed to optimize the YOLOV8 model. This optimization significantly reduces both the number of parameters and the computational load, making the model more efficient. Second, an adaptive spatial-and-channel attention module is designed to enhance feature extraction capabilities. This module enhances feature extraction capabilities without compromising detection accuracy. Third, the Wise-IOU loss function is incorporated to enhance the overall performance of the detection method during training. Finally, the method is evaluated on our real X-ray pseudo-color image dataset, PIDRAY and CLCXRAY with the existing methods. Our proposed method attains a detection accuracy of 98.83 % on the self-constructed dataset, demonstrating a 0.6 % improvement, while concomitantly reducing the parameters by 64.2 % and computational load by 66.3 %. Furthermore, it achieves accuracy enhancements of 0.7 % and 0.82 % on the two public datasets, respectively. The experimental results indicate that this method not only reduces hardware requirements due to a lower number of parameters and computational load but also broadens the model's applicability. This work underscores the importance of balancing model complexity with performance and sets the stage for future research in AI-driven security inspection technologies.},
  archive      = {J_ASOC},
  author       = {Xizhuo Yu and Chunyang Chen and Shu Cheng and Jingming Li},
  doi          = {10.1016/j.asoc.2025.113822},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113822},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A lightweight detection method for X-ray security inspection based on YOLOV8},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic transformation of basic probability assignment based on weighted visibility graph networks. <em>ASOC</em>, <em>184</em>, 113821. (<a href='https://doi.org/10.1016/j.asoc.2025.113821'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster-Shafer evidence theory (DSET) provides a powerful framework for uncertain reasoning, offering a theoretical basis for decision-making under ambiguity. However, its core representation, the basic probability assignment (BPA), cannot be directly applied to probabilistic decision-making, prompting the need for effective probability transformation methods. A key challenge lies in quantifying the uncertainty inherent in BPAs to guide this transformation process. To address this, we propose an improved probabilistic transformation method that integrates belief entropy and weighted visibility graph networks, which yields more accurate and interpretable probability distributions than existing approaches. Specifically, given a frame of discernment and mass function, we first apply two refined belief entropy measures to evaluate the informational content of each focal element. Based on these entropy-derived orderings, we construct a weighted visibility graph that captures the structural relationships among focal elements. The weights from this graph are then used to compute a proportional belief transformation. Experimental validation across benchmark cases on classical BPA scenarios demonstrates that our method outperforms traditional approaches in terms of entropy consistency and decision quality, as evidenced by lower Kullback–Leibler (KL) divergence, higher probability information capacity (PIC), and reduced Shannon entropy. These results highlight the method’s dual advantage in balancing decisiveness (via PIC maximization) and fidelity (via entropy minimization), making it a robust tool for uncertainty-aware decision support systems.},
  archive      = {J_ASOC},
  author       = {Yongchuan Tang and Kangkang Wu and Rongfei Li and He Guan and Deyun Zhou and Yubo Huang},
  doi          = {10.1016/j.asoc.2025.113821},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113821},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Probabilistic transformation of basic probability assignment based on weighted visibility graph networks},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electric network frequency-based digital audio tampering event identification using multimodal feature interaction network. <em>ASOC</em>, <em>184</em>, 113820. (<a href='https://doi.org/10.1016/j.asoc.2025.113820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of digital Audio Tampering Event (ATE) detection based on Electric Network Frequency (ENF), accurately extracting ENF signals is crucial for tampering event identification. However, ENF signals are susceptible to noise interference, and it is difficult to establish an effective matching relationship with the reference frequency database, which poses a challenge to the effectiveness of existing ATE detection methods. To solve these problems, a Multimodal Feature Interactive Network (MFIN) is proposed for ATE identification under low-SNR conditions. First, a Modified Kaiser-window-based S-Transform (MKST) method is proposed to extract the estimated frequency, phase, rate of change of frequency, and rate of change of phase of the ENF component in digital audio. The frequency and time resolution are increased through the improved control function, thereby enhancing the accuracy of ENF estimation. Subsequently, a Multi-Branch Multi-Scale Attention Convolutional (MBSAC) neural network is further proposed to extract and classify ENF features. In MBSAC, the Multi-Branch Multi-Scale Temporal (MBST) attention fusion block, serving as the network’s primary structure, increases feature diversity and enhances classification performance. Finally, the ATE data acquisition hardware platform is built. Experimental results on a dataset comprising six types of ATEs demonstrate that the proposed MFIN outperforms several state-of-the-art ATE detection methods in both ENF extraction and tampering type classification.},
  archive      = {J_ASOC},
  author       = {Bing Li and Junfeng Duan and Yao Zheng and Xinxin Cai and Wei Qiu and He Yin and Wenxuan Yao},
  doi          = {10.1016/j.asoc.2025.113820},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113820},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Electric network frequency-based digital audio tampering event identification using multimodal feature interaction network},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing financial resilience in manufacturing SMEs: A q-rung picture fuzzy set-based decision framework for digital transformation adoption. <em>ASOC</em>, <em>184</em>, 113819. (<a href='https://doi.org/10.1016/j.asoc.2025.113819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital transformation (DT) has emerged as a crucial strategy for enhancing the financial resilience of small and medium-sized enterprises (SMEs) in the manufacturing sector. Despite its importance, there is a significant gap in the quantitative evaluation of the factors influencing SMEs’ DT adoption. This study addresses this gap by developing a decision framework using q-rung picture fuzzy sets (q-RPF) to identify and analyze the drivers of DT implementation aimed at boosting financial resilience in manufacturing SMEs. The proposed framework incorporates the q-RPF-weighted Heronian mean aggregation operator to aggregate expert evaluations and capture the interrelationships among input decision data. A novel weighting approach, based on the q-RPF deviation measure, is introduced to assess the significance of various enablers. Furthermore, the q-RPF-MARCOS’H model is employed to evaluate the effectiveness of DT in enhancing financial resilience across different SMEs by integrating the methodologies mentioned above. A numerical example involving manufacturing SMEs from a specific city demonstrates the practical application of the q-RPF-MARCOS’H model-based framework. The results reveal that “concurrent operations” (0.102) is a significant enabler of DT adoption in promoting financial resilience. The framework’s validity is confirmed through both sensitivity and comparative analyses. These outcomes offer recommendations for policymakers and industry leaders to design effective incentives for DT adoption and provide practical guidance for SMEs seeking to leverage DT for improved financial resilience.},
  archive      = {J_ASOC},
  author       = {Zhengyan Yang and Wei Zhong Wang and Zelin Wang and Muhammet Deveci and Dursun Delen},
  doi          = {10.1016/j.asoc.2025.113819},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113819},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhancing financial resilience in manufacturing SMEs: A q-rung picture fuzzy set-based decision framework for digital transformation adoption},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A regret theory-based three-way decision model under comparative linguistic expressions. <em>ASOC</em>, <em>184</em>, 113816. (<a href='https://doi.org/10.1016/j.asoc.2025.113816'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real world, experts often prefer to utilize linguistic expressions over numerical data when evaluating alternatives. However, due to the complexity of actual decision-making, single linguistic terms are insufficient for experts to express their judgments accurately. Thus, it is necessary to employ a richer form of linguistic expression, known as comparative linguistic expressions (CLEs). Furthermore, existing multi-attribute decision-making (MADM) models under CLE suffer from the following limitations: (1) they fail to provide decision-making references for alternatives; (2) they do not incorporate the psychological factors of experts. In order to address the aforementioned challenges, this paper proposes a novel regret theory (RT)-based three-way decision (TWD) model under CLE. First, the attribute weights are calculated by an improved optimization model. This model combines index variability with comprehensive entropy, enabling a more objective conclusion to be drawn regarding the relative importance of attributes. Second, an enhanced neighborhood relationship is introduced, which is shown to fulfill the properties of Symmetry, Reflexivity, and Non-transitivity. Building on this foundation, this study integrates RT with the neighborhood relationship to construct a wide TWD framework. This framework incorporates decision-making references for the alternatives and accounts for the influence of experts’ psychological factors. Subsequently, the ranking of alternatives is determined using the technique for order preference by similarity to ideal solution (TOPSIS) method. Finally, the feasibility of the proposed method is demonstrated through a real-case study. Comparative experiments and parameter sensitivity analysis are designed to demonstrate the superiority and effectiveness of the model.},
  archive      = {J_ASOC},
  author       = {Zhanhao Liu and Huangjian Yi and Yushan Yao and Jiajia Wang},
  doi          = {10.1016/j.asoc.2025.113816},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113816},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A regret theory-based three-way decision model under comparative linguistic expressions},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A Q-learning based estimation of distribution algorithm for automated guided vehicle scheduling in disassembly workshop. <em>ASOC</em>, <em>184</em>, 113815. (<a href='https://doi.org/10.1016/j.asoc.2025.113815'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid upgrade of electronic products, the disassembly process is becoming increasingly crucial in facilitating resources recycling. In practical disassembly workshops, the automated guided vehicle (AGV) plays an important role in improving efficiency of product transportation between different disassembly machines. In this paper, a Q-learning based estimation of distribution algorithm (QEDA) is proposed to solve the AGV scheduling problem in disassembly workshops with minimization of makespan for all transportation tasks. Firstly, a mathematical model for the problem is established, and specific encoding and decoding rules are designed for solution representation. Secondly, a novel update mechanism of EDA is designed by fully information utilization of both elite and poor solutions to accelerate convergence. Thirdly, a local search strategy based on Q-learning with three time-related states is designed for the elite solutions to enhance exploitation. Finally, comparative experiments on 120 benchmark test sets demonstrate that the QEDA outperforms the state-of-the-art algorithms in both solution quality and convergence speed, confirming its superior effectiveness for AGV scheduling in disassembly workshops.},
  archive      = {J_ASOC},
  author       = {Honggui Han and Teng Wang and Jingjing Wang},
  doi          = {10.1016/j.asoc.2025.113815},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113815},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A Q-learning based estimation of distribution algorithm for automated guided vehicle scheduling in disassembly workshop},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Criterion-guided polypharmacy side effects prediction with dual-view contrastive learning. <em>ASOC</em>, <em>184</em>, 113814. (<a href='https://doi.org/10.1016/j.asoc.2025.113814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting side effects from taking multiple drugs (polypharmacy) is a critical challenge in healthcare, with significant implications for patient safety. Traditional machine learning methods often overlook the multi-scale nature of drug information and the interdependencies among side effects, limiting their predictive power. To address these gaps, we propose CASE (Criterion-guided polyphArmacy Side Effects prediction with dual-view contrastive learning). CASE captures both microscopic (molecular graph) and macroscopic (biochemical knowledge) drug features via an adaptive substructure encoder and a biochemical feature aggregator, respectively, under a dual-view framework. Then, contrastive learning is employed to jointly balance and integrate structural and biochemical representations, enabling a more comprehensive and synergistic understanding of drug interactions. Moreover, a criterion-guided decoding strategy is designed to model complex side effect relationships. This effective design enables the proposed CASE model to achieve superior performance, with an accuracy of 88.70 %, precision of 83.62 %, recall of 96.45 %, F1-score of 89.56 %, AUROC of 94.75 %, and AUPRC of 91.16 %, respectively, on the benchmark dataset. Ablation experiments and case studies further confirm the robustness and practical utility of the model. These results demonstrate that CASE can effectively assist clinical decision-making by identifying high-risk drug combinations and delivering reliable polypharmacy risk assessments, thereby supporting safer and more personalized treatment strategies.},
  archive      = {J_ASOC},
  author       = {Yike Wang and Huifang Ma and Zihao Gao and Zhixin Li and Liang Chang},
  doi          = {10.1016/j.asoc.2025.113814},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113814},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Criterion-guided polypharmacy side effects prediction with dual-view contrastive learning},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying suicidal ideations from social media posts using deep learning and explainable AI-driven approach. <em>ASOC</em>, <em>184</em>, 113813. (<a href='https://doi.org/10.1016/j.asoc.2025.113813'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background At present, suicide has become one of the leading causes of unnatural deaths worldwide. Individuals having suicidal urges often express their self-harming ideas through social media posts. Early identification of such ideations is critical for timely intervention and prevention. Besides, continuous assessment of the texts containing suicidal thoughts can uncover the hidden triggers of suicidal urges. This study presents a comprehensive approach to analyze the user-generated textual contents on social media that reflect suicidal ideas. Methodology For identifying the underlying topics that express suicidal ideations, this study has employed the Latent Dirichlet Allocation (LDA) model. Semantic Network Analysis (SNA) is used to gain a deeper quantitative and qualitative insight into these texts. Besides, an exploratory investigation of different deep learning (DL) models has been performed to identify the posts speculating suicidal ideations. Furthermore, this study has integrated Explainable AI (XAI) techniques like Local Interpretable Model-agnostic Explanations (LIME) and Shapley Additive Explanations (SHAP) to enhance interpretability of the decisions taken by the DL models. Techniques like LDA and SNA offer a better understanding of the linguistic features of the suicidal posts, while the integration of the XAI techniques with the DL models elevates the transparency of their decisions. Contributions This study has developed an end-to-end web application, that can perform real-time classification of posts for suicidal ideation. Moreover, this application can provide insights into the rationale behind the taken decisions. This study aims to contribute to suicide prevention efforts through an innovative combination of computational techniques and AI-driven tools.},
  archive      = {J_ASOC},
  author       = {Md. Sabab Zulfiker and Nasrin Kabir and Al Amin Biswas and Md. Mashih Ibn Yasin Adan and Mohammad Shorif Uddin},
  doi          = {10.1016/j.asoc.2025.113813},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113813},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Identifying suicidal ideations from social media posts using deep learning and explainable AI-driven approach},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight network enhanced by attention-guided cross-scale interaction for underwater object detection. <em>ASOC</em>, <em>184</em>, 113811. (<a href='https://doi.org/10.1016/j.asoc.2025.113811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the image quality degradation caused by multipath effects and scattering in underwater environments, we propose a lightweight neural network architecture, PRCII-Net, optimized for small target detection under complex underwater conditions. First, a Progressive Re-parameterized Attention-based Intra-scale Feature Interaction module (PR-AIFI) is proposed, which improves the network performance while reducing the difficulty of training and maintaining training stability. Second, a feature pyramid network named as the Cross-scale Information Interaction Feature Pyramid Network (CII-FPN) is proposed, including the two main fusion structures. The CII-FPN not only fully utilizes shallow and deep information, but also enhances the network’s spatial representation and the interaction between deep feature layers, thereby boosting the detection capability for small targets. Meanwhile, to reduce the model’s size and resource consumption, 1x1 convolutions are introduced into the backbone network for efficient channel compression and cross-channel feature fusion, significantly lowering computational complexity. Experiments on the Detecting Underwater Objects (DUO) and Real-time Underwater Object Detection (RUOD) datasets demonstrate that PRCII-Net outperforms existing real-time neural network models in mAP and F1 scores while maintaining efficient inference on resource-constrained devices.},
  archive      = {J_ASOC},
  author       = {Dehua Zhang and Changcheng Yu and Zhen Li and Chunbin Qin and Ruixue Xia},
  doi          = {10.1016/j.asoc.2025.113811},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113811},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A lightweight network enhanced by attention-guided cross-scale interaction for underwater object detection},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preferences relative ordering by frequency inclusion technique (PROFIT) for optimizing performance evaluation. <em>ASOC</em>, <em>184</em>, 113807. (<a href='https://doi.org/10.1016/j.asoc.2025.113807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this investigation is to introduce the novel concept of the neutro-cardinal family of inclusion measures, a four-parameter family of fuzzy inclusion measures tailored for single-valued neutrosophic sets (SVNSs). These measures are built using a new scalar cardinality measure for SVNSs, termed weighted average cardinality, and incorporate logical operators such as single-valued neutrosophic Frank t-norms and their corresponding dual t-conorms. The versatility offered by this four-parameter family allows the variation of t-norms and t-conorms within each measure based on a fixed combination of parameters. This flexibly supports modeling various layers of human cognitive behavior, particularly the outermost states: optimism (via fuzzy Lukasiewicz t-norms and t-conorms), neutrality (via product and probabilistic sum operators), and pessimism (via min and max operators). Moreover, capturing these distinct mental states, the family allows combinations of them, enabling the representation of more complex and deeper cognitive processes. Consequently, the proposed inclusion measures serve as robust and versatile mathematical tools for designing artificial intelligence (AI) systems in multi-criteria decision making (MCDM) environments. Building upon this family, we present a new MCDM method named PROFIT (Preferences Relative Ordering by Frequency Inclusion Technique). PROFIT is designed as a simple yet effective decision-making approach that leverages the neutro-cardinal measures to support AI-based evaluation processes. It is investigated in the context of organizational management, in which it enables diligent performance evaluation. The PROFIT model’s data-driven and adaptive structure is consistent with resilience-focused initiatives like Resilient Manufacturing, ManuChain II, and Towards Resilience in Industry 5.0. As such, it serves as a strategic tool for optimizing decision-making, enhancing performance, and strengthening organizational resilience in dynamic and complex environments.},
  archive      = {J_ASOC},
  author       = {Madiha Qayyum and Dania Farooq and Muhammad Riaz and Muhammad Aslam and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2025.113807},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113807},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Preferences relative ordering by frequency inclusion technique (PROFIT) for optimizing performance evaluation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A state alignment-centric approach to federated system identification: The FedAlign framework. <em>ASOC</em>, <em>184</em>, 113800. (<a href='https://doi.org/10.1016/j.asoc.2025.113800'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents FedAlign, a Federated Learning (FL) framework, designed for System Identification (SYSID) of linear State-Space Models (SSMs) by aligning state representations. Local workers can learn linear SSMs with equivalent representations but different parameter basins. We demonstrate that directly aggregating these local SSMs via FedAvg results in a global model with altered system dynamics. FedAlign overcomes this problem by employing similarity transformation matrices to align state representations of local SSMs, thereby establishing a common parameter basin that retains the dynamics of local SSMs. FedAlign computes similarity transformation matrices via two distinct approaches. In FedAlign-A, we represent the global SSM in controllable canonical form (CCF). We use control theory to analytically derive similarity transformation matrices that convert each local SSM into this form. Yet, establishing global SSM in CCF brings additional alignment challenges in multi-input multi-output SYSID, as CCF representation is not unique, unlike in single-input single-output SYSID. In FedAlign-O, we address the alignment challenges by reformulating the local parameter basin alignment problem as an optimization task. We set the parameter basin of a local worker as the common parameter basin and solve least square problems to obtain the transformation matrices needed to align the remaining local SSMs. The experiments conducted on synthetic and real-world datasets show that FedAlign outperforms FedAvg, converges faster, and provides improved global SSM stability thanks to local parameter basins’ alignment.},
  archive      = {J_ASOC},
  author       = {Ertuğrul Keçeci and Müjde Güzelkaya and Tufan Kumbasar},
  doi          = {10.1016/j.asoc.2025.113800},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113800},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A state alignment-centric approach to federated system identification: The FedAlign framework},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal harmonics prediction for distribution systems powered by multi-energy sources using bidirectional long-short term memory combined with data sequence. <em>ASOC</em>, <em>184</em>, 113799. (<a href='https://doi.org/10.1016/j.asoc.2025.113799'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-energy resource aims to maintain a balance between energy output and load consumption and to ensure power continuity during different operating conditions. The harmonic distortions can be estimated from the output current of a harmonic source, which may not fully reflect its true harmonic distortions due to the interactions between the state changes at the power network level and the harmonic sources. System operators monitor each system's harmonic performance under different conditions of operation to find the actual contribution of grid-connected systems to harmonic-related issues. Development of machine learning algorithms leads to effective progress in the harmonic prediction and computation. In this paper, the combined data sequencing, and Bidirectional Long-Short Term Memory (Bi-LSTM) network has been exploited for the real-time harmonic prediction of future events in multi-energy sources. The validity of the proposed Model including the applications of ANFIS, ANNs, MLRA and LSTM is conducted on the two standard systems as IEEE 9-bus and IEEE 34-bus multi energy resources system that is associated with PV systems. The simulation results, based on climate changes of solar irradiance and ambient temperature in PV systems, demonstrate that the proposed methods can accurately forecast changes in total harmonic distortion (THD) as well as the voltage profile at the point of common coupling. The performance of Bi-LSTM, original LSTM, Machine Linear Regression (MLR), and Artificial Neural Networks (ANNs) techniques were assessed. These findings provide valuable insights. Four performance validation indices, RMSE, R-squared and MSE are considered to assess the performance of the competitive learning algorithms. The results showed that in the model IEEE 9-bus, Bi-LSTM outperformed all the applied methods as its RMSE value was 0.000019 while its MSE value was 3.61e-10 and finally, the Bi-LSTM had a higher value squared error (R 2 ) was equal 1 which indicates the effectiveness of Bi-LSTM for predicting sequential total harmonic distortion. On the other hand, in case study of IEEE 34-bus, the RMSE, MSE and R 2 are 0, 3.276e-30 and 1 using Bi-LSTM which means that the Bi-LSTM leads to the best performance validation indices compared to other competitive algorithms for the tested multi-energy systems.},
  archive      = {J_ASOC},
  author       = {Hasnaa M. El-Arwash and Almoataz Y. Abdelaziz and Ragab A. El-Sehiemy},
  doi          = {10.1016/j.asoc.2025.113799},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113799},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimal harmonics prediction for distribution systems powered by multi-energy sources using bidirectional long-short term memory combined with data sequence},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced robot path planning on rough terrain: A Q-learning-based multi-objective PSO algorithm. <em>ASOC</em>, <em>184</em>, 113798. (<a href='https://doi.org/10.1016/j.asoc.2025.113798'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning remains one of the most extensively studied problems in mobile robotics. While particle swarm optimization (PSO) has been widely adopted for this task, conventional implementations exhibit critical limitations including being prone to local optima, lacking population diversity, and having low accuracy — all of which compromise both the quality and efficiency of path planning solutions. To address these challenges, this paper proposes a novel hybrid algorithm called MOQLCPSO that synergistically integrates Q-learning (QL) with crossover operators into multi-objective particle swarm optimization (MOPSO) for car-like mobile robots operating in known static rough terrain environments. The proposed framework aims to generate collision-free optimal paths characterized by minimal length and terrain roughness through three key innovations: Firstly, we implement QL-based dynamic parameter adaptation to autonomously adjust PSO’s inertia weight and learning factors during optimization, effectively enhancing convergence towards the Pareto front. Secondly, a strategic crossover operator is introduced to augment exploration capabilities and maintain population diversity throughout the optimization process. Finally, comprehensive comparative simulations against state-of-the-art alternatives demonstrate MOQLCPSO’s superior performance metrics. The experimental results reveal statistically significant improvements in search accuracy, population diversity, and optimization efficiency across multiple terrain complexity levels. Notably, when benchmarked against the most competitive contemporary algorithm, MOQLCPSO achieves path length reduction of 0.64%, 2.42%, and 3.87%, terrain roughness reduction of 6.68%, 5.24%, and 4.72% in simple, moderately complex, and highly complex terrains, respectively. These advancements highlight the algorithm’s strong potential for deployment in multi-objective optimization scenarios ranging from autonomous mobile robot navigation and smart manufacturing resource allocation to power grid dispatch operations.},
  archive      = {J_ASOC},
  author       = {Zhaoxia Duan and Yi Zhang and Zhen Shao and Zhen Xu and Zhengrong Xiang},
  doi          = {10.1016/j.asoc.2025.113798},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113798},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advanced robot path planning on rough terrain: A Q-learning-based multi-objective PSO algorithm},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combined variable precision fuzzy rough set and its application in medical diagnosis. <em>ASOC</em>, <em>184</em>, 113797. (<a href='https://doi.org/10.1016/j.asoc.2025.113797'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data processing, variable precision fuzzy rough set plays a crucial role in removing noisy data. Different variable precision ideas have been used to solve various problems and achieve different goals. Among them, the variable precision ideas by Zhao and Yao are widely recognized by researchers. However, a single method is often insufficient to solve complex problems. In this study, we combined these two variable precision ideas and introduced a new variable precision fuzzy rough set model ( O - C-VPFR ), which includes the advantages and properties of the aforementioned two models. Next, using the concept of attribute importance in O - C-VPFR , we developed a simple, objective method for calculating attribute weights. Based on this method, we further developed a comprehensive decision-making method integrating Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) and Preference Ranking Organization Method for Enrichment Evaluations (PROMETHEE). The new method was applied to the problem of health risk assessment of pregnant women (HRPW, https://archive.ics.uci.edu/dataset/863/maternal+health+risk ). We conducted parameter and comparative analyses by randomly selecting 10 data points from HRPW, proving the stability and reliability of our method through the Pearson correlation coefficient. Further, we used the entire dataset and performed an ordered similarity experiment and a hypothesis testing experiment to verify the stability, effectiveness, and robustness of the proposed method. In all experiments, our method comprehensively ranked pregnant women, identified high-risk individuals, and enabled timely treatment.},
  archive      = {J_ASOC},
  author       = {Jingwen Xie and Lingqiang Li},
  doi          = {10.1016/j.asoc.2025.113797},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113797},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Combined variable precision fuzzy rough set and its application in medical diagnosis},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing evacuation path planning in high-rise building fires using an improved ant colony algorithm and dynamic window approach under smoke control scenarios. <em>ASOC</em>, <em>184</em>, 113796. (<a href='https://doi.org/10.1016/j.asoc.2025.113796'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional emergency evacuation strategies are constrained by limited adaptability to dynamic conditions and inefficient allocation of rescue resources. To assess the impact of smoke control facilities during high-rise fire evacuations, Building EXODUS software was used to simulate occupant behavior under the influence of air curtains and mechanical smoke exhaust systems. Furthermore, to address real-time obstacle avoidance in dynamic environments and during group movement in fire emergencies, a multi-person evacuation path planning method was developed by integrating an improved ant colony optimization algorithm with the dynamic window approach. This method incorporates a heuristic function that considers fire conditions and potential fields, along with a dynamic pheromone update strategy featuring reward and punishment mechanisms. The results indicate that the effectiveness of smoke control facilities in improving evacuation outcomes ranks as follows: combined operation of mechanical smoke extraction and air curtains, mechanical smoke extraction alone, and air curtains alone. Compared to the standard ant colony algorithm, the improved algorithm reduced planned path length by 7.71 %, decreased turn times by 73.30 %, and improved computational efficiency by 6.56 %. Furthermore, under scenarios with and without operational smoke control facilities, the improved algorithm combined with the dynamic window approach reduced path overlap areas by 11.76 % and 18.19 %, respectively, and shortened path lengths by 13.49 % and 14.19 %, respectively, compared to the Building EXODUS. The proposed method effectively addresses dynamic fire environments in high-rise buildings and provides a theoretical foundation for intelligent occupant evacuation.},
  archive      = {J_ASOC},
  author       = {Yaping Yu and Qinghe Wang and Lu Jin and Ji-nan Ding and Faqi Liu},
  doi          = {10.1016/j.asoc.2025.113796},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113796},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimizing evacuation path planning in high-rise building fires using an improved ant colony algorithm and dynamic window approach under smoke control scenarios},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ribonucleic-acid protein interaction prediction based on deep learning: A comprehensive survey. <em>ASOC</em>, <em>184</em>, 113795. (<a href='https://doi.org/10.1016/j.asoc.2025.113795'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interaction between Ribonucleic Acids (RNAs) and proteins, also called RNA Protein Interaction (RPI), governs biological processes, including gene regulation and disease pathogenesis. This comprehensive survey examines Artificial Intelligence (AI) applications in Deep Learning-based RPI Prediction (DL-based RPIP) through eight Research Questions (RQs), analyzing 179 studies (2014–2023). The key findings include: sustained technical evolution through embryonic (2014–2017), accelerated (2018–2022), and expansion phases (2023) (RQ1); hybrid models integrating Graph Neural Networks (GNNs) (for topological interface modeling) and Transformers (for long-range dependencies) achieve state-of-the-art performance (RQ4); pretrained language models enhance small-sample learning, but the cross-species generalization declines sharply with evolutionary distance (RQ5). Critical challenges persist, including data heterogeneity across databases, the scarcity of standardized benchmarks (RQ2), and balancing the trade-off between feature encoding and information preservation (RQ3). Future advancements require biologically informed DL architectures, multi-feature fusion, and rigorous cross-validation to bridge the generalization-interpretability gap (RQ8): This would accelerate the clinical translation of predictive tools (RQ6/RQ7). As the first comprehensive analysis spanning feature encoding, modeling, evaluation, applications, and tools, this work fills a critical gap in the DL-based RPIP literature.},
  archive      = {J_ASOC},
  author       = {Danyu Li and Rubing Huang and Chenhui Cui and Dave Towey and Ling Zhou and Jinyu Tian and Bin Zou},
  doi          = {10.1016/j.asoc.2025.113795},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113795},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ribonucleic-acid protein interaction prediction based on deep learning: A comprehensive survey},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level pooling self-adaptive evolutionary multi-objective gene selection algorithm for microarray data classification. <em>ASOC</em>, <em>184</em>, 113794. (<a href='https://doi.org/10.1016/j.asoc.2025.113794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gene selection is a vital preprocessing technique for cancer classification using microarray data, focusing on identifying a subset of genes that achieve high classification accuracy while minimizing the gene selection rate. Despite the prevalence of multi-objective optimization algorithms in microarray data classification, balancing high classification accuracy and effective guidance in microarray classification remains challenging for most existing algorithms. This study proposes a novel multi-objective gene selection method, MOGS-MLPSAE, which utilizes multi-level pooling and self-adaptive evolutionary techniques to enhance classification accuracy. MOGS-MLPSAE employs a Pareto-based ranking pool division strategy to facilitate cross-level learning among individuals and introduces a population-biased evolutionary mechanism with five rules to drive the population toward higher classification accuracy. Compared with seven state-of-the-art multi-objective algorithms across 14 microarray datasets, MOGS-MLPSAE achieves superior performance, with classification accuracy 1.56–8.04 % higher than other algorithms and the lowest gene selection rate (average 1 %, minimum 0.01 %). This study demonstrates MOGS-MLPSAE's effectiveness in balancing classification accuracy and gene selection rate, offering a robust solution for microarray-based cancer classification.},
  archive      = {J_ASOC},
  author       = {Min Li and Rutun Cao and Chen Jin and Junke Wang and Shaobo Deng and Xiang Yu},
  doi          = {10.1016/j.asoc.2025.113794},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113794},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-level pooling self-adaptive evolutionary multi-objective gene selection algorithm for microarray data classification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Activity transitions for semi-supervised federated learning in sensor-based human activity recognition. <em>ASOC</em>, <em>184</em>, 113793. (<a href='https://doi.org/10.1016/j.asoc.2025.113793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor-based Human Activity Recognition (HAR) is a core component in many real-world applications such as healthcare, fitness tracking, and smart environments. However, training effective HAR models is often constrained by limited labeled data and growing privacy concerns. Federated Learning (FL) offers a privacy-preserving solution by enabling collaborative model training without sharing raw sensor data. To further address the label scarcity challenge, we propose ATCoFed, a Semi-Supervised Federated Learning (SSFL) framework that introduces a novel pseudo-label filtering method based on activity transition patterns. Unlike existing approaches that rely solely on confidence thresholds, ATCoFed incorporates temporal context by using Long Short-Term Memory (LSTM) networks and Large Language Models (LLMs) as data-driven evaluators to validate the consistency of predicted activity sequences. This dual-evaluator mechanism improves the quality of pseudo-labels and enhances model robustness. Experimental results on benchmark HAR datasets demonstrate that ATCoFed consistently outperforms SSFL baselines, achieving better accuracy while maintaining computational and communication efficiency. These findings highlight the potential of activity-aware filtering to improve semi-supervised learning in privacy-preserving HAR applications.},
  archive      = {J_ASOC},
  author       = {Tori Andika Bukit and Ericka Pamela Bermudez Pillado and Bernardo Nugroho Yahya and Seok-Lyong Lee},
  doi          = {10.1016/j.asoc.2025.113793},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113793},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Activity transitions for semi-supervised federated learning in sensor-based human activity recognition},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TPCMEA: A tri-population evolutionary algorithm with adaptive stage-switching for complex CMOPs. <em>ASOC</em>, <em>184</em>, 113792. (<a href='https://doi.org/10.1016/j.asoc.2025.113792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems (CMOPs) involve the optimization of objective functions along with the satisfaction of constraints, presenting significant challenges in obtaining optimal solutions. To address difficulties such as conflicting objectives, complex constraints, disconnected and narrow feasible regions, this paper proposes a novel tri-population constrained multi-objective evolutionary algorithm (TPCMEA). This algorithm innovatively introduces an adaptive diversity-convergence stage-switching method (DCSSM), based on dual indicators of diversity and convergence, by dynamically monitoring the Euclidean distance distribution of the populations and convergence towards the optimal objective vector, overcoming the issues of premature convergence or resource wastage in traditional algorithms. Moreover, TPCMEA adopts a collaborative framework with three populations, each utilizing different search strategies to effectively solve complex CMOPs. These strategies encompass achieving rapid convergence under constraints, exploring unconstrained fronts to enhance solution diversity, and integrating information from the first two populations through knowledge transfer and compressive sampling strategies. Experimental results demonstrate that TPCMEA exhibits significant competitive advantages across the MW, LIRCMOP, CF benchmark test suites and real-world engineering problems, not only in terms of superior convergence and diversity but also displaying stronger robustness and adaptability in addressing issues related to narrow feasible regions and disconnected fronts.},
  archive      = {J_ASOC},
  author       = {Jun Chen and Xiaobo Li and Yuxin Zhao and Zhendi Ma and Zhongmei Han and Yanxia Bao},
  doi          = {10.1016/j.asoc.2025.113792},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113792},
  shortjournal = {Appl. Soft. Comput.},
  title        = {TPCMEA: A tri-population evolutionary algorithm with adaptive stage-switching for complex CMOPs},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective differential evolution algorithm integrating a directional generation mechanism for multi-objective optimization problems. <em>ASOC</em>, <em>184</em>, 113791. (<a href='https://doi.org/10.1016/j.asoc.2025.113791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective Evolutionary Algorithms (MOEAs) have gained significant attention due to their effectiveness in solving multi-objective optimization problems. However, when dealing with complex problems, they often face challenges such as low convergence accuracy and poor diversity. To address these issues, we propose a novel multi-objective differential evolution algorithm, MODE-FDGM, which integrates a directional generation mechanism. The key contributions are: (1) A directional-generation method leverages current and past information to rapidly build feasible solutions, boosting both speed and quality in exploring Pareto non-dominated space; (2) An update mechanism that combines crowding distance evaluation, iterating the population and incorporating historical information to enhance diversity and improve the ability to escape local optima; and (3) The introduction of an ecological niche radius concept along with a dual-mutation ecological niche selection evolution strategy, which improves exploration of unexplored spaces and preserves population diversity. Comparative experiments against 7 algorithms, including both classical and contemporary ones, on 24 benchmark functions demonstrate that the proposed algorithm markedly enhances the exploration of Pareto non-dominated solutions, exhibiting superior performance and advanced capabilities.},
  archive      = {J_ASOC},
  author       = {Zhuoxuan Yuan and Haibin Ouyang and Steven Li and Essam H. Houssein and Nagwan Abdel Samee},
  doi          = {10.1016/j.asoc.2025.113791},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113791},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-objective differential evolution algorithm integrating a directional generation mechanism for multi-objective optimization problems},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relaxation-based exploration and clustering-based exploitation for multimodal multi-objective optimization. <em>ASOC</em>, <em>184</em>, 113790. (<a href='https://doi.org/10.1016/j.asoc.2025.113790'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multi-objective optimization problems represent a specific type of multi-objective optimization problem where multiple distinct Pareto optimal solution sets (PSs) correspond to the same Pareto optimal front. Although the local PSs may not be as effective as the global PSs, obtaining the latter can be more costly. Therefore, the local PSs still hold some value for decision makers. However, many multimodal multi-objective evolutionary algorithms (MMOEAs) adopt the convergence-first criterion, which makes it challenging to obtain both the global and local PSs. To address the above issue, this paper proposes a two-stage dual-population coevolutionary algorithm with relaxation-based exploration and clustering-based exploitation (RCEA). Specifically, the relaxation-based exploration strategy defines an adaptive maximum Pareto rank, and relaxes the selection threshold for candidates from strictly non-dominated solutions to valuable solutions within this rank. Moreover, the clustering-based exploitation strategy performs a density-based decomposition on the population, separating different global and local PSs to facilitate more targeted evolution. During exploitation, a novel offspring generation operator is employed for intra-subpopulation crossover, preventing the waste of computational resources. Additionally, an improved convergence indicator is proposed to measure the convergence of solutions, which effectively handles the isolated solutions that may be erroneously identified as local Pareto optimal solutions by adaptively adjusting the neighborhood radius. Experimental results demonstrate that RCEA outperforms seven state-of-the-art MMOEAs on 70 benchmark problems.},
  archive      = {J_ASOC},
  author       = {Qianlong Dang and Zhiyang Zhang and Xiaochuan Gao and Tingting Wang},
  doi          = {10.1016/j.asoc.2025.113790},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113790},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Relaxation-based exploration and clustering-based exploitation for multimodal multi-objective optimization},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compute-efficient and backpropagation-free pseudoinverse learning for neural networks: A comprehensive survey. <em>ASOC</em>, <em>184</em>, 113789. (<a href='https://doi.org/10.1016/j.asoc.2025.113789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pseudoinverse learning algorithm is a non-gradient, efficient learning scheme originally designed for training single hidden layer feedforward neural networks. It has been developed into various variants and successfully applied across numerous fields. This paper provides a systematic review of the fundamental theories of the pseudoinverse learning algorithm and its major variants, outlining different types of neural networks and learning system architectures based on the pseudoinverse learning scheme. Furthermore, we summarize the fundamental ideas and methodologies of applying the pseudoinverse learning scheme to various learning tasks such as classification, representation learning, time series forecasting, incremental learning, automated machine learning, and content generation. We also summarize and compare the performance of pseudoinverse learning with representative competing baselines on several commonly used data sets based on existing literature reports. The results demonstrate that PIL exhibits significant efficiency advantages over gradient-based approaches (training time was reduced by 72.73% to 99.37%), aligning with its inherent gradient-free nature. Notably, recent PIL variants maintain this computational superiority while achieving enhanced performance compared to other gradient-free algorithms. In addition, we briefly introduce the representative applications of pseudoinverse learning in various fields. To the best of our knowledge, this is the first comprehensive review in this field to encompass all aforementioned aspects. It facilitates the synthesis and integration of existing knowledge from disparate studies. By highlighting limitations in prior works including the computational complexity in large-scale pseudoinverse computation, potential numerical instability for ill-conditioned matrices, risk of overfitting, and constraints in modeling multidimensional patterns, this paper also recommends directions for future research in this area.},
  archive      = {J_ASOC},
  author       = {Ke Wang and Pandi Liu and Mohammed A.B. Mahmoud and Ping Guo and Yafei Li},
  doi          = {10.1016/j.asoc.2025.113789},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113789},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Compute-efficient and backpropagation-free pseudoinverse learning for neural networks: A comprehensive survey},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient constrained multi-population cooperation search algorithm for multi-objective optimization of multireservoir operation. <em>ASOC</em>, <em>184</em>, 113788. (<a href='https://doi.org/10.1016/j.asoc.2025.113788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-objective optimization of multireservoir operation, complex nonlinear constraints often result in highly fragmented and discontinuous feasible regions, making it difficult for traditional algorithms to simultaneously achieve rapid convergence and maintain solution diversity. To effectively address this challenge, this paper proposes a novel Constrained Multi-Population Cooperation Search Algorithm (cMPCSA), which establishes an adaptive balance between global exploration and local exploitation through a cooperative evolutionary mechanism. The proposed algorithm achieves key advancements by constructing a modular multi-population framework with distinct subpopulation roles, integrating a constraint-independent environmental selection mechanism, and introducing a multi-factor learning strategy that combines edge, mean, and stochastic solutions to guide the search process more effectively. Experimental results on four mainstream multi-objective benchmark test suites demonstrate that cMPCSA significantly outperforms existing algorithms in terms of convergence performance and solution quality. Further application to a real-world multireservoir operation case confirms its robustness and superiority in coordinating multiple objectives such as hydropower generation, water supply reliability, and ecological flow protection. Overall, this study provides an efficient and scalable algorithmic tool for addressing complex multi-objective optimization problems in modern water resource management.},
  archive      = {J_ASOC},
  author       = {Zhong-kai Feng and Li Zhang and Xia-yu Wang and Fang Yang and Yi-hong Jiang and Sen Wang and Wen-jing Niu},
  doi          = {10.1016/j.asoc.2025.113788},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113788},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An efficient constrained multi-population cooperation search algorithm for multi-objective optimization of multireservoir operation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep insights into cognitive decline: A survey of leveraging non-intrusive modalities with deep learning techniques. <em>ASOC</em>, <em>184</em>, 113787. (<a href='https://doi.org/10.1016/j.asoc.2025.113787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive decline is a natural part of aging. However, under some circumstances, this decline is more pronounced than expected, typically due to disorders such as Alzheimer’s disease. Early detection of an anomalous decline is crucial, as it can facilitate timely professional intervention. While medical data can help, it often involves invasive procedures. An alternative approach is to employ non-intrusive techniques such as speech or handwriting analysis, which do not disturb daily activities. This survey reviews the most relevant non-intrusive methodologies that use deep learning techniques to automate the cognitive decline detection task, including audio, text, and visual processing. We discuss the key features and advantages of each modality and methodology, including state-of-the-art approaches like Transformer architecture and foundation models. In addition, we present studies that integrate different modalities to develop multimodal models. We also highlight the most significant datasets and the quantitative results from studies using these resources. From this review, several conclusions emerge. In most cases, text-based approaches consistently outperform other modalities. Furthermore, combining various approaches from individual modalities into a multimodal model consistently enhances performance across nearly all scenarios.},
  archive      = {J_ASOC},
  author       = {David Ortiz-Perez and Manuel Benavent-Lledo and Jose Garcia-Rodriguez and David Tomás and M. Flores Vizcaya-Moreno},
  doi          = {10.1016/j.asoc.2025.113787},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113787},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep insights into cognitive decline: A survey of leveraging non-intrusive modalities with deep learning techniques},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving adversarial transferability with neighborhood gradient information. <em>ASOC</em>, <em>184</em>, 113786. (<a href='https://doi.org/10.1016/j.asoc.2025.113786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are known to be susceptible to adversarial examples, leading to significant performance degradation. In black-box attack scenarios, a considerable attack performance gap between the surrogate model and the target model persists. This work focuses on enhancing the transferability of adversarial examples to narrow this performance gap. We observe that the gradient information around the clean image, i.e., Neighborhood Gradient Information (NGI) , can offer high transferability. Based on this insight, we introduce NGI-Attack, incorporating Example Backtracking and Multiplex Mask strategies to exploit this gradient information and enhance transferability. Specifically, we first adopt Example Backtracking to accumulate Neighborhood Gradient Information as the initial momentum term. Then, we utilize Multiplex Mask to form a multi-way attack strategy that forces the network to focus on non-discriminative regions, which can obtain richer gradient information during only a few iterations. Extensive experiments demonstrate that our approach significantly enhances adversarial transferability. Especially, when attacking numerous defense models, we achieve an average attack success rate of 95.2%. Notably, our method can seamlessly integrate with any off-the-shelf algorithm, enhancing their attack performance without incurring extra time costs.},
  archive      = {J_ASOC},
  author       = {Haijing Guo and Jiafeng Wang and Zhaoyu Chen and Kaixun Jiang and Lingyi Hong and Pinxue Guo and Jinglun Li and Wenqiang Zhang},
  doi          = {10.1016/j.asoc.2025.113786},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113786},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Improving adversarial transferability with neighborhood gradient information},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated semi-supervised learning for in-domain/Cross-domain person re-identification. <em>ASOC</em>, <em>184</em>, 113785. (<a href='https://doi.org/10.1016/j.asoc.2025.113785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Person Re-identification (Re-ID) task refers to retrieving images of the same person from different camera views. However, the task faces three major challenges: building a person dataset may infringe on personal privacy, collecting large-scale datasets for identity annotation requires high costs, and low quality local datasets can lead to performance bottlenecks. To address the above challenges, we propose Federated semi-supervised frameworks for the first time to solve in-domain/Cross-domain Re-ID problems, which can reduce annotation costs while protecting privacy. Firstly, we propose two different weighted aggregation federated learning strategies. Specifically, under the in-domain setting, labeled clients are utilized to determine the quality of unlabeled clients. Under the cross-domain setting, the model’s recognition capability is extended to each unlabeled domain by measuring inter-domain differences. In addition, a cascaded Global-personalized Model System and Personalized Model Knowledge Transfer Module are proposed to further address the domain-gap issue by sufficiently decoupling the global shared knowledge and the personalized knowledge unique to each domain. Finally, a Classifier Checking Module is proposed to significantly reduce computational costs by dynamically adjusting the pseudo-labels of unlabeled samples. Extensive experiments on multiple public datasets of varying scales and quality verify that the proposed frameworks can achieve acceptable performance at a lower cost while ensuring the security of personal data. Meanwhile, the effectiveness of the proposed training strategies and modules in other tasks is also verified, which proves their inspirational significance for research and applications in the fields of weakly supervised learning, user privacy protection and intelligent video surveillance.},
  archive      = {J_ASOC},
  author       = {Xinyuan Chen and Mingwen Shao and Yi Niu and Qiao Zhang},
  doi          = {10.1016/j.asoc.2025.113785},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113785},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Federated semi-supervised learning for in-domain/Cross-domain person re-identification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-guided triplet framework for synthetic data generation and semantic segmentation of railway fasteners under data scarcity and disparity. <em>ASOC</em>, <em>184</em>, 113784. (<a href='https://doi.org/10.1016/j.asoc.2025.113784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railway infrastructure monitoring faces significant challenges due to limited data availability, labor-intensive annotations, and imbalanced datasets—factors that hinder efficient fastener maintenance. To address these issues, this study proposes a novel three-phase framework that leverages attention-guided deep learning for the generation and analysis of synthetic railway fastener images. In the first phase, an attention-based Deep Convolutional Generative Adversarial Network (DCGAN) is introduced to generate high-fidelity synthetic images that closely mimic real-world conditions. Unlike conventional GANs, the attention mechanism enables the model to focus on critical structural features of fasteners, enhancing the realism and diversity of the generated data. The second phase applies advanced denoising techniques, with the DnCNN model outperforming traditional methods like Median Filtering in preserving fine details. The final phase employs a Convolutional Autoencoder (CAE) for accurate semantic segmentation, achieving 88.8 % accuracy on the synthetic dataset. This end-to-end methodology improves model generalizability, reduces reliance on manual labeling, and provides a cost-effective solution for automated railway inspection. By bridging the gap between real and synthetic data, it also lays the groundwork for scalable, intelligent infrastructure monitoring systems, supporting the advancement of safer and more efficient railway operations.},
  archive      = {J_ASOC},
  author       = {Qasim Zaheer and Momina Malik and S.Muhammad Ahmed Hassan Shah and Chengbo Ai and Hongzhi Wang and Zhiyu Liang and Shi Qiu},
  doi          = {10.1016/j.asoc.2025.113784},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113784},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Attention-guided triplet framework for synthetic data generation and semantic segmentation of railway fasteners under data scarcity and disparity},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An Actor–Critic-based adapted deep reinforcement learning model for multi-step traffic state prediction. <em>ASOC</em>, <em>184</em>, 113783. (<a href='https://doi.org/10.1016/j.asoc.2025.113783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic state prediction is critical to decision-making in various traffic management applications. Despite significant advancements in Deep Learning (DL) models, such as Long Short-Term Memory (LSTM), Graph Neural Networks (GNN), and attention-based transformer models, multi-step predictions remain challenging. The state-of-the-art models face a common limitation: the predictions’ accuracy decreases as the prediction horizon increases, a phenomenon known as error accumulation. In addition, with the arrival of non-recurrent events and external noise, the models fail to maintain good prediction accuracy. Deep Reinforcement Learning (DRL) has been widely applied to diverse tasks, including optimising intersection traffic signal control. However, its potential to address multi-step traffic prediction challenges remains underexplored. This study introduces an Actor–Critic-based adapted DRL method to explore the solution to the challenges associated with multi-step prediction. The Actor network makes predictions by capturing the temporal correlations of the data sequence, and the Critic network optimises the Actor by evaluating the prediction quality using Q-values. This novel combination of Supervised Learning and Reinforcement Learning (RL) paradigms, along with non-autoregressive modelling, helps the model to mitigate the error accumulation problem and increase its robustness to the arrival of non-recurrent events. It also introduces a Denoising Autoencoder to deal with external noise effectively. The proposed model was trained and evaluated on three benchmark traffic flow and speed datasets. Baseline multi-step prediction models were implemented for comparison based on performance metrics such as Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). The results reveal that the proposed method outperforms the baselines by achieving average improvements of 0.26 to 21.29% in terms of MAE and RMSE for up to 24 time steps of prediction length on the three used datasets, at the expense of relatively higher computational costs. On top of that, this adapted DRL approach outperforms traditional DRL models, such as Deep Deterministic Policy Gradient (DDPG), in accuracy and computational efficiency.},
  archive      = {J_ASOC},
  author       = {Selim Reza and Marta Campos Ferreira and J.J.M. Machado and João Manuel R.S. Tavares},
  doi          = {10.1016/j.asoc.2025.113783},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113783},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An Actor–Critic-based adapted deep reinforcement learning model for multi-step traffic state prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grammatical evolution for automatic design of actuated traffic signal control plans. <em>ASOC</em>, <em>184</em>, 113782. (<a href='https://doi.org/10.1016/j.asoc.2025.113782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In traffic networks, proper signal control design is essential to ensure a reasonable level of service. Signal control designs are becoming increasingly complex, with numerous settings that must be calibrated and set. This paper introduces a novel approach for handling this complexity by automatically generating optimal actuated signal control plans using Grammatical Evolution (GE). GE has proven its effectiveness in automating the design of different complex systems, such as neural networks and analog electronic circuits. GE’s distinctive mapping and representation capabilities make it a powerful candidate for optimizing various systems. In contrast to traditional optimization methods for actuated signal plans, which focus on specific parameters, such as green times and cycle length, the GE-based approach evolves complete plans, including phases, detector placements, and transit priority strategies. As a result, it eliminates the need for human intervention in the design process, making it more efficient and less time-consuming. The proposed approach was tested with an application to an isolated intersection in Haifa, Israel. The results showed that the automatically generated signal plan outperformed the existing plan by reducing delay times and queue lengths. Moreover, this method demonstrated its efficiency in generating reliable traffic signal plans under challenging traffic conditions.},
  archive      = {J_ASOC},
  author       = {Mahmud Keblawi and Tomer Toledo},
  doi          = {10.1016/j.asoc.2025.113782},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113782},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Grammatical evolution for automatic design of actuated traffic signal control plans},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized resource management in containerized clouds via hierarchical autoregressive network based workload prediction. <em>ASOC</em>, <em>184</em>, 113781. (<a href='https://doi.org/10.1016/j.asoc.2025.113781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swift growth of containerized applications calls for highly precise and real-time prediction of workloads to make resource allocation in cloud environments efficient. Current methods are deficient either by not being able to catch the complex long-term workload dependencies in patterns or by introducing too much computational overhead that degrades real-time performance. We propose a new integrated model where a transformer-based Hierarchical Autoregressive Network (HARN) is dynamically fused with TES. With the use of self-attention mechanisms in modeling complex temporal dynamics and long-range dependencies, on the one hand, HARN captures the detailed seasonal variation but robustly deals with the smoother short-term oscillations, giving TES ample opportunity to function. The model dynamically adjusts their contributions to fit the best weighting in real-time, hence leading to optimal predictability even for changing workloads. Our analysis on the publicly released Alibaba v2018 dataset shows an average improvement in Mean Absolute Error (MAE) of 15.50% and an improvement in Root Mean Square Error (RMSE) of 14.80%. Furthermore, experiments on a specially designed container dataset show even more significant improvements, with improvements of up to 25% in CPU metrics and 40% in memory metrics. These findings and minimal computational overhead emphasize the model’s ability to facilitate real-time proactive resource provisioning in dynamic cloud settings.},
  archive      = {J_ASOC},
  author       = {Shivani Tripathi and Angelina Shibu and Priyadarshni and Rajiv Misra and T.N. Singh},
  doi          = {10.1016/j.asoc.2025.113781},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113781},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimized resource management in containerized clouds via hierarchical autoregressive network based workload prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pervasive multifaceted process based generative adversarial network for image quality enhancement. <em>ASOC</em>, <em>184</em>, 113780. (<a href='https://doi.org/10.1016/j.asoc.2025.113780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The practice of Generative Adversarial Networks (GAN) has extended a lot of consideration in recent times. In most of the GAN methods are problem-specific related that are personalized to report numerous trials of individual application rather than performing other image improvement tasks. Furthermore, the basic GAN generators influence their boundaries in numerous image restoration and development use cases. Therefore, in this paper, we propose a generic GAN referred to as Pervasive Multifaceted Process based Generative Adversarial Network (PMPGAN). In this generator, we introduced multiple Convolutional Neural Networks (CNN) followed by Multi-dimensional Pyramid Pooling Module (MPPM) and Attention Module (AM), of which the input for the AM is given as low-level features and it produces output with enhanced feature map. Meanwhile, we enhanced the improvement outcome of the generated image with discriminator loss function. Finally, we tested the efficiency of the proposed system through extensive experiments on five challenging applications for image enhancement, image restoration, and infrared image translation to determine the dominance and efficiency in eliminating image degradation and producing visually interesting fake images. Our PMPGAN quantitatively outperforms several latest models. The results show that the PMPGAN model is superior to the existing models.},
  archive      = {J_ASOC},
  author       = {K. Balaji},
  doi          = {10.1016/j.asoc.2025.113780},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113780},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Pervasive multifaceted process based generative adversarial network for image quality enhancement},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-term time series forecasting by a frequency-domain enhanced temporal convolutional network with the stationary residual regularization. <em>ASOC</em>, <em>184</em>, 113779. (<a href='https://doi.org/10.1016/j.asoc.2025.113779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current time series models can resolve the long-term time series forecasting problem by leveraging artificial neural networks (ANNs) to capture complex temporal dependencies. However, the state-of-the-art ANNs for long-term prediction, Transformer-based models, have two inherent shortcomings that undermine both credibility and accuracy: losing temporal order information and ignoring information in prediction residuals. To fill these gaps, this study proposes a frequency-domain enhanced multi-scale temporal convolutional network (FMTCN) and a hybrid loss function regularized by stationary residuals called QM. Firstly, to preserve temporal order information, a multi-scale block with dilated causal convolution is developed as the core component of FMTCN, which can ensure the dependencies of predictions on sequentially ordered data. Secondly, an adaptive fusion mechanism for time and frequency domain patterns is designed to bridge the performance gap between convolution-based and Transformer-based models. Thirdly, to reduce residual autocorrelation, the proposed hybrid loss function integrates the Ljung–Box statistic into the mean squared error loss function as the regularization. Finally, extensive experiments across five real-world datasets are conducted to validate the proposed methods. Compared with the state-of-the-art method, the proposal improves the accuracy by 8.6% in the univariate long-term prediction and 6.1% in the multivariate long-term prediction.},
  archive      = {J_ASOC},
  author       = {Jing Wang and Yanbing Ju and Peiwu Dong and Tian Ju},
  doi          = {10.1016/j.asoc.2025.113779},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113779},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Long-term time series forecasting by a frequency-domain enhanced temporal convolutional network with the stationary residual regularization},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Loss functions in classification: An comprehensive overview and comparative study. <em>ASOC</em>, <em>184</em>, 113778. (<a href='https://doi.org/10.1016/j.asoc.2025.113778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loss functions are among the most fundamental components of a classifier’s learning processes and consequently can significantly affect the performance of classification methods. However, despite the substantial potential impact of loss functions on the classification accuracy, they have been incomprehensively investigated in the literature. For this reason, this paper tries to comprehensively evaluate the potency and impact of loss functions on the performance and accuracy in classification problems. For this purpose, fifty-five different loss functions in twelve categories—Linear Continuous Distance, Nonlinear Continuous Distance, Linear Semi-Continuous Distance, Nonlinear Semi-Continuous Distance, Linear Discrete Distance, Nonlinear Discrete Distance, Linear Continuous Direction, Nonlinear Continuous Direction, Linear Semi-Continuous Direction, Nonlinear Semi-Continuous Direction, Linear Discrete Direction, and Nonlinear Discrete Direction, are considered. In addition, in this paper, six distinct environmental pollutants/pollution benchmark data sets, three classifier types—statistical, shallow intelligence, and deep intelligence, are exemplary considered. Furthermore, in this paper, the most important measure of regular classification problems, the classification rate, has been chosen in order to compare these loss functions. The experimental results have unequivocally validated that the choice of loss functions has a significant impact on accuracy and classification rates. Numerical results of loss functions indicate that the difference between the lowest and the highest classification rate in the statistical, shallow intelligent, and deep learning classifiers, is averagely equal to 6.41 %, 5.16 %, and 2.24 %, respectively. It means that the model designer, by choosing the appropriate loss function, can averagely improve more than 4 % the obtained classification rate. Empirical results show that in the general perspective, the lowest performances of loss functions are overall related to the linear, continuous, and distance-based categories, in contrast to the highest ones, which are nonlinear, discrete, and direction-based. The exception to this outcome is the Zero-One family, in which all their loss functions, i.e., linear/nonlinear, distance/direction, are equivalent and yield the same accuracy. The best classification rate is also related to this family, that significantly better than other loss functions in all cases, as well as all classifiers. The Zero-One loss functions can averagely achieve a 98.62 % classification rate that 17.65 % is averagely higher than others. These evidences illustrate that, in addition to other effective features and factors, the loss function type should also be considered by environmental model designers in order to yield a more desired classification rate.},
  archive      = {J_ASOC},
  author       = {Fatemeh Chahkoutahi and Mehdi Khashei and Naser Molaverdi},
  doi          = {10.1016/j.asoc.2025.113778},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113778},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Loss functions in classification: An comprehensive overview and comparative study},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultra-low memory spatiotemporal decomposition recurrent neural networks for edge structural fault monitoring. <em>ASOC</em>, <em>184</em>, 113777. (<a href='https://doi.org/10.1016/j.asoc.2025.113777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hardware memory resources of microcontrollers in wireless sensor network nodes are limited, currently only capable of data acquisition and simple computing, making it difficult to perform neural network inference for edge fault monitoring. Running neural networks on microcontrollers can enhance the edge data processing capabilities of the nodes. Recurrent neural networks with short and medium term memory excel at processing sequential data. However, inference on microcontrollers consumes a significant amount of memory, necessitating solutions to the memory constraints. This study proposes a spatiotemporal decomposition method for recurrent neural networks to address the memory constraint issue when performing inference on resource-constrained nodes, thus enabling edge fault monitoring. The method decomposes recurrent neural networks in spatiotemporal dimensions, significantly reducing memory usage during operation. Additionally, it proposes model parameter storage and addressing techniques to ensure accurate reading of Flash data. Experiments have verified that this method can achieve 99.7 % accuracy in edge fault classification, consuming only 332 bytes of RAM and 768 bytes of Flash. The spatiotemporal decomposition method also provides a solution for running other time-series models on resource-constrained edge devices.},
  archive      = {J_ASOC},
  author       = {Hao Fu and Lei Deng and Baoping Tang and Shuaiwen Cui and Yuguang Fu},
  doi          = {10.1016/j.asoc.2025.113777},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113777},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Ultra-low memory spatiotemporal decomposition recurrent neural networks for edge structural fault monitoring},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid SpinalNet-fuzzy-shufflenet for brain tumor detection using MRI images. <em>ASOC</em>, <em>184</em>, 113775. (<a href='https://doi.org/10.1016/j.asoc.2025.113775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, a significant portion of the global population is affected by the serious medical condition known as Brain Tumor (BT). Damage to healthy brain tissue is suspected, as it is currently the most important cause of a huge quantity of mortality. To prevent patients from dying, early detection is very essential. Despite various notable efforts and hopeful results in this area, accurate segmentation and categorization remain a difficult task. To address these gaps, a SpinalNet Fuzzy Shufflenet (SFShuffleNet) is proposed for the detection of BT. First, the input image is fed into the preprocessing stage, utilizing ROI extraction. Subsequently, the preprocessed image undergoes enhancement using histogram equalization techniques. Then, the enhanced image undergoes segmentation with Fuzzy Local Information C-Means (FLICM). Following segmentation, the image is augmented through sharpening, translation, random erasing, and resizing techniques. Features such as mean, variance, standard deviation, average, contrast, skewness, kurtosis, and entropy with the Local Frequency Descriptor (LFD) are extracted. Finally, the proposed SFShuffleNet, which combines SpinalNet and Shufflenet with fuzzy concept modifications, detects BT. SFShuffleNet achieved the highest accuracy, sensitivity, specificity, and F1-score of 91.46 %, 90.96 %, 92.78 %, and 90.79 %, respectively.},
  archive      = {J_ASOC},
  author       = {P Srinivasa Rao and Swathi Sowmya Bavirthi and G. Sharada and Ponnaboyina Ranganath and Vemuri Sailaja and G Vimala Kumari},
  doi          = {10.1016/j.asoc.2025.113775},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113775},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hybrid SpinalNet-fuzzy-shufflenet for brain tumor detection using MRI images},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enzyme classification integrating LSTM and prot-BERT sequence encoding. <em>ASOC</em>, <em>184</em>, 113774. (<a href='https://doi.org/10.1016/j.asoc.2025.113774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enzyme classification is essential for deciphering cellular and biological processes, driving targeted research, and influencing domains such as drug discovery and bioengineering. While various automated tools exist for enzyme classification, many are limited in scope or no longer operational. This study utilizes advanced artificial intelligence (AI) algorithms, including SVM, RF, simpleRNN, LSTM, ConvLSTM, and bidirectional LSTM, combined with numeric and Prot-BERT-based protein sequence encodings, to classify 1991 enzymes across 7 main classes, 69 subclasses, 216 sub-subclasses, and 1333 substrates. Among all trained models, the bidirectional LSTM model integrated with Prot-BERT sequence encoding (ECiLPSE) demonstrated exceptional accuracy of 99.14 % on the training set and 98.41 % on the test set, effectively capturing intricate sequence details. In addition to high accuracy, ECiLPSE achieved an F1-score of 0.99 (training set) and 0.98 (test set), with AU-ROC scores of 0.98 and 0.97, respectively. Precision and recall were both 0.99 on the training set and 0.98 on the test set. The 95 % confidence interval for test set accuracy (98.00 % - 99.97 %) further supports the model’s robustness and discriminative capability across classes. To benchmark performance, ECiLPSE was evaluated against four EC prediction tools (ECPred, CLEAN, EZYPred, EzyDeep), demonstrating superior accuracy and computational efficiency. The results from three case studies (using New-1277, Price-149, and halogenases datasets) highlight the limitations of the existing tools, underscoring the predictive accuracy, reliability, and applicability of ECiLPSE. ECiLPSE is available as a standalone tool for large datasets and as a web server for small datasets, offering a robust resource for enzyme classification, advancing computational approaches in enzyme research, and promising applications in drug discovery.},
  archive      = {J_ASOC},
  author       = {Anju Sharma and Vineet Diwakar and Rajnish Kumar and Prabha Garg},
  doi          = {10.1016/j.asoc.2025.113774},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113774},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enzyme classification integrating LSTM and prot-BERT sequence encoding},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent urban GNSS measurement uncertainty prediction by exploring the spatial characteristics with transformer. <em>ASOC</em>, <em>184</em>, 113773. (<a href='https://doi.org/10.1016/j.asoc.2025.113773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global navigation satellite system (GNSS) positioning accuracy is essential for civil applications. Unfortunately, in urban areas, GNSS signals are easily blocked and reflected by tall buildings, namely non-line-of-sight (NLOS) receptions. Thus, it is essential to classify these contaminated receptions and mitigate their pseudorange error for positioning improvement. This paper designed a Transformer-based network that utilizes satellite spatial characteristics to predict GNSS measurement uncertainty. The proposed method accurately classifies 89 % of satellites’ visibility and around 45 % compensation in NLOS pseudorange error, outperforming the state-of-the-art algorithms. By analyzing the attention matrix generated by Transformer, we explore how Transformer utilizes spatial characteristics for satellite measurement uncertainty prediction, which regards satellite visibility and pseudorange as different tasks for training.},
  archive      = {J_ASOC},
  author       = {Zekun Zhang and Penghui Xu and Guohao Zhang},
  doi          = {10.1016/j.asoc.2025.113773},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113773},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Intelligent urban GNSS measurement uncertainty prediction by exploring the spatial characteristics with transformer},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling self-supervised learning for handling the concept drift with ternary-adaptive ensemble. <em>ASOC</em>, <em>184</em>, 113772. (<a href='https://doi.org/10.1016/j.asoc.2025.113772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last several decades, drift detection and adaptation models have been trained on historical drift labels struggle with real-world data streams due to evolving distributions, impacting accurate future predictions. Existing methods update predictive models but often fail to retain previously learned patterns from streaming data, hindered by insufficient predefined labels for categorizing drift detection. To address these constraints, the proposed work introduces a two-task framework comprising a Self-Supervised Learning (SSL) model with a pretext task and a downstream task to efficiently adapt the model to evolving data distributions. In the pretext task, the proposed approach learns patterns from the unlabeled offline data in a self-supervised manner and utilizes the knowledge from the performance-based drift detector. In a subsequent downstream task, the model that has been enhanced with a forgetting-aware Ternary-Adaptive Ensemble (TAE) learner without requiring the drift labels. In the proposed approach, the TAE algorithm comprises drift-aware model updation methods for the Long Short-Term Memory (LSTM) to resolve forgetting in sequential data streams, and the three updation methods involve the pretext model’s weight transfer, Bayesian Optimization-based hyperparameter tuning, and Elastic Weight Consolidation (EWC). The proposed approach effectively handles drifts and outperformed while testing on the real-world weather and synthetic, mixed drift datasets with 82.6% and 92.36% accuracy, respectively.},
  archive      = {J_ASOC},
  author       = {Shubhangi Suryawanshi and Anurag Goswami and Pramod Patil},
  doi          = {10.1016/j.asoc.2025.113772},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113772},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Modeling self-supervised learning for handling the concept drift with ternary-adaptive ensemble},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain knowledge distillation for domain adaptation with GCN-driven MLP generalization. <em>ASOC</em>, <em>184</em>, 113771. (<a href='https://doi.org/10.1016/j.asoc.2025.113771'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) and domain adaptation (DA) represent potential research directions for reducing costs associated with deploying deep neural networks (DNN) in real-world applications. KD focuses on model compression, exploring methods to transfer informative representations from a complex model to a lighter one without incurring additional costs. Conversely, DA emphasizes the data distribution perspective, aiming to decrease labeling expenses by leveraging knowledge extracted from a labeled source domain to minimize classification errors in an unlabeled target domain. In this paper, we introduce a novel knowledge distillation (KD) approach with a teacher–student paradigm for domain adaptation (DA) tasks, termed Improved Cross-domain Knowledge Distillation (ICDKD). Specifically, we employ a graph convolutional network (GCN) classifier as the teacher model and a multilayer perceptron (MLP) classifier as the student model. During training, the teacher model utilizes a message-passing mechanism to capture the topology of the training data through neighbor information, thus explicitly enhancing semantic representations in each category to improve classification accuracy. Subsequently, the extracted knowledge from the GCN teacher model is distilled to the MLP student model. Finally, in the inference stage, only the MLP student model is utilized to meet the latency constraints of applications. Our proposed method effectively combines the strengths of both GCN and MLP classifiers to improve the classification performance and satisfy the real-world application requirements. We implemented our method on various DA benchmark datasets under unsupervised and semi-supervised domain adaptation settings, including ImageCLEF-DA, Office-31, Office-Home, VisDA2017, and DomainNet. The experimental results demonstrate the effectiveness of our proposed method on both CNN-based and ViT-based architectures, achieving outstanding classification performance compared to prior state-of-the-art domain adaptation methods.},
  archive      = {J_ASOC},
  author       = {Ba Hung Ngo and Tae Jong Choi},
  doi          = {10.1016/j.asoc.2025.113771},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113771},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cross-domain knowledge distillation for domain adaptation with GCN-driven MLP generalization},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy delphi-SERVQUAL model using degree of belief structure for assessing customer satisfaction in automotive after-sales services. <em>ASOC</em>, <em>184</em>, 113770. (<a href='https://doi.org/10.1016/j.asoc.2025.113770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel two-phase fuzzy multi-attribute decision-making (MADM) framework for assessing customer satisfaction in automotive after-sales services under uncertainty. The proposed model integrates a modified Fuzzy Delphi Method (FDM) with an enhanced fuzzy SERVQUAL approach, both embedded within a Degree of Belief (DoB) structure to capture evaluative ambiguity and confidence levels in expert and customer judgments. In the first phase, a belief-based FDM enables the efficient screening and prioritization of 58 service quality criteria using a single-round process that incorporates both optimistic and pessimistic expert viewpoints. In the second phase, a belief-driven SERVQUAL model evaluates customer perceptions and expectations from both stringent and lenient perspectives across six dimensions, including a newly introduced Digital Technology dimension that reflects emerging service delivery mechanisms. The model also features a δ-based sensitivity analysis to examine the impact of decision-making attitudes and a seven-zone classification system to categorize service quality gaps with high diagnostic precision. Application of the proposed framework in the Iranian automotive after-sales sector enabled the prioritization of 29 key service quality criteria from an initial pool of 58 indicators, with the most critical factors identified in the ‘Reliability’ and ‘Responsiveness’ dimensions. The resulting insights support evidence-based managerial actions, including the reallocation of resources toward high-impact service areas, targeted digital transformation initiatives, and the formulation of differentiated improvement strategies based on gap severity and belief-based customer expectations .},
  archive      = {J_ASOC},
  author       = {Mojtaba Elahi and Ramin Enayati and Mehdi Keramatpour},
  doi          = {10.1016/j.asoc.2025.113770},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113770},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fuzzy delphi-SERVQUAL model using degree of belief structure for assessing customer satisfaction in automotive after-sales services},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing a hybrid circular intuitionistic fuzzy framework to assess tourism 5.0 challenges. <em>ASOC</em>, <em>184</em>, 113769. (<a href='https://doi.org/10.1016/j.asoc.2025.113769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of Industry 5.0 (I5.0) in tourism is still in its early stages, and its complex implementation presents challenges that are not fully understood. Existing studies often focus on context-specific challenges, limiting the exploration of broader obstacles. This research aims to identify a comprehensive set of challenges, rank them, and evaluate their interdependencies in I5.0 adoption within tourism. A systematic literature review was conducted to identify key challenges, and expert input was gathered to validate and refine the findings. To evaluate the significance of the identified challenges, a novel extension of the Stepwise Weight Assessment Ratio Analysis (SWARA) method into the Circular Intuitionistic Fuzzy (CIF) environment, referred to as CIF-SWARA, was formulated to determine the relative weights of each challenge under uncertainty with more precision. Additionally, the Decision-Making Trial and Evaluation Laboratory (DEMATEL) method was extended using CIF sets, termed CIF-DEMATEL, to evaluate the causal relationships and relative influence among the challenges. The results from both methods were combined to derive final weights. Furthermore, a conceptual model was constructed using Total Interpretive Structural Modeling (TISM) based on the CIF-DEMATEL output, providing a detailed qualitative assessment of the interactions among the challenges. Findings highlight that “infrastructure issues” are the most urgent challenge requiring attention. Additionally, “technical and technological issues,” “acceptance and adaptability issues,” and “financial issues” emerged as the three most significant challenges for transitioning to “Tourism 5.0.” The model’s robustness was confirmed via sensitivity analysis, and comparative evaluations demonstrated consistent performance against established fuzzy environments. This study advances I5.0 research in tourism by identifying and modeling key challenges, offering valuable insights for policymakers.},
  archive      = {J_ASOC},
  author       = {Vahideh Shahin and Dragan Pamucar and Moslem Alimohammadlou},
  doi          = {10.1016/j.asoc.2025.113769},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113769},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Developing a hybrid circular intuitionistic fuzzy framework to assess tourism 5.0 challenges},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-adaptive discrete artificial bee colony algorithm based on block swap for steelmaking and continuous casting scheduling problem. <em>ASOC</em>, <em>184</em>, 113768. (<a href='https://doi.org/10.1016/j.asoc.2025.113768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the high temperature characteristics of the steelmaking continuous casting production, the temperature decreasing energy consumption (TDEC) in the processing process cannot be ignored. Therefore, this paper establishes a mixed integer mathematical model for the steelmaking continuous casting scheduling problem with TDEC (SCCSP TDEC ). The SCCSP TDEC chooses to minimize the objective functions of the total weighted earliness and tardiness, the TDEC and the makespan. To solve the SCCSP TDEC , an improved heuristic based on problem-specific features is proposed in this paper, which takes into account the completion time of the third stage’s cast, and the effect of the cast’s holistic nature. Then, a self-adaptive discrete artificial bee colony algorithm based on block swap (SDABC bs ) is proposed to solve the SCCSP TDEC . This strategy can adaptively select an optimal structure suitable for the current population, and effectively expand the search space of neighborhood solutions. Finally, this paper tests the SDABC bs algorithm based on the extensive instances generated according to the actual production process, and the performance of the SDABC bs algorithm is verified by comparing with other efficient algorithms. The experimental results show that the proposed SDABC bs algorithm is more effective for the SCCSP TDEC among all the algorithms in comparison.},
  archive      = {J_ASOC},
  author       = {Yang Yu and Guo-Dong Yang and Qichun Zhang and Liangliang Sun and Xinfu Pang and Yefeng Liu},
  doi          = {10.1016/j.asoc.2025.113768},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113768},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A self-adaptive discrete artificial bee colony algorithm based on block swap for steelmaking and continuous casting scheduling problem},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained mutation operators for community hiding using genetic algorithms. <em>ASOC</em>, <em>184</em>, 113767. (<a href='https://doi.org/10.1016/j.asoc.2025.113767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection plays a key role in uncovering group structures in networks, but its misuse can lead to privacy risks by exposing sensitive relationships. As a proactive defense, community hiding seeks to perturb the network structure to reduce the effectiveness of community detection algorithms. Given the NP-hard nature of this task, genetic algorithms (GAs) widely used due to their robust global search capabilities. However, existing methods lack effective guidance when dealing with vast solution spaces, resulting in inefficient exploration and suboptimal obfuscation outcomes. To address this, we propose Network- T opology- C ombined Community Information H iding A lgorithm (TCHA), a novel GA-based method that leverages node similarity information via node embedding to guide perturbations more effectively. TCHA introduces a multidimensional mutation operator that combines coarse-grained and fine-grained mutation strategies. These fine-grained mutations are performed in the embedding space and decoded back to graph edits, enabling more precise and topologically-aware perturbations. To evaluate the efficiency of this process, we introduce a novel metric based on expected path length within a mutation transition graph, offering deeper insight into evolutionary search dynamics. Experiments on six real-world networks demonstrate that TCHA achieves an average modularity reduction of 31.92% and an average normalized mutual information of 0.6447, outperforming baselines such as Q-Attack, NEURAL, and DICE. These results confirm the superiority of the embedding-guided fine-grained mutation strategy in enhancing community hiding effectiveness.},
  archive      = {J_ASOC},
  author       = {Shanqing Yu and Jintao Zhou and Meng Zhou and Yidan Song and Jiaxiang Li and Zeyu Wang and Qi Xuan and Silu Mu and Xiaolei Qian},
  doi          = {10.1016/j.asoc.2025.113767},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113767},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fine-grained mutation operators for community hiding using genetic algorithms},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting scour depth in the presence of aprons using XGBoost-optuna. <em>ASOC</em>, <em>184</em>, 113766. (<a href='https://doi.org/10.1016/j.asoc.2025.113766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the impact of an apron in mitigating scour downstream of a trapezoidal PK weir through an experimental study. Three apron lengths were tested with two sediment types under varying hydraulic conditions to address local scouring. Results show that longer aprons reduce scouring, especially at lower densimetric Froude numbers, affecting the location of the maximum scour depth and its volume. On average, apron lengths of 1 P , 1.5 P , and 2 P ( P is weir height) decrease the scour hole areas and volumes by approximately 69–77 %. Scour indices decrease by 73–90 % for corresponding apron lengths. New empirical equations have been proposed to aid in apron design, and the estimation of various scour hole geometries . Bayesian Optimized Neural Network (BONN), Extreme Gradient Boosting model tuned by Optuna algorithm (XGBoost-Optuna), and Random Forest were also developed for forecasting scour hole characteristics in the presence of apron. Various regression tests, including residual plots and uncertainty quantification, were imposed to compare the models. The results demonstrated that the XGBoost-Optuna model outperformed the other models, achieving a correlation coefficient ranging from 0.924 to 0.985, a root mean squared error between 0.055 and 5.072, and a mean relative percentage error of 7.14–11.71 %. Most forecasts generated by the XGBoost-Optuna model fell within ±20 % error margins, highlighting its superiority in predicting scour hole characteristics in the presence of the apron for PK weirs.},
  archive      = {J_ASOC},
  author       = {Chonoor Abdi Chooplou and Saeed Balahang and Masoud Ghodsian and Mohammad Vaghefi},
  doi          = {10.1016/j.asoc.2025.113766},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113766},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Predicting scour depth in the presence of aprons using XGBoost-optuna},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LanPPT: Enhancing landslide crack detection through pyramid pooling transformers. <em>ASOC</em>, <em>184</em>, 113765. (<a href='https://doi.org/10.1016/j.asoc.2025.113765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Landslide cracks, also known as tension cracks, are a major part of landslides. Based on the distribution of landslide fractures, the location of a landslide can be broadly described, and the stress distribution of the sliding mass can be inferred. Cracks at a landslide’s head, which are a key indicator of the displacement of the landslide body, can provide early warning signs for landslide hazards. The complete knowledge of the crack development features is still lacking because of many influencing elements and intricate reasons for fracture creation. Even though some early interventions reported models for automated crack identification utilizing advanced machine learning techniques, the problem still has not been solved to its full potential. Thus, an effective deep architecture for landslide crack segmentation is suggested to address these issues, utilizing a synergistic blend of vision transformers and the pyramid pooling concept. In this work, we use the universal vision transformer backbone called the Pyramid Pooling Transformer, and plug it into our pooling-based multi-head spatial attention to build a deep architecture that identifies and segments the landslide cracks, namely LanPPT. Experiments revealed that when a pyramid pooling transformer is used as the backbone network, it performs significantly better than many earlier convolutional neural networks and normal transformer-based networks in various vision tasks. Systematic experiments show that the proposed model achieved superior performance in terms of mIoU and FPS when compared with the chosen state-of-the-art baselines in the landslide crack detection task.},
  archive      = {J_ASOC},
  author       = {S. Sreelakshmi and S.S. Vinod Chandra},
  doi          = {10.1016/j.asoc.2025.113765},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113765},
  shortjournal = {Appl. Soft. Comput.},
  title        = {LanPPT: Enhancing landslide crack detection through pyramid pooling transformers},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differential evolution algorithm with cosine similarity-based individual reduction and symmetric uncertainty-based attribute recovery for feature selection. <em>ASOC</em>, <em>184</em>, 113764. (<a href='https://doi.org/10.1016/j.asoc.2025.113764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the increase in data scaling, effectively handling high-dimensional datasets has become a focal point of attention. Feature selection (FS), a method for dealing with datasets containing features, has emerged as a crucial technique in fields such as machine learning and data mining with the objective of selecting features that contain richer information while eliminating redundancy. Due to their remarkable performance in global search, evolutionary computation techniques hold substantial potential in the application of FS. However, many existing FS methods overlook the relationships between features. In the context of classification problems, this study presents a novel wrapper FS algorithm based on the differential evolution algorithm. The proposed method reduces redundant features among individuals based on cosine similarity and selectively and recovers certain features in the crossover phase according to the uncertainty similarity. In addition, a probabilistic-based initialization method is designed. The proposed algorithm significantly outperforms five other algorithms in terms of classification error rates over 18 experimental datasets. The experimental results demonstrate a significant enhancement in the performance of the proposed algorithm attributed to these two components.},
  archive      = {J_ASOC},
  author       = {Chunzhi Hou and Ziqian Wang and Yu Zhang and Yuki Todo and Jun Tang and Zhenyu Lei and Shangce Gao},
  doi          = {10.1016/j.asoc.2025.113764},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113764},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Differential evolution algorithm with cosine similarity-based individual reduction and symmetric uncertainty-based attribute recovery for feature selection},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion model based on stochastic differential equation with transformer for stock price prediction. <em>ASOC</em>, <em>184</em>, 113763. (<a href='https://doi.org/10.1016/j.asoc.2025.113763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of stock prices is an exemplary interdisciplinary problem, straddling the domains of finance, computer science, econometrics, and mathematics. The fundamental characteristics of stock price data, notably its non-linearity, non-stationarity, and considerable complexity, make the prediction of stock prices an exceptionally challenging task. In recent years, the domain of deep neural networks has shown substantial promise in terms of learning capacities, leading to significant advancements in the field of stock price prediction. However, most existing methods are still limited to predicting the closing price of the next day, rather than the future trend of stock prices, leaving investors with insufficient information for trading decisions. We propose an innovative model, DiffVT, which incorporates a Volatility Transformer for feature extraction from historical data. We introduced a de-stationary attention mechanism that integrates non-stationary information into the model to capture the dependencies in highly volatile stock price sequences. The output is then fed into an improved diffusion model based on stochastic differential equation (SDE). By iteratively solving the reverse-time SDE, our model generates a probabilistic distribution. This approach not only predicts the single-point stock price for the next day but also forecasts the future trend of stock prices over a period, providing a possible range of stock price movements. To our knowledge, DiffVT is the first model to combine a diffusion model with Transformer for stock price prediction. Extensive experiments on multiple stock indices and individual stock datasets demonstrate that DiffVT significantly outperforms state-of-the-art baseline methods, exhibiting excellent performance across various prediction window lengths. Specifically, compared to the second-best models in each domain, our approach achieves reductions of up to 11.73% in Mean Absolute Error (MAE) for point predictions, 17.23% in Continuous Ranked Probability Score (CRPS) for probabilistic predictions, and an improvement of 12.93% in the Sharpe ratio, clearly establishing its superior performance. Our code is available at https://github.com/SoraKsgn/DiffVT/ .},
  archive      = {J_ASOC},
  author       = {Chaoyang Wang and Guangyu Liu and Ling Zhu},
  doi          = {10.1016/j.asoc.2025.113763},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113763},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Diffusion model based on stochastic differential equation with transformer for stock price prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiobjective coevolutionary bayesian learning for hyperspectral sparse unmixing. <em>ASOC</em>, <em>184</em>, 113762. (<a href='https://doi.org/10.1016/j.asoc.2025.113762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capability of multiobjective evolutionary algorithms (MOEAs) to directly address ℓ 0 norm minimization has introduced innovative perspectives for solving sparse problems. However, enhancing the search efficiency of MOEAs remains a formidable challenge, especially in high-dimensional sparse problems. To alleviate the above problem, we propose a novel multiobjective coevolutionary Bayesian learning framework for a classical sparse problem—sparse unmixing. Leveraging the spatial similarity inherent in hyperspectral image patches, the proposed framework alleviates the complexity of the sparse unmixing task by segmenting the original image into homogeneous regions using superpixel segmentation. These regions are then demixed independently and jointly optimized under a cooperative evolutionary paradigm. During the optimization, the row-sparsity parameter inferred through cooperative Bayesian learning is embedded into a specially designed image-level genetic strategy. This parameter can guide the evolutionary direction of the population, encourages the solution to conform to the structural characteristic and significantly improves search efficiency. Experimental results on synthetic and real datasets demonstrated the effectiveness of the proposed algorithm as compared with several sparse unmixing methods.},
  archive      = {J_ASOC},
  author       = {Yiting Liu and Maoguo Gong and Xiangming Jiang and Jianzhao Li and Yue Zhao and Yan Pu and Ziqi Di},
  doi          = {10.1016/j.asoc.2025.113762},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113762},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiobjective coevolutionary bayesian learning for hyperspectral sparse unmixing},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time anomaly detection in seasonal time series with conditional variational autoencoder. <em>ASOC</em>, <em>184</em>, 113761. (<a href='https://doi.org/10.1016/j.asoc.2025.113761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time anomaly detection in high-frequency seasonal time series is commonly addressed using prediction-based methods, which require waiting for new values to perform subsequent predictions and demand continuous processing over time. This work introduces a novel framework for real-time anomaly detection in seasonal time series, with a practical implementation using Conditional Variational Autoencoders based on Multilayer Perceptrons. Our approach eliminates the need for historical time series data at inference time, instead generating a one-shot long-term expected time series that enables immediate evaluation of streaming data with minimal computational resources. Empirical evaluations on real-world seasonal time series demonstrate that the proposed approach achieves state-of-the-art performance compared in both semi-supervised and unsupervised settings. The framework provides computational efficiency and low energy consumption, making it suitable for deployment in commodity hardware and offline environments.},
  archive      = {J_ASOC},
  author       = {Lorenzo Porcelli and Marcello Trovati and Francesco Palmieri},
  doi          = {10.1016/j.asoc.2025.113761},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113761},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Real-time anomaly detection in seasonal time series with conditional variational autoencoder},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weight optimized stacked LSTM with conditional random fields using self-adaptive generalized normal distribution optimizer for crop yield forecasting. <em>ASOC</em>, <em>184</em>, 113760. (<a href='https://doi.org/10.1016/j.asoc.2025.113760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the agricultural sector, estimating crop production is a difficult task. A crucial element in recent years has forecasted the crop prediction, which is dependent on outside variables include soil, water, and agricultural characteristics. Crop feature extraction is used to predict crop yield using deep learning-based approaches. The predictive ability of the method heavily relies on the nature of the collected information because there is a nonlinear translation between the unprocessed information and crop yield data. Agricultural marketing, crop production, efficient harvest management, and effective fertilization management rely heavily on crop yield forecasts. Numerous manual analyses are used for remote sensing, which is often used for crop prediction. Here, the deep learning technique is more crucial for predicting crop yields from the remote sensing images, and more complicated approaches are needed to derive the essential spatiotemporal features of the data. Thus, this paper suggests a new weight-optimized Stacked Long Short Term Memory with Conditional Random Field (SLSTM-CRF) and a Modified Self-Adaptive Generalized Normal Distribution Optimizer (MSGNDO) for the prediction of crop yield. This research work has the following phases; data collection, data preprocessing, weighted feature selection, and crop yield forecasting. Primarily, the standard agricultural data is taken from the benchmark sources. Then, data preprocessing is carried out to improve the quality of data. Next, the features are optimally chosen using a newly recommended MSGNDO, in which the weights are tuned via MSGNDO. Further, the tuned weights are multiplied by the extracted features. The final crop yield prediction is done via weight-optimized SLSTM-CRF, where the parameter optimization is done using the same MSGNDO method. The prediction performance of the suggested framework is compared with existing techniques using diverse error-based measures to show effective performance regarding Dataset 1 and Dataset 2. While considering the Root Mean Squared Error (RMSE) analysis, the suggested framework shows 22.4571 less than 29.88774 of CNN, 29.20486 of RNN, 27.9877 of ResNet-50, and 25.38448 of LSTM. Overall, the performance analysis of the developed model while using dataset 1 achieves 3.549 and 24.46 for Mean Absolute Error (MAE) and RMSE, respectively. While comparing dataset 2, the developed model shows values of 5.196 and 29.16 regarding MAE and RMSE measures. Hence, the entire experimental evaluation of the recommended methods shows more effective outcomes than the existing conventional models.},
  archive      = {J_ASOC},
  author       = {Shaik Shameer Basha and B S Nissar Begum},
  doi          = {10.1016/j.asoc.2025.113760},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113760},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Weight optimized stacked LSTM with conditional random fields using self-adaptive generalized normal distribution optimizer for crop yield forecasting},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimized logic mining method for data processing through higher-order satisfiability representation in discrete hopfield neural network. <em>ASOC</em>, <em>184</em>, 113759. (<a href='https://doi.org/10.1016/j.asoc.2025.113759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A high performance classification tool such as logic mining has emerged as one of the future computing systems for big data processing. The collaboration between logic and neural network resulted in extracting the most suitable induced logic to represent knowledge from real-life datasets. However, there are certain limitations within the current logic mining models including a non-flexible logical structure, non-optimal computation of the best logic, and the generation of overfitting solutions. Motivated by these limitations, a novel logic mining model incorporating the non-systematic Satisfiability, namely Random 3 Satisfiability in Discrete Hopfield Neural Network is proposed as a logical structure to represent the behaviour of the dataset. The proposed logic mining models used flexible logical structures to prevent overfitting solutions and optimize synaptic weight values. A new computational approach of the best logic by considering True Positive and True Negative values of the learning system is applied in this work to preserve the significance behaviour of the dataset. Furthermore, the comparative experiments of the logic mining models by utilizing various repository real-life datasets are conducted from repositories to assess their efficiency. In accordance with the results, the proposed logic mining model dominates in all the metrics for the average rank. The average rank for each metrics are Accuracy (1.9375), Precision (1.9375), Specificity (1.8125), Mathews Correlation (1.5625), and Fowlkes Mallows Index (2.3125). Numerical results and in-depth analysis demonstrate that the proposed logic mining model consistently produces optimal induced logic that best represents the real-life dataset for all the performance metrics used in this study.},
  archive      = {J_ASOC},
  author       = {Nurul Atiqah Romli and Nur Fariha Syaqina Zulkepli and Mohd Shareduwan Mohd Kasihmuddin and Syed Anayet Karim and Siti Zulaikha Mohd Jamaludin and Nur ‘Afifah Rusdi and Gaeithry Manoharam and Mohd. Asyraf Mansor and Nur Ezlin Zamri},
  doi          = {10.1016/j.asoc.2025.113759},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113759},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An optimized logic mining method for data processing through higher-order satisfiability representation in discrete hopfield neural network},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing nonlinear dependencies of mamba via negative feedback for time series forecasting. <em>ASOC</em>, <em>184</em>, 113758. (<a href='https://doi.org/10.1016/j.asoc.2025.113758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mamba is a rising model designed to distill complex patterns from historical data, providing predictive capabilities for time series forecasting tasks. Mamba’s similarity to linear-based models has been criticized due to its limited ability to capture nonlinear dependencies. In this work, we propose a novel model named Embedding C hannel Attention M aclaurin E instein Mamba (CME-Mamba 1 .) based on Mamba framework, with both Embedding Channel Attention and Maclaurin mechanisms incorporated. To further address gradient vanishing issues, we integrate Einstein FFT algorithms, ensuring robust performance against abnormal behaviors of Mamba-based architectures. Extensive experiments conducted on 11 real-world datasets with different numbers of variates, domain focus and granularity, reveal that CME-Mamba achieves state-of-the-art performance in both MSE and MAE, while maintaining reasonable memory efficiency and low time cost. The robustness and credibility of all results are substantiated by a comprehensive convergence and stability analysis. Statistically, consolidated by the Friedman Nonparametric Test and the Wilcoxon Signed-Rank Test, CME-Mamba ranks the first place with significance over counterparts. In addition, in terms of time and memory analysis, CME-Mamba is among the top three models for time and memory efficiency. Despite this, our results further demonstrate that the main contributor is the Embedding Channel Attention Block, which greatly enhances nonlinear dependencies over datasets. The Einstein FFT Block effectively suppresses gradient vanishing occurrences and contributes considerably to performance improvements, driving CME-Mamba both stable and promising. Moreover, the Maclaurin Block based on negative feedback is asymptotically stable without additional gradient vanishing issues and pioneered in achieving synergies with other blocks and greatly enhances nonlinear dependencies. With enhanced nonlinear dependencies generated from the synergy effect of all the three blocks, CME-Mamba grows excellent to uncover complex paradigms and predict future states in various domains, especially improving the performance for periodic and high-variate situations, such as traffic flow management ( ≈ + 8 % ), electricity predictions( ≈ + 6 % ).},
  archive      = {J_ASOC},
  author       = {Sijie Xiong and Cheng Tang and Yuanyuan Zhang and Haoling Xiong and Youhao Xu and Atsushi Shimada},
  doi          = {10.1016/j.asoc.2025.113758},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113758},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhancing nonlinear dependencies of mamba via negative feedback for time series forecasting},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential unsupervised–supervised learning for clustering time-dependent patterns using ellipsoidal calculus. <em>ASOC</em>, <em>184</em>, 113757. (<a href='https://doi.org/10.1016/j.asoc.2025.113757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces a sequential clustering algorithm that combines unsupervised and supervised learning methodologies using ellipsoidal calculus and recurrent neural networks (RNNs). The unsupervised clustering algorithm (ULCA) identifies ellipsoidal sets for the data by applying Lagrange multipliers. These sets are then optimized with gradient descent to adjust their volume and orientation. For time-dependent data, the optimized ellipsoidal sets are updated dynamically by an RNN, which refines their center, orientation, and axis sizes in response to changes in the data. The ULCA is compared to density-based spatial clustering (DBSCAN) and K-means algorithms, showing superior accuracy without the need for pre-determined cluster numbers. Additionally, the convergence of the ULCA and RNN algorithms, working sequentially, is formally proven using Lyapunov stability theory, ensuring continuous classification of data that evolves over time. This study demonstrates the advantages of the proposed hybrid method over traditional clustering algorithms.},
  archive      = {J_ASOC},
  author       = {Alejandro Guarneros and Mariana Ballesteros and Iván Salgado and Isaac Chairez},
  doi          = {10.1016/j.asoc.2025.113757},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113757},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sequential unsupervised–supervised learning for clustering time-dependent patterns using ellipsoidal calculus},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid quantum annealing for large-scale exam scheduling: Validation in real-world educational scenarios. <em>ASOC</em>, <em>184</em>, 113756. (<a href='https://doi.org/10.1016/j.asoc.2025.113756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study applied the hybrid quantum annealing to address complex exam scheduling challenges in large-scale educational scenarios through hybrid quantum annealing enhanced by graph-based preprocessing. By formulating the problem as a Quadratic Unconstrained Binary Optimization (QUBO) model and leveraging the D-Wave Advantage system, our method integrates quantum annealing with classical preprocessing to resolve constraints on exam room availability, student-course conflicts, and batch synchronization. The approach was applied in a university’s 2022 pandemic-era makeup exam scheduling for 1807 students and 215 courses (2749 exam instances) with zero conflicts. Experimental results show that hybrid quantum annealing consumes merely 86 ms of Quantum Processing Unit (QPU) execution time. In contrast, classical simulated annealing requires 13547 ms of Central Processing Unit (CPU) execution time for the same problem scale. This work bridges quantum computing and educational operations, offering a comparative analysis of hybrid algorithms in multi-constraint optimization domains.},
  archive      = {J_ASOC},
  author       = {Ziyu Zhou and Qing Chen and Chaojie Zhang and Mengtong Tan and Shuyan Li},
  doi          = {10.1016/j.asoc.2025.113756},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113756},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hybrid quantum annealing for large-scale exam scheduling: Validation in real-world educational scenarios},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-phase evolutionary search space shrinking for large-scale multi-objective feature selection. <em>ASOC</em>, <em>184</em>, 113755. (<a href='https://doi.org/10.1016/j.asoc.2025.113755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is essential in machine learning, especially for high-dimensional datasets, where irrelevant and redundant features can degrade performance and increase computational cost. In such settings, the search space becomes exponentially large and sparsely populated with relevant solutions, making effective exploration highly challenging. Despite progress in evolutionary methods, many existing algorithms struggle to scale or maintain sparsity. There is an urgent need for scalable strategies that intelligently reduce the search space while retaining essential features. Using feature importance to guide search space shrinking offers a powerful, domain-specific approach tailored for feature selection. This paper proposes a novel large-scale multi-objective evolutionary algorithm, LMSSS, that addresses sparse feature selection through a multi-phase search space shrinking strategy. Features are ranked based on correlation with class labels and frequency in an initial low-cost evolutionary process. A voting-based crossover operator prioritizes parent solutions with better classification accuracy, while a guided mutation mechanism reintroduces prematurely excluded features for reevaluation. These components enable efficient exploration of sparse, high-dimensional spaces. Experiments on 15 large-scale datasets demonstrate that LMSSS achieves superior classification accuracy with smaller, more informative feature subsets compared to state-of-the-art methods, highlighting its effectiveness and scalability.},
  archive      = {J_ASOC},
  author       = {Azam Asilian Bidgoli and Shahryar Rahnamayan},
  doi          = {10.1016/j.asoc.2025.113755},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113755},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-phase evolutionary search space shrinking for large-scale multi-objective feature selection},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive information mesh for multimodal brain tumor segmentation. <em>ASOC</em>, <em>184</em>, 113754. (<a href='https://doi.org/10.1016/j.asoc.2025.113754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utilizing advanced deep learning techniques for automatically segmenting brain tumors in multiparametric magnetic resonance imaging (mpMRI) is crucial in enhancing diagnostic processes. However, extreme data imbalance between brain tumors and non-tumorous tissues, as well as among different subregions within the tumors, poses significant challenges for precise tumor segmentation. In this study, we revisit the problem of positive and negative sample balance from the perspective of segmentation difficulty, integrating information entropy theory. We propose an Adaptive Information Mesh that resamples based on the conditional entropy between each pixel in the original data and the final segmentation target. This resampling approach standardizes the data to a uniform level of segmentation difficulty while preserving contextual information. Our methodology includes Multi-density Sparse Convolution and Topological Reconstruction Operator to process data effectively after AI mesh sampling. Multi-density Sparse Convolution exploits the advantages of mesh data to overcome the limitations of traditional sparse convolutions, which cannot exchange information over long distances due to a fixed receptive field. The Topological Reconstruction Operator rebuilds the topological relationships between mesh layers, facilitating information exchange. We conducted training on the BraTS 2018, 2019, and 2021 datasets. Comprehensive benchmark testing on the same metrics demonstrates that our performance is comparable to state-of-the-art structured networks in terms of accuracy while reasonably allocating computational resources. Results on the ISLES 2022 dataset for infarct segmentation in ischemic stroke underscore the robustness of our method.},
  archive      = {J_ASOC},
  author       = {Qingfan Hou and Yanjun Peng and Zhuofei Wang and Jian Jiang and Nan Lv},
  doi          = {10.1016/j.asoc.2025.113754},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113754},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive information mesh for multimodal brain tumor segmentation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An attention-based multiple band interaction network for motor imagery EEG decoding. <em>ASOC</em>, <em>184</em>, 113750. (<a href='https://doi.org/10.1016/j.asoc.2025.113750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-computer interfaces (BCIs) based on motor imagery electroencephalogram (MI-EEG) have been extensively used in many applications to assist disabled people. Key frequency bands play a crucial role in MI-EEG signal decoding. However, existing researches pay insufficient attention to the interaction among different bands, especially during feature extraction process. To address this issue, in this work, a multiple band interaction network, called MBINet, is carefully constructed, which adopts band-dependent multi-branch setting. Particularly, an attention-based guide block and a multi-scale interaction block are elaborately designed. The former allows to improve the feature extraction process of μ and β bands by the lights of full band characteristics, and the latter enables to promote multi-angle and multi-scale interactive fusion of high-order significant features from multiple bands. The performance testing of MBINet is performed on two publicly available MI datasets, namely the BCI competition IV-2a dataset and the High gamma dataset. The experimental results show that MBINet outperforms the state-of-the-art methods, with an average classification accuracy of 81.66% and 95.78%, respectively. MBINet provides a new perspective for decoding nonlinear time series, especially EEG signals, by emphasizing diverse interactions between key frequency bands.},
  archive      = {J_ASOC},
  author       = {Weidong Dang and Kefa Zhang and Haoyu Li and Dongmei Lv and Wei Guo and Zhongke Gao},
  doi          = {10.1016/j.asoc.2025.113750},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113750},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An attention-based multiple band interaction network for motor imagery EEG decoding},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The neighborhood rough set based on division-mining-fusion strategy. <em>ASOC</em>, <em>184</em>, 113749. (<a href='https://doi.org/10.1016/j.asoc.2025.113749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neighborhood rough set (NRS) model exhibits significant value in numerous data mining tasks. However, most existing NRS models are only suitable for data mining problems in a single dataset, and their comprehensive performance in processing data is not ideal. To address these two challenges, we develop a novel NRS model by applying the division-mining-fusion (DMF) strategy. Specifically, we first decompose the original dataset into multiple subsets. Then, a submodel is established for each subset, and finally, all submodels are integrated to develop a new NRS model. The experimental results demonstrate that the developed model can not only effectively handle the data mining tasks in scenarios with multiple datasets, but also has outstanding comprehensive performance. The NRS model developed in the paper provides a novel solution for efficiently processing large-scale complex data.},
  archive      = {J_ASOC},
  author       = {Conghao Yan and Qingzhao Kong and Wenbin Zhang},
  doi          = {10.1016/j.asoc.2025.113749},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113749},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The neighborhood rough set based on division-mining-fusion strategy},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable deep learning framework for lower limb activity classification using reconstructed sEMG signals in healthy and pathological subjects. <em>ASOC</em>, <em>184</em>, 113748. (<a href='https://doi.org/10.1016/j.asoc.2025.113748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing human activities from Surface Electromyography (sEMG) signals is fraught with challenges, including noise susceptibility and signal crosstalk. Addressing these, our study analyses sEMG data from 11 healthy and 11 pathological subjects across three distinct activities: sitting, standing, and walking. We introduce a pioneering preprocessing approach that integrates Bandpass Filtering, Wavelet Denoising, and Ensemble Empirical Mode Decomposition (EEMD) for signal enhancement. A significant aspect of our approach involves the reconstruction of signals by selecting the top 50% of Intrinsic Mode Functions (IMFs) based on entropy, Signal-to-Noise Ratio (SNR), correlation, and energy, effectively capturing the most informative features of the sEMG signals. To counterbalance dataset imbalances and facilitate robust feature extraction, we applied Adaptive Synthetic (ADASYN) sampling and segmented the data into 256 ms windows with a 25% overlap. Our Convolution Neural Network (CNN) achieves remarkable classification accuracies: for sitting, 99.4% in healthy and 99.2% in pathological subjects; for standing, 99.7% and 98.8% respectively; and for walking, 99.4% and 98.6%, respectively. Furthermore, the integration of Explainable AI (XAI) through Permutation Feature Importance (PFI) provides critical insights into the significant impact of muscle signals, particularly highlighting the Rectus Femoris (RF) muscle’s role in sitting with leg extension, BF muscles’s role in standing with flexion. This comprehensive and innovative methodology not only overcomes the inherent challenges of sEMG signal analysis but also enhances the interpretability and reliability of activity recognition, marking a significant advancement for personalized healthcare interventions.},
  archive      = {J_ASOC},
  author       = {Pratibha Tokas and Vijay Bhaskar Semwal and Sweta Jain},
  doi          = {10.1016/j.asoc.2025.113748},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113748},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Explainable deep learning framework for lower limb activity classification using reconstructed sEMG signals in healthy and pathological subjects},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mission assignment and path planning for ground forces using permutation-based simplified swarm optimization with Q-learning adaptation. <em>ASOC</em>, <em>184</em>, 113747. (<a href='https://doi.org/10.1016/j.asoc.2025.113747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study tackles task assignment and path planning for counteroffensive operations using a bi-level programming model inspired by spatial crowdsourcing. While existing models often prioritize centralized platform decisions, they tend to overlook the autonomy and real-time judgment of on-site participants, whose local actions critically affect coordination outcomes. To address this, we propose the Defender Deployment and Routing Model (DDRM), which integrates upper-level task assignment with lower-level route planning. To solve DDRM efficiently, we develop a hybrid nested framework integrating an Adaptive Permutation-Based Simplified Swarm Optimization (APSSO) algorithm with Dijkstra’s algorithm. APSSO incorporates a task-aware initialization strategy and a lightweight Q-learning mechanism for operator selection. As the first SSO-based approach with permutation-based operators, APSSO effectively handles discrete task allocation structures. Experimental results on 36 benchmark instances show that APSSO achieves the best performance in 34 cases compared to six tailored evolutionary variants. Statistical analysis confirms its superiority in solution quality, while the added Q-learning module introduces minimal computational overhead. These results highlight APSSO’s efficiency and robustness across varying problem scales.},
  archive      = {J_ASOC},
  author       = {Jun-Lin Lin and Chyh-Ming Lai and Song-Pei Wu},
  doi          = {10.1016/j.asoc.2025.113747},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113747},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Mission assignment and path planning for ground forces using permutation-based simplified swarm optimization with Q-learning adaptation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic event-triggered adaptive fuzzy admittance control of robotic systems with uncertainties. <em>ASOC</em>, <em>184</em>, 113746. (<a href='https://doi.org/10.1016/j.asoc.2025.113746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern industrial production and daily life, the increasing complexity of application scenarios has led to higher requirements for the compliance and safety of robotic systems. However, during robot control, a large number of redundant signals are often sampled, which significantly increases the communication burden. Therefore, how to substantially reduce the communication burden while ensuring satisfactory performance has become an urgent issue to be addressed. To address this challenge, this paper proposes a dynamic event-triggered adaptive fuzzy admittance control (DETAFAC) strategy for robotic systems with uncertainties, where the more aggressive dynamic event-triggered condition can significantly reduce the communication burden and the admittance model is used to reshape the desired trajectory of the robotic systems. Additionally, a fuzzy logic system (FLS) is utilized to address the uncertainties of the robotic systems, the update law of the FLS and the stability of the control system are examined using the Lyapunov stability theorem, and the dynamic triggering condition is formulated to prevent Zeno behavior. Simulation and experimental validations are performed, and the results demonstrate that the proposed DETAFAC strategy can achieve better performances in comparison to the similar approaches.},
  archive      = {J_ASOC},
  author       = {Jinzhu Peng and Xuxin Liu and Shuai Ding and Yaqiang Liu},
  doi          = {10.1016/j.asoc.2025.113746},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113746},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic event-triggered adaptive fuzzy admittance control of robotic systems with uncertainties},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boxing action recognition using inertial data and deep learning. <em>ASOC</em>, <em>184</em>, 113745. (<a href='https://doi.org/10.1016/j.asoc.2025.113745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the ongoing shift toward automated sports performance analysis by employing Deep Convolutional Neural Networks (DCNNs) for the classification of movement data in combat sports, specifically boxing. Using data from wearable inertial measurement units (IMUs), this study addresses the limitations of traditional, expensive video analysis by providing an accessible, cost-effective alternative that can be seamlessly integrated into athletes' training routines. IMUs offer a practical solution for continuous performance monitoring and feedback, establishing a foundation for automated performance assessment during training sessions. In this study, the classification accuracy and recall of DCNNs are rigorously compared with alternative algorithms, demonstrating a high overall recall of 99 % and accuracy of 91 %. Focusing on pad work training as a key application area, this work advances the automation of boxing action recognition, with implications for both training optimization and real-time scoring automation in competitive boxing. These findings underscore the potential for wearable technology and advanced machine learning methods to transform athletic performance evaluation and bring engineering innovation to sports training.},
  archive      = {J_ASOC},
  author       = {J. Brindha and G. Nallavan and Radana Vilimkova Kahankova and Radek Martinek},
  doi          = {10.1016/j.asoc.2025.113745},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113745},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Boxing action recognition using inertial data and deep learning},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive dual-network control for modular robots in human–robot interaction. <em>ASOC</em>, <em>184</em>, 113744. (<a href='https://doi.org/10.1016/j.asoc.2025.113744'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to address safety and compliance challenges in physical human–robot interaction (pHRI), this paper presents an adaptive dual-neural network (NN) control framework for modular robot manipulators (MRMs). The proposed approach enables seamless switching between autonomous trajectory tracking and compliant motion guided by human interaction. An adaptive fuzzy model uncertainty compensation method is employed to estimate the interaction torque that is utilized to detect physical contact, determining the MRM’s operation mode. Additionally, the reference trajectory tracking information is provided by human motion intention identification via NNs. This method avoids the need for external force/torque sensors and increases the intention recognition accuracy by jointly estimating human impedance parameters. The overall control scheme simultaneously incorporates adaptive fuzzy PD control and decentralized impedance control through a mode-switching structure, ensuring compliant and accurate motion in the two operation modes. A Lyapunov-based analysis is then conducted. The obtained results demonstrate that the tracking errors of the closed-loop system are uniformly ultimately bounded (UUB). An experimental validation for various tasks also demonstrates the high robustness and effectiveness of the proposed strategy. Note that all the procedures adopted in this paper are conducted following standard safety guidelines, with full consideration of ethical aspects in pHRI.},
  archive      = {J_ASOC},
  author       = {Yuexi Wang and Tianjiao An and Bo Dong and Mingchao Zhu and Yuanchun Li},
  doi          = {10.1016/j.asoc.2025.113744},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113744},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive dual-network control for modular robots in human–robot interaction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-informed machine learning: Data-driven reconstruction of delay differential equations models. <em>ASOC</em>, <em>184</em>, 113743. (<a href='https://doi.org/10.1016/j.asoc.2025.113743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the understanding of the dynamical mechanisms underlying complex systems, this study presents a novel data-driven framework for modeling Delay Differential Equations. The Galerkin-Koornwinder theory is combined with Neural Ordinary Differential Equations for the first time, addressing the significant challenge of reconstructing models that incorporate time-delay effects by approximating them with Ordinary Differential Equations within a rigorous mathematical framework. Leveraging Neural Ordinary Differential Equations to learn these approximate models, the approach achieves high interpretability and generalizability, effectively capturing the dynamics of various delay systems, including those with discrete delays, multi-time delays, and distributed delays. Extensive simulation experiments on models exhibiting bifurcation and chaos, as well as real-world biological data, demonstrate the superior performance of this method in long-term prediction and system dynamics reconstruction. When validated on a set of real-world biological experimental data, the long-term behavior prediction error was reduced from 11% to below 1%. The comparison with similar studies elucidates that the approach can accurately capture complex behaviors and outperforms existing methods in terms of prediction accuracy and generalization capability. All data and code are openly available, facilitating reproducibility and further research.},
  archive      = {J_ASOC},
  author       = {Xiyuan Chen and Zhong Liu and Qiubao Wang and Zikun Han},
  doi          = {10.1016/j.asoc.2025.113743},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113743},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic-informed machine learning: Data-driven reconstruction of delay differential equations models},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusion of data-driven models with a knowledge-guided loss function for flood forecasting. <em>ASOC</em>, <em>184</em>, 113742. (<a href='https://doi.org/10.1016/j.asoc.2025.113742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heavy rainfall frequently causes flooding disasters in basins of all sizes; however, small and medium-sized basins -typically defined as drainage areas less than 1000 km²- are particularly vulnerable due to their rapid runoff response, often resulting in casualties and property losses. Researchers worldwide have made excellent progress in advancing flood prediction capabilities by developing intelligent data-driven models. However, these models rely only on available data and ignore expert knowledge of floods and fail to account for the varying importance of prediction errors during flood and non-flood events in their training process. Therefore, we propose fusing data-driven models with expert knowledge frameworks by designing a custom loss function for accurate flood forecasting. The proposed model effectively interprets the complexity of flood events in small and medium-sized basins and introduces accurate results. By incorporating expert knowledge constraints, it emphasises the importance of prediction errors during critical flood events. The model was tested using hourly streamflow data from the Heihe and Tunxi basins in China. Results show that our model improves prediction accuracy by up to 80 % in root mean square error (RMSE) and 87 % in mean absolute error (MAE) in Heihe and increases the coefficient of determination (R²) by 66 % and the Kling–Gupta efficiency (KGE) by 58 % in Tunxi compared to baseline models such as INFORMER, TD-CNN-LSTM, STA-LSTM, STA-TCN, LSTM, CNN, TCN, and SVR. These findings demonstrate the model’s superior performance in providing accurate and reliable 6-hour-ahead (T + 6) flood forecasts.},
  archive      = {J_ASOC},
  author       = {Haider Malik and Jun Feng and Mohammed Abdallah and Jiru Zhang and Pingping Shao and Zaid Ameen Abduljabbar},
  doi          = {10.1016/j.asoc.2025.113742},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113742},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fusion of data-driven models with a knowledge-guided loss function for flood forecasting},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-organizing interval type-2 fuzzy neural network based on eigenvalue decomposition. <em>ASOC</em>, <em>184</em>, 113741. (<a href='https://doi.org/10.1016/j.asoc.2025.113741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an eigenvalue decomposition-based self-organizing interval type-2 fuzzy neural network (ED-SOIT2FNN) is proposed to tackle the identification problem of nonlinear systems. The network model determines both the structure and parameters of the network through online learning, which can realize the structure learning and parameter learning simultaneously. Firstly, in the structure learning process of ED-SOIT2FNN, the error criterion and the completeness criterion of fuzzy rules are used to verify whether the rules grow. Meanwhile, the eigenvalue decomposition method is adopted to find the less active rules for deletion, so that obtain a more compact network structure. Secondly, in terms of ED-SOIT2FNN parameter optimization and the characteristics of network parameters, they are divided into the linear and nonlinear ones. The algorithm of adaptive discount recursive partial least square is employed to optimize the linear parameters, which is conducive to improving the noise resistance of the network model and solving the data saturation problem. And the sliding window adaptive second-order algorithm with a forgetting factor is adopted to optimize the nonlinear parameters. Compared with the algorithm of gradient descent optimization, it can accelerate the convergence and achieve a good adaptability with stability. Finally, the proposed ED-SOIT2FNN was applied to four typical nonlinear examples for identification. The experimental results showed that compared with similar methods in the existing literature, the proposed ED-SOIT2FNN could produce a more compact network structure with higher accuracies of identification and prediction.},
  archive      = {J_ASOC},
  author       = {Panchao Wang and Taoyan Zhao and Jiangtao Cao and Ping Li},
  doi          = {10.1016/j.asoc.2025.113741},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113741},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Self-organizing interval type-2 fuzzy neural network based on eigenvalue decomposition},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Berth-quay crane-experiment allocation method based on improved genetic algorithm for cargo and scientific research port. <em>ASOC</em>, <em>184</em>, 113740. (<a href='https://doi.org/10.1016/j.asoc.2025.113740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Against the background of booming global shipping trade and growing demand for marine scientific research, multifunctional ports with both cargo transportation and scientific research functions, namely CSR_Ports, are facing significant operational scheduling challenges. Due to the intricate mutual influence and resource competition among cargo vessels, research vessels, and marine experiments, the existing method struggles to cope with the diversified demands of port operations. To solve the above challenges, this study considers the differences in infrastructure requirements between cargo vessels and research vessels, designs differentiated work areas, abstracts the berth-quay crane-experiment allocation problem into a two-dimensional packing problem with time window constraints, and establishes a dual-objective berth-quay crane-experiment allocation (BQCEA) model to minimize the vessels' average turnaround time and the average variation of the experiment start time. Then, given the limitations of genetic algorithms, such as insufficient adaptive ability and a tendency to fall into local optimality, an improved algorithm, namely NQRGA, is proposed based on neighborhood search, quantum multi-point crossover, and retention mechanism. Finally, the BQCEA model is combined with the NQRGA to propose a novel solution method for solving the berth-quay crane-experiment allocation problem, referred to as BQCEA_NQRGA. The effectiveness of the BQCEA_NQRGA method is evaluated using real operational data from two CSR_Ports in China. The test results show that, compared with the FCFS method, the BQCEA_NQRGA method achieves at least a 49.79 % performance improvement, and the optimization effect gradually increases to 101 % with the increase in the scheduling scale. Compared with the six advanced algorithms selected in this paper, the proposed NQRGA performs best in all six different instances. Notably, the BQCEA_NQRGA method can generate high-quality allocation schemes for 70 vessels and 14 experiments simultaneously within 100 s.},
  archive      = {J_ASOC},
  author       = {Ming-Wei Li and Xiang-Yang Li and Jing Geng and Zhong-Yi Yang and Wei-Chiang Hong},
  doi          = {10.1016/j.asoc.2025.113740},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113740},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Berth-quay crane-experiment allocation method based on improved genetic algorithm for cargo and scientific research port},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep reinforcement learning model based on DDPG considering attention mechanism and combined with GRU network for short-term load forecasting. <em>ASOC</em>, <em>184</em>, 113739. (<a href='https://doi.org/10.1016/j.asoc.2025.113739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term load forecasting plays a crucial role in power system operations and energy market efficiency. This paper addresses the challenge of capturing complex nonlinear patterns and temporal dependencies in electricity load data, which traditional forecasting methods often fail to handle effectively. We propose a novel deep reinforcement learning approach that combines attention mechanisms with gated recurrent units within a deep deterministic policy gradient framework (Attention-GRU-DDPG). The key innovation lies in treating load forecasting as a decision-making problem, where the model learns to adapt its predictions based on multivariate inputs including historical load, weather conditions, and electricity prices. Our approach uniquely integrates three complementary components: attention mechanisms for feature prioritization, GRU networks for temporal pattern recognition, and reinforcement learning for adaptive strategy optimization. Extensive experiments on Australian electricity market data demonstrate that our model achieves superior forecasting accuracy compared to ten benchmark methods. The proposed framework offers a practical solution for power system operators requiring accurate 24–168 h ahead load predictions, contributing to more efficient grid management and market operations.},
  archive      = {J_ASOC},
  author       = {Xin He and Wenlu Zhao and Zhijun Gao and Licheng Zhang and Qiushi Zhang and Xinyu Li},
  doi          = {10.1016/j.asoc.2025.113739},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113739},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel deep reinforcement learning model based on DDPG considering attention mechanism and combined with GRU network for short-term load forecasting},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel blood supply management model using evolutionary neural network. <em>ASOC</em>, <em>184</em>, 113738. (<a href='https://doi.org/10.1016/j.asoc.2025.113738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing demand and supply uncertainties and the short lifetime of blood products cause wastage of the blood gathered from donors. Also, there is a high shortage of blood products because of the limited number of donors and emergency demands. Hence, there is a great significance to constructing a blood supply management model by minimizing (1) transportation cost, (2) shortage cost, (3) wastage cost, (4) ordering cost, and (5) inventory holding cost. The different types of costs with constraints make blood supply management a challenging multi-objective combinatorial optimization problem. Earlier, neural genetic algorithms mostly concentrate on single-objective optimization problems. In this paper, we propose a blood supply management procedure using a network-driven evolutionary network (D2NNEA). A set of pointer networks are utilized to solve the multi-objective problem. The performance of the proposed technique is analyzed by comparing it with existing techniques and the superiority of the proposed technique in solving multi-objective optimization problems is verified.},
  archive      = {J_ASOC},
  author       = {Harinandan Tunga and Soumyadip Dhar and Samarjit Kar and Debasis Giri},
  doi          = {10.1016/j.asoc.2025.113738},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113738},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel blood supply management model using evolutionary neural network},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial unified learning for dynamic change detection in hyperspectral images. <em>ASOC</em>, <em>184</em>, 113737. (<a href='https://doi.org/10.1016/j.asoc.2025.113737'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image change detection (HSI-CD) aims to identify changes in bi-temporal hyperspectral images (HSIs) captured at different times in the same location. Existing algorithms often overlook the inherent class imbalance in HSI-CD, leading to poor generalization in detecting changes while introducing redundant computation in unchanged regions. This paper introduces a novel mechanism based on Partial Unified Learning for Dynamic Change Detection (PUL-DCD) to address these limitations. Particularly, a novel partial unified learning network is proposed, whose backbone is trained using multiple datasets, whilst the task-specific networks are trained independently with each individual dataset. In so doing, the network can maintain outstanding performance on specific datasets while having strong generalization ability. Furthermore, an innovative dynamic architecture is introduced that distinguishes between easy and hard regions for change detection, thereby optimizing parameter configuration and enhancing detection performance in challenging areas, while mitigating redundancy regarding unchanged information. Experimental results on three datasets show that PUL-DCD is competitive in both accuracy and efficiency.},
  archive      = {J_ASOC},
  author       = {Keyun Zhao and Ying Li and Qingping Zheng and Qiang Shen},
  doi          = {10.1016/j.asoc.2025.113737},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113737},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Partial unified learning for dynamic change detection in hyperspectral images},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Offline reinforcement learning for job-shop scheduling problems. <em>ASOC</em>, <em>184</em>, 113736. (<a href='https://doi.org/10.1016/j.asoc.2025.113736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep learning have shown significant potential for solving combinatorial optimization problems in real-time. Unlike traditional methods, deep learning can generate high-quality solutions efficiently, which is crucial for applications like routing and scheduling. However, existing approaches like deep reinforcement learning (RL) and behavioral cloning have notable limitations, with deep RL suffering from slow learning and behavioral cloning relying solely on expert actions, which can lead to generalization issues and neglect of the optimization objective. Offline RL addresses these challenges by learning from fixed datasets while leveraging reward signals, making it especially suitable for constrained combinatorial problems where online exploration is impractical. This paper introduces a novel offline RL method designed for combinatorial optimization problems with complex constraints, where the state is represented as a heterogeneous graph and the action space is variable. Our approach encodes actions in edge attributes and balances expected rewards with the imitation of expert solutions. We demonstrate the effectiveness of this method on job-shop scheduling and flexible job-shop scheduling benchmarks, achieving superior performance compared to state-of-the-art techniques.},
  archive      = {J_ASOC},
  author       = {Imanol Echeverria and Maialen Murua and Roberto Santana},
  doi          = {10.1016/j.asoc.2025.113736},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113736},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Offline reinforcement learning for job-shop scheduling problems},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrogate-assisted multi-objective covariance matrix adaptation evolution strategies. <em>ASOC</em>, <em>184</em>, 113728. (<a href='https://doi.org/10.1016/j.asoc.2025.113728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is one of the most preferred evolutionary algorithms for single-objective black-box optimization, its performance is limited in the multi-objective space due to its reliance solely on Gaussian-based mutation without any crossover for offspring generation. To address this limitation, this work proposes a surrogate-assisted multi-objective CMA-ES algorithm with an ensemble of offspring generation schemes. In the proposed algorithm, trial solutions are generated from an ensemble of the standard CMA-ES operator and a Genetic Algorithm-inspired operator. Consequently, the solutions are evaluated on a Gaussian Process-based surrogate model, and the solution with the best Expected Improvement (EI) is selected as the generated offspring. Experiments on the Walking Fish Group (WFG) test suite and 18 benchmark multi-objective Neural Architecture Search (NAS) problems demonstrate that the proposed approach is statistically superior to existing multi-objective CMA-ES variants and other state-of-the-art non-CMA-ES multi-objective algorithms. Specifically, the proposed algorithm achieves a win rate of 79.63% and 77.8% on the WFG and NAS test suites, respectively, against other CMA-ES variants, and demonstrates a 68.8% win rate against state-of-the-art algorithms on the NAS test suite.},
  archive      = {J_ASOC},
  author       = {Oladayo S. Ajani and Adeyinka Adedigba and Kalyana C. Veluvolu and Rammohan Mallipeddi},
  doi          = {10.1016/j.asoc.2025.113728},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113728},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Surrogate-assisted multi-objective covariance matrix adaptation evolution strategies},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-source domain adaptation approach with learning domain-specific representations for bearing fault diagnosis under limited samples. <em>ASOC</em>, <em>184</em>, 113727. (<a href='https://doi.org/10.1016/j.asoc.2025.113727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearings, vital to train traction motors, directly influence train safety due to their exposure to harsh environments and alternating loads, leading to various faults. Bearing fault diagnosis is thus critical for ensuring train safety. However, the challenge of data privacy and the scarcity of data make diagnosing faults difficult. Currently, transfer models based on single-source domain adaptation are used to address the above issues. However, data from multiple related domains may exist simultaneously in some scenarios. Therefore, learning fault knowledge from multiple domains and transferring it to the target domain for faults is a difficult problem. In view of this, we propose a multi-source domain adaptation approach with learning domain-specific representations (MDA-LDDSR) for bearing fault diagnosis under limited samples. First, MDA-LDDSR adds a domain-specific feature extractor (MAS-Net) for source and target domain to align the target domain with the distribution. After purifying the features by a partial feature selection strategy, we innovatively construct an intra-class alignment strategy to keep the marginal and conditional distributions of the data in alignment. Then, we utilize the instance-to-domain Mahalanobis distance to explicitly model the similarity between different domains. Finally, this similarity is assigned in the form of weights to multiple domain hypotheses. Superiorly, experiments in real rolling bearing fault diagnosis also show that the model has better convergence while it is characterized by high efficiency and robustness. The proposed approach has a strong advantage to be used for real-time bearing fault diagnosis when noise is added to the environment. Also, it obtains the desired diagnosis results compared to other approaches of the same type.},
  archive      = {J_ASOC},
  author       = {Qiang Zhou and Wengang Ma and Yadong Zhang and Jin Guo},
  doi          = {10.1016/j.asoc.2025.113727},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113727},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-source domain adaptation approach with learning domain-specific representations for bearing fault diagnosis under limited samples},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrounding and context-aware network for individual emotion complement in social networks. <em>ASOC</em>, <em>184</em>, 113726. (<a href='https://doi.org/10.1016/j.asoc.2025.113726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most sentiment analysis focuses on identifying individual emotional shifts related to a specific topic or predicting an individual’s emotional state in the future. However, it overlooks the influence of surrounding factors and contextual emotional information within social networks. Furthermore, it is also important to address the gap in understanding the missing emotions of individuals during critical historical moments. In this paper, we propose a surrounding and context-aware network for individual emotion complement(denoted as SCAEC) to infer missing emotional states at pivotal moments in history. The SCAEC network consists of an encoder layer for emotion embedding, a surrounding-aware layer, a context-aware layer, a feature interactive learning layer and an emotion distribution layer. Additionally, we introduce a decay long short-term memory (LSTM) network (DLSTM) within the SCAEC, which effectively extracts emotional features from individuals during moments of emotional absence and allows for the decay of emotional influence over time. We use DLSTM to extract associated emotional features as global features and apply multi-head attention to capture key emotional features as local features from posts/comments before and after moments of emotional absence. This allows us to obtain surrounding and context features based on the global and local features, respectively. The feature interactive learning layer then combines these features between the surrounding and context features to learn their interaction. Additionally, the emotion distribution layer simulates the emotional interaction between the individual and their surroundings. Finally, we derive the individual’s emotion distribution. Experimental results demonstrate that SCAEC model achieves an F1 score of 67.52% on the X and 68.98% on the Microblog dataset, marking an improvement of 1%–10% compared to baseline methods.},
  archive      = {J_ASOC},
  author       = {Sai Kang and YaJun Du and Xianyong Li and Xiaoliang Chen and Chunzhi Xie and Jia Liu and Yan-li Lee},
  doi          = {10.1016/j.asoc.2025.113726},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113726},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Surrounding and context-aware network for individual emotion complement in social networks},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spam bot detection on twitter platform using positional attention based dense convolutional neural network. <em>ASOC</em>, <em>184</em>, 113725. (<a href='https://doi.org/10.1016/j.asoc.2025.113725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, social media platforms such as Twitter and Facebook play a major role in everyday life because of the incredible opportunities they offer users. Twitter is the most essential social media platform since it allows people to express themselves through tweets. However, because of its popularity among a vast number of users, the Twitter platform is being abused by automated accounts known as bots. Since automated accounts transmit fake news, fake ideas, and fake products, early detection of bots on the Twitter platform is critical. Previously, researchers introduced ineffective methods for identifying social media bots. Positional Attention-based Dense Convolutional Neural Network (PAtt_Dense CNN) is a new deep learning-based spam bot detection framework proposed in this paper. Pre-processing of the incoming data includes stop word removal, tokenization, stemming, n-gram identification, user mention, URL and hashtag removal, vocabulary density, and richness analysis. From the pre-processed images, significant features are extracted utilizing N-gram level vectorizer, TF-IDF vectorizer, character level vectorizer, and Extended Bidirectional Encoder Representations from Transformer (EBERT). After feature extraction, binary water wheel plant optimization is used to select the best characteristics. Finally, spam bot detection and classification are performed using a PAtt_Dense CNN. The performance of the proposed technique is then evaluated by analyzing the performance indicators and comparing them to existing procedures. According to the comparison results, the proposed technique achieved the enhanced outcome in terms of Accuracy, Precision, Recall, and F1-Score of 97.8 %, 97.2 %, 98.3 %, and 99.2 %, respectively.},
  archive      = {J_ASOC},
  author       = {Hemal Girishkumar Shah and Hiren Joshi},
  doi          = {10.1016/j.asoc.2025.113725},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113725},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Spam bot detection on twitter platform using positional attention based dense convolutional neural network},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistency- and ordinal consensus-based multiple scenario model for group decision-making with incomplete probabilistic linguistic preference relations. <em>ASOC</em>, <em>184</em>, 113722. (<a href='https://doi.org/10.1016/j.asoc.2025.113722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete probabilistic linguistic preference relations (InPLPRs), as a practical expression to portray the uncertainty of things, can describe the information on decision makers’ (DMs’) evaluation of things in pairwise comparisons in group decision making with two dimensions simultaneously. This paper investigates a group decision-making (GDM) method with InPLPRs to express the preference information of DMs and establish a consensus reaching mechanism for multiple scenarios. First, to obtain incomplete information, we define the concept of opinion swing neighborhood based on referring to the opinions of others and analyzing the mental behavior of DMs. Furthermore, a missing information estimation model of InPLPRs considering the opinion swing neighborhood is developed to obtain consistent optimal estimates. Secondly, the ordinal consensus index is defined, facilitating a more accurate measure of consensus attainment. Then, we thoroughly explore the classification of decision situations using consistency, consensus, illogical rate, and distinguishing index. Based on this, the corresponding consensus optimization models are proposed for different decision scenarios. Subsequently, the DMs’ weights are presented for aggregating individual opinions with acceptable consistency and consensus into group opinions, and the collective opinions are ranked and selected. Finally, numerical examples, simulation experiments, and comparative analysis demonstrate the proposed method’s applicability, effectiveness, and advantages. The proposed method offers a comprehensive GDM approach based on InPLPRs, which can be applied to various real-world GDM scenarios, demonstrating broad applicability.},
  archive      = {J_ASOC},
  author       = {Ran Dang and Peide Liu and Peng Wang and Luis Martínez},
  doi          = {10.1016/j.asoc.2025.113722},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113722},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Consistency- and ordinal consensus-based multiple scenario model for group decision-making with incomplete probabilistic linguistic preference relations},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Equidistant deep embedding-based multi-label group activity recognition with dependency-constrained training. <em>ASOC</em>, <em>184</em>, 113721. (<a href='https://doi.org/10.1016/j.asoc.2025.113721'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group activities in real-world scenarios are often complex and require multiple labels for adequate representation, as they involve multifaceted social interactions among individuals within a small group setting. Existing group activity recognition (GAR) methods primarily focus on model inference, overlooking the inherent challenges of multi-label learning (MLL). One common approach to MLL is the label powerset (LP) method, which transforms multi-hot label vectors into one-hot vectors, converting the multi-label problem into a single-label multi-classification problem. However, this projection loses correlations among active elements in multi-hot vectors, hindering the capture of inter-activity dependencies. To address this limitation, we propose a novel equidistant deep embedding-based (EDE) multi-label GAR framework with dependency-constrained training, building upon the LP approach. Our framework leverages a deep embedding network with self-supervised equidistant regularization loss to project multi-hot label vectors into evenly spaced dense vectors, which not only facilitate problem transformation but also contain latent activity patterns, including label correlations. We treat these dense vectors as new labels and design a corresponding deep learning and classification (DLC) strategy that optimizes all GAR model parameters except for the classification layers. Additionally, we propose a training-only auxiliary branch, dubbed TransOvR module, to bolster the model’s capacity for inter-activity dependency reasoning. By leveraging Transformer’s context-aware capability, this module facilitates interactions between multiple binary classifiers, focusing on correlations between activities. Our extensive experiments demonstrate the effectiveness of our method, outperforming state-of-the-art multi-label GAR methods.},
  archive      = {J_ASOC},
  author       = {Lindong Li and Linbo Qing and Pingyu Wang and Yang Xiao and Wang Tang and Yonghong Peng},
  doi          = {10.1016/j.asoc.2025.113721},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113721},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Equidistant deep embedding-based multi-label group activity recognition with dependency-constrained training},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced nonlinear optimization of low- and high-resolution medical images using adaptive deep spearman correlation analysis (D-SCA) for pattern sequence recognition. <em>ASOC</em>, <em>184</em>, 113720. (<a href='https://doi.org/10.1016/j.asoc.2025.113720'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the state-of-art model for those healthcare multimedia datasets that have nonlinear limitations during the processing of multi-dimensional or non-linear data that usually decrease the accuracy rate and increase computational cost as per computational resources. Such as correlation among the low-resolution images to high-resolution images, and videos, the reason is non-linearity between data, non-linear dimensions or variation and illusion in the data. The proposed state-of-the-art model uses multiple techniques with transfer learnings approach to solve these issues. This paper further explains the details of the proposed deep convolutional neural network model for visual feature maps extraction and then followed by the proposed algebraic extension of Spearman correlation analysis to create the relationship of low-resolution image to high-resolution image with adaptive optimization. Then it leads to the next component of model as Radial Basis Function Network (RBFN) for non-linear mapping among LR to HR images, for classification the hybrid Xception deep learning model is used and implemented on four benchmark datasets.},
  archive      = {J_ASOC},
  author       = {Muhammad Saddam Khokhar and Misbah Ayoub and Zakria and Abdullah Lakhan},
  doi          = {10.1016/j.asoc.2025.113720},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113720},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advanced nonlinear optimization of low- and high-resolution medical images using adaptive deep spearman correlation analysis (D-SCA) for pattern sequence recognition},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-modal deep interaction and modal-aware aggregation network for visible and infrared tracking. <em>ASOC</em>, <em>184</em>, 113719. (<a href='https://doi.org/10.1016/j.asoc.2025.113719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, developing a robust RGB-Thermal (RGBT) tracking method in complex environments remains challenging in effectively mining and fusing cross-modal complementary information, enhancing modal perception capabilities, and improving the representation ability of fused semantic features. To address these challenges, we propose a novel architecture called Multi-branch Cross-modal Deep Interaction Fusion and Adaptive Aggregation Integrating Hybrid Attention Semantic Enhancement Network (MCFTNet). Specifically, MCFTNet first extracts modality-specific features through dedicated branches, followed by designing a cross-modal deep interaction fusion network to achieves deep interaction and comprehensive fusion of cross-modal features through a fusion branch as the medium. Furthermore, a modal-aware adaptive aggregation module is developed to dynamically aggregates high-resolution features from different branches, while significantly enhancing the discriminative ability of multi-modal features. Finally, a hybrid attention semantic enhancement module is introduced that combines carefully designed enhanced multi-head attention and hierarchical attention to optimize the fused semantic features, thereby achieving highly accurate prediction of target position and shape. Extensive experiments on three mainstream public benchmark datasets, GTOT, RGBT234, and LasHeR, demonstrate the effectiveness and robustness of our proposed method.},
  archive      = {J_ASOC},
  author       = {Xiang Liu and Haiyan Li and Victor Sheng and Yujun Ma and Xiaoguo Liang and Guanbo Wang},
  doi          = {10.1016/j.asoc.2025.113719},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113719},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cross-modal deep interaction and modal-aware aggregation network for visible and infrared tracking},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Embedding neural sampling and adversarial bandit into gene expression programming for symbolic regression. <em>ASOC</em>, <em>184</em>, 113718. (<a href='https://doi.org/10.1016/j.asoc.2025.113718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary computation methods for symbolic regression problems use a search method to actively explore the mathematical expression space to find a solution. However, the evolutionary computation search process lacks a clear direction due to the randomness of evolutionary operations. In contrast, deep learning methods focus on learning a clear mapping from a given dataset to a mathematical function, but the learning process does not generally involve an active search of the potential solution space. To combine the advantages of the active search of evolutionary computation and the clear mapping direction of neural networks, this paper proposes a novel algorithm called GVAE-ABGEP. GVAE-ABGEP incorporates a grammar variational autoencoder and adversarial bandit into gene expression programming to guide its search process. GVAE-ABGEP partitions the mathematical expression space into many subspaces. It then leverages an adversarial bandit — AvgHExp3 to choose a subspace. In the selected subspace, it then utilizes an autoencoder to sample individuals whose fitnesses are near the local optima, and executes crossover, mutation, and selection in evolutionary computation to explore the global optima. Experiments on 18 symbolic regression and 12 physics benchmarks show that GVAE-ABGEP outperforms three baseline gene expression programming methods and six baseline machine learning methods.},
  archive      = {J_ASOC},
  author       = {Qiang Lu and Qiuchen Yuan and Dawei Li and Congwen Xu and Jake Luo and Zhiguang Wang},
  doi          = {10.1016/j.asoc.2025.113718},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113718},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Embedding neural sampling and adversarial bandit into gene expression programming for symbolic regression},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based analysis of problem space and genetic programming classifier performance using optimal transport dataset distance. <em>ASOC</em>, <em>184</em>, 113716. (<a href='https://doi.org/10.1016/j.asoc.2025.113716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding and interpreting machine learning tasks is a non-trivial endeavor. To this end, many works have proposed creative ways to organize and visualize a problem dataset, the learning process itself, or the models produced after learning has occurred. Moreover, as the scope of machine learning increases, the re-purposing or specialization of models becomes more common, or as continued automation is sought for algorithm deployment, understanding sets of problems has also become relevant. The present work proposes a graph-based representation of a set of machine learning problems, a novel characterization of the relationships and structures that are present in such a set. While similar proposals have been made before, the proposed methodology employs a recent and unique metric between problem datasets, the Optimal Transport Dataset Distance, which allows for the computation of a mathematically rigorous distance matrix for problem sets. This allows for the construction of a graph-based representation, while previous works relied on representations based on problem meta-features that were defined heuristically. Results show that the resulting graph representation of a problem set exhibits structural properties that are related to empirical indicators of problem difficulty, such as the average error, the size of the dataset, and the class imbalance. A similar analysis using meta-features shows that the structure of the resulting graphs cannot capture the same nuanced relationships between problems.},
  archive      = {J_ASOC},
  author       = {Joel Lee Nation and Daniel Fajardo and Yuliana Martínez and Arnoldo Díaz-Ramírez and Leonardo Trujillo},
  doi          = {10.1016/j.asoc.2025.113716},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113716},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph-based analysis of problem space and genetic programming classifier performance using optimal transport dataset distance},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based deep reinforcement learning for dynamic scheduling of flexible job-shop considering worker fatigue and multi-skill factors. <em>ASOC</em>, <em>184</em>, 113712. (<a href='https://doi.org/10.1016/j.asoc.2025.113712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the dynamic scheduling problem of flexible job shops (DFJSP) has garnered significant attention. However, most DFJSP studies focus solely on machine constraints, often overlooking the crucial factor of worker constraints. As an essential resource within the production process, the efficient utilization of workers can substantially enhance production efficiency. Consequently, the scheduling problem in dual-resource constrained (DRC) production systems, where operation times fluctuate according to worker skill levels and fatigue, is investigated. Considering new job arrivals as dynamic events, this study comprehensively integrates worker skill and fatigue factors, with the goal of minimizing total cost and makespan by developing a dual-resource constrained dynamic flexible job-shop scheduling (DRC-DFJSP) optimization model. To enable real-time model resolution in dynamic environments, an end-to-end deep reinforcement learning (DRL) scheduling method is introduced. The decision-making process is formulated as a Markov decision process (MDP) and guided by a reward mechanism tailored to optimization objectives. An enhanced proximal policy optimization (PPO) algorithm, combined with an adaptive clipping mechanism and a prioritized experience replay buffer, is applied to handle operation ordering, machine assignment, and worker allocation within the DRC-DFJSP framework. To further enhance decision-making capabilities, an attention-based graph neural network feature extraction method is incorporated to capture the intricate connections between operations, machines, and workers, resulting in a more precise characterization of the workshop state. Numerical experiments and case studies demonstrate that the proposed scheduling method surpasses existing strategies in dynamic environments that account for worker skill and fatigue levels.},
  archive      = {J_ASOC},
  author       = {Yiwen Hu and Zequn Zhang and Jie Chen and Dunbing Tang and Qixiang Cai},
  doi          = {10.1016/j.asoc.2025.113712},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113712},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph-based deep reinforcement learning for dynamic scheduling of flexible job-shop considering worker fatigue and multi-skill factors},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Command and control network architecture optimization method based on dual-layer weighting and TOPSIS-GRA of indicators. <em>ASOC</em>, <em>184</em>, 113711. (<a href='https://doi.org/10.1016/j.asoc.2025.113711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern warfare, the effectiveness of command and control (C2) networks plays a pivotal role in shaping operational performance and determining combat outcomes. Even under identical resource allocations, variations in command strategies and network architectures can lead to vastly different results. While many existing optimization methods rely on complex network theory to enhance system robustness, they often exhibit randomness and overlook commanders’ intent and expert knowledge during architecture design. Unlike civilian networks, military C2 networks are highly dependent on operational planning and domain expertise, emphasizing decision transparency and interpretability. Subjective evaluation methods-such as those based on rules or expert logic-are more intuitive for commanders but suffer from bias and inconsistency. Conversely, purely data-driven models like deep learning lack transparency, limiting their practical utility in high-stakes scenarios. To bridge this gap, this study proposes a dual-layer weighting optimization approach based on the TOPSIS and Grey Relational Analysis (GRA) methods. First, C2 network architectures are constructed using complex network theory. Then, an evaluation index system is developed around four key metrics: invulnerability, communication efficiency, connectivity, and network density. Subjective weights are derived via the Analytic Hierarchy Process (AHP), while objective weights are calculated using an improved entropy method. These are integrated into a variable-weight model to obtain final weights for optimization. By combining TOPSIS and GRA, the method accounts for both subjective preferences and objective measurements, ensuring a balanced evaluation. Simulation results demonstrate that the proposed method comprehensively considers both subjective and objective factors as well as the impact of state changes on weight adjustments, aligning more closely with real battlefield environments. The constructed C2 network architecture can adapt to different combat missions, guided by subjective evaluations of commander intent and expert experience while being refined through objective assessments to achieve adaptive adjustments. The ranking results account for both the distance and shape variations among indicators. Statistical analysis and comparisons with other methods further validate the effectiveness of the proposed approach, which also reduces computation time by a factor of five compared to alternative algorithms, highlighting its superiority.},
  archive      = {J_ASOC},
  author       = {Jianwei Wang and Qing Zhang and Chengsheng Pan},
  doi          = {10.1016/j.asoc.2025.113711},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113711},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Command and control network architecture optimization method based on dual-layer weighting and TOPSIS-GRA of indicators},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A distributed learning framework with blockchain and privacy-preserving for IoV. <em>ASOC</em>, <em>184</em>, 113710. (<a href='https://doi.org/10.1016/j.asoc.2025.113710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Vehicles (IoV), as a critical component of the Internet of Things (IoT), constructs a distributed system comprising vehicles, roadside units (RSUs), and cloud servers. In the IoV environment, the secure sharing of data and the protection of privacy are of paramount importance, as they directly impact the decision-making processes of intelligent vehicles and overall road safety. Given the openness of IoV, it faces risks of privacy leakage and poisoning attacks during data exchange and model training, which threaten the integrity and reliability of the data. To address these challenges, this study proposes a privacy protection framework that integrates blockchain technology and differential privacy. This framework incorporates dual differential privacy techniques within federated learning to enhance data privacy protection and designs a dynamic gradient aggregation mechanism to defend against data poisoning attacks, thereby ensuring the security of the data. Experimental results demonstrate that this framework maintains high model accuracy even under attack rates of up to 30%, exhibiting remarkable resilience against such attacks. Overall, this study emphasizes the significance of data security and privacy protection in the IoV domain and illustrates the potential of blockchain and differential privacy technologies in enhancing the security of IoV data and safeguarding user privacy. This research provides robust support for the sustainable development of IoV.},
  archive      = {J_ASOC},
  author       = {Chunhai Li and Yan Long and Yong Ding and Changsong Yang and Chuan Zhang and Meng Shen and Liehuang Zhu},
  doi          = {10.1016/j.asoc.2025.113710},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113710},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A distributed learning framework with blockchain and privacy-preserving for IoV},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chaotic vortex nanoparticle swarms (CVNPS): Formation and stability analysis. <em>ASOC</em>, <em>184</em>, 113708. (<a href='https://doi.org/10.1016/j.asoc.2025.113708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vortex Nanoparticle Swarms (VNPS) are a class of self-organizing systems that exhibit vortex-like collective behavior but often suffer from dynamic instability and poor angular momentum conservation. While VNPS may achieve partial spatial stability, coherent motion is typically unsustained. To address this, the Chaotic Vortex Nanoparticle Swarm (CVNPS) model is proposed, incorporating chaotic perturbations via logistic maps within a discrete particle model governed by the Generalized Morse Potential. This integration enhances system stability by accelerating convergence, reducing energy fluctuations, and promoting sustained vortex formation. Comparative analysis using key performance indicators – average nearest neighbor distance, polarization, angular momentum, swarm diameter, total energy, energy dissipation rate, and variance – demonstrates that CVNPS significantly outperforms traditional VNPS. It achieves faster stabilization and maintains coherent structure over time, even under varied initial conditions. By addressing both configurational and dynamical stability, CVNPS establishes a foundation for more reliable nanoparticle swarm applications in nanotechnology.},
  archive      = {J_ASOC},
  author       = {Mahvish Khurshid Bijli and Prabal Verma and Amrit Pal Singh},
  doi          = {10.1016/j.asoc.2025.113708},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113708},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Chaotic vortex nanoparticle swarms (CVNPS): Formation and stability analysis},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect-based context iterative network with hyperbolic tangent function for aspect-based sentiment classification. <em>ASOC</em>, <em>184</em>, 113707. (<a href='https://doi.org/10.1016/j.asoc.2025.113707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of natural language processing, sentiment analysis emerges as a pivotal undertaking. Especially, aspect-based sentiment classification has garnered significant attention in recent years, as it can identify and evaluate emotions related to specific aspects within sentences. Existing approaches typically achieve satisfactory results by extracting keyword information from the context to identify polarity. However, a common challenge faced by these methods is the inclusion of irrelevant words in the extracted keywords, leading to decreased classification accuracy. To tackle this issue, we propose an aspect-based context multiple iteration approach, which leverages the correlation between aspects and context and employs the multi-head attention mechanism to iteratively extract contextual keywords. By doing so, we aim to mitigate the interference of irrelevant words and enhance the accuracy of sentiment classification. Additionally, we address the peculiarities of hard samples by introducing a novel loss function that cleverly incorporates the hyperbolic tangent function and allows for improved model accuracy. To validate the effectiveness of our proposed approach, we conduct extensive experiments on four widely datasets and demonstrate the efficacy of our model in improving sentiment classification.},
  archive      = {J_ASOC},
  author       = {Chao Zhu and Benshun Yi and Laigan Luo},
  doi          = {10.1016/j.asoc.2025.113707},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113707},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Aspect-based context iterative network with hyperbolic tangent function for aspect-based sentiment classification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOGA: Multi-objective genetic algorithm to select stacking ensemble learning for classification. <em>ASOC</em>, <em>184</em>, 113706. (<a href='https://doi.org/10.1016/j.asoc.2025.113706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stacking Ensemble Learning (SEL) has been effectively integrated with Multi-Objective Optimisation (MOO) heuristics for classification tasks across various domains, including finance, healthcare, and cybersecurity. This study aims to address the challenge of generalising SEL to a diverse set of classification cases. Thus, the Multi-Objective Genetic Algorithm (MOGA) framework is proposed, utilising a Genetic Algorithm (GA) to evolve a population of distinct SELs, each built from a varied subset of base models. The goal is to select the subset that composes the most effective SEL for a given classification task. MOGA is designed with two main objectives—maximising p r e c i s i o n and r e c a l l —which helps to maintain independence from any specific classification case. In addition, incorporating models of varied types ensures adaptability and high performance in different situations. Comprehensive experimentation was conducted on 23 diverse datasets, where MOGA demonstrated high performance in nearly all datasets, outperforming other ensemble learning (EL) methods in 100% of the datasets in p r e c i s i o n , 78% in r e c a l l , 69.5% in f 1 − s c o r e , and 78% in a c c u r a c y . A t-test analysis yielded results of p -value < 0 . 05 , indicating a statistically significant improvement in the a c c u r a c y of the MOGA over the base models. Moreover, the framework’s application can be extended to regression tasks as well.},
  archive      = {J_ASOC},
  author       = {Abdellah Rezoug and Mohamed Bader-el-den},
  doi          = {10.1016/j.asoc.2025.113706},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113706},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MOGA: Multi-objective genetic algorithm to select stacking ensemble learning for classification},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning with evolutionary algorithm-guided imitation for capacitated vehicle routing problems. <em>ASOC</em>, <em>184</em>, 113705. (<a href='https://doi.org/10.1016/j.asoc.2025.113705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacitated vehicle routing problem (CVRP) is a complex combinatorial optimization challenge that seeks to determine cost-effective routes for customer deliveries while adhering to specific capacity constraints. Although deep reinforcement learning (DRL) has shown promise in addressing CVRP, it often encounters issues such as slow convergence and suboptimal accuracy. This study introduces an innovative approach that enhances both convergence efficiency and solution quality by integrating DRL with imitation learning (IL), utilizing an evolutionary algorithm (EA) as an expert. The proposed methodology incorporates an attention mechanism-based neural network to effectively capture the intricate features of CVRP. It leverages IL to use EA-generated solutions as expert demonstrations, thereby guiding the DRL model toward a more efficient exploration of the solution space. The REINFORCE algorithm with baseline is employed to ensure stable and rapid training of the DRL model. Experimental results indicate that this hybrid approach significantly outperforms widely adopted baseline methods and approaches the performance levels of advanced algorithms like LKH3. Furthermore, the method demonstrates robust generalization capabilities across various CVRP instances, underscoring its potential for practical applications in diverse routing scenarios. This research contributes to the field by demonstrating how integrating EA as experts within an IL framework can effectively enhance DRL for solving CVRP.},
  archive      = {J_ASOC},
  author       = {Wenqiang Zhang and Xiaomeng Wang and Yashuan Mu and Miaolei Deng and Peng Li},
  doi          = {10.1016/j.asoc.2025.113705},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113705},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep reinforcement learning with evolutionary algorithm-guided imitation for capacitated vehicle routing problems},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A focal quotient gradient system method for deep neural network training. <em>ASOC</em>, <em>184</em>, 113704. (<a href='https://doi.org/10.1016/j.asoc.2025.113704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel approach for training deep neural networks, leveraging a mini-batch focal quotient gradient system (QGS-Focal). The proposed method addresses critical challenges in imbalanced datasets and optimization efficiency. By introducing residual constraints into the loss function, we construct a quotient gradient system that effectively mitigates model overfitting and gradient vanishing problems. By incorporating a focal loss mechanism, it innovatively solves data imbalance issues at the algorithmic level. The adoption of a mini-batch strategy and limited memory method significantly reduces computational costs. Our comprehensive experiments on imbalanced CIFAR-10 and CIFAR-100 have demonstrated the superiority of QGS-Focal, achieving 83.4 % precision, 83.6 % recall, and 82.9 % F1-score on CIFAR-10, significantly outperforming SGD, Adam, and QGS. Moreover, our approach reduces training time by 13.3 %, enhancing computational efficiency while maintaining superior classification performance. The t-SNE visualization further confirms that QGS-Focal has superior convergence properties compared to traditional optimization approaches.},
  archive      = {J_ASOC},
  author       = {Caili Lv and Xian-long Lv and Zhiyuan Wang and Tianqi Zhao and Wei Tian and Qingqing Zhou and Lin Zeng and Min Wan and Chenghu Liu},
  doi          = {10.1016/j.asoc.2025.113704},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113704},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A focal quotient gradient system method for deep neural network training},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial differential equations and machine learning integration for transit-oriented development. <em>ASOC</em>, <em>184</em>, 113703. (<a href='https://doi.org/10.1016/j.asoc.2025.113703'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate classification of rail transit stations is critical for advancing Transit-Oriented Development (TOD) and promoting sustainable urban growth. This research presents a novel hybrid framework that integrates Partial Differential Equations (PDEs) with Machine Learning (ML) techniques for the classification of rail transit stations. Unlike conventional TOD models, this study applies the heat equation to the Node, Place, Ridership-Time (NPRT) framework, offering a mathematically grounded approach to capture spatial-temporal dynamics in transit systems. This integration represents the first known application of PDE-based physical modeling combined with supervised learning for classifying transit stations within a TOD framework. This approach significantly enhances the model’s interpretability while maintaining competitive prediction accuracy. Through extensive case studies and empirical validation, the PDE-NPRT model demonstrates strong performance, with Mean Squared Error (MSE) values ranging from 0.0075 to 0.0222. Although slightly outperformed by enhanced ML models—such as K-Nearest Neighbors (KNN), Deep KNN (DKNN), and Deep Distributed Neural Networks (DDNN)—which achieve MSEs as low as 0.0034, the PDE-NPRT model offers a more interpretable and theoretically robust alternative. Additionally, the study introduces a multi-layer modeling strategy that combines regression analysis, clustering algorithms, PDEs, and neural networks, further enriching the understanding of ridership patterns and congestion mechanisms. Clustering outcomes are validated through external indices, confirming the alignment of model predictions with real-world site characteristics. This work represents a significant advancement in TOD modeling, offering a robust and explainable tool for urban planners and decision-makers. By bridging advanced mathematical modeling with machine learning, it paves the way for more intelligent, data-driven, and sustainable urban mobility strategies.},
  archive      = {J_ASOC},
  author       = {Ahad Amini Pishro and Shiquan Zhang and Alain L’Hostis and Qixiao Hu and Yuetong Liu and Zhengrui Zhang and Van Duc Nguyen and Yongguo Fu and Tianzeng Li},
  doi          = {10.1016/j.asoc.2025.113703},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113703},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Partial differential equations and machine learning integration for transit-oriented development},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic SLAM algorithm based on improved YOLOv9S. <em>ASOC</em>, <em>184</em>, 113700. (<a href='https://doi.org/10.1016/j.asoc.2025.113700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the limitations of conventional visual SLAM algorithms and the time-intensive process of semantic segmentation in dynamic environments, this paper proposes a SLAM algorithm that incorporates an enhanced version of YOLOv9S specifically designed for dynamic scenes. The ECASPPELAN and DRepNCSPELAN4 modules have been developed to improve the model’s detection capabilities in dynamic scenes. Secondly, the improved YOLOv9S is integrated into the ORB-SLAM2 framework, which employs bipolar geometry to reject dynamic targets and utilizes a depth separation algorithm to prevent the erroneous rejection of static features. Subsequently, the detection performance of the model was evaluated on the PASCAL VOC dataset, resulting in a 2% improvement in mAP_0.5 and a 1.3% improvement in mAP_0.5:0.95. The tracking performance of the system is examined in the TUM dynamic dataset, where the absolute trajectory root mean square error (RMSE) is reduced by 97.5%, and the relative rotational RMSE is reduced by 92.9% in comparison to ORB-SLAM2 in the high-dynamics scenario. Additionally, the average running rate surpasses 30 Hz while constructing high-quality dense maps in real indoor dynamic environments. This allows the robot to receive more detailed texture information. The experimental results demonstrate that the enhanced algorithm presented in this paper exhibits enhanced accuracy and resilience in dynamic scenarios.},
  archive      = {J_ASOC},
  author       = {Qiguang Zhu and Yuchao Zhao and Haofeng Zhang and Weidong Chen},
  doi          = {10.1016/j.asoc.2025.113700},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113700},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A dynamic SLAM algorithm based on improved YOLOv9S},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural semantic evaluation of blockchain policy tools in china. <em>ASOC</em>, <em>184</em>, 113699. (<a href='https://doi.org/10.1016/j.asoc.2025.113699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To explore the differences in policies guiding the development of the blockchain industry in different regions of mainland China, in this study, we developed a compound neural network model comprising bidirectional long short term memory and deep biaffine attention models that analyses the semantic texts of blockchain policies issued by 31 provinces in mainland China. Machine learning models — specifically, term frequency–inverse document frequency and K-means models are used to implement feature selection of the policy text matrix classification after semantic analysis. Finally, this study proposes an innovative policy tools matching approach. We construct a word-topological map for each text category based on semantic relationships. To validate the effectiveness of these tools, we conduct an empirical analysis using a multivariate linear regression model. The results demonstrate that blockchain policy tools significantly promote blockchain innovation in Mainland China.},
  archive      = {J_ASOC},
  author       = {Yuxi Zhang and Haifeng Guo and Ke Peng and Hongzhi Wang},
  doi          = {10.1016/j.asoc.2025.113699},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113699},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Neural semantic evaluation of blockchain policy tools in china},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable nature-inspired optimization via virtual and actual multi-objective strategies to establish a smart earthquake early warning system. <em>ASOC</em>, <em>184</em>, 113698. (<a href='https://doi.org/10.1016/j.asoc.2025.113698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geosynthetic-reinforced soil (GRS) structures are considered for reducing displacement and providing economical reinforcement solutions. The risk assessment of these structures against earthquakes, based on the prediction of seismic sliding displacement, is a major challenge in this field. Multi-objective optimization is a powerful machine learning tool for selecting efficient features for high-performance forecasting. This research investigates two strategies based on swarm intelligence and genetic programming for a comprehensive evaluation. These frameworks integrate multiobjective optimization algorithms and Newmark methods for utilizing effective physics-informed features. The first strategy is virtual multi-objective (VMO) optimization by applying particle swarm optimization (PSO) based on minimizing one function via variations of other functions. In this approach, the error function, as a computational error object, is minimized versus the nomination of interpretable feature space as a computational cost object through the virtual Pareto front. The second strategy is actual multi-objective (AMO) optimization by exploiting nondominated sorting genetic algorithm II (NSGA-II) based on minimizing several functions simultaneously with two various approaches, including bi-objective and many-objective algorithms through actual Pareto-optimal solutions. In this approach, the computational error value, computational cost value, and computational time value are minimized at the same time. The main novelty of the first technique is low computational complexity, resulting in high speed due to definite search space dimension-based exploration and exploitation to forecast seismic sliding displacement, whereas the major achievement of the second technique is high computational accuracy due to multiobjective structure-assisted exploitation and exploitation. Through numerical validation by employing the Newmark methods, the resultant model predicts the seismic sliding displacement of these structures using two algorithms efficiently. Nevertheless, both strategies have good performance for intelligent forecasting. The actual many-objective optimization algorithm is a more effective switchable machine learning tool based on the proposed adaptable performance index for developing a smart earthquake early warning software that can precisely detect imminent natural hazards.},
  archive      = {J_ASOC},
  author       = {Milad Zarchi and Reza A. Nazari and Kong Fah Tee},
  doi          = {10.1016/j.asoc.2025.113698},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113698},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Explainable nature-inspired optimization via virtual and actual multi-objective strategies to establish a smart earthquake early warning system},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DTKD-DL: Dual-teacher knowledge distillation with dual-loops for continuous few-shot relation extraction. <em>ASOC</em>, <em>184</em>, 113696. (<a href='https://doi.org/10.1016/j.asoc.2025.113696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new model named DTKD-DL, designed to address the issue of Continuous Few-Shot Relation Extraction (CFRE) across tasks, with the goal of learning and adapting to newly emerging relations while reducing catastrophic forgetting. In this paper, we have designed a dual-teacher knowledge distillation model based on relation information to enrich knowledge representation and retain prior knowledge. We employ a dual-loops distillation approach, which facilitates knowledge transfer and optimizes the direction of parameter updates, thereby reducing the occurrence of catastrophic forgetting. Furthermore, to avoid overfitting issues caused by multiple rounds of distillation, we have innovatively integrated reinforcement learning with the model. We have validated our model on the FewRel and TACRED datasets and compared it with the large language model Llama3-8b, demonstrating the effectiveness of our model in this scenario and its advantages over the most advanced methods, achieving state-of-the-art results.},
  archive      = {J_ASOC},
  author       = {Ruifeng Xu and Yi Chen and Zhongyan Yi and Shun Huang and Liang He},
  doi          = {10.1016/j.asoc.2025.113696},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113696},
  shortjournal = {Appl. Soft. Comput.},
  title        = {DTKD-DL: Dual-teacher knowledge distillation with dual-loops for continuous few-shot relation extraction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage feature selection approach with fuzzy covering-based rough sets based on discernibility matrix. <em>ASOC</em>, <em>184</em>, 113695. (<a href='https://doi.org/10.1016/j.asoc.2025.113695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy β -covering has attracted considerable research attention due to its enhanced capability to accurately and comprehensively represent uncertain information. Unlike partition-based approaches, fuzzy β -covering maintains its covering properties when augmented with additional elements. This inherent flexibility necessitates rigorous redundancy analysis. Hence, the calculation of the reduct of fuzzy β -covering relative to decision attribute constitutes a fundamental challenge in this context. To address this issue, we formally define the concepts of indispensable covering elements and core of fuzzy β -covering with respect to the decision attribute. Then, to facilitate efficient computation of core and reduct, we introduce the discernibility matrix for fuzzy β -covering and establish equivalent representations of the core and reduct. Furthermore, we conduct systematic examinations to verify the indispensability of some existing concepts in fuzzy β -covering. Meanwhile, a significant limitation of current feature selection methods useing fuzzy β -covering lies in their computational complexity, primarily due to repeated recalculation of dependency functions during iterations. To overcome this limitation, we propose an efficient feature selection algorithm that identifies all reducts directly through the discernibility matrix. Furthermore, we propose a two-stage feature selection method for fuzzy β -covering, which iteratively eliminates redundant features to identify optimal feature subsets in each iteration. Finally, we verify through time complexity analysis and numerical experiments that the proposed algorithm significantly outperforms existing feature selection algorithms in computational efficiency. Comparative analysis further reveals that our method achieves superior results in terms of selected feature subset sizes and classification accuracy.},
  archive      = {J_ASOC},
  author       = {Tianyu Wang and Shuai Liu and Bin Yang},
  doi          = {10.1016/j.asoc.2025.113695},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113695},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-stage feature selection approach with fuzzy covering-based rough sets based on discernibility matrix},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-source remote sensing image watermarking model based on multi-domain generative adversarial networks. <em>ASOC</em>, <em>184</em>, 113694. (<a href='https://doi.org/10.1016/j.asoc.2025.113694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the heterogeneity stemming from distinct sensor types, quantized spatial resolution levels, and categorized acquisition angles within multi-source remote sensing images, their data distribution and characteristics vary significantly, leading to poor cross-domain consistency and weak resistance to domain-specific distortions in traditional watermarking approaches. Traditional watermarking methods often struggle to handle such heterogeneous datasets. To address this challenge, this paper presents a watermarking model based on a multi-domain generative adversarial network (MD-GAN). By incorporating a multi-domain adversarial training mechanism and designing multiple domain discriminators, the generator is optimized to work across various image domains, thereby enhancing model robustness. Additionally, a multi-scale generator is utilized to account for differences in spatial resolution, improving both the watermark’s concealment and extraction accuracy. Experimental results demonstrate that the MD-GAN model achieves a 7 % improvement in robustness over the state-of-the-art models in terms of resistance to noise attacks and geometric transformations. Ablation studies confirm that the multi-domain adversarial training mechanism and multi-scale generator contribute significantly to this enhancement. MD-GAN provides a powerful solution for the copyright protection of multi-source remote sensing images, with substantial potential for real-world applications such as secure transactions and data sharing.},
  archive      = {J_ASOC},
  author       = {Heyan Wang and Xingxiang Jiang and Minxuan Wang and Changqing Zhu and Na Ren and Luanyun Hu},
  doi          = {10.1016/j.asoc.2025.113694},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113694},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-source remote sensing image watermarking model based on multi-domain generative adversarial networks},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale convolution-attention model for efficient alzheimer’s disease and mild cognitive impairment diagnosis approach using sMRI. <em>ASOC</em>, <em>184</em>, 113693. (<a href='https://doi.org/10.1016/j.asoc.2025.113693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer's disease (AD) affects over 50 million people worldwide and causes a gradual decline in memory, language, and actions, with no known cure. Early identification and treatment are crucial to improve the quality of life of affected individuals. Deep learning algorithms based on brain structural magnetic resonance imaging (sMRI) show promise in predicting AD. However, relying solely on deep convolutional neural network (CNN) architecture has limitations in global modeling. Transformer, which is a feature learning technique, has excelled in computer vision applications, sparking interest in its application in brain image processing. However, pure Transformer architectures encounter challenges when trained on small sMRI datasets. Meanwhile, CNN-based methods do not consider the interdependence between voxels, which hinders the comprehensive understanding of the global characteristics of sMRI data. To address these challenges, an effecient deep learning framework was developed that combines the benefits of both the CNN and Transformer. In the preliminary phase of feature extraction, we introduce a multiscale feature fusion stem that employs convolutional kernels of varying scales to derive low-level features from the sMRI and integrate them to enhance the recognition accuracy. Furthermore, the proposed method introduces convolutional split attention with a squeeze and excitation block and additional convolution operations in the core sections of the Transformer, thereby enabling multiscale feature extraction and fusion. The model integrates multi-head light self-attention and a sandglass local feed-forward network block for classifier modeling, enhancing the extraction of sMRI features with a MobileNet cost. The proposed model, which was tested on the Alzheimer's Disease Neuroimaging Initiative dataset, achieved superior performance in AD diagnosis with fewer parameters and reduced computational costs, demonstrating its potential as a state-of-the-art solution.},
  archive      = {J_ASOC},
  author       = {Uttam Khatri and Jun-Hyung Kim and Goo-Rak Kwon},
  doi          = {10.1016/j.asoc.2025.113693},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113693},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiscale convolution-attention model for efficient alzheimer’s disease and mild cognitive impairment diagnosis approach using sMRI},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). F2CAU-net: A dual fuzzy medical image segmentation cascade method based on fuzzy feature learning. <em>ASOC</em>, <em>184</em>, 113692. (<a href='https://doi.org/10.1016/j.asoc.2025.113692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate medical image segmentation plays a pivotal role in clinical diagnosis and treatment planning. However, existing methods – particularly those based on U-Net architectures – still face considerable difficulties when dealing with ambiguous boundaries, low-contrast regions, and noise artifacts. These challenges arise from the deterministic nature of conventional convolutional and attention mechanisms, which are often inadequate in modeling the inherent uncertainty and variability present in medical images. To tackle these limitations, we propose F 2 CAU-Net, a Dual Fuzzy Medical Image Segmentation Cascade Method that integrates a fuzzy convolution module for better modeling of uncertain and imprecise features, and a fuzzy attention mechanism to suppress redundancy and enhance focus on regions of interest. The proposed method captures both local and global contextual fuzzy information to improve segmentation accuracy and robustness. Extensive experiments on multiple benchmark datasets – including COVID-19 lesions, brain tumors, and skin cancer – demonstrate that F 2 CAU-Net significantly outperforms existing state-of-the-art models, particularly in scenarios with complex boundaries and noise. This approach offers promising potential for clinical applications, providing a more reliable and uncertainty-aware solution for medical image analysis.},
  archive      = {J_ASOC},
  author       = {Tianyi Zhou and Haipeng Wang and Sheng Geng and Hengrong Ju and Jiashuang Huang and Fan Fu and Weiping Ding},
  doi          = {10.1016/j.asoc.2025.113692},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113692},
  shortjournal = {Appl. Soft. Comput.},
  title        = {F2CAU-net: A dual fuzzy medical image segmentation cascade method based on fuzzy feature learning},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics-informed mitigation method for DC microgrids under cyber attacks. <em>ASOC</em>, <em>184</em>, 113691. (<a href='https://doi.org/10.1016/j.asoc.2025.113691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber attacks pose serious threats to DC microgrids, making effective mitigation strategies very critical. However, most existing mitigation schemes ignore the physical characteristics of microgrids, which may lead to inaccurate attack detection and affect the mitigation performance. To address this issue, a physics-informed mitigation method for cyber attacks on DC microgrids is proposed. A cyber–physical framework of the DC microgrid is established, and the impact of cyber attacks on the microgrid is analyzed. The denoising autoencoder is utilized to improve the quality of the input data, and then the consistency characteristic of the DC microgrid is incorporated as a physical-informed constraint into the training of the state estimation model. Subsequently, anomaly detection is performed by comparing the estimated state and the real-time measured state. Once the attacks are detected, the estimated state is used to compensate the control inputs, mitigating the effect of attacks and ensuring the safe and stable operation of the DC microgrid. Simulation results show that compared with existing neural network-based estimators, the proposed physics-informed state estimation model can enhance the accuracy by 7 . 98 % ∼ 12 . 54 % , providing more precise estimated states to mitigate the effects of attacks.},
  archive      = {J_ASOC},
  author       = {Wanwan Ren and Jun Peng and Yun Zhou and Weirong Liu and Fu Jiang},
  doi          = {10.1016/j.asoc.2025.113691},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113691},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A physics-informed mitigation method for DC microgrids under cyber attacks},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Acquisition of representative data sets by filtering out redundant objects and attributes with fuzzy preference-based rough sets and dominance principles. <em>ASOC</em>, <em>184</em>, 113690. (<a href='https://doi.org/10.1016/j.asoc.2025.113690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dominance principle is crucial for evaluating consistency in dominance-based rough sets, yet redundant objects or attributes impair decision consistency. While existing work focuses on modeling and attribute reduction, object-induced inconsistency remains understudied. This study proposes a novel methodology for acquiring compact datasets through representative object extraction and attribute reduction in fuzzy preference-based rough sets, with a specific focus on preserving consistency in dominance principles. Firstly, the extent of dominance relations is quantified by fuzzy preference relations, while the evaluation of consistency between conditional and decision attributes is accomplished through distance measures. Subsequently, representative objects are identified by eliminating those with lower consistency in dominance principles, as assessed by distance measures with a predefined parameter. Further, a streamlined dataset is achieved through attribute reductions in fuzzy preference-based rough sets, incorporating representative objects. In conclusion, our proposed method is validated using numerical datasets, and its effectiveness is evaluated through measures rooted in rough set theory, machine learning, and statistics. This research contributes to a more comprehensive understanding of dominance-based rough sets by addressing the often-overlooked issue of inconsistency resulting from redundant objects.},
  archive      = {J_ASOC},
  author       = {Shuyun Yang and Guang Shi and Yuchao Li},
  doi          = {10.1016/j.asoc.2025.113690},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113690},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Acquisition of representative data sets by filtering out redundant objects and attributes with fuzzy preference-based rough sets and dominance principles},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spiking neural network with time-varying weights for rail squat detection. <em>ASOC</em>, <em>184</em>, 113689. (<a href='https://doi.org/10.1016/j.asoc.2025.113689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Axle box acceleration (ABA) measurements can be used for continuously monitoring rail infrastructure and detecting rail surface defects such as squats. However, accurately detecting squats is challenging due to their short-duration responses and low occurrence in ABA signals, particularly for light squats that exhibit subtle ABA responses. To address this challenge, we propose using a spiking neural network (SNN) with time-varying weights to enhance the detection performance of rail squats based on ABA measurements. Our approach employs a simple SNN architecture without hidden layers, trained using a method that combines genetic algorithms, k-fold cross-validation, and multi-start gradient-based approach to optimise hyperparameters and weights. The proposed methodology demonstrates competitive accuracy compared to other state-of-the-art SNN-based methods on UCI benchmarks for both binary and multi-class nonlinear problems. Part of its advantages include higher efficiency with a simpler architecture and training approach that reduces computational times while achieving effective spatiotemporal pattern detection. As shown by real-field measurements from Dutch and Swedish railways in anomaly detection, it effectively captures subtle changes in light squat defect responses in ABA signals and achieves a detection performance of 100% for severe squat defects and over 93% for light squat defects. Furthermore, we show that the spike responses, postsynaptic potentials, and membrane potentials can be used as a new way to explain and analyse the ABA signals. The proposed method using time-varying weights highlights a correspondence with the physical problem and offers an ability to capture sudden and subtle changes in the responses, which is crucial, particularly for detecting defects in their early stages.},
  archive      = {J_ASOC},
  author       = {Wassamon Phusakulkajorn and Jurjen Hendriks and Zili Li and Alfredo Núñez},
  doi          = {10.1016/j.asoc.2025.113689},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113689},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Spiking neural network with time-varying weights for rail squat detection},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectral–spatial representation progressive learning via segmented attention for 3D skeleton-based motion prediction. <em>ASOC</em>, <em>184</em>, 113688. (<a href='https://doi.org/10.1016/j.asoc.2025.113688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, GCNs-based methods have demonstrated impressive performance in human behavior prediction tasks. We believe that human motion modeling can explained as motion correlation extraction from the combination of the active and static motion parts analysis. However, existing methodologies fail to address the issue that feature information associated with static regions may overshadow feature information from dynamic regions, ultimately affecting the extraction of network features. Moreover, the unique low-pass feature pre-retention processing mechanism of GCN on the spectrum will lead to the attitude of some sequences remaining unchanged during the prediction process and further hurt the prediction. In this paper, we propose a Spectral–Spatial Representation Progressive Learning network to solve the problem above. Firstly, we propose a segmented attention block to compare the input observation sequence with the static contrast standard to obtain the motion region and the rest region. Then, we design the Spectrum Deconstruction Recombination Factor block(SDRF) to extract the global bandpass spectrum of human bone joints. The joint features of different regions are encoded by graph convolution and high-frequency feature filter coding based on geometric algebra. Specifically, a spectral–spatial interaction block is presented in each SDRF, focusing on the diversity of motion sequence frequency domain and spatial domain map, and realizes the fine extraction of historical pose sequence features from the two levels of space and spectral domain. Experimental results demonstrate that our approach outperforms state-of-art algorithms by 2.4%, 5.3% and 4.7% in terms of 3D mean per joint position error on Human 3.6M, CMU Mocap and 3DPW datasets, respectively.},
  archive      = {J_ASOC},
  author       = {Wenming Cao and Jianhua Zhang and Jianqi Zhong},
  doi          = {10.1016/j.asoc.2025.113688},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113688},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Spectral–spatial representation progressive learning via segmented attention for 3D skeleton-based motion prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal multi-trip supply chain model aided by smart contract victim tracking — An innovative pathway to disaster management under uncertainty. <em>ASOC</em>, <em>184</em>, 113687. (<a href='https://doi.org/10.1016/j.asoc.2025.113687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the complex challenges of post-earthquake rescue operations, using the recent earthquake in Turkey as a reference case. It focuses on developing an optimized model for scenarios with acute vehicle shortages, aiming to minimize both operational costs and response time during the critical initial phase of disaster relief. The proposed solution is built upon a robust mathematical framework that employs aerial vehicles for post-disaster area assessment, resource allocation, and the relocation of critically injured victims. The model leverages a soft computing approach, integrating the Weighted Sum Method (WSM) and Neutrosophic Compromise Programming (NCP). To enhance decision-making under uncertainty, the framework incorporates hexagonal type-2 fuzzy defuzzification, a technique grounded in soft computing principles. Results demonstrate the effectiveness of this approach: the NCP method achieved a response time of 213 min (3.55 h) and a cost of Rs 821,026.5, compared to 217.5 min (3.62 h) and Rs 820,860.3 for the WSM method—both successfully coordinating the rescue of 1,450 victims through efficient deployment of drones and helicopters. In addition, the study introduces a decentralized Ethereum-based smart contract to securely store and retrieve critical victim information. Validated through rigorous unit testing, the contract ensures data transparency and integrity, executing at a cost of 0.00379246 Ether. This blockchain-enabled feature complements the core optimization model, supporting real-time, tamper-proof data handling. To further validate the model’s applicability, a second real-life numerical example based on the recent Sikkim cloudburst is analyzed. The findings reinforce the model’s adaptability and practical value. The managerial implications of this research highlight the importance of soft computing-driven decision support, proactive contingency planning, and the integration of intelligent technologies in disaster response. This holistic framework — combining soft computing methodologies, advanced optimization models, and blockchain technology — offers an innovative and scalable solution for enhancing the resilience and efficiency of disaster management supply chains.},
  archive      = {J_ASOC},
  author       = {Alisha Roushan and Amrit Das and Anirban Dutta and Uttam Kumar Bera},
  doi          = {10.1016/j.asoc.2025.113687},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113687},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-modal multi-trip supply chain model aided by smart contract victim tracking — An innovative pathway to disaster management under uncertainty},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning with hard negatives for sentence embeddings. <em>ASOC</em>, <em>184</em>, 113685. (<a href='https://doi.org/10.1016/j.asoc.2025.113685'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised sentence representation learning remains a core challenge in natural language processing. Recent contrastive learning methods have shown strong potential in capturing sentence-level semantics, but their effectiveness is often constrained by the quality of positive and negative samples. In particular, constructing informative hard negatives in textual data is significantly more difficult than in vision tasks due to the ambiguity and compositionality of natural language. We propose HNCSE, a novel unsupervised contrastive learning framework that enhances sentence representations through hard negative compositional strategies. HNCSE introduces two key components: HNCSE-HNM, which synthesizes informative hard negatives via mixup within the batch, and HNCSE-PM, which generates harder positives by leveraging the most challenging negatives. This joint design improves both alignment and discrimination in embedding space without relying on external supervision. Extensive experiments on semantic textual similarity and transfer tasks demonstrate that HNCSE consistently outperforms existing unsupervised and supervised baselines.},
  archive      = {J_ASOC},
  author       = {Wenxiao Liu and Zihong Yang and Chaozhuo Li and Zijin Hong and Jianfeng Ma and Zhiquan Liu and Litian Zhang and Feiran Huang},
  doi          = {10.1016/j.asoc.2025.113685},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113685},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Contrastive learning with hard negatives for sentence embeddings},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HumanMoD: A multi-RAG collaborative LLM for inclusive urban public healthcare services. <em>ASOC</em>, <em>184</em>, 113684. (<a href='https://doi.org/10.1016/j.asoc.2025.113684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Large Language Models (LLMs) with healthcare systems offers transformative solutions for sustainable public health programs, especially in underserved urban and rural communities where access to professional medical expertise is limited. This paper introduces HumanMoD, a novel LLM framework designed to emulate collaborative clinical workflows of multi-expert medical doctors. Specifically, the proposed Mixture of Doctors module enables parallel diagnostic streams from diverse medical specialties, mimicking the collaborative decision-making of human doctors to ensure comprehensive assessments in resource-constrained environments. The Knowledge-driven Medical Assistant leverages domain-specific knowledge bases to mitigate LLM hallucinations, ensuring that recommendations are rooted in credible medical knowledge. Exquisitely, the Humanoid Health Conductor and LLM-powered Corrector further refine outputs to minimize diagnostic discrepancies, enhancing the reliability of responses for large-scale public health applications such as community health kiosks and mobile health apps serving remote or low-income areas. Unlike fine-tuned models, HumanMoD operates without parameter adjustment, enabling cost-effective deployment in regions with scarce computational resources, thus bridging the healthcare gap for socially vulnerable groups. Experimental results on MedQA and PubMedQA demonstrate that HumanMoD outperforms state-of-the-art models, highlighting its potential to drive equitable healthcare access and support data-driven public health policies in diverse urban and rural settings.},
  archive      = {J_ASOC},
  author       = {Song Sun and Zhijie Zhong and Nanlan Yu and Xinrong Gong and Kaixiang Yang},
  doi          = {10.1016/j.asoc.2025.113684},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113684},
  shortjournal = {Appl. Soft. Comput.},
  title        = {HumanMoD: A multi-RAG collaborative LLM for inclusive urban public healthcare services},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A KPI-related fault diagnosis method for multimode manufacturing processes based on supervised minimal gated unit and sparse broad learning system. <em>ASOC</em>, <em>184</em>, 113679. (<a href='https://doi.org/10.1016/j.asoc.2025.113679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multimode manufacturing processes, the key performance indicator (KPI)-related fault diagnosis plays a critical role in ensuring product quality and enhancing economic benefits. However, variability in working modes, lack dynamic description for the KPIs, and model structure redundancy may lead to poor universality and low diagnostic accuracy of conventional deep learning-based approaches. In this work, a supervised minimal gated unit and sparse broad learning system (SMGU-SBLS) is developed for KPI-related fault diagnosis. Specifically, the KPIs and process variables are simultaneously utilized in the SMGU to learn the KPI-related dynamic features. Then, aiming at simplifying the network structure, a sparse version of broad learning system is proposed for fault diagnosis. Furthermore, the expansion capability of SMGU-SBLS has been analyzed. Finally, the proposed SMGU-SBLS network is applied to a real hot strip mill process (HSMP). Simulation results show that the proposed method has higher diagnostic performance than the other four state-of-the-art deep learning methods.},
  archive      = {J_ASOC},
  author       = {Chuanfang Zhang and Wenxiao Yin and Chi Zhang and Kaixiang Peng and Xueyi Zhang},
  doi          = {10.1016/j.asoc.2025.113679},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113679},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A KPI-related fault diagnosis method for multimode manufacturing processes based on supervised minimal gated unit and sparse broad learning system},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Green maritime transport performance analysis of G-7 countries using an interval-valued fermatean fuzzy ARLON-based decision model. <em>ASOC</em>, <em>184</em>, 113677. (<a href='https://doi.org/10.1016/j.asoc.2025.113677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maritime transport operations are witnessing heightened environmental sensitivities, prompting the implementation of environmentally focused maritime transport practices. The principal aim is to develop a decision support system for evaluating countries' green maritime transport performance. To this end, the interval-valued Fermatean fuzzy (IVFF)-simple weight calculation (SIWEC)-skewness impact through distributional evaluation (SITDE)-alternative ranking using two-step logarithmic normalization (ARLON) model is developed within this study. This method enables the analysis of countries' green maritime transport performance by integrating expert opinions with environmental and maritime transport parameters. The model determines the influence of experts using IVFF sets. It further facilitates the simultaneous use of subjective and objective criteria weighting approaches to compute the weights of green maritime transport performance criteria. ARLON is employed to assess and rank countries' green maritime transport performance levels. The applicability of the IVFF-SIWEC-SITDE-ARLON model is tested through a case study focusing on G-7 countries, and the results supported the successful implementation of the method. Furthermore, sensitivity and comparative analyses demonstrated the consistency and robustness of the model. According to the findings of the case study, the United States emerges as the country with the highest green maritime transport performance among the G-7 countries. The "linear shipping connectivity index" is identified as the most influential criterion in the decision-making process. The study offers actionable recommendations for the maritime industry, thereby contributing to the advancement of green maritime transport practices.},
  archive      = {J_ASOC},
  author       = {Galip Cihan Yalçın and Karahan Kara and Emre Kadir Özekenci and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2025.113677},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113677},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Green maritime transport performance analysis of G-7 countries using an interval-valued fermatean fuzzy ARLON-based decision model},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive self-correction network for human motion prediction. <em>ASOC</em>, <em>184</em>, 113676. (<a href='https://doi.org/10.1016/j.asoc.2025.113676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction aims to generate future poses from the observed historical human motion sequence. It is fundamental to many intelligent systems, e.g., human–robot interaction and self-driving. Though the existing encoder–decoder methods obtain good performance in some scenarios, there is still a gap between their prediction results and ground truth in many cases. In this work, we propose to estimate the deviation between the decoding results (which will be referred to as the conventional human motion prediction ) and the groundtruth, and integrate this estimation with the conventional prediction results to derive the corrected human motion prediction . In this way, our method can self-correct the conventional prediction results based on a preliminary estimated deviation from it to the groundtruth, and thus enhance the performance. In our work, we adopt five independent lightweight branches rather than a global estimator to estimate the deviation of the five human body components ( i.e., left arm, right arm, torso, left leg, and right leg). Based on this component-wise deviation estimation strategy, we propose a Fixed Self-Correction Network (FSCNet) for human motion prediction to obtain enhanced performance. Recognizing that not all joints exhibit the same motion dynamics inside one given body component, we further propose the Adaptive Self-Correction Network (ASCNet) to let these five estimators adaptively capture the correlated deviations and thus enhance human motion prediction performance. Extensive experiments on three large datasets (Human3.6M, CMU-Mocap, and 3DPW) validate the superiority of our proposed FSCNet and ASCNet over the established works.},
  archive      = {J_ASOC},
  author       = {Jinkai Li and Jinghua Wang and Xin Wang and Liang Yan and Xiaoling Luo and Yong Xu},
  doi          = {10.1016/j.asoc.2025.113676},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113676},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive self-correction network for human motion prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RGB-D indoor scene parsing via wavelet sub-band guided transformer. <em>ASOC</em>, <em>184</em>, 113675. (<a href='https://doi.org/10.1016/j.asoc.2025.113675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth information has been shown to be complementary to RGB scene parsing. However, inherent disparities between RGB and depth modalities create challenges for effective feature fusion. Furthermore, current methods often lose high-frequency information during downsampling, limiting the full utilization of RGB and depth image information. To address these issues, we propose the Wavelet Sub-band Guided Transformer (WSGFormer), which utilizes wavelet sub-band to enhance feature correction, fusion, and refinement. The WSGFormer contains three important modules. Firstly, the Wavelet Cross-attention Rectification Module employs Haar wavelet transforms to decompose features into wavelet sub-band, and adaptively aligns RGB and depth features by extracting their mapping relationships. Secondly, the Multi-scale Fusion Module combines RGB and depth branches, utilizing vertical bar-shaped convolutions to enable cross-modal feature selection and enhance the sensitivity to high-frequency components through frequency-aware techniques. Finally, the Discrepancy Compensation Module starts with high-level semantic information and progressively guides the fusion of adjacent layers downwards, reducing disparities between them through subtraction operations. The evaluation conducted on the NYUv2, SUN-RGBD and ScanNetV2 datasets highlights the superior performance of the proposed WSGFormer.},
  archive      = {J_ASOC},
  author       = {Wen Xie and Heng Liu and JiaHao Li},
  doi          = {10.1016/j.asoc.2025.113675},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113675},
  shortjournal = {Appl. Soft. Comput.},
  title        = {RGB-D indoor scene parsing via wavelet sub-band guided transformer},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language model driven multiple operating conditions identification and predictive control. <em>ASOC</em>, <em>184</em>, 113674. (<a href='https://doi.org/10.1016/j.asoc.2025.113674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic changes in operating conditions are common in industrial process control. Efficient and accurate detection of condition transitions and identification of operating states are critical for achieving precise control across multiple operating conditions. Traditional condition identification methods primarily rely on the numerical similarity of input–output sequences, often neglecting the dynamic semantic information embedded within the data, such as variation rates and overshoot magnitudes, which can lead to frequent misclassifications. Recently, large language models (LLMs) have exhibited remarkable capabilities in semantic understanding of complex sequences, offering a new perspective for the identification of operating conditions. However, their application in industrial control still faces two major challenges. First, the enormous parameter scale of LLMs results in high computational costs, making it difficult to achieve real time comparisons between online sequences and large historical datasets, thereby compromising the timeliness of condition identification. Second, LLMs are designed primarily for textual input, leading to a significant modality gap when processing numerical input–output sequence data, which limits their full semantic understanding potential in industrial scenarios. To address these challenges, this paper proposes a novel large language model driven multiple operating conditions identification and predictive control method. The proposed method fully leverages the semantic understanding capabilities of LLMs by mining the underlying dynamic characteristics of input–output sequences, enabling rapid identification of operating conditions under limited sample scenarios and achieving precise control across multiple conditions. Specifically, first, to accurately detect condition changes in multiple operating condition industrial processes, an Approximate Entropy based operating condition change detection method is proposed. Considering that condition transitions often cause a prediction model mismatch, leading to increased complexity and irregularity in control sequences, approximate entropy is employed to quantify the sequence complexity. A data driven adaptive thresholding mechanism based on kernel density estimation is further developed to achieve robust detection of condition changes. Second, to address the issues of limited samples and low identification accuracy arising from solely relying on numerical features, a novel LLM driven multimodal condition identification method is proposed. This method constructs a sparse representation based prediction model for historical operating conditions, forming a high information density knowledge base consisting of prediction models and representative sequences. To bridge the modality gap between numerical and textual data, a numerical to textual sequence description method enriched with dynamic semantics is innovatively introduced, enabling effective alignment between the two modalities. Furthermore, a dynamic semantics enhanced prompt engineering strategy is developed to fully exploit the LLM’s semantic understanding capabilities, facilitating accurate condition identification even under limited sample conditions. Finally, to achieve rapid response and precise control following condition changes, the proposed method quickly matches a suitable prediction model based on the LLM driven condition identification results and dynamically adjusts control parameters using a rolling horizon optimization strategy, thereby significantly improving control accuracy across multiple operating conditions. Notably, the proposed approach eliminates the need for reconstructing condition models after changes, ensuring smooth and continuous control under dynamic conditions. Extensive experiments verified the superiority of the proposed method in terms of both condition identification and multiple operating conditions control performance.},
  archive      = {J_ASOC},
  author       = {Zhongyu Zhang and Minzhi Mao and Keke Huang and Dehao Wu and Chunhua Yang},
  doi          = {10.1016/j.asoc.2025.113674},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113674},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Large language model driven multiple operating conditions identification and predictive control},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MetaIndux-PLC: A control logic-guided LLM for PLC code generation in industrial control systems. <em>ASOC</em>, <em>184</em>, 113673. (<a href='https://doi.org/10.1016/j.asoc.2025.113673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programmable Logic Controllers (PLCs) are widely used for automation control, and they are well-suited for industrial systems control tasks. LLMs can assist engineers in streamlining the programming process and reducing development costs, and one of the key issues is the construction of the PLC code dataset. However, the lack of an open-source PLC code dataset in the research community, combined with the high complexity of industrial systems control logic, has caused most LLMs to struggle with generating accurate control code. This complexity arises from the need to manage real-time sensor data fusion, integrate various communication protocols, and ensure compliance with stringent safety and regulatory standards. In this study, we construct ST4Indux, a PLC code dataset specifically for industrial systems control. And we propose the Control Logic-Guided Iterative Fine-Tuning (CLIFT) method, which iteratively optimizes the model’s generation capability. Based on these, we train a large language model named MetaIndux-PLC, to enable the generation of complex motion control code. Additionally, we propose a multi-dimensional evaluation and optimization method to systematically assess the model’s performance in terms of task completion quality, efficiency, and user experience. The experimental results demonstrate that the proposed approach significantly enhances MetaIndux-PLC’s performance and reliability in real-world engineering environments, providing a foundation for the future development of intelligent programming assistance systems.},
  archive      = {J_ASOC},
  author       = {Lei Ren and Haotian Wang and Jiabao Dong and Haiteng Wang and Shuai Liu and Yuanjun Laili and Lin Zhang},
  doi          = {10.1016/j.asoc.2025.113673},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113673},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MetaIndux-PLC: A control logic-guided LLM for PLC code generation in industrial control systems},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage identification of false data injection attacks in power systems via semi-supervised deep learning. <em>ASOC</em>, <em>184</em>, 113672. (<a href='https://doi.org/10.1016/j.asoc.2025.113672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies find that malicious data manipulations against the state estimation, such as the false data injection attack (FDIA), can evade the detection of a conventional bad data detector equipped with a measurement meter. This calls for advanced FDIA identification approaches urgently. However, existing data-driven efforts are designed under the assumption that attacks are frequent and the amount of compromised data is comparable to benign data, which may not be realistic. Thus, these approaches deliver unsatisfactory performance under highly imbalanced data in the real world. To overcome this issue, we propose a novel two-stage FDIA identification pipeline, which formulates the problem as global detection and fine-grained localization. Following this framework, we leverage deep support vector data description to distinguish attacks from benign measurements in an unsupervised manner and employ a modified one-dimensional ResNet to locate the attacking aims upon detecting an FDIA. Our approach can overcome existing limitations induced by data-driven methods under infrequent FDIAs, leading to effective and robust FDIA identification. Case studies on IEEE standard 14-bus and 118-bus systems demonstrate the effectiveness and superiority of our approach and validate our findings.},
  archive      = {J_ASOC},
  author       = {Fengrui Liu and Keng-Weng Lao and Yida Xu and Yang Li and Haotian Guo and Xiaorui Hu and Yikun Yin},
  doi          = {10.1016/j.asoc.2025.113672},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113672},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Two-stage identification of false data injection attacks in power systems via semi-supervised deep learning},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic target continuous assignment method for unmanned clusters in fragmented information environments. <em>ASOC</em>, <em>184</em>, 113671. (<a href='https://doi.org/10.1016/j.asoc.2025.113671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target assignment stands as a pivotal resource management technique in collaborative clustering. During far-sea search and rescue (SAR) missions, challenges arise in formation control under fragmented information, stemming from unstable communication and incomplete data. Additionally, the dynamic nature of targets poses continuous assignment challenges. Addressing these issues in cluster collaboration represents a significant challenge. This paper proposes a method for dynamic target successive allocation tailored to fragmented information environments. First, inspired by biological cluster behaviors and integrating graph theory and complex network theory, the approach achieves decentered cluster formation by managing subgroup separation and aggregation. This solution effectively addresses the formation control challenge in fragmented information settings during cluster collaboration. Second, leveraging reinforcement learning principles, the method determines device behavioral strategies based on maximizing the device’s interaction rewards with the environment. This approach resolves the dynamic continuous target assignment challenge within clustered environments. This paper proposes a Broken Info-Driven Target Assignment (BI-DTA) method to address these research challenges. Experimental results demonstrate that the method achieves effective decentered formation control and dynamic continuous target assignment rapidly, exhibiting robustness and stability in fragmented information environments.},
  archive      = {J_ASOC},
  author       = {Rui Ding and Yuhan Zhu and Baojie Chai},
  doi          = {10.1016/j.asoc.2025.113671},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113671},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic target continuous assignment method for unmanned clusters in fragmented information environments},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A surrogate-assisted evolutionary algorithm based on the two-round selection strategy incorporating local search for expensive high-dimensional multi/many-objective optimization. <em>ASOC</em>, <em>184</em>, 113670. (<a href='https://doi.org/10.1016/j.asoc.2025.113670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted multi-objective optimization has exhibited excellent performance for solving optimization problems that involve time-intensive computer simulations or resource-intensive physical experiments. However, the majority of existing research has focused on low-dimensional problems. In this paper, a surrogate-assisted evolutionary algorithm based on the two-round selection strategy incorporating local search (TRLS) is proposed for expensive high-dimensional multi/many-objective optimization. Specifically, the convergence and diversity of the trial solutions are assessed based on the estimation of Pareto fronts, and the uncertainty is quantified by analyzing the distribution of relevant points in the decision space. The infill sampling task is guided by the above three performance indicators. Firstly, a preliminary screening is conducted by considering convergence and diversity performance. Subsequently, the quality of candidates is further refined through the implementation of a local search strategy. Finally, a comprehensive fitness is constructed to select the sampling individual. In addition, a dynamic termination criterion is devised for the surrogate-assisted evolution phase. Empirical studies, conducted on two classical benchmark suites and two real-world tasks, reveal the effectiveness and applicability of the proposed TRLS.},
  archive      = {J_ASOC},
  author       = {Yang Li and Weigang Li and Songtao Li and Qifeng Wang and Junwei Hu},
  doi          = {10.1016/j.asoc.2025.113670},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113670},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A surrogate-assisted evolutionary algorithm based on the two-round selection strategy incorporating local search for expensive high-dimensional multi/many-objective optimization},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study of the hesitant fuzzy aggregation operators for the transportation of perishable goods under real life scenarios. <em>ASOC</em>, <em>184</em>, 113668. (<a href='https://doi.org/10.1016/j.asoc.2025.113668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transportation of the perishable goods has always been a critical challenge in the market. The inherent susceptibility of the perishable items to spoilage and deterioration during transit necessitates the development and implementation of the preservation technologies that enhance the shelf life and maintain the quality of perishable products during transportation. Also, the carbon emissions stemming from activities associated with transportation present a significant and progressively urgent challenge, markedly contributing to environmental degradation. Consequently, the escalating carbon emissions linked to the transportation-related activities pose a threat to the sustainability of the environment. Recalling these facts, this paper explores the study of an interval valued multi-objective fixed charge solid transportation problem under hesitant fuzzy aggregation operators. Furthermore, this paper introduces a practical mathematical framework designed to represent the decision-making process inherited in the transportation scenarios. The proposed method leverages the hesitant fuzzy aggregation operators to offer a specific approach for the decision-making across such operators. Additionally, it introduces the notion of hesitant degrees for different objectives through the utilization of membership functions. Three conflicting objective functions: time minimization for customer satisfaction, profit maximization for the economic sustainability and minimization of the carbon emissions for the environmental sustainability have been addressed in the suggested model. The transportation time and the fuel consumption have been managed by introducing a variable called the vehicle speed coefficient. An analysis of the deterioration rates of the perishable products has been conducted considering the presence of a preservation value. Moreover, the proposed model has been formulated by employing the diverse approaches and have been solved using multi-objective techniques. A real-life-based numerical problem is presented and solved to validate the proposed concept. The results are compared with respect to different vehicle speeds and preservation values.},
  archive      = {J_ASOC},
  author       = {Awdhesh Kumar Bind and Deepika Rani and Ali Ebrahimnejad},
  doi          = {10.1016/j.asoc.2025.113668},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113668},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A study of the hesitant fuzzy aggregation operators for the transportation of perishable goods under real life scenarios},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAGE-net: Single-layer augmented gated encoder network for efficient multimodal sentiment analysis. <em>ASOC</em>, <em>184</em>, 113665. (<a href='https://doi.org/10.1016/j.asoc.2025.113665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis has achieved remarkable progress. However, the increasing computational complexity of existing models poses significant challenges in resource-constrained scenarios. To address these challenges, this study introduces a single-layer augmented gated encoder network (SAGE-Net), a novel lightweight multimodal sentiment analysis architecture. In contrast to conventional multilayer, deeply stacked architectures, SAGE-Net employs only a single-layer encoder to preserve multimodal feature comprehension, significantly reducing computational complexity. To enable effective inter-modal interaction, a single-layer cross-attention mechanism is integrated. We extensively evaluate multiple feature fusion strategies and data augmentation strategies to enhance model effectiveness. Experimental results on the CMU-MOSI and CMU-MOSEI, and CH-SIMS datasets demonstrate that SAGE-Net achieves competitive performance and significantly lowers model size and tuning costs. These results validate SAGE-Net as a viable lightweight solution for multimodal sentiment analysis in resource-constrained scenarios.},
  archive      = {J_ASOC},
  author       = {Jiazheng Zhou and Xin Kang and Weiping Ding and Linhuang Wang and Fei Ding and Kazuyuki Matsumoto and Chenmeng Zhang and Huiwen Chi},
  doi          = {10.1016/j.asoc.2025.113665},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113665},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SAGE-net: Single-layer augmented gated encoder network for efficient multimodal sentiment analysis},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust weakly supervised product surface defect segmentation based on guided cropping and inpainting extension. <em>ASOC</em>, <em>184</em>, 113661. (<a href='https://doi.org/10.1016/j.asoc.2025.113661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of industrial manufacturing, automatic detection and segmentation of surface defects in products is vital to enhance both product quality and efficiency. However, a large number of existing deep learning methods require a substantial amount of manually labeled data for training, and the high-cost labeling process hampers the practical application of such methods. Towards this end, we present a weakly supervised defect segmentation algorithm without any segment labels. First, a training enhancement method based on a contrastive learning module (CLM) coupled with a guided cropping module (GCM) is proposed to improve the network’s attention to defects in the Defect Focus Classifier (DFC) training phase. Subsequently, a novel inpainting extension module (IEM) generates a final class activation map (CAM) to obtain a pseudo label automatically for segment network training. Finally, conditional random field (CRF) and an additional training round refine the segmentation results. Moreover, the whole process is distilled into a fully supervised segmentation network to improve the inference efficiency. Conducting extensive experimentation, we have achieved 100% and 93.39% average precision (AP) and 41.73% and 53.14% average intersection-over-union (IOU) on the public datasets KolektorSDD and KolektorSDD2, respectively. Furthermore, we verified the generalizability of our method by conducting experiments on several industrial product classes in the MVTec AD, MTD, and DAGM datasets. In these experiments, we achieved favorable classification and segmentation results using solely image classification labels.},
  archive      = {J_ASOC},
  author       = {Rui Yan and Xiaojun Wu and Qixun Yang and Michael Yu Wang},
  doi          = {10.1016/j.asoc.2025.113661},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113661},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Robust weakly supervised product surface defect segmentation based on guided cropping and inpainting extension},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised lip-tongue segmentation with boundary region contrast sampling. <em>ASOC</em>, <em>184</em>, 113653. (<a href='https://doi.org/10.1016/j.asoc.2025.113653'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Traditional Chinese Medicine, the accurate segmentation mask of the tongue and lip is the key of inspection. Although deep learning has made remarkable progress in medical image segmentation, a lot of manual annotations are still required for training. Semi-supervised learning (SSL) is used to reduce annotation work, but its performance often suffers when applied to tongue and lip segmentation, which is because tongue and lip images have noisy background information and unique boundary regions. To alleviate the problem, we propose a semi-supervised framework named Lip-Tongue segmentation with Boundary Region Contrast Sampling (Lip-Tongue-BReCoSample). We first preprocess the data, roughly locating the target and filtering out noisy background information. Then we generate the key boundary regions and sample to carry out contrast learning, which alleviates the problem that SSL cannot make fine modeling of the boundary regions of the target with limited information. After a lot of experiments, our method has achieved good results in SSL, and makes it reach or even exceed the performance of many traditional supervised methods, which can improve MIOU performance from 88.09 to 90.43 (+2.34) in SSL specifically. Our method is also better than the latest large-dataset pre-trained model (e.g., SegGPT). To the best of our knowledge, it is the first application of SSL in tongue and lip semantic segmentation.},
  archive      = {J_ASOC},
  author       = {Tao Jiang and Lechao Zhang and Wang Yuan and Liping Tu and Ji Cui and Xiaojuan Hu and Xin Tan and Lizhuang Ma and Jiatuo Xu},
  doi          = {10.1016/j.asoc.2025.113653},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113653},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Semi-supervised lip-tongue segmentation with boundary region contrast sampling},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-term multistep wind direction prediction of unmanned sailboats based on OVMD and optimized deep learning model. <em>ASOC</em>, <em>184</em>, 113651. (<a href='https://doi.org/10.1016/j.asoc.2025.113651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate short-term multistep wind direction prediction is crucial for enhancing the sailing performance and operational safety of unmanned sailboats. Existing methods often face challenges due to the complexity, non-stationarity, and diverse frequency characteristics of wind direction data. In this study, a novel approach is proposed that combines optimal variational mode decomposition (OVMD) with optimized deep learning model for wind direction prediction. First, OVMD is applied to decompose the wind data into stable modal signals, effectively reducing the impact of data complexity and non-stationarity on prediction performance. Considering that different subsequences exhibit distinct frequency patterns, five deep learning models, including Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks, are employed to predict each subsequence separately. The most suitable model for each subsequence is selected based on the root mean square error (RMSE) metric. Additionally, hyperparameter optimization is conducted to enhance prediction accuracy, reduce training time, and eliminate the need for subjective parameter settings. Experimental results demonstrate that the proposed method can accurately capture wind direction variations and achieves superior performance compared to baseline models across all evaluation metrics, ensuring high accuracy and stability in short-term multistep wind direction prediction.},
  archive      = {J_ASOC},
  author       = {Zhipeng Shen and Shaoqing Zhang and Yang Yang and Zhaoyang Wu and Haomiao Yu},
  doi          = {10.1016/j.asoc.2025.113651},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113651},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Short-term multistep wind direction prediction of unmanned sailboats based on OVMD and optimized deep learning model},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-inspired text-based recommender system with explanatory capabilities. <em>ASOC</em>, <em>184</em>, 113650. (<a href='https://doi.org/10.1016/j.asoc.2025.113650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are widely used to help users find relevant and personalized items in various domains. However, providing accurate recommendations is not enough to ensure user satisfaction, trust, and engagement. Nowadays, users demand transparency from these systems typically in the form of an explanation of the recommendation given. This paper presents a novel explainable Recommender System designed to generate recommendations from natural language queries while providing model-intrinsic explanations inspired by attention mechanisms. The system adds transparency, interpretability, and new user cold-start capabilities. We evaluate our approach on twelve datasets from diverse domains and languages, demonstrating its effectiveness and robustness. Results show that our proposal achieves competitive accuracy with respect to strong baselines, while consistently outperforming a prior interpretable model developed for the same task.},
  archive      = {J_ASOC},
  author       = {Pablo Pérez-Núñez and Paul Buitelaar and Jorge Díez and Oscar Luaces and Antonio Bahamonde},
  doi          = {10.1016/j.asoc.2025.113650},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113650},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Attention-inspired text-based recommender system with explanatory capabilities},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MHGCL: A multi-modal hypergraph contrastive learning framework for molecular property prediction. <em>ASOC</em>, <em>184</em>, 113645. (<a href='https://doi.org/10.1016/j.asoc.2025.113645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate molecular property prediction (MPP) is pivotal in drug discovery. Although current models integrate multi-modal (1D, 2D, and 3D) molecular features, they often suboptimally leverage pharmacophoric information and inadequately capture higher-order intramolecular relationships, such as conjugated systems. This study introduces a novel multi-modal hypergraph contrastive learning framework (MHGCL) to generate enriched molecular representations for enhanced MPP. MHGCL uniquely employs hypergraphs to model complex, many-to-many interactions within molecules. It incorporates a dual-channel architecture, featuring a hypergraph transformer and an equivariant graph neural network, to distinctly process 2D and 3D molecular information. Crucially, functional group and chemical element-oriented knowledge graphs are integrated to explicitly imbue the model with pharmacophoric knowledge. The contrastive learning strategy effectively aligns these diverse representations. Extensive experiments across ten benchmark datasets demonstrate that MHGCL consistently outperforms existing state-of-the-art methods. Further ablation studies confirm that the proposed hypergraph-based molecular representation captures structural motifs of molecular functional groups more effectively, thereby affirming the design efficacy of the model’s constituent modules.},
  archive      = {J_ASOC},
  author       = {Rui Han and Qun Liu and Xu Gong and Guoyin Wang and Li Liu and Xingping Xian},
  doi          = {10.1016/j.asoc.2025.113645},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113645},
  shortjournal = {Appl. Soft. Comput.},
  title        = {MHGCL: A multi-modal hypergraph contrastive learning framework for molecular property prediction},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-hop shapley-based framework for graph convolutional network node classification explanation. <em>ASOC</em>, <em>184</em>, 113615. (<a href='https://doi.org/10.1016/j.asoc.2025.113615'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks (GCNs) have recently demonstrated superior performance across various graph machine learning tasks. However, they are often regarded as “black-box” models, which has sparked significant interest in developing methods to interpret their predictions. Among various GCN explanation techniques, game-theoretic Shapley value approaches stand out for their ability to identify important nodes, edges, and features. Nonetheless, most Shapley-based explanation models tend to concentrate on dependencies within a fixed radius, resulting in a constrained perceptual field. Additionally, existing explanation methods primarily focus on the total marginal contributions of either very small or very large coalitions during sampling, which limits their effectiveness in capturing the joint marginal contributions inherent in mid-sized subgraphs. To address these challenges, we propose a novel Shapley-based GCN explanation model called MixHopShap, which incorporates multi-hop information and a balanced sampling strategy. MixHopShap employs a multi-hop computational graph construction process to generate an explanation domain, enabling it to capture both local and long-range dependencies. Moreover, MixHopShap introduces a new sampling strategy that promotes balanced coalition coverage, allowing for efficient sampling of mid-sized subgraphs and facilitating learning of marginal contributions for each edge. We conduct experiments on six real world datasets to evaluate the performance of MixHopShap in terms of Fidelity and ROAR metrics. The experimental results demonstrate the superiority of MixHopShap over state-of-the-art methods. Additionally, the explainability of MixHopShap can significantly improve the confidence of GCN’s prediction in node classification tasks.},
  archive      = {J_ASOC},
  author       = {Yifan Zheng and Xibei Yang and Qiguo Sun and Keyu Liu and Qihang Guo},
  doi          = {10.1016/j.asoc.2025.113615},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113615},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-hop shapley-based framework for graph convolutional network node classification explanation},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural network-based interactive clustering enhanced by human knowledge. <em>ASOC</em>, <em>184</em>, 113595. (<a href='https://doi.org/10.1016/j.asoc.2025.113595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering techniques face persistent challenges in balancing automation with human interpretability. Traditional methods require laborious parameter tuning and domain expertise to define similarity measures and validate results, while deep learning approaches trade transparency for performance. To bridge this gap, we propose a human-in-the-loop framework that synergizes domain knowledge with graph-based semi-supervised learning. Our system enables users to iteratively refine clusters through intuitive visual adjustments on a subset of data, guided by real-time quality metrics to reduce errors and decision fatigue. These sparse annotations propagate to unlabeled instances via a graph neural network (GNN) that models latent relationships through modularity-driven structural learning. By translating cluster adjustments into semi-supervised classification tasks, our method eliminates manual feature engineering and scales to large datasets without retraining. Evaluations on two subsets of the MNIST dataset demonstrated that the NMI (Normalized Mutual Information) of our method improved by 50.44% and 64.77% relative to baseline clustering method, respectively.},
  archive      = {J_ASOC},
  author       = {Yunzhe Wang and Yushi Li and Qiming Fu and Chengtao Ji and You Lu and Jianping Chen},
  doi          = {10.1016/j.asoc.2025.113595},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113595},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph neural network-based interactive clustering enhanced by human knowledge},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced deep learning approaches for fault detection in solar PV systems: A comparative study of SPDA and AIFD-SolDL. <em>ASOC</em>, <em>184</em>, 113592. (<a href='https://doi.org/10.1016/j.asoc.2025.113592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient operation of solar photovoltaic (PV) systems is critical for maximizing power generation and ensuring optimal energy conversion. However, faults in PV modules can significantly impact system performance and reduce energy output. Therefore, accurate identification and diagnosis of these malfunctions are essential. To address the challenge of fault detection in solar PV systems, this study presents two distinct approaches. The first, called Solar Panel Degradation Assessment (SPDA), evaluates faults in solar panels by analyzing degradation effects while considering environmental factors like radiation and temperature. The second approach, named Efficient Ensemble Deep Learning Model for Enhancing Fault Detection in Solar PV Systems (AIFD-SolDL), utilizes advanced deep learning techniques, including DenseNet201, Inception-ResNet-v2, and Inception-v3, to enhance fault detection accuracy. In the AIFD-SolDL approach, PV module data undergo deep feature extraction followed by dimensionality reduction using principal component analysis (PCA). The reduced feature set is then used to train classifiers such as support vector machines (SVM), Gaussian Naive Bayes (GaussianNB), and random forests (RF) to differentiate between normal and fault conditions. Performance metrics, including precision, accuracy, recall, and F1-score, are computed for each combination of feature extractor and classifier. Extensive experiments with both the Solar Panel Images Dataset and the Infrared Solar Module Dataset show that the proposed approaches outperform state-of-the-art methods. For instance, the AIFD-SolDL approach utilizing SVM achieved perfect accuracy, precision, recall, and F1-score of 100% on the Solar Panel Images Dataset. Overall, the SPDA approach effectively detects faults, while deep learning techniques demonstrate high accuracy in fault classification, thereby enhancing the reliability of PV system maintenance and optimization.},
  archive      = {J_ASOC},
  author       = {Mohamed R. Shoaib and Heba M. Emara and Jun Zhao and Milad Taleby Ahvanooey and Essam Nabil},
  doi          = {10.1016/j.asoc.2025.113592},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113592},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advanced deep learning approaches for fault detection in solar PV systems: A comparative study of SPDA and AIFD-SolDL},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuroevolution-based multiobjective algorithm for feature selection and binary classification of DNA microarrays. <em>ASOC</em>, <em>184</em>, 113520. (<a href='https://doi.org/10.1016/j.asoc.2025.113520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The genomes of organisms have been sequenced for many years, leading to the discovery of thousands of genes. DNA microarrays are widely used tools for simultaneously analysing numerous genes, commonly employed in detecting and identifying various diseases, including cancer. However, microarray datasets have non-relevant and redundant information, hindering their analysis. This problem is further exacerbated considering the datasets’ high dimensionality and imbalanced classes. Consequently, standard practice involves incorporating a feature selection process to identify the most relevant genes and their associations with diseases. Various methods have been employed to address this task. However, none have taken a more holistic approach that effectively handles feature selection, automatically identifies the optimal classifier configuration, and manages potential conflicting objectives simultaneously. In response, this study introduces the S -metric selection - multiobjective neuroevolution of augmenting topologies (SMS-MONEAT) algorithm, which combines the multiobjective optimisation framework from S -metric selection - evolutionary multiobjective algorithm (SMS-EMOA) and the evolutionary operators from the neuroevolution algorithm N3O, a variation from NEAT which stands for ‘3 new operators’. SMS-MONEAT algorithm was designed to perform both feature selection and optimise the configuration of artificial neural networks for classification tasks. SMS-MONEAT was evaluated against classic and state-of-the-art methods for feature selection and microarray classification. The experiments were conducted on 20 highly challenging cancer-type datasets primarily sourced from the Curated Microarray Database, and the results were investigated for statistical significance. The findings suggest that SMS-MONEAT either outperforms or achieves competitive results in terms of classification compared to the mentioned methods, while at the same time, it selects a smaller subset of features.},
  archive      = {J_ASOC},
  author       = {Daniel García-Núñez and Katya Rodrígez-Vázquez and Carlos Hernández and Edgar Galván},
  doi          = {10.1016/j.asoc.2025.113520},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {113520},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Neuroevolution-based multiobjective algorithm for feature selection and binary classification of DNA microarrays},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based bangla text normalization with emotion classification for expressive text-to-speech synthesizer. <em>ASOC</em>, <em>184</em>, 112899. (<a href='https://doi.org/10.1016/j.asoc.2025.112899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel method for text normalization and emotion classification specifically designed for the preprocessing steps of Expressive Text-to-Speech (ETTS) synthesizers. Text normalization, which converts non-standard words into standardized forms, is essential for generating clear and coherent output in ETTS synthesizers. Previous studies have encountered difficulties with Bangla homographic words, prompting the development of our proposed method. Our approach begins with the creation of a tokenized and categorized dataset consisting of 26 unique semiotic classes, utilizing a rule-based method with regular expressions. This dataset is derived from the Bangla Text Normalization Corpus (BTN Corpus), which contains 2 million Bangla sentences. Initially, Bangla written texts are tokenized, and each token is classified using a Temporal Convolutional Network (TCN) algorithm trained on the BTN Corpus to identify its semiotic class. This classification aids in generating normalized text, where the resulting tokens are reassembled into coherent sentences for final output. In addition to text normalization, we implement emotion classification for each normalized sentence using a Hierarchical Attention Network (HAN) model. The HAN model was trained on 67,277 normalized texts from the Bangla Normalized Emotion Text Corpus (BNET Corpus), categorizing each text into one of six emotion classes through a rule-based method with regular expressions. The proposed method demonstrates high accuracy rates, achieving a token classification accuracy of 99.977 % with the TCN and an emotion classification accuracy of 99.735 % with the HAN model.},
  archive      = {J_ASOC},
  author       = {Md. Rezaul Islam and Mohammad Shahidur Rahman},
  doi          = {10.1016/j.asoc.2025.112899},
  journal      = {Applied Soft Computing},
  month        = {12},
  pages        = {112899},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep learning-based bangla text normalization with emotion classification for expressive text-to-speech synthesizer},
  volume       = {184},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="autom">AUTOM - 33</h2>
<ul>
<li><details>
<summary>
(2026). Sector stabilization criterion of a novel nonlinear flexible marine riser coupled system. <em>AUTOM</em>, <em>183</em>, 112618. (<a href='https://doi.org/10.1016/j.automatica.2025.112618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper establishes a sector stabilization criterion for a nonlinear flexible marine riser system that incorporates lateral and transverse coupling vibrations, derived from Hamilton’s principle. This criterion, grounded in the sector-bounded condition, encompasses a wide range of linear and nonlinear feedback control laws applied to the transverse and lateral directions at the top boundary of the flexible marine riser, respectively. In the analysis, the nonlinear semigroup theory is utilized to establish the well-posedness of the resulting closed-loop coupled system. Notably, the solution demonstrates continuous dependence on the initial conditions. Furthermore, the exponential stability of the closed-loop coupled system is achieved by employing a generalized Gronwall-type integral inequality and the integral multiplier method, which involves the innovative development of an energy-like functional. To demonstrate the effectiveness of the proposed controls, numerical simulations utilizing the finite element method are presented.},
  archive      = {J_AUTOM},
  author       = {Yi Cheng and Xin Wang and Yuhu Wu and Bao-Zhu Guo},
  doi          = {10.1016/j.automatica.2025.112618},
  journal      = {Automatica},
  month        = {1},
  pages        = {112618},
  shortjournal = {Automatica},
  title        = {Sector stabilization criterion of a novel nonlinear flexible marine riser coupled system},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed data-driven unknown-input observers. <em>AUTOM</em>, <em>183</em>, 112614. (<a href='https://doi.org/10.1016/j.automatica.2025.112614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unknown inputs related to, e.g., sensor aging, modeling errors, or device bias, represent a major concern in wireless sensor networks, as they degrade the state estimation performance. To improve the performance, unknown-input observers (UIOs) have been proposed. Most of the results available to design UIOs are based on explicit system models, which can be difficult or impossible to obtain in real-world applications. Data-driven techniques, on the other hand, have become a viable alternative for the design and analysis of unknown systems using only data. In this context, a novel data-driven distributed unknown-input observer (D-DUIO) for unknown continuous-time linear time-invariant (LTI) systems is developed, which requires solely some data collected offline, without any prior knowledge of the system matrices. In the paper, first, a model-based approach to the design of a DUIO is presented. A sufficient condition for the existence of such a DUIO is recalled, and a new one is proposed, that is prone to a data-driven adaptation. Moving to a data-driven approach, it is shown that under suitable assumptions on the input/output/state data collected from the continuous-time system, it is possible to both claim the existence of a D-DUIO and to derive its matrices in terms of the matrices of pre-collected data. Finally, the efficacy of the D-DUIO is illustrated by means of numerical examples.},
  archive      = {J_AUTOM},
  author       = {Yuzhou Wei and Giorgia Disarò and Wenjie Liu and Jian Sun and Maria Elena Valcher and Gang Wang},
  doi          = {10.1016/j.automatica.2025.112614},
  journal      = {Automatica},
  month        = {1},
  pages        = {112614},
  shortjournal = {Automatica},
  title        = {Distributed data-driven unknown-input observers},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robustness of supervisory controllers subject to measurement disturbances. <em>AUTOM</em>, <em>183</em>, 112613. (<a href='https://doi.org/10.1016/j.automatica.2025.112613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the supervisory control problem for a class of uncertain nonlinearly parameterized systems in the presence of measurement disturbance. Based on the well-established estimator-based supervisory control structure, a robustification of supervisory controller dealing with measurement disturbance is developed taking advantage of the monitoring signals redesign, such that the plant state asymptotically converges to a given set-point or its neighborhood, subject to the vanishing or the persistent measurement disturbance, respectively. Moreover, a constructive design of the multi-estimator using measurement feedback is proposed for the supervisory control of a class of uncertain nonlinearly parameterized systems in the strict-feedback form. A numerical simulation based on an uncertain mass–spring system is given to show the efficacy of our proposed algorithm, in which we use an event-trigger to be a measurement disturbance generator.},
  archive      = {J_AUTOM},
  author       = {Yutian Wang and Qingkai Meng and Yi Jiang},
  doi          = {10.1016/j.automatica.2025.112613},
  journal      = {Automatica},
  month        = {1},
  pages        = {112613},
  shortjournal = {Automatica},
  title        = {Robustness of supervisory controllers subject to measurement disturbances},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive fault-tolerant control of nonlinear systems: A self-regulating spatiotemporal performance approach. <em>AUTOM</em>, <em>183</em>, 112602. (<a href='https://doi.org/10.1016/j.automatica.2025.112602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of performance constraints of uncertain nonlinear systems with actuator faults. Particularly, by developing the boundary threshold triggering strategy, the performance boundaries would be updated adaptively once the distance between the tracking error and the performance boundaries is smaller than the given threshold. Moreover, compared with the existing works, the transient behaviors are improved, and the limitation imposed on the initial conditions is removed attributed to the construction of novel performance functions and error transformation. Then, an adaptive fault-tolerant control scheme with self-regulating spatiotemporal performance is designed for a class of nonlinear systems with non-parametric uncertainties. It is shown that both the boundedness of the closed-loop signals and the satisfactory performance constraints are guaranteed in the presence of unpredictable actuator failure. The effectiveness of the proposed method is verified by theoretical analysis and numerical simulation.},
  archive      = {J_AUTOM},
  author       = {Zeqiang Li and Jason J.R. Liu and Yongduan Song},
  doi          = {10.1016/j.automatica.2025.112602},
  journal      = {Automatica},
  month        = {1},
  pages        = {112602},
  shortjournal = {Automatica},
  title        = {Adaptive fault-tolerant control of nonlinear systems: A self-regulating spatiotemporal performance approach},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed nash equilibrium seeking with a dynamic set of players. <em>AUTOM</em>, <em>183</em>, 112598. (<a href='https://doi.org/10.1016/j.automatica.2025.112598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper formulates a new distributed Nash equilibrium seeking problem with a dynamic set of players in which players are allowed to join and leave the network in a free manner during the decision-making process. To accommodate the dynamic joining and leaving behaviors of the players, a status estimation mechanism, which is capable of estimating in a finite time whether the players are active or inactive, is introduced. Based on the status estimation mechanism, a gradient play based algorithm is developed for distributed Nash equilibrium seeking in the dynamic environment. It is shown that under strongly connected communication graphs, players’ actions are convergent to a small neighborhood of the new Nash equilibrium linearly every time the player set changes. Moreover, the convergence accuracy and convergence rate can be adjusted by suitably tuning the step-size. To cover more general communication scenarios, strongly connected graphs are further relaxed to be B-jointly connected graphs, under which the convergence properties of the proposed algorithm are analytically studied. Furthermore, the upper bound of the average tracking error is quantified to evaluate the dynamic performance of the proposed algorithm. In the last, a simulation study on energy consumption games is given to verify the effectiveness of the proposed algorithm.},
  archive      = {J_AUTOM},
  author       = {Yuxuan Liu and Maojiao Ye and Lei Ding and Lihua Xie and Qing-Long Han},
  doi          = {10.1016/j.automatica.2025.112598},
  journal      = {Automatica},
  month        = {1},
  pages        = {112598},
  shortjournal = {Automatica},
  title        = {Distributed nash equilibrium seeking with a dynamic set of players},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Constrained finite-time and fixed-time stabilization for linear systems: Adaptive implicit lyapunov function-based control. <em>AUTOM</em>, <em>183</em>, 112597. (<a href='https://doi.org/10.1016/j.automatica.2025.112597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, finite-time and fixed-time stabilization problems are investigated for single-input single-output (SISO) linear system under the control input constraint. The achievement of finite-time or fixed-time convergence rates is facilitated through the utilization of adaptive implicit Lyapunov function (ILF)-based control. For ease of practical implementation, the dynamics of Approximated-ILF (AILF) guarantees the precise estimation of ILF, while the stability of AILF-based control holds established. Furthermore, from both performance and input-constrained safety considerations, the anti-windup (AW) AILF endows the system with tolerance to saturation and maintains the non-asymptotic convergence properties. Numerical simulations support the obtained theoretical results and verify their effectiveness.},
  archive      = {J_AUTOM},
  author       = {Peng Wang and Mou Chen and Shuzhi Sam Ge and Xiaobing Zhang},
  doi          = {10.1016/j.automatica.2025.112597},
  journal      = {Automatica},
  month        = {1},
  pages        = {112597},
  shortjournal = {Automatica},
  title        = {Constrained finite-time and fixed-time stabilization for linear systems: Adaptive implicit lyapunov function-based control},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Input-to-state stability of self-triggered impulsive control systems. <em>AUTOM</em>, <em>183</em>, 112596. (<a href='https://doi.org/10.1016/j.automatica.2025.112596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the local input-to-state stability ( LISS ) of nonlinear systems under the self-triggered impulsive control ( STIC ) method. A novel LISS -type comparison principle is proposed, by which the LISS property of addressed system can be derived by the LISS property of its comparison system. On the basis of it, some Lyapunov-based sufficient conditions for non-Zeno behavior and LISS of nonlinear systems are provided in the framework of STIC . Moreover, the designed self-triggering mechanism ( STM ) is in the form of an explicit relationship with simple structure and east implementation. Finally, two numerical examples are given to illustrate the effectiveness of the proposed results.},
  archive      = {J_AUTOM},
  author       = {Xiaodi Li and Mingzhu Wang},
  doi          = {10.1016/j.automatica.2025.112596},
  journal      = {Automatica},
  month        = {1},
  pages        = {112596},
  shortjournal = {Automatica},
  title        = {Input-to-state stability of self-triggered impulsive control systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-model-hybrid-driven near-optimal operational control of two-time-scale industrial systems with unknown operational model. <em>AUTOM</em>, <em>183</em>, 112594. (<a href='https://doi.org/10.1016/j.automatica.2025.112594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the optimal operational control (OOC) problem of two-time-scale (TTS) industrial systems with unknown operation model. Based on the singular perturbation theory (SPT), the OOC problem of TTS industrial systems is decomposed into an optimal regulation problem in fast time-scale and an optimal set-point tracking problem in slow time-scale. Then, by convex duality, the obtained optimization problems are equivalently transformed into convex optimization (CO) problems, and a data-model-hybrid-driven composite controller is designed. The design method of this composite controller avoids the potential numerical stiffness problems, and does not need complete system dynamics information while ensuring the steady-state output tracking error converges to zero. Finally, an example of mixed separation thickening process (MSTP) of hematite beneficiation is given to show the effectiveness of the proposed scheme.},
  archive      = {J_AUTOM},
  author       = {Yao Xu and Linna Zhou and Jianguo Zhao and Lei Ma and Chunyu Yang},
  doi          = {10.1016/j.automatica.2025.112594},
  journal      = {Automatica},
  month        = {1},
  pages        = {112594},
  shortjournal = {Automatica},
  title        = {Data-model-hybrid-driven near-optimal operational control of two-time-scale industrial systems with unknown operational model},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reducing real-time complexity via sub-control lyapunov functions: From theory to experiments. <em>AUTOM</em>, <em>183</em>, 112592. (<a href='https://doi.org/10.1016/j.automatica.2025.112592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The techniques to design control Lyapunov functions (CLF), along with a proper stabilizing feedback, possibly in the presence of constraints, often provide control laws that are too complex for proper implementation online, especially when an optimization problem is involved. In this work, we show how to acquire an alternative, computationally attractive feedback. Given a nominal CLF and a nominal state feedback, we say that a different positive definite function is a Sub-control Lyapunov function (SCLF) if its Lyapunov derivative is negative-definite and bounded above by the Lyapunov derivative of the nominal function with the nominal control. It turns out that if we consider a family of basis functions, then an SCLF can be computed by linear programming, with an infinite number of constraints. The idea is that although the offline computational burden to achieve the new controller and solve the linear program is considerable, the online computational burden is drastically reduced. Comprehensive simulations and experiments on drone control are conducted to demonstrate the effectiveness of the study.},
  archive      = {J_AUTOM},
  author       = {Huu-Thinh Do and Franco Blanchini and Stefano Miani and Ionela Prodan},
  doi          = {10.1016/j.automatica.2025.112592},
  journal      = {Automatica},
  month        = {1},
  pages        = {112592},
  shortjournal = {Automatica},
  title        = {Reducing real-time complexity via sub-control lyapunov functions: From theory to experiments},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adversarial dynamic games for markov jump systems: A policy iteration Q-learning method. <em>AUTOM</em>, <em>183</em>, 112591. (<a href='https://doi.org/10.1016/j.automatica.2025.112591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a reinforcement Q-learning approach for solving adversarial dynamic games in Markov jump systems. The H ∞ control problem is first formulated as a two-player zero-sum dynamic game, where the control policy and the disturbance policy act as adversarial players. To derive the Nash equilibrium control strategies for such games, a set of coupled algebraic Riccati equations is established, with the disturbance attenuation level properly prescribed. On this basis, two novel data-driven parallel Q-learning algorithms are proposed. The advantages of the proposed method are threefold: (i) it does not require precise knowledge of the system dynamics; (ii) it learns the optimal disturbance attenuation level; (iii) it yields Nash equilibrium control strategies. Finally, two simulation examples validate the effectiveness of the proposed method.},
  archive      = {J_AUTOM},
  author       = {Hao Shen and Jiacheng Wu and Jing Wang and Zhengguang Wu},
  doi          = {10.1016/j.automatica.2025.112591},
  journal      = {Automatica},
  month        = {1},
  pages        = {112591},
  shortjournal = {Automatica},
  title        = {Adversarial dynamic games for markov jump systems: A policy iteration Q-learning method},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). H2/H∞ state and output feedback control with sparse actuation. <em>AUTOM</em>, <em>183</em>, 112581. (<a href='https://doi.org/10.1016/j.automatica.2025.112581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present novel convex optimization formulations for designing full-state and output-feedback controllers with sparse actuation that achieve user-specified H 2 and H ∞ performance criteria. The sparsity is induced through the ℓ 1 -minimization over channel-wise H 2 norms from disturbances to the individual actuator signals, while simultaneously constraining H 2 or H ∞ norm from disturbances to the output variables The proposed approach is applied to a structural dynamics problem, demonstrating the advantages of simultaneous optimization of the control law and the actuation architecture in realizing an efficient closed-loop system, as well as highlighting the trade-offs between maximum allowable actuator magnitudes and the controller sparsity.},
  archive      = {J_AUTOM},
  author       = {Vedang M. Deshpande and Raktim Bhattacharya},
  doi          = {10.1016/j.automatica.2025.112581},
  journal      = {Automatica},
  month        = {1},
  pages        = {112581},
  shortjournal = {Automatica},
  title        = {H2/H∞ state and output feedback control with sparse actuation},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive dynamic event–triggered distributed optimal coordination of heterogeneous uncertain nonlinear multiagent systems. <em>AUTOM</em>, <em>183</em>, 112580. (<a href='https://doi.org/10.1016/j.automatica.2025.112580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed optimal coordination problem for a class of heterogeneous uncertain nonlinear multiagent systems. Instead of relying on the analytical forms of gradient functions, we use the measured gradient values depending on agents’ real-time outputs and propose a novel adaptive distributed control scheme. This scheme integrates event-triggered optimal coordinators, high-order filters, and tracking controllers. To handle the interaction between optimal coordinators and filters, we incorporate a new compensation term into the updating law for the coupling weight of each edge. Moreover, we design a novel adaptive distributed dynamic event-triggering mechanism that ensures that the inter-event times of each agent are lower bounded by a positive constant. Asymptotic convergence of agents’ outputs to the optimal point is proved by constructing a composite Lyapunov function. The proposed control scheme does not depend on global topology information. A numerical example is given to demonstrate the effectiveness of the proposed control scheme.},
  archive      = {J_AUTOM},
  author       = {Tianyu Liu and Lu Liu},
  doi          = {10.1016/j.automatica.2025.112580},
  journal      = {Automatica},
  month        = {1},
  pages        = {112580},
  shortjournal = {Automatica},
  title        = {Adaptive dynamic event–triggered distributed optimal coordination of heterogeneous uncertain nonlinear multiagent systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Accelerated primal–dual methods for strongly convex objective functions in continuous and discrete time. <em>AUTOM</em>, <em>183</em>, 112579. (<a href='https://doi.org/10.1016/j.automatica.2025.112579'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a “second-order primal” + “first-order dual” continuous-time dynamic for linearly constrained optimization problems, where the objective function is μ -strongly convex. We consider a constant damping 2 μ for the second-order ordinary differential equation in the primal variable, following Nesterov’s acceleration for strongly convex optimization. A positive constant scaling is applied to the primal variable, while a positive increasing scaling function is applied to the dual variable. We prove that the proposed dynamic achieves a fast convergence rate for both the objective residual and the feasibility violation, with the decay rate potentially reaching O ( e − μ t ) . Additionally, we show that the dynamic is robust under small perturbations. By discretizing the proposed continuous-time dynamic, we develop an accelerated linearized augmented Lagrangian method for strongly convex composite optimization with linear constraints, where the objective function has a nonsmooth + smooth composite structure. The proposed algorithm achieves a fast convergence rate that matches the one of the continuous-time dynamic. We also consider an inexact version of the proposed algorithm, which can be viewed as a discrete version of the perturbed continuous-time dynamic. Numerical results are provided to verify the practical performances.},
  archive      = {J_AUTOM},
  author       = {Xin He and Dong He and Ya-Ping Fang},
  doi          = {10.1016/j.automatica.2025.112579},
  journal      = {Automatica},
  month        = {1},
  pages        = {112579},
  shortjournal = {Automatica},
  title        = {Accelerated primal–dual methods for strongly convex objective functions in continuous and discrete time},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical supervisory control of networked and cyber-attacked discrete-event systems. <em>AUTOM</em>, <em>183</em>, 112578. (<a href='https://doi.org/10.1016/j.automatica.2025.112578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In standard supervisory control of discrete-event systems, partial (incomplete) observations are given by deterministic functions such as natural projections, which erase unobservable events, or masks, which can represent indistinguishable events, where two or more different events yield the same observation. However, communication channels in modern technological systems are not always reliable and can be attacked by malicious external agents. In that case, the plant observations obtained by the supervisor may not be deterministic, e.g., due to delays and losses, or external attacks. This paper considers a unified supervisory control framework with set-valued (nondeterministic) observations and proposes a simplified version of nondeterministic observability, together with a generalized normality. It shows how the results of hierarchical control can be extended to the networked and cyber-attacked discrete-event systems at the same time.},
  archive      = {J_AUTOM},
  author       = {Shaowen Miao and Jan Komenda and Feng Lin},
  doi          = {10.1016/j.automatica.2025.112578},
  journal      = {Automatica},
  month        = {1},
  pages        = {112578},
  shortjournal = {Automatica},
  title        = {Hierarchical supervisory control of networked and cyber-attacked discrete-event systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the design of linear time varying model predictive control for trajectory stabilization. <em>AUTOM</em>, <em>183</em>, 112577. (<a href='https://doi.org/10.1016/j.automatica.2025.112577'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stabilizing a reference trajectory of a nonlinear system is a recurrent, non-trivial task in control engineering. A common approach is to linearize the dynamics along the trajectory, thus deriving a linear-time-varying (LTV) model, and to design a model predictive controller (MPC), which results to be computationally efficient, since only convex programs need to be solved in real time, while retaining constraint handling capabilities. Building on recent developments in gain-scheduling control design, where linearization errors and tracking error bounds are considered, a new approach to derive such LTV-MPC controllers is presented. The method addresses the systematic derivation of a suitable terminal cost. The resulting MPC law is tube-based, exploiting the co-designed auxiliary gain-scheduled controller. Computational and implementation aspects are discussed as well, and the resulting hierarchical method is demonstrated both in simulation and in experiments with a small drone with fast dynamics and limited embedded computational capacity.},
  archive      = {J_AUTOM},
  author       = {Nicolas Kessler and Lorenzo Fagiano},
  doi          = {10.1016/j.automatica.2025.112577},
  journal      = {Automatica},
  month        = {1},
  pages        = {112577},
  shortjournal = {Automatica},
  title        = {On the design of linear time varying model predictive control for trajectory stabilization},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intersection-based architectures for decentralized diagnosis of discrete event systems. <em>AUTOM</em>, <em>183</em>, 112576. (<a href='https://doi.org/10.1016/j.automatica.2025.112576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, two intersection-based architectures, named the normal-state-estimator-intersection-based architecture (N-SEI architecture) and the failure-state-estimator-intersection-based architecture (F-SEI architecture), are examined for decentralized diagnosis of discrete event systems. For each of these architectures, the corresponding notion of codiagnosability is defined. These defined notions of codiagnosability are incomparable with inference diagnosability for the inference-based architecture. In addition, codiagnosability for the N-SEI architecture is weaker than the existing notion of intersection-based codiagnosability, while codiagnosability for the F-SEI architecture is incomparable with it. For each of the N-SEI and F-SEI architectures, a method for verifying the corresponding notion of codiagnosability is developed.},
  archive      = {J_AUTOM},
  author       = {Shigemasa Takai and Takashi Yamamoto},
  doi          = {10.1016/j.automatica.2025.112576},
  journal      = {Automatica},
  month        = {1},
  pages        = {112576},
  shortjournal = {Automatica},
  title        = {Intersection-based architectures for decentralized diagnosis of discrete event systems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed stochastic constrained optimization with constant step-sizes via saddle-point dynamics. <em>AUTOM</em>, <em>183</em>, 112575. (<a href='https://doi.org/10.1016/j.automatica.2025.112575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers distributed stochastic optimization problems over a multi-agent network, where each agent collaboratively minimizes the sum of individual expectation-valued cost functions subject to nonidentical set constraints. We first recast the distributed constrained optimization as a constrained saddle-point problem. Subsequently, two distributed stochastic algorithms via optimistic gradient descent ascent (SOGDA) and extragradient (SEG) methods are developed with constant step sizes, in which the variable sample-size technique is incorporated to reduce the variance of the sampled gradients. We present the explicit selection criteria of the constant step size, under which the developed algorithms achieve almost sure convergence to an optimal solution. Moreover, the convergence rate is O ( 1 / k ) for merely convex cost functions, which matches the optimal rate of its deterministic counterpart. Finally, a numerical example is provided to reflect the theoretical findings.},
  archive      = {J_AUTOM},
  author       = {Yi Huang and Shisheng Cui and Xianlin Zeng and Ziyang Meng},
  doi          = {10.1016/j.automatica.2025.112575},
  journal      = {Automatica},
  month        = {1},
  pages        = {112575},
  shortjournal = {Automatica},
  title        = {Distributed stochastic constrained optimization with constant step-sizes via saddle-point dynamics},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A characterization method of terminal ingredients for nonlinear MPC using value-based reinforcement learning. <em>AUTOM</em>, <em>183</em>, 112574. (<a href='https://doi.org/10.1016/j.automatica.2025.112574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stability of nonlinear model predictive control (MPC) relies significantly on stabilizing factors such as the terminal region and cost. A larger terminal region not only expands the region of attraction for the closed-loop system but also contributes to reducing online computation costs. However, existing methods in the literature often impose limitations on the degrees of freedom available for characterizing terminal ingredients. This limitation arises from the reliance on either a predetermined linear local controller or a preset control Lyapunov function. This paper introduces an innovative approach to terminal ingredient characterization leveraging value-based reinforcement learning (RL). This method provides ample degrees of freedom for expanding the terminal region. To achieve this, a deep neural network is employed to learn the parametric state value function, serving as the terminal cost for MPC. The local controller adopts a one-step MPC instead of a predetermined linear or nonlinear feedback controller. Subsequently, a terminal set sequence is constructed iteratively through the one-step set expansion. The proposed approach’s effectiveness is validated through simulations.},
  archive      = {J_AUTOM},
  author       = {Jinghan Cui and Jinwu Gao and Xiangjie Liu and Yuqi Liu and Shuyou Yu},
  doi          = {10.1016/j.automatica.2025.112574},
  journal      = {Automatica},
  month        = {1},
  pages        = {112574},
  shortjournal = {Automatica},
  title        = {A characterization method of terminal ingredients for nonlinear MPC using value-based reinforcement learning},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Aperiodic-sampled neural network controllers with closed-loop stability verifications. <em>AUTOM</em>, <em>183</em>, 112573. (<a href='https://doi.org/10.1016/j.automatica.2025.112573'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we synthesize two aperiodic-sampled deep neural network (DNN) control schemes, based on the closed-loop tracking stability guarantees. By means of the integral quadratic constraint coping with the input–output behavior of system uncertainties/nonlinearities and the convex relaxations of nonlinear DNN activations leveraging their local sector-bounded attributes, we establish conditions to design the event- and self-triggered logics and to compute the ellipsoidal inner approximations of region of attraction, respectively. Finally, we perform a numerical example of an inverted pendulum to illustrate the effectiveness of the proposed aperiodic-sampled DNN control schemes.},
  archive      = {J_AUTOM},
  author       = {Renjie Ma and Zhijian Hu and Rongni Yang and Ligang Wu},
  doi          = {10.1016/j.automatica.2025.112573},
  journal      = {Automatica},
  month        = {1},
  pages        = {112573},
  shortjournal = {Automatica},
  title        = {Aperiodic-sampled neural network controllers with closed-loop stability verifications},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Backstepping for partial differential equations: A survey. <em>AUTOM</em>, <em>183</em>, 112572. (<a href='https://doi.org/10.1016/j.automatica.2025.112572'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systems modeled by partial differential equations (PDEs) are at least as ubiquitous as those by nature finite-dimensional and modeled by ordinary differential equations (ODEs). And yet, systematic and readily usable methodologies, for such a significant portion of real systems, have been historically scarce. Around the year 2000, the backstepping approach to PDE control began to offer not only a less abstract alternative to PDE control techniques replicating optimal and spectrum assignment techniques of the 1960s, but also enabled the methodologies of adaptive and nonlinear control, matured in the 1980s and 1990s, to be extended from ODEs to PDEs, allowing feedback synthesis for systems that are uncertain, nonlinear, and infinite-dimensional. The PDE backstepping literature has since grown to hundreds of papers and nearly a dozen books. This survey aims to facilitate the entry into this thriving area of overwhelming size and topical diversity. Designs of controllers and observers, for parabolic, hyperbolic, and other classes of PDEs, in one or more dimensions, with nonlinear, adaptive, sampled-data, and event-triggered extensions, are covered in the survey. The lifeblood of control are technology and physics. The survey places a particular emphasis on applications that have motivated the development of the theory and which have benefited from the theory and designs: flows, flexible structures, materials, thermal and chemically reacting dynamics, energy (from oil drilling to batteries and magnetic confinement fusion), and vehicles.},
  archive      = {J_AUTOM},
  author       = {Rafael Vazquez and Jean Auriol and Federico Bribiesca-Argomedo and Miroslav Krstic},
  doi          = {10.1016/j.automatica.2025.112572},
  journal      = {Automatica},
  month        = {1},
  pages        = {112572},
  shortjournal = {Automatica},
  title        = {Backstepping for partial differential equations: A survey},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Maximum principle for partial information non-zero sum stochastic differential games with mixed delays. <em>AUTOM</em>, <em>183</em>, 112570. (<a href='https://doi.org/10.1016/j.automatica.2025.112570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with one kind of partial information non-zero sum stochastic differential game with mixed delays. Both the state and control processes contain delays, where the former contains moving-average delay, discrete delay and noisy memory. We establish a necessary as well as two sufficient stochastic maximum principles for the game. As one of the main features of this research, a new kind of sufficient maximum principle is given, where the diffusion term can be controlled with non-convex control domains, and no second-order adjoint equation is needed. The theoretical results are applied to study two examples where the adjoint processes can be derived by two approaches and then the equilibrium points are obtained. This research generalizes those of stochastic optimal control problems.},
  archive      = {J_AUTOM},
  author       = {Pan Chen and Feng Zhang},
  doi          = {10.1016/j.automatica.2025.112570},
  journal      = {Automatica},
  month        = {1},
  pages        = {112570},
  shortjournal = {Automatica},
  title        = {Maximum principle for partial information non-zero sum stochastic differential games with mixed delays},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). State estimation for lithium-ion batteries based on electrolyte–electrode PDE observers. <em>AUTOM</em>, <em>183</em>, 112568. (<a href='https://doi.org/10.1016/j.automatica.2025.112568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate information about the states of an electrochemical battery model facilitates a deeper understanding of battery behavior and enables performance enhancement. This paper first proposes backstepping Partial Differential Equation (PDE) observers for lithium concentration in the electrolyte phase within the negative electrode, positive electrode, and separator. Reverse sensitivity analysis is conducted to identify the most suitable measurable parameter for obtaining the electrolyte lithium concentration at the boundaries, which is used in the design of the electrolyte-phase observer. Subsequently, enhanced observers for the solid-phase lithium concentration in the negative and positive electrodes are developed. The proposed solid-phase observer enables more accurate State-of-Charge (SoC) estimation by leveraging the closed-loop electrolyte-phase observer. Simulations of the reverse sensitivity analysis and state observers are performed on a commercial cylindrical lithium iron phosphate ( LiFePO 4 ) cell to validate the effectiveness of the proposed approach.},
  archive      = {J_AUTOM},
  author       = {Sara Sepasiahooyi and Shu-Xia Tang},
  doi          = {10.1016/j.automatica.2025.112568},
  journal      = {Automatica},
  month        = {1},
  pages        = {112568},
  shortjournal = {Automatica},
  title        = {State estimation for lithium-ion batteries based on electrolyte–electrode PDE observers},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interval-constraint multiagent systems: Global attractivity and structural stability of equilibria. <em>AUTOM</em>, <em>183</em>, 112566. (<a href='https://doi.org/10.1016/j.automatica.2025.112566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the dynamic behavior of an interval-constraint multiagent system. Each agent has a constraint interval that limits its potential consensus values, achieved by encoding a nonsmooth piecewise function into the agent. In addition, the underlying graphs considered are strongly connected. First, a dichotomy of equilibria is identified: either a unique non-consensus equilibrium point or multiple consensus points, depending on whether the intersection of the constraint intervals is empty or not. Then, the set of equilibria is proven to be a global attractor. Structural stability of such a system is also proven based on real-analysis methods, showing that the equilibria have continuous dependence on changes of the constraint intervals. Three running examples are used to illustrate the proposed results.},
  archive      = {J_AUTOM},
  author       = {Fengqiu Liu and Kuize Zhang and Yuhu Wu and Xiaoping Xue},
  doi          = {10.1016/j.automatica.2025.112566},
  journal      = {Automatica},
  month        = {1},
  pages        = {112566},
  shortjournal = {Automatica},
  title        = {Interval-constraint multiagent systems: Global attractivity and structural stability of equilibria},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Closed-loop data-enabled predictive control and its equivalence with closed-loop subspace predictive control. <em>AUTOM</em>, <em>183</em>, 112556. (<a href='https://doi.org/10.1016/j.automatica.2025.112556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factors like growing data availability and increasing system complexity have sparked interest in data-driven predictive control (DDPC) methods like Data-enabled Predictive Control (DeePC). However, closed-loop identification bias arises in the presence of noise, which reduces the effectiveness of obtained control policies. In this paper we propose Closed-loop Data-enabled Predictive Control (CL-DeePC), a framework that unifies different approaches to address this challenge. To this end, CL-DeePC incorporates instrumental variables (IVs) to synthesize and sequentially apply consistent single or multi-step-ahead predictors. Furthermore, a computationally efficient CL-DeePC implementation is developed that reveals an equivalence with Closed-loop Subspace Predictive Control (CL-SPC). Time marching simulations of DeePC and CL-DeePC are conducted using Hankel matrices of past data that are updated at every time step to induce potentially troublesome closed-loop correlations between inputs and noise. Compared to DeePC, CL-DeePC simulations demonstrate superior reference tracking, with a sensitivity study finding a 48% lower susceptibility to noise-induced reference tracking performance degradation.},
  archive      = {J_AUTOM},
  author       = {Rogier Dinkla and Tom Oomen and Sebastiaan Paul Mulders and Jan-Willem van Wingerden},
  doi          = {10.1016/j.automatica.2025.112556},
  journal      = {Automatica},
  month        = {1},
  pages        = {112556},
  shortjournal = {Automatica},
  title        = {Closed-loop data-enabled predictive control and its equivalence with closed-loop subspace predictive control},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Byzantine-resilient federated online learning for gaussian process regression. <em>AUTOM</em>, <em>183</em>, 112554. (<a href='https://doi.org/10.1016/j.automatica.2025.112554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study Byzantine-resilient federated online learning for Gaussian process regression (GPR). We develop a Byzantine-resilient federated GPR algorithm that allows a cloud and a group of agents to collaboratively learn a latent function and improve the learning performances where some agents exhibit Byzantine failures, i.e., arbitrary and potentially adversarial behavior. Each agent-based local GPR sends potentially compromised local predictions to the cloud, and the cloud-based aggregated GPR computes a global model by a Byzantine-resilient product of experts aggregation rule. Then the cloud broadcasts the current global model to all the agents. Agent-based fused GPR refines local predictions by fusing the received global model with that of the agent-based local GPR. Moreover, we quantify the learning accuracy improvements of the agent-based fused GPR over the agent-based local GPR. Experiments on a toy example and two medium-scale real-world datasets are conducted to demonstrate the performances of the proposed algorithm.},
  archive      = {J_AUTOM},
  author       = {Xu Zhang and Zhenyuan Yuan and Minghui Zhu},
  doi          = {10.1016/j.automatica.2025.112554},
  journal      = {Automatica},
  month        = {1},
  pages        = {112554},
  shortjournal = {Automatica},
  title        = {Byzantine-resilient federated online learning for gaussian process regression},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Observer-based asymptotic active fault diagnosis: Separate and joint design of observer gain and input. <em>AUTOM</em>, <em>183</em>, 112548. (<a href='https://doi.org/10.1016/j.automatica.2025.112548'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes observer gain and input design methods for observer-based asymptotic active fault diagnosis, which are based on a newly-defined notion named the excluding degree of the origin from a zonotope. Using the excluding degree, a quantitative specification is obtained to characterize the performance of set-based robust fault diagnosis. Furthermore, a separate gain design method and a joint gain and input design method are proposed, respectively. This is the first work to achieve a joint observer gain and input design for set-based active fault diagnosis. Compared with the existing methods that design gains and input separately, the proposed joint gain and input design method has advantages to exploit the fault diagnosis potential of observer-based schemes. Finally, several examples are used to illustrate the effectiveness of the proposed methods.},
  archive      = {J_AUTOM},
  author       = {Feng Xu and Yiming Wan and Ye Wang and Vicenç Puig},
  doi          = {10.1016/j.automatica.2025.112548},
  journal      = {Automatica},
  month        = {1},
  pages        = {112548},
  shortjournal = {Automatica},
  title        = {Observer-based asymptotic active fault diagnosis: Separate and joint design of observer gain and input},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Controller synthesis from noisy-input noisy-output data. <em>AUTOM</em>, <em>183</em>, 112545. (<a href='https://doi.org/10.1016/j.automatica.2025.112545'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of synthesizing a dynamic output-feedback controller for a linear system, using solely input–output data corrupted by measurement noise. To handle input–output data, an auxiliary representation of the original system is utilized. By exploiting the structure of the auxiliary system, we design a controller that robustly stabilizes all possible systems consistent with data. Notably, we also provide a novel solution to extend the results to generic multi-input multi-output systems. The findings are illustrated by numerical examples.},
  archive      = {J_AUTOM},
  author       = {Lidong Li and Andrea Bisoffi and Claudio De Persis and Nima Monshizadeh},
  doi          = {10.1016/j.automatica.2025.112545},
  journal      = {Automatica},
  month        = {1},
  pages        = {112545},
  shortjournal = {Automatica},
  title        = {Controller synthesis from noisy-input noisy-output data},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Accuracy bounds for the simulation of a class of continuous-time nonlinear models. <em>AUTOM</em>, <em>183</em>, 112543. (<a href='https://doi.org/10.1016/j.automatica.2025.112543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world dynamic systems evolve in the continuous-time world, while their models are simulated in the digital world using discrete-time numerical simulation algorithms. Such simulation is essential for a variety of system and control problems such as system identification and performance analysis of (control) systems. Ideally, the simulated model response should be identical to the system response. However, this is typically not the case in practice, even when the effects of unmodelled dynamics and parametric uncertainty are excluded. Even in that scenario, a mismatch exists between the response of the system and the model due to the interface between the physical world and the digital computer, unknown disturbances, and simulation inaccuracies. For the class of continuous-time, nonlinear Lur’e-type systems, this paper analyses the mismatch between the steady-state system response and the steady-state model response computed using the so-called mixed time–frequency algorithm. Firstly, a bound on the mismatch between the steady-state system response and the computed steady-state model response based on continuous-time signals is derived. Secondly, a bound for the same mismatch is derived for a sampled version of the signals. The bounds are further decomposed into several components, each given an interpretation that can be used to reduce the bounds on the mismatch. In a numerical case study, we show that reducing the bounds also reduces the actual mismatch.},
  archive      = {J_AUTOM},
  author       = {Fahim Shakib and Johan Schoukens and Alexander Yu. Pogromsky and Alexey Pavlov and Nathan van de Wouw},
  doi          = {10.1016/j.automatica.2025.112543},
  journal      = {Automatica},
  month        = {1},
  pages        = {112543},
  shortjournal = {Automatica},
  title        = {Accuracy bounds for the simulation of a class of continuous-time nonlinear models},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revisiting lossless convexification: Theoretical guarantees for discrete-time optimal control problems. <em>AUTOM</em>, <em>183</em>, 112537. (<a href='https://doi.org/10.1016/j.automatica.2025.112537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lossless Convexification (LCvx) is a modeling approach that transforms a class of nonconvex optimal control problems, where nonconvexity primarily arises from control constraints, into convex problems through convex relaxations. These convex problems can be solved using polynomial-time numerical methods after discretization, which converts the original infinite-dimensional problem into a finite-dimensional one. However, existing LCvx theory is limited to continuous-time optimal control problems, as the equivalence between the relaxed convex problem and the original nonconvex problem holds only in continuous-time. This paper extends LCvx theory to discrete-time optimal control problems by classifying them into normal and long-horizon cases. For normal cases, after an arbitrarily small perturbation to the system dynamics (recursive equality constraints), applying the existing LCvx method to discrete-time problems results in optimal controls that meet the original nonconvex constraints at all but no more than n x − 1 temporal grid points, where n x is the state dimension. For long-horizon cases, the existing LCvx method fails, but we resolve this issue by integrating it with a bisection search, leveraging the continuity of the value function from the relaxed convex problem to achieve similar results as in normal cases. This paper strengthens the theoretical foundation of LCvx, extending the applicability of LCvx theory to discrete-time optimal control problems.},
  archive      = {J_AUTOM},
  author       = {Dayou Luo and Kazuya Echigo and Behçet Açıkmeşe},
  doi          = {10.1016/j.automatica.2025.112537},
  journal      = {Automatica},
  month        = {1},
  pages        = {112537},
  shortjournal = {Automatica},
  title        = {Revisiting lossless convexification: Theoretical guarantees for discrete-time optimal control problems},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated cubic regularized newton learning with sparsification-amplified differential privacy. <em>AUTOM</em>, <em>183</em>, 112531. (<a href='https://doi.org/10.1016/j.automatica.2025.112531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the cubic-regularized Newton method within a federated learning framework while addressing two major concerns: privacy leakage and communication bottlenecks. We propose the Differentially Private Federated Cubic Regularized Newton (DP-FCRN) algorithm, which leverages second-order techniques to achieve lower iteration complexity than first-order methods. We incorporate noise perturbation during local computations to ensure privacy. Furthermore, we employ sparsification in uplink transmission, which not only reduces the communication costs but also amplifies the privacy guarantee. Specifically, this approach reduces the necessary noise intensity without compromising privacy protection. We analyze the convergence properties of our algorithm and establish the privacy guarantee. Finally, we validate the effectiveness of the proposed algorithm through experiments on a benchmark dataset.},
  archive      = {J_AUTOM},
  author       = {Wei Huo and Changxin Liu and Kemi Ding and Karl Henrik Johansson and Ling Shi},
  doi          = {10.1016/j.automatica.2025.112531},
  journal      = {Automatica},
  month        = {1},
  pages        = {112531},
  shortjournal = {Automatica},
  title        = {Federated cubic regularized newton learning with sparsification-amplified differential privacy},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A consensus kalman filter on l2 spaces. <em>AUTOM</em>, <em>183</em>, 112530. (<a href='https://doi.org/10.1016/j.automatica.2025.112530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the estimation problem of infinite dimensional discrete-time stochastic linear systems with finite dimensional measurements on sensor networks modeled by connected undirected graphs. The framework encompasses discretized PDEs with sampled measurements. A new scheme of distributed consensus on measurements is extended to systems evolving in L 2 spaces in order to limit the information exchange to finite-dimensional vectors. We show that, in analogy to the finite-dimensional case, at each node the variance of the estimation error tends to the one of the centralized Kalman filter for systems is L 2 when the number of consensus steps increases.},
  archive      = {J_AUTOM},
  author       = {Stefano Battilotti and Alessandro Borri and Filippo Cacace and Massimiliano d’Angelo and Alfredo Germani},
  doi          = {10.1016/j.automatica.2025.112530},
  journal      = {Automatica},
  month        = {1},
  pages        = {112530},
  shortjournal = {Automatica},
  title        = {A consensus kalman filter on l2 spaces},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed-time learning for safe time-critical verification using reachability analysis. <em>AUTOM</em>, <em>183</em>, 112528. (<a href='https://doi.org/10.1016/j.automatica.2025.112528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address a safe time-critical control problem using reachability analysis and design a reinforcement learning-based mechanism for learning online and in fixed-time the solution to the safe time-critical control problem. Safety is ensured by determining a set of states for which there exists an admissible control law generating a system trajectory that does not reach a set of forbidden states at a user-prescribed time instant. Specifically, we cast our safe time-critical problem as a Mayer optimal feedback control problem whose solution satisfies the Hamilton–Jacobi–Bellman (HJB) equation and characterizes the set of safe states. Since the HJB equation is generally difficult to solve, we develop an online critic-only reinforcement learning-based algorithm for simultaneously learning the solution to the HJB equation and the safe set in a fixed time. In particular, we introduce a non-Lipschitz experience replay-based learning law utilizing recorded and current data for updating the critic weights to learn the value function and the safe set. The non-Lipschitz property of the dynamics gives rise to fixed-time convergence, whereas the experience replay-based approach eliminates the need to satisfy the persistence of excitation condition provided that a recorded data set is sufficiently rich. Simulation results illustrate the efficacy of the proposed approach to the problem of fixed-wing unmanned aerial vehicle collision avoidance.},
  archive      = {J_AUTOM},
  author       = {Nick-Marios T. Kokolakis and Kyriakos G. Vamvoudakis and Wassim M. Haddad},
  doi          = {10.1016/j.automatica.2025.112528},
  journal      = {Automatica},
  month        = {1},
  pages        = {112528},
  shortjournal = {Automatica},
  title        = {Fixed-time learning for safe time-critical verification using reachability analysis},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Orchestrating on-board sensors for global hybrid robust stabilization of unicycles. <em>AUTOM</em>, <em>183</em>, 112502. (<a href='https://doi.org/10.1016/j.automatica.2025.112502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider mobile robots described through unicycle dynamics equipped with on-board range sensors and cameras, one facing forward and one facing backward, providing measurements of the distance and misalignment to a target. We propose a hybrid control law combining the two on-board measurements and discuss stability results for the closed-loop expressed in the on-board camera-based coordinates, using Lyapunov-based arguments. We prove robustness of the stability properties to uncertainties affecting the sensors and external perturbations acting on the robot. The results are illustrated via simulations.},
  archive      = {J_AUTOM},
  author       = {Riccardo Ballaben and Alessandro Astolfi and Philipp Braun and Luca Zaccarian},
  doi          = {10.1016/j.automatica.2025.112502},
  journal      = {Automatica},
  month        = {1},
  pages        = {112502},
  shortjournal = {Automatica},
  title        = {Orchestrating on-board sensors for global hybrid robust stabilization of unicycles},
  volume       = {183},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="cma">CMA - 14</h2>
<ul>
<li><details>
<summary>
(2025). An averaged l1 ADI compact difference scheme for the three-dimensional time-fractional mobile/immobile transport equation with weakly singular solutions. <em>CMA</em>, <em>200</em>, 102-116. (<a href='https://doi.org/10.1016/j.camwa.2025.09.019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a three-dimensional (3D) time-fractional mobile/immobile (MIM) transport equation, which incorporates the Caputo time-fractional derivative of order α ∈ ( 0 , 1 ) , is taken into consideration. The space derivatives are discretized using the compact finite difference approximation, and the Caputo time-fractional derivative is estimated by employing the averaged L1 formula. Combining with corresponding alternating direction implicit (ADI) algorithms, the overall computational cost is reduced significantly. Using the discrete energy analysis methodology, we demonstrate that the suggested method possesses temporal second-order convergence and spatial fourth-order convergence under the regularity assumption. Numerical experiments demonstrate that ADI techniques is effective in computing 3D problems.},
  archive      = {J_CMA},
  author       = {Kai Liu and Haixiang Zhang and Xuehua Yang},
  doi          = {10.1016/j.camwa.2025.09.019},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {102-116},
  shortjournal = {Comput. Meth. Appl.},
  title        = {An averaged l1 ADI compact difference scheme for the three-dimensional time-fractional mobile/immobile transport equation with weakly singular solutions},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pricing american options with exogenous and endogenous transaction costs. <em>CMA</em>, <em>200</em>, 85-101. (<a href='https://doi.org/10.1016/j.camwa.2025.09.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an American option pricing problem with liquidity risks and transaction fees. As endogenous transaction costs, liquidity risks of the underlying asset are modeled by a mean-reverting process. Transaction fees are exogenous transaction costs and are assumed to be proportional to the trading amount, with the long-run liquidity level depending on the proportional transaction costs rate. Two nonlinear partial differential equations are established to characterize the option values for the holder and the writer, respectively. To illustrate the impact of these transaction costs on option prices and optimal exercise prices, we apply the alternating direction implicit method to solve the linear complementarity problem numerically. Finally, we conduct model calibration from market data via maximum likelihood estimation, and find that our model incorporating liquidity risks outperforms the Leland model significantly.},
  archive      = {J_CMA},
  author       = {Dong Yan and Xin-Jie Huang and Guiyuan Ma and Xin-Jiang He},
  doi          = {10.1016/j.camwa.2025.09.008},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {85-101},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Pricing american options with exogenous and endogenous transaction costs},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A space-time discontinuous petrov-galerkin finite element formulation for a modified schrödinger equation for laser pulse propagation in waveguides. <em>CMA</em>, <em>200</em>, 67-84. (<a href='https://doi.org/10.1016/j.camwa.2025.09.004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a modified nonlinear Schrödinger equation for modeling pulse propagation in optical waveguides. The proposed model bifurcates into a system of elliptic and hyperbolic equations depending on waveguide parameters. The proposed model leads to a stable first-order system of equations, distinguishing itself from the canonical nonlinear Schrödinger equation. We have employed the space-time discontinuous Petrov-Galerkin finite element method to discretize the first-order system of equations. We present a stability analysis for both the elliptic and hyperbolic systems of equations and demonstrate the stability of the proposed model through several numerical examples on space-time meshes.},
  archive      = {J_CMA},
  author       = {A. Chakraborty and J. Muñoz-Matute and L. Demkowicz and J. Grosek},
  doi          = {10.1016/j.camwa.2025.09.004},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {67-84},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A space-time discontinuous petrov-galerkin finite element formulation for a modified schrödinger equation for laser pulse propagation in waveguides},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence analysis of an energy-stable linearized virtual element method for the strongly damped klein-gordon equation. <em>CMA</em>, <em>200</em>, 49-66. (<a href='https://doi.org/10.1016/j.camwa.2025.09.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose and analyze an efficient, linearized, fully discrete scheme for the nonlinear, strongly damped Klein-Gordon equation on polygonal meshes. The numerical scheme uses a conforming virtual element method for spatial discretization and a modified leapfrog (central finite difference) scheme for time discretization, with the nonlinear term | u | p − 1 u is treated semi-implicitly. We first prove that the proposed scheme is energy dissipative in the sense of discrete energy, and then the stability of the numerical solution in the H 1 -norm is established using mathematical induction, which plays an important role in handling the nonlinear term. By applying the boundedness of the numerical solution and the Sobolev embedding inequality, we derive the optimal H 1 error estimate of order O ( h k + τ 2 ) without imposing any ratio restrictions between the time step τ and the mesh size h . Additionally, we remark that the leapfrog virtual element scheme can be applied to some more complex nonlinear damped wave equations. Finally, some numerical examples are provided to confirm the theoretical results.},
  archive      = {J_CMA},
  author       = {Zhixin Liu and Minghui Song and Yuhang Zhang},
  doi          = {10.1016/j.camwa.2025.09.002},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {49-66},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Convergence analysis of an energy-stable linearized virtual element method for the strongly damped klein-gordon equation},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A posteriori error estimate of the discontinuous galerkin method with lagrange multiplier for elliptic problems. <em>CMA</em>, <em>200</em>, 38-48. (<a href='https://doi.org/10.1016/j.camwa.2025.09.005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to derive and analyze an a posteriori error estimator for the solution of the discontinuous Galerkin method with Lagrange multiplier (DGLM) for the elliptic problems with nonhomogeneous Dirichlet boundary condition u = g for g in H 1 / 2 ( ∂ Ω ) . A general version of the DGLM method is derived. Strong stability of the solution of the DGLM method is proved. Edgewise iterative scheme for the general DGLM method is described.},
  archive      = {J_CMA},
  author       = {Mi-Young Kim},
  doi          = {10.1016/j.camwa.2025.09.005},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {38-48},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A posteriori error estimate of the discontinuous galerkin method with lagrange multiplier for elliptic problems},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability and convergence analysis of mixed finite element approximations for a biot-brinkman model. <em>CMA</em>, <em>200</em>, 22-37. (<a href='https://doi.org/10.1016/j.camwa.2025.09.006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many multiphysics processes of fluid-solid interaction within a porous medium can be described by the Biot-Brinkman model to account for the effects of viscosity in fluid flow. By introducing the auxiliary variables, we can transform the original problem into two generalized Stokes equations. The generalized Stokes equations incorporate a built-in mechanism to circumvent the Poisson locking for the continuous Galerkin method. Subsequently, we establish an energy law and provide a priori estimates for the reformulated problem. Well-posedness is demonstrated using the standard Galerkin method in conjunction with a compactness argument. After that, we develop stable mixed finite element algorithms for the reformulated problem. Influenced by Lamé constant λ , we design three finite element pairs for the proposed algorithms and present the corresponding error estimates. Numerical tests are conducted to validate the theoretical results.},
  archive      = {J_CMA},
  author       = {Wenlong He and Jiwei Zhang},
  doi          = {10.1016/j.camwa.2025.09.006},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {22-37},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Stability and convergence analysis of mixed finite element approximations for a biot-brinkman model},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed neural network for option pricing weather derivatives model. <em>CMA</em>, <em>200</em>, 1-21. (<a href='https://doi.org/10.1016/j.camwa.2025.09.001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weather derivatives are financial tools that use a weather index as the underlying asset to provide protection against non-catastrophic weather events. In this article, we propose a physics-informed neural network (PINN) approach for pricing weather derivatives associated with two standard processes: the Ornstein-Uhlenbeck process and the Ornstein-Uhlenbeck process with jump-diffusions. PINNs are a scientific machine learning method specifically designed to address problems related to partial differential equations (PDEs). To apply the PINN technique for jump-diffusion, we convert the partial integro-differential equation into a PDE using integral discretization. We randomly select training data points within the domain and utilize the transformed PDE along with the initial and boundary conditions to construct the loss function. For the neurons in the hidden layer, we employ the hyperbolic tangent function (tanh) as the activation function. The weights of the network connection are optimized using the L-BFGS algorithm. We will conduct numerical experiments to evaluate the efficiency of the proposed technique. Additionally, we compare our method with conventional numerical approaches to show that our technique serves as an effective alternative to existing pricing methods for weather derivatives. Finally, we will examine a real-world case study where the model's parameters are determined using precipitation data.},
  archive      = {J_CMA},
  author       = {Saurabh Bansal and Pradanya Boro and Srinivasan Natesan},
  doi          = {10.1016/j.camwa.2025.09.001},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {1-21},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Physics-informed neural network for option pricing weather derivatives model},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shape derivative of the laplacian eigenvalue problem. <em>CMA</em>, <em>199</em>, 127-147. (<a href='https://doi.org/10.1016/j.camwa.2025.09.013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Laplacian eigenvalue problem with two different densities is investigated. By the squeeze theorem, the shape derivative of the least eigenvalue on the interface of two different density subdomains is derived. As an application, the minimization of the least eigenvalue with area constraint is considered. The shape derivative of the objective functional is applied as the velocity for the level set method to involve the interface. The numerical results validate that the proposed method is effective to capture the final optimized distribution of two different densities.},
  archive      = {J_CMA},
  author       = {Zhengfang Zhang and Lulu Guo and Xiangjing Gao and Weifeng Chen and Xiaoliang Cheng},
  doi          = {10.1016/j.camwa.2025.09.013},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {127-147},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Shape derivative of the laplacian eigenvalue problem},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regular boundary element method for composite shear deformable plate and shell. <em>CMA</em>, <em>199</em>, 106-126. (<a href='https://doi.org/10.1016/j.camwa.2025.09.016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a fundamental solution for a double-curvature simply supported shell, incorporating three concentrated forces and two bending moments. It introduces the reference domain concept and formulates fictitious load boundary integral equations using both constant and linear elements. These equations are developed in the Laplace transform domain for both static and dynamic problems. The key contribution of this study is the development of the Regular Boundary Element Method (RBEM) based on the new fundamental solution. The reference domain includes the real structure’s configuration, and a system of linear equations is established with fictitious forces and moments as unknowns. These equations are derived from traction and displacement boundary conditions. To obtain all physical values in the time domain, the Durbin’s Laplace inverse technique is applied. The accuracy and reliability of the proposed method are evaluated through four numerical examples, with results compared against exact solutions or the finite element method.},
  archive      = {J_CMA},
  author       = {W. Huang and X.B. Yan and J.X. Liao and L.K. Feng and P.H. Wen},
  doi          = {10.1016/j.camwa.2025.09.016},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {106-126},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Regular boundary element method for composite shear deformable plate and shell},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Source point selection in the MFS using orthogonal matching pursuit: Two-dimensional elastic wave scattering by a rectangular cavity. <em>CMA</em>, <em>199</em>, 80-105. (<a href='https://doi.org/10.1016/j.camwa.2025.09.003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we apply orthogonal matching pursuit (OMP) to the source point selection in the method of fundamental solutions (MFS) and discuss its effectiveness. The proposed method initially places an excess number of source points relative to the collocation points within the complementary domain of the analysis region and then selects the source points that efficiently reduce the residual of the system of equations. We apply the proposed method to two-dimensional elastic wave scattering by a rectangular cavity, a well-known challenging problem in MFS analysis. Numerical examples demonstrate the effectiveness of the proposed method by comparing its performance with the conventional MFS using truncated singular value decomposition (TSVD). The proposed method provides solutions that more accurately satisfy the traction-free boundary conditions compared to the conventional method, indicating its potential advantages.},
  archive      = {J_CMA},
  author       = {Akira Furukawa},
  doi          = {10.1016/j.camwa.2025.09.003},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {80-105},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Source point selection in the MFS using orthogonal matching pursuit: Two-dimensional elastic wave scattering by a rectangular cavity},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A DOFs condensation based algorithm for solving saddle point systems in 2D contact computation. <em>CMA</em>, <em>199</em>, 64-79. (<a href='https://doi.org/10.1016/j.camwa.2025.08.032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In contact mechanics computation, the constraint conditions on the contact surfaces are typically enforced by the Lagrange multiplier method, resulting in a saddle point system. The mortar finite element method is usually employed to discretize the variational form on the meshed contact surfaces, yielding a large-scale discretized saddle point system. Due to the indefiniteness of the discretized system, it is a challenge to solve the saddle point algebraic system. For two-dimensional tied contact problem, we develop an efficient algorithm based on degree-of-freedom (DOF) condensation. In this approach, a DOFs elimination process is first performed by exploiting the tridiagonal structure of the mortar matrix. The reduced linear system, now smaller in scale and symmetric positive definite (SPD), is then solved using the preconditioned conjugate gradient (PCG) method. Numerical results demonstrate the effectiveness of the algorithm.},
  archive      = {J_CMA},
  author       = {Xiaoyu Duan and Zihan Wang and Hengbin An and Zeyao Mo},
  doi          = {10.1016/j.camwa.2025.08.032},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {64-79},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A DOFs condensation based algorithm for solving saddle point systems in 2D contact computation},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven SFB solutions and parameters discovery for nonlinear schrödinger equation via time domain decomposition physics-informed neural networks. <em>CMA</em>, <em>199</em>, 45-63. (<a href='https://doi.org/10.1016/j.camwa.2025.09.007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we integrate domain decomposition techniques into the classical physics-informed neural networks (PINNs) by introducing interface training points, and propose a time domain decomposition PINNs (TDD-PINNs) framework. This model is applied to investigate the dynamic behaviour of solitons on finite background (SFB) solutions and parameter discovery in the nonlinear Schrödinger equation (NLSE). The TDD-PINNs is employed to study various SFB solutions, including the Akhmediev breather, Peregrine soliton, Kuznetsov-Ma soliton, as well as second- and third-order rogue waves. Experimental results demonstrate that, compared to classical PINNs, the proposed TDD-PINNs significantly reduce training time and improve prediction accuracy by one to two orders of magnitude. For inverse problems, the TDD-PINNs algorithm can accurately identify unknown parameters in the NLSE, both under noisy and noise-free conditions, addressing the complete failure of classical PINNs in parameter identification for NLSE and demonstrating strong robustness.},
  archive      = {J_CMA},
  author       = {Jiaxin Chen and Biao Li and Manwai Yuen},
  doi          = {10.1016/j.camwa.2025.09.007},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {45-63},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Data-driven SFB solutions and parameters discovery for nonlinear schrödinger equation via time domain decomposition physics-informed neural networks},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixed nitsche extended finite element method for solving three-dimensional h(curl)-elliptic interface problems. <em>CMA</em>, <em>199</em>, 22-44. (<a href='https://doi.org/10.1016/j.camwa.2025.08.031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a Lagrange multiplier to relax the divergence-free constraint and propose a mixed Nitsche extended finite element method for solving three-dimensional H(curl)-elliptic interface problems. To ensure stability, we incorporate ghost penalty terms. By exploiting the commuting relationship of the de Rham complex, we derive an inf-sup stability result for the discrete bilinear form, which is uniform with respect to the mesh size, discontinuous parameters, and the interface position. Based on this, we establish the well-posedness of our method and demonstrate optimal error bounds in the discrete energy norm and L 2 norm. Finally, numerical experiments are presented to illustrate the theoretical results.},
  archive      = {J_CMA},
  author       = {Nan Wang and Hanyu Chu and Jinru Chen and Ying Cai},
  doi          = {10.1016/j.camwa.2025.08.031},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {22-44},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Mixed nitsche extended finite element method for solving three-dimensional h(curl)-elliptic interface problems},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence analysis of a fast ADI compact finite difference method for two-dimensional semi-linear time-fractional reaction-diffusion equations with weak initial singularity. <em>CMA</em>, <em>199</em>, 1-21. (<a href='https://doi.org/10.1016/j.camwa.2025.08.028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, considering the solution's weak initial singularity, a rigorous error analysis of a finite difference method for simulating a two-dimensional semi-linear time-fractional reaction-diffusion equation (TFRDE) is presented. The recently introduced ADI method by Kumari and Roul (2024) [31] for solving a class of linear TFRDEs encounters with problematic mesh parameter adjustments and ignorance of the derivative bounds, potentially rendering the latest methodology deficient and erroneous. The present study aims to design a computationally efficient L1 ADI scheme for semi-linear TFRDEs and provide a comprehensive error analysis. To address intrinsically non-local characteristics of the solution, we employ sum-of-exponential approximation to the singular kernel of time-fractional derivative on a graded mesh with unequal time-steps that yield denser mesh near the initial point. As a result, we effectively mitigate the high storage and computational requirements and return the convergence point to its optimal state. The two spatial variables are treated with a fourth order compact finite difference operator. Moreover, an alternating direction implicit method is utilized to compute the solution of the derived two-dimensional system by splitting it into two separate one-dimensional problems. With the aid of local truncation error estimate and discrete fractional Grönwall inequality, the stability and convergence analysis of the scheme are carried out rigorously through the discrete energy approach. The numerical results corroborate the convergence analysis and highlight the computational efficacy of the numerical scheme. Numerical examples demonstrate the CPU performance of the fast compact ADI method, and presented comparisons distinctly showcases the effectiveness of the graded mesh enhancing convergence order to achieve optimal results.},
  archive      = {J_CMA},
  author       = {Priyanka and Sunil Kumar},
  doi          = {10.1016/j.camwa.2025.08.028},
  journal      = {Computers & Mathematics with Applications},
  month        = {12},
  pages        = {1-21},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Convergence analysis of a fast ADI compact finite difference method for two-dimensional semi-linear time-fractional reaction-diffusion equations with weak initial singularity},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="cmame">CMAME - 48</h2>
<ul>
<li><details>
<summary>
(2025). Structural transient dynamic topology optimization based on autoencoder-enhanced generative adversarial network and elitist guidance evolutionary algorithm. <em>CMAME</em>, <em>447</em>, 118417. (<a href='https://doi.org/10.1016/j.cma.2025.118417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural transient dynamic optimization faces significant challenges stemming from material nonlinearities and geometric nonlinearities induced by large deformations. These nonlinear phenomena severely complicate gradient-based sensitivity analysis, while conventional non-gradient optimization approaches face limitations including prohibitive computational demands, suboptimal solution quality, and compromised robustness. To overcome these challenges, we present an integrated computational framework synergistically combining an autoencoder-enhanced generative adversarial network with an elitist guidance evolutionary algorithm for nonlinear dynamic optimization. The developed multi-fidelity surrogate modeling architecture achieves dual enhancement in computational efficiency and solution diversity, while the elitism-preserving mechanism in elitist guidance evolutionary algorithm ensures superior convergence characteristics. Furthermore, we introduce a self-supervised criterion noise rate metric for quantitatively evaluating structural performance under transient loads. Results demonstrate that the proposed method improves structural clarity and diversity by 18.56 and 21.55 times compared to conventional methods. Case studies with both cantilever and fixed-end beams across dynamic loading regimes confirm the method’s generalizability. This framework is easily transferable to other engineering fields, offering new insights for solving transient nonlinear problems.},
  archive      = {J_CMAME},
  author       = {Haojie Ma and Xiao Kang and Yixing Huang and Shengyu Duan and Ying Li and Daining Fang},
  doi          = {10.1016/j.cma.2025.118417},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118417},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Structural transient dynamic topology optimization based on autoencoder-enhanced generative adversarial network and elitist guidance evolutionary algorithm},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GALDS: A graph-autoencoder-based latent dynamics surrogate model to predict neurite material transport. <em>CMAME</em>, <em>447</em>, 118409. (<a href='https://doi.org/10.1016/j.cma.2025.118409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurons exhibit intricate geometries within their neurite networks, which play a crucial role in processes such as signaling and nutrient transport. Accurate simulation of material transport in the networks is essential for understanding these biological phenomena but poses significant computational challenges because of the complex tree-like structures involved. Traditional approaches are time-intensive and resource-demanding, yet the inherent properties of neuron trees, which consists primarily of pipes with steady-state parabolic velocity profiles and bifurcations, provide opportunities for computational optimization. To address these challenges, we propose a Graph-Autoencoder-based Latent Dynamics Surrogate (GALDS) model, which is specifically designed to streamline the simulation of material transport in neural trees. GALDS employs a graph autoencoder to encode latent representations of the network’s geometry, velocity fields, and concentration profiles. These latent space representations are then assembled into a global graph, which is subsequently used to predict system dynamics in the latent space via a trained graph latent space system dynamic model, inspired by the Neural Ordinary Differential Equations (Neural ODEs) concept. The integration of an autoencoder allows for the use of smaller graph neural network models with reduced training data requirements. Furthermore, the Neural ODE component effectively mitigates the issue of error accumulation commonly encountered in recurrent neural networks. The effectiveness of the GALDS model is demonstrated through results on eight unseen geometries and four abnormal transport examples, where our approach achieves mean relative error of 3 % with maximum relative error < 8 % and demonstrates a 10-fold speed improvement compared to previous surrogate model approaches.},
  archive      = {J_CMAME},
  author       = {Tsung Yeh Hsieh and Yongjie Jessica Zhang},
  doi          = {10.1016/j.cma.2025.118409},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118409},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {GALDS: A graph-autoencoder-based latent dynamics surrogate model to predict neurite material transport},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectral-element SBPML for 3D infinite transient wave problems. <em>CMAME</em>, <em>447</em>, 118407. (<a href='https://doi.org/10.1016/j.cma.2025.118407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops a novel spectral-element scaled boundary perfectly matched layer (SBPML) coupled the spectral elements method (SEM) to simulate wave problems in 3D unbounded domains. The SBPML can accommodate boundary of general shapes and consider the planar physical interfaces and surfaces that extend infinitely. Furthermore, it supports direct coupling with 3D spectral elements of any orders in interior domain, leading to significantly higher computation accuracy. The spectral-element SBPML can flexibly and adaptively adjust the elements orders within the SBPML domain according to those used in the finite domain. Moreover, by generalizing the flexibility matrix, this method can model 3D transversely isotropic (TI) unbounded media, thereby enhancing its applicability to realistic geological scenarios. Firstly, quadrilateral spectral element shape functions are introduced in the circumferential direction of scaled boundary coordinates, which is compatible with 3D spectral elements of any orders of the finite domain. Subsequently, a complex coordinate stretching function is introduced along the radial direction, transforming the unbounded domain into a complex-valued space that defines the SBPML domain. This SBPML formulation employs a 2nd-order mixed unsplit-field displacement-stress form via spatial discretization of the SBPML domain. This mixed element is formulated by using shape functions of an n -th order spectral element for the displacement field and an ( n -1)-th order element for the auxiliary stress field. This method allows for the use of different interpolation orders along the radial and circumferential directions in SBPML, achieving an optimal balance between numerical accuracy and computational efficiency. Ultimately, the accuracy, convergence, and robustness of the proposed approach are validated by three wave propagation problems and two seismic response analyses of complex sites.},
  archive      = {J_CMAME},
  author       = {Junru Zhang and Mi Zhao and Guoliang Zhang and Junqi Zhang and Xiuli Du},
  doi          = {10.1016/j.cma.2025.118407},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118407},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Spectral-element SBPML for 3D infinite transient wave problems},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A polytopal discontinuous galerkin method for the pseudo-stress formulation of the unsteady stokes problem. <em>CMAME</em>, <em>447</em>, 118404. (<a href='https://doi.org/10.1016/j.cma.2025.118404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to construct and analyze a discontinuous Galerkin method on polytopal grids (PolydG) to solve the pseudo-stress formulation of the unsteady Stokes problem. The pseudo-stress variable is introduced due to the growing interest in non-Newtonian flows and coupled interface problems, where stress assumes a fundamental role. The space-time discretization of the problem is achieved by combining the PolydG approach with the implicit θ -method time integration scheme. For both the semi- and fully-discrete problems we present a detailed stability analysis. Moreover, we derive convergence estimates for the fully discrete space-time discretization. A set of verification tests is presented to verify the theoretical estimates and the application of the method to cases of engineering interest.},
  archive      = {J_CMAME},
  author       = {Paola F. Antonietti and Michele Botti and Alessandra Cancrini and Ilario Mazzieri},
  doi          = {10.1016/j.cma.2025.118404},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118404},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A polytopal discontinuous galerkin method for the pseudo-stress formulation of the unsteady stokes problem},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anant-net: Breaking the curse of dimensionality with scalable and interpretable neural surrogate for high-dimensional PDEs. <em>CMAME</em>, <em>447</em>, 118403. (<a href='https://doi.org/10.1016/j.cma.2025.118403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional partial differential equations (PDEs) arise in diverse scientific and engineering applications but remain computationally intractable due to the curse of dimensionality. Traditional numerical methods struggle with the exponential growth in computational complexity, particularly on hypercubic domains, where the number of required collocation points increases rapidly with dimensionality. Here, we introduce Anant-Net , an efficient neural surrogate that overcomes this challenge, enabling the solution of PDEs in high dimensions. Unlike hyperspheres, where the internal volume diminishes as dimensionality increases, hypercubes retain or expand their volume (for unit or larger length), making high-dimensional computations significantly more demanding. Anant-Net efficiently incorporates high-dimensional boundary conditions and minimizes the PDE residual at high-dimensional collocation points. To enhance interpretability, we integrate Kolmogorov-Arnold networks into the Anant-Net architecture. We benchmark Anant-Net’s performance on several linear and nonlinear high-dimensional equations, including the Poisson, Sine-Gordon, and Allen-Cahn equations, as well as transient heat equations, demonstrating high accuracy and robustness across randomly sampled test points from high-dimensional spaces. Importantly, Anant-Net achieves these results with remarkable efficiency, solving 300-dimensional problems on a single GPU within a few hours. We also compare Anant-Net’s results for accuracy and runtime with other state-of-the-art methods. Our findings establish Anant-Net as an accurate, interpretable, and scalable framework for efficiently solving high-dimensional PDEs. The Anant-Net code is available at https://github.com/ParamIntelligence/Anant-Net .},
  archive      = {J_CMAME},
  author       = {Sidharth S. Menon and Ameya D. Jagtap},
  doi          = {10.1016/j.cma.2025.118403},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118403},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Anant-net: Breaking the curse of dimensionality with scalable and interpretable neural surrogate for high-dimensional PDEs},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rigorous error analysis of ETDRK4P-SAV scheme for the allen-cahn equation. <em>CMAME</em>, <em>447</em>, 118398. (<a href='https://doi.org/10.1016/j.cma.2025.118398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel numerical method for the Allen-Cahn (AC) equation. By combining the dimension-splitting technique with the fourth-order exponential time-differencing Runge-Kutta(ETDRK)-scalar auxiliary variable (SAV) extrapolation method, we construct a fourth-order accurate ETDRK4P-SAV scheme with energy decay property. In terms of spatial discretization, a fourth-order central difference combined with dimension-splitting technique is employed; for temporal discretization, a fourth-order ETDRK-SAV extrapolation method based on the Padé approximation is utilized. From a theoretical perspective, we rigorously prove that the fully discrete scheme preserves the maximum principle, energy decay property and unique solvability, while also establishing the optimal error estimation theory. Numerical experimental results show that this scheme not only has good convergence but also maintains the discrete energy dissipation property, verifying its effectiveness and reliability in solving the AC equation.},
  archive      = {J_CMAME},
  author       = {Xiaoyan Li and Xinlong Feng and Lingzhi Qian},
  doi          = {10.1016/j.cma.2025.118398},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118398},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Rigorous error analysis of ETDRK4P-SAV scheme for the allen-cahn equation},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition-free variational quantum linear solver: Application in computational mechanics. <em>CMAME</em>, <em>447</em>, 118396. (<a href='https://doi.org/10.1016/j.cma.2025.118396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving a linear system of equations is a fundamental task in computational mechanics. The recently proposed variational quantum linear solver (VQLS) offers potential acceleration for this task by using quantum computing. However, its application faces a critical bottleneck: the costly requirement to decompose the coefficient matrix into a linear combination of unitary matrices. In this work, we propose a decomposition-free variational quantum linear solver (DF-VQLS) that eliminates this requirement, enabling direct application without matrix decomposition. The key innovation lies in proposing two vectorization techniques, which map the cost functions of VQLS to the inner product of vectors. Specifically, the vectorization techniques reshape the matrix into a vector, and only manipulations on the vector are needed to compute the cost functions, thereby eliminating matrix decomposition entirely. The convergence and accuracy of the proposed method are validated through numerical examples on a quantum simulator. Three application examples in computational mechanics, including bar, truss, and two-dimensional continuum problems, are also presented to show the potential feasibility.},
  archive      = {J_CMAME},
  author       = {Yongchun Xu and Heng Hu},
  doi          = {10.1016/j.cma.2025.118396},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118396},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Decomposition-free variational quantum linear solver: Application in computational mechanics},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-order time-marching schemes for incompressible flow in particle methods. <em>CMAME</em>, <em>447</em>, 118395. (<a href='https://doi.org/10.1016/j.cma.2025.118395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents novel high-order time-marching schemes for simulating incompressible flow in particle methods. The proposed schemes are based on a newly developed formulation that describes the time evolution of computational variables along particle trajectories, resulting in a new form of the pressure Poisson equation. This formulation enables the direct application of existing forward-advancing time integration schemes, such as explicit Runge–Kutta methods, to achieve high-order temporal accuracy. Furthermore, the proposed schemes are generalized for arbitrary particle movement, enabling the efficient incorporation of particle shifting without requiring additional particle movement or variable corrections. By applying Runge–Kutta methods, this study presents four single- or multistage schemes referred to as RK1–RK4, corresponding to the number of stages. The validity of the proposed schemes is rigorously evaluated through numerical investigations involving four test cases and three types of particle movement (Lagrangian, Eulerian, and quasi-Lagrangian). The results reveal that the proposed RK2, RK3, and RK4 schemes achieve second-, third-, and fourth-order temporal convergence, respectively, and exhibit substantially higher accuracy than conventional first-order schemes, leading to improved volume and energy conservation. In addition, the proposed schemes demonstrate high computational efficiency, indicating their practical value for the numerical analysis of incompressible flow.},
  archive      = {J_CMAME},
  author       = {Takuya Matsunaga},
  doi          = {10.1016/j.cma.2025.118395},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118395},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {High-order time-marching schemes for incompressible flow in particle methods},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantized local reduced-order modeling in time (ql-ROM). <em>CMAME</em>, <em>447</em>, 118393. (<a href='https://doi.org/10.1016/j.cma.2025.118393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporally chaotic systems, such as the solutions of some nonlinear partial differential equations, are dynamical systems that evolve toward a lower dimensional manifold. This manifold has an intricate geometry with heterogeneous density, which makes the design of a single (global) nonlinear reduced-order model (ROM) challenging. In this paper, we turn this around. Instead of modeling the manifold with one single model, we partition the manifold into clusters within which the dynamics are locally modeled. This results in a quantized local reduced-order model (ql-ROM), which consists of (i) quantizing the manifold via unsupervised clustering; (ii) constructing intrusive ROMs for each cluster; and (iii) connecting the switching of local models with a change of basis and assignment functions. We test the method on two nonlinear partial differential equations, i.e., the Kuramoto-Sivashinsky and 2D Navier-Stokes equations (Kolmogorov flow), across bursting, chaotic, quasiperiodic, and turbulent regimes. The local models are built via Galerkin projection onto the local principal directions, which are centered on the cluster centroids. The dynamics are modeled by switching the local ROMs based on the cluster proximity. The proposed ql-ROM framework has three advantages over global ROMs (g-ROMs): (i) numerical stability, (ii) improved short-term prediction accuracy in time, and (iii) accurate prediction of long-term statistics, such as energy spectra and probability distributions. The computational overhead is minimal with respect to g-ROMs. The proposed framework retains the interpretability and simplicity of intrusive projection-based ROMs, whilst overcoming their limitations in modeling complex, high-dimensional, nonlinear dynamics.},
  archive      = {J_CMAME},
  author       = {Antonio Colanera and Luca Magri},
  doi          = {10.1016/j.cma.2025.118393},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118393},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Quantized local reduced-order modeling in time (ql-ROM)},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Isogeometric analysis for non-newtonian viscoplastic fluids: Challenges for non-smooth solutions. <em>CMAME</em>, <em>447</em>, 118386. (<a href='https://doi.org/10.1016/j.cma.2025.118386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores the application of high-order Isogeometric Analysis (IGA) to the numerical simulation of non-Newtonian viscoplastic fluids, particularly in the presence of yield surfaces and non-smooth solutions. While IGA has demonstrated superior accuracy in smooth problems due to its high-continuity basis functions, its performance in cases with sharp transitions, such as viscoplastic flows with localized singularities, presents unique challenges. To address this, we develop a stabilized isogeometric framework for viscoplastic Stokes flow using the Variational Multiscale (VMS) method, ensuring numerical stability and preventing spurious pressure oscillations in equal-order discretizations. Additionally, we integrate an embedded boundary approach based on the Shifted Boundary Method (SBM) to efficiently handle complex geometries without the need for body-fitted meshes. The effectiveness of this high-order stabilized IGA framework is assessed through numerical benchmarks. The results confirm that high-order B-Spline bases achieve optimal convergence in smooth regions, while their performance near yield surfaces is affected by localized oscillations due to the inherent continuity of the basis functions. Furthermore, we demonstrate that the SBM-IGA formulation successfully enforces boundary conditions in embedded domains while preserving high-order accuracy. These findings provide valuable insights into the role of basis smoothness, stabilization techniques, and embedded formulations in non-Newtonian flow simulations, offering a foundation for future advancements in isogeometric methods for complex fluids.},
  archive      = {J_CMAME},
  author       = {Nicolò Antonelli and Andrea Gorgi and Rubén Zorrilla and Riccardo Rossi},
  doi          = {10.1016/j.cma.2025.118386},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118386},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Isogeometric analysis for non-newtonian viscoplastic fluids: Challenges for non-smooth solutions},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-fidelity modelling of floor-borne vibrations in axisymmetric MRI magnets using hp-finite element method. <em>CMAME</em>, <em>447</em>, 118385. (<a href='https://doi.org/10.1016/j.cma.2025.118385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic Resonance Imaging (MRI) relies on the stability of highly uniform fields from superconducting main coils and spatially varying fields from AC-driven gradient coils. Both types of coils are thermally separated, as the main coils are cryogenically cooled within a cryostat whilst gradient coils operate at room temperature. Externally generated floor-borne vibrations (FBV) can induce relative motion between radiation shields and coils, generating eddy currents in the shields. These in turn produce parasitic magnetic fields that compromise field homogeneity and degrade image quality. This paper presents a high-fidelity computational framework for simulating the magneto-mechanical effects of FBV in axisymmetric MRI scanners to inform the manufacturing design workflow. The approach introduces three key advancements: first , a nonlinear, fully coupled magneto-mechanical formulation solved using h p -Finite Element Methods ( h p -FEM) in the open-source NGSolve framework, with a focus on optimal interpolation order p and time step size; second , explicit mechanical modelling of both main and gradient coils, moving beyond idealised Biot-Savart type current sources; and third , the use of realistic axisymmetric geometries with structural connectivity between coils and radiation shields in order to inform preliminary designs in Industry. A comprehensive series of numerical results is presented in order to validate the method against some benchmarked scenarios and highlight its potential for guiding vibration mitigation and improving MRI image fidelity.},
  archive      = {J_CMAME},
  author       = {Yashwanth Sooriyakanthan and Antonio J. Gil and Paul D. Ledger and Michael J. Mallett},
  doi          = {10.1016/j.cma.2025.118385},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118385},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {High-fidelity modelling of floor-borne vibrations in axisymmetric MRI magnets using hp-finite element method},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite deformation analysis of flexoelectric shells. <em>CMAME</em>, <em>447</em>, 118384. (<a href='https://doi.org/10.1016/j.cma.2025.118384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a nonlinear shell model for the coupled mechanical and electrical analysis of thin flexoelectric polymers is developed. In addition to the classical terms, contributions from the second gradient of deformation, electro-mechanical coupling and flexoelectricity are incorporated into the free energy density of these materials. Furthermore, starting from a variational framework, a nonlinear finite element formulation in the material setting is developed to provide numerical solutions for various problems. By neglecting the electrical and flexoelectric effects, the present formulation can reflect the deformation of purely mechanical gradient shells. Conversely, by disregarding the gradient and flexoelectric effects, the present formulation is greatly capable of modeling the deformation of electro-active shells. The midsurface displacement and director difference vectors are interpolated using C 1 shape functions, while C 0 -continuous interpolation functions are used for the thickness stretching and voltage parameters. Several numerical examples are solved to evaluate performance and robustness of the proposed formulation. The results show that the present formulation yields excellent agreement with those available in the literature. Moreover, the proposed formulation effectively captures the flexoelectric response of both initially flat and initially curved thin structures experiencing finite deformations.},
  archive      = {J_CMAME},
  author       = {Farzam Dadgar-Rad and Shahab Sahraee and Mokarram Hossain and Stefan Hartmann},
  doi          = {10.1016/j.cma.2025.118384},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118384},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Finite deformation analysis of flexoelectric shells},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symplectic hamiltonian hybridizable discontinuous galerkin methods for linearized shallow water equations. <em>CMAME</em>, <em>447</em>, 118383. (<a href='https://doi.org/10.1016/j.cma.2025.118383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the numerical approximation of the linearized shallow water equations using hybridizable discontinuous Galerkin (HDG) methods, leveraging the Hamiltonian structure of the evolution system. First, we propose an equivalent formulation of the equations by introducing an auxiliary variable. Then, we discretize the space variables using HDG methods, resulting in a semi-discrete scheme that preserves a discrete version of the Hamiltonian structure. The use of an alternative formulation with the auxiliary variable is crucial for developing the HDG scheme that preserves this Hamiltonian structure. The resulting system is subsequently discretized in time using symplectic integrators, ensuring the energy conservation of the fully discrete scheme. We present numerical experiments that demonstrate optimal convergence rates for all variables and showcase the conservation of total energy, as well as the evolution of other physical quantities.},
  archive      = {J_CMAME},
  author       = {Cristhian Núñez and Manuel A. Sánchez},
  doi          = {10.1016/j.cma.2025.118383},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118383},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Symplectic hamiltonian hybridizable discontinuous galerkin methods for linearized shallow water equations},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear model reduction using spectral proper orthogonal decomposition. <em>CMAME</em>, <em>447</em>, 118382. (<a href='https://doi.org/10.1016/j.cma.2025.118382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most model reduction methods reduce the state dimension and then temporally evolve a set of coefficients that encode the state in the reduced representation. In this paper, we instead employ an efficient representation of the entire trajectory of the state over some time interval of interest and then solve for the static coefficients that encode the trajectory on the interval. We use spectral proper orthogonal decomposition (SPOD) modes, which are provably optimal for representing long trajectories and substantially outperform any representation of the trajectory in a purely spatial basis (e.g., POD). We develop a method to solve for the SPOD coefficients that encode the trajectories for forced linear dynamical systems given the forcing and initial condition, thereby obtaining the accurate prediction of the dynamics afforded by the SPOD representation of the trajectory. The method, which we refer to as spectral solution operator projection (SSOP), is derived by projecting the general time-domain solution for a linear time-invariant system onto the SPOD modes. We demonstrate the new method using two examples: a linearized Ginzburg-Landau equation and an advection-diffusion problem. In both cases, the error of the proposed method is orders of magnitude lower than that of POD-Galerkin projection and balanced truncation. The method is also fast, with CPU time comparable to or lower than both benchmarks in our examples. Finally, we describe a data-free space-time method that is a derivative of the proposed method and show that it is also more accurate than balanced truncation in most cases.},
  archive      = {J_CMAME},
  author       = {Peter Frame and Cong Lin and Oliver T. Schmidt and Aaron Towne},
  doi          = {10.1016/j.cma.2025.118382},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118382},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Linear model reduction using spectral proper orthogonal decomposition},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A phase-field cohesive fracture model free from the length scale constraints. <em>CMAME</em>, <em>447</em>, 118374. (<a href='https://doi.org/10.1016/j.cma.2025.118374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In conventional phase-field cohesive fracture methods, an upper bound on the phase-field length scale parameter is typically imposed to ensure the convexity of the energy degradation function. However, this constraint can result in substantial computational costs when analyzing large-scale structures, geological fractures, or fractures in high-strength materials. To overcome this limitation, this work introduces a novel field variable that guarantees the convexity of the energy degradation function is always satisfied, thereby eliminating the physical constraint on the phase-field length scale parameter. Based on this innovation, a new class of phase-field cohesive fracture models is formulated using a variational approach, and the intrinsic relationship between the characteristic function and the cohesive law is established through the one-dimensional analytical solution. Both implicit and explicit dynamic algorithms are developed for the numerical implementation of the model. The effectiveness and robustness of the proposed approach are demonstrated through simulations of several typical fracture problems. The results indicate that the model can efficiently and accurately address large-scale fracture and high-strength material failure analyses, while maintaining insensitivity to the phase-field length scale parameter in both static and dynamic cases. These findings highlight the model’s potential for broad application in the computational analysis of complex fracture phenomena.},
  archive      = {J_CMAME},
  author       = {Lu Hai and Ye Feng},
  doi          = {10.1016/j.cma.2025.118374},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118374},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A phase-field cohesive fracture model free from the length scale constraints},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Full-scale topology optimization for dynamic responses of functionally graded porous infill designs using nitsche-type multi-patch isogeometric analysis. <em>CMAME</em>, <em>447</em>, 118365. (<a href='https://doi.org/10.1016/j.cma.2025.118365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Porous structures, with their outstanding mechanical properties, play a crucial role in engineering applications and are an important consideration in material distribution optimization for structural dynamic performance. Recently, Isogeometric Analysis (IGA) has gained significant interest due to precise geometric representation, high-order continuity, and flexible topology evolution capabilities. Hence, this study proposes a novel infill design approach through a periodic constraint strategy in multiple Non-Uniform Rational B-Splines (NURBS) patches for two dynamic topology optimization problems, namely eigenfrequency maximization and dynamic compliance minimization. By coupling multiple NURBS patches in a conforming mesh, the complexity of the structural design domain is effectively enhanced. The Nitsche-type dynamic formulation is introduced within the IGA framework, and the theoretical analysis of the stabilization condition is performed. Furthermore, the periodic constraint strategy is imposed onto NURBS patches within the specified parameter direction, which controls the sensitivity update values of the objective function across these patches to generate a gradient porous structure. The global topology is described by the Density Distribution Function (DDF) to achieve full-scale topology optimization. The Multi-frequency Quasi-Static Ritz Vector (MQSRV) method is used to reduce the computational cost associated with dynamic problems. The mathematical models for the dynamic compliance minimization and the eigenfrequency maximization are established, where the sensitivity analysis is derived in detail. Finally, the optimized results produced by the work are fully applicable to complex structural design domains and exhibit well-defined boundaries and smooth gradient distributions. Several numerical examples are presented to demonstrate the effectiveness of the proposed multi-patch isogeometric topology optimization infill design method.},
  archive      = {J_CMAME},
  author       = {Zhen Yang and Liang Gao and Haibin Tang and Jie Gao},
  doi          = {10.1016/j.cma.2025.118365},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118365},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Full-scale topology optimization for dynamic responses of functionally graded porous infill designs using nitsche-type multi-patch isogeometric analysis},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel meshfree superconvergent gradient smoothing stabilized collocation method (GSSCM) for large deformation problems: A concise discretized form. <em>CMAME</em>, <em>447</em>, 118364. (<a href='https://doi.org/10.1016/j.cma.2025.118364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The strong form Direct Collocation Method (DCM) with Reproducing Kernel (RK) shape function is hindered in its development due to its computational complexity and low efficiency in derivative calculations. Furthermore, the nonlinear large deformation governing equations in strong form, which involve intricate derivative terms, introduce additional challenges for discretization and iterative solutions. This paper proposes a novel efficient and superconvergent Gradient Smoothing Stabilized Collocation Method (GSSCM) using RK shape function. Based upon the divergence theorem, the proposed method converts traditional subdomain integration in the Stabilized Collocation Method (SCM) into subdomain boundary integration by gradient smoothing, which reduces the order of derivatives and simplifies the discretized terms of governing equations. This allows RK shape function with low-order basis functions like the linear basis functions, and enhances computational efficiency. GSSCM ensures exact integration using low-order Gaussian quadrature and improves solution stability. Both conforming and non-conforming smoothing domain are constructed for the gradient smooth. The incremental Newton-Raphson iteration approach is employed to solve the nonlinear discrete equations. Numerical results demonstrate that the proposed approach achieves superconvergent rates when odd RK basis functions are used. The GSSCM can also outperform traditional DCM, SCM and Superconvergent Gradient Smoothing Meshfree Collocation (SGSMC) method with gradient smoothing of shape function in terms of computational efficiency under the same accuracy. Moreover, GSSCM-II with conforming integration subdomains generally outmatches GSSCM-I and SCM with non-conforming subdomains in accuracy, efficiency and stability. The advantages of GSSCMs hold significant promise for nonlinear solid mechanics and engineering applications.},
  archive      = {J_CMAME},
  author       = {Zhiyuan Xue and Lihua Wang and Yan Li and Magd Abdel Wahab},
  doi          = {10.1016/j.cma.2025.118364},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118364},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A novel meshfree superconvergent gradient smoothing stabilized collocation method (GSSCM) for large deformation problems: A concise discretized form},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics-motivated geometric method for overheating prevention in topology optimization for additive manufacturing. <em>CMAME</em>, <em>447</em>, 118363. (<a href='https://doi.org/10.1016/j.cma.2025.118363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designs generated by topology optimization are often geometrically too complex for conventional manufacturing techniques. While additive manufacturing holds promise for producing such complex designs, several manufacturability constraints must be addressed, including overhang and overheating. Unlike the well-studied overhang constraints, which can be described geometrically, overheating lacks a straightforward and reliable geometric characterization and therefore requires thermal process simulations to identify regions prone to it. However, these simulations are computationally expensive and thus unsuitable for topology optimization, which involves numerous design evaluations. This paper proposes a computationally efficient alternative for detecting zones prone to overheating. The key idea is to estimate local thermal conductivity—and thereby potential overheating—by analyzing the local material distribution. This geometric approach provides a physically motivated approximation of thermal behavior. The method is then integrated into topology optimization, resulting in optimized structures that exhibit clear heat conduction paths to the baseplate. Comparisons with high-fidelity thermal simulations demonstrate the effectiveness and efficiency of the proposed method in mitigating overheating in topology optimization.},
  archive      = {J_CMAME},
  author       = {Manabendra Nath Das and Rajit Ranjan and Kai Wu and Jun Wu and Can Ayas},
  doi          = {10.1016/j.cma.2025.118363},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118363},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A physics-motivated geometric method for overheating prevention in topology optimization for additive manufacturing},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Virtual element methods for HJB equations with cordes coefficients. <em>CMAME</em>, <em>447</em>, 118362. (<a href='https://doi.org/10.1016/j.cma.2025.118362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose and analyze both conforming and nonconforming virtual element methods (VEMs) for the fully nonlinear second-order elliptic Hamilton-Jacobi-Bellman (HJB) equations with Cordes coefficients. By incorporating stabilization terms, we establish the well-posedness of the proposed methods, thus avoiding the need to construct a discrete Miranda-Talenti estimate. We derive the optimal error estimate in the discrete H 2 norm for both numerical formulations. Furthermore, a semismooth Newton’s method is employed to linearize the discrete problems. Several numerical experiments using the lowest-order VEMs are provided to demonstrate the efficacy of the proposed methods and to validate our theoretical results.},
  archive      = {J_CMAME},
  author       = {Ying Cai and Hailong Guo and Zhimin Zhang},
  doi          = {10.1016/j.cma.2025.118362},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118362},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Virtual element methods for HJB equations with cordes coefficients},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provably third-order energy stable adaptive algorithm for modeling square pattern in phase field crystal. <em>CMAME</em>, <em>447</em>, 118361. (<a href='https://doi.org/10.1016/j.cma.2025.118361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Square pattern emerges widely in crystallography, ranging from soft matters to thermal convection in fluid dynamics. The square phase field crystal equation models such pattern formation on atomic length and diffusive time scales. The governing equation, derived from a conserved gradient flow of a free energy, involves sixth-order spatial derivatives and Laplacian-gradient type nonlinear term, which result in severe stability restriction on the time stepsizes and difficulty in theoretical analysis. In this paper, we propose a novel unconditionally energy stable, third-order adaptive BDF scheme. The convex-splitting and a multistep stabilization are leveraged to maintain energy stable with arbitrary time stepsizes, and the adaptive time-stepping control based on evolution rate is applied to efficiently obtain high-resolution results. We strictly prove optimal error estimate in the variable-step setting under a mild step ratio constraint by enhancing the discrete kernel framework proposed recently. Numerical tests in 2D/3D demonstrate the square pattern evolution in crystallization process from random or supercooled liquid initial states over a long time. The adaptive algorithm reduces computation time by 95 % while capturing details of phases, confirming the effectiveness of our method. This is the first systematic work on adaptive high-order structure-preserving method for square phase field crystal.},
  archive      = {J_CMAME},
  author       = {Ren-jun Qi and Xuan Zhao},
  doi          = {10.1016/j.cma.2025.118361},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118361},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Provably third-order energy stable adaptive algorithm for modeling square pattern in phase field crystal},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust-weighted hybrid nonlinear regression for reliability based topology optimization with multi-source uncertainties. <em>CMAME</em>, <em>447</em>, 118360. (<a href='https://doi.org/10.1016/j.cma.2025.118360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational burden in topology optimization (TO) under probabilistic constraints is a major challenge for both topology optimization and reliability analysis methods. The machine learning method can be applied for controlling the computational burden of inverse TO method for approximating the optimal volume fraction (Vf) which is related to max/min a probabilistic constraint. In this current work a hybrid nonlinear modelling training method is proposed by using the exponential nonlinear function and improved harmony search optimization for approximating the optimal Vf applied in reliability-based TO (RBTO) problems. For improving the accuracy predictions of nonlinear model a weighted training scheme is proposed given based on absolute bi-linear loss function applied as robust learning format. The applied weights given from near optimal constraints computed by Vf and loss function is determined based on two absolute function with different slop as 1 and 0.1. The proposed learning approach for nonlinear function is compared with the results of TO-based bisection under multi-source uncertainties for both accuracy and computational burden through four engineering problems. Results indicated that the proposed robust-weighted hybrid learning method computed by hybrid nonlinear regression and harmony search optimization is strongly improved the computational burden for evaluating the optimal Vf in TO and RBTO problems compared to TO and RBTO using bisection while it is more accurate as the nonlinear regression.},
  archive      = {J_CMAME},
  author       = {Shiyuan Yang and Debiao Meng and Mahmoud Alfouneh and Behrooz Keshtegar and Shun-Peng Zhu},
  doi          = {10.1016/j.cma.2025.118360},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118360},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A robust-weighted hybrid nonlinear regression for reliability based topology optimization with multi-source uncertainties},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermodynamically consistent coupled chemo-thermo-mechanical model of interfaces in overmolded thermoplastic parts. <em>CMAME</em>, <em>447</em>, 118359. (<a href='https://doi.org/10.1016/j.cma.2025.118359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving reliable bonding between dissimilar semicrystalline polymers in overmolded components remains a critical challenge in advanced manufacturing, with significant implications for structural integrity, process efficiency, and material design. This work introduces a transformational, thermodynamically consistent multiphysics framework that, for the first time, captures the full coupling between heat conduction, crystallization, deformation, and nanoscale polymer diffusion during the cooling stage of the overmolding process. The framework rigorously links manufacturing conditions to the mechanical performance of the final product by integrating process-induced residual stresses, interfacial crystallinity, and polymer interpenetration into a cohesive zone model whose fracture properties evolve dynamically. Unlike existing approaches, which rely on phenomenological models or decoupled analyses, our formulation provides predictive capability grounded in continuum thermodynamics and validated by experimental observations. This enables not only the detection of manufacturing-induced interfacial defects but also virtual process optimization through simulation. The resulting model serves as a digital twin for overmolded thermoplastics, offering a powerful new tool for engineering high-performance composite parts in automotive, aerospace, and biomedical applications.},
  archive      = {J_CMAME},
  author       = {Junhe Cui and Tiansheng Liu and Michele Valsecchi and Martin Giersberg and Hakan Çelik and Jaan-Willem Simon and Sanat Kumar and Jan Petersen and Jacob Fish},
  doi          = {10.1016/j.cma.2025.118359},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118359},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Thermodynamically consistent coupled chemo-thermo-mechanical model of interfaces in overmolded thermoplastic parts},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). History-aware neural operator: Robust data-driven constitutive modeling of path-dependent materials. <em>CMAME</em>, <em>447</em>, 118358. (<a href='https://doi.org/10.1016/j.cma.2025.118358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an end-to-end learning framework for data-driven modeling of path-dependent inelastic materials using neural operators. The novel framework is built on the premise that the irreversible evolution of material responses, governed by hidden dynamics, can be inferred from observable data. We develop the History-Aware Neural Operator (HANO), an autoregressive model that predicts path-dependent material responses from short segments of recent strain-stress history without relying on hidden state variables, thereby overcoming the self-consistency issues commonly encountered in recurrent neural network (RNN)-based models. Built on a Fourier-based neural operator backbone, HANO enables discretization-invariant learning. To further enhance its ability to capture both global loading patterns and critical local path dependencies, we embed a hierarchical self-attention mechanism that facilitates multiscale feature extraction. Beyond ensuring self-consistency, HANO mitigates sensitivity to initial hidden states, a commonly overlooked issue that can lead to instability in recurrent models when applied to generalized loading paths. By modeling stress-strain evolution as a continuous operator rather than relying on fixed input-output mappings, HANO naturally accommodates varying path discretizations and exhibits robust performance under complex conditions, including irregular sampling, multi-cycle loading, noisy data, and pre-stressed states. We evaluate HANO on two benchmark problems: elastoplasticity with hardening and progressive anisotropic damage in brittle solids. Results show that HANO consistently outperforms baseline models in predictive accuracy, generalization, and robustness. With its demonstrated capabilities and discretization-invariant design, HANO provides an effective and flexible data-driven surrogate for simulating a broad class of inelastic materials.},
  archive      = {J_CMAME},
  author       = {Binyao Guo and Zihan Lin and QiZhi He},
  doi          = {10.1016/j.cma.2025.118358},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118358},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {History-aware neural operator: Robust data-driven constitutive modeling of path-dependent materials},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixed-depth physics-informed neural network with nested activation mechanism in solving partial differential equations. <em>CMAME</em>, <em>447</em>, 118356. (<a href='https://doi.org/10.1016/j.cma.2025.118356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks (PINNs) have become promising tools for solving complex partial differential equations (PDEs), but traditional PINNs suffered from slow convergence, vanishing gradients, and poor handling of local physical features. This paper proposes a mixed-depth physics-informed neural network ( md -PINN) for solving the complex PDEs, aiming to improve the efficiency of network structure and activation function. The contributions are two aspects: (1) the md -PINN includes the various mixed-depth blocks, each of which contains parallel connected deep sub-network and shallow sub-network. The deep sub-network captures complex physical features, ensuring a comprehensive understanding of the system; while the shallow sub-network focuses on the basic physical features, facilitating the stable training; (2) the md -PINN introduces a new nest-tanh (.) activation functions with nested mechanism in shallow sub-networks to enable efficient extraction of complex features using fewer hidden layers, reducing reliance on deep networks. By incorporating mixed-depth structures, md -PINN enables more efficient information sharing across different layer, leading to faster convergence and improved training efficiency. Theoretical analysis demonstrates that md -PINN avoids suboptimal convergence with appropriate initialization. The proposed approach is validated across multiple PDEs, including heat transfer scenarios with complex boundaries, bi-material solid mechanical problems, Allen-Cahn equation, fluid dynamics, and the higher order Kuramoto-Sivashinsky equation. Results show that md -PINN exhibits the superior capabilities in approximating and capturing intricate system features. These findings underscore the computational efficiency and potential of md -PINN in tackling real-world and complex problems.},
  archive      = {J_CMAME},
  author       = {Tianhao Wang and Guirong Liu and Eric Li and Xu Xu},
  doi          = {10.1016/j.cma.2025.118356},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118356},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Mixed-depth physics-informed neural network with nested activation mechanism in solving partial differential equations},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertain constitutive model for metals in the presence of inherent defects. <em>CMAME</em>, <em>447</em>, 118355. (<a href='https://doi.org/10.1016/j.cma.2025.118355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The constitutive model of metals is one of the most important elements in solid mechanics, as the mechanical behavior at different spatial scales is uncertain, and the constitutive model is inevitably subject to uncertainty of defects. The complexity of metal microstructure, coupled with the high cost of numerical simulation, poses a challenge in establishing the correlation between macro and micro uncertainties in metals. This article proposes a new uncertain constitutive model for hexagonal close packing (HCP) polycrystal, integrating Point defect and dislocation into micro-uncertainty analysis and developing a multiscale framework for calculating the uncertain constitutive model of metal. Building on density functional theory and microcrystalline plasticity theory, interval forms are employed as variables for micro-uncertainty, allowing for accurate quantification of uncertainties in parameters such as initial dislocation density. By constructing a surrogate model for cross-scale uncertainty propagation, the performance envelope of metals can be determined. The framework is then applied to engineering case study of α-phase pure titanium to calculate system responses.},
  archive      = {J_CMAME},
  author       = {Jiazheng Zhu and Xiaojun Wang and Yanru Mu},
  doi          = {10.1016/j.cma.2025.118355},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118355},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Uncertain constitutive model for metals in the presence of inherent defects},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). System reliability-based design optimization of structures using non-probabilistic ellipsoidal convex model. <em>CMAME</em>, <em>447</em>, 118354. (<a href='https://doi.org/10.1016/j.cma.2025.118354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a system non-probabilistic reliability-based design optimization (SNRBDO) framework for engineering structural systems. In view of the limitations of traditional probabilistic methods due to insufficient uncertainty information, the ellipsoidal convex model is used to quantify the uncertainty while considering the parameter correlation. The non-probabilistic credible set uncertainty method is employed to quantify the ellipsoidal uncertainty domain of uncertain parameters. A system non-probabilistic reliability index, defined as the volume ratio of safe regions to uncertainty domains, is introduced to evaluate structural safety under multiple failure modes. To enhance computational efficiency, Kriging surrogate model is utilized to replace the finite element analysis during optimization, and a localized sampling strategy is developed to refine accuracy near critical design points. The method is validated through a mathematical example and two engineering applications. The results demonstrate significant improvements in computational efficiency and design precision compared to conventional methods.},
  archive      = {J_CMAME},
  author       = {Zirui Liu and Jinglei Gong and Yongxiang Mu and Xiaojun Wang},
  doi          = {10.1016/j.cma.2025.118354},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118354},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {System reliability-based design optimization of structures using non-probabilistic ellipsoidal convex model},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully GPU-accelerated, matrix-free immersed boundary method for complex fiber-reinforced hyperelastic cardiac models. <em>CMAME</em>, <em>447</em>, 118353. (<a href='https://doi.org/10.1016/j.cma.2025.118353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The immersed boundary (IB) method has become a leading approach in cardiac fluid-structure interaction (FSI) modeling due to its ability to handle large deformations and complex geometries without requiring mesh regeneration. However, the use of nonlinear, fiber-reinforced hyperelastic materials for modeling soft cardiac tissues introduces challenges in computational efficiency, particularly due to the additional projection steps required for stability in the IB framework. These steps often involve sparse matrix storage and computation, which can degrade GPU performance. In this work, we present a fully GPU-accelerated, matrix-free IB method for FSI in anatomically realistic cardiac models, which novelly integrates established components into a unified, GPU-optimized system. By employing nodal coupling, our method eliminates the need for projection operations in the finite element space. Additionally, we solve the Navier-Stokes equations using Chorin’s projection method combined with a matrix-free geometric multigrid solver, ensuring the entire FSI algorithm remains matrix-free and highly compatible with GPU acceleration. Our implementation features several GPU-specific optimizations, including the use of constant memory to store values of nodal basis functions and their derivatives at quadrature points, and texture memory to efficiently implement the semi-Lagrangian discretization of convection terms. These innovations maximize GPU utilization while preserving the complex mechanical behavior of soft cardiac tissue. Benchmark tests demonstrate that our GPU-accelerated solver achieves a 50 × − 100 × speedup compared to a 20-core CPU implementation, with comparable accuracy. Critically, this performance enables clinically viable cardiac valve FSI simulations to be completed within a few hours on a single consumer-grade GPU-an achievement that was previously infeasible using traditional CPU-based frameworks.},
  archive      = {J_CMAME},
  author       = {Pengfei Ma and Li Cai and Xuan Wang and Hao Gao},
  doi          = {10.1016/j.cma.2025.118353},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118353},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Fully GPU-accelerated, matrix-free immersed boundary method for complex fiber-reinforced hyperelastic cardiac models},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid flux-preserving finite element for coupled flow deformation: Linear formulation. <em>CMAME</em>, <em>447</em>, 118351. (<a href='https://doi.org/10.1016/j.cma.2025.118351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate modeling of coupled solid-fluid systems in porous media poses intrinsic computational challenges due to the nonlinear interaction between kinematic fields and fluid transport. Although a wide spectrum of finite element formulations is documented in the literature, the majority are based on principles in which solid displacement and fluid pressure fields are treated as primary unknowns, leading to a saddle point problem, thus requiring the satisfaction of the inf-sup condition to ensure the well-posedness and stability of the mixed formulation. Furthermore, in critical scenarios, such as low permeability or small time steps, numerical instabilities, including pressure oscillations, may still occur, requiring the implementation of stabilization techniques or the adoption of high-resolution discretizations to maintain solution accuracy. The present contribution proposes a novel hybrid flux-preserving finite element formulation, designed to preserve mass flux consistency within each element, by adopting an alternative set of primary variables. An original hybrid variational principle is established, wherein the solid deformation and the mass flux fields are adopted as primary unknowns, while the fluid potential acts as a Lagrange multiplier to enforce weak continuity of mass flow across inter-element boundaries, thus avoiding the necessity of globally conforming function spaces. The resulting hybrid element is implemented within the open-source software FEAP. Its performance is assessed through classical benchmark problems in poroelasticity. In particular, the accurate resolution of the fluid pressure field highlights the advantages of the proposed formulation over classical displacement-pressure elements and shows the potential of the proposed method.},
  archive      = {J_CMAME},
  author       = {Simona Lo Franco and Michele Terzano and Guido Borino and Gerhard A. Holzapfel and Francesco Parrinello},
  doi          = {10.1016/j.cma.2025.118351},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118351},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A hybrid flux-preserving finite element for coupled flow deformation: Linear formulation},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Peridynamic correspondence model for nearly-incompressible finite elasticity. <em>CMAME</em>, <em>447</em>, 118350. (<a href='https://doi.org/10.1016/j.cma.2025.118350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a correspondence model for use with peridynamic states in the context of nearly incompressible finite elasticity. An isochoric/volumetric decomposition is adopted, enabling the derivation of the peridynamic force state from a purely spherical, pointwise non-local deformation gradient and a deviatoric, bond-level non-local deformation gradient. This approach leads to a stable one-field, state-based peridynamic formulation that is free from zero-energy modes and capable of accurately capturing the mechanical behavior of elastic materials under large deformations, including those with low or negligible compressibility, typical of unfilled elastomers and isotropic soft biological tissues. Notably, the proposed correspondence model, based on a selective bond-associated deformation gradient, avoids the artificial stiffening commonly observed in standard displacement-based formulations near the incompressible limit. Moreover, its performance is shown to be independent of the specific compressibility ratio assumed in the hyperelastic constitutive law. The model has been successfully validated using classical polynomial strain energy functions through a series of illustrative examples involving both homogeneous and inhomogeneous finite deformations in isotropic hyperelastic solids.},
  archive      = {J_CMAME},
  author       = {Francesco Scabbia and Vito Diana and Francesca Fantoni and Mirco Zaccariotto and Ugo Galvanetto},
  doi          = {10.1016/j.cma.2025.118350},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118350},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Peridynamic correspondence model for nearly-incompressible finite elasticity},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S-PINN: Stabilized physics-informed neural networks for alleviating barriers between multi-level co-optimization. <em>CMAME</em>, <em>447</em>, 118348. (<a href='https://doi.org/10.1016/j.cma.2025.118348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks (PINNs) have rapidly evolved since their robust capabilities of integrating physical laws into data-driven models. However, the multi-level co-optimization mechanism hidden in the collocation-type loss function in PINNs leads to conflicts between data and physical equations, as well as conflicts among pointwise residuals, which results in poor stability and conservation. In this paper, a stabilized physics-informed neural network (S-PINN) framework is proposed to alleviate these limitations. First, S-PINN incorporates local domains around collocation points for evaluating residuals of conserved quantities. These domains can be flexibly established by creating a square centered on the collocation point of the original PINN, without constructing any mesh with topological relations. During online training, S-PINN mitigates conflicts in the multi-level co-optimization by minimizing a novel loss function based on the cumulative residuals of conserved quantities in all subdomains, significantly enhancing conservation. Finally, the novel approach is applied to predict the dynamic characteristics of incompressible fluid problems, with benchmarks including the pressure Poisson equation of fluid, Burgers' equation, heat diffusion equation, and the Navier-Stokes equations. Results demonstrate notable advancements in both the conservation and accuracy of the S-PINN. While traditional PINN lays a solid foundation for model interpretability and integration of physical laws, the newly proposed S-PINN exhibits improved performances in multiples aspects compared to PINN. These improvements promote extensive applicability in solving partial differential equations integrated with observational data, which is crucial for the application of complex dynamic systems.},
  archive      = {J_CMAME},
  author       = {Tengmao Yang and Zhihao Qian and Nianzhi Hang and Moubin Liu},
  doi          = {10.1016/j.cma.2025.118348},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118348},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {S-PINN: Stabilized physics-informed neural networks for alleviating barriers between multi-level co-optimization},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model order reduction of hæmodynamics by space–time reduced basis and reduced fluid–structure interaction. <em>CMAME</em>, <em>447</em>, 118347. (<a href='https://doi.org/10.1016/j.cma.2025.118347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we apply the space–time Galerkin reduced basis (ST–GRB) method to a reduced fluid–structure interaction model, for the numerical simulation of hæmodynamics in arteries. In essence, ST–GRB extends the classical reduced basis (RB) method, exploiting a data–driven low–dimensional linear encoding of the temporal dynamics to further cut the computational costs. The current investigation brings forth two key enhancements, compared to previous works on the topic. On the one side, we model blood flow through the Navier–Stokes equations, hence accounting for convection. In this regard, we implement a hyper–reduction scheme, based on approximate space–time reduced affine decompositions, to deal with nonlinearities effectively. On the other side, we move beyond the constraint of modelling blood vessels as rigid structures, acknowledging the importance of elasticity for the accurate simulation of complex blood flow patterns. To limit computational complexity, we adopt the Coupled Momentum model, incorporating the effect of wall compliance in the fluid’s equations through a generalized Robin boundary condition. In particular, we propose an efficient strategy for handling the spatio–temporal projection of the structural displacement, which ultimately configures as a by–product. The performances of ST–GRB are assessed in three different numerical experiments. The results confirm that the proposed approach can outperform the classical RB method, yielding precise approximations of high–fidelity solutions at more convenient costs. However, the computational gains of ST–GRB vanish if the number of retained temporal modes is too large, which occurs either when complex dynamics arise or if very precise solutions are sought.},
  archive      = {J_CMAME},
  author       = {Riccardo Tenderini and Simone Deparis},
  doi          = {10.1016/j.cma.2025.118347},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118347},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Model order reduction of hæmodynamics by space–time reduced basis and reduced fluid–structure interaction},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sharp-PINNs: Staggered hard-constrained physics-informed neural networks for phase field modelling of corrosion. <em>CMAME</em>, <em>447</em>, 118346. (<a href='https://doi.org/10.1016/j.cma.2025.118346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks have shown significant potential in solving partial differential equations (PDEs) across diverse scientific fields. However, their performance often deteriorates when addressing PDEs with intricate and strongly coupled solutions. In this work, we present a novel Sharp-PINN framework to tackle complex phase field corrosion problems. Instead of minimizing all governing PDE residuals simultaneously, the Sharp-PINNs introduce a staggered training scheme that alternately minimizes the residuals of Allen-Cahn and Cahn-Hilliard equations, which govern the corrosion system. To further enhance its efficiency and accuracy, we design an advanced neural network architecture that integrates random Fourier features as coordinate embeddings, employs a modified multi-layer perceptron as the primary backbone, and enforces hard constraints in the output layer. This framework is benchmarked through simulations of corrosion problems with multiple pits, where the staggered training scheme and network architecture significantly improve both the efficiency and accuracy of PINNs. Moreover, in three-dimensional cases, our approach is 5–10 times faster than traditional finite element methods while maintaining competitive accuracy, demonstrating its potential for real-world engineering applications in corrosion prediction.},
  archive      = {J_CMAME},
  author       = {Nanxi Chen and Chuanjie Cui and Rujin Ma and Airong Chen and Sifan Wang},
  doi          = {10.1016/j.cma.2025.118346},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118346},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Sharp-PINNs: Staggered hard-constrained physics-informed neural networks for phase field modelling of corrosion},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature preserving data assimilation via feature alignment. <em>CMAME</em>, <em>447</em>, 118345. (<a href='https://doi.org/10.1016/j.cma.2025.118345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data assimilation combines information from physical observations and numerical simulation results to obtain better estimates of the state and parameters of a physical system. A wide class of physical systems of interest have solutions that exhibit the formation of structures, called features, that have to be accurately captured by the assimilation framework. For example, fluids can develop features such as shock waves and contact discontinuities that need to be tracked and preserved during data assimilation. State-of-the-art data assimilation techniques are agnostic of such features. Current ensemble-based methods construct state estimates by taking linear combinations of multiple ensemble states; repeated averaging tends to smear the features over multiple assimilation cycles, leading to nonphysical state estimates. A novel feature-preserving data assimilation methodology that combines sequence alignment with the ensemble transform particle filter is proposed to overcome this limitation of existing assimilation algorithms. Specifically, optimal transport of particles is performed along feature-aligned characteristics. The strength of the proposed feature-preserving filtering approach is demonstrated on multiple test problems described by the compressible Euler equations.},
  archive      = {J_CMAME},
  author       = {Amit~N. Subrahmanya and Adrian Sandu},
  doi          = {10.1016/j.cma.2025.118345},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118345},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Feature preserving data assimilation via feature alignment},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A meshfree immersed variational multiscale method for perfectly bonded interfaces. <em>CMAME</em>, <em>447</em>, 118344. (<a href='https://doi.org/10.1016/j.cma.2025.118344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Composites are ubiquitous in many engineering applications, and computing stresses near material interfaces is crucial for predicting and understanding meso- and micro-structural failure in these materials. While many notable approaches to this problem are available, stable interfacial tractions are still difficult to achieve in numerical simulations. This work presents a simplified immersed variational multiscale (SIVMS) method for interfaces that achieves stable, convergent results for the normal traction. The convergence behavior in both the bulk domain fields and interfacial tractions is investigated for SIVMS and is compared to conventional methods such as the Lagrange multiplier method and Nitsche’s method. The difficulty in selecting appropriate values of parameters for Nitsche’s method is highlighted. In contrast, SIVMS provides stabilization that emanates naturally from the assumed fine-scale basis functions. The proposed SIVMS method is free from ad-hoc parameters and provides good accuracy and stability in interfacial tractions. Several benchmark test cases are presented to show the effectiveness and confirm the range of applicability of the proposed method.},
  archive      = {J_CMAME},
  author       = {Andrew B. Groeneveld and Michael C. Hillman and Pinlei Chen},
  doi          = {10.1016/j.cma.2025.118344},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118344},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A meshfree immersed variational multiscale method for perfectly bonded interfaces},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A velocity-vorticity-pressure formulation for the steady Navier–Stokes–Brinkman–Forchheimer problem. <em>CMAME</em>, <em>447</em>, 118343. (<a href='https://doi.org/10.1016/j.cma.2025.118343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flow of incompressible fluid in highly permeable porous media in vorticity - velocity - Bernoulli pressure form leads to a double saddle-point problem in the Navier–Stokes–Brinkman–Forchheimer equations. The paper establishes, for small sources, the existence of solutions on the continuous and discrete level of lowest-order piecewise divergence-free Crouzeix–Raviart finite elements. The vorticity employs a vector version of the pressure space with normal and tangential velocity jump penalisation terms. A simple Raviart–Thomas interpolant leads to pressure-robust a priori error estimates. An explicit residual-based a posteriori error estimate allows for efficient and reliable a posteriori error control. The efficiency for the Forchheimer nonlinearity requires a novel discrete inequality of independent interest. The implementation is based upon a light-weight forest-of-trees data structure handled by a highly parallel set of adaptive mesh refining algorithms. Numerical simulations reveal robustness of the a posteriori error estimates and improved convergence rates by adaptive mesh-refining.},
  archive      = {J_CMAME},
  author       = {Santiago Badia and Carsten Carstensen and Alberto F. Martín and Ricardo Ruiz-Baier and Segundo Villa-Fuentes},
  doi          = {10.1016/j.cma.2025.118343},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118343},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A velocity-vorticity-pressure formulation for the steady Navier–Stokes–Brinkman–Forchheimer problem},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A locking free multiscale method for linear elasticity in stress-displacement formulation with high contrast coefficients. <em>CMAME</em>, <em>447</em>, 118342. (<a href='https://doi.org/10.1016/j.cma.2025.118342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving strongly symmetric stress approximations for linear elasticity problems in high-contrast media poses a significant computational challenge. Conventional methods often struggle with prohibitively high computational costs due to excessive degrees of freedom, limiting their practical applicability. To overcome this challenge, we introduce an efficient multiscale model reduction method and a computationally inexpensive coarse-grid simulation technique for linear elasticity equations in highly heterogeneous, high-contrast media. We first utilize a stable stress-displacement mixed finite element method to discretize the linear elasticity problem and then present the construction of multiscale basis functions for the displacement and the stress. The mixed formulation offers several advantages such as direct stress computation without post-processing, local momentum conservation (ensuring physical consistency), and robustness against locking effects, even for nearly incompressible materials. Theoretical analysis confirms that our method is inf-sup stable and locking-free, with first-order convergence relative to the coarse mesh size. Notably, the convergence remains independent of contrast ratios as enlarging oversampling regions. Numerical experiments validate the method’s effectiveness, demonstrating its superior performance even under extreme contrast conditions.},
  archive      = {J_CMAME},
  author       = {Eric T. Chung and Changqing Ye and Xiang Zhong},
  doi          = {10.1016/j.cma.2025.118342},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118342},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A locking free multiscale method for linear elasticity in stress-displacement formulation with high contrast coefficients},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analytical hierarchical bayesian modeling framework for model updating and uncertainty propagation utilizing frequency response function data. <em>CMAME</em>, <em>447</em>, 118341. (<a href='https://doi.org/10.1016/j.cma.2025.118341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model updating using frequency response functions (FRFs) provides critical advantages in structural dynamics. However, existing probabilistic approaches struggle to balance computational efficiency with comprehensive uncertainty quantification. To this end, this paper introduces an analytical hierarchical Bayesian modeling (HBM) framework that overcomes these limitations through utilization of complex-valued FRF data and variational inference. In particular, the proposed approach incorporates a complex Gaussian likelihood formulation directly into the HBM framework for the FRF experimental data, which allows for a more appropriate and physically consistent treatment of FRF data, particularly when both magnitude and phase information (real and imaginary parts) are essential. Additionally, the proposed approach enables the analytical HBM solution under the complex likelihood setting, improving both the accuracy of parameter estimation and the efficiency of the computation. The framework further propagates the parameter uncertainty to the response predictions and reliability assessment. Numerical and experimental validations on a simply supported beam demonstrate the effectiveness of the proposed approach. Results indicate that the proposed framework provides a reasonable uncertainty estimate of the model parameters as well as the response predictions. Reliability computations on the numerical example also suggest that the proposed framework provides conservative and reliable failure probability estimates, compared to the classical Bayesian modeling which often leads to unsafe engineering decisions.},
  archive      = {J_CMAME},
  author       = {Xinyu Jia and Weinan Hou and Shi-Ze Cao and Wang-Ji Yan and Costas Papadimitriou},
  doi          = {10.1016/j.cma.2025.118341},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118341},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Analytical hierarchical bayesian modeling framework for model updating and uncertainty propagation utilizing frequency response function data},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified framework of bond-associated peridynamic material correspondence models: Formulation and evaluation. <em>CMAME</em>, <em>447</em>, 118340. (<a href='https://doi.org/10.1016/j.cma.2025.118340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional peridynamic material correspondence formulation is known to suffer from issue of material instability or existence of zero-energy modes. This issue arises from the non-unique mapping between the nonlocal deformation gradient and the resulting bond force density state. Among many stabilization techniques proposed to handle this issue, a number of bond-associated models that employ bond-level deformation gradients have emerged as more effective approaches. Although initially developed from different theoretical perspectives, many of these models share underlying structural similarities. This paper aims to unify these differing approaches and introduce a generalized framework for all bond-associated peridynamic material correspondence models. On the basis of formulations proposed in the literature, a unified expression for the bond-associated deformation gradient is developed. Assuming energy equivalence with the local continuum mechanics theory, the unified bond force density state is derived using the Fréchet derivative. In addition, some properties of the bond-associated models, including linear momentum balance, angular momentum balance, and objectivity, are thoroughly examined. To assess and compare the performance of bond-associated models, a series of numerical studies are carried out, including bond mapping analysis, elastic deformation prediction, and elastic wave propagation modeling. It is found that in wave propagation modeling the use of non-constant spherical influence functions, even though this is common in peridynamic models, can lead to phase shift phenomena in certain bond-associated models. Overall, this work provides a comprehensive and unified treatment of bond-associated peridynamic material correspondence models, and it is intended to serve as a valuable reference for further development and application of bond-associated material correspondence formulations in peridynamics.},
  archive      = {J_CMAME},
  author       = {Xuan Hu and Hailong Chen and Shaofan Li},
  doi          = {10.1016/j.cma.2025.118340},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118340},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A unified framework of bond-associated peridynamic material correspondence models: Formulation and evaluation},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative high-order weakly compressible smoothed particle hydrodynamics model for viscous fluid flows. <em>CMAME</em>, <em>447</em>, 118339. (<a href='https://doi.org/10.1016/j.cma.2025.118339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smoothed particle hydrodynamics (SPH) is an efficient and robust particle-based method for large deformation problems such as strongly nonlinear free interface flow and structural damage due to its meshless characteristics. However, achieving consistent high-order accuracy remains a fundamental challenge under irregular particle distributions, which often leads to significant accuracy degradation in conventional SPH interpolation schemes. To address this issue, we propose a novel iterative high-order SPH framework to systematically improve the accuracy of gradient and Laplacian operators through multiple layers of Taylor expansions. An adaptive iteration strategy is introduced at each expansion layer, resulting in a recursive correction that utilizes high-order derivatives to improve low-order estimates, thereby improving consistency and robustness for inhomogeneous particle fields. To maintain accuracy near domain boundaries, a new high-order ghost particle extrapolation scheme is developed to ensure consistency of spatial derivatives. The proposed framework is validated on a series of typical incompressible viscous flow benchmarks, including Taylor-Green vortex, Lamb-Osing vortex, inviscid shear layer, Burggraf flow, and Lid driven flow. Results show that the proposed approach achieves up to fourth-order convergence even with irregular particle arrangements and improves simulation accuracy by two orders of magnitude compared to the conventional SPH formulation. By avoiding the use of high-order kernel functions and large matrix systems, this method provides a scalable approach for high-fidelity particle-based simulations.},
  archive      = {J_CMAME},
  author       = {Guixun Zhu and Siming Zheng and Yaru Ren and Yuzhu Pearl Li},
  doi          = {10.1016/j.cma.2025.118339},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118339},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Iterative high-order weakly compressible smoothed particle hydrodynamics model for viscous fluid flows},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-energy physics-informed multi-material topology optimization method within the phase-field framework. <em>CMAME</em>, <em>447</em>, 118338. (<a href='https://doi.org/10.1016/j.cma.2025.118338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a dual-energy physics-informed multi-material topology optimization method within the phase-field framework. The method employs a dual-network collaborative architecture, utilizing two fully connected networks incorporating Fourier transformations to approximate the displacement field and the multiphase field, respectively. This approach enables a fully physics-driven optimization process throughout the entire workflow. The displacement field is approximated via the deep energy method, using the principle of minimum potential energy as the driving mechanism. Within the phase-field framework, an energy functional is constructed that incorporates the classical Ginzburg-Landau free energy, elastic strain energy and volume fraction constraints. This functional serves as the loss function that couples the displacement and phase fields, promoting the balancing of mechanical performance, interface thickness, material volume fractions, and phase repulsion during network training. Thus it achieves a deep integration of multi-material physical information. The pretraining strategy effectively reduces convergence time and enhances optimization performance. Automatic differentiation replaces traditional sensitivity analysis, enhancing computational efficiency, while appropriate control of sampling points balances training cost and accuracy. Several numerical experiments validate the effectiveness of the proposed method.},
  archive      = {J_CMAME},
  author       = {Sijing Lai and Jiachen Feng and Zhixian Lv and Junseok Kim and Yibao Li},
  doi          = {10.1016/j.cma.2025.118338},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118338},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A dual-energy physics-informed multi-material topology optimization method within the phase-field framework},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Midplane based 3D single pass unbiased segment-to-segment contact interaction using penalty method. <em>CMAME</em>, <em>447</em>, 118335. (<a href='https://doi.org/10.1016/j.cma.2025.118335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces a contact interaction methodology for an unbiased treatment of contacting surfaces without assigning surfaces as master and slave. Contact tractions between interacting discrete segments are evaluated with respect to a midplane in a single pass, inherently maintaining traction equilibrium. These tractions are based on the penalisation of true interpenetration between opposite surfaces, and the procedure of their integral for discrete contacting segments is described. A detailed examination of the possible geometric configurations of interacting 3D segments is provided to support visual understanding and better traction evaluation accuracy. The accuracy and robustness of the proposed method are validated against the analytical solutions of the contact patch test and Hertzian contact, demonstrating the capability to reproduce contact between flat and curved surfaces. The method passes the contact patch test with the uniform transmission of contact pressure matching the accuracy levels of finite elements. It converges towards the analytical solution with appropriate mesh refinement and a suitably high penalty factor in Hertzian contact. Dynamic problems involving elastic and inelastic collisions between two bars, as well as oblique collisions of cylinders, are also presented. The ability of the algorithm to resolve contacts between flat and curved surfaces in nonconformal meshes for both static and dynamic cases with high accuracy demonstrates its versatility for general contact problems, including self-contact.},
  archive      = {J_CMAME},
  author       = {Indrajeet Sahu and Nik Petrinic},
  doi          = {10.1016/j.cma.2025.118335},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118335},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Midplane based 3D single pass unbiased segment-to-segment contact interaction using penalty method},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistent pressure formulation of the stokes problem and approximation thereof. <em>CMAME</em>, <em>447</em>, 118333. (<a href='https://doi.org/10.1016/j.cma.2025.118333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A non-conforming approximation of a non standard formulation of the generalized Stokes problem is proposed using continuous finite elements. The stability, convergence, and scalability properties of the method are numerically tested. Four key features of the method are as follows: (i) It is observed to converge optimally with pairs of equal order; (ii) The resulting algebraic system is simple to precondition; (iii) The formulation is pressure-robust for equal pairs; (iv) The formulation is particularly well adapted for the approximation of the time-dependent incompressible Navier-Stokes equations.},
  archive      = {J_CMAME},
  author       = {Melvin Creff and Jean-Luc Guermond},
  doi          = {10.1016/j.cma.2025.118333},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118333},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Consistent pressure formulation of the stokes problem and approximation thereof},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving long-term autoregressive spatiotemporal predictions: A proof of concept with fluid dynamics. <em>CMAME</em>, <em>447</em>, 118332. (<a href='https://doi.org/10.1016/j.cma.2025.118332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven approaches have emerged as a powerful alternative to traditional numerical methods for forecasting physical systems, offering fast inference and reduced computational costs. However, for complex systems and those without prior knowledge, the accuracy of long-term predictions frequently deteriorates due to error accumulation. Existing solutions often adopt an autoregressive approach that unrolls multiple time steps during each training iteration; although effective for long-term forecasting, this method requires storing entire unrolling sequences in GPU memory, leading to high resource demands. Moreover, optimizing for long-term accuracy in autoregressive frameworks can compromise short-term performance. To address these challenges, we introduce the Stochastic PushForward (SPF) training framework in this paper. SPF preserves the one-step-ahead training paradigm while still enabling multi-step-ahead learning. It dynamically constructs a supplementary dataset from the model’s predictions and uses this dataset in combination with the original training data. By drawing inputs from both the ground truth and model-generated predictions through a stochastic acquisition strategy, SPF naturally balances short- and long-term predictive performance and further reduces overfitting and improves generalization. Furthermore, the training process is executed in a one-step-ahead manner, with multi-step-ahead predictions precomputed between epochs-thus eliminating the need to retain entire unrolling sequences in memory, thus keeping memory usage stable. We demonstrate the effectiveness of SPF on the Burgers’ equation and the Shallow Water benchmark. Experimental results demonstrated that SPF delivers superior long-term accuracy compared to autoregressive approaches while reducing memory consumption. This positions SPF as a promising solution for resource-constrained environments and complex physical simulations.},
  archive      = {J_CMAME},
  author       = {Hao Zhou and Sibo Cheng},
  doi          = {10.1016/j.cma.2025.118332},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118332},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Improving long-term autoregressive spatiotemporal predictions: A proof of concept with fluid dynamics},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A curvilinear surface ALE formulation for self-evolving navier-stokes manifolds – Stabilized finite element formulation. <em>CMAME</em>, <em>447</em>, 118331. (<a href='https://doi.org/10.1016/j.cma.2025.118331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a stabilized finite element formulation of the arbitrary Lagrangian-Eulerian (ALE) surface theory for Navier-Stokes flow on self-evolving manifolds developed in Sauer [1]. The formulation is physically frame-invariant, applicable to large deformations, and relevant to fluidic surfaces such as soap films, capillary menisci and lipid membranes, which are complex and inherently unstable physical systems. It is applied here to area-incompressible surface flows using a stabilized pressure-velocity (or surface tension-velocity) formulation based on quadratic finite elements and implicit time integration. The unknown ALE mesh motion is determined by membrane elasticity such that the in-plane mesh motion is stabilized without affecting the physical behavior of the system. The resulting three-field system is monolithically coupled, and fully linearized within the Newton-Rhapson solution method. The new formulation is demonstrated on several challenging examples including shear flow on self-evolving surfaces and inflating soap bubbles with partial inflow on evolving boundaries. Optimal convergence rates are obtained in all cases. Particularly advantageous are C 1 -continuous surface discretizations, for example based on NURBS.},
  archive      = {J_CMAME},
  author       = {Roger A. Sauer},
  doi          = {10.1016/j.cma.2025.118331},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118331},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A curvilinear surface ALE formulation for self-evolving navier-stokes manifolds – Stabilized finite element formulation},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive physics-informed system modeling with control for nonlinear structural system estimation. <em>CMAME</em>, <em>447</em>, 118330. (<a href='https://doi.org/10.1016/j.cma.2025.118330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately capturing the nonlinear dynamic behavior of structures remains a significant challenge in mechanics and engineering. Traditional physics-based models and data-driven approaches often struggle to simultaneously ensure model interpretability, noise robustness, and estimation optimality. To address this issue, this paper proposes an Adaptive Physics-Informed System Modeling with Control (APSMC) framework. By integrating Kalman filter-based state estimation with physics-constrained proximal gradient optimization, the framework adaptively updates time-varying state-space model parameters while processing real-time input–output data under white noise disturbances. Theoretically, this process is equivalent to real-time tracking of the Jacobian matrix of a nonlinear dynamical system. Within this framework, we leverage the theoretical foundation of stochastic subspace identification to demonstrate that, as observational data accumulates, the APSMC algorithm yields state-space model estimates that converge to the theoretically optimal solution. The effectiveness of the proposed framework is validated through numerical simulations of a Duffing oscillator and the seismic response of a frame structure, as well as experimental tests on a scaled bridge model and real wind turbine health monitoring data. Experimental results show that, under noisy conditions, APSMC successfully predicts 19 consecutive 10-second time series using only a single initial 10-second segment for model updating, achieving a minimum normalized mean square error (NMSE) of 0.398 %. Furthermore, APSMC achieves the best performance among classical time-domain algorithms on measured wind turbine acceleration data. These findings demonstrate that the APSMC framework not only offers superior online identification and denoising performance but also provides a reliable foundation for downstream applications such as structural health monitoring, real-time control, adaptive filtering, and system identification. An open-source Python implementation is available on GitHub .},
  archive      = {J_CMAME},
  author       = {Biqi Chen and Chenyu Zhang and Jun Zhang and Ying Wang},
  doi          = {10.1016/j.cma.2025.118330},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118330},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Adaptive physics-informed system modeling with control for nonlinear structural system estimation},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics-augmented GraphGPS framework for the reconstruction of 3D riemann problems from sparse data. <em>CMAME</em>, <em>447</em>, 118328. (<a href='https://doi.org/10.1016/j.cma.2025.118328'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In compressible fluid flow, reconstructing shocks, discontinuities, rarefactions, and their interactions from sparse measurements is an important inverse problem with practical applications. Moreover, physics-informed machine learning has recently become an increasingly popular approach for performing reconstructions tasks. In this work we explore a machine learning recipe, known as GraphGPS, for reconstructing canonical compressible flows known as 3D Riemann problems from sparse observations, in a physics-informed manner. The GraphGPS framework combines the benefits of positional encodings, local message-passing of graphs, and global contextual awareness, and we explore the latter two components through an ablation study. Furthermore, we modify the aggregation step of message-passing such that it is aware of shocks and discontinuities, resulting in sharper reconstructions of these features. Additionally, we modify message-passing such that information flows strictly from known nodes only, which results in computational savings, better training convergence, and no degradation of reconstruction accuracy. We also show that the GraphGPS framework outperforms numerous machine learning and classical benchmarks.},
  archive      = {J_CMAME},
  author       = {Rami Cassia and Rich Kerswell},
  doi          = {10.1016/j.cma.2025.118328},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118328},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A physics-augmented GraphGPS framework for the reconstruction of 3D riemann problems from sparse data},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A low-level teamwork hybrid model based swarm intelligent algorithm for engineering design optimization. <em>CMAME</em>, <em>447</em>, 118317. (<a href='https://doi.org/10.1016/j.cma.2025.118317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a multi-algorithm hybrid strategy, named WIFN, to mitigate the poor performance of the naked mole-rat algorithm (NMRA). The proposed WIFN algorithm employs the best exploration and exploitation properties of existing algorithms, viz. weighted mean of vectors (INFO), whale optimization algorithm (WOA) and fission fusion optimization (FuFiO). These algorithms are integrated into the worker phase of the NMRA. A new stagnation phase is introduced in WIFN to minimize the effect of local optima stagnation. To add self-adaptivity, five new mutation/inertia weight strategies are added to the parameters of WIFN. To assess its performance, four data sets are used: classical benchmarks, CEC 2014, CEC 2017 and CEC 2019. An experimental study is carried out using i) five constrained engineering design problems and ii) 15 real-world constrained problems from the CEC 2020 benchmark dataset to analyze the applicability of WIFN for computationally expensive problems. In addition, WIFN is applied to multilevel image thresholding with type-II fuzzy sets. It is tested using a real image set that features different histogram distributions for three different threshold numbers. Experimental results suggest that WIFN perform significantly better than the existing state-of-the-art algorithms in terms of quality metrics, viz. mean squared error (MSE), peak signal-to-noise ratio (PSNR), and structural similarity index (SSIM). Wilcoxon’s ranksum and the Friedman test establish the superiority of WIFN statistically.},
  archive      = {J_CMAME},
  author       = {Amanjot Kaur Lamba and Rohit Salgotra and Nitin Mittal},
  doi          = {10.1016/j.cma.2025.118317},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118317},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A low-level teamwork hybrid model based swarm intelligent algorithm for engineering design optimization},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-stage constitutive modeling framework based on finite strain data-driven identification and physics-augmented neural networks. <em>CMAME</em>, <em>447</em>, 118289. (<a href='https://doi.org/10.1016/j.cma.2025.118289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this contribution, we present a novel consistent dual-stage approach for the automated generation of hyperelastic constitutive models which only requires experimentally measurable data. As a proof of concept, the present work relies on synthetic data generated through virtual experiments. To generate input data for our approach, an experiment with full-field measurement has to be conducted to gather testing force and corresponding displacement field of the sample. Then, in the first step of the dual-stage framework, a new finite strain Data-Driven Identification (DDI) formulation is applied. This method enables to identify tuples consisting of stresses and strains by only prescribing the applied boundary conditions and the measured displacement field. In the second step, the data set is used to calibrate a Physics-Augmented Neural Network (PANN), which fulfills all common conditions of hyperelasticity by construction and is very flexible at the same time. We demonstrate the applicability of our approach by several descriptive examples. Two-dimensional synthetic data are exemplarily generated in virtual experiments by using a reference constitutive model. The calibrated PANN is then applied in 3D Finite Element simulations. In addition, a real experiment including noisy data is mimicked.},
  archive      = {J_CMAME},
  author       = {Lennart Linden and Karl A. Kalina and Jörg Brummund and Brain Riemer and Markus Kästner},
  doi          = {10.1016/j.cma.2025.118289},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {12},
  pages        = {118289},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A dual-stage constitutive modeling framework based on finite strain data-driven identification and physics-augmented neural networks},
  volume       = {447},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="comcom">COMCOM - 40</h2>
<ul>
<li><details>
<summary>
(2025). A scalable blockchain framework for IoT based on restaking and incentive mechanisms. <em>COMCOM</em>, <em>242</em>, 108317. (<a href='https://doi.org/10.1016/j.comcom.2025.108317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a scalable blockchain framework based on sidechain solution for the Internet of Things (IoT). Considering the low-trust models of existing sidechains, we present a restaking-based trust aggregation method for Proof of Stake (PoS). By allowing mainchain validators to duplicate their stake on the sidechain network, we enhance the cryptoeconomics security of the sidechain while reducing costs. Given the potential conflicts between risks and rewards of trust aggregation, and the challenges posed by the heterogeneity of IoT devices for quantitative analysis, we propose an incentive analysis framework based on contract. By analyzing the optimal strategies of different risk-preference validators, design differentiated contracts to promote incentive-compatible outcomes. Additionally, we account for the uncertainty in the distribution of sidechain validators and discuss optimal configurations under various conditions. To address potential collusion attacks, we introduce a quantifiable exemption mechanism to limit the security risks. Finally, numerical simulations verify the feasibility and effectiveness of our proposed method.},
  archive      = {J_COMCOM},
  author       = {Fang Ye and Zitao Zhou and Yifan Wang and Yibing Li},
  doi          = {10.1016/j.comcom.2025.108317},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108317},
  shortjournal = {Comput. Commun.},
  title        = {A scalable blockchain framework for IoT based on restaking and incentive mechanisms},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proactive retention-aware online video caching scheme in mobile edge computing. <em>COMCOM</em>, <em>242</em>, 108313. (<a href='https://doi.org/10.1016/j.comcom.2025.108313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current massive video requests have caused severe network congestion. To reduce transmission latency and improve user Quality of Experience (QoE), caching infrastructures are deployed closer to the edge. Nowadays, most caching systems tend to cache content with a high programming voltage to ensure a long retention time, which leads to significant cache damage. However, as new videos emerge every second, the rapidly changing popularity makes long retention time wasteful in terms of caching resource. Moreover, with the rise of emerging video formats (such as virtual reality content), the diverse requirements for transmission latency across various video categories make balancing user QoE more challenging. To tackle these challenges, we propose a joint optimization framework that balances user QoE and operational costs through video category recognition and adaptive retention time selection. First, we model user QoE as transmission latency cost and further formulate the optimization problem as a Markov Decision Process (MDP) to minimize the system cost. To solve the proposed problem, we design a two-step Double Deep Q-Network (DDQN)-based scheme. The scheme first determines the optimal retention time through unifying the process of action selection and state-value evaluation. Secondly, it makes replacement decisions according to the computed caching value of each content. By validating on three datasets, the experiments show that the proposed scheme outperforms the baseline algorithms in both cache hit rate and system cost.},
  archive      = {J_COMCOM},
  author       = {Guangzhou Liu and Zhen Qian and Guanghui Li},
  doi          = {10.1016/j.comcom.2025.108313},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108313},
  shortjournal = {Comput. Commun.},
  title        = {Proactive retention-aware online video caching scheme in mobile edge computing},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trust-defined network: A panoramic P2P framework for distributed ledger systems. <em>COMCOM</em>, <em>242</em>, 108311. (<a href='https://doi.org/10.1016/j.comcom.2025.108311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has revolutionized distributed ledger systems by offering superior security and transparency compared to traditional centralized systems. Despite its advantages, current blockchain systems face significant challenges such as network congestion, communication errors, and scalability issues, largely due to the limitations of blockchain peer-to-peer (P2P) protocols. These problems hinder the performance, reliability, and widespread adoption of blockchain technology. In this paper, we propose a Trust-Defined Network (TDN) framework designed to solve these challenges by reflecting the physical network information to the blockchain. This approach enables the precise diagnosis of existing blockchain P2P protocol limitations and facilitates the objective verification of new improvement measures. Our proposed framework supports various blockchain network environments, particularly Ethereum-based networks, and ensures enhanced network stability and performance. Through extensive simulations and real-world case studies in IoT-enabled blockchain applications, we demonstrate that TDN significantly reduces network congestion, improves transaction finality, and enhances the reliability of blockchain communication channels. These findings highlight the framework’s potential to optimize blockchain infrastructure, making it more robust for large-scale deployment and real-world applications.},
  archive      = {J_COMCOM},
  author       = {Taehoon Yoo and Kiseok Kim and Hwangnam Kim},
  doi          = {10.1016/j.comcom.2025.108311},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108311},
  shortjournal = {Comput. Commun.},
  title        = {Trust-defined network: A panoramic P2P framework for distributed ledger systems},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-reinforcement learning driven model architecture and algorithm optimization in intelligent driving task offloading. <em>COMCOM</em>, <em>242</em>, 108310. (<a href='https://doi.org/10.1016/j.comcom.2025.108310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of rapid development of intelligent driving technology, the amount of data generated by vehicles increases dramatically, while the bottleneck of storage and computation capacity of in-vehicle devices becomes more and more prominent, and task offloading becomes the key to improve the performance of intelligent driving systems. In this context, this paper proposes the MRL-ADTO algorithm, which innovatively applies meta-reinforcement learning (MRL) to the field of intelligent driving task offloading, optimizes the directed acyclic graph (DAG) synthesis logic and the task priority ranking algorithm, designs a neural network model based on the sequence to sequence (Seq2Seq) structure, and introduces the mechanism of multi-head attention at the same time. The experimental results show that MRL-ADTO can significantly reduce the task execution delay in multiple scenarios compared with the existing algorithms, and has obvious advantages in terms of training efficiency and convergence performance, providing an efficient and reliable solution for smart driving task offloading.},
  archive      = {J_COMCOM},
  author       = {Peiying Zhang and Jiamin Liu and Zhiyuan Ren and Lizhuang Tan and Neeraj Kumar and Konstantin Igorevich Kostromitin},
  doi          = {10.1016/j.comcom.2025.108310},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108310},
  shortjournal = {Comput. Commun.},
  title        = {Meta-reinforcement learning driven model architecture and algorithm optimization in intelligent driving task offloading},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed learning-based context-aware SFC deployment in the artificial intelligence of things. <em>COMCOM</em>, <em>242</em>, 108309. (<a href='https://doi.org/10.1016/j.comcom.2025.108309'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the Internet of Things (IoT) and Artificial Intelligence (AI) technologies, the Artificial Intelligence of Things (AIoT) has become a key driving force for realizing intelligent and automated applications. The deployment of Service Function Chains (SFCs) is crucial in dynamic AIoT environments, where efficiently and flexibly deploying SFCs to meet real-time application demands is a research focus. However, existing SFC deployment methods often face challenges such as dynamic variations and uncertainty in contextual information, resource allocation inefficiencies, and limited adaptability to changing network conditions. To address these issues, we propose a learning-based context-aware dynamic SFC deployment method tailored for AIoT environments. Specifically, we introduce an attention-based contextual feature extraction method to capture dynamic changes (e.g., link latency variations) and prioritize key contextual information, improving the rate of served requests by 17.90% (69.60% vs. 59.03% for MADDPG) and enhancing the flexibility of SFC deployment decisions. Additionally, to address resource allocation bottlenecks and adaptability challenges in SFC deployment, we propose a distributed learning-based context-aware approach that uses collaborative learning and periodic updates (every 200 ms) to adjust SFC deployment strategies in response to topology changes and load variations and optimize system performance. Extensive experimental results demonstrate the efficacy of the proposed algorithm. Numerical results demonstrate that our algorithm reduces SFC deployment latency by 8% (46 ms vs. 50 ms for MADDPG), achieves 98.3% computational resource utilization, processes 211 Mbit/s service data volume, and improves adaptability to network changes, as validated in simulations.},
  archive      = {J_COMCOM},
  author       = {Wenlin Cheng and Xingwei Wang and Fuliang Li and Bo Yi and Qiang He and Chuangchuang Zhang and Chengxi Gao and Min Huang},
  doi          = {10.1016/j.comcom.2025.108309},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108309},
  shortjournal = {Comput. Commun.},
  title        = {Distributed learning-based context-aware SFC deployment in the artificial intelligence of things},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-feature fusion approach for physical layer authentication in LEO satellites. <em>COMCOM</em>, <em>242</em>, 108308. (<a href='https://doi.org/10.1016/j.comcom.2025.108308'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial information networks (SINs) have emerged as a means to enhance the expanse and dependability of communication and data transmission services. SINs rely on satellite systems to provide these services, among which low earth orbit (LEO) satellites are widely concerned because of their advantages of low orbital altitude, small network transmission delay, small path loss, and high signal strength. However, due to the frequent switching of communication links between LEO satellites and the ground, the authentication mechanism of the ground users to the satellites is vulnerable to spoofing attacks, and the traditional upper layer authentication method based on encryption usually requires a lot of overhead and delay. In this case, the lightweight physical layer authentication (PLA) mechanism utilizes the inherent distinctiveness and unpredictable nature of channel physical properties, serving as a vital application in SINs for ensuring authentication. Therefore, our work introduces a PLA method incorporating multi-feature integration, aimed at delivering effective identity verification tailored for LEO satellites. The approach employs doppler frequency shift (DS), angles of arrival (AOAs), and received power (RP) features, fusing an support vector machine (SVM) classifier, to distinguish between legal and illegal satellites in different simulation scenarios. The satellite toolkit (STK) is used to collect data from the actual orbit of satellites and assess the efficacy of the scheme. The findings indicate that the scheme offers enhanced authentication capabilities.},
  archive      = {J_COMCOM},
  author       = {Rongjun Yan and Fan Jia},
  doi          = {10.1016/j.comcom.2025.108308},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108308},
  shortjournal = {Comput. Commun.},
  title        = {A multi-feature fusion approach for physical layer authentication in LEO satellites},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating blockchain with IoT: Evaluating the feasibility of lightweight bitcoin wallets on resource-constrained devices. <em>COMCOM</em>, <em>242</em>, 108300. (<a href='https://doi.org/10.1016/j.comcom.2025.108300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of blockchain technology with IoT architectures holds immense potential for advancing application design and enhancing security properties. However, the resource constraints typically present in IoT devices pose a challenge. This paper explores the feasibility of running a lightweight Bitcoin wallet on IoT devices and identifies the minimum requirements for their successful operation. A review of the literature is used to identify existing integration architectures and derive the wallet needs. The study evaluates performance metrics such as execution time, memory usage, network data transmission, and power consumption to determine the feasibility of deploying these architectures.},
  archive      = {J_COMCOM},
  author       = {Mohsen Rahmanikivi and Cristina Pérez-Solà and Víctor Garcia-Font},
  doi          = {10.1016/j.comcom.2025.108300},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108300},
  shortjournal = {Comput. Commun.},
  title        = {Integrating blockchain with IoT: Evaluating the feasibility of lightweight bitcoin wallets on resource-constrained devices},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Source-rate planning in self-powered wireless multi-hop D2D settings under stochasticity: A scenario-based iterative optimization approach. <em>COMCOM</em>, <em>242</em>, 108299. (<a href='https://doi.org/10.1016/j.comcom.2025.108299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop Device-to-Device (D2D) communications are emerging as the foundation for numerous compelling 6G applications, enabling seamless information flow between distributed nodes. In the context of such uncertain wireless multi-hop D2D settings, jointly optimizing source data rates, routing, and transmission power decisions is both an essential task and a highly complex problem, particularly due to uncertainties introduced by the wireless channel states and the energy harvesting processes on the nodes. In the current literature, this problem is mostly tackled in a future agnostic sense, and/or using specific distributions to model the uncertainties. In contrast, in this paper, we compute a future energy and resource allocation plan of the network’s operation, using scenario-based optimization techniques to account for stochasticities. Scenarios can model generic distributions of uncertain quantities in a tractable manner. The formulated problem is inherently non-convex and to solve it, we propose CoNetPlan-E, a heuristic iterative method that at each iteration solves appropriately parameterized convex approximations of the original problem. We prove that CoNetPlan-E converges under realistic assumptions, while ensuring that the obtained solution at convergence is feasible for the original non-convex problem. Numerical evaluations showcase the effectiveness of the proposed method compared to existing baseline solutions, while considering three levels of increasing network topology complexity. Importantly, CoNetPlan-E is superior with respect to scalability and runtime while leading to close-to-optimal solutions as these are determined by the standard non-convex solver Ipopt.},
  archive      = {J_COMCOM},
  author       = {Georgia Stavropoulou and Eleni Stai and Maria Diamanti and Symeon Papavassiliou},
  doi          = {10.1016/j.comcom.2025.108299},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108299},
  shortjournal = {Comput. Commun.},
  title        = {Source-rate planning in self-powered wireless multi-hop D2D settings under stochasticity: A scenario-based iterative optimization approach},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed denial of service attack analysis and mitigation for MQTTv5 shared subscription. <em>COMCOM</em>, <em>242</em>, 108298. (<a href='https://doi.org/10.1016/j.comcom.2025.108298'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sixth-generation (6G) networks will feature Massive IoT (M-IoT) deployments with a huge number of interconnected devices, enabling fast and reliable IoT applications. To address scalability and enhance message delivery, MQTTv5 introduces the shared subscription mechanism. However, the increased interconnectivity amplifies security vulnerabilities, posing significant risks with potentially severe consequences. In light of these challenges, this work aims to conduct a security-focused analysis of the shared subscription feature. Our study highlights the potential extent of damage from such an attack, which can potentially lead to indefinite starvation among legacy subscribers, and proposes a countermeasure to mitigate its impact. Additionally, to provide comprehensive security to the proposed mitigation mechanism, we design an Authenticated Encryption with Associated Data (AEAD)-based protection to counteract external malicious entities as well as an attacker detection mechanism based on a trust-based approach combined with the z-score statistical method to protect the proposed mitigation against internal attackers. These countermeasures are designed to accommodate the lightweight nature of MQTT and are characterized by a low protocol footprint while effectively mitigating the impact of the attack. Through an extensive experimental campaign, we tested this solution under real IoT traffic patterns to demonstrate its effectiveness and capability to restore the performance of the MQTT system targeted by the discovered attack.},
  archive      = {J_COMCOM},
  author       = {Graziano Rizzo and Mattia Giovanni Spina and Floriano De Rango},
  doi          = {10.1016/j.comcom.2025.108298},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108298},
  shortjournal = {Comput. Commun.},
  title        = {Distributed denial of service attack analysis and mitigation for MQTTv5 shared subscription},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applying reinforcement learning in slotted LoRaWAN: From concept to implementation. <em>COMCOM</em>, <em>242</em>, 108297. (<a href='https://doi.org/10.1016/j.comcom.2025.108297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Low Power Wide Area Networks (LPWANs) are increasingly adopted for Internet of Things (IoT) applications, they face significant challenges related to interference and scalability, which can lead to high collision rates and reduced network throughput. This paper presents a novel approach to enhancing the performance of LoRaWAN, one of the dominant LPWAN protocols, by leveraging Reinforcement Learning (RL). The proposed solution introduces a synchronization framework designed to operate under LoRaWAN principles, coupled with a low-cost, on-device RL mechanism that autonomously mitigates collisions. Through extensive simulations and real-world experiments, the effectiveness of the RL approach is demonstrated, showing an over 30% improvement in terms of packet delivery ratio (PDR) compared to traditional multiple access methods such as Pure-Aloha, Slotted-Aloha, and Carrier Sense Multiple Access (CSMA). Additionally, open-source implementations for both simulation and experimental validation are provided, ensuring reproducibility and facilitating further research in this domain.},
  archive      = {J_COMCOM},
  author       = {Dimitrios Zorbas and Sultan Kasenov and Kamila Salimzhanova and Dias Gaziz and Timur Ismailov and Batyrkhan Baimukhanov},
  doi          = {10.1016/j.comcom.2025.108297},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108297},
  shortjournal = {Comput. Commun.},
  title        = {Applying reinforcement learning in slotted LoRaWAN: From concept to implementation},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on grouping strategy for NOMA downlink based on pointer network. <em>COMCOM</em>, <em>242</em>, 108296. (<a href='https://doi.org/10.1016/j.comcom.2025.108296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the application of Non-Orthogonal Multiple Access (NOMA) technology in 5G and beyond communication systems, how to effectively group users to optimize power allocation has become a key challenge. This paper proposes a user grouping method based on a Pointer Network, which efficiently extracts user location information through embedding layers, encoder–decoder structures, and attention mechanisms, achieving the goal of precise grouping decisions and power optimization. The embedding layer maps users’ two-dimensional coordinates into a high-dimensional space, enhancing the model’s spatial awareness. The encoder–decoder structure, combined with Long Short-Term Memory (LSTM) networks and attention mechanisms, captures the spatiotemporal dependencies between users and dynamically selects the optimal path during the grouping process. Experimental results show that when users are located 300 meters from the base station, the recognition accuracy of a 4-user grouping reaches 94.85%, and that of a 6-user grouping reaches 89.3%. The method also demonstrates strong robustness under multipath fading channels and low signal-to-noise ratio conditions. Compared to random grouping methods, the proposed grouping strategy exhibits better adaptability and scalability in complex communication environments, significantly reducing power consumption, and providing new technical support for resource allocation and energy management in NOMA systems.},
  archive      = {J_COMCOM},
  author       = {Lingfeng Wu and Rui Zhu and Yarong Chen and Peng Chu and Juan Tian and Jiuxiao Cao},
  doi          = {10.1016/j.comcom.2025.108296},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108296},
  shortjournal = {Comput. Commun.},
  title        = {Research on grouping strategy for NOMA downlink based on pointer network},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Private networks: Evolution, ecosystem, use cases, architecture, spectrum, and deployment challenges. <em>COMCOM</em>, <em>242</em>, 108295. (<a href='https://doi.org/10.1016/j.comcom.2025.108295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private networks have reshaped enterprise communications by providing unmatched control, security, and tailored solutions for various industries. This paper presents an in-depth survey of private networks, covering their evolution, current landscape, and future outlook. Key topics include the use cases, architecture, spectrum management, and deployment strategies. The study examines the transition from private 4G/LTE to private 5G networks, fueled by demands for higher data throughput and ultra-low latency across sectors. It highlights the advantages of private 5G over public mobile networks (MNOs) and Wi-Fi, with a special focus on spectrum sharing as a means to optimize frequency use. Additionally, the paper reviews global spectrum allocations for private 5G, providing an overview of regulatory frameworks and available frequency bands across countries. It also explores future prospects, including private 6G networks and emerging spectrum technologies. Key challenges such as high deployment costs, interoperability issues, and security concerns are discussed alongside potential solutions. Through this comprehensive analysis, the paper aims to provide valuable insights for researchers, practitioners, and policymakers in the field of private networks.},
  archive      = {J_COMCOM},
  author       = {Onur Sahin and Vanlin Sathya and Mehmet Yavuz},
  doi          = {10.1016/j.comcom.2025.108295},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108295},
  shortjournal = {Comput. Commun.},
  title        = {Private networks: Evolution, ecosystem, use cases, architecture, spectrum, and deployment challenges},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simplifying distributed application deployment at the edge through software-defined overlay networks. <em>COMCOM</em>, <em>242</em>, 108294. (<a href='https://doi.org/10.1016/j.comcom.2025.108294'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for low latency, bandwidth efficiency, and privacy has driven the deployment of distributed applications to the network edge. However, edge environments introduce concrete challenges such as limited infrastructure control, constrained connectivity due to NAT or firewalls, and the heterogeneity of devices and network conditions. This paper introduces a software-defined overlay networking (SDON) middleware that addresses these issues by simplifying the development and deployment of edge applications through centralized control and dynamic overlay management. SDON allows applications to define high-level requirements, such as node and link characteristics and the network topology. These requirements are translated into device-specific configurations and enforced across suitable edge devices. We implemented our SDON middleware as a fully functional software and evaluated it in two edge computing use cases: i) routing for video streaming across middleboxed edge devices and ii) computation offloading on heterogeneous edge devices. Our results show that deployments via SDON, with centrally enforced optimizations, improve application performance by reducing mean streaming latency by 20 % and computation times by 22 %.},
  archive      = {J_COMCOM},
  author       = {Heiko Bornholdt and Kevin Röbert and Stefan Schulte and Janick Edinger and Mathias Fischer},
  doi          = {10.1016/j.comcom.2025.108294},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108294},
  shortjournal = {Comput. Commun.},
  title        = {Simplifying distributed application deployment at the edge through software-defined overlay networks},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving satellite network efficiency with terminal traffic prediction and SQP-SRA algorithm. <em>COMCOM</em>, <em>242</em>, 108293. (<a href='https://doi.org/10.1016/j.comcom.2025.108293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the low resource utilization in satellite networks caused by heterogeneous regional traffic demands, this paper proposes a resource allocation strategy for LEO satellite internet based on terminal traffic prediction. An improved LSTM-GRU hybrid model is developed using real-world datasets to forecast ground traffic, accounting for periodic patterns and weather effects. A leaseable EOSN differentiated transmission framework is designed to enable targeted resource allocation and inter-satellite leasing, enhancing network coverage. To optimize data transmission ratios, user bandwidth, and service pricing, we introduce a sequential quadratic programming-based satellite resource allocation (SQP-SRA) algorithm that balances latency and energy consumption. Compared with LSTM, GRU, Transformer, and wavelet neural networks, the proposed model reduces traffic prediction error by approximately 26%. Simulation results demonstrate that, relative to the DDTOA, FCFS, and TOMRA algorithms, the proposed strategy improves user benefits by approximately 60% and enhances satellite service provider revenues by approximately 80%.},
  archive      = {J_COMCOM},
  author       = {Liangang Qi and Enqiang Wang and Tianfang Xu and Yuan Zhu and Yun Zhao},
  doi          = {10.1016/j.comcom.2025.108293},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108293},
  shortjournal = {Comput. Commun.},
  title        = {Improving satellite network efficiency with terminal traffic prediction and SQP-SRA algorithm},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved AVB-aware scheduling of time-triggered traffic in time-sensitive networks. <em>COMCOM</em>, <em>242</em>, 108292. (<a href='https://doi.org/10.1016/j.comcom.2025.108292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-Sensitive Networking (TSN) provides deterministic services for diverse traffic types within a unified network. Among them, time-triggered (TT) traffic requires stringent timing guarantees, typically achieved through precise scheduling using Gate Control Lists (GCLs) in Time-Aware Shapers (TASs). However, most existing studies primarily focus on TT scheduling, often overlooking its impact on Audio Video Bridging (AVB) traffic, which demands worst-case delay (WCD) guarantees. This paper proposes an improved AVB-aware scheduling approach for TT traffic that enhances AVB performance without compromising TT schedulability. A rigorous network calculus analysis identifies two critical factors influencing WCD of AVB traffic: the maximum TT window length and the minimum relative offset between adjacent TT windows. Building on these insights, we develop a lightweight objective function for TT flow scheduling, enabling efficient evaluation of the impact on AVB traffic. This objective function is embedded into a Greedy Randomized Adaptive Search Procedure (GRASP)-based scheduling framework, further enhanced by a flow sorting strategy and a flexible local search mechanism that prioritizes high-impact TT flows and adaptively escapes local optima. Simulation results demonstrate that the proposed method significantly improves AVB performance and reduces runtime overhead, while consistently maintaining full TT schedulability across diverse TSN scenarios.},
  archive      = {J_COMCOM},
  author       = {Meng Wang and Yiqin Lu},
  doi          = {10.1016/j.comcom.2025.108292},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108292},
  shortjournal = {Comput. Commun.},
  title        = {An improved AVB-aware scheduling of time-triggered traffic in time-sensitive networks},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing vertical handover of energy efficient sleep mode schemes in heterogeneous networks. <em>COMCOM</em>, <em>242</em>, 108291. (<a href='https://doi.org/10.1016/j.comcom.2025.108291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous networks (HetNets) are a promising solution for the growing traffic demands of 5G. However, the continuous construction of small base stations (SBSs) increases the number of vertical handovers, which is closely related to a decrease in quality of service (QoS) due to the challenges in handover management. Therefore, many studies calculate the vertical handover rate using simulation-based or numerical methods. The sleep mode schemes, which dynamically put some SBSs into sleep mode, aim to address the concerns of excessive power consumption and also reduce the number of vertical handovers. Sleep modes are cost-effective and have become one of the popular methods for reducing energy consumption in HetNets. However, there is currently no model to analyze the number of vertical handovers when sleep modes are applied, making it difficult for internet service providers (ISPs) to estimate the impact of vertical handovers. In this paper, we analyze the number of vertical handovers in sleep mode schemes for heterogeneous networks and calculate the energy savings of three different schemes. The average errors of our proposed mathematical equations are less than 5%.},
  archive      = {J_COMCOM},
  author       = {Ting-Yu Lin and Hao-Zhong Zheng and Chun-Hao Yang and Fang-Yi Lee and Chia-Heng Tu and Meng-Hsun Tsai},
  doi          = {10.1016/j.comcom.2025.108291},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108291},
  shortjournal = {Comput. Commun.},
  title        = {Analyzing vertical handover of energy efficient sleep mode schemes in heterogeneous networks},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Network traffic classification through high-order L-moments and multi-objective optimization. <em>COMCOM</em>, <em>242</em>, 108290. (<a href='https://doi.org/10.1016/j.comcom.2025.108290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of encrypted and dynamic network traffic poses significant challenges to traditional traffic analysis methods, underscoring the need for robust and scalable solutions. Statistical approaches like L-moments have demonstrated exceptional potential in characterizing traffic flows, offering reduced sensitivity to outliers and the ability to capture higher-order distributional properties with minimal data. Building on previous work by the authors, this study introduces significant enhancements to the L-moment-based methodology for flow analysis and classification, specifically addressing limitations in feature selection and sample size requirements, aspects crucial for achieving deployable configurations in high-performance network environments. Key contributions include the integration of the fifth-order L-moment ratio ( τ 5 ) for enriched traffic representation and a multi-objective optimization framework based on a multi-objective evolutionary algorithm that balances competing goals: minimizing flow features selected for flow classification, reducing sample sizes for L-moment estimation, and maximizing classification quality. The enhanced methodology was applied to the CIC-DDoS2019 dataset, previously used in the authors’ earlier work, enabling direct comparison. Results show a reduction in sample size requirements from 200 to as few as 10, while simultaneously improving classification accuracy and selecting minimal features. These findings demonstrate the scalability and effectiveness of the proposed framework, designed for resource-constrained environments in Next-Generation Networks (NGNs), and make it publicly available for reproducibility and future research.},
  archive      = {J_COMCOM},
  author       = {Jesús Galeano-Brajones and Mihaela I. Chidean and Francisco Luna and Jesús Calle-Cancho and Javier Carmona-Murillo},
  doi          = {10.1016/j.comcom.2025.108290},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108290},
  shortjournal = {Comput. Commun.},
  title        = {Network traffic classification through high-order L-moments and multi-objective optimization},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A blockchain solution for decentralized training in machine learning for IoT. <em>COMCOM</em>, <em>242</em>, 108289. (<a href='https://doi.org/10.1016/j.comcom.2025.108289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of Internet of Things (IoT) devices and applications has led to an increased demand for advanced analytics and machine learning techniques capable of handling the challenges associated with data privacy, security, and scalability. Federated learning (FL) and blockchain technologies have emerged as promising approaches to address these challenges by enabling decentralized, secure, and privacy-preserving model training on distributed data sources. In this paper, we present a novel IoT solution that combines the incremental learning vector quantization algorithm (XuILVQ) with Ethereum blockchain technology to facilitate secure and efficient data sharing, model training, and prototype storage in a distributed environment. Our proposed architecture addresses the shortcomings of existing blockchain-based FL solutions by reducing computational and communication overheads while maintaining data privacy and security. We assess the performance of our system through a series of experiments, showing its potential to enhance the accuracy and efficiency of machine learning tasks in IoT settings.},
  archive      = {J_COMCOM},
  author       = {Carlos Beis-Penedo and Francisco Troncoso-Pastoriza and Rebeca P. Díaz-Redondo and Ana Fernández-Vilas and Manuel Fernández-Veiga and Martín González Soto},
  doi          = {10.1016/j.comcom.2025.108289},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108289},
  shortjournal = {Comput. Commun.},
  title        = {A blockchain solution for decentralized training in machine learning for IoT},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FLoV2T: A fine-grained malicious traffic classification method based on federated learning for AIoT. <em>COMCOM</em>, <em>242</em>, 108288. (<a href='https://doi.org/10.1016/j.comcom.2025.108288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Artificial Intelligence of Things (AIoT), the network security risks associated with AIoT have surged, making precise fine-grained malicious traffic classification (MTC) technology essential, but the reliance on large datasets raises privacy concerns. Federated Learning (FL) offers a privacy-preserving alternative, but existing FL-based solutions still suffer from suboptimal classification accuracy, limited terminal resources, and the non-independent and identically distributed (non-IID) IoT data that hinder effective global model aggregation. To address these issues, this paper introduces FLoV2T — a FL-based fine-grained MTC method for AIoT. To improve classification performance, we first employ a pretrained Vision Transformer (ViT) to extract discriminative features by visualizing raw network traffic as images, thereby tackling the problem of inadequate feature representation. To alleviate the burden of resource constraints and high communication costs, we then implement a local parameter fine-tuning mechanism based on Low-Rank Adaptation (LoRA), significantly reducing the parameter for model learning and communication at the edge. Furthermore, to counteract the model bias towards clients’ non-IID data on model aggregation, we design a regularized parameter aggregation strategy to enhance global model robustness. Experimental results show that FLoV2T achieves an average accuracy of 97.26% and an F1 score of 96.99%, surpassing the baseline by 10.94% and 11.47%. Moreover, LoRA reduces parameter count by approximately 64 times while maintaining high classification performance, and under non-IID conditions, overall performance reaches an average accuracy of 96.17% and an average F1 score of 95.81%, underscoring FLoV2T’s potential in future AIoT communication networks.},
  archive      = {J_COMCOM},
  author       = {Fanyi Zeng and Chen Xu and Dapeng Man and Junhui Jiang and Wu Yang},
  doi          = {10.1016/j.comcom.2025.108288},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108288},
  shortjournal = {Comput. Commun.},
  title        = {FLoV2T: A fine-grained malicious traffic classification method based on federated learning for AIoT},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ILoRa: Interleaving-driven neural network for rate adaptation in LoRa communications. <em>COMCOM</em>, <em>242</em>, 108287. (<a href='https://doi.org/10.1016/j.comcom.2025.108287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rate adaptation in LoRa communications is crucial for improving the channel throughput by adjusting the data rate according to varying channel conditions. Existing methods typically operate at the packet or symbol level, which limits their ability to achieve fine-grained rate adaptation. In this paper, we propose ILoRa, an Interleaving-driven partial transmission method that automatically adjusts transmission rates according to real-time channel conditions. To be specific, we first introduce intra-symbol interleaving that leverages a progressive inorder traversal method to determine the transmission order within a symbol. Then inter-symbol interleaving is applied to coordinate the order across symbols. To manage the interleaving-induced partial transmission and improve communication performance under noisy conditions, we employ a multi-task convolutional recurrent neural network (MT-CRNN). This network leverages advanced data augmentation methods to further enhance channel robustness: time-spectral augmentation to mitigate information loss and synthetic noisy data to simulate various channel conditions. Extensive experimental results demonstrate that ILoRa significantly enhance transmission efficiency while maintaining reliable performance even in challenging environments.},
  archive      = {J_COMCOM},
  author       = {Xiaoke Qi and Haiyang Li and Dian Zhang and Lu Wang},
  doi          = {10.1016/j.comcom.2025.108287},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108287},
  shortjournal = {Comput. Commun.},
  title        = {ILoRa: Interleaving-driven neural network for rate adaptation in LoRa communications},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning based interference optimization for coordinated beamforming in ultra-dense wi-fi networks. <em>COMCOM</em>, <em>242</em>, 108286. (<a href='https://doi.org/10.1016/j.comcom.2025.108286'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next-generation Wi-Fi networks are expected to have an ultra-dense deployment of access points (APs), thus, interference from overlapping basic service sets (OBSSs) poses challenges for interference management. Wi-Fi 8 aims at mitigating such interference using multi-access point coordination (MAPC). One of the MAPC variants is coordinated beamforming (Co-BF), where neighboring APs direct their signals towards specific users. Besides beam steering, APs can also perform null steering, which is more complex but can bring greater performance gains. In this paper, we present a centralized approach named intelligent null steering by reinforcement learning (IntelliNull), designed to reduce interference from neighboring transmitters by coordinated nulling while maximizing the signal quality at each station. We show that training the beam and null steering mechanism with a deep deterministic policy gradient (DDPG), it is possible to steer beams toward associated stations while intelligently nulling the most destructive interference from OBSS rather than nulling random interference directions. This method enhances communication between the AP and neighboring stations by reducing channel access contention, enabling transmissions at full power, and reducing worst-case latency. The proposed IntelliNull agent continuously adapts to changes in the network environment, including node mobility using channel state information (CSI) collected in real-time. We also compare our IntelliNull, which is based on beamforming plus nulling, with the baseline which is based on beamforming only. Our results demonstrate that IntelliNull outperforms the baseline by effectively mitigating interference, leading to higher throughput and better signal-to-interference-plus-noise ratio (SINR), especially in dense deployment scenarios where beamforming alone fails to sufficiently suppress OBSS interference.},
  archive      = {J_COMCOM},
  author       = {Jamshid Bacha and Anatolij Zubow and Szymon Szott and Katarzyna Kosek-Szott and Falko Dressler},
  doi          = {10.1016/j.comcom.2025.108286},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108286},
  shortjournal = {Comput. Commun.},
  title        = {Deep reinforcement learning based interference optimization for coordinated beamforming in ultra-dense wi-fi networks},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient security service function chaining based on federated learning in edge networks. <em>COMCOM</em>, <em>242</em>, 108285. (<a href='https://doi.org/10.1016/j.comcom.2025.108285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The escalating demand for network services has prompted the evolution of Service Function Chaining (SFC) within 6G networks to deliver sophisticated, customized services while ensuring robust cybersecurity. This paper introduces an efficient and secure framework for SFC in Mobile Edge Computing (MEC) environments, termed the Federated Learning-based SFC (FL-SFC), which integrates SFC, MEC, and Federated Learning (FL) to enhance service policy decision-making and safeguard user privacy. The FL-SFC framework enables dynamic updating of service policies and optimizes communication efficiency. We propose an anomaly detection model, CNN-GRU, which combines Convolutional Neural Networks (CNNs) and Gated Recurrent Units (GRUs) to significantly improve anomaly detection performance at the network edge. Additionally, to address the high communication costs associated with service policy models, we have designed a model compression mechanism leveraging sparsification and quantization techniques, which substantially reduces communication overhead during model training. Simulation experiments demonstrated the superiority of the FL-SFC framework and the CNN-GRU model in detection performance over existing methods. Results indicate that our model excels in accuracy, precision, recall, and F1-score while significantly reducing the number of communication bits, thereby validating the effectiveness of our approach.},
  archive      = {J_COMCOM},
  author       = {Yunjian Jia and Jian Yu and Liang Liang and Fang Fang and Wanli Wen},
  doi          = {10.1016/j.comcom.2025.108285},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108285},
  shortjournal = {Comput. Commun.},
  title        = {Efficient security service function chaining based on federated learning in edge networks},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correctness of flow migration across network function instances. <em>COMCOM</em>, <em>242</em>, 108284. (<a href='https://doi.org/10.1016/j.comcom.2025.108284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Functions (NFs) improve the safety and efficiency of networks. Flows traversing NFs may need to be migrated from a source NF instance (sNF) to a destination NF instance (dNF) to balance load, conserve energy, etc. When NFs are stateful, the information stored on an sNF per flow must be migrated to the corresponding dNF before the flow is migrated, to avoid problems of consistency. Our main contribution is to examine what it means to correctly migrate flows from a stateful NF instance. We define the property of Weak-O, where only the state information required for packets to be correctly forwarded from an sNF is migrated first to the corresponding dNF, while the remaining states are eventually migrated. Weak-O can be preserved without buffering or dropping packets, unlike existing algorithms. We propose an algorithm that preserves Weak-O and prove its correctness. Even though this may cause packet re-ordering, we experimentally demonstrate that the goodputs with and without migration are comparable when the old and new paths have the same delays and bandwidths. This is also true when the new path has larger bandwidth or at most 5 times longer delays. Thus flow migration without buffering is practical, contrary to what was thought before. We also prove that no criterion stronger than Weak-O can be preserved in a flow migration system that requires no buffering or dropping of packets and eventually synchronizes its states.},
  archive      = {J_COMCOM},
  author       = {Ranjan Patowary and Gautam Barua and Radhika Sukapuram},
  doi          = {10.1016/j.comcom.2025.108284},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108284},
  shortjournal = {Comput. Commun.},
  title        = {Correctness of flow migration across network function instances},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDR: Stackelberg-based deep reinforcement learning for multi-skill spatiotemporal task allocation in AIoT systems. <em>COMCOM</em>, <em>242</em>, 108283. (<a href='https://doi.org/10.1016/j.comcom.2025.108283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In AIoT-based multi-skill environments, task allocation is a complex process that involves multiple constraints and worker acceptance rates. However, existing studies often overlook worker acceptance rates and fail to properly balance the interests of both workers and requesters. To address this, we propose SDR, a system based on a dual Dueling DQN model in deep reinforcement learning, designed to maximize the long-term utility of all participants while considering user acceptance rates and demand constraints. SDR introduces targeted enhancements in state, action, and reward design to balance acceptance rates with spatiotemporal and skill constraints, optimizing both immediate and long-term task allocation performance. To resolve conflicts of interest, we integrate Pareto optimization into the Q-value computation and action selection. For scenarios where interests align, we adopt Stackelberg game theory to refine the reward mechanism. Extensive simulations on both synthetic and real-world datasets validate the effectiveness of our approach in improving task allocation and pricing strategies.},
  archive      = {J_COMCOM},
  author       = {Yu Li and Fengya Yin and Yihao Zheng and Wenjian Xu and Jung Yoon Kim and Zhe Peng},
  doi          = {10.1016/j.comcom.2025.108283},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108283},
  shortjournal = {Comput. Commun.},
  title        = {SDR: Stackelberg-based deep reinforcement learning for multi-skill spatiotemporal task allocation in AIoT systems},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proactive handover for task offloading in UAVs. <em>COMCOM</em>, <em>242</em>, 108282. (<a href='https://doi.org/10.1016/j.comcom.2025.108282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) are usually deployed alongside Internet of Things (IoT) devices in smart city applications, particularly for critical tasks such as disaster management that require continuous service. UAVs often handle resource-intensive and sensitive tasks through offloading, but unexpected task interruptions due to UAV dropouts can generate safety risks and increase costs. Although existing approaches in the literature have already addressed proactive handovers to mitigate such disruptions, their primary focus is on communication issues arising from UAV movement and are unable to handle offloading related issues. In this paper, we include in our model, in addition to communication, factors such as energy, computation requirements, and dynamic environmental conditions (e.g., wind speed and incentive), pushing toward a comprehensive solution for UAV task offloading and resource allocation. In fact, we formulate our problematic as a Markov game, which we solve using a Multi Agent Deep Q Network (MADQN). In our experiments, we assessed our approach using a federated learning scenario to illustrate its effectiveness in a realistic distributed application setting against several baselines from the state of the art. Results showed that our approach outperforms its peers in terms of system utility, and tradeoff between cost and dropout rates, leading to an improved handover management of computational and energy resources in UAV-IoT based systems. In fact, it reduces the dropout rate by approximately 45% compared to the second-best baseline, leading to a 2% improvement in model accuracy and a 50% reduction in deployment costs.},
  archive      = {J_COMCOM},
  author       = {Mohammed Riyadh Abdmeziem and Amina Ahmed Nacer and Soumeya Demil},
  doi          = {10.1016/j.comcom.2025.108282},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108282},
  shortjournal = {Comput. Commun.},
  title        = {Proactive handover for task offloading in UAVs},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance model and system optimization of an energy-saving strategy based on adaptive service rate tuning in cloud data centers with micro-burst traffic. <em>COMCOM</em>, <em>242</em>, 108281. (<a href='https://doi.org/10.1016/j.comcom.2025.108281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing competition in cloud market, reducing operating costs and improving Quality of Service (QoS) are two of the key issues that cloud vendors need to consider. In order to reduce the power consumption while mitigating the negative impact of micro-burst traffic in Cloud Data Centers (CDCs) on performance, and make cloud vendors more competitive, we design an Energy-saving Strategy based on Sleep and Adaptive Service-rate Tuning (ES-SAST) in this paper. We model the arrivals of the cloud task requests as an environment-dependent R -phase Markov Arrival Process (MAP ( R ) ), and we establish a multi-server synchronous multi-vacation queue with adaptive service rate tuning. We construct a four-dimensional Markov chain to analyze the queue, and we calculate some measures to evaluate the energy efficiency and QoS in the steady state. Then we develop an objective function composed of three performance measures. Finally, we propose an Improved Fire Hawk Optimizer (IFHO) with multi-strategy integration, and IFHO jointly optimizes two system parameters. An empirical study shows that IFHO chooses a lower system expected cost, where the power consumption of the system falls by 3%, the latency of tasks decreases by 19%, and the loss rate of the system reduces by 37%, on average.},
  archive      = {J_COMCOM},
  author       = {Xuena Yan and Shunfu Jin},
  doi          = {10.1016/j.comcom.2025.108281},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108281},
  shortjournal = {Comput. Commun.},
  title        = {Performance model and system optimization of an energy-saving strategy based on adaptive service rate tuning in cloud data centers with micro-burst traffic},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming data limitations in internet traffic forecasting: LSTM models with transfer learning and wavelet augmentation. <em>COMCOM</em>, <em>242</em>, 108280. (<a href='https://doi.org/10.1016/j.comcom.2025.108280'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate internet traffic prediction in smaller ISP networks is challenged by limited data availability. This paper explores this issue using transfer learning and data augmentation techniques with two LSTM-based models, LSTMSeq2Seq and LSTMSeq2SeqAtn, initially trained on a comprehensive dataset provided by Juniper Networks, Inc. and subsequently applied to smaller datasets. The datasets represent real internet traffic telemetry, offering insights into diverse traffic patterns across different network domains. Our study found that although both models performed well in single-step predictions, multi-step forecasting was more challenging, especially regarding long-term accuracy. Empirical results demonstrated that LSTMSeq2Seq outperformed LSTMSeq2SeqAtn on smaller datasets, with improvements in forecasting accuracy by up to 36.70% in MAE and 27.66% in WAPE after applying data augmentation using Discrete Wavelet Transform. The LSTMSeq2Seq model achieved an accuracy improvement from 83% to 88% for 6-step forecasts, 82% to 88% for 9-step forecasts, and 81% to 87% for 12-step forecasts, whereas LSTMSeq2SeqAtn exhibited a more stable short-term performance but higher variability in longer forecasts. Additionally, the mean absolute percentage error (MAPE) of multi-step predictions increased over longer horizons, with LSTMSeq2Seq reaching 6.74% at 12 steps and LSTMSeq2SeqAtn at 6.77%, highlighting the challenge of long-term forecasting. Variability analysis showed that while the attention mechanism in LSTMSeq2SeqAtn improved short-term prediction consistency, it also increased uncertainty in longer forecasts, as seen in the interquartile range (IQR) rising from 0.578 at 6 steps to 1.237 at 9 steps. Outlier analysis further confirmed that LSTMSeq2Seq exhibited more stable improvements, whereas LSTMSeq2SeqAtn showed increased dispersion in forecast accuracy. These findings underscore the importance of transfer learning and data augmentation in enhancing forecasting accuracy, particularly for smaller ISP networks with limited data availability. Furthermore, our analysis highlights the trade-offs between model complexity, short-term consistency, and long-term stability in internet traffic prediction.},
  archive      = {J_COMCOM},
  author       = {Sajal Saha and Anwar Haque and Greg Sidebottom},
  doi          = {10.1016/j.comcom.2025.108280},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108280},
  shortjournal = {Comput. Commun.},
  title        = {Overcoming data limitations in internet traffic forecasting: LSTM models with transfer learning and wavelet augmentation},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring traffic pattern variability in vehicular federated learning. <em>COMCOM</em>, <em>242</em>, 108279. (<a href='https://doi.org/10.1016/j.comcom.2025.108279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of software-defined vehicles has brought machine learning into the vehicular domain. To support these data-driven applications, techniques to incentivize users to share their vehicle data are crucial. Federated learning trains machine learning models in a distributed manner, leveraging client data without compromising its privacy. Nonetheless, in vehicular networks, the dynamic behavior of nodes affects client availability and the global model’s performance. Accordingly, this paper evaluates federated learning (FL) in a realistic vehicular network topology, accounting for real vehicle traffic in two Brazilian urban areas. The network simulation covers 3 . 7 km 2 with 1290 vehicles per hour and road speeds, based on real data. Our paper provides a comprehensive analysis of the impact that different traffic behaviors can yield during the training phase of a federated learning model. We observe that there is a performance decay in urban areas with longer vehicle permanence. Interestingly, longer vehicle participation in FL training leads to a biased final model with reduced generalization. We propose a novel approach to verify vehicle variability over time, by using the Dice-Sørensen coefficient to compare the set of clients participating in different rounds of training. By maintaining the vehicle variability over the rounds we can reduce the effect of the bias on the model, and – with a 47% reduction of the communication overhead – achieve faster learning, higher convergence in the first 15 rounds, and an equivalent final accuracy. Additionally, we extend our analysis by conducting simulations under more extreme traffic scenarios across multiple datasets, using a MobileNetV3. The results confirm that sustaining high vehicle variability – in scenarios with a brief participation of vehicles in the training – yields comparable model performance while saving up to 83.5 GB in communication costs.},
  archive      = {J_COMCOM},
  author       = {Giuliano Fittipaldi and Rodrigo S. Couto and Luís H.M.K. Costa},
  doi          = {10.1016/j.comcom.2025.108279},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108279},
  shortjournal = {Comput. Commun.},
  title        = {Exploring traffic pattern variability in vehicular federated learning},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Delay analysis of BFT consensus: Case study of narwhal and bullshark protocols. <em>COMCOM</em>, <em>242</em>, 108278. (<a href='https://doi.org/10.1016/j.comcom.2025.108278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acknowledging the critical influence of consensus delays on blockchain performance, this paper presents an analytical and simulation-based exploration of delay characteristics in Byzantine Fault Tolerant (BFT) consensus mechanisms. Our focus is on SUI, a blockchain system that employs a Directed Acyclic Graph (DAG) structure to support parallel transaction execution. SUI relies on two integrated protocols: Narwhal, a mempool protocol responsible for efficient block dissemination and DAG construction; and Bullshark, which organizes DAG vertices to produce a consistent total order of transactions without incurring additional communication overhead. While our previous work modeled Narwhal’s delay characteristics under various message propagation distributions, this study shifts attention to Bullshark—the protocol responsible for reaching consensus. We propose a probabilistic analytical model that estimates the number of rounds required to reach consensus. In this model, each validator’s decision is treated as a Bernoulli trial, and we apply the binomial distribution to determine the probability of reaching quorum. This framework enables us to analyze the expected delay of the protocol. To validate our model, we implemented both Narwhal and Bullshark and conducted extensive simulations. The simulation results show strong agreement with our analytical predictions, confirming the accuracy of our model. For instance, under a Gaussian delay model with mean μ = 1 ms and standard deviation σ = 0 . 25 ms—values representative of short-range wireless communication in real-world IoT or LAN settings [1] —we predict an average round duration of approximately 3.26 ms. Furthermore, based on our binomial-based model of block commitment, the expected number of rounds to reach consensus is approximately 1 when f = 10 , indicating that blocks typically commit in a single round with high probability. To the best of our knowledge, this is the first study to model Bullshark’s consensus process using Bernoulli trials and binomial distributions. Our contributions offer a novel framework for evaluating its efficiency and provide insights that can guide future optimization and scalability efforts for DAG-based BFT protocols.},
  archive      = {J_COMCOM},
  author       = {Khouloud Hwerbi and Ichrak Amdouni and Cédric Adjih and Leila Azouz Saidane and Anis Laouiti},
  doi          = {10.1016/j.comcom.2025.108278},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108278},
  shortjournal = {Comput. Commun.},
  title        = {Delay analysis of BFT consensus: Case study of narwhal and bullshark protocols},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic split federated learning for resource-constrained IoT systems. <em>COMCOM</em>, <em>242</em>, 108275. (<a href='https://doi.org/10.1016/j.comcom.2025.108275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient resource utilization in Internet of Things (IoT) systems is challenging due to device limitations. These limitations restrict on-device machine learning (ML) model training, leading to longer processing times and inefficient metadata analysis. Additionally, conventional centralized data collection poses privacy concerns, as raw data has to leave the device to the server for processing. Combining Federated Learning (FL) and Split Learning (SL) offers a promising solution by enabling effective machine learning on resource-constrained devices while preserving user privacy. However, the dynamic nature of IoT resources and device heterogeneity can complicate the application of these solutions, as some IoT devices cannot complete the training task on time. To address these concerns, we have developed a Dynamic Split Federated Learning (DSFL) architecture that dynamically adjusts to the real-time resource availability of individual clients. Combining real-time split-point selection with a Genetic Algorithm (GA) for client selection, tailored to heterogeneous, resource-constrained IoT devices. DSFL ensures optimal utilization of resources and efficient training across heterogeneous IoT devices and servers. Our architecture detects each IoT device’s training capabilities by identifying the number of layers it can train. Moreover, an effective Genetic Algorithm (GA) process strategically selects the clients required to complete the split federated learning round. Cooperatively, the clients and servers train their parts of the model, aggregate them, and then combine the results before moving to the next round. Our proposed architecture enables collaborative model training across devices while preserving data privacy by combining FL’s parallelism with SL’s dynamic modeling. We evaluated our architecture on sensory and image-based datasets, showing improved accuracy and reduced overhead compared to baseline methods.},
  archive      = {J_COMCOM},
  author       = {Mohamad Wazzeh and Ahmad Hammoud and Azzam Mourad and Hadi Otrok and Chamseddine Talhi and Zbigniew Dziong and Chang-Dong Wang and Mohsen Guizani},
  doi          = {10.1016/j.comcom.2025.108275},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108275},
  shortjournal = {Comput. Commun.},
  title        = {Dynamic split federated learning for resource-constrained IoT systems},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physical layer security in FAS-aided wireless powered NOMA systems. <em>COMCOM</em>, <em>242</em>, 108274. (<a href='https://doi.org/10.1016/j.comcom.2025.108274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of communication technologies and the emergence of sixth-generation (6G) networks have introduced unprecedented opportunities for ultra-reliable, low-latency, and energy-efficient communication. Integrating technologies like non-orthogonal multiple access (NOMA) and wireless powered communication networks (WPCNs) brings new challenges. These include energy constraints and increased security vulnerabilities. Traditional antenna systems and orthogonal multiple access schemes struggle to meet the increasing demands for performance and security in such environments. To address this gap, this paper investigates the impact of emerging fluid antenna systems (FAS) on the performance of physical layer security (PLS) in WPCNs. Specifically, we consider a scenario in which a transmitter, powered by a power beacon via an energy link, transmits confidential messages to legitimate FAS-aided users over information links while an external eavesdropper attempts to decode the transmitted signals. Additionally, users leverage the NOMA scheme, where the far user may also act as an internal eavesdropper. For the proposed model, we first derive the distributions of the equivalent channels at each node and subsequently obtain compact expressions for the secrecy outage probability (SOP) and average secrecy capacity (ASC), using the Gaussian quadrature methods. Our results reveal that incorporating the FAS for NOMA users, instead of the TAS, enhances the performance of the proposed secure WPCN.},
  archive      = {J_COMCOM},
  author       = {Farshad Rostami Ghadi and Masoud Kaveh and Kai-Kit Wong and Diego Martín and Riku Jäntti and Zheng Yan},
  doi          = {10.1016/j.comcom.2025.108274},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108274},
  shortjournal = {Comput. Commun.},
  title        = {Physical layer security in FAS-aided wireless powered NOMA systems},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A slot-based energy storage decision-making approach for optimal off-grid telecommunication operator. <em>COMCOM</em>, <em>242</em>, 108273. (<a href='https://doi.org/10.1016/j.comcom.2025.108273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a slot-based energy storage approach for decision-making in the context of an Off-Grid telecommunication operator. We consider network systems powered by solar panels, where harvest energy is stored in a battery that can also be sold when fully charged. To reflect real-world conditions, we account for non-stationary energy arrivals and service demands that depend on the time of day, as well as the failure states of PV panel. The network operator we model faces two conflicting objectives: maintaining the operation of its infrastructure and selling (or supplying to other networks) surplus energy from fully charged batteries. To address these challenges, we developed a slot-based Markov Decision Process (MDP) model that incorporates positive rewards for energy sales, as well as penalties for energy loss and battery depletion. This slot-based MDP follows a specific structure we have previously proven to be efficient in terms of computational performance and accuracy. From this model, we derive the optimal policy that balances these conflicting objectives and maximizes the average reward function. Additionally, we present results comparing different cities and months, which the operator can consider when deploying its infrastructure to maximize rewards based on location-specific energy availability and seasonal variations. Experimental results show that our proposed algorithm outperforms classical methods in large-scale scenarios. While Relative Value Iteration algorithm remains competitive on smaller instances, its convergence time increases significantly under strict precision requirements (e.g., ϵ < 1 0 − 10 ). In contrast, our method maintains both speed and robustness, solving MDPs with up to 2 × 1 0 5 states and 100 actions in under one hour, whereas standard approaches exceed 1 0 4 seconds.},
  archive      = {J_COMCOM},
  author       = {Youssef Ait El Mahjoub and Jean-Michel Fourneau},
  doi          = {10.1016/j.comcom.2025.108273},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108273},
  shortjournal = {Comput. Commun.},
  title        = {A slot-based energy storage decision-making approach for optimal off-grid telecommunication operator},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight secret-sharing-based defense against model poisoning attacks in privacy-preserving federated learning. <em>COMCOM</em>, <em>242</em>, 108272. (<a href='https://doi.org/10.1016/j.comcom.2025.108272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Artificial Intelligence of Things (AIoT) converges with Privacy-Preserving Federated Learning (PPFL), the challenge of defending against model poisoning attacks emerges as increasingly critical. Due to PPFL’s cryptographic protocols for protecting gradient exchanges, detecting poisoning attacks becomes challenging. Traditional defense mechanisms rely on plaintext gradient analysis and thus cannot be directly applied to encrypted gradients. Although homomorphic encryption-based defense schemes enable secure computations on encrypted data, their substantial computational overhead makes them impractical for resource-constrained Internet of Things (IoT) deployments. To address these challenges, we propose a Secret-Sharing-based Defense Framework (SSDF), a lightweight scheme that enables efficient similarity calculations on encrypted gradients under secure aggregation protocols. Our scheme facilitates robust aggregation of encrypted parameters in resource-constrained edge computing environments while protecting the privacy of local model updates. Extensive experiments on four datasets demonstrate that our proposed scheme provides robust defense capabilities against poisoning attacks for both Independent and Identically Distributed (IID) and non-IID data.},
  archive      = {J_COMCOM},
  author       = {Hengheng Xiong and Jiguang Lv and Dapeng Man and Yukun Zhu and Tao Liu and Huanran Wang and Chen Xu and Wu Yang},
  doi          = {10.1016/j.comcom.2025.108272},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108272},
  shortjournal = {Comput. Commun.},
  title        = {A lightweight secret-sharing-based defense against model poisoning attacks in privacy-preserving federated learning},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A homomorphic MAC-based verifiable secure aggregation for federated learning in cloud–edge AIoT. <em>COMCOM</em>, <em>242</em>, 108271. (<a href='https://doi.org/10.1016/j.comcom.2025.108271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cloud–edge collaborative Artificial Intelligence of Things (AIoT) architecture addresses challenges in managing vast data storage, intelligent information processing, device interconnectivity within the Internet of Things. For its security risks and data privacy, federated learning emerges as a promising solution for ensuring data privacy in AIoT. However, susceptibility to malicious attacks during data transmission poses a significant challenge and a semi-trusted server may deviate from the specified protocol leading to inaccurate aggregation parameters returned to clients. Our proposed solution introduces a federated learning integrity verification scheme based on homomorphic Message Authentication Code (MAC) within a cloud–edge collaborative AIoT architecture. Homomorphic MAC ensures secure aggregation and integrity verification, even when distinct clients possess different keys, emphasizing integrity verification by edge node, contributes to reduced client computing costs. Further verifying of the aggregated parameters by users prevents untrusted transmission from edge node. Leveraging data integrity verification proves effective in mitigating challenges associated with parameter security, especially in scenarios involving inaccurate aggregation of local model parameters within federated learning. Our solution is free bilinear pairing, resulting in a significant reduction in computational overhead. We evaluate accuracy on the MNIST dataset through comparison with the FedAVG plaintext scheme, showing that our approach ensures parameter integrity while maintaining model performance, numerical simulations also confirm its efficiency.},
  archive      = {J_COMCOM},
  author       = {Shufen Niu and Weiying Kong and Lihua Chen and Xusheng Zhou and Ning Wang},
  doi          = {10.1016/j.comcom.2025.108271},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108271},
  shortjournal = {Comput. Commun.},
  title        = {A homomorphic MAC-based verifiable secure aggregation for federated learning in cloud–edge AIoT},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance of UAV-assisted C-V2X communications with 3D antenna beam-width fluctuations. <em>COMCOM</em>, <em>242</em>, 108267. (<a href='https://doi.org/10.1016/j.comcom.2025.108267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The antenna’s three-dimensional (3D) beam-width orientation is crucial in assessing the effectiveness of vehicular communications. This paper investigates the influence of variations of millimeter waveband antenna 3D beam-width on the performance of un-crewed aerial vehicle (UAV)-assisted cellular vehicle-to-everything (C-V2X) communications. The cellular base-stations are represented using a two-dimensional Poisson point process (PPP), while vehicular nodes (V-Ns) are represented using a Poisson line process, and UAVs are represented using a 3D PPP. The typical transmitting V-N can connect with the nearest V-N in direct mode transmission or with the (macro base-station) MBS, line-of-sight (LOS) UAV, or non-LOS (NLOS) UAV in shared mode transmission. The efficiency of the system is measured by using the antenna’s 3D beam-width relative to coverage and spectrum efficiency. To that aim, analytical equations for the association and coverage probability of vehicular-to-vehicular, vehicular-to-MBS, vehicular-to-LOS UAV, and vehicular-to-NLOS UAV connections are obtained in the setting of variation in beam-width. The efficiency is also measured in terms of V-Ns, MBS, and UAVs. The findings revealed that our system, considering millimeter waveband-based UAV-assisted C-V2X network leveraging the benefits of MBSs and UAVs, performs better than the conventional V2X network. The findings reveal that the efficiency of the UAV-assisted C-V2X networks is affected by the variable 3D beam-width, hence, it needs to be thoroughly specified. Furthermore, the network’s performance degrades when the UAV’s beam-width variations grow.},
  archive      = {J_COMCOM},
  author       = {Mohammad Arif and Wooseong Kim and Asif Mehmood},
  doi          = {10.1016/j.comcom.2025.108267},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108267},
  shortjournal = {Comput. Commun.},
  title        = {Performance of UAV-assisted C-V2X communications with 3D antenna beam-width fluctuations},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ACSFL: An adaptive client selection-based federated learning with personalized differential privacy for heterogeneous AIoT environments. <em>COMCOM</em>, <em>242</em>, 108264. (<a href='https://doi.org/10.1016/j.comcom.2025.108264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the rapid development of Artificial Intelligence (AI) and the Internet of Things (IoT), the Artificial Intelligence of Things (AIoT) is increasingly applied in smart environments. Federated Learning (FL) meets the need for intelligent data processing in these environments by providing powerful training capabilities while preserving privacy. However, AIoT environments pose new challenges for FL, particularly due to the heterogeneity of edge devices, which vary in hardware, software, network conditions, and data distribution. These factors degrade model performance and hinder convergence. Additionally, communication overhead and data privacy risks are also critical concerns. Although Differential Privacy (DP) can offer protection, they often apply uniform privacy levels, overlooking the diversity of AIoT devices. On the other hand, while current client-selection approaches partially address the heterogeneity of AIoT devices, they also tend to ignore the impact of the noising mechanisms. In this paper, we propose ACSFL, an adaptive client selection-based FL framework that integrates personalized local DP. By a novel, dynamic evaluation metric of node heterogeneity, privacy budget, and contribution, ACSFL can jointly optimize model performance, privacy preservation, and communication efficiency. We further propose a personalized local differential privacy mechanism in ACSFL, to filter and allocate each client’s budget per round, substantially enhancing privacy preservation and yielding significant accuracy gains under identical overall privacy constraints. All the above assertions are also well supported by theoretical and experimental demonstration. Specifically, our experiments show that ACSFL improves model convergence and generalization by 14% on average, achieves comparable model accuracy with 20% fewer clients, reduces communication overhead by over 25%, and saves about 26% of the privacy budget compared to other client selection methods.},
  archive      = {J_COMCOM},
  author       = {Zhousheng Wang and Junjie Chen and Hua Dai and Jian Xu and Geng Yang and Hao Zhou},
  doi          = {10.1016/j.comcom.2025.108264},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108264},
  shortjournal = {Comput. Commun.},
  title        = {ACSFL: An adaptive client selection-based federated learning with personalized differential privacy for heterogeneous AIoT environments},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient blockchain synchronization mechanism over NDN based on directed interest forwarding. <em>COMCOM</em>, <em>242</em>, 108258. (<a href='https://doi.org/10.1016/j.comcom.2025.108258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology, as a decentralized technology, has been applied across various industries due to its immutability and information security features. With the increasing adoption of blockchain technology, network scale and transaction volumes have increased rapidly. The growing data transmission demands have exposed network performance issues in blockchain systems, creating a bottleneck for further improvements. While Named Data Networking (NDN) offers strong support for blockchain networks, some existing designs lack efficient synchronization methods, resulting in redundancies and limiting the full potential of NDN in blockchain networks. To address this issue, this paper proposes a directed Interest forwarding-based synchronization mechanism for NDN-based blockchain networks. In this mechanism, we design a Block Synchronous Forward Table (BSFT) to record the synchronization status of upstream and downstream nodes. Through the structure of this table, nodes can obtain information about other nodes in the network via six specifically designed NDN Interests. During synchronization, nodes dynamically select the appropriate peers to send data request Interest based on the actual network state and synchronization status, thereby reducing the large number of redundant Interest packets and corresponding response Data packets caused by Interest broadcasts. Experimental results demonstrate that our proposed synchronization mechanism can effectively reduce network traffic, lowering traffic by about 30% or more compared to traditional IP-based blockchain and other NDN-based blockchain solutions. This also accelerates the synchronization of Data packets across the entire network, thereby enhancing the overall performance of blockchain networks.},
  archive      = {J_COMCOM},
  author       = {Dehao Zhang and Jiapeng Xiu and Zhengqiu Yang and Huixin Liu and Shaoyong Guo},
  doi          = {10.1016/j.comcom.2025.108258},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108258},
  shortjournal = {Comput. Commun.},
  title        = {Efficient blockchain synchronization mechanism over NDN based on directed interest forwarding},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing mobility prediction in 5G for enhanced C-V2X applications: A multidisciplinary research survey. <em>COMCOM</em>, <em>242</em>, 108254. (<a href='https://doi.org/10.1016/j.comcom.2025.108254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of 5G New Radio technologies, autonomous vehicles are evolving from isolated units into components of a larger, interconnected system. This transformation is enabled by robust Vehicle-to-Everything (V2X) communications, facilitating applications such as high-definition sensor data sharing and collision avoidance within the Cellular-V2X (C-V2X) framework. Nationwide, ultra-reliable, low-latency coverage is crucial for these applications, necessitating a smart, flexible network to manage mobility uncertainties effectively. To achieve this, mobility prediction will play a pivotal role by preparing the network for anticipated traffic patterns and optimizing its radio and computational resources, thereby enhancing overall efficiency. This survey provides a comprehensive review and analysis of current and emerging mobility prediction methodologies essential for enhancing these networks. We explore these methodologies along with the standards and requirements set by key organizations like the 3rd Generation Partnership Project (3GPP) and industry leaders such as the 5G Automotive Association (5GAA). By reviewing state-of-the-art mobility prediction techniques, this survey critically analyzes their role in forecasting key network performance indicators (KPIs), enabling proactive resource allocation, robust edge-computing strategies, and slice orchestration, all crucial for optimizing 5G performance and ensuring ultra-reliable, low-latency C-V2X communications.},
  archive      = {J_COMCOM},
  author       = {Mario Bou Abboud and Maroua Drissi and Oumaya Baala and Sylvain Allio},
  doi          = {10.1016/j.comcom.2025.108254},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108254},
  shortjournal = {Comput. Commun.},
  title        = {Optimizing mobility prediction in 5G for enhanced C-V2X applications: A multidisciplinary research survey},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing bandwidth allocation in mmWave/sub-THz cellular networks using maximum flow algorithms. <em>COMCOM</em>, <em>242</em>, 108221. (<a href='https://doi.org/10.1016/j.comcom.2025.108221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exploitation of millimeter wave (mmWave) and sub-Terahertz (sub-THz) bands is expected to be one of the main pillars for the development of future cellular networks due to the high available bandwidth they provide. The existence of Line-of-Sight (LOS) link between a user equipment (UE) and an access point (AP) is a prerequisite for connection establishment in these networks, as the wireless links in these bands are very sensitive to blockage effects. This can be achieved by densifying APs within a network area. An arising challenge is the efficient exploitation of the available bandwidth of a given network. In this paper, the maximization of the number of served UEs in modern mmWave and sub-THz cellular networks is investigated and achieved by deploying a Maximum Flow Algorithm for UE-AP association (MFUA) to optimize bandwidth allocation, assuming that every AP will have a finite and predefined amount of bandwidth which they can share among UEs. MFUA determines the maximum flow between two given nodes of a graph corresponding to a specific network, where the capacity of its edges is known. An extensive simulation campaign was carried out revealing that the use of MFUA utilizes bandwidth more effectively compared to the reference method and improves the system performance, leading to the maximization of number of served UEs. The examined test cases include static and time-evolving scenarios.},
  archive      = {J_COMCOM},
  author       = {Kyriakos N. Manganaris and Panagiotis Promponas and Aris Tsolis and Fotis I. Lazarakis and Kostas P. Peppas},
  doi          = {10.1016/j.comcom.2025.108221},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108221},
  shortjournal = {Comput. Commun.},
  title        = {Optimizing bandwidth allocation in mmWave/sub-THz cellular networks using maximum flow algorithms},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accountable privacy-enhanced multi-authority attribute-based authentication scheme for cloud services. <em>COMCOM</em>, <em>242</em>, 108205. (<a href='https://doi.org/10.1016/j.comcom.2025.108205'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current attribute-based authentication (ABA) schemes have three major drawbacks: first, the single attribute authority (AA) becomes the system bottleneck, i.e., if the AA is corrupted, the entire system will stop working; second, user privacy is not completely secured; and third, malicious users may exploit their anonymity. To overcome these defects, we improved a previously established privacy-preserving decentralized ciphertext policy attribute-based encryption (PPD-CP-ABE) scheme, obtaining a PPD-CP-ABE with verifiable outsourced decryption (PPD-CP-ABE-VOD). This improved scheme uses outsourced decryption, secure two-party computation protocol, and zero-knowledge proofs. We transformed the PPD-CP-ABE-VOD scheme into a new privacy-enhanced multi-authority ABA scheme using an identity tracing mechanism based on linear encryption. This new scheme has the following advantages over similar schemes. First, it introduces multiple AAs and does not require users to trust AA fully. Second, it protects users’ attributes, global identifiers, and access behavior, thus strengthening user privacy protection. Finally, it balances user privacy protection and user accountability. Theoretical and experimental analyses have shown that the new scheme is comparable to recently proposed ABA systems in terms of performance in the key generation and authentication phases, despite appending multiple security properties.},
  archive      = {J_COMCOM},
  author       = {Xin Liu and Hao Wang and Bo Zhang and Bin Zhang},
  doi          = {10.1016/j.comcom.2025.108205},
  journal      = {Computer Communications},
  month        = {10},
  pages        = {108205},
  shortjournal = {Comput. Commun.},
  title        = {Accountable privacy-enhanced multi-authority attribute-based authentication scheme for cloud services},
  volume       = {242},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="cor">COR - 21</h2>
<ul>
<li><details>
<summary>
(2026). Optimizing high-tech product take-back schemes in a closed-loop supply chain. <em>COR</em>, <em>185</em>, 107282. (<a href='https://doi.org/10.1016/j.cor.2025.107282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent product development is a solution to the shortened product lifecycles in the consumer electronics industry. It enables companies to maintain competitiveness and strengthen their market share. However, environmental concerns bring reverse logistics practices into focus. A take-back policy is a strategic reverse logistics activity known to foster market share; however, it poses various challenges and uncertainties. Considering uncertain demand, we introduced an innovative adoption model with two distinct take-back policies, trade-in and credit, to address challenges in multi-generation production planning. Inspired by real-world practices of companies like Apple and Samsung, our model first examines how trade-in programs drive repeat purchases and enhance market share, with credit-based programs to attract new customers. It then captures changes in demand, production planning, recovery decisions, and internal competition among multiple product generations. Distinct from previous conclusions, this study explores how producers can strategically manage demand for new generations to slow diffusion, thereby increasing refurbishment and recycling volumes over time. Our findings highlight the pivotal role of adaptive pricing strategies and production scalability in maximizing profitability and promoting sustainability in competitive high-tech industries.},
  archive      = {J_COR},
  author       = {Fatemeh Keshavarz-Ghorbani and Mohamad Y. Jaber and Seyed Hamid Reza Pasandideh},
  doi          = {10.1016/j.cor.2025.107282},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107282},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing high-tech product take-back schemes in a closed-loop supply chain},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Q-learning-based hyper-heuristic algorithm for open dimension irregular packing problems. <em>COR</em>, <em>185</em>, 107279. (<a href='https://doi.org/10.1016/j.cor.2025.107279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heuristic methods provide a computationally efficient framework for addressing two-dimensional irregular packing problems, particularly in resource-constrained industrial settings. As a typical combinatorial optimization problem, irregular packing exhibits exponential growth in computational complexity with increasing workpiece counts, while the solution space dynamically reconfigures due to geometric variability among workpieces. Although heuristic algorithms can generate feasible layouts within acceptable timeframes, their reliance on fixed search rule limits adaptability to diverse scenarios, necessitating more flexible approaches. In this paper, a hyper-heuristic algorithm based on Q-Learning is proposed to solve open dimension packing problems, including one-open and two-open dimension problems. Q-Learning is adopted as the high-level strategy for its ability to optimize low-level heuristic selection through reward-driven experience accumulation. The method incorporates a mixed encoding method for solution representation, four specialized low-level heuristic operators, a linear population decline mechanism, and an elite preservation strategy to balance exploration–exploitation. The Q-Learning controller dynamically selects operators by updating the Q-table based on Bellman’s equation. The proposed algorithm is compared to some advanced algorithms in general datasets. The results show that our method has better performance and applicability.},
  archive      = {J_COR},
  author       = {Yongchun Wang and Qingjin Peng and Zhen Wang and Shuiquan Huang and Zhengkai Xu and Chuanzhen Huang and Baosu Guo},
  doi          = {10.1016/j.cor.2025.107279},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107279},
  shortjournal = {Comput. Oper. Res.},
  title        = {Q-learning-based hyper-heuristic algorithm for open dimension irregular packing problems},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A note on battery swapping policies in the electric vehicle routing problem with time windows and battery swapping vehicles. <em>COR</em>, <em>185</em>, 107277. (<a href='https://doi.org/10.1016/j.cor.2025.107277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Çatay and Sadati [An improved matheuristic for solving the electric vehicle routing problem with time windows and synchronized mobile charging/battery swapping. Computers & Operations Research 159, 106310, 2023] explores a variant of the Electric Vehicle Routing Problem with Time Windows that incorporates mobile chargers for recharging electric vehicles (EVs) at selected locations while serving customers. The authors propose a matheuristic method to address this problem and its special case, where EV batteries are swapped in constant time instead of being recharged over variable durations. While comparing their results with those in the literature, the authors overlook a critical assumption regarding the swapping policy, potentially causing confusion in interpreting the findings. This note addresses the issue, clarifies the overlooked assumption, and updates the results that do not align with the actual scenario in the literature. Furthermore, it introduces two new battery swapping policies and presents an extensive computational study to offer new insights on synchronized mobile battery swapping.},
  archive      = {J_COR},
  author       = {Bülent Çatay and İhsan Sadati},
  doi          = {10.1016/j.cor.2025.107277},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107277},
  shortjournal = {Comput. Oper. Res.},
  title        = {A note on battery swapping policies in the electric vehicle routing problem with time windows and battery swapping vehicles},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive K-means and reinforcement learning (RL) algorithm to effective vaccine distribution. <em>COR</em>, <em>185</em>, 107275. (<a href='https://doi.org/10.1016/j.cor.2025.107275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new adaptive reinforcement learning (RL) approach, integrated with a K-means clustering algorithm and guided by simulated annealing, to address the capacitated vehicle routing for vaccine distribution (CVRVD) problem. This integrated method provides an efficient and scalable solution for optimizing vaccine distribution logistics. By incorporating cost factors related to travel distance, inventory levels, and penalty terms – while adhering to delivery time windows – our approach improves both operational efficiency and vaccine allocation effectiveness. Experimental results demonstrate that our K-means supported RL algorithm significantly outperforms traditional solvers in tackling this NP-hard problem, particularly in large-scale scenarios. Specifically, our approach can efficiently solve CVRVD instances with up to 1,000 facilities—scenarios that are computationally intractable for exact methods. We demonstrate the effectiveness of the adaptive K-means supported RL algorithm using data from New Jersey, USA, where facility-level vaccination data were available through the state’s Immunization Information System. Beyond vaccine distribution, our method has broad applicability in logistics and transportation, enabling more efficient and cost-effective allocation of critical resources such as vaccines and medical supplies.},
  archive      = {J_COR},
  author       = {Elson Cibaku and İ. Esra Büyüktahtakın},
  doi          = {10.1016/j.cor.2025.107275},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107275},
  shortjournal = {Comput. Oper. Res.},
  title        = {An adaptive K-means and reinforcement learning (RL) algorithm to effective vaccine distribution},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A Q-learning-based evolutionary algorithm for solving the low-carbon multi-objective flexible job shop scheduling problem. <em>COR</em>, <em>185</em>, 107266. (<a href='https://doi.org/10.1016/j.cor.2025.107266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, how to reduce energy consumption at the manufacturing system level in the low-carbon multi-objective flexible job shop scheduling problem (LCM-FJSP) has received significant attention. In this research, a model with the maximum completion time, total machine workload and total carbon emissions is built. Moreover, a Q-learning-based adaptive weight-adjusted decomposition evolutionary algorithm (QMOEA/D-AWA) is proposed. In the QMOEA/D-AWA, an initialization strategy with four heuristic initial rules for obtaining high-quality population, a variable neighborhood search strategy with four problem-specific local search methods for enhancing exploration and a Q-learning-based parameter adaptive strategy for automatically determining the number of neighborhood solutions are designed. To validate the effectiveness of the proposed QMOEA/D-AWA, it is compared with five state-of-the-art algorithms on 15 instances. In the statistical analysis, the QMOEA/D-AWA obtains the overwhelming metric results in 10 instances. In the visual analysis, the completion time is reduced by 3.74%, the total workload is reduced by 3.94%, and the carbon emissions are reduced by 5.94%.},
  archive      = {J_COR},
  author       = {Zhixue Wang and Maowei He and Hanning Chen and Yabao Hu and Yelin Xia},
  doi          = {10.1016/j.cor.2025.107266},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107266},
  shortjournal = {Comput. Oper. Res.},
  title        = {A Q-learning-based evolutionary algorithm for solving the low-carbon multi-objective flexible job shop scheduling problem},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A benders-branch-and-cut methodology for global cargo vessel traffic prediction given declining arctic sea ice and changing risks. <em>COR</em>, <em>185</em>, 107265. (<a href='https://doi.org/10.1016/j.cor.2025.107265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global warming has led to declining sea-ice in the Arctic Ocean, making it easier for ice-class vessels to navigate Arctic waters for greater portions of the year. As sailing conditions in these waters improve over coming decades, these passageways are expected to open for larger portions of the year and to become increasingly viable options for unsupported transit and even open-water vessels. This paper proposes a Benders-branch-and-cut methodology for estimating changes in global maritime cargo flow patterns under future climate scenarios with declining Arctic sea ice. The model accounts for changing incident risk along Arctic passageways and corresponding ice-class vessel and icebreaker escort requirements, lower speeds, increased insurance premiums, higher accident probabilities, and constraints on path-based maximum risk exposure. The resulting mixed-integer program involves path-based, continuous decision variables. The solution technique is applied on a model of the global maritime container network including 80 ports, 76 routes, 426 links and 4,303 legs associated with the world’s largest carrier alliance. Embedded acceleration techniques and a label-correcting algorithm that employs specialized fathoming rules for a non-additive, constrained path subproblem enable solution at this global scale. The outcome is an estimate of seasonal future global maritime trade flows along key global routes and through ports predicted under six climate-related scenarios. Results illustrate that the developed model can provide support to companies, nations and regions as they prepare for a changing global landscape and climate.},
  archive      = {J_COR},
  author       = {Wenjie Li and Elise Miller-Hooks},
  doi          = {10.1016/j.cor.2025.107265},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107265},
  shortjournal = {Comput. Oper. Res.},
  title        = {A benders-branch-and-cut methodology for global cargo vessel traffic prediction given declining arctic sea ice and changing risks},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep reinforcement learning approach for dynamic job-shop scheduling problem considering time variable and new job arrivals. <em>COR</em>, <em>185</em>, 107263. (<a href='https://doi.org/10.1016/j.cor.2025.107263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the complexity of the production process due to increased demand for customization has greatly increased the difficulty of dynamic job-shop scheduling problem (DJSP). This paper proposes a deep reinforcement learning (DRL) approach to tackle the DJSP based on proximal policy optimization (PPO) algorithm. A novel state representation method that expresses state features as multi-channel images is proposed to simplify the state characterization process. Various heuristic-based priority dispatching rules (PDRs)are used to construct action space. By converting scheduling instances into images and leveraging the spatial pyramid pooling fast (SPPF) module for feature extraction, this model can handle scheduling instances of varying scales and map size-independent processing information matrix to fixed action space. Additionally, a dense reward based on a predefined scheduling region is developed to offer detailed guidance to the agent, enabling more precise and comprehensive policy assessment. Static tests are conducted on well-known benchmarks, and the experimental results indicate that our scheduling model surpasses the performance of the three latest DRL approaches on average. Compared with PDR methods, dynamic experiments demonstrate that the proposed DRL model excels in adaptability and robustness when new tasks arrive and the processing time fluctuates with uncertainty.},
  archive      = {J_COR},
  author       = {Haoyang Yu and Wenbin Gu and Na Tang and Zhenyang Guo},
  doi          = {10.1016/j.cor.2025.107263},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107263},
  shortjournal = {Comput. Oper. Res.},
  title        = {A deep reinforcement learning approach for dynamic job-shop scheduling problem considering time variable and new job arrivals},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient resource utilization and scheduling strategy for in-service aircraft maintenance and operations. <em>COR</em>, <em>185</em>, 107262. (<a href='https://doi.org/10.1016/j.cor.2025.107262'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal scheduling of maintenance activities requires the solution of combinatorial optimization problems that need to be efficiently modeled and solved with optimization techniques. Maintenance scheduling and operations-associated problems in the aviation industry can efficiently enhance competitiveness. In the maintenance and scheduling problem, aircrafts need to undergo tasks for both line (A check) and base (C check) maintenance at various hangers at MRO (Maintenance, Repair and Operations) based on resource availability (both human and material). The determination of the optimal maintenance plan, in terms of allocating the resources to the aircraft, and resource movement from one aircraft to another based on availability and licensed skills in the presence of multiple tasks and capacity constraints so as to obtain maximum utilization of resources at maintenance site and minimize the turnaround time is a complex combinatorial optimization problem. To the best of our knowledge, this work is the first CP (Constraint Programming) based mathematical solution that jointly integrates zone, task precedence, technician-pool sharing, and multi-shift continuity for large-scale aircraft maintenance scheduling. In this article, we proposed an efficient optimization strategy that overcomes many of the drawbacks of the formulation/strategies available in literature and helps in determining efficient execution of maintenance work packages. The proposed strategy is generic, encompassing multi-aircraft, multi-skill and multi-shift scheduling capabilities and is validated on two real scenario business case studies, one each for line maintenance (A check) tasks and base maintenance (C check) tasks, as well as six large-scale synthetic scenarios with up to 20,000 tasks, demonstrating feasibility and scalable performance. The proposed strategy is demonstrated on MRO scheduling and it shows an improvement of up to 30.68% in the turn-around time by incorporating the proposed optimization strategy.},
  archive      = {J_COR},
  author       = {Sandeep Singh Chauhan and Likhith Maadhav and Abhijit Dake and Gauthier Brillaud},
  doi          = {10.1016/j.cor.2025.107262},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107262},
  shortjournal = {Comput. Oper. Res.},
  title        = {An efficient resource utilization and scheduling strategy for in-service aircraft maintenance and operations},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A data-driven optimization approach for the integrated train scheduling and maintenance planning in high-speed railways. <em>COR</em>, <em>185</em>, 107261. (<a href='https://doi.org/10.1016/j.cor.2025.107261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In railway systems, preventive maintenance plans are essential for ensuring the safety of train operations. However, these tasks are often subject to various disturbances (e.g., bad weather), leading to unpredictable deviations between planned and actual maintenance durations, which can further disrupt train schedules. Unlike most studies that assume constant maintenance durations, this paper introduces a data-driven, two-stage distributionally robust optimization (DRO) model for jointly optimizing train scheduling and maintenance planning. In the first stage, we determine the initial train schedule and maintenance plan. In the second stage, we allow for slight adjustments to train departure and arrival times at each station to accommodate disturbances affecting maintenance tasks. Our objective is to minimize both the expected travel time of trains and the deviation from the planned schedule under worst-case scenarios for maintenance disturbances. To capture the uncertainty of maintenance disturbances, we construct an ambiguity set using historical data and the Wasserstein metric. We show that the proposed two-stage DRO model, formulated over the Wasserstein ambiguity set, can be reformulated into an efficiently solvable equivalent form. Finally, we apply our model to a real-world case study of the Beijing–Guangzhou high-speed railway and compare it with traditional stochastic programming methods, including sample average approximation and robust optimization. The results highlight the efficiency of our approach and provide valuable insights for railway management.},
  archive      = {J_COR},
  author       = {Hangyu Ji and Chuntian Zhang and Jiateng Yin and Lixing Yang},
  doi          = {10.1016/j.cor.2025.107261},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107261},
  shortjournal = {Comput. Oper. Res.},
  title        = {A data-driven optimization approach for the integrated train scheduling and maintenance planning in high-speed railways},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ROBIST: Robust optimization by iterative scenario sampling and statistical testing. <em>COR</em>, <em>185</em>, 107260. (<a href='https://doi.org/10.1016/j.cor.2025.107260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose ROBIST , a simple, yet effective, data-driven algorithm for optimization under parametric uncertainty. The algorithm first generates solutions in an iterative manner by sampling and optimizing over a relatively small set of scenarios. Then, using statistical testing, the robustness of the solutions is evaluated, which can be done with a much larger set of scenarios. ROBIST offers a number of practical advantages over existing methods as it is: (i) easy to implement, (ii) able to deal with a wide range of problems and (iii) capable of providing sharp probability guarantees that are easily computable and independent of the dimensions of the problem. Numerical experiments demonstrate the effectiveness of ROBIST in comparison to alternative methods.},
  archive      = {J_COR},
  author       = {Justin Starreveld and Guanyu Jin and Dick den Hertog and Roger J.A. Laeven},
  doi          = {10.1016/j.cor.2025.107260},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107260},
  shortjournal = {Comput. Oper. Res.},
  title        = {ROBIST: Robust optimization by iterative scenario sampling and statistical testing},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A branch-and-price algorithm for energy aware task scheduling of constellations of nanosatellites. <em>COR</em>, <em>185</em>, 107259. (<a href='https://doi.org/10.1016/j.cor.2025.107259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a branch-and-price algorithm for solving the Optimal Network Task Scheduling (ONTS) problem in satellite constellations. The algorithm efficiently manages both constellation tasks that can be performed by any satellite and satellite-specific tasks that must be executed by designated satellites, while considering critical energy constraints. We formulate the problem as a Mixed-Integer Linear Programming (MILP) model and develop a Dantzig–Wolfe decomposition that handles battery management constraints for the satellites at the master level, while addressing constellation-wide coordination requirements in the subproblems. A novel dynamic programming algorithm is proposed to solve the pricing subproblem for constellation tasks, augmented with dual stabilization techniques to improve convergence. Comprehensive computational experiments on realistic instances derived from nanosatellite operations demonstrate the effectiveness of the algorithm. Results show that our structured formulation significantly outperforms a naive approach, particularly for large instances, while effectively balancing workload distribution and energy management across the constellation. This work provides a practical framework for optimizing task scheduling in modern satellite constellations, with direct applications in Earth observation, telecommunications, and scientific missions.},
  archive      = {J_COR},
  author       = {Pedro Marcolin Antunes and Laio Oriel Seman and Eduardo Camponogara},
  doi          = {10.1016/j.cor.2025.107259},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107259},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-price algorithm for energy aware task scheduling of constellations of nanosatellites},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid memetic metaheuristic for medical staff assignment in major public health emergencies. <em>COR</em>, <em>185</em>, 107256. (<a href='https://doi.org/10.1016/j.cor.2025.107256'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During major public health emergencies, effective assignment of medical staff is crucial for saving lives and controlling the spread of epidemics. This work focuses on the assignment of doctors and nurses to hospitals to form treatment groups that carry out patient treatment tasks. We consider the practical constraints of skill types of medical staff and the severity of patients’ conditions and propose a mixed integer programming model with the objective of maximizing demand satisfaction and personnel skill matching. To solve this problem, we introduce a hybrid memetic search algorithm that combines a specialized crossover operator for generating promising offspring solutions and a variable neighborhood search procedure to improve their quality. Computational results demonstrate that our algorithm outperforms the general mixed integer programming solver GUROBI . The key components of the proposed algorithm are experimentally analyzed and managerial insights are derived.},
  archive      = {J_COR},
  author       = {Yang Wang and He Zheng and Zequn Wei and Christophe Wilbaut and Saïd Hanafi},
  doi          = {10.1016/j.cor.2025.107256},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107256},
  shortjournal = {Comput. Oper. Res.},
  title        = {A hybrid memetic metaheuristic for medical staff assignment in major public health emergencies},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning-guided iterated local search for the minmax multiple traveling salesman problem. <em>COR</em>, <em>185</em>, 107255. (<a href='https://doi.org/10.1016/j.cor.2025.107255'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minmax multiple traveling salesman problem involves minimizing the costs of a longest tour among a set of tours. The problem is of great practical interest because it can be used to formulate several real-life applications. To solve this computationally challenging problem, we propose a learning-driven iterated local search approach that combines an effective local search procedure to find high-quality local optimal solutions and a multi-armed bandit algorithm to select removal and insertion operators to escape local optimal traps. Extensive experiments on 77 commonly used benchmark instances show that the algorithm achieves excellent results in terms of solution quality and running time. In particular, it achieves 32 new best results (improved upper bounds) and matches the best-known results for 35 other instances. Additional experiments shed light on the understanding of the algorithm’s constituent elements. Multi-armed bandit selection can be used advantageously in other multi-operator local search algorithms.},
  archive      = {J_COR},
  author       = {Pengfei He and Jin-Kao Hao and Jinhui Xia},
  doi          = {10.1016/j.cor.2025.107255},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107255},
  shortjournal = {Comput. Oper. Res.},
  title        = {Learning-guided iterated local search for the minmax multiple traveling salesman problem},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Grouping strategies on two-phase methods for bi-objective combinatorial optimization. <em>COR</em>, <em>185</em>, 107254. (<a href='https://doi.org/10.1016/j.cor.2025.107254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-phase methods are commonly used to solve bi-objective combinatorial optimization problems. In the first phase, all extreme supported nondominated points are generated through a dichotomic search. This phase also allows the identification of search zones that may contain other nondominated points. The second phase focuses on exploring these search zones to locate the remaining points, which typically accounts for most of the computational cost. Ranking algorithms are frequently employed to explore each zone individually, but this approach leads to redundancies, causing multiple visits to the same solutions. To mitigate these redundancies, we propose several strategies that group adjacent zones, allowing a single run of the ranking algorithm for the entire group. Additionally, we explore an implicit grouping approach based on a new concept of coverage. Our experiments on the Bi-Objective Spanning Tree Problem demonstrate the beneficial impact of these grouping strategies when combined with coverage.},
  archive      = {J_COR},
  author       = {Felipe O. Mota and Luís Paquete and Daniel Vanderpooten},
  doi          = {10.1016/j.cor.2025.107254},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107254},
  shortjournal = {Comput. Oper. Res.},
  title        = {Grouping strategies on two-phase methods for bi-objective combinatorial optimization},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Drone-aided mobile blood collection problem: A rolling-horizon-based matheuristic. <em>COR</em>, <em>185</em>, 107253. (<a href='https://doi.org/10.1016/j.cor.2025.107253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the drone-aided mobile blood collection problem, which integrates mobile blood donation vehicles with drones to improve operations related to the blood collection in urban areas. Each vehicle, carrying multiple drones, travels to several collection sites to conduct blood collection operations within a working day. Drones fly between vehicles to pick up collected blood bags and deliver them to the blood center. This collaborative framework enhances the performances of the collection system and ensures the freshness of collected blood upon arrival to the blood center. We develop a novel mixed-integer linear programming model to optimally synchronize the routes and collection schedules of mobile units and drones to ensure the timely delivery of collected blood to the blood center. We also develop a rolling-horizon-based matheuristic to solve large-scale instances of the problem. This algorithm combines a rolling horizon approach, which divides the problem into manageable subproblems solved sequentially, with a local branching technique that enhances solutions by exploring promising neighborhoods. To evaluate the algorithm’s performance, we conduct a comprehensive computational study. Our results show that the proposed algorithm not only finds better solutions than those obtained by Gurobi but also outperforms other matheuristics, including the rolling horizon, relax-and-fix, and fix-and-optimize algorithms. Finally, we demonstrate the real-life applicability of the problem through a case study in Quebec City, Canada.},
  archive      = {J_COR},
  author       = {Amirhossein Abbaszadeh and Hossein Hashemi Doulabi},
  doi          = {10.1016/j.cor.2025.107253},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107253},
  shortjournal = {Comput. Oper. Res.},
  title        = {Drone-aided mobile blood collection problem: A rolling-horizon-based matheuristic},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fair and efficient multi-agent routing for cooperative and autonomous agricultural fleets with implements. <em>COR</em>, <em>185</em>, 107252. (<a href='https://doi.org/10.1016/j.cor.2025.107252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing use of autonomous tractor fleets with detachable implements presents complex logistical challenges in agriculture. Current systems often rely on simple heuristics and avoid implement swapping, limiting efficiency. A central challenge is to dynamically coordinate vehicle routing and implement exchanges to enable efficient, low-intervention task execution. Due to high costs, such fleets are owned mainly by large enterprises or cooperatives, where fair task allocation and profit sharing are critical. Addressing both coordination and fairness, in this paper, we introduce the Agricultural Fleet Vehicle Routing Problem with Implements (AFVRPI). We propose a distributed model derived from a centralized formulation also presented in this paper. This model is embedded within a Distributed Multi-Agent System Architecture (DIMASA), where autonomous vehicle agents manage routing and implement use under limited fuel autonomy, while implement agents ensure compatibility and sufficient capacity to meet task demands. Our solution applies systematic egalitarian social welfare optimization to iteratively maximize the profit of the worst-off vehicle, balancing fairness with system efficiency. To enhance scalability, we use column generation in the distributed model, achieving solution quality comparable to the centralized model while significantly reducing computing time. Simulation results on new benchmark instances demonstrate that our distributed multi-agent AFVRPI approach is scalable, efficient, and fair.},
  archive      = {J_COR},
  author       = {Aitor López-Sánchez and Marin Lujak and Frédéric Semet and Holger Billhardt},
  doi          = {10.1016/j.cor.2025.107252},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107252},
  shortjournal = {Comput. Oper. Res.},
  title        = {Fair and efficient multi-agent routing for cooperative and autonomous agricultural fleets with implements},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Flexible scheduling of customized bus for green mega-events: A distributionally robust optimization approach. <em>COR</em>, <em>185</em>, 107249. (<a href='https://doi.org/10.1016/j.cor.2025.107249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mega-events such as the Olympics and the World Championships face significant challenges in evacuating large numbers of attendees after the events conclude, which consume substantial transportation resources. Under the global pressure to reduce carbon emissions, energy conservation and emission reduction are increasingly becoming top priorities. This paper focuses on the efficient scheduling of customized buses (CB) after green mega-events, incorporating skip-stop operations and coordinated bus services to minimize energy consumption, fixed and transportation costs, and facilitate the evacuation of attendees, while accounting for practical constraints such as the availability of customized buses, vehicle capacity, time windows, and flow balance. A distributionally robust optimization (DRO) model is developed, using a novel ambiguity set to model uncertain demand via parametric interval-valued fuzzy variables. To ensure computational tractability, the model is reformulated as an integer linear programming model. To address the computational challenges of large-scale instances, an improved variable neighborhood search heuristic is designed by incorporating the reinforcement learning techniques, including the KL-UCB algorithm and a sliding window mechanism. Extensive numerical experiments are conducted to verify the performance of the proposed heuristic. Computational results demonstrate that the proposed DRO model effectively handles uncertainty, offering robust and adaptable solutions. Compared to existing heuristics, the proposed heuristic improves performance by 6.51% on average, and incorporating reinforcement learning into VNS enhances computational efficiency by 4.88% on average. A real-life case study further validates the model, demonstrating that the skip-stop strategy significantly reduces vehicle travel time and enhances overall operational efficiency.},
  archive      = {J_COR},
  author       = {Xiaojie An and Xiang Li and Bowen Zhang},
  doi          = {10.1016/j.cor.2025.107249},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107249},
  shortjournal = {Comput. Oper. Res.},
  title        = {Flexible scheduling of customized bus for green mega-events: A distributionally robust optimization approach},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal planning of power distribution networks with fault-tolerant configuration. <em>COR</em>, <em>185</em>, 107248. (<a href='https://doi.org/10.1016/j.cor.2025.107248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power Distribution networks are essential infrastructures that should be designed by satisfying two conflicting requests: cost minimization and reliability. While traditional network planning aimed at radial configurations, which are more similar to the typical working configuration of a network but are not fault-tolerant, modern techniques seek for meshed configurations, since these architectures are more fault-tolerant. Due to the complexity of the problem and the large size of nowadays instances, most of the techniques used for planning are based on heuristic approaches. Thus, they are usually unable to guarantee optimality and not even able to provide an assessment of the distance from the optimal solution. In this work, we address the challenge of planning a fault tolerant network through an exact approach, by introducing innovative Mixed-Integer Linear Programming models designed for the planning of meshed distribution networks with loop-feeder or open-loop topology. Differently from other techniques, our approach simplifies the formulation by avoiding the need for fault scenarios, significantly reducing the computational burden of the optimization problem. The outcomes of our approach are the generation of optimal meshed network, which effectively balance cost and reliability of the electric distribution system. Comprehensive studies on realistic test instances show the advantages of the proposed formulations.},
  archive      = {J_COR},
  author       = {Renato Bruni and Alberto Geri and Marco Maccioni and Ludovico Nati},
  doi          = {10.1016/j.cor.2025.107248},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107248},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal planning of power distribution networks with fault-tolerant configuration},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Centrality measures and opinion dynamics in two-layer networks with replica nodes. <em>COR</em>, <em>185</em>, 107245. (<a href='https://doi.org/10.1016/j.cor.2025.107245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose two fast and accurate algorithms to approximate game-theoretic centrality measures and examine connection between centrality measures, network properties, and key performance indicators (consensus time and winning rate) of opinion dynamic processes on such networks. As an example, we consider a Zachary’s karate club as a social network and extend it by adding the second (internal) layer of communication. The internal layer represents the network where individuals can share their real opinions with the close friends. The structures of the external and internal layers may be different. The significant positive correlation between internal graph density and consensus time, and significant negative correlation between centrality of authoritative nodes and consensus time are found. The proposed algorithms are verified by a series of experiments from two aspects: the accuracy and the efficiency. The algorithms are novel and can be considered as a contribution to the network theory independently of opinion dynamics as they can be used to calculate node centrality in any weighted graph.},
  archive      = {J_COR},
  author       = {Chi Zhao and Elena Parilina},
  doi          = {10.1016/j.cor.2025.107245},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107245},
  shortjournal = {Comput. Oper. Res.},
  title        = {Centrality measures and opinion dynamics in two-layer networks with replica nodes},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI automatic decision in newsvendor model with nash bargaining fairness concern. <em>COR</em>, <em>185</em>, 107227. (<a href='https://doi.org/10.1016/j.cor.2025.107227'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the impact of artificial intelligence (AI) automatic ordering and producing decisions on fairness-concerned supply chains under the newsvendor model. We develop a dyadic supply chain model in which the manufacturer acts as the Stackelberg leader while the retailer serves as the follower in a push supply chain. In contrast, their roles are switched in a pull supply chain. We assume that only human decision-making leads to decision regret behavior, whereas AI-automated decision-making does not. Without adopting AI, our results show that fairness concern does not necessarily lead to a decreasing quantity in ordering or producing, which is different from most previous studies. Different from the prior findings, our work reveals that in binding equilibrium, if fairness concerns are considered, the order quantity will decrease, while in non-binding equilibrium, the order quantity may not necessarily be less than the previous results. Interestingly, when decision regret bias is considered for fairness-concerned decision-makers, we can obtain quantity coordination solutions for supply chains under specific conditions. With adopting AI, our results show that increasing fairness concerns are beneficial for improving the follower’s profit while at the expense of sacrificing the leader’s profit margins, while the leader can only benefit from AI adoption when the decision regret bias of the follower is relatively high. It is noteworthy that under certain conditions, AI automation may negatively impact the profits of both push and pull decentralized supply chains. For instance, in low-margin profit scenarios where decision-makers exhibit moderate regret bias and fairness concerns, such effects can emerge. This indicates that under specific circumstances, the human behavioral factors — regret bias and fairness concerns — may sometimes enhance the performance of decentralized supply chain members. Our research findings provide significant practical implications for the adoption of AI-automated decision-making in real-world supply chains.},
  archive      = {J_COR},
  author       = {Rui Hou and Yishen Cen and Jianxin Chen},
  doi          = {10.1016/j.cor.2025.107227},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107227},
  shortjournal = {Comput. Oper. Res.},
  title        = {AI automatic decision in newsvendor model with nash bargaining fairness concern},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Green horizons: Sustainable global logistics in dynamic supply chain management. <em>COR</em>, <em>185</em>, 107226. (<a href='https://doi.org/10.1016/j.cor.2025.107226'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply chain management in a global scale involves addressing numerous uncertainties, from demand fluctuations to unforeseen disruptions. Developing advanced solution approaches is critical to manage such complexities and ensure resilience. This study presents a multi-stage stochastic–dynamic model for the global supply chain, incorporating hedging policies. The aim is to identify optimal order scheduling for bill of materials, production planning, and inventory management across warehouses (i.e., materials and finished products). Due to the dynamic nature of the global supply chain (e.g., demand fluctuations, disruptions, and lead time), a multi-stage stochastic model is developed for the stochastic–dynamic supply chain network. To address dynamic factors of real-world global supply chain, an accelerated parallel stochastic dual dynamic integer programming (SDDiP) approach is proposed to deal with disruptions (e.g., political unrest, natural disasters, and pandemics), enhancing supply chain resiliency. To validate the proposed parallel SDDiP , various scenarios with different sizes are generated using the case study and compared to the SDDiP with Benders cuts and integrated stage-wise Lagrangian dual cut ( SWLDC ) (i.e., SDDiP-SWLDC ). According to the obtained results, the proposed parallel node strategy for accelerated SDDiP consistently outperforms the basic stochastic dual dynamic programming (SDDP) and demonstrated robust CPU scalability. Evaluation across various scenario sizes shows stochastic dual dynamic integer programming-mixed integer rounding cuts ( SDDiP-MIR ) achieving faster computation and a smaller 7% optimality gap compared to SDDiP-SWLDC and SDDiP in large-size instances, highlighting its superior performance in complex supply chain settings.},
  archive      = {J_COR},
  author       = {Mahsa Mohammadi and Babak Mohamadpour Tosarkani},
  doi          = {10.1016/j.cor.2025.107226},
  journal      = {Computers & Operations Research},
  month        = {1},
  pages        = {107226},
  shortjournal = {Comput. Oper. Res.},
  title        = {Green horizons: Sustainable global logistics in dynamic supply chain management},
  volume       = {185},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="csda">CSDA - 7</h2>
<ul>
<li><details>
<summary>
(2026). An algorithm for estimating threshold boundary regression models. <em>CSDA</em>, <em>214</em>, 108274. (<a href='https://doi.org/10.1016/j.csda.2025.108274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an innovative iterative two-stage algorithm designed for estimating threshold boundary regression (TBR) models. By transforming the non-differentiable least-squares (LS) problem inherent in fitting TBR models into an optimization framework, our algorithm combines the optimization of a weighted classification error function for the threshold model with obtaining LS estimators for regression models. To improve the efficiency and flexibility of TBR model estimation, we integrate the weighted support vector machine (WSVM) as a surrogate method for solving the weighted classification problem. The TBR-WSVM algorithm offers several key advantages over recently developed methods: it eliminates pre-specification requirements for threshold parameters, accommodates flexible estimation of nonlinear threshold boundaries, and streamlines the estimation process. We conducted several simulation studies to illustrate the finite-sample performance of TBR-WSVM. Finally, we demonstrate the practical applicability of the TBR model through a real data analysis.},
  archive      = {J_CSDA},
  author       = {Chih-Hao Chang and Takeshi Emura and Shih-Feng Huang},
  doi          = {10.1016/j.csda.2025.108274},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108274},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {An algorithm for estimating threshold boundary regression models},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rate accelerated inference for integrals of multivariate random functions. <em>CSDA</em>, <em>214</em>, 108273. (<a href='https://doi.org/10.1016/j.csda.2025.108273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation of integrals is a fundamental task in the analysis of functional data, where the data are typically considered as random elements in a space of squared integrable functions. Effective unbiased estimation and inference procedures are proposed for integrals of uni- and multivariate random functions. Applications to key problems in functional data analysis involving random design points are examined and illustrated. In the absence of noise, the proposed estimates converge faster than the sample mean and standard numerical integration algorithms. The estimator also supports effective inference by generally providing better coverage with shorter confidence and prediction intervals in both noisy and noiseless settings.},
  archive      = {J_CSDA},
  author       = {Valentin Patilea and Sunny G․ W․ Wang},
  doi          = {10.1016/j.csda.2025.108273},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108273},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Rate accelerated inference for integrals of multivariate random functions},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust selection of the number of change-points via FDR control. <em>CSDA</em>, <em>214</em>, 108272. (<a href='https://doi.org/10.1016/j.csda.2025.108272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust quantification of uncertainty regarding the number of change-points presents a significant challenge in data analysis, particularly when employing false discovery rate (FDR) control techniques. Emphasizing the detection of genuine signals while controlling false positives is crucial, especially for identifying shifts in location parameters within flexible distributions. Traditional parametric methods often exhibit sensitivity to outliers and heavy-tailed data. Addressing this limitation, a robust method accommodating diverse data structures is proposed. The approach constructs component-wise sign-based statistics. Leveraging the global symmetry inherent in these statistics enables the derivation of data-driven thresholds suitable for multiple testing scenarios. Method development occurs within the framework of U-statistics, which naturally encompasses existing cumulative sum-based procedures. Theoretical guarantees establish FDR control for the component-wise sign-based method under mild assumptions. Demonstrations of effectiveness utilize simulations with synthetic data and analyses of real data.},
  archive      = {J_CSDA},
  author       = {Hui Chen and Chengde Qian and Qin Zhou},
  doi          = {10.1016/j.csda.2025.108272},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108272},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Robust selection of the number of change-points via FDR control},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Kernel density estimation with a markov chain monte carlo sample. <em>CSDA</em>, <em>214</em>, 108271. (<a href='https://doi.org/10.1016/j.csda.2025.108271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian inference relies on the posterior distribution, which is often estimated with a Markov chain Monte Carlo sampler. The sampler produces a dependent stream of variates from the limiting distribution of the Markov chain, the posterior distribution. When one wishes to display the estimated posterior density, a natural choice is the histogram. However, abundant literature has shown that the kernel density estimator is more accurate than the histogram in terms of mean integrated squared error for an i.i.d. sample. With this as motivation, a kernel density estimation method is proposed that is appropriate for the dependence in the Markov chain Monte Carlo output. To account for the dependence, the cross-validation criterion is modified to select the bandwidth in standard kernel density estimation approaches. A data-driven adjustment to the biased cross-validation method is suggested with introducing the integrated autocorrelation time of the kernel. The convergence of the modified bandwidth to the optimal bandwidth is shown by adapting theorems from the time series literature. Simulation studies show that the proposed method finds the bandwidth close to the optimal value, while standard methods lead to smaller bandwidths under Markov chain samples and hence to undersmoothed density estimates. A study with real data shows that the proposed method has a considerably smaller integrated mean squared error than standard methods. The R package KDEmcmc to implement the suggested algorithm is available on the Comprehensive R Archive Network.},
  archive      = {J_CSDA},
  author       = {Hang J. Kim and Steven N. MacEachern and Young Min Kim and Yoonsuh Jung},
  doi          = {10.1016/j.csda.2025.108271},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108271},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Kernel density estimation with a markov chain monte carlo sample},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Measure selection for functional linear model. <em>CSDA</em>, <em>214</em>, 108270. (<a href='https://doi.org/10.1016/j.csda.2025.108270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in modern science have led to an increased prevalence of functional data, which are usually viewed as elements of the space of square-integrable functions L 2 . Core methods in functional data analysis, such as functional principal component analysis, are typically grounded in the Hilbert structure of L 2 and rely on inner products based on integrals with respect to the Lebesgue measure over a fixed domain. A more flexible framework is proposed, where the measure can be arbitrary, allowing natural extensions to unbounded domains and prompting the question of optimal measure choice. Specifically, a novel functional linear model is introduced that incorporates a data-adaptive choice of the measure that defines the space, alongside an enhanced function principal component analysis. Selecting a good measure can improve the model’s predictive performance, especially when the underlying processes are not well-represented when adopting the default Lebesgue measure. Simulations, as well as applications to COVID-19 data and the National Health and Nutrition Examination Survey data, show that the proposed approach consistently outperforms the conventional functional linear model.},
  archive      = {J_CSDA},
  author       = {Su I Iao and Hans-Georg Müller},
  doi          = {10.1016/j.csda.2025.108270},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108270},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Measure selection for functional linear model},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overview of normal-reference tests for high-dimensional means with implementation in the r package ‘HDNRA’. <em>CSDA</em>, <em>214</em>, 108269. (<a href='https://doi.org/10.1016/j.csda.2025.108269'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge of testing for equal mean vectors in high-dimensional data poses significant difficulties in statistical inference. Much of the existing literature introduces methods that often rely on stringent regularity conditions for the underlying covariance matrices, enabling asymptotic normality of test statistics. However, this can lead to complications in controlling test size. To address these issues, a new set of tests has emerged, leveraging the normal-reference approach to improve reliability. The latest normal-reference methods for testing equality of mean vectors in high-dimensional samples, potentially with differing covariance structures, are reviewed. The theoretical underpinnings of these tests are revisited, providing a new unified justification for the validity of centralized L 2 -norm-based normal-reference tests (NRTs) by deriving the convergence rate of the distance between the null distribution of the test statistic and its corresponding normal-reference distribution. To facilitate practical application, an R package, HDNRA , is introduced, implementing these NRTs and extending beyond the two-sample problem to accommodate general linear hypothesis testing (GLHT). The package, designed with user-friendliness in mind, achieves efficient computation through a core implemented in C++ using Rcpp , OpenMP , and RcppArmadillo . Examples with real datasets are included, showcasing the application of various tests and providing insights into their practical utility.},
  archive      = {J_CSDA},
  author       = {Pengfei Wang and Tianming Zhu and Jin-Ting Zhang},
  doi          = {10.1016/j.csda.2025.108269},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108269},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Overview of normal-reference tests for high-dimensional means with implementation in the r package ‘HDNRA’},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-dimensional subgroup functional quantile regression with panel and dependent data. <em>CSDA</em>, <em>214</em>, 108268. (<a href='https://doi.org/10.1016/j.csda.2025.108268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional additive functional partial linear single-index quantile regression with high-dimensional parameters under subgroup panel data is investigated. Based on spline-based approach, we construct oracle estimators of the unknown parameter and functions, and discuss their consistency with rates and asymptotic normality under α -mixing assumptions. A penalized estimation method by using the SCAD technique is introduced to estimate the additive functions and parameter, enabling variable selection and automatic identification of the number of groups. Hypothesis testing for the parameter is also considered, and the asymptotic distributions of the restricted estimators and the test statistic are derived under both the null and local alternative hypotheses. Simulation studies and real data analysis are conducted to verify the validity of the proposed methods and applications.},
  archive      = {J_CSDA},
  author       = {Xiao-Ge Yu and Han-Ying Liang},
  doi          = {10.1016/j.csda.2025.108268},
  journal      = {Computational Statistics & Data Analysis},
  month        = {2},
  pages        = {108268},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {High-dimensional subgroup functional quantile regression with panel and dependent data},
  volume       = {214},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="cviu">CVIU - 9</h2>
<ul>
<li><details>
<summary>
(2025). Two-stage attribute-guided dual attention network for fine-grained fashion retrieval. <em>CVIU</em>, <em>261</em>, 104497. (<a href='https://doi.org/10.1016/j.cviu.2025.104497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained clothing retrieval is essential for intelligent shopping and personalized recommendation systems. However, conventional methods often fail to capture subtle attribute variations. This paper proposes a novel two-stage attribute-guided dual attention network. The network combines global and local feature extraction with Attribute-aware Multi-Scale Spatial Attention (AMSA) and Attribute-guided Dynamic Channel Attention (ADCA). AMSA captures attribute-specific spatial details at multiple scales, while ADCA dynamically adjusts channel importance based on attribute embeddings, enabling precise attribute-level similarity modeling. A multi-level joint loss function further optimizes both global and local representations and enhances feature alignment. Experiments on FashionAI and the self-built FGDress dataset show that the proposed method achieves mAP scores of 66.01% and 73.98%, respectively, outperforming baseline approaches. Attribute-level analysis confirms robust recognition of both well-defined and challenging attributes. These results validate the practicality and generalizability of the proposed framework, with promising applications in personalized recommendation, fashion trend analysis, and design evaluation.},
  archive      = {J_CVIU},
  author       = {Bo Pan and Jun Xiang and Ning Zhang and Ruru Pan},
  doi          = {10.1016/j.cviu.2025.104497},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104497},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Two-stage attribute-guided dual attention network for fine-grained fashion retrieval},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JSF: A joint spatial-frequency domain network for low-light image enhancement. <em>CVIU</em>, <em>261</em>, 104496. (<a href='https://doi.org/10.1016/j.cviu.2025.104496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The enhancement of low-light images remains a prominent focus in the field of image processing. The degree of lightness significantly influences vision-based intelligent recognition and analysis. Departing from conventional methods, this paper proposes an innovative joint spatial-frequency domain network for low-light image enhancement, referred to as JSF. In the spatial domain, brightness is optimized through the amalgamation of global and local information. In the frequency domain, noise is reduced and details are amplified using Fourier Transformation to carry out amplitude and phase enhancement. Additionally, the enhanced results from the aforementioned domains are fused by linear and nonlinear stretching. To validate the effectiveness of JSF, this paper presents both qualitative and quantitative comparison results, demonstrating its superiority over several existing state-of-the-art methods.},
  archive      = {J_CVIU},
  author       = {Yahong Wu and Feng Liu and Rong Wang},
  doi          = {10.1016/j.cviu.2025.104496},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104496},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {JSF: A joint spatial-frequency domain network for low-light image enhancement},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCNet: A feature complementary network for nighttime flare removal. <em>CVIU</em>, <em>261</em>, 104495. (<a href='https://doi.org/10.1016/j.cviu.2025.104495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nighttime image flare removal is a very challenging task due to the presence of various types of unfavorable degrading effects, including glare, shimmer, streak and saturated blobs. Most of the existing methods focus on the spatial domain and limited perception field, resulting in incomplete flare removal and severe artifacts. To address these challenges, we propose a two-stage feature complementary network for nighttime flare removal, which is used for flare perception and removal, respectively. In the first stage, a Spatial-Frequency Complementary Module (SFCM) is designed to perceive the flare region from different domains to get a mask of the flare. In the second stage, the flare mask and image are fed into the Spatial-Frequency Complementary Gating Module (SFCGM) to preserve the background information, while removing the flares from different angles and restoring the detailed features. Finally the flare and non-flare regions are modeled by the Flare Interactive Module (FIM) to refine the flare regions at a fine-grained level to suppress the artifact problem. Extensive experiments on Flare 7K++ validate the superiority of the proposed approach over state-of-the-arts, both qualitatively and quantitatively.},
  archive      = {J_CVIU},
  author       = {Kejing Qi and Bo Wang and Chongyi Li},
  doi          = {10.1016/j.cviu.2025.104495},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104495},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {FCNet: A feature complementary network for nighttime flare removal},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GRE-net: A forgery image detection framework based on gradient feature and reconstruction error. <em>CVIU</em>, <em>261</em>, 104494. (<a href='https://doi.org/10.1016/j.cviu.2025.104494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous technological breakthroughs in Generative Adversarial Networks (GANs) and diffusion models, remarkable progress has been achieved in the field of image generation. These technologies enable the creation of highly realistic images, thereby intensifying the risk of spreading fake information. However, traditional image detectors face a growing challenge of inadequate generalization capabilities when confronted with images generated by models that were not included during the training phase. To tackle this challenge, we introduce a novel detection framework, named GRE-Net (Network integrating Gradient and Reconstruction Error), which extracts gradient feature through the DPG module and calculates the reconstruction error utilizing the DIRE method. By integrating these two aspects into a comprehensive feature representation, GRE-Net effectively detects the authenticity of images. Specifically, we devise a dual-branch model that leverages the proposed DPG (Discriminator of ProjectedGAN to extract Gradient) module to extract gradient feature from images and concurrently employs the DIRE (DIffusion Reconstruction Error) method to obtain the diffusion reconstruction error of images. By fusing the features extracted from these two modules as a universal representation, we describe the artifacts produced by generative models, crafting a comprehensive detector capable of identifying both GAN-generated and diffusion model-generated images. Notably, the DPG approach utilizes the discriminator of ProjectedGAN as an intermediary bridge, mapping all data into the gradient domain. This transformation process effectively captures the intrinsic feature differences during the image generation process. Subsequently, the gradient feature are fed into a classifier to achieve efficient discrimination between authentic and fake images. To validate the efficacy of our proposed detector, we conducted evaluations on a dataset comprising images generated by ten diverse diffusion models and GANs. Extensive experiments demonstrate that our detector exhibits stronger generalization capabilities and higher robustness, rendering it suitable for real-world generated image detection tasks.},
  archive      = {J_CVIU},
  author       = {Wenqing Wu and Xinyi Shi and Jinghai Ai and Xiaodong Wang},
  doi          = {10.1016/j.cviu.2025.104494},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104494},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {GRE-net: A forgery image detection framework based on gradient feature and reconstruction error},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating forgetting in the adaptation of CLIP for few-shot classification. <em>CVIU</em>, <em>261</em>, 104493. (<a href='https://doi.org/10.1016/j.cviu.2025.104493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adapter-style efficient transfer learning has demonstrated outstanding performance in fine-tuning vision-language models, especially in scenarios with limited data. However, existing methods fail to effectively balance the prior knowledge acquired during the pre-training process and the training samples. To address this problem, we propose a method called Mitigating Forgetting in the Adaptation (MiFA) of CLIP. MiFA first employs class prototypes to represent the most prominent features of a class, and these prototypes provide a robust initialization for the classifier. To overcome the forgetting of prior knowledge, MiFA then leverages a memory module that retains the initial parameters and the parameters of training history by creating a memory weight through momentum. The weight is used to initialize a new classification layer, which, along with the original layer, guides each other to balance prior knowledge and feature adaptation. Similarly, in the text processing branch, a parallel initialization strategy is adopted to ensure that the model’s performance is improved. Text features are employed to initialize a text classification layer, and CLIP logits help prevent excessive forgetting of useful text information. Extensive experiments have demonstrated the effectiveness of our method.},
  archive      = {J_CVIU},
  author       = {Jiale Cao and Yuanheng Liu and Zhong Ji and Jingren Liu and Aiping Yang and Yanwei Pang},
  doi          = {10.1016/j.cviu.2025.104493},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104493},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Mitigating forgetting in the adaptation of CLIP for few-shot classification},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint multi-dimensional dynamic attention and transformer for general image restoration. <em>CVIU</em>, <em>261</em>, 104491. (<a href='https://doi.org/10.1016/j.cviu.2025.104491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outdoor images often suffer from severe degradation due to rain, haze, and noise, impairing image quality and challenging high-level tasks. Current image restoration methods struggle to handle complex degradation while maintaining efficiency. This paper introduces a novel image restoration architecture that combines multi-dimensional dynamic attention and self-attention within a U-Net framework. To leverage the global modeling capabilities of transformers and the local modeling capabilities of convolutions, we integrate sole CNNs in the encoder–decoder and sole transformers in the latent layer. Additionally, we design convolutional kernels with selected multi-dimensional dynamic attention to capture diverse degraded inputs efficiently. A transformer block with transposed self-attention further enhances global feature extraction while maintaining efficiency. Extensive experiments demonstrate that our method achieves a better balance between performance and computational complexity across five image restoration tasks: deraining, deblurring, denoising, dehazing, and enhancement, as well as superior performance for high-level vision tasks. The source code will be available at https://github.com/House-yuyu/MDDA-former .},
  archive      = {J_CVIU},
  author       = {Huan Zhang and Xu Zhang and Nian Cai and Jianglei Di and Yun Zhang},
  doi          = {10.1016/j.cviu.2025.104491},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104491},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Joint multi-dimensional dynamic attention and transformer for general image restoration},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LAM-YOLO: Drones-based small object detection on lighting-occlusion attention mechanism YOLO. <em>CVIU</em>, <em>261</em>, 104489. (<a href='https://doi.org/10.1016/j.cviu.2025.104489'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drone-based target detection presents inherent challenges, including the high density and overlap of targets in drone images, as well as the blurriness of targets under varying lighting conditions, which complicates accurate identification. Traditional methods often struggle to detect numerous small, densely packed targets against complex backgrounds. To address these challenges, we propose LAM-YOLO, an object detection model specifically designed for drone-based applications. First, we introduce a light-occlusion attention mechanism to enhance the visibility of small targets under diverse lighting conditions. Additionally, we incorporate Involution modules to improve feature layer interactions. Second, we employ an improved SIB-IoU as the regression loss function to accelerate model convergence and enhance localization accuracy. Finally, we implement a novel detection strategy by introducing two auxiliary detection heads to better identify smaller-scale targets. Our quantitative results demonstrate that LAM-YOLO outperforms methods such as Faster R-CNN, YOLOv11, and YOLOv12 in terms of mAP@0.5 and mAP@0.5:0.95 on the VisDrone2019 public dataset. Compared to the original YOLOv8, the average precision increases by 7.1%. Additionally, the proposed SIB-IoU loss function not only accelerates convergence speed during training but also improves average precision compared to the traditional loss function.},
  archive      = {J_CVIU},
  author       = {Yuchen Zheng and Yuxin Jing and Jufeng Zhao and Guangmang Cui},
  doi          = {10.1016/j.cviu.2025.104489},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104489},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {LAM-YOLO: Drones-based small object detection on lighting-occlusion attention mechanism YOLO},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Camera pose in SfT and NRSfM under isometric and weaker deformation models. <em>CVIU</em>, <em>261</em>, 104488. (<a href='https://doi.org/10.1016/j.cviu.2025.104488'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camera pose is a very natural concept in 3D vision in the rigid setting. It is however much more difficult to work with in deformable settings. Consequently, numerous deformable reconstruction methods simply ignore camera pose. We analyse the concept of pose in deformable settings and prove that it is unconstrained with the existing formulations, properly justifying the existing pose-less methods reconstructing structure only. We explain this result intuitively by the impossibility to define an intrinsic coordinate frame to a general deforming object. The proposed analysis uses the isometric deformation model and extends to the weaker models including conformality and equiareality We propose a novel prior to rescue camera pose estimation in deformable settings, which attributes the deforming object’s dominant rigid-body motion to the camera. We show that adding this prior to any existing formulation fully constrains camera pose and leads to elegant two-step solution methods, involving deformable structure reconstruction using a base method in the first step, and absolute orientation or Procrustes analysis in the second step. We derive the proposed approach for the template-based and template-less settings, respectively implemented using Shape-from-Template (SfT) and Non-Rigid Structure-from-Motion (NRSfM) as base methods and validate them experimentally, showing that the computed pose is qualitatively and quantitatively plausible.},
  archive      = {J_CVIU},
  author       = {Adrien Bartoli and Agniva Sengupta},
  doi          = {10.1016/j.cviu.2025.104488},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104488},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Camera pose in SfT and NRSfM under isometric and weaker deformation models},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-granularity balance learning for long-tailed image classification. <em>CVIU</em>, <em>261</em>, 104469. (<a href='https://doi.org/10.1016/j.cviu.2025.104469'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In long-tailed datasets, the training of deep neural network-based models faces challenges, where the model may become biased towards the head classes with abundant training data, resulting in poor performance on tail classes with limited samples. Most current methods employ contrastive learning to learn more balanced representations by finding the class center. However, these methods use class centers to address local imbalance within a mini-batch, they overlook the global imbalance between batches throughout an epoch, caused by the long-tailed distribution of the dataset. In this paper, we propose bi-granularity balance learning to address the two-layer imbalance. We decouple the attraction–repulsion term in contrastive loss into two independent components: global and local balance. The global balance component focuses on capturing semantic information from different perspectives of the image and shifting learning attention from the head classes to the tail classes in the global perspective. The local balance component aims to learn inter-class separability from the local perspective. The proposed method efficiently learns the intra-class compactness and inter-class separability in long-tailed model training and improves the performance of the long-tailed model. Experimental results show that the proposed method achieves competitive performance on long-tailed benchmarks such as CIFAR-10/100-LT, TinyImageNet-LT, and iNaturalist 2018.},
  archive      = {J_CVIU},
  author       = {Ning Ren and Xiaosong Li and Yanxia Wu and Yan Fu},
  doi          = {10.1016/j.cviu.2025.104469},
  journal      = {Computer Vision and Image Understanding},
  month        = {11},
  pages        = {104469},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Bi-granularity balance learning for long-tailed image classification},
  volume       = {261},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="disopt">DISOPT - 3</h2>
<ul>
<li><details>
<summary>
(2025). Computational aspects of lifted cover inequalities for knapsacks with few different weights. <em>DISOPT</em>, <em>58</em>, 100912. (<a href='https://doi.org/10.1016/j.disopt.2025.100912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cutting planes are frequently used for solving integer programs. A common strategy is to derive cutting planes from building blocks or a substructure of the integer program. In this paper, we focus on knapsack constraints that arise from single row relaxations. Among the most popular classes derived from knapsack constraints are lifted minimal cover inequalities. The separation problem for these inequalities is NP-hard though, and one usually separates them heuristically, therefore not fully exploiting their potential. For many benchmarking instances however, it turns out that many knapsack constraints only have few different coefficients. This motivates the concept of sparse knapsacks where the number of different coefficients is a small constant, independent of the number of variables present. For such knapsacks, we observe that there are only polynomially many different classes of structurally equivalent minimal covers. This opens the door to specialized techniques for using lifted minimal cover inequalities. In this article we will discuss two such techniques, which are based on specialized sorting methods. On the one hand, we present new separation routines that separate equivalence classes of inequalities rather than individual inequalities. On the other hand, we derive compact extended formulations that express all lifted minimal cover inequalities by means of a polynomial number of constraints. These extended formulations are based on tailored sorting networks that express our separation algorithm by linear inequalities. We conclude the article by a numerical investigation of the different techniques for popular benchmarking instances.},
  archive      = {J_DISOPT},
  author       = {Christopher Hojny and Cédric Roy},
  doi          = {10.1016/j.disopt.2025.100912},
  journal      = {Discrete Optimization},
  month        = {11},
  pages        = {100912},
  shortjournal = {Discret. Optim.},
  title        = {Computational aspects of lifted cover inequalities for knapsacks with few different weights},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved bound for the price of anarchy for related machine scheduling. <em>DISOPT</em>, <em>58</em>, 100911. (<a href='https://doi.org/10.1016/j.disopt.2025.100911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce an improved upper bound for the efficiency of Nash equilibria in utilitarian scheduling games on related machines. The machines have varying speeds and adhere to the shortest processing time first policy. The goal of each job is to minimize its completion time, while the social objective is to minimize the sum of completion times. Our main finding establishes an upper bound of 2 − 1 / ( 4 m − 2 ) on the price of anarchy for the general case of m machines. We improve this bound to 3/2 for the case of two machines, and to 2 − 1 / ( 2 m ) for the general case of m machines when the machines have divisible speeds, i.e., if the speed of each machine is divisible by the speed of any slower machine.},
  archive      = {J_DISOPT},
  author       = {André Berger and Arman Rouhani and Marc Schröder},
  doi          = {10.1016/j.disopt.2025.100911},
  journal      = {Discrete Optimization},
  month        = {11},
  pages        = {100911},
  shortjournal = {Discret. Optim.},
  title        = {An improved bound for the price of anarchy for related machine scheduling},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the circuit diameter conjecture for counterexamples to the hirsch conjecture. <em>DISOPT</em>, <em>58</em>, 100910. (<a href='https://doi.org/10.1016/j.disopt.2025.100910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circuit diameters of polyhedra are a fundamental tool for studying the complexity of circuit augmentation schemes for linear programming and for finding lower bounds on combinatorial diameters. The main open problem in this area is the circuit diameter conjecture, the analogue of the Hirsch conjecture in the circuit setting. A natural question is whether the well-known counterexamples to the Hirsch conjecture carry over. Previously, Stephen and Yusun showed that the Klee-Walkup counterexample to the unbounded Hirsch conjecture does not transfer to the circuit setting. Our main contribution is to show that the original counterexamples for other variants, using monotone walks or for bounded polytopes, also do not transfer. A challenge lies in the dependence of circuit diameters on the specific realization of a polyhedron. We discuss for which realizations, in addition to the original ones from the literature, our tools resolve this question. Our results rely on new observations on structural properties of these counterexamples. To analyze the bounded case, we exploit the geometry of certain 2-faces of the polytopes underlying all known bounded Hirsch counterexamples in Santos’ work. For Todd’s monotone Hirsch counterexample, we study linear programs on spindles and prove sufficient conditions for short monotone circuit walks to exist. We then enumerate all linear programs over Todd’s polytope and find four new orientations that contradict the monotone Hirsch conjecture, while the remaining 7107 satisfy the bound. The conclusion then follows by applying these sufficient conditions to Todd’s counterexample.},
  archive      = {J_DISOPT},
  author       = {Alexander E. Black and Steffen Borgwardt and Matthias Brugger},
  doi          = {10.1016/j.disopt.2025.100910},
  journal      = {Discrete Optimization},
  month        = {11},
  pages        = {100910},
  shortjournal = {Discret. Optim.},
  title        = {On the circuit diameter conjecture for counterexamples to the hirsch conjecture},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="dke">DKE - 13</h2>
<ul>
<li><details>
<summary>
(2026). A graph-based model for semantic textual similarity measurement. <em>DKE</em>, <em>161</em>, 102509. (<a href='https://doi.org/10.1016/j.datak.2025.102509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring semantic similarity between sentence pairs is a fundamental problem in Natural Language Processing with applications in various domains, including machine translation, speech recognition, automatic question answering, and text summarization. Despite its significance, accurately assessing semantic similarity remains a challenging task, particularly for underrepresented languages such as Vietnamese. Existing methods have yet to fully leverage the unique linguistic characteristics of Vietnamese for semantic similarity measurement. To address this limitation, we propose GBNet-STS (Graph-Based Network for Semantic Textual Similarity), a novel framework for measuring the semantic similarity of Vietnamese sentence pairs. GBNet-STS integrates lexical-grammatical similarity scores and distributional semantic similarity scores within a multi-layered graph-based model. By capturing different semantic perspectives through multiple interconnected layers, our approach provides a more comprehensive and robust similarity estimation. Experimental results demonstrate that GBNet-STS outperforms traditional methods, achieving state-of-the-art performance in Vietnamese semantic similarity tasks.},
  archive      = {J_DKE},
  author       = {Van-Tan Bui and Quang-Minh Nguyen and Van-Vinh Nguyen and Duc-Toan Nguyen},
  doi          = {10.1016/j.datak.2025.102509},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102509},
  shortjournal = {Data Knowl. Eng.},
  title        = {A graph-based model for semantic textual similarity measurement},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rule-guided process discovery. <em>DKE</em>, <em>161</em>, 102508. (<a href='https://doi.org/10.1016/j.datak.2025.102508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event data extracted from information systems serves as the foundation for process mining, enabling the extraction of insights and identification of improvements. Process discovery focuses on deriving descriptive process models from event logs, which form the basis for conformance checking, performance analysis, and other applications. Traditional process discovery techniques predominantly rely on event logs, often overlooking supplementary information such as domain knowledge and process rules. These rules, which define relationships between activities, can be obtained through automated techniques like declarative process discovery or provided by domain experts based on process specifications. When used as an additional input alongside event logs, such rules have significant potential to guide process discovery. However, leveraging rules to discover high-quality imperative process models, such as BPMN models and Petri nets, remains an underexplored area in the literature. To address this gap, we propose an enhanced framework, IMr, which integrates discovered or user-defined rules into the process discovery workflow via a novel recursive approach. The IMr framework employs a divide-and-conquer strategy, using rules to guide the selection of process structures at each recursion step in combination with the input event log. We evaluate our approach on several real-world event logs and demonstrate that the discovered models better align with the provided rules without compromising their conformance to the event log. Additionally, we show that high-quality rules can improve model quality across well-known conformance metrics. This work highlights the importance of integrating domain knowledge into process discovery, enhancing the quality, interpretability, and applicability of the resulting process models.},
  archive      = {J_DKE},
  author       = {Ali Norouzifar and Marcus Dees and Wil van der Aalst},
  doi          = {10.1016/j.datak.2025.102508},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102508},
  shortjournal = {Data Knowl. Eng.},
  title        = {Rule-guided process discovery},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LQ-FJS: A logical query-digging fake-news judgment system with structured video-summarization engine using LLM. <em>DKE</em>, <em>161</em>, 102507. (<a href='https://doi.org/10.1016/j.datak.2025.102507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of online social platforms can greatly benefit people by fostering remote relationships, but it also inevitably amplifies the impact of multimodal fake news on societal trust and ethics. Existing fake-news detection AI systems are still vulnerable to the inconspicuous and indiscernible multimodal misinformation, and often lacking interpretability and accuracy in cross-platform settings. Hence, we propose a new innovative logical query-digging fake-news judgment system (LQ-FJS) to tackle the above problem based on multimodal approach. The LQ-FJS verifies the truthfulness of claims made within multimedia news by converting video content into structured textual summaries. It then acts as an interpretable agent, explaining the reasons for identified fake news by the structured video-summarization engine (SVSE) to act as an interpretable detection intermediary agent. The SVSE generates condensed captions for raw video content, converting it into structured textual narratives. Then, LQ-FJS exploits these condensed captions to retrieve reliable information related to the video content from LLM. Thus, LQ-FJS cross-verifies external knowledge sources and internal LLM responses to determine whether contradictions exist with factual information through a multimodal inconsistency verification procedure. Our experiments demonstrate that the subtle summarization produced by SVSE can facilitate the generation of explanatory reports that mitigate large-scale trust deficits caused by opaque “black-box” models. Our experiments show that LQ-FJS improves F1 scores by 4.5% and 7.2% compared to state-of-the-art models (FactLLaMA 2023 and HiSS 2023), and increases 14% user trusts through interpretable conclusions.},
  archive      = {J_DKE},
  author       = {Jhing-Fa Wang and Din-Yuen Chan and Hsin-Chun Tsai and Bo-Xuan Fang},
  doi          = {10.1016/j.datak.2025.102507},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102507},
  shortjournal = {Data Knowl. Eng.},
  title        = {LQ-FJS: A logical query-digging fake-news judgment system with structured video-summarization engine using LLM},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ABBA: Index structure for sequential pattern-based aggregate queries. <em>DKE</em>, <em>161</em>, 102506. (<a href='https://doi.org/10.1016/j.datak.2025.102506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pattern-based aggregate (PBA) queries constitute an important and widely used type of analytical queries in sequence OLAP (S-OLAP) systems. Unfortunately, finding accurate answers to PBA queries in the S-OLAP system is often very expensive both in terms of time and memory consumption. In this paper we propose an efficient and easily maintainable index structure called the ABBA Index, which addresses the problem of PBA query processing. Experiments conducted using the KDD Cup data and public transport passengers’ travel behavior data show that our index outperforms state-of-the art solutions while requiring much less memory. The ABBA Index can be easily extended to support pattern-based aggregate queries over hierarchy (PBA-H), a novel class of analytical queries which we introduce as the second main contribution of the paper. Sensitivity, scalability and complexity analysis of the ABBA Index is also provided.},
  archive      = {J_DKE},
  author       = {Witold Andrzejewski and Tadeusz Morzy and Maciej Zakrzewicz},
  doi          = {10.1016/j.datak.2025.102506},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102506},
  shortjournal = {Data Knowl. Eng.},
  title        = {ABBA: Index structure for sequential pattern-based aggregate queries},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Elevating human-machine collaboration in NLP for enhanced content creation and decision support. <em>DKE</em>, <em>161</em>, 102505. (<a href='https://doi.org/10.1016/j.datak.2025.102505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-machine collaboration in Natural Language Processing (NLP) is revolutionizing content creation and decision support by seamlessly combining the strengths of both entities for enhanced efficiency and quality. The lack of seamless integration between human creativity and machine efficiency in NLP hinders optimal content creation and decision support. The objective of this study is to explore and promote the integration of human-machine collaboration in NLP to enhance both content creation and decision support processes. Data Acquisition for NLP requests involves defining the task and target audience, identifying relevant data sources like text documents and web data, and incorporating human expertise for data curation through validation and annotation. Machine processing techniques like tokenization, stemming/lemmatization, and removal of stop words, as well as human input for tasks like data annotation and error correction, to improve data quality and relevance for NLP applications. The combination of automated processing and human feedback leads to more precise and dependable effects. Techniques such as sentiment analysis, topic modelling, and entity recognition are utilized to excerpt valued perceptions from the data and enhance collaboration between humans and machines. These techniques help to streamline the NLP process and ensure that the system is providing accurate and relevant information to users. The analysis of NLP models in machine processing involves training the models to perform specific tasks, such as summarization, sentiment analysis, information extraction, trend identification, and creative content generation. The results show that social media leads with 90% usage, pivotal for audience engagement, while blogs at 78% highlight their depth in content creation implementation using Python software. These trained models are then used to improve decision-making processes, generate creative content, and enhance the accuracy of search results. The future scope involves leveraging advanced NLP techniques to deepen the collaboration between humans and machines for more effective content creation and decision support.},
  archive      = {J_DKE},
  author       = {Priyanka V. Deshmukh and Aniket K. Shahade},
  doi          = {10.1016/j.datak.2025.102505},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102505},
  shortjournal = {Data Knowl. Eng.},
  title        = {Elevating human-machine collaboration in NLP for enhanced content creation and decision support},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ELEVATE-ID: Extending large language models for end-to-end entity linking evaluation in indonesian. <em>DKE</em>, <em>161</em>, 102504. (<a href='https://doi.org/10.1016/j.datak.2025.102504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing tasks. However, their effectiveness in low-resource languages remains underexplored, particularly in complex tasks such as end-to-end Entity Linking (EL), which requires both mention detection and disambiguation against a knowledge base (KB). In earlier work, we introduced IndEL — the first end-to-end EL benchmark dataset for the Indonesian language — covering both a general domain (news) and a specific domain (religious text from the Indonesian translation of the Quran), and evaluated four traditional end-to-end EL systems on this dataset. In this study, we propose ELEVATE-ID, a comprehensive evaluation framework for assessing LLM performance on end-to-end EL in Indonesian. The framework evaluates LLMs under both zero-shot and fine-tuned conditions, using multilingual and Indonesian monolingual models, with Wikidata as the target KB. Our experiments include performance benchmarking, generalization analysis across domains, and systematic error analysis. Results show that GPT-4 and GPT-3.5 achieve the highest accuracy in zero-shot and fine-tuned settings, respectively. However, even fine-tuned GPT-3.5 underperforms compared to DBpedia Spotlight — the weakest of the traditional model baselines — in the general domain. Interestingly, GPT-3.5 outperforms Babelfy in the specific domain. Generalization analysis indicates that fine-tuned GPT-3.5 adapts more effectively to cross-domain and mixed-domain scenarios. Error analysis uncovers persistent challenges that hinder LLM performance: difficulties with non-complete mentions, acronym disambiguation, and full-name recognition in formal contexts. These issues point to limitations in mention boundary detection and contextual grounding. Indonesian-pretrained LLMs, Komodo and Merak, reveal core weaknesses: template leakage and entity hallucination, respectively—underscoring architectural and training limitations in low-resource end-to-end EL. 1},
  archive      = {J_DKE},
  author       = {Ria Hari Gusmita and Asep Fajar Firmansyah and Hamada M. Zahera and Axel-Cyrille Ngonga Ngomo},
  doi          = {10.1016/j.datak.2025.102504},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102504},
  shortjournal = {Data Knowl. Eng.},
  title        = {ELEVATE-ID: Extending large language models for end-to-end entity linking evaluation in indonesian},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time-aware complex question answering over temporal knowledge graph. <em>DKE</em>, <em>161</em>, 102503. (<a href='https://doi.org/10.1016/j.datak.2025.102503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph Question Answering (KGQA) is a crucial topic in Knowledge Graphs (KGs), with the objective of retrieving the corresponding facts from KGs to answer given questions. In practical applications, facts in KGs usually have time constraints, thus, question answering on Temporal Knowledge Graphs (TKGs) has attracted extensive attention. Existing Temporal Knowledge Graph Question Answering (TKGQA) methods focus on dealing with complex questions involving multiple facts, and mainly face two challenges. First, these methods only consider matching questions with facts in TKGs to identify the answer, ignoring the temporal order between different facts, which makes it challenging to solve the questions involving temporal order. Second, they usually focus on the representation of the question text while neglecting the rich semantic information within the questions, which leads to certain limitations in understanding question. To address the above challenges, this research proposes a model named Time-Aware Complex Question Answering (TA-CQA). Specifically, we extend the Temporal Knowledge Graph Embedding (TKGE) model by incorporating temporal order information into the embedding vectors, ensuring that the model can distinguish the temporal order of different facts. To enhance the semantic representation of the question, we integrate question information using attention mechanism and learnable encoder. Different from the previous TKGQA methods, we propose time relevance measurement to further enhance the accuracy of answer prediction by better capturing the correlation between question information and time information. Multiple sets of experiments on CronQuestions and TimeQuestions demonstrate our model’s superior performance across all question types. In particular, for complex questions involving multiple facts, the hit@1 values are increased by 3.2% and 3.5% respectively.},
  archive      = {J_DKE},
  author       = {Luyi Bai and Tongyue Zhang and Guangchen Feng},
  doi          = {10.1016/j.datak.2025.102503},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102503},
  shortjournal = {Data Knowl. Eng.},
  title        = {Time-aware complex question answering over temporal knowledge graph},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Conceptual modeling of user perspectives — From data warehouses to alliance-driven data ecosystems. <em>DKE</em>, <em>161</em>, 102502. (<a href='https://doi.org/10.1016/j.datak.2025.102502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity of modern information systems has highlighted the need for advanced conceptual modeling techniques that incorporate multi-perspective and view-based approaches. This paper explores the role of multi-perspective modeling and view modeling in designing distributed, heterogeneous systems while addressing diverse user requirements and ensuring semantic consistency. These methods enable the representation of multiple viewpoints, traceability, and dynamic integration across different levels of abstraction. Key advancements in schema mapping, view maintenance, and semantic metadata management are examined, illustrating how they support query optimization, data quality, and interoperability. We discuss how data management architectures, such as data ecosystems, data warehouses, and data lakes, leverage these innovations to enable flexible and sustainable data sharing. By integrating user-centric and goal-oriented modeling frameworks, the alignment of technical design with organizational and social requirements is emphasized. Future challenges include the need for enhanced reasoning capabilities and collaborative tools to manage the growing complexity of interconnected systems while maintaining adaptability and trust.},
  archive      = {J_DKE},
  author       = {Sandra Geisler and Christoph Quix and István Koren and Matthias Jarke},
  doi          = {10.1016/j.datak.2025.102502},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102502},
  shortjournal = {Data Knowl. Eng.},
  title        = {Conceptual modeling of user perspectives — From data warehouses to alliance-driven data ecosystems},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Source-free domain adaptation with complex distribution considerations for time series data. <em>DKE</em>, <em>161</em>, 102501. (<a href='https://doi.org/10.1016/j.datak.2025.102501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained model from a labeled source domain to an unlabeled target domain without accessing source domain data, thereby protecting source domain privacy. Although SFDA has recently been applied to time series data, the inherent complex distribution characteristics including temporal variability and distributional diversity of such data remain underexplored. Time series data exhibit significant dynamic variability influenced by collection environments, leading to discrepancies between sequences. Additionally, multidimensional time series data face distributional diversity across dimensions. These complex characteristics increase the learning difficulty for source models and widen the adaptation gap between the source and target domains. To address these challenges, this paper proposes a novel SFDA method for time series data, named Adaptive Latent Subdomain feature extraction and joint Prediction (ALSP). The method divides the source domain, which has a complex distribution, into multiple latent subdomains with relatively simple distributions, thereby effectively capturing the features of different subdistributions. It extracts latent domain-specific and domain-invariant features to identify subdomain-specific characteristics. Furthermore, it combines domain-specific classifiers and a domain-invariant classifier to enhance model performance through multi-classifier joint prediction. During target domain adaptation, ALSP reduces domain dependence by extracting invariant features, thereby narrowing the distributional gap between the source and target domains. Simultaneously, it leverages prior knowledge from the source domain distribution to support the hypothesis space and dynamically adapt to the target domain. Experiments on three real-world datasets demonstrate that ALSP achieves superior performance in cross-domain time series classification tasks, significantly outperforming existing methods.},
  archive      = {J_DKE},
  author       = {Jing Shang and Zunming Chen and Zhiwen Xiao and Zhihui Wu and Yifei Zhang and Jibing Wang},
  doi          = {10.1016/j.datak.2025.102501},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102501},
  shortjournal = {Data Knowl. Eng.},
  title        = {Source-free domain adaptation with complex distribution considerations for time series data},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Conceptual modeling: A large language model assistant for characterizing research contributions. <em>DKE</em>, <em>161</em>, 102497. (<a href='https://doi.org/10.1016/j.datak.2025.102497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The body of conceptual modeling research publications is vast and diverse, making it challenging for a single researcher or research group to fully comprehend the field’s overall development. Although some approaches have been proposed to help organize these research contributions, it is still unrealistic to expect human experts to manually comprehend and characterize all of this research. However, as generative AI tools based on large language models, such as ChatGPT, become increasingly sophisticated, it may be possible to replace or augment tedious, manual work with semi-automated approaches. In this research, we present a customized version of ChatGPT that is tuned to the task of characterizing conceptual modeling research. Experiments with this AI tool demonstrate that it is feasible to create a usable knowledge survey for the continually evolving body of conceptual modeling research contributions.},
  archive      = {J_DKE},
  author       = {Stephen W. Liddle and Heinrich C. Mayr and Oscar Pastor and Veda C. Storey and Bernhard Thalheim},
  doi          = {10.1016/j.datak.2025.102497},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102497},
  shortjournal = {Data Knowl. Eng.},
  title        = {Conceptual modeling: A large language model assistant for characterizing research contributions},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic time warping for classifying long-term trends in time series. <em>DKE</em>, <em>161</em>, 102495. (<a href='https://doi.org/10.1016/j.datak.2025.102495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the potential of dynamic time warping (DTW) for recognizing different segments in time series data characterized by their long-term trends and curvature. To perform classification, a set of reference data for each class is required, where each time series in the reference set represents a typical shape of that class. The classification process involves computing the DTW distance between a given time series and each reference time series, then assigning the time series to the class with the minimum distance. Experiments on both simulated and real-world time series data from two different use cases demonstrate that DTW can correctly classify the different segments. Additionally, the paper investigates whether incorrectly classified phases could indicate data security issues. Additional experiments are performed to assess the number of data points required to reliably classify a segment correctly. These experiments highlight the limitations and emphasize the importance of selecting good reference data.},
  archive      = {J_DKE},
  author       = {Anna-Christina Glock and Klaus Chmelina and Johannes Fürnkranz and Thomas Hütter},
  doi          = {10.1016/j.datak.2025.102495},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102495},
  shortjournal = {Data Knowl. Eng.},
  title        = {Dynamic time warping for classifying long-term trends in time series},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semantic-aware query answering with large language models. <em>DKE</em>, <em>161</em>, 102494. (<a href='https://doi.org/10.1016/j.datak.2025.102494'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern data-driven world, answering queries over heterogeneous and semantically inconsistent data remains a significant challenge. Modern datasets originate from diverse sources, such as relational databases, semi-structured repositories, and unstructured documents, leading to substantial variability in schemas, terminologies, and data formats. Traditional systems, constrained by rigid syntactic matching and strict data binding, struggle to capture critical semantic connections and schema ambiguities, failing to meet the growing demand among data scientists for advanced forms of flexibility and context-awareness in query answering. In parallel, the advent of Large Language Models (LLMs) has introduced new capabilities in natural language interpretation, making them highly promising for addressing such challenges. However, LLMs alone lack the systematic rigor and explainability required for robust query processing and decision-making in high-stakes domains. In this paper, we propose Soft Query Answering (Soft QA), a novel hybrid approach that integrates LLMs as an intermediate semantic layer within the query processing pipeline. Soft QA enhances query answering adaptability and flexibility by injecting semantic understanding through context-aware, schema-informed prompts, and leverages LLMs to semantically link entities, resolve ambiguities, and deliver accurate query results in complex settings. We demonstrate its practical effectiveness through real-world examples, highlighting its ability to resolve semantic mismatches and improve query outcomes without requiring extensive data cleaning or restructuring.},
  archive      = {J_DKE},
  author       = {Paolo Atzeni and Teodoro Baldazzi and Luigi Bellomarini and Eleonora Laurenza and Emanuel Sallinger},
  doi          = {10.1016/j.datak.2025.102494},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102494},
  shortjournal = {Data Knowl. Eng.},
  title        = {Semantic-aware query answering with large language models},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An integrated requirements framework for analytical and AI projects. <em>DKE</em>, <em>161</em>, 102493. (<a href='https://doi.org/10.1016/j.datak.2025.102493'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To this day, the requirements of data warehouses, user visualizations and ML projects have been tackled in an independent manner, ignoring the possible cross-requirements, collective constraints and dependencies between the outputs of the different systems that should be taken into account to ensure a successful analytical project. In this work, we take a holistic approach and propose a methodology that supports modeling and subsequent analysis while taking into account these three aspects. This methodology has several advantages, mainly that (i) it enables us to identify possible conflicts between actors on different tasks that are overlooked if the systems are treated in an isolated manner and (ii) this holistic view enables modeling multi-company systems, where the information or even the analytical results can be provided by third-parties, identifying key participants in federated environments. After presenting the required formalism to carry out this kind of analysis, we showcase it on a real-world running example of the tourism sector.},
  archive      = {J_DKE},
  author       = {Juan Trujillo and Ana Lavalle and Alejandro Reina-Reina and Jorge García-Carrasco and Alejandro Maté and Wolfgang Maaß},
  doi          = {10.1016/j.datak.2025.102493},
  journal      = {Data & Knowledge Engineering},
  month        = {1},
  pages        = {102493},
  shortjournal = {Data Knowl. Eng.},
  title        = {An integrated requirements framework for analytical and AI projects},
  volume       = {161},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="dss">DSS - 6</h2>
<ul>
<li><details>
<summary>
(2025). Decision support for integrated trade agent's procurement and sales planning under uncertainty. <em>DSS</em>, <em>198</em>, 114537. (<a href='https://doi.org/10.1016/j.dss.2025.114537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a trade agent decision optimization problem (TADOP), in which a trade agent (TA) selects a subset of retailers and suppliers to maximize its profit under uncertain demand and spot price. The TA operates between suppliers and retailers as a third-party platform and decide which subset of retailers to serve, taking into account capacity reservations with option suppliers in advance. Once demand and spot price are realized, the TA decides how much to procure from each channel to fulfill retailers' demand. The problem is formulated as a two-stage stochastic program. Due to the high complexity and large number of scenarios, we reformulate the problem as a set-partition model, where the master problem (MP) selects the combination of retailers to serve, and the subproblem (SP) identifies the optimal procurement plans, thus reducing the number of variables and constraints. To further enhance tractability, the SP is transformed into an equivalent shortest-path problem (SPP) to address issues of non-linearity and non-convexity. Experimental results demonstrate the effectiveness of the decomposition approach, providing TAs with a practical decision-making tool for procurement and sales. Furthermore, the insights gained into TAs' procurement and sales strategies across various scenarios offer valuable guidance for decision-making in uncertain supply chain environments.},
  archive      = {J_DSS},
  author       = {An Liu and Xinyu Wang and Jiafu Tang},
  doi          = {10.1016/j.dss.2025.114537},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114537},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Decision support for integrated trade agent's procurement and sales planning under uncertainty},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling hybrid firm relationships with graph neural networks for stock investment decisions. <em>DSS</em>, <em>198</em>, 114528. (<a href='https://doi.org/10.1016/j.dss.2025.114528'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The highly volatile nature of the stock market makes predicting data patterns challenging. Significant efforts have been dedicated to modeling complex stock correlations to improve stock return forecasting and support better investor decision-making. Although various predefined intrinsic associations and learned implicit graph structures have been discovered, they have limitations in fully exploring and leveraging both types of graph information. In this paper, we proposed a Hybrid Structure-aware Graph Neural Network (HSGNN) framework. Unlike models that rely solely on predefined or learned graphs, HSGNN utilizes money-flow graphs to complementarily learn implicit graph structures and applies sparse supply-chain graphs to jointly enhance stock return forecasting. Extensive experiments on real stock benchmarks demonstrate our proposed HSGNN outperforms various state-of-the-art forecasting methods, offering a robust decision-support system for financial stakeholders.},
  archive      = {J_DSS},
  author       = {Yang Du and Biao Li and Zhichen Lu and Gang Kou},
  doi          = {10.1016/j.dss.2025.114528},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114528},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Modeling hybrid firm relationships with graph neural networks for stock investment decisions},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Social capital matters: Towards comprehensive user preference for product recommendation with deep learning. <em>DSS</em>, <em>198</em>, 114527. (<a href='https://doi.org/10.1016/j.dss.2025.114527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommender systems help address data sparsity in user–product interactions by leveraging social relationships to infer user preferences. However, existing models often overlook the role of social capital that influence decision-making in social commerce. Social capital consists of structural, relational, and cognitive dimensions, all of which shape user preferences. To better understand these influences, we propose a multi-task learning framework named DeepSC that integrates social capital theory into preference modeling. Its user preference learning module extracts structural features through graph-based pre-training, learns relational features from dynamic user embeddings, and models cognitive features using a hypergraph attention network. Additionally, the dual graph-based product feature learning module enhances cognitive feature extraction by incorporating product co-interactions. DeepSC is optimized through a joint learning objective, combining point-wise and pair-wise learning with an auxiliary social link prediction task to refine user representations. Experiments on three e-commerce datasets demonstrate that DeepSC significantly outperforms the state-of-the-art recommendation models, highlighting the effectiveness of integrating social capital into social preference learning. Our research advances social recommendation by providing a social capital theory-driven approach to modeling user behavior in digital commerce.},
  archive      = {J_DSS},
  author       = {Weiyue Li and Ming Gao and Bowei Chen and Jingmin An and Yeming Gong},
  doi          = {10.1016/j.dss.2025.114527},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114527},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Social capital matters: Towards comprehensive user preference for product recommendation with deep learning},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cybersecurity risk assessment using temporal knowledge graph-based explainable decision support system. <em>DSS</em>, <em>198</em>, 114526. (<a href='https://doi.org/10.1016/j.dss.2025.114526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing cybersecurity policies is crucial for any organization to combat evolving cyber threats. The absence of a comprehensive dataset has prevented previous studies from analyzing the risk of organizations’ cybersecurity policies. Past studies have not considered temporal information in the policies. Analysis of cybersecurity policies using attention mechanism requires automated determination of optimal number of attention units which remains unaddressed. Moreover, absence of interpretation in cybersecurity studies creates a barrier to understanding policy vulnerabilities and developing targeted solutions. To address these challenges, we develop a decision support system which (i) enhances risk classification of organization’s cybersecurity policies, (ii) develops a comprehensive cybersecurity policy dataset from the websites of 190 companies, transformed into a knowledge graph to capture entity relationships among various policies, (iii) integrates temporal information into the knowledge graph by incorporating time stamps from event sequences in cyberattack information, (iv) develops Explainable Factor Analysis based Multi-Head Attention mechanism, which automates the determination of the optimal number of attention units and optimizes data allocation across attention units using factor analysis, and (v) utilizes attention heatmaps and shapley values for interpretability. Our cybersecurity policy dataset is used as a case study with four benchmark datasets for further validation. Results reveal that our model outperforms the other state-of-the-art, achieving an 87.78% F 1 score, followed by robustness checking and statistical significance testing. Finally, Shapley values are used to interpret the model’s output to identify vulnerabilities within the organizational policies, providing crucial insights enabling decision-makers to enhance their cybersecurity policies and mitigate potential threats.},
  archive      = {J_DSS},
  author       = {Subhajit Bag and Sobhan Sarkar and Indranil Bose},
  doi          = {10.1016/j.dss.2025.114526},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114526},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Enhancing cybersecurity risk assessment using temporal knowledge graph-based explainable decision support system},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A field study on the impact of the counter ad-blocking wall strategy on user engagement. <em>DSS</em>, <em>198</em>, 114525. (<a href='https://doi.org/10.1016/j.dss.2025.114525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ad-blocking tools prevent ads from being shown to web users. Their increasingly widespread usage poses an existential risk to online publishers who provide free content and rely on display ads for revenue. Studies on counter ad-blocking strategies taken by publishers are limited, especially with regard to how these strategies affect user engagement, thus posing additional uncertainties to the selection of a suitable counter ad-blocking strategy. Through a randomized field experiment with a large global publisher, our study seeks to understand how the two most common counter ad-blocking strategies, (i) Wall and (ii) Acceptable Ads Exchange (AAX), affect user engagement differently. Our results show that the Wall strategy causes a lower overall engagement compared to AAX, mainly due to users who refuse to whitelist and leave the website. Over time, the negative impact increases, albeit at a slower speed. Furthermore, heavier users, identified based on the amount of engagement in the pre-treatment period, are less affected by the Wall strategy than lighter users; instrumental users, who read for practical purposes, are less affected than entertainment users. Finally, the Wall strategy has a bigger negative impact on the engagement of popular and new articles, compared to niche and old articles, respectively, as observed by a longer tail in engagement distribution with respect to content. These results on the heterogeneous effects of counter ad-blocking strategies on engagement offer novel and important managerial implications on a publisher’s choice of counter ad-blocking strategy and editorial decisions.},
  archive      = {J_DSS},
  author       = {Michael K. Chen and Shuai Zhao and Cristian Borcea and Yi Chen},
  doi          = {10.1016/j.dss.2025.114525},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114525},
  shortjournal = {Decis. Supp. Syst.},
  title        = {A field study on the impact of the counter ad-blocking wall strategy on user engagement},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cross-platform rumor detection framework considering data privacy protection and different detection capabilities of online social platforms. <em>DSS</em>, <em>198</em>, 114524. (<a href='https://doi.org/10.1016/j.dss.2025.114524'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anonymity and widespread popularity of online social platforms (OSPs) allow users to share uncertain posts freely, leading to numerous rumors. Similar rumors spread widely across OSPs, resulting in frequent cross-platform rumors (CPRs). Owing to the unique nature of the cross-platform spread, the dual challenges of data privacy protection constraints and differences in the data and detection capabilities of OSPs exacerbate the difficulty of CPR detection. Thus, to detect CPRs effectively, we designed and implemented a novel deep learning framework named Cross Platform Rumor Detection based on Improved Federated Learning (CPRDIFL), which integrates and improves federated learning and the pre-trained Masked and Contextualized BERT (MacBERT). Our framework uses FL to analyze data from OSPs independently, thus avoiding the need for data integration and ensuring the data privacy protection of OSPs. Moreover, MacBERT is deployed on the clients of CPRDIFL to extract contextual features from posts and dynamically update local weights based on the data and detection performance. Weight parameters are dynamically shared between clients and servers and between clients to achieve complementary advantages across OSPs. Our framework was used in six comprehensive experiments in different scenarios, and the experimental results showed that it achieved the best results in CPR detection. This study not only provides an effective solution for CPR detection but also marks a significant step toward the automated detection of cross-OSP information pollution.},
  archive      = {J_DSS},
  author       = {Xuelong Chen and Jinchao Pan},
  doi          = {10.1016/j.dss.2025.114524},
  journal      = {Decision Support Systems},
  month        = {11},
  pages        = {114524},
  shortjournal = {Decis. Supp. Syst.},
  title        = {A cross-platform rumor detection framework considering data privacy protection and different detection capabilities of online social platforms},
  volume       = {198},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="eaai">EAAI - 271</h2>
<ul>
<li><details>
<summary>
(2025). A novel weight-optimized machine-learning hybrid model for daily river runoff prediction. <em>EAAI</em>, <em>162</em>, 112396. (<a href='https://doi.org/10.1016/j.engappai.2025.112396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The daily runoff process has been characterized as nonlinear and unsteady due to the impacts of watershed precipitation and evaporation, vegetation coverage rate, reservoir operations and other human activities. In recent years, machine-learning (ML) models have been widely applied in the daily runoff predictions, but the robustness and effectiveness of individual ML model is always limited. A novel weight optimization scheme has been introduced to ML models to obtain accurate predictions of daily river runoff. Variational modal decomposition method is adopted in the dataset preprocessing, and the runoff prediction performance of various classic ML models, including Genetic Algorithm-Back Propagation neural network (GA-BP), Long Short-Term Memory network (LSTM), Elman neural network (Elman) and Genetic Algorithm-Support Vector Machine (GA-SVM) are subsequently evaluated. A particle swarm optimization (PSO) based weight optimization strategy is proposed to combine different types of ML models, thus more accurate and robust results could be obtained. The ten-fold cross-validation method has been adopted and the performance of the optimized hybrid models are further evaluated for different schemes. A case study at Hankou hydrological station demonstrates that root mean square error (RMSE) and mean absolute percentage error (MAPE) is improved by 35.7 %, 75.8 % respectively for the optimized hybrid model. The present study shares useful insights to the comprehensive optimization of various ML models in the intelligent management of water resources.},
  archive      = {J_EAAI},
  author       = {Zhonglian Jiang and Jianglong Ying and Zhen Yu and Xiao Chu and Chengqiang Yu},
  doi          = {10.1016/j.engappai.2025.112396},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112396},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel weight-optimized machine-learning hybrid model for daily river runoff prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent assessment of habitat quality based on multiple machine learning fusion methods. <em>EAAI</em>, <em>162</em>, 112395. (<a href='https://doi.org/10.1016/j.engappai.2025.112395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating habitat quality can help balance the relationship between economic development and biodiversity conservation, and it serves as a foundation for constructing an ecological security pattern. However, research on the intelligent construction of habitat quality is limited. This study develops a comprehensive framework to assess habitat quality based on optimized machine learning methods. The findings of the research are as follows: (1) From the perspective of human-machine interactive interpretation, ensemble learning is used to enhance the performance of basic classifiers, resulting in a classification map with high precision and recall. (2) The particle swarm optimization (PSO) algorithm can improve the goodness of fit of the Extreme Gradient Boosting (XGBoost) inversion model by 4–5 %. (3) The habitat quality inversion method based on XGBoost-PSO has high credibility and application value, with its texture structure being the result of both expert experience and image information interaction. (4) The model demonstrates certain application potential in downscaling; under the seven-band perspective, the blue and near-infrared bands are the most important, while in the four-band perspective, green and near-infrared bands take precedence.},
  archive      = {J_EAAI},
  author       = {Kui Yang and Dongge Cui and Chengrui Wang and Qi Tang and Linguang Miao},
  doi          = {10.1016/j.engappai.2025.112395},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112395},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent assessment of habitat quality based on multiple machine learning fusion methods},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Health state estimation of retired batteries based on physical constraints. <em>EAAI</em>, <em>162</em>, 112390. (<a href='https://doi.org/10.1016/j.engappai.2025.112390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing use of retired lithium-ion batteries, accurately monitoring their health status has become increasingly important. This study proposed a method to estimate the health of retired batteries by embedding their capacity degradation characteristics directly into the loss function of a Bidirectional Long Short-Term Memory (BiLSTM) network, combined with a Physically Informed Neural Network (PINN) model. The model is developed by incorporating the dynamics of the solid electrolyte interface (SEI) membrane, which evolves as the lithium-ion poles of the retired battery move. By combining these dynamics with the governing equations of motion, a partial differential equation (PDE) is derived. This approach integrates physical constraints, data-driven learning, and PDEs into a composite loss function. The proposed method is validated on two different datasets under varying operating temperatures. The results show that the PINN-BiLSTM model achieves a Root Mean Square Percentage Error (RMSPE) of 0.024, representing a 9.67 % improvement over the PINN-LSTM. This adaptive PINN method offers highly accurate health state predictions across temperature variations, thus supporting the sustainable use of retired batteries in secondary applications and helping to mitigate energy scarcity.},
  archive      = {J_EAAI},
  author       = {Fei Xia and Qianwen Dong and Lin Xia and Zhenyi An and Ziyang Xia and Chunyang Gong},
  doi          = {10.1016/j.engappai.2025.112390},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112390},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Health state estimation of retired batteries based on physical constraints},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimisation approach guided by crack variation mechanism in the informer prediction model. <em>EAAI</em>, <em>162</em>, 112381. (<a href='https://doi.org/10.1016/j.engappai.2025.112381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring (SHM) faces a fundamental challenge in reconciling predictive performance with physical interpretability for infrastructure diagnostics. Conventional deep learning (DL) approaches neglect essential mechanisms governing crack width variation—including thermal gradients, hysteretic responses, and phase-shifted correlations—limiting their reliability in real-world applications. To bridge this gap, we propose a mechanism-guided optimization (MGO) framework that integrates domain knowledge into the Informer architecture through physics-informed enhancements: auto-correlation modeling for capturing temperature-crack hysteresis, static gated fusion for multi-feature integration, and adaptive elastic net regularization for feature selection. Validated on cable-stayed bridge monitoring data, our framework achieves significant mean absolute error reductions (MAE) (5 %–60 %) and root mean square error reductions (RMSE) (10 %–55 %) versus baseline Informer across all cracks and prediction horizons, with diebold-mariano (DM) tests confirming statistical superiority in most cases. Crucially, it demonstrates superior precision relative to six state-of-the-art benchmarks across all evaluation scenarios. The ordinary least squares (OLS)-enhanced variant further delivers volatility reduction, while sensor failure tests establish quantifiable robustness benchmarks through MAE progression from 0.013 mm to 0.391 mm. This work establishes an interpretable, physics-grounded paradigm that explicitly links environmental drivers to structural degradation.},
  archive      = {J_EAAI},
  author       = {Xujia Liu and Youliang Ding and Fei Xu and Yichao Xu and Kang Yang},
  doi          = {10.1016/j.engappai.2025.112381},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112381},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimisation approach guided by crack variation mechanism in the informer prediction model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm. <em>EAAI</em>, <em>162</em>, 112376. (<a href='https://doi.org/10.1016/j.engappai.2025.112376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, global climate warming has led to a significant increase in both the frequency and intensity of tropical cyclones (TCs). The development of TCs is often accompanied by frequent lightning activities. The risk of lightning strikes to high offshore wind turbines is substantially elevated. This study evaluates the lightning risk faced by offshore wind farms influenced by tropical cyclones. Firstly, TC paths are analyzed in both spatial and temporal dimensions by linking them with lightning data to examine the distribution of TC-related lightning, and the lightning strike characteristics of offshore wind turbines are investigated. Secondly, a Bayesian Optimization (BO)-based eXtreme Gradient Boosting (XGBoost) model for lightning risk assessment is proposed, incorporating characteristics of TC lightning and offshore wind farms as input variables. The proposed BO-XGBoost model outperforms XGBoost, Bidirectional Long Short-Term Memory (Bi-LSTM), Support Vector Machine (SVM) and Neural Network (NN), achieving a precision of 98.9 % and a recall of 98.9 % on the test set. Additionally, SHapley Additive exPlanations (SHAP) value analysis indicates that TC lightning characteristics and offshore wind farm characteristics significantly impact the model output, enhancing the accuracy of the model. The assessment outcomes provide a theoretical basis for future offshore wind farm planning and guidance for lightning protection measures in offshore wind farms.},
  archive      = {J_EAAI},
  author       = {Qibin Zhou and Kehan Chen and Xiaoyan Bian and Shangjie Chen and Gaopeng Lu},
  doi          = {10.1016/j.engappai.2025.112376},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112376},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightning risk assessment of offshore wind farms considering tropical cyclone impacts based on an improved gradient boosting algorithm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm. <em>EAAI</em>, <em>162</em>, 112368. (<a href='https://doi.org/10.1016/j.engappai.2025.112368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the convergence of mobile communication, sensing, and computational networks in sixth-generation technology, the integration of sensing and communication with unmanned aerial vehicles (UAVs) is promising. This paper focuses on the contribution of artificial intelligence in optimizing the deployment of UAV swarms for multi-objective target detection applications in sixth-generation networks. Specifically, the artificial intelligence contribution lies in the development of an improved multi-objective particle swarm optimization (IMOPSO) algorithm for solving a complex multi-objective deployment problem. The problem aims to simultaneously optimize communication rate, sensing quality, and energy consumption in the deployment of UAV swarms. To address this, the proposed IMOPSO incorporates chaotic initialization, Lévy flight mutation, dynamic mutation rate, and an elimination mechanism based on opposition-based learning. These innovations are designed to enhance the algorithm’s ability to explore the solution space effectively, overcome premature convergence to local solutions, and improve solution quality. In terms of engineering applications, the IMOPSO is applied to the deployment of UAV swarms for target detection, demonstrating its ability to enhance communication and sensing performance while reducing energy consumption in practical scenarios. Through extensive simulations, we show that the IMOPSO outperforms traditional optimization methods and other baseline algorithms, achieving superior results across all optimization objectives. Specifically, the IMOPSO achieves approximately 5% higher transmission data rate, 9% better sensing quality, and 19% lower energy consumption compared to baseline algorithms across multiple test scenarios. Furthermore, the solutions obtained are not only closer to the optimal front but also more concentrated, indicating higher-quality results.},
  archive      = {J_EAAI},
  author       = {Hongjuan Li and Haiyuan Chen and Miao Wang and Jiahui Li and Hui Kang and Yuzhuo Guan and Xu Lin},
  doi          = {10.1016/j.engappai.2025.112368},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112368},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective deployment optimization for integrated sensing and communication-enabled unmanned aerial vehicle swarm},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complete information extraction for monocular depth estimation using a dual framework. <em>EAAI</em>, <em>162</em>, 112337. (<a href='https://doi.org/10.1016/j.engappai.2025.112337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to address the problem of efficient extraction of complete multi-scale information for supervised monocular depth estimation. Most of the existing depth estimation methods are based on Convolutional Neural Network (CNN). By gradually exploring the contextual and semantic features, they have achieved good results in scene depth estimation. However, with the expansion of the receptive field, global information limited by the local induction bias is gradually suppressed, resulting in the performance cannot be further improved. Recently, Transformer-based methods have been widely used to model the global correlation between features. Nevertheless, since the Transformer networks are not spatially aware enough, they usually lose local details and have no clear mechanism for reusing features when processing images. The Transformer networks perform self-attention mechanism at each location and cannot directly obtain information from other locations for features. Therefore, we propose a novel dual framework called as Transformer-CNN, which includes the Transformer-branch and the CNN-branch for monocular depth estimation. Specifically, the Transformer-branch is able to model the global contextual information and the CNN-branch can capture local spatial relationships in images. However, simply fusing these two independent branches may result in insufficient feature aggregation. To this end, we design a Parallel Feature Interaction Module (PFIM), which contains a Self-Attention Module (SAM) and a Cross-Attention Module (CAM), so as to highlight features from the Transformer-branch and the CNN-branch respectively and extract complementary information between the two branches. Meanwhile, in order to make full use of the low-level features with low quality in the scene, we propose a Low-level Information Acquisition Module (LIAM) to capture texture-related information and preserve texture details in the CNN-branch. Finally, to address the lack of multi-scale contextual information in Vision Transformer (ViT), we introduce a Wide Area Multi-scale Decoder (WAMD), which incorporates the multi-scale feature representations into the decoder part via a Wide Area Attention (WAA). Extensive experiments on benchmark datasets collected in the outdoor and indoor environments demonstrate the competitive results of the proposed method, compared with the state-of-the-art monocular depth estimation methods.},
  archive      = {J_EAAI},
  author       = {Bin Li and Dazheng Zhou and Xianjie Gao and Mingliang Zhang},
  doi          = {10.1016/j.engappai.2025.112337},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112337},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complete information extraction for monocular depth estimation using a dual framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models. <em>EAAI</em>, <em>162</em>, 112335. (<a href='https://doi.org/10.1016/j.engappai.2025.112335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Artificial Intelligence (AI)-based weather forecasting is growing rapidly, with continuous progress in model development, techniques, and performance improvements. This paper provides a comprehensive overview of AI-based weather forecasting models, focusing on their current status, challenges, and directions for further development. A review of more than 40 models, primarily proposed after 2015, underscores the importance of critically examining various aspects of AI-based forecasting. Unlike previous reviews that targeted only a limited number of models or features, this study addresses a complete set of aspects and analyzes existing challenges from multiple perspectives. These aspects include the Machine Learning (ML) and Deep Learning (DL) methods used, datasets, predictand parameters, overfitting, and capability for forecasting extreme weather, lead time, spatiotemporal scale, performance criteria, overfitting, data assimilation, data-driven models, and the analysis of state-of-the-art (SOTA) models such as FengWu, ClimaX, Pangu-Weather, FourCastNet, GraphCast, GenCast, and Artificial Intelligence Forecasting System (AIFS) from various viewpoints. The review also discusses current challenges, including limited historical data and data quality, small-scale weather forecasting, model explainability, uncertainty, extreme weather prediction, physical constraints, temporal adaptation, and generalization, and outlines potential future directions.},
  archive      = {J_EAAI},
  author       = {Saeid Haji-Aghajany and Witold Rohm and Piotr Lipinski and Maciej Kryza},
  doi          = {10.1016/j.engappai.2025.112335},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112335},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning. <em>EAAI</em>, <em>162</em>, 112330. (<a href='https://doi.org/10.1016/j.engappai.2025.112330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The textual adversarial attack aims to fool existing models into making erroneous predictions by adding strategic perturbations to normal data without affecting the user’s understanding. Recently, methods based on Pre-trained Language Models (PLMs) and Large Language Models (LLMs) have shown promising performance in various Natural Language Processing (NLP) downstream tasks. However, due to significant deviations between the original and perturbed texts, these methods struggle to achieve satisfactory results in defending against textual adversarial attacks, especially in Chinese, which has unique syntactic structures. To address this issue, we propose a domain adaptation method for defending against Chinese textual adversarial attacks through a prompt-tuning model, which effectively mitigates the discrepancy between different domains. Specifically, the original and perturbed texts are treated as the source and target domains, respectively, with the textual adversarial defense task framed as a cross-domain classification problem. The soft prompt-tuning model trained in the source domain is iteratively adapted to uncover the true label information in the target domain. The graph attention network is incorporated to integrate Chinese syntactic structure information with semantic features. Through a voting mechanism on predicted labels generated by the iterative model, soft prompt-tuning is further optimized for cross-domain classification tasks. Extensive experimental results demonstrate the superior effectiveness of our method in Chinese textual adversarial defense tasks compared to baseline methods, including the state-of-the-art fine-tuning approaches for PLMs and LLMs.},
  archive      = {J_EAAI},
  author       = {Yi Zhu and Zhenglong Li and Yun Li and Yunhao Yuan and Jipeng Qiang},
  doi          = {10.1016/j.engappai.2025.112330},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112330},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A domain adaptation method to defend chinese textual adversarial attacks via prompt-tuning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection. <em>EAAI</em>, <em>162</em>, 112321. (<a href='https://doi.org/10.1016/j.engappai.2025.112321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slow Feature Analysis (SFA) has shown considerable success in the field of industrial process fault detection. Nonetheless, due to its unsupervised nature, SFA relies solely on the normal training data and overlooks the incorporation of prior process knowledge, which consequently diminishes its efficacy in early fault detection. To mitigate this limitation, this paper introduces the concept of Zero-Shot Learning (ZSL) and proposes an improved SFA approach, referred to as ZSL-SFA. This novel method leverages fault semantic representations as auxiliary knowledge to enhance fault detection sensitivity in industrial process monitoring. The ZSL-SFA framework implements a dual-model collaborative monitoring system: (1) a primary SFA model is developed using normal operational data to capture the dynamic characteristics of the process; and (2) a semantic encoding mechanism, grounded in expert knowledge, is devised to build the auxiliary model, where a probabilistic attribute learner adaptively extracts semantic information from fault attribute descriptions, facilitating effective fault knowledge transfer through similarity analysis. The monitoring outcomes from both the primary and auxiliary models are integrated using a Bayesian fusion strategy, culminating in a comprehensive ZSL-SFA monitoring system. The main advantage of this method is its ability to fully exploit prior process knowledge to enhance the basic SFA model without the need for additional labeled fault samples. Experimental validations on the Tennessee-Eastman process simulation platform are performed to indicate that the proposed ZSL-SFA method surpasses the basic SFA method in terms of fault detection performance.},
  archive      = {J_EAAI},
  author       = {Wenjie Yang and Xiaogang Deng and Lumeng Huang and Yuping Cao},
  doi          = {10.1016/j.engappai.2025.112321},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112321},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-shot learning augmented slow feature analysis for semantic-aware industrial process fault detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction. <em>EAAI</em>, <em>162</em>, 112318. (<a href='https://doi.org/10.1016/j.engappai.2025.112318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {T-cell receptor sequences (TCR-seq) are closely related to cancers, and in particular, cancer-related TCR-seq are crucial in cancer diagnosis and treatment. Current prediction methods for cancer-related TCR-seq often focus solely on the sequence structure, neglecting its spatial structure. Therefore, we propose a multimodal deep learning method based on parallel and residual structures (MDPR) for the detection of cancer-related TCR-seq. MDPR can effectively integrate the spatial and sequence structure of TCR-seq for accurately identifying cancer-related sequences. First, we introduce a TCR-seq encoding method based on atomic three-dimensional spatial coordinates, allowing for more effective extraction of the spatial structural features of TCR-seq. Second, we use high-dimensional word vectors instead of the amino acid feature vectors traditionally used by other researchers. Third, we pretrain the spatial feature extraction module and then conduct joint training with the sequence feature extraction module. This approach allows the model to better consider the relationship between the two modalities, thereby improving prediction accuracy. Finally, MDPR achieved an area under the curve (AUC) of 0.971 after ten rounds of three-fold cross-validation on the dataset. The AUC of MDPR is 5% higher than that of the previous best method. In short, we propose an artificial intelligence method called MDPR, and apply it to the biomedical field. MDPR can be obtained from https://github.com/biomg/MDPR .},
  archive      = {J_EAAI},
  author       = {Junjiang Liu and Shusen Zhou and Mujun Zang and Chanjuan Liu and Tong Liu and Qingjun Wang},
  doi          = {10.1016/j.engappai.2025.112318},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112318},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodality based deep learning method for cancer-related T-cell receptor sequence prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering. <em>EAAI</em>, <em>162</em>, 112317. (<a href='https://doi.org/10.1016/j.engappai.2025.112317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is a significant application for wearable devices, which primarily identifies current human activities by analyzing sequential sensor data. The real-time data recording of wearable devices enables the collection of vast amount of unlabeled data. Utilizing this data for self-supervised contrastive pre-training of HAR models presents a feasible solution to the decline in recognition performance due to limited labeled data. However, traditional contrastive learning frameworks are primarily designed based on positive and negative sample pairs in the image domain. The relatively simple sequence data of HAR is prone to generating incorrect negative pairs, thus pre-training HAR models solely in this manner is unsatisfactory. Given the phenomena described above, this paper proposes an Instance Prediction and Clustering Self-supervised Contrastive Learning Framework (IPCSC) for HAR, considering the characteristics of human activity data. IPCSC circumvents negative sample pairs, instead extracting contrastive information at the instance perspective by prediction tasks among various augmented views of samples and integrating clustering concepts for contrastive learning from a holistic perspective. The primary objective is to enable the model to discern critical information within human activity data and distinguishable features between different activities, thereby improving the model’s pre-training efficacy and enhancing its downstream activity recognition performance. Numerous experimental analyses demonstrate that IPCSC outperforms other self-supervised methods, achieving an average F1-Score performance improvement of 5.65%, 4.11%, and 7.99% over supervised baselines on the UCI-HAR, MobiAct, and MotionSense datasets, respectively, with only 1% of the labeled data.},
  archive      = {J_EAAI},
  author       = {Zhixuan Yang and Kewen Li and Zongchao Huang and Zhifeng Xu and Xinyuan Zhu and Yuan Xiao},
  doi          = {10.1016/j.engappai.2025.112317},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112317},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combined perspective self-supervised contrastive learning framework for human activity recognition integrating instance prediction and clustering},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised method for learning path-augmented knowledge graph embedding. <em>EAAI</em>, <em>162</em>, 112315. (<a href='https://doi.org/10.1016/j.engappai.2025.112315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) consist of factual triples that describe relations between entities in the real world. Knowledge graph embedding (KGE) aims to map entities and relations into constantly low-dimensional vectors, which is important for lots of downstream tasks (e.g., KG completion and information retrieval). Current KGE methods primarily rely on explicit structural patterns, neglecting latent contextual semantics behind those structures and resulting in sub-optimal performance. While some methods incorporate additional data (e.g., textual descriptions), such dependencies limit applicability due to additional data requirements. Furthermore, most KGE models suffer from limited supervision with sparse labeled triples, restricting their capacity to learn comprehensive semantic features. Inspired by the simple but effective self-supervised language model word2vec, one interesting question is: Can KGE be performed as a simple self-supervised language model ? To achieve this, we innovatively propose a self-supervised KGE framework that learns entity and relation embeddings by adapting word2vec’s skip-gram objective to path sequences extracted from KGs. Our framework employs separate embedding spaces for entities and relations with an entity-relation mapping mechanism for effective interaction between the two embedding spaces. Further, to enhance the training efficiency, we introduce a markov chain-based negative sampling strategy, which generates semantically meaningful negative samples by preserving the structural contexts along KG paths. Our framework, which is the first attempt to follow the context-based self-supervised idea of language models to conduct KGE tasks, addresses the constraints of label-dependent supervised KGE techniques and obviates the requirement for external information, while simultaneously enabling effective extraction of the implicit contextual semantics inherent in triple structures. Experiments on two widely-used KGE datasets show state-of-the-art performance, demonstrating our framework’s ability to learn semantically rich representations solely from graph structure.},
  archive      = {J_EAAI},
  author       = {Tong Shen and Fu Zhang and Jingwei Cheng},
  doi          = {10.1016/j.engappai.2025.112315},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112315},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A self-supervised method for learning path-augmented knowledge graph embedding},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion. <em>EAAI</em>, <em>162</em>, 112313. (<a href='https://doi.org/10.1016/j.engappai.2025.112313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence-based single-cell RNA sequencing (scRNA-seq) technology is widely used in cell type identification and disease research, but its data often contain a large number of missing values and zero values due to technical limitations and biological differences. These zero values not only affect downstream analysis, but also make it difficult to distinguish technical zero values from biological zero values. Therefore, this paper proposes a scRNA-seq data interpolation method (sc-MKNMF) based on non-negative matrix factorization and multi-kernel similarity network fusion for the first time. This method improves the accuracy of cell clustering by accurately filling some zero values. First, sc-MKNMF uses gene-cell dual-level analysis to distinguish technical zero values from biological zero values, and then calculates the similarity network of multi-kernel fusion of genes and cells respectively. Then, this method uses non-negative matrix factorization combined with similarity network to construct the objective function, and introduces sparse regularization terms to ensure the similarity between genes and cells and improve stability. In addition, sc-MKNMF is also equipped with an efficient optimization algorithm to promote its convergence by continuously updating the objective function. Finally, the verification and comparative experiments on 12 scRNA-seq datasets show that the sc-MKNMF method outperforms other advanced data interpolation methods. In addition, the extension of sc-MKNMF to the two tasks of cell trajectory inference and differentially expressed gene analysis showed significant improvement and excellent versatility.},
  archive      = {J_EAAI},
  author       = {Pei Liu and Cheng Chen and Hao Liu and Jin Gu and Xinya Chen and Ying Su and Zhiyuan Cheng and Xiaoyi Lv and Chen Chen},
  doi          = {10.1016/j.engappai.2025.112313},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112313},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A single-cell RNA sequencing data imputation method based on non-negative matrix factorization and multi-kernel similarity network fusion},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention. <em>EAAI</em>, <em>162</em>, 112311. (<a href='https://doi.org/10.1016/j.engappai.2025.112311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cercospora leaf spot (CLS) is a widespread disease that seriously threatens beet yield and sugar quality. Timely detection enables farmers to take early control measures and reduce economic losses. Although artificial intelligence (AI)-based methods are replacing manual inspection in agriculture, CLS detection in complex field environments remains highly challenging due to subtle early-stage symptoms and severe occlusions caused by overlapping leaves and weeds. To address these challenges, this paper presents Cercospora Leaf Spot–You Only Look Once (CLS–YOLO), an enhanced detection model built upon You Only Look Once version 11 (YOLOv11), incorporating novel modules specifically designed for accurate CLS detection under challenging field conditions. To improve the detection of weak and early-stage symptoms, we design the Multi-Scale Large Kernel Decomposition (MSLKD) module, which enhances feature extraction for subtle lesions. Furthermore, we develop the Spatial-Channel Interaction Attention (SCIA) module to mitigate detection errors arising from occlusion and fragmented disease patterns by refining multi-scale feature representations. Experimental results demonstrate CLS–YOLO achieves superior performance, reaching an mAP@0.5 of 73.6% ± 0.2% and an mAP@0.5:0.95 of 40.6% ± 0.3% over five independent runs, outperforming twelve mainstream object detection algorithms while maintaining lightweight efficiency. To validate generalization capability across scenarios, crops, and diseases, we conducted comparative experiments on two public crop disease datasets, where our method achieved superior overall performance. In summary, this study provides an effective AI-driven solution for precise crop disease detection, contributing to the practical advancement of intelligent agriculture.},
  archive      = {J_EAAI},
  author       = {Hualong Dong and Yi Lu and Yurong Qian and Xuefei Ning and Ting Chen and Ke Tang},
  doi          = {10.1016/j.engappai.2025.112311},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112311},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel object detection model for sugar beet cercospora leaf spot in field scenarios based on large kernel decomposition and spatial channel interaction attention},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ElecBench: A large language model benchmark in electric power domain. <em>EAAI</em>, <em>162</em>, 112310. (<a href='https://doi.org/10.1016/j.engappai.2025.112310'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have made substantial advancements in the field of natural language processing, necessitating the development of new benchmarks to accurately track their progress. In this paper, we introduce ElecBench, the first benchmark specifically designed for the electric power domain. ElecBench comprises 24 datasets spanning different scenarios, covering general electric power knowledge and four specific business applications, with a total of 34,030 data entries. Furthermore, we evaluate the performance of a series of open-source Chinese LLMs on ElecBench. Our experiments demonstrate that ElecBench serves as an effective benchmark for electric power scenarios and highlight that existing LLMs require further optimization to gain domain-specific knowledge and achieve better performance.},
  archive      = {J_EAAI},
  author       = {Sai Zhang and Qiaochu Huang and Qiang Zhang and Xiao Liang and Weiwei Liu and Kunlun Gao and Fei Zhou and Congcong Shi},
  doi          = {10.1016/j.engappai.2025.112310},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112310},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ElecBench: A large language model benchmark in electric power domain},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-enhanced edge-INverse attention network for skin lesion segmentation. <em>EAAI</em>, <em>162</em>, 112306. (<a href='https://doi.org/10.1016/j.engappai.2025.112306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer, particularly melanoma, is one of the most aggressive and deadly forms of cancer with its incidence rising globally. Early detection is crucial for improving survival rates, but the traditional dermatoscopy method is a highly time-consuming and subjective process. To resolve this issue, we propose a novel Feature-Enhanced Edge-INverse attention network (FEEINnet) model that helps to segment the skin lesion region more accurately. FEEINnet consists of three sub-networks: Feature Enhanced Mechanism (FEM) learns and extracts the fine-grained enhanced features from informative channels, the Edge Attention Mechanism (EAM) helps to precisely identify the edges of the lesion region and the INverse Attention Mechanism (INAM) generates inverse attention maps which emphasize the less confident or ambiguous regions thereby increasing the segmentation accuracy iteratively. These three sub-networks collectively help to improve feature extraction, enhance boundary detection, and refine segmentation maps, even in challenging scenarios with varying lesion sizes, shapes and pigmentation. FEEINnet consistently outperforms existing models, achieving a F1-score of 95.55%, 95.53%, and 94.52%; Intersection over Union (IoU) of 92.76%, 92.43%, and 91.34%; and Structural Similarity Index Measure (SSIM) of 94.63%, 93.51%, and 91.85% on the Human Against Machine 10000 (HAM10000), Pedro Hispano Hospital ( P H 2 ), and International Skin Imaging Collaboration 2018 (ISIC2018) datasets, respectively. The obtained results demonstrate that the proposed model has a greater ability to segment complex skin lesions more accurately.},
  archive      = {J_EAAI},
  author       = {Shivamm Warambhey and Aravindkumar Sekar},
  doi          = {10.1016/j.engappai.2025.112306},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112306},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-enhanced edge-INverse attention network for skin lesion segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method. <em>EAAI</em>, <em>162</em>, 112305. (<a href='https://doi.org/10.1016/j.engappai.2025.112305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault-free functioning of Heating, Ventilation, and Air Conditioning (HVAC) systems is essential for reducing energy waste in modern-day buildings. Hence, data-driven approaches for HVAC fault detection have gained popularity. Faults become more severe with time. Fault detection reveals the presence of an anomaly, but it does not convey how critical the fault severity is. Fault severity indication provides this essential context, enabling urgent resource allocation to more severe faults, adding practical significance. However, faults being rare, obtaining substantial data at different severity levels to train supervised Machine Learning models is a realistic challenge. Therefore, we propose a method for estimating fault severity in an unsupervised setting. We define a robust Severity Indicator (SI) that reflects the shift in the severity levels of a fault. First, we define a healthy domain boundary for fault-free data using One-Class Support Vector Machines. SI scores are then computed using a novel adaptive feature weighing algorithm that assigns weights to individual features, adaptively, for every fault. We focus on detecting the shift in severity, rather than quantifying it. The study of the robustness of SI for different faults in HVAC subsystems, chillers, and air handling units (AHUs) yields consistently promising results. Our comparative analysis shows that our method outperforms the unweighted approach and existing state-of-the-art techniques for fault severity estimation. Notably, our method excels in detecting low-severity faults, addressing a common limitation in current methods.},
  archive      = {J_EAAI},
  author       = {Ramnath V. Prabhu Bam and Rajesh S. Prabhu Gaonkar and Clint Pazhayidam George},
  doi          = {10.1016/j.engappai.2025.112305},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112305},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A severity indicator for unsupervised fault severity shift detection of heating, ventilation, and air conditioning sub-system faults using a novel adaptive feature weighing method},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning. <em>EAAI</em>, <em>162</em>, 112301. (<a href='https://doi.org/10.1016/j.engappai.2025.112301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failures in propulsion components, such as propellers, can critically affect flight safety; thus, early failure detection, preferably before flight, is essential. Traditional fault-diagnosis methods typically rely on additional sensors or operational data, which may not be available or practical in all situations. This study addresses these challenges by introducing motor-electric-signal-based fault diagnosis that is independent of airframe configuration and can detect faults, even when the aircraft is not in operation. However, difficulties arise owing to poor class variance in motor-electric-signal data and the challenge of obtaining fault data. To overcome these issues, a semi-supervised learning model based on a modified variational autoencoder-generative adversarial network (VAE-GAN) is proposed, which predicts faults using only normal motor-electric-signal data. Additionally, a new preprocessing method and patch-based ensemble inference technique are introduced to improve the poor class-variance characteristics of the data, thereby enhancing the prediction performance. This work demonstrates that propeller faults can be successfully diagnosed using motor-electric signals without the need for additional sensors or fault-data acquisition.},
  archive      = {J_EAAI},
  author       = {Sanga Lee and Dohyeong Kim and Minkyun Noh and Shinkyu Jeong and Jikang Kong and Youngjun Yoo},
  doi          = {10.1016/j.engappai.2025.112301},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112301},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Propeller fault-detection method for electric-propulsion aircraft using motor signals and generative model-based semi-supervised learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue. <em>EAAI</em>, <em>162</em>, 112292. (<a href='https://doi.org/10.1016/j.engappai.2025.112292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid flow shop scheduling problem (HFSP) is a prominent challenge in advanced manufacturing systems. Existing research often overlooks the impact of workers in production shops or treats worker fatigue as a static parameter, failing to capture its nonlinear accumulation and recovery effects on processing efficiency. However, with the advent of Industry 5.0, there has been a growing emphasis on the critical role of human factors in production scheduling. As a result, designing an effective algorithm for HFSP that considers human factors has become a prominent research focus. In this paper, an extended distributed heterogeneous hybrid flow shop scheduling problem with the dynamic effects of worker fatigue (DHHFSP-WF) is investigated. To address this problem, a Deep Q-Network-based multi-objective optimization algorithm (DQNMOEA) is designed to minimize makespan, total energy consumption (TEC), and total worker idle time (WIT). In DQNMOEA, a four-dimensional vector encoding scheme considering worker allocation represents solution, and a reconstruction strategy ensures initial population quality and diversity. Moreover, an improved order crossover, two-point crossover, and a segment-based recombination mutation method are proposed to enhance the global search performance of the algorithm. Then, a problem-specific local search strategy is designed for each layer of the vector, allowing the Deep Q-Network (DQN)-based adaptive decision-making mechanism to perform local perturbations on the current non-dominated solutions in the most suitable dimensions. Finally, seven algorithms are adopted to make a comparison on 36 sets of instances, the experimental results indicate that DQNMOEA exhibits competitive performance in solving DHHFSP-WF.},
  archive      = {J_EAAI},
  author       = {Jianlin Zhang and Longbin Ma and Wu Zhao and Jie Cao and Zuohan Chen and Tianpeng Xu},
  doi          = {10.1016/j.engappai.2025.112292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep Q-network-driven multi-objective evolutionary algorithm for distributed heterogeneous hybrid flow shop scheduling with worker fatigue},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate. <em>EAAI</em>, <em>162</em>, 112279. (<a href='https://doi.org/10.1016/j.engappai.2025.112279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary program diffing, or simply binary diffing, is a type of program analysis technique that quantifies the similarity between two binary programs to derive their differences. In particular, binary diffing is an essential technique for uncovering vulnerabilities and potential attack vectors in industrial control systems, where patch deployment is complicated by closed and restricted environments. Studies on binary diffing can be broadly categorized into dynamic analysis-based, static analysis-based, and neural network-based approaches. Each category of existing studies has its shortcomings, including limited coverage, low accuracy, and issues with on-demand learning. In this paper, we propose the binary diffing with sampling-and-aggregate, a hierarchical binary diffing model that generates inductive code representations based on graph sampling-and-aggregate. Our model sequentially produces instruction-level embedding, block-level embedding, and function-level embedding from the inter-procedural control flow graph of a given program, and then performs hierarchical code diffing based on these embeddings. We formally define the detailed models and present the algorithm of hierarchical binary diffing. Additionally, we conduct a thorough analysis of this algorithm, deriving several advantages. We implemented a prototype and evaluated it on a large-scale dataset in a cross-version, cross-optimization, and obfuscation settings. Our prototype showed F1-scores up to 0.96 and 0.968 in cross-version setting for function and basic block diffing, respectively. Also, our method demonstrated its robustness over several binary obfuscations. In conclusion, our proposal, which generates basic block- and function-level embedding by considering the control flow, has solid advantages on binary diffing and shows the robustness on the binary tampering.},
  archive      = {J_EAAI},
  author       = {Seungho Jeon and Kijong Koo and Daesung Moon and Jung Taek Seo},
  doi          = {10.1016/j.engappai.2025.112279},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112279},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical binary diffing with inductive code representation learning with graph sampling-and-aggregate},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network. <em>EAAI</em>, <em>162</em>, 112278. (<a href='https://doi.org/10.1016/j.engappai.2025.112278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Excavator arms are integral to the mining and construction industries, where real-time excavation load prediction is a critical element for the advancement of automated excavation technology. This study presents a novel Physics-guided Neural Network (PGNN) designed to predict the excavating force of hydraulic cylinders used in earthwork excavation. The PGNN model synergizes the physical load model of excavators with a Gated Recurrent Unit (GRU) neural network and is optimized using the Hyperband algorithm to attain both high-speed and precise forecasting. Through comparative experiments, the study validates the PGNN model's ability to achieve optimal response speed and precision in predicting excavation loads. Additionally, the predictive performance of the PGNN model is assessed via a Hardware-in-the-loop (HIL) test, conducted within the context of an actual excavation experiment. This research introduces a promising approach that seamlessly integrates physics-based modeling with machine learning techniques, facilitating real-time load forecasting for excavators. The findings pave the way for more efficient and precise excavation processes, with implications for the broader fields of mining and construction automation.},
  archive      = {J_EAAI},
  author       = {Jinshi Chen and Yue Yu and Dongyang Huo and Han Zhang and Jingyan Wang},
  doi          = {10.1016/j.engappai.2025.112278},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112278},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear excavation load prediction of hydraulic excavator based on gated recurrent unit neural network},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plug-and-play fine grained neural cognitive diagnosis framework. <em>EAAI</em>, <em>162</em>, 112276. (<a href='https://doi.org/10.1016/j.engappai.2025.112276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive diagnosis (CD) is a core task in intelligent education, which accurately assesses students’ mastery of specific knowledge concepts (KCs) by analyzing their answer records. However, existing methods mainly rely on explicit interaction data and use diagnostic models for automatic knowledge proficiency inference. These methods lack systematic optimization for fine-grained knowledge level representation, making it difficult to fully reflect students’ true learning status. To address this, this paper introduces a Plug-and-Play F ine Grained N eural C ognitive D iagnosis Framework (FNCD) with Knowledge-Level Constraint Awareness . The framework combines a knowledge proficiency evaluation module with students’ answer records and a Q-matrix to statically assess knowledge mastery. It uses a student similarity construction method based on random grouping to reveal latent learning pattern associations. Additionally, it employs a multi-scale relational learning strategy and a Top-k attention-enhanced graph network mechanism to dynamically adjust the student similarity relationship network, accurately modeling the complex learning relationships between students. Ultimately, a joint training mechanism is used to optimize the outputs of each module, significantly improving the rationality, interpretability, and accuracy of CD. The experimental results demonstrate that FNCD, as an artificial intelligence-driven plug-and-play module, can be effectively integrated into existing CD models to enhance the modeling of fine-grained knowledge mastery and improve diagnostic accuracy, showcasing the application potential of artificial intelligence in personalized education.},
  archive      = {J_EAAI},
  author       = {Xinjie Sun and Qi Liu and Kai Zhang and Weiyin Gong and Shuanghong Shen and Fei Wang and Yan Zhuang and Meikai Bao and Shijin Wang and Yuling Ma and Enhong Chen},
  doi          = {10.1016/j.engappai.2025.112276},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112276},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Plug-and-play fine grained neural cognitive diagnosis framework},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight citrus detection and counting method based on deep learning model. <em>EAAI</em>, <em>162</em>, 112268. (<a href='https://doi.org/10.1016/j.engappai.2025.112268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picking robots have become an important development direction of smart agriculture, and the accurate detection, counting and lightweight deployment of fruits are the technical basis for realizing robot picking. However, due to complex weather conditions and the possible mutual occlusion between branches and citrus, it is challenging to accurately detect and count citrus in orchards. This study proposes a lightweight small target detection model for detecting and counting citrus, and deploys it on the citrus detection platform. The model first introduces FasterNet Block into the cross-stage partial feature fusion module of the backbone network to reduce the number of parameters and calculations while improving the detection accuracy of the network. Secondly, a multi-scale attention mechanism is added to the backbone network to enhance the feature extraction ability of the network. Finally, a bounding box loss function based on a dynamic non-monotonic focusing mechanism is used to increase the model convergence speed and further improve the model accuracy. Experimental results show that the model has an accuracy of 92.7%, an average precision of 91.7%, and a model size of only 5.37 megabytes. The lightweight model is applied to the citrus detection platform. Based on this application, a citrus counting method is proposed, which obtains a mean absolute error (MAE) of 0.92, a root mean square error (RMSE) of 1.28, a determination coefficient ( R 2 ) of 0.98, and a frame rate of 80.6 per second, which meets the requirements of real-time citrus detection and counting. This provides technical support for the subsequent deployment and counting research of picking robots.},
  archive      = {J_EAAI},
  author       = {Jiqing Chen and Mingchang Zhang and Bin Lu and Quan Chen and Zhiwu Jiang and Peilin Li and Jingyao Gai},
  doi          = {10.1016/j.engappai.2025.112268},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112268},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight citrus detection and counting method based on deep learning model},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes. <em>EAAI</em>, <em>162</em>, 112245. (<a href='https://doi.org/10.1016/j.engappai.2025.112245'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate seismic risk assessment of railway embankments is critical for risk mitigation, seismic design, and emergency planning. However, conventional methods often suffer from computational inefficiency and complexity. This study proposes a novel machine learning (ML) framework to rapidly and accurately evaluate probabilistic seismic demand and risk for railway embankments. Latin hypercube sampling is utilised to generate representative soil parameter samples to construct numerical models for simulating dynamic responses under near-fault pulse-like ground motions. The peak permanent settlement (PPS) of the embankment surface is used as the key performance metric. Multiple ML models, including decision trees, random forests (RFs), extreme gradient boosting (XGBoost), artificial neural networks (ANNs), and a stacked ML model that integrates RFs, XGBoost, and ANNs, are trained and compared. The stacked ML model outperforms the other models and achieves the highest predictive accuracy for the PPS. SHapley Additive exPlanations are used to identify the velocity spectrum intensity (VSI) and the internal friction angle of the embankment as the most influential factors. Seismic fragility and risk curves are subsequently developed. The VSI and a power-law seismic hazard function are combined to estimate the annual exceedance probabilities for three seismic design criteria levels. The proposed ML framework significantly enhances the efficiency of seismic risk analysis while maintaining high precision, thereby providing a transformative approach for the seismic assessment of railway embankments.},
  archive      = {J_EAAI},
  author       = {Pan Si and Liang Tang and Shuang Tian and Xianzhang Ling and Yanfang Liu},
  doi          = {10.1016/j.engappai.2025.112245},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112245},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stacked machine learning-based probabilistic seismic demand and risk assessment of railway embankments with variable slopes},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events. <em>EAAI</em>, <em>162</em>, 112236. (<a href='https://doi.org/10.1016/j.engappai.2025.112236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic Principal Component Analysis (PPCA) is widely used in process monitoring. However, its underlying assumption that data follows a Gaussian distribution limits its effectiveness in handling Low Probability Events (LPEs), which often deviate from this assumption. To address this challenge, we propose a novel method called Sparse Filtering-based Improved Mixed-Gaussian Probabilistic Principal Component Analysis (SFIMPPCA) for enhanced LPEs detection. First, a Sparse Filtering (SF) preprocessing technique with an incremental structure is employed to extract the most discriminative features. Second, to address the distortion caused by LPEs, a dynamic ratio correction mechanism based on statistical variability is introduced, followed by a newly designed Mixed-Gaussian Probabilistic Principal Component Analysis (MPPCA). Third, a Bayesian Optimization Algorithm (BOA) is applied to automatically adjust control limits, enhancing the accuracy and reliability of fault detection. The effectiveness of the proposed method is validated using the Tennessee Eastman (TE) process and the Tin Chemical Process (TCP). Experimental results demonstrate that the proposed method significantly improves performance under LPEs conditions, achieving a 10%–12% improvement in most cases.},
  archive      = {J_EAAI},
  author       = {Chuangyan Yang and Jiande Wu and Peng Li and Xun Lang and Mingxi Ai and Hancheng Wang},
  doi          = {10.1016/j.engappai.2025.112236},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112236},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive chemical industrial processes fault detection model based on sparse filtering-based improved mixed-gaussian probabilistic principal component analysis considering low-probability events},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation. <em>EAAI</em>, <em>162</em>, 112219. (<a href='https://doi.org/10.1016/j.engappai.2025.112219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain gaps can often cause dramatic performance deterioration when applying medical image segmentation models trained on the source domain to the target domain. Although unsupervised domain adaptation methods can address the domain gap challenge to some extent, their reliance on accessing source images largely hampers their practical applicability, as source data are often inaccessible due to privacy concerns. Moreover, the low-quality characteristic of medical images can further degrade the domain adaptation performance of segmentation models. To address these issues, we propose the Masked-AutoEncoder-guided Diffusion (MAE-Diff) framework for source-free domain adaptive medical image segmentation. MAE-Diff mainly consists of a Masked AutoEncoder (MAE) Module for effective feature extraction and domain adaptation, and a Diffusion Module for effective segmentation of low-quality medical images. On source images, the MAE encoder is trained to extract image-specific features, and the Diffusion Module is trained to generate segmentation maps following a gradual denoising strategy, under the guidance of features extracted by the MAE encoder. Training on the target domain involves only fine-tuning MAE (trained on the source images) with target images, allowing MAE-Diff to adapt to the target domain distribution. Inference on target images can then be made by the source-based Diffusion Module, under the guidance of features extracted by the MAE encoder fine-tuned on the target images. Extensive experiments on three datasets demonstrate the effectiveness of the proposed framework for source-free domain-adaptive medical image segmentation. The code of MAE-Diff is available at https://github.com/xuss804/MAEDiff .},
  archive      = {J_EAAI},
  author       = {Shanshan Xu and Le Xu and Yeqing Yang and Lixia Tian},
  doi          = {10.1016/j.engappai.2025.112219},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112219},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MAE-diff: Masked-AutoEncoder-guided diffusion framework for source-free domain adaptive medical image segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule. <em>EAAI</em>, <em>162</em>, 112199. (<a href='https://doi.org/10.1016/j.engappai.2025.112199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first-order Takagi–Sugeno–Kang (TSK) fuzzy classifiers are famous for their high computational efficiency and strong interpretability, but they often struggle to learn from complex and large-scale datasets, and perform not very well compared to higher-order TSK fuzzy classifiers. To address this issue, in this paper we propose a novel Dynamic-Static Siamese TSK Fuzzy classifier with Inductive-Reflection Deep Fuzzy rule. It aims to enhance the model’s self-learning capabilities by utilizing Siamese network to integrate deep fuzzy knowledge and fine-grained knowledge without the need for a teacher model. The innovations of this study are as follows: (1) The deep fuzzy rules in the proposed classifier are enriched with an “Inductive-Reflection” process, which reduces constraints on traditional basic fuzzy rule and aligns rule acquisition more closely with general human thinking manners; (2) The proposed method includes a mechanism for self-learning and improvement from both deep and fine-grained fuzzy knowledge, eliminating the complexity of retraining a new teacher model; (3) An adaptive learning function is developed to effectively adjust the learning process, adapting to tasks with different complexities. Extensive experiments results on benchmark datasets, as well as two real-world datasets, demonstrate the effectiveness of the proposed classifier in terms of classification accuracy and weighted F1-score.},
  archive      = {J_EAAI},
  author       = {Xiongtao Zhang and Qihuan Shi and Yunliang Jiang and Qing Shen and Jungang Lou and Ruiqin Wang},
  doi          = {10.1016/j.engappai.2025.112199},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112199},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic-static siamese Takagi–Sugeno-kang fuzzy system with inductive-reflection deep fuzzy rule},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology. <em>EAAI</em>, <em>162</em>, 112113. (<a href='https://doi.org/10.1016/j.engappai.2025.112113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is a network of interconnected devices that collect, monitor, analyze, and exchange data. This technology plays a crucial role in the smart city infrastructure by seamlessly interconnecting various nodes. The extensive application and recognition of IoT across multiple city domains, such as healthcare, transportation, energy, education, and agriculture, bring significant challenges, with security among the most pressing. Traditional hardware technologies like Complementary Metal Oxide Semiconductor (CMOS) and Very Large Scale Integration (VLSI) suffer from limitations such as high power consumption and insufficient scalability, which hinder secure and sustainable IoT deployment. Such limitations have prompted the need to seek other technologies that would serve the dual purpose of providing security as well as energy. Quantum-based technologies can become adequate candidates offering promising solutions to make IoT devices and sustainable systems more secured. Quantum-dot Cellular Automata (QCA) has been proposed as a nanotechnology with the potential of consuming ultra-low powers, less area, and high-speed operation. QCA enhances security through sustainable computing objectives by minimizing energy usage. To improve the future security and efficiency of IoT hardware, this paper suggests a QCA-based Arithmetic Logic Unit (ALU). This ALU can generate more than 12 logical and arithmetic operations. Designed together with the majority gates, XOR gates, multiplexers, and full adders, the ALU is simulated using the QCA-Designer 2.0.3. Simulated results indicate improvements in the number of cells and reduced occupied area relative to the earlier designs. These results indicate the potential of QCA technology in enabling secure, energy-efficient, and compact computing architecture applicable in the future IoT.},
  archive      = {J_EAAI},
  author       = {Maryam Zaker and Seyed Sajad Ahmadpour and Nima Jafari Navimipour and Muhammad Zohaib and Neeraj Kumar Misra and Sankit Kassa and Ahmad Habibizad Navin and Arash Heidari and Mehdi Hosseinzadeh and Omar I. Alsaleh},
  doi          = {10.1016/j.engappai.2025.112113},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112113},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new design of arithmetic and logic unit for enhancing the security of future internet of things devices using quantum-dot technology},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GhostPointNet: A deep learning-based method for ghost point noise detection in four-dimensional (4D) millimeter-wave radar point clouds of underground mine. <em>EAAI</em>, <em>161</em>, 112380. (<a href='https://doi.org/10.1016/j.engappai.2025.112380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high dust concentration, multi-metal supports, and narrow winding tunnels in underground mines collectively lead to frequent ghost point noise in four-dimensional (4D) millimeter-wave radar point clouds, posing serious challenges for mining perception and localization. To address this, we propose a deep learning algorithm, named GhostPointNet, for 4D millimeter-wave radar ghost point detection in underground mining environments. From an artificial intelligence perspective, this model thoroughly considers the multi-modal features of 4D millimeter-wave radar and the environmental complexity of underground mines. It incorporates multi-parameterized spatial information inputs in both Cartesian and Spherical coordinates, coupled with “Double T-Net” adaptive alignment correction, while integrating non-spatial information such as radar power and Doppler data to achieve multi-modal representation and end-to-end discrimination between ghost points and real points. Experimental validation shows that GhostPointNet achieves excellent performance in underground mining scenarios with 92.45 % accuracy and 95.84 % F1-score, outperforming traditional filtering, clustering, and machine learning algorithms. From an engineering application perspective, GhostPointNet is specifically designed for ghost noise detection in underground mines. Even in complex scenarios such as mine tunnel intersections and turns, it preserves critical structural points. Its end-to-end neural network simplifies post-processing procedures, enhances operational efficiency, and provides stable and reliable perceptual support for subsequent tasks such as autonomous mine locomotive navigation and three-dimensional (3D) structure reconstruction. Experimental results demonstrate that this method surpasses baseline approaches in ghost point detection, real point preservation, and generalization capability, providing significant support for improving underground mining safety and efficiency.},
  archive      = {J_EAAI},
  author       = {Hu Liu and Zhenghua Zhang and Jing Yang and Jörg Benndorf and Xiaofei Wang and Jiaqi Dong and Zitao Lin and Guoliang Chen},
  doi          = {10.1016/j.engappai.2025.112380},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112380},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GhostPointNet: A deep learning-based method for ghost point noise detection in four-dimensional (4D) millimeter-wave radar point clouds of underground mine},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid ensemble learning for predicting peak deviatoric stress in soil-rock mixtures from triaxial test data. <em>EAAI</em>, <em>161</em>, 112377. (<a href='https://doi.org/10.1016/j.engappai.2025.112377'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peak deviatoric stress ( q f ) is an important mechanical property index of soil-rock mixtures (SRM). However, determining it through experiments is a challenging and time-consuming task. This study presents a weighted averaging ensemble model for predicting the q f of SRM. 585 sets of consolidated drained triaxial test data for SRM were collected to construct the proposed models. Firstly, taking the extreme gradient boosting (XGBoost) as an example, the accuracy of the models established with different input parameter combinations was tested to determine the optimal inputs. Then, five artificial intelligence models were used to train the dataset, and the Bayesian optimization method was adopted for hyperparameter adjustment. Based on the prediction results, two base models (i.e. XGBoost and random forest (RF)) with good performance were selected from these five models, and a novel weighted averaging ensemble model was developed to predict the q f of SRM. The coefficient of determination (R 2 ), root mean squared error (RMSE) and mean absolute error (MAE) values of the ensemble model were 0.990, 220.0 kPa (kPa) and 118.4 kPa, respectively, for all datasets, indicating that this model has great potential in predicting the q f of SRM. In addition, the robustness, parameter patterns and the SHapley Additive exPlanations (SHAP) analysis of the ensemble model were also conducted in this study. The results of this study can be applied to rapid analysis of mechanical parameters for SRM in engineering, and are of great significance for geotechnical engineering design and disaster prevention.},
  archive      = {J_EAAI},
  author       = {Ruiliang Zhang and Xinhua Xue},
  doi          = {10.1016/j.engappai.2025.112377},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112377},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid ensemble learning for predicting peak deviatoric stress in soil-rock mixtures from triaxial test data},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph attention neural network for advancing medical imaging by enhancing segmentation and classification. <em>EAAI</em>, <em>161</em>, 112372. (<a href='https://doi.org/10.1016/j.engappai.2025.112372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor classification and segmentation using Magnetic Resonance Imaging (MRI) scans remain challenging due to limited spatial relationships and the inability of conventional models, such as Convolutional Neural Networks (CNNs), to effectively capture structural dependencies. To address these limitations, this study introduces GANN-Med (Graph Attention Neural Network for Medical Imaging), a novel framework designed to improve the accuracy and reliability of brain tumor detection, segmentation, and classification. The framework utilizes the publicly available Brain Tumor MRI dataset and applies preprocessing followed by wavelet transform to extract both spatial and frequency features, generating wavelet-based node embeddings that represent fine textures and overall tumor structure. These features are modeled as a graph and processed through a U-Net (U-shaped Convolutional Network) architecture integrated with Graph Attention Networks (GATs), enabling adaptive attention to be directed to critical tumor regions. The segmented tumor regions are then classified using GraphSAGE (Graph Sample and Aggregation) with a pooling aggregator, which supports inductive neighborhood learning while preserving topological consistency. Unlike existing models such as mResU-Net (Modified Residual U-Net) and LG-GNN (Local-Global Graph Neural Network), GANN-Med uniquely combines wavelet-based multi-resolution graph embeddings with attention mechanisms in a unified architecture. Experimental results demonstrate a significant performance boost, including an 18.47 % increase in Dice Similarity Coefficient (DSC), notable improvements in Jaccard Index and sensitivity, a 21.04 % reduction in false positives, and an overall classification accuracy of 93.2 %, with a balanced accuracy of 91.8 % across glioma, meningioma, pituitary, and no tumor classes. Additionally, the model achieves minimal training and validation losses of 43.2 % and 41.6 %, respectively, highlighting its potential to minimize misdiagnosis and contribute to more accurate, early-stage clinical decision-making in neuro-oncology.},
  archive      = {J_EAAI},
  author       = {Meshari D. Alanazi and Khaled Kaaniche and Mohammed Albekairi and Turki M. Alanazi and Munid Alanazi and Ghulam Abbas},
  doi          = {10.1016/j.engappai.2025.112372},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112372},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph attention neural network for advancing medical imaging by enhancing segmentation and classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy scheduling in distributed heterogeneous printed circuit board assembly lines: Feedback assisted neighborhood-based search coupling with rapid evaluations. <em>EAAI</em>, <em>161</em>, 112353. (<a href='https://doi.org/10.1016/j.engappai.2025.112353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Printed Circuit Board (PCB) production involves multiple heterogeneous and highly automated assembly lines running concurrently. These assembly lines involve complex processes with uncertain and fuzzy production times, presenting significant challenges for scheduling. Moreover, PCB production is notably affected by carryover sequence-dependent setup times (CSDST) and the need for product grouping, further complicating the scheduling process. To address these challenges, this paper formulates the scheduling problem as a fuzzy distributed heterogeneous flowshop group scheduling problem with carryover sequence-dependent setup times (FDHFGSP/CSDST). A novel and effective feedback-assisted population-based neighborhood search (FPBNS) algorithm, coupling with rapid evaluation of neighboring solutions, is proposed to solve this problem. The feedback strategy operates on two main levels: evaluating population quality and adjusting the search process. Additionally, an integrated heuristic method is employed to generate a high-quality and diverse initial population. To further enhance solution quality, a collaborative operation is designed to improve interaction between solutions. This comprehensive algorithm significantly enhances its adaptability in PCB manufacturing, providing an efficient solution to the complex scheduling challenges of real-world production environments. Comprehensive and systematic experiments were conducted to evaluate the effectiveness of the proposed algorithm and related methods, demonstrating its superior performance in solving the complex scheduling problem in PCB manufacturing.},
  archive      = {J_EAAI},
  author       = {Zhen-duo Han and Biao Zhang and Chao Lu and Lei-lei Meng and Wen-qiang Zou},
  doi          = {10.1016/j.engappai.2025.112353},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112353},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy scheduling in distributed heterogeneous printed circuit board assembly lines: Feedback assisted neighborhood-based search coupling with rapid evaluations},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A high-precision acupoint recognition and localization model for acupuncture robot end-effectors. <em>EAAI</em>, <em>161</em>, 112348. (<a href='https://doi.org/10.1016/j.engappai.2025.112348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate acupoint recognition is fundamental to therapeutic efficacy of acupuncture robots, presenting a crucial challenge in medical robotics: high-precision, real-time localization of sparse features on deformable skin surfaces. To address this, we propose the Acupoint Recognition Network (ACU-Net) for reliable acupoint identification to guide robotic acupuncture. From an artificial intelligence (AI) perspective, the core contribution of ACU-Net lies in its novel modules. The Convolutional Dilatation with Residual and Split (CDRS) module uses dilated convolution to expand the receptive field and overcomes the sparsity of acupoint features by capturing both anatomical contexts and subtle local gradients. The Cross-Scale Feature Fusion (CSFF) architecture integrates spatial and semantic information more effectively than standard Feature Pyramid Network (FPN). Formulated as a keypoint regression task, the network is jointly optimized using a weighted Object Keypoint Similarity (OKS)-based loss function. Evaluated on a physician-annotated, large-scale chest acupoint dataset, ACU-Net has achieved a mean Average Precision (AP 50-95 (B)) of 94.1 % for acupoint bounding boxes and 99.5 % for acupoint points (AP 50-95 (P)), outperforming mainstream Convolutional Neural Networks (CNNs) and Transformer models. Its average prediction error (0.282 cm) on volunteers represents a 30.9 % reduction compared to the second-best model of Real-Time Multi-person Pose Estimation (RTMPose). Robustness test on an independent forearm dataset confirmed its precision. Attention visualization showed strong focus on acupoint regions. Testing on chest acupoint under adverse imaging conditions of low illumination and information loss demonstrated its reliability with zero missed detection. This work significantly advances the development of acupuncture robotics for intelligent diagnosis and treatment.},
  archive      = {J_EAAI},
  author       = {Ailing Tan and Hao Mu and Wei Ma and Yu'e Lv and Haoyu Wang and Yong Zhao},
  doi          = {10.1016/j.engappai.2025.112348},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112348},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A high-precision acupoint recognition and localization model for acupuncture robot end-effectors},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Eviformer: An uncertainty fault diagnosis framework guided by evidential deep learning. <em>EAAI</em>, <em>161</em>, 112328. (<a href='https://doi.org/10.1016/j.engappai.2025.112328'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unpredictable signals are commonly encountered during equipment operation, and existing deep learning-based fault diagnosis methods often fail to accurately evaluate the uncertainty of diagnostic results, limiting the model's capacity to respond to unexpected signals. To address this challenge, this study introduces a modified Transformer model based on deep evidential learning—Eviformer. The proposed model first employs a Swin-Transformer (ST)-based distribution projector, which preserves the advantages of ST in extracting features from vibration signals and simultaneously projects these signals directly into a Dirichlet distribution with second-order probabilities. Furthermore, by incorporating novel evidence correction terms and a constraint factor to reconstruct the evidence constraint loss, more precise uncertainty quantification in diagnostic predictions is achieved. Using a gear-bearing vibration dataset, comparative experiments were conducted across various scenarios, including out-of-distribution gear faults, faults in unmonitored components, noise interference, and variable speed conditions. The results demonstrate that the proposed method can promptly issue uncertainty-based warnings when encountering vibration signals that significantly differ from the training set distribution, thereby offering essential support for maintenance decisions.},
  archive      = {J_EAAI},
  author       = {Jingjie Luo and Fucai Li and Xiaolei Xu and Wenqiang Zhao and Dongqing Zhang},
  doi          = {10.1016/j.engappai.2025.112328},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112328},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Eviformer: An uncertainty fault diagnosis framework guided by evidential deep learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale spatiotemporal feature fusion for super-resolution video reconstruction in dynamic scenes. <em>EAAI</em>, <em>161</em>, 112327. (<a href='https://doi.org/10.1016/j.engappai.2025.112327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-quality geospatial video reconstruction is vital for applications such as urban surveillance and disaster assessment. However, existing methods often suffer from motion blur and visual artifacts due to hardware limitations and dynamic environments with rapid motion, frequent background changes, and lighting variations. To address these challenges, we propose a novel video super-resolution method called Multi-Scale Spatiotemporal Feature Fusion for Video Super-Resolution. This approach leverages artificial intelligence techniques to extract rich spatiotemporal features using a multi-scale deformable convolutional pyramid with parallel branches. It integrates contextual residual learning and optical flow estimation to capture spatial details and compensate for missing temporal information. A hybrid spatiotemporal attention mechanism adaptively fuses key features across frames through dynamic weighting, suppressing background interference and enhancing target-region representation. The framework includes an explicit motion compensation module for precise frame alignment, followed by upsampling to generate high-resolution frames with improved perceptual quality. A multi-task joint loss function optimizes structural fidelity, motion consistency, and visual realism. Experimental results on the University of Alberta Detection and Tracking dataset and Video for Super-Resolution benchmark show the method achieves a peak signal-to-noise ratio of 30.62 dB and a structural similarity index of 0.92, surpassing state-of-the-art methods by up to 4.28 dB and improving perceptual metrics such as Learned Perceptual Image Patch Similarity and Flip Loss in Perception. Ablation studies confirm each module's contribution. The model runs efficiently at 24.8 ms per frame, demonstrating potential for real-time applications. This approach offers a robust and efficient solution for high-resolution geospatial video reconstruction.},
  archive      = {J_EAAI},
  author       = {mengqin Yang and yanhui Wang and yang Yang and chunhua Peng},
  doi          = {10.1016/j.engappai.2025.112327},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112327},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale spatiotemporal feature fusion for super-resolution video reconstruction in dynamic scenes},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable framework based on integrated sensor fusion and deep learning to estimate stability in high-speed micromilling of thin-walled titanium alloy. <em>EAAI</em>, <em>161</em>, 112326. (<a href='https://doi.org/10.1016/j.engappai.2025.112326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel deep learning (DL) framework based on multi-sensor fusion based on vibration and audio signals with transfer learning has been developed and validated for chatter onset prediction in micromilling of thin-walled titanium (TC4) alloys. The DL framework has been trained and validated with individual sensor data, labelled using machined surface micrographs and cutting tool condition. A total of 879,840 spectrograms has been generated for training via signal segmentation and augmentation methods that yielded a validation accuracy of 89 % during training phase. The trained DL model has been tested on the unlabelled fused signal data to make the DL model adapt to the unseen patterns in the signals recorded during real-time machining. The proposed DL framework based on fused signals outperformed individual sensor-based detection methods by demonstrating an increment of 33 % in accuracy, with a mean absolute error of 0.027416 and R 2 of 0.987. Ablation studies confirm that fusing signals enhances the DL model's performance, yielding a 21 % and 29 % improvement in precision and recall, respectively. The optimal fusion strategy reduced chatter misclassification, with one instance of misclassification. The proposed framework presents a robust, explainable DL approach that can be readily used for adaptive control of cutting conditions in different manufacturing processes. The industry readiness of the DL model has been demonstrated by testing the pretrained model on turning process. The DL model shows 95.31 % prediction accuracy with only three misclassifications out of sixty-four test conditions.},
  archive      = {J_EAAI},
  author       = {Sethurao Gururaja and Kundan K. Singh},
  doi          = {10.1016/j.engappai.2025.112326},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112326},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable framework based on integrated sensor fusion and deep learning to estimate stability in high-speed micromilling of thin-walled titanium alloy},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Liquid metal microfluidic cooling system for high-efficiency thermal management via learning-based genetic algorithm. <em>EAAI</em>, <em>161</em>, 112324. (<a href='https://doi.org/10.1016/j.engappai.2025.112324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High heat flux density is a critical factor that limits the performance and reliability of miniaturized, high-power microelectronic systems. This study proposes a liquid metal (LM)-based microfluidic cooling system optimized through a data-driven computational framework based on an enhanced Genetic Algorithm (LC-GA), aiming to deliver an efficient thermal management solution for high-density integrated systems. By integrating LM near-junction cooling with microchannel heat dissipation in a silicon substrate, we developed a heterogeneous three-dimensional interconnect cooling architecture capable of optimizing thermal performance through algorithm-guided parameter tuning. To validate the proposed method, four distinct microchannel configurations were designed, fabricated, and experimentally tested. LM was introduced into the channels to conduct both experimental cooling tests and thermal performance simulations on a simulated heat source. The results demonstrate that this LM-based microfluidic cooling system, optimized through computational parameter determination, can effectively dissipate heat from chips with power consumption up to 800 W while maintaining stable thermal performance. Additionally, a response surface methodology combined with enhanced LC-GA was utilized for multi-factor sensitivity analysis and multi-objective optimization, enabling automatic determination of optimal design and operating parameters to balance thermal resistance and pressure drop. The optimized configuration reduced the maximum chip temperature to approximately 357.54 K, lowered the system pressure requirement, and improved the Performance Evaluation Criterion (PEC) to 2.327. This work provides a data-driven optimization approach that supports the development of high-performance integrated microsystems through algorithm-assisted thermal design.},
  archive      = {J_EAAI},
  author       = {Yucheng Wang and Antong Bi and Kaiyu Chen and Shenxin Yu and Wanping Gao and Wenyi Zhang and Yuwan Wu and Zhiqiang Li and Shaoxi Wang},
  doi          = {10.1016/j.engappai.2025.112324},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112324},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Liquid metal microfluidic cooling system for high-efficiency thermal management via learning-based genetic algorithm},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HoloFluoNet: Live cell imaging intelligence based on fused holography and fluorescence for virtual staining, cell segmentation, classification, and viability analysis. <em>EAAI</em>, <em>161</em>, 112323. (<a href='https://doi.org/10.1016/j.engappai.2025.112323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluorescence microscopy enables detailed visualization of subcellular structures but is limited by phototoxicity, photobleaching, and labor-intensive labeling. In contrast, digital holographic microscopy (DHM) offers label-free, quantitative phase imaging but lacks biochemical specificity. To integrate the strengths of both modalities, we propose HoloFluoNet, a deep learning-based framework that generates virtual fluorescence information from phase images acquired by DHM. Using a dual-mode imaging system, we simultaneously captured phase and fluorescence images of live cancer cells. The fluorescence data were used to construct biologically grounded supervision signals, including nuclei masks and multi-class cell viability labels. From a single-phase image, HoloFluoNet predicts a virtual nuclei mask, a distance map for boundary refinement, and a viability mask. The architecture incorporates multi-scale feature extractor, and attention mechanisms, optimized with novel inclusion and exclusion loss functions. Post-processing using the watershed algorithm ensures accurate segmentation of overlapping cells. The final registered image provides label-free virtual staining for nuclei localization, viability assessment, and class-specific morphological profiling. HoloFluoNet achieved a Dice score of 0.8685 and an Aggregated Jaccard Index (AJI) of 0.7883, outperforming conventional deep learning models such as U-Net, Fully Convolutional Network (FCN), Pyramid Scene Parsing Network (PSPNet), and DeepLab v3+. These improvements were statistically validated using one-way analysis of variance (p < 0.01). Ablation experiments confirmed the complementary roles of architectural modules and novel loss functions, while robustness tests under noisy and low-quality conditions revealed high stability to low contrast and moderate noise. With an inference speed of 0.123 s per image, the model enables real-time cellular analysis. By bridging structural and molecular imaging, HoloFluoNet provides an efficient, label-free alternative to fluorescence microscopy, with promising applications in artificial intelligence (AI)-assisted drug screening, cancer research, and live-cell monitoring.},
  archive      = {J_EAAI},
  author       = {Seonghwan Park and Jaeseong Lee and Jaewoo Park and Inkyu Moon},
  doi          = {10.1016/j.engappai.2025.112323},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112323},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HoloFluoNet: Live cell imaging intelligence based on fused holography and fluorescence for virtual staining, cell segmentation, classification, and viability analysis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Method for ensuring quasi-maximum stability of a system with interval deviations by a robust controller parametric synthesis. <em>EAAI</em>, <em>161</em>, 112320. (<a href='https://doi.org/10.1016/j.engappai.2025.112320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that ensuring reliable stability of automatic control systems with interval and stochastic parameter deviations is critical for aviation and other critical areas. Therefore, this article proposes a method for synthesizing Proportional-Integral-Derivative controller parameters based on the coefficient approach to stability analysis (through the characteristic polynomial neighboring coefficients ratios) with an extension to interval uncertainties and the stability quasi-maximum degree integration into the multi-criteria optimization Non-Dominated Sorting Genetic Algorithm II. Scientific contribution and novelty lie in combining analytical sufficient stability conditions (including verification by Kharitonov polynomials and dominant polynomial analysis) with multi-objective optimization taking into account parameter errors and energy costs, which allows obtaining stable and economical Proportional-Integral-Derivative settings for discrete two-channel systems. The results are confirmed by numerical experiments on a helicopter turboshaft engine two-channel control system model with real on-board data. It is shown that the optimal parameter vector provides overshoot of ≈1.43 % and transient process time of ≈1.12 s and maintains stability with local changes in coefficients (±3 … 7 %) and in Monte-Carlo tests. At the same time, a comparative analysis with traditional and neural network controllers showed the proposed approach's advantage in key metrics.},
  archive      = {J_EAAI},
  author       = {Denys Baranovskyi and Serhii Vladov and Valerii Sokurenko and Oleksandr Muzychuk and Victoria Vysotska and Maryna Bulakh},
  doi          = {10.1016/j.engappai.2025.112320},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112320},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Method for ensuring quasi-maximum stability of a system with interval deviations by a robust controller parametric synthesis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust deep learning model selection with data augmentation for automatic detection of tessellated fundus images and explainable artificial intelligence based interpretation. <em>EAAI</em>, <em>161</em>, 112316. (<a href='https://doi.org/10.1016/j.engappai.2025.112316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust deep learning system for automatically classifying retinal fundus images into two classes—normal and tessellated—is presented in this study. Visual Geometry Group – 16 is used as the base model, taking advantage of transfer learning to develop an efficient framework for fundus image classification. The approach uses nine different model architectures and makes use of a dataset of 352 fundus images that was increased to 4865 samples using sophisticated data augmentation techniques. Of these, Model_8 performed the best, achieving a loss of 0.129 % and an impressive accuracy of 99.39 %. The suggested approach ensures higher performance and dependability by combining rigorous data augmentation, efficient preprocessing, and model fine-tuning techniques. Furthermore, Explainable Artificial Intelligence was used to improve the interpretability of the model and visualize important aspects such as features or imposed pathologies in fundus images more clearly. The study offers promising support to ophthalmologists by offering precise automated diagnoses for the early identification and treatment of retinal disorders.},
  archive      = {J_EAAI},
  author       = {Kachi Anvesh and Shanmugasundaram Hariharan and Bharati M. Reshmi and Qiang Xu and Joan Lu and Vinay Kukreja and Murugaperumal Krishnamoorthy},
  doi          = {10.1016/j.engappai.2025.112316},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112316},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust deep learning model selection with data augmentation for automatic detection of tessellated fundus images and explainable artificial intelligence based interpretation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Camera-invariance correlation learning and inter-domain-specific distinct representation for person re-identification. <em>EAAI</em>, <em>161</em>, 112314. (<a href='https://doi.org/10.1016/j.engappai.2025.112314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) in person re-identification (ReID) experiences performance degradation due to two primary factors: (1) the information changes across cameras among intra-domain identity samples within the source and target domains; and (2) the inter-domain gap when applied to an unexplored image domain, which makes it a challenging task. The majority of current methodologies predominantly address the inter-domain gap while overlooking the impact of the intra-domain issue. To overcome this limitation, this paper proposes an effective invariance representation ReID (IR-ReID) network that encompasses camera-invariance correlation learning (CICL) and Transformer-based, inter-domain-specific discriminative representation (IDSR), supported by curriculum learning, with the aim of concurrently addressing both of these pivotal issues. Specifically, a CICL module is designed to explore intra-domain distinct features of an individual captured by multiple cameras across the source and target domains. Secondly, an IDSR module is proposed to address the inter-domain gap issue. Thirdly, a curriculum learning-driven strategy is introduced for sample training, systematically guiding our network in learning samples progressively, ranging from easy to difficult instances. Meanwhile, a cluster-based constraint loss is presented to further optimize the clustering results. Finally, extensive experiments are conducted on three well-known datasets, which demonstrate the effectiveness and superiority of our proposed approach in comparison to the prevailing state-of-the-art methodologies.},
  archive      = {J_EAAI},
  author       = {Shangdong Zhu and Yunzhou Zhang and Peng Duan},
  doi          = {10.1016/j.engappai.2025.112314},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112314},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Camera-invariance correlation learning and inter-domain-specific distinct representation for person re-identification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applications of machine vision technology for conveyor belt deviation detection: A review and roadmap. <em>EAAI</em>, <em>161</em>, 112312. (<a href='https://doi.org/10.1016/j.engappai.2025.112312'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conveyor belt deviation is a frequent challenge in product transportation filed, and failure to promptly detect and rectify this anomaly not only significantly reduces transport efficiency but also poses a risk of serious safety accidents, leading to enormous economic losses. Traditional contact-based deviation detection technologies, with their inherent limitations of high costs and complicated maintenance, have struggled to meet the practical demands of long-distance conveyor belt inspection. In this context, non-contact machine vision technology has emerged as a prominent solution in the field of conveyor belt deviation detection, thanks to its notable advantages of a simple hardware structure and round-the-clock operational capability. Recently, with the rapid development of artificial intelligence theories, this research field has accumulated a series of effective solutions that have been proven through machine vision practical applications. This paper delves into the technical principles of the existing solutions, systematically summarizes them and objectively evaluates their strengths and weaknesses in practical applications. Based on this foundation, this paper also provides an insight on the future development trends of intelligent monitoring for conveyor belt deviation, aiming to offer valuable reference and guidance to technicians in related fields.},
  archive      = {J_EAAI},
  author       = {Jiaming Han and Ting Fang and Wensheng Liu and Chenxiao Zhang and Molin Zhu and Jibin Xu and Jie Ji and Xianhua He and Zhang Wang and Min Tang and Chong Dong and Long Ma and Xinlong Yang},
  doi          = {10.1016/j.engappai.2025.112312},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112312},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Applications of machine vision technology for conveyor belt deviation detection: A review and roadmap},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic aperture radar target recognition with limited training data based on frequency-domain-assisted dual-stream attention hierarchical deformable convolutional networks. <em>EAAI</em>, <em>161</em>, 112309. (<a href='https://doi.org/10.1016/j.engappai.2025.112309'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of synthetic aperture radar (SAR) automatic target recognition (ATR), the recognition performance of deep learning methods is often constrained by sample scarcity. To address this issue, this paper proposes a frequency-domain-assisted dual-stream attention hierarchical deformable convolutional network (DAHDF-Net). A frequency-domain-assisted dataset construction method is designed to extend the representational diversity of the sample feature space. Then, a parallel input architecture of frequency-space dual-stream features is constructed, and the adaptive dynamic fusion of frequency-domain stream features with spatial-domain stream features is realized by using a channel attention module in the frequency-domain stream. To enhance the expressiveness of the network on the basis of modulated deformation convolution, a hierarchical residual (H-residual) module is designed. Moreover, a triple hybrid loss is proposed to address the issues of high deformation, which makes classification difficult, and the fuzzy decision boundaries between categories. Experiments were conducted on the moving and stationary target acquisition and recognition (MSTAR) dataset and the FUSAR-Ship dataset. Among them, DAHDF-Net achieves recognition accuracies of 99.75 % and 97.48 % on all training sets and 10-way 25-shot under standard operating condition (SOC) of MSTAR, which demonstrated superior recognition accuracy compared to current state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Shanliang Yuan and Hongyuan Gao and Xiaoyuan Gu and Jingya Ma},
  doi          = {10.1016/j.engappai.2025.112309},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112309},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synthetic aperture radar target recognition with limited training data based on frequency-domain-assisted dual-stream attention hierarchical deformable convolutional networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale distance similarity entropy: A novel complexity measurement for gearbox fault diagnosis. <em>EAAI</em>, <em>161</em>, 112308. (<a href='https://doi.org/10.1016/j.engappai.2025.112308'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entropy-based methods have gained increasing attention in fault diagnosis due to their capability in quantifying the intrinsic complexity and dynamic behavior of time series signals. Vibration signals from gearboxes are typically nonlinear, nonstationary, and transient, often spanning multiple time scales, thus requiring robust multi-scale analysis for accurate condition assessment. However, existing multi-scale entropy methods, prone to missing local variations and vulnerable to noise, often yield incomplete features and low diagnostic accuracy with high computational costs. To overcome these challenges, this paper proposes a novel complexity measurement method termed multi-scale distance similarity entropy, which integrates distance similarity entropy with a multi-scale coarse-graining process. By computing element-wise distances and mapping them through a Gaussian kernel function, multi-scale distance similarity entropy captures subtle nonlinear variations in vibration signals while effectively suppressing noise interference. It estimates the similarity distribution between adjacent vectors, enabling sensitive tracking of dynamic complexity changes in mechanical vibration data. Experimental validation on two gearbox datasets encompassing both single and compound faults demonstrates that multi-scale distance similarity entropy achieves superior classification accuracies of 98.63 % and 97.14 %, respectively. The method also shows strong robustness under random impulse noise and low signal-to-noise ratio conditions, along with high computational efficiency, particularly in small-sample scenarios. These characteristics make it highly suitable for online real-time fault diagnosis in complex and noise contaminated industrial environments involving diverse and compound fault patterns.},
  archive      = {J_EAAI},
  author       = {Tao Wang and Shin Yee Khoo and Zhi Chao Ong and Pei Yi Siow and Teng Wang},
  doi          = {10.1016/j.engappai.2025.112308},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112308},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale distance similarity entropy: A novel complexity measurement for gearbox fault diagnosis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JSSM-DTA: Joint sequence-structure modeling with multi-scale transformers for explainable drug-target affinity prediction. <em>EAAI</em>, <em>161</em>, 112303. (<a href='https://doi.org/10.1016/j.engappai.2025.112303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-Target Affinity (DTA) prediction is a pivotal task in drug discovery, aiming to quantify the strength of interactions between drug molecules and their biological targets, such as proteins. Despite significant advancements in deep learning-based methods, several challenges persist. Scale mismatches obstruct functional group-specific representations, leading to suboptimal feature extraction and loss of critical interaction patterns. Additionally, the inability to fully exploit molecular graph structures weakens hierarchical dependency modeling, while ineffective feature fusion hampers the integration of heterogeneous molecular representations, restricting the capture of intricate drug-target interaction dynamics. To address these challenges, this work introduces JSSM-DTA, a novel Joint Sequence-Structure Modeling framework that integrates Multi-Scale Transformers with intermodal feature attention to enhance DTA prediction. JSSM-DTA formulates a unified representation space through the Adaptive Convolutional Transformer (ACT) and the Multi-Scale Diffusion Transformer (MSDT), where ACT refines sequential feature extraction by capturing intricate local dependencies and long-range contextual relationships, while MSDT preserves hierarchical learning, optimizing both global topological organization and fine-grained interactions. Additionally, the Factorized Inter-layer Interaction Module constructs joint embeddings by seamlessly integrating heterogeneous representations, enabling robust feature fusion. The proposed model was evaluated on Davis, KIBA, Metz and BindingDB datasets, demonstrating superior predictive accuracy over state-of-the-art methods. Explainability analysis reveals key molecular substructures and binding interactions, enhancing transparency in decision-making and establishing JSSM-DTA as a benchmark for both accuracy and interpretability in DTA prediction.},
  archive      = {J_EAAI},
  author       = {Uma E. and Mala T.},
  doi          = {10.1016/j.engappai.2025.112303},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112303},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {JSSM-DTA: Joint sequence-structure modeling with multi-scale transformers for explainable drug-target affinity prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyclic translations between pathomics and genomics improve automatic cancer diagnosis from whole slide images. <em>EAAI</em>, <em>161</em>, 112302. (<a href='https://doi.org/10.1016/j.engappai.2025.112302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incorporating genomic characterization into histopathological image modeling brings substantial value to enhancing diagnostic accuracy and supporting the development of targeted and effective treatment strategies. However, prevailing multi-modal integration methods often assume the availability of both pathomics and genomics data in both training and testing phases, overlooking the challenge of data absence due to prohibitive costs. In this paper, we propose a multi-modal cyclic feature generation network (MCFGN) that facilitates cyclic translations between pathomics and genomics to acquire a unified representation of multi-modal data. This approach enables the use of pathological images alone as input to generate joint representations during the testing phase. First, we utilize a general-purpose, self-supervised vision encoder to embed histological image patches as distinctive visual tokens. Next, we hierarchically aggregate patch-level tokens to region-level and slide-level, generating improved whole slide image (WSI) representations. We build self-supervised Masked Autoencoders (MAE) to initialize the hierarchical aggregator. Finally, to incorporate genomic characterization into the learning process, we develop a novel cross-modal cyclic feature generation module to create an intermediate joint representation of pathological and genetic features for patient diagnosis. Evaluations have been conducted on two public datasets from The Cancer Genome Atlas Breast Invasive Carcinoma (TCGA-BRCA) and Non-Small Cell Lung Cancer (TCGA-NSCLC) for various diagnostic tasks, including cancer subtyping and biomarker status prediction. Experiments indicate that our MCFGN model improves predictive performance in cancer diagnosis using histological slides, yielding an 8.7% improvement in area under the curve (AUC) for the cancer subtyping task and a 14.1% gain for biomarker prediction.},
  archive      = {J_EAAI},
  author       = {Xinyu Hao and Hongming Xu and Xiaofeng Wang and Tong Wang and Timo Hamalainen and Fengyu Cong},
  doi          = {10.1016/j.engappai.2025.112302},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112302},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cyclic translations between pathomics and genomics improve automatic cancer diagnosis from whole slide images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multimodal industrial anomaly detection method based on mask training and teacher–student joint memory. <em>EAAI</em>, <em>161</em>, 112299. (<a href='https://doi.org/10.1016/j.engappai.2025.112299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the teacher–student framework has been applied to both single-modality detection and multimodal detection, which realizes anomaly detection based on the feature difference between the teacher model and the student model. However, current multimodal teacher–student models use the same teacher model to extract two-dimensional (2D) image and three-dimensional (3D) point cloud features. The point cloud features extracted by the teacher model pre-trained on images are not the optimal feature representation. To further improve the performance of the teacher–student framework on the multimodal anomaly detection task, this paper proposes M ultimodal T eacher- S tudent J oint M emory ( MTSJM ). MTSJM constructs a teacher–student joint memory bank for each modality, the feature distance between the test sample and the memory bank is used as the anomaly indicator. This distance reflects the feature differences between the test sample and the normal sample at multiple levels, including the teacher–teacher, teacher–student, and student–student levels. Then, this paper proposes a mask-based student model training method. While ensuring that the student learns the feature of normal regions, mask training increases the feature difference of non-normal regions between the student and the teacher. On the MVTec 3D Anomaly Detection (MVTec 3D-AD) dataset, the proposed MTSJM achieves effective anomaly detection performance, reaching 95.7% mean Image-level Area Under the Receiver Operator Curve (I-AUROC) and 97.2% mean Area Under the Per-Region Overlap (AUPRO). In addition, MTSJM achieves 99.3% I-AUROC and 99.6% Pixel-level AUROC (P-AUROC) on a real-world vehicle stamping part task, which further illustrates the applicability of MTSJM on the multimodal anomaly detection task.},
  archive      = {J_EAAI},
  author       = {Yi Liu and Changsheng Zhang and Xingjun Dong and Yufei Yang},
  doi          = {10.1016/j.engappai.2025.112299},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112299},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multimodal industrial anomaly detection method based on mask training and teacher–student joint memory},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuse MetaFormer with convolutional neural networks for three-dimensional model classification. <em>EAAI</em>, <em>161</em>, 112298. (<a href='https://doi.org/10.1016/j.engappai.2025.112298'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimedia technology is widely applied to artificial intelligence and it is key to the performance of artificial intelligence systems, such as computer-aided design system, virtual reality system, the augmented reality system, medical image processing system, and game development system. With the development of multimedia technology, the number of three-dimensional (3D) models in network or database is becoming larger and larger. It is important to classify 3D models. In order to improve accuracy of three-dimensional model classification, a method of 3D model classification fusing MetaFormer with CNN (Convolutional Neural Networks) is proposed. 3D model is projected into two-dimensional (2D) views through the fixed-view projection, and representative views are selected by the clustering algorithm. Points sampled randomly from representative view are used to calculate its shape descriptors. View feature is extracted from representative view by MetaFormer. Shape feature is extracted from shape descriptors of representative view by Convolutional Neural Networks. View feature and shape feature of representative view are fused. At the same time, majority voting algorithm is used to determine category of 3D model based on the fusion of view features and shape features. Experiments are conducted on ModelNet10 dataset. Experimental results show that the proposed method achieves better results than others.},
  archive      = {J_EAAI},
  author       = {Xueyao Gao and Haomin Wu and Chunxiang Zhang and Yongzeng Xue},
  doi          = {10.1016/j.engappai.2025.112298},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112298},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuse MetaFormer with convolutional neural networks for three-dimensional model classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent design of broadband metasurface based on spectrum prediction neural network and transition simulated annealing algorithm. <em>EAAI</em>, <em>161</em>, 112297. (<a href='https://doi.org/10.1016/j.engappai.2025.112297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, metasurfaces have demonstrated considerable potential for application across various fields, including wireless communication, Internet of Things, holographic imaging, and radar systems. With the rapid development of artificial intelligence and its application in other disciplines, metasurface design based on artificial intelligence techniques, particularly deep learning, has attracted widespread attention. In this paper, we propose a novel scheme that integrates deep neural networks with an enhanced simulated annealing algorithm to achieve intelligent design of broadband metasurfaces. Firstly, we construct and train a neural network capable of accurately predicting the amplitude and phase responses of an isotropic metasurface structure, achieving a Mean Absolute Error of 1.36° on the test set. Subsequently, we develop a novel simulated annealing algorithm that is integrated with the prediction neural network to form an intelligent optimization framework. This approach can effectively search for the solution space to accurately achieve arbitrary target phase response, with a very low Mean Squared Error calculated on the test set. Furthermore, we validate the effectiveness of the proposed model and algorithm through a practical application that demonstrates broadband dispersion characteristics within the frequency range of 9–11 Gigahertz (GHz). Additionally, the prediction model can employ transfer learning strategy to adapt to various operating frequency bands, significantly enhancing its generalization capabilities. The proposed intelligent design methodology introduces a novel pathway for rapidly designing metasurface in complex application scenarios, serving as a valuable reference for the engineering design of devices in electronics, optics, and wireless communication.},
  archive      = {J_EAAI},
  author       = {Yin Zhang and Yuxin Dai and Yiyu Fan and Jun Yu},
  doi          = {10.1016/j.engappai.2025.112297},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112297},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent design of broadband metasurface based on spectrum prediction neural network and transition simulated annealing algorithm},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Industrial fabric defect-generative adversarial network (IFD-GAN): High-fidelity fabric cross-scale defect samples synthesis method for enhancing automated recognition performance. <em>EAAI</em>, <em>161</em>, 112296. (<a href='https://doi.org/10.1016/j.engappai.2025.112296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {—High-quality defect samples and datasets are the cornerstone for enhancing the performance of deep learning detection algorithms for fabric defects. Constraints, such as the complexity of fabric textures, the diversity and sporadic occurrence of defects, the insufficient scale, and the significant class imbalance of datasets, impede improvements in detection accuracy and generalization of detection models, thereby limiting industrial application. To address the issues above, a two-stage generative model for fabric defect images called Industrial Fabric Defect-Generative Adversarial Network (IFD-GAN), based on contrastive learning mutual information mechanism, was introduced. The Pixel-level Defect-Background Stripper (DBS) was devised for precise localization, and the Longitude-Latitude Self-Attention Mechanism (LLSA) was proposed to efficiently focus on defect foreground details, facilitating decoupling and efficient extraction of defect features. The combination of the two, along with the structural similarity loss function, collectively regulates the coordination and consistency between defect and background textures. An industrial-grade fabric defect dataset was collected for IFD-GAN training and generative testing. The model's effectiveness in generating defect images was evaluated based on dimensions such as fidelity and diversity. IFD-GAN is used to enhance this dataset, and the system compared the performance of advanced object detection models trained on the datasets before and after the enhancement. Extensive experimental results show that IFD-GAN can accomplish high-fidelity generation of high-resolution cross-scale fabric defect images in an unsupervised environment, significantly contributing to the creation of more balanced and diverse large-scale industrial fabric defect datasets and the enhancement of defect detection networks in precision, robustness, and generalizability.},
  archive      = {J_EAAI},
  author       = {Shun Xu and Sheng Cheng and Shuyang Jin and Xudong Hu and Weitao Wu and Zhong Xiang},
  doi          = {10.1016/j.engappai.2025.112296},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112296},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Industrial fabric defect-generative adversarial network (IFD-GAN): High-fidelity fabric cross-scale defect samples synthesis method for enhancing automated recognition performance},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample-efficient planning-control framework for autonomous underwater vehicle docking using lightweight cross Q-learning. <em>EAAI</em>, <em>161</em>, 112293. (<a href='https://doi.org/10.1016/j.engappai.2025.112293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous Underwater Vehicles (AUVs) are essential for long-duration missions in underwater sensor networks, but their operation is constrained by limited onboard energy and low-bandwidth communication. Docking stations are deployed to support energy replenishment and data transfer, requiring AUVs to autonomously plan return trajectories and achieve precise docking. Traditional motion planning and control methods for AUV docking often decouple global motion planning from local control or rely on accurate dynamics models, while existing deep reinforcement learning (DRL) approaches frequently neglect sample efficiency. This work presents a novel DRL framework that tightly integrates motion planning and control while emphasizing sample efficiency to enable reliable and efficient AUV docking. The docking task is formulated as an Markov Decision Process (MDP), in which a structured reward function is defined to guide the agent towards goal-directed behavior in an interpretable and sample-efficient manner. A lightweight Cross Q-Learning (CrossQ-Lite) algorithm is developed by removing target networks and incorporating batch normalization, achieving stable learning with approximately 92.8% fewer parameters while maintaining comparable performance. Simulation results demonstrate that, under the proposed MDP formulation, CrossQ-Lite achieves a minimum of 1 . 39 × higher sample efficiency and improved training stability compared to state-of-the-art DRL baselines. The trained model reliably completes AUV docking tasks, providing a practical and high-performance solution for autonomous underwater sensor networks.},
  archive      = {J_EAAI},
  author       = {Kaixin Zhang and Yuelong Xu and Minghao Zhao and Yu Jiang},
  doi          = {10.1016/j.engappai.2025.112293},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112293},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sample-efficient planning-control framework for autonomous underwater vehicle docking using lightweight cross Q-learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault diagnosis of wind turbine based on dual-channel feature aggregation network with attentional mechanism. <em>EAAI</em>, <em>161</em>, 112291. (<a href='https://doi.org/10.1016/j.engappai.2025.112291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind turbines are subjected to alternating stresses and shock loads during operation, and the collected vibration signals are nonlinear, non-stationary and contain noise, resulting in subtle fault features that are difficult to extract. In order to extract discriminative features from vibration signals under variable speed operating conditions, a dual-channel feature aggregation network (DCNet) with attention mechanism is developed in this paper. First, a Parallel Patch-Aware Convolutional Module (PPCM) is constructed to extract feature information of different scales and levels from Time–Frequency Representations (TFR). Specifically, convolutional operations are performed in both the spatial and frequency domains, endowing it with local–global capturing capabilities and efficiency. Then, to improve the network operation rate, Haar Wavelet Downsampling (HWD) is embedded into the DCNet architecture. The core idea is to reduce the spatial resolution of features through Haar wavelet transform while preserving as many discriminative features as possible. Additionally, Channel Prior Convolutional Attention (CPCA) is introduced to enable DCNet to focus on more critical feature parts by dynamically allocating channel and spatial attention weights, thereby suppressing redundant feature interference. Finally, in the Deep Feature Fusion Module (DFFM), a cross-attention mechanism is adopted for global interaction, fusing features from different channels to achieve feature enhancement. To obtain good diagnostic results under variable speed conditions, we apply a label smoothing algorithm to assist model training. The experimental results show that the proposed model has high diagnostic accuracy, can generalize effectively, and it still maintains high diagnostic accuracy under noise and variable speed working conditions.},
  archive      = {J_EAAI},
  author       = {Haiyu Guo and Xingzheng Guo and Xiaoguang Zhang and Fanfan Lu and Chuang Liang},
  doi          = {10.1016/j.engappai.2025.112291},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112291},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis of wind turbine based on dual-channel feature aggregation network with attentional mechanism},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new deep learning framework for intelligent aerial monitoring of power transmission line insulators. <em>EAAI</em>, <em>161</em>, 112290. (<a href='https://doi.org/10.1016/j.engappai.2025.112290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transmission line insulators are critical components for maintaining the integrity and efficiency of power transmission lines. Monitoring the health, performance, and efficiency of this network has always been of interest since the past. Traditional and field inspection methods are often tedious, costly, and prone to human error. In order to monitor the condition of transmission lines and overcome traditional challenges, this study proposes an intelligent monitoring framework using unmanned aerial vehicle (UAV) imaging and advanced deep learning models to identify and classify insulator defects. The dataset used in this study consists of 870 original images, 600 healthy images, 140 damaged images, and 130 images of flashover insulators collected from UAV flights and online sources. To increase the diversity of the training data, a data augmentation technique was used, increasing the number of images to 1952 samples and dividing the data into 80 % training sets and 20 % test sets. While the current evaluation is performed on this dataset, real-world experiments will be considered in future studies to further validate the model. In this approach, three scenarios were considered to evaluate and detect these errors. The first scenario used an independent convolutional neural network (CNN) for feature extraction and classification, achieving an accuracy of 82.54 %. The second scenario combined CNN with transfer learning (TL) techniques to improve feature representation, achieving an accuracy of 95.99 %. Scenario Three integrated a hybrid CNN model with a long short-term memory network, achieving an average accuracy of 99.67 % in fault detection and classification. The results demonstrate the superiority and robustness of the proposed hybrid model, providing a reliable and cost-effective solution for transmission line insulator monitoring. This study highlights the significant potential of combining UAV imagery with deep learning algorithms, reassuring the audience of the effectiveness of the proposed solution.},
  archive      = {J_EAAI},
  author       = {Reza Rahimi Nejadbougar and Ebadat Ghanbari Parmehr and Alireza Afary and Samira Mavaddati},
  doi          = {10.1016/j.engappai.2025.112290},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112290},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new deep learning framework for intelligent aerial monitoring of power transmission line insulators},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal generative network based on deep long short-term memory autoencoder for hand skeleton data sequences reconstruction and recognition. <em>EAAI</em>, <em>161</em>, 112289. (<a href='https://doi.org/10.1016/j.engappai.2025.112289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks attract the highest research focus in the developing field of Hand Gesture Recognition (HGR). Nevertheless, these approaches presented a challenging task in adapting to time-series data. In skeleton-based HGR, extracting spatial–temporal information remains a challenge. In recent times, recurrent neural networks have exhibited exceptional performance in detecting desired hand gestures by processing of varied length time-series data. Although they outperform traditional methods when huge training data is accessible, their effectiveness significantly diminishes when data availability is constrained. In this study, we introduce an unsupervised data augmentation network known as the Spatial-Temporal Generative Network (STGN), which reconstructs both the spatial and temporal information of the input sequences by leveraging a Deep Long Short-Term Memory Auto-Encoder (DLSTM-AE) network. Consequently, the DLSTM-AE combined with different Long Short-Term Memory (LSTM) network variations, forming an integrated network that can be trained end-to-end for HGR. Through experimentation conducted on the LeapGestureDB dataset (Leap Motion-based Gesture Dataset) and RIT dataset (Rochester Institute of Technology Hand Gesture Dataset), we prove that data reconstruction using STGN had a prominent effect on improving the accuracy of recognizing time-series based hand gestures. For all experiments, the best recognition results are achieved in the augmented dataset. Accuracies were improved on all tested LSTM networks from 2 to 10%. For reproducible research, the code is available at: https://github.com/AMEURsafa/STGN .},
  archive      = {J_EAAI},
  author       = {Safa Ameur and Mohamed Ali Mahjoub and Anouar Ben Khalifa},
  doi          = {10.1016/j.engappai.2025.112289},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112289},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spatial-temporal generative network based on deep long short-term memory autoencoder for hand skeleton data sequences reconstruction and recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural dynamic fluid reconstruction technique for four-dimensional imaging of combustion flame based on deep learning. <em>EAAI</em>, <em>161</em>, 112288. (<a href='https://doi.org/10.1016/j.engappai.2025.112288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional optical diagnostic techniques based on the principles of tomographic imaging enable the acquisition of rich three-dimensional information in experimental flow fields through reconstruction calculations. However, for tasks involving the reconstruction of three-dimensional flow fields at high temporal resolutions, existing methods incur high computational costs, low reconstruction efficiency, and struggle to achieve high spatiotemporal resolution measurements. This paper proposes the Neural Dynamic Fluid Reconstruction Technique (NDFRT) based on deep learning. NDFRT incorporates the time dimension into the reconstruction scope to achieve the four-dimensional reconstruction of dynamic flow fields using neural networks. NDFRT has the following technical advantages: (1) ultra-high spatiotemporal reconstruction resolution; (2) good computational efficiency, with the reconstruction parameter scale only half that of traditional voxel-based methods; (3) the ability to perform three-dimensional frame prediction of dynamic fluids. We validated the proposed method using numerical simulation and experimental jet flame reconstruction and compared it with the traditional algebraic reconstruction technique (ART). Experimental results demonstrate that NDFRT outperforms traditional ART methods in terms of computational efficiency, reconstruction resolution, and reconstruction accuracy.},
  archive      = {J_EAAI},
  author       = {Fuhao Zhang and Zhiyin Ma and Can Gao and Gang Xun and Qingchun Lei and Xuesong Li},
  doi          = {10.1016/j.engappai.2025.112288},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112288},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural dynamic fluid reconstruction technique for four-dimensional imaging of combustion flame based on deep learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BeltDiff: Diffusion-based self-labeled generation system for conveyor belt damage detection. <em>EAAI</em>, <em>161</em>, 112287. (<a href='https://doi.org/10.1016/j.engappai.2025.112287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The damages of conveyor belt are abnormal occurrence of industrial production line, generally resulting in serious economic losses. While utilizing deep-learning-based methods in belt damage detection task, models training is challenging due to the prevalent scarcity of both numbers and diversity in dataset, leading to the restricted performance and limited accuracy in practical applications. To address this issue, we propose a novel self-labeled generation system based on diffusion model, for creating effective and large-scale conveyor belt detection datasets. Specifically, the training of our system is divided into three stages for progressive task decomposition and interpretable user control. Among the generation process, we focus on the textual prompt alignment and shape guidance to generate more reasonable and high-quality damaged belt images. Meanwhile, larger scale datasets are created via our method on two scenes, including base scene with limited samples, and brand new scenes with no damaged samples, which compose 9636 and 7500 images respectively. By evaluating the quality of damaged images, and the relations between generated and real images, our method demonstrates its effectiveness on generating damaged belt image pairs with annotations. Further, for verifying the validity of our generative datasets, we implement numerous experiments of 4 types of popular detection models training on different settings. The results demonstrate that our datasets support effective accuracy improvement, comparing with the base datasets and the classic augmented datasets, specifically increased by up to 14.4% in the brand new scenes with no damaged samples.},
  archive      = {J_EAAI},
  author       = {Peixian Zhuang and Yuanxiu Cai and Xi Liu and Xianchao Zheng and Fuheng Xiao and Jiangyun Li},
  doi          = {10.1016/j.engappai.2025.112287},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112287},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {BeltDiff: Diffusion-based self-labeled generation system for conveyor belt damage detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust deep learning based model for denoising phonocardiogram signals in clinical environments. <em>EAAI</em>, <em>161</em>, 112286. (<a href='https://doi.org/10.1016/j.engappai.2025.112286'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A cardiac auscultation, being a very popular first line cardiovascular diseases screening method, typically produces phonocardiogram signals contaminated by background sounds, e.g., speech and movement of other patients and doctors/nurses, phone ringing and door knocking/opening/closing, and internal physiological body noises, e.g., lung sounds, muscle contraction and motion artifacts, as it is usually done in a noisy environment and it is not possible to suppress all the internal physiological body noises. So, a quality of the recording is finally decreased. Moreover, this can strongly affect a subsequent analysis/classification of the captured recording and can also lead to its incorrect classification. In this paper, we propose a novel deep convolutional architecture that integrates the bidirectional long short-term memory layers with the transformer blocks involving multi-head attention mechanism, which is particularly designed for denoising phonocardiogram signals. The performance of the proposed artificial intelligence-based approach is evaluated through synthetic data generated by using one public phonocardiogram dataset and two public real-world hospital ambient/respiratory sound databases as well as by deploying two public and renowned real-world clinical environment datasets containing phonocardiogram signals contaminated by various environmental and physiological noises recorded during the clinical auscultations. The deployed complex evaluation strategy assures a higher robustness and generalizability of the proposed approach. As also a result of that, the proposed model outperforms the current state-of-the-art approaches and provides the significant improvements in all the assessed signal quality and noise suppression metrics and over all the involved benchmark datasets. Finally, it should be noted here that the model achieved an average estimated SNR of 14.984 dB and 11.924 dB for the PASCAL and CirCor22 dataset respectively, which represent the renowned real-world clinical environment datasets.},
  archive      = {J_EAAI},
  author       = {Maros Jakubec and Eva Lieskovska and Peter Pocta},
  doi          = {10.1016/j.engappai.2025.112286},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112286},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust deep learning based model for denoising phonocardiogram signals in clinical environments},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based end-to-end point restoration network for filtering temporarily-static objects from point cloud. <em>EAAI</em>, <em>161</em>, 112284. (<a href='https://doi.org/10.1016/j.engappai.2025.112284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precision of map-based localization systems is pivotal for advanced navigation and autonomous vehicle technologies. This study addresses the challenge of dynamic environments where temporarily-static objects, such as vehicles, introduce occlusion and temporal alterations to the mapping landscape, leading to inaccuracies in mapping and localization. We propose a transformer-based deep learning model that removes temporarily-static objects and refines occluded areas in raw point cloud data, thereby enhancing both mapping and localization. Our method leverages a transformer-based point restoration network trained on a novel dataset that does not require human-driven manual annotation and predicts point clouds free of temporarily-static objects. The approach was validated through experiments demonstrating improved qualitative and quantitative results. The results display the importance of our method by removing temporarily-static objects and refining occluded areas. The proposed method achieves a 26.4 % reduction in Chamfer Distance L1 (CD-L1), 33.1 % reduction in Chamfer Distance L2 (CD-L2), and a 30.2 % relative improvement in the harmonic mean of precision and recall (F-Score) over the baseline network, demonstrating significantly enhanced model for filtering. This research contributes to artificial intelligence (AI)-enabled autonomous navigation by offering a systematic solution to a common problem in dynamic environments, setting a new filtering technology for mapping systems.},
  archive      = {J_EAAI},
  author       = {Sabir Hossain and Xianke Lin},
  doi          = {10.1016/j.engappai.2025.112284},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112284},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer-based end-to-end point restoration network for filtering temporarily-static objects from point cloud},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-view gait recognition based on discriminative global–local feature representation and learning. <em>EAAI</em>, <em>161</em>, 112282. (<a href='https://doi.org/10.1016/j.engappai.2025.112282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance of gait recognition can be heavily influenced by deformation of walking silhouettes due to variations of view angle. Cross-view gait recognition is still one of the most challenging problems in pattern recognition community. In this paper, we propose a new cross-view gait recognition algorithm by discriminative global–local feature representation and learning. First, we design cross-view convolutional neural network for learning global gait feature representations underlying binary walking silhouettes sequences. Second, we propose to extract local gait features by partial spatial–temporal sequence and local feature extractors, which can represent the motion characteristics and temporal changes of different human body parts. Both global and local features in our proposed method are extracted from different gait representations to provide spatial–temporal information from diverse aspects, and they are fused on feature level to further reduce the sensitivity to variations of view angle and improve the performance of gait recognition. Finally, we introduce deep metric learning framework and propose a robust, effective, and view-related loss function, named view triplet loss function, to learn discriminative gait features. Compared with triplet loss, the proposed loss function explores hierarchical relationship of the variations of view angles, which achieves better intra-subject compactness and inter-subject separability. Experimental results on CASIA-B, OULP and OUMVLP gait datasets demonstrate the feasibility and advantage of our proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Muqing Deng and Yi Zou and Zhi Zeng and Xiaoreng Feng and Yanjiao Wang and Yuan Liu},
  doi          = {10.1016/j.engappai.2025.112282},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112282},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cross-view gait recognition based on discriminative global–local feature representation and learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel clustering-ensemble learning model for day-ahead photovoltaic power forecasting. <em>EAAI</em>, <em>161</em>, 112281. (<a href='https://doi.org/10.1016/j.engappai.2025.112281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate day-ahead photovoltaic power forecasting (PPF) is essential for grid scheduling and transaction planning. However, time series prediction models based on historical meteorological and photovoltaic power data often struggle to capture long-term dependencies. Existing research typically employs multivariate regression models to establish mapping relationships between numerical weather prediction (NWP) and photovoltaic power data, yet still exhibits deficiencies in weather pattern recognition and consideration of temporal patterns. Therefore, this paper proposes a novel clustering-ensemble learning model to enhance predictive performance. In the proposed deep time-series clustering algorithm, key features from NWP data are extracted for clustering, addressing the inefficiencies of traditional clustering methods in handling high-dimensional data. A weighted Warp-Euclidean distance is proposed to capture sequence trend homogeneity and spatial similarity, overcoming the limitations of Euclidean distance in time-series data. The ensemble learning model combines the advantages of two gradient boosting tree models to handle nonlinear features and high-dimensional data, while introducing lag features to enhance temporal dynamic learning capability. This approach enhances the stability and mitigates the limitations associated with relying primarily on weather-related features. This study utilizes NWP and measured photovoltaic data from two stations in Hebei Province, China. Results demonstrate superior performance compared to other clustering algorithms and prediction models in day-ahead PPF tasks, achieving R 2 scores of 0.952 and 0.943 on two public photovoltaic datasets, representing improvements of 0.020 and 0.017 over optimal benchmark models. The proposed framework provides theoretical guidance for the stable operation of grid-connected photovoltaic systems.},
  archive      = {J_EAAI},
  author       = {Feifei Yang and Xueqian Fu and Zhengshuo Li and Dawei Qiu and Hamed Badihi},
  doi          = {10.1016/j.engappai.2025.112281},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112281},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel clustering-ensemble learning model for day-ahead photovoltaic power forecasting},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence-based phonocardiogram signal classification using segment-specific multi-domain features for cardiovascular and arterial disease. <em>EAAI</em>, <em>161</em>, 112280. (<a href='https://doi.org/10.1016/j.engappai.2025.112280'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart diseases are the leading cause of death globally, and early diagnosis coupled with timely treatment can save lives. The human heart produces sounds that reflect the functions of its valves and chambers, with murmurs often indicating abnormal heart behavior. The phonocardiogram (PCG) analysis offers a quick, easy, and affordable diagnostic method for detecting such conditions. The PhysioNet/2016 dataset, containing annotated heart sound recordings, has advanced automated heart sound classification research. Despite the dataset encompassing nine classes of heart diseases, it has primarily been used for binary classification tasks. Multi-class classification is challenging due to overlapping acoustic features among certain heart conditions and signal variability. To address these issues, we implemented segment specific feature extraction across six domains — time, frequency, amplitude, wavelet, spectrum, signal processing — and evaluated various machine learning classifiers. Our findings revealed that the Random Forest classifier outperformed others, leading us to integrate it into our model. On the testing dataset, it attained 94% accuracy, 93% sensitivity and 93% specificity for binary classification Our model achieved 89% accuracy, 80% sensitivity and 98% specificity for nine-class classification including both valve diseases and artery-related conditions.},
  archive      = {J_EAAI},
  author       = {Syeda Sana Bukhari and Shahab U. Ansari and Khurram Khan Jadoon and Raja Hashim Ali},
  doi          = {10.1016/j.engappai.2025.112280},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112280},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial intelligence-based phonocardiogram signal classification using segment-specific multi-domain features for cardiovascular and arterial disease},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic forecasting of non-ferrous metal prices based on outlier treatment algorithms, quantile regression based deep learning and two-phase multi-objective optimization. <em>EAAI</em>, <em>161</em>, 112277. (<a href='https://doi.org/10.1016/j.engappai.2025.112277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of non-ferrous metal prices plays a crucial role in helping enterprises optimize production, control costs, and manage risks, as well as in enabling countries and industries to formulate resource strategies, ensure economic security, and promote sustainable development. However, existing research still has limitations in outlier detection, uncertainty analysis, and model optimization, making it difficult to meet the forecasting needs in complex market environments. To fill these gaps, this study proposes a novel combined probabilistic forecasting framework for non-ferrous metal prices. First, this study utilizes outlier treatment algorithms to achieve robust outlier detection and correction. Second, multiple quantile regression-based deep learning models are established for probabilistic forecasting. Subsequently, a two-phase multi-objective optimization strategy is proposed. Specifically, the first phase is designed to optimize the upper quantile half-interval and lower quantile half-interval of each quantile regression-based deep learning model, while the second phase is used to optimize the combined weights of the aforementioned single model to synergistically enhance interval reliability and prediction accuracy. Finally, silver and aluminum futures prices are used as illustrative case studies. The experimental results show that the proposed model outperforms the benchmark method in terms of interval coverage and prediction accuracy. This study provides a scientific basis and reference for industrial production optimization, investment decision-making and resource management planning.},
  archive      = {J_EAAI},
  author       = {Pei Du and Fangrui Gui and Lijie Shan and Qianyi Xing and Jianzhou Wang},
  doi          = {10.1016/j.engappai.2025.112277},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112277},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probabilistic forecasting of non-ferrous metal prices based on outlier treatment algorithms, quantile regression based deep learning and two-phase multi-objective optimization},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying nonlinear roll damping and restoring parameters via physics-informed neural network. <em>EAAI</em>, <em>161</em>, 112275. (<a href='https://doi.org/10.1016/j.engappai.2025.112275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To effectively characterize a ship’s roll motion, developing a robust dynamic model that incorporates accurate damping and restoring parameters is essential. Given that only limited free-decay measurements have been measured, an efficient physics-informed neural network-based approach has been developed to simultaneously determine the nonlinear damping and restoring parameters associated with ship rolling. Rather than relying on a large dataset to train a neural network for parameter identification, the proposed method incorporates the physical equations of roll motion into the residual networks, ensuring that the identified parameters adhere to their physical interpretation. Three numerical cases, encompassing computational fluid dynamics (CFD) analyses, and laboratory experiments, are presented to show the superior performance of the developed method. Key findings indicate that the proposed method effectively identifies the investigated parameters with high precision while maintaining consistent performance across various initial roll angle conditions. Compared to traditional methods, the proposed approach offers significant advantages, including reduced reliance on large datasets, automated parameter identification without manual tuning, and the ability to incorporate physical constraints directly into the learning process. These features make the method particularly suitable for real-world applications where data is sparse or costly to obtain.},
  archive      = {J_EAAI},
  author       = {Shuai Cong and Jinwei Sun and Qianying Cao and Changhong Zhi and Shixuan Liu},
  doi          = {10.1016/j.engappai.2025.112275},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112275},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identifying nonlinear roll damping and restoring parameters via physics-informed neural network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection in offshore open radio access network using long short-term memory models on a novel artificial intelligence-driven cloud-native data platform. <em>EAAI</em>, <em>161</em>, 112274. (<a href='https://doi.org/10.1016/j.engappai.2025.112274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Radio Access Network (RAN) is a critical component of modern telecommunications infrastructure, currently evolving towards disaggregated and open architectures. These advancements are pivotal for integrating intelligent, data-driven applications aimed at enhancing network reliability and operational autonomy through the introduction of cognitive capabilities, as exemplified by the emerging Open Radio Access Network (O-RAN) standards. Despite its potential, the nascent nature of O-RAN technology presents challenges, primarily due to the absence of mature operational standards. This complicates the management of data and intelligent applications, particularly when integrating with traditional network management and operational support systems. Divergent vendor-specific design approaches further hinder migration and limit solution reusability. These challenges are compounded by a skills gap in telecommunications business-oriented engineering, which remains a key barrier to effective O-RAN deployment and intelligent application development. To address these challenges, Boldyn Networks developed a novel cloud-native data analytics platform, specifically designed to support scalable Artificial Intelligence (AI) integration within O-RAN deployments. This platform underwent rigorous testing in real-world scenarios, and applied advanced AI techniques to improve operational efficiency and customer experience. Implementation involved adopting Development Operations (DevOps) practices, leveraging data lakehouse architectures tailored for AI applications, and employing sophisticated data engineering strategies. The platform successfully addresses connectivity challenges inherent in real-world offshore wind farm deployments using Long Short-Term Memory (LSTM) models for anomaly detection in network connectivity. After integrating the LSTM models into the network control, more than 90 percent of connectivity issues were reduced in runtime. This marks a step toward autonomous, self-organizing, and self-healing networks.},
  archive      = {J_EAAI},
  author       = {Abdelrahim Ahmad and Peizheng Li and Robert Piechocki and Rui Inacio},
  doi          = {10.1016/j.engappai.2025.112274},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112274},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Anomaly detection in offshore open radio access network using long short-term memory models on a novel artificial intelligence-driven cloud-native data platform},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural design through reinforcement learning. <em>EAAI</em>, <em>161</em>, 112273. (<a href='https://doi.org/10.1016/j.engappai.2025.112273'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Structural Optimization gym (SOgym), a novel open-source Reinforcement Learning (RL) environment designed to advance machine learning in Topology Optimization (TO). SOgym enables RL agents to generate physically viable and structurally robust designs by integrating the physics of TO into the reward function. To enhance scalability, SOgym leverages feature-mapping methods as a mesh-independent interface between the environment and the agent, allowing efficient interaction with the design variables regardless of mesh resolution. Baseline results use a model-free Proximal Policy Optimization agent and a model-based DreamerV3 agent. Three observation space configurations were tested. The Topology Optimization game ( TopOpt game) inspired configuration, an interactive educational tool for designing structures to minimize compliance under volume constraints, performed best in terms of performance and sample efficiency. The 100 million parameter DreamerV3 model (DreamerV3-100M) produced structures with compliance values approximately 54 % higher than those from traditional optimization methods and a 0 % disconnection rate, an improvement over supervised learning approaches that often struggle with disconnected load paths. When comparing the learning rates of the agents to those of engineering students from the TopOpt game experiment, the DreamerV3-100M model shows a learning rate approximately four orders of magnitude lower, an impressive feat for a policy trained from scratch through trial and error. These results suggest RL's potential to solve continuous TO problems and its capacity to explore and learn from diverse design solutions. SOgym provides a platform for developing RL agents for structural design challenges and is publicly available to support research in the field.},
  archive      = {J_EAAI},
  author       = {Thomas Rochefort-Beaudoin and Aurelian Vadean and Niels Aage and Sofiane Achiche},
  doi          = {10.1016/j.engappai.2025.112273},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112273},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Structural design through reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-channel selection for epileptic seizure identification through a custom machine learning model. <em>EAAI</em>, <em>161</em>, 112272. (<a href='https://doi.org/10.1016/j.engappai.2025.112272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy affects millions of people worldwide, triggering undesirable motor and sensory events that drastically impair the quality of life of those affected. Detecting this condition through a monitoring system can be extremely useful in identifying epileptic seizures without relying exclusively on a specialist. Our goal is to identify these seizures using personalized supervised machine learning models – eXtreme Gradient Boosting – for each patient, employing only one electroencephalogram input channel. Our methodology explores the relationship between the selected input channel and the topographic location of epileptic seizures modeled for the patient. The results revealed notable accuracy performances for the three patients investigated: 100%, 99%, and 88%, after applying the proposed time filter that checks for the presence/absence of a seizure every 3 s. Furthermore, it was possible to observe that the results are consistent with the affected area in each patient, demonstrating the effectiveness of the method in selecting the single channel. This approach demonstrates the feasibility of detecting convulsive seizures using only one input channel and underscores the need to extend the methodology to more patients.},
  archive      = {J_EAAI},
  author       = {Jusciaane Chacon Vieira and Ignacio Sanchez-Gendriz and Luiz Affonso Guedes},
  doi          = {10.1016/j.engappai.2025.112272},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112272},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Single-channel selection for epileptic seizure identification through a custom machine learning model},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IMobileTransformer: A fusion-based lightweight model for rice disease identification. <em>EAAI</em>, <em>161</em>, 112271. (<a href='https://doi.org/10.1016/j.engappai.2025.112271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rice blast, sheath blight, leaf scald, bacterial leaf blight, and brown spot severely threaten rice yield. To address the limitations of current deep learning methods in rice disease recognition, particularly their insufficient integration of local and global features, this study proposes an Improved MobileTransformer (IMobileTransformer) model. The proposed architecture synergistically combines MobileNet’s strengths in local feature extraction and lightweight architecture with Transformer’s superior capability in global information processing. Specifically, the model is designed with three functional branches: a) a MobileNet branch utilizing inverted residual structure with depthwise separable convolution layers to reduce parameters and computational complexity, b) a Transformer branch modified from Swin-Transformer architecture, where the Multilayer Perceptron (MLP) layer is enhanced by splitting input feature channels through an Inception-based structure to maintain global feature extraction efficiency while minimizing computational overhead, and c) a feature fusion branch that concatenates reshaped outputs from both branches through channel-wise stacking, enabling effective integration of local and global representations. Experimental results show that compared to classical models such as MobileNetV3-Large, EfficientNet-B0, Vision Transformer Base/16 (ViT-B/16), Shifted Window Transformer (Swin-Transformer), Tiny Vision Transformer (TinyViT), Mobile Vision Transformer (MobileViT), LocalViT-S, IMobileTransformer achieves a recognition accuracy of 99.62% for rice diseases, with improvements of 1.71%, 0.91%, 38.09%, 4.17%, 1.99%, 1.5% and 0.42%, respectively, providing an effective solution for rice disease recognition.},
  archive      = {J_EAAI},
  author       = {Yang Lu and Haoyang Zhou and Peng Wang and Erzhi Wang and Gongfa Li and Tongjian Yu},
  doi          = {10.1016/j.engappai.2025.112271},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112271},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IMobileTransformer: A fusion-based lightweight model for rice disease identification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized and safe medication recommendation based on convolutional neural network and transformer architecture. <em>EAAI</em>, <em>161</em>, 112267. (<a href='https://doi.org/10.1016/j.engappai.2025.112267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the accumulation of electronic health records (EHRs), artificial intelligence (AI) based medical services such as medication recommendation (MR) has aroused widespread concern. However, existing drug recommendation models suffer from inadequate patient representation and adverse drug–drug interactions (DDIs). To address these challenges, we propose an AI-based personalized and safe medication recommendation method based on convolutional neural network and transformer architecture (CT-PASMR). Specifically, convolutional neural network (CNN) and transformer are combined in parallel (CAT) to model local relationships in a patient’s single visit and long-term dependencies in sequential EHR data, respectively. Subsequently, graph attention networks (GATs) are deployed to capture drug co-occurrences and adverse DDIs with various weights, generating safe drug representations. Moreover, a joint loss function is introduced to balance accuracy and safety in CT-PASMR. Finally, the experimental results on MIMIC (Medical Information Mart for Intensive Care)-III and MIMIC-IV datasets demonstrate that CT-PASMR achieves competitive performance on seven evaluation metrics such as DDI rate, Jaccard index and F1 score, compared with nine state-of-the-art (SOTA) baseline models. Ultimately, ablation studies and further analysis confirm the efficacy of CATs and GATs in providing personalized and safe medication recommendations. Code, qualitative results, and trained weights will be available at the link: https://github.com/gefengru/CT-PASMR .},
  archive      = {J_EAAI},
  author       = {Fengru Ge and Xiaomei Yu and Xue Li and Xingxu Fan and Yanjie Zhao},
  doi          = {10.1016/j.engappai.2025.112267},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112267},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Personalized and safe medication recommendation based on convolutional neural network and transformer architecture},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning with similarity enhancement for dimensionality reduction. <em>EAAI</em>, <em>161</em>, 112266. (<a href='https://doi.org/10.1016/j.engappai.2025.112266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensionality reduction aims to reduce the number of dimensions while preserving crucial information. As a self-supervised learning approach, contrastive learning provides a novel perspective for dimensionality reduction. However, most contrastive learning methods focus on optimizing similarity, which have limitations in reducing feature redundancy. Moreover, the dependence on negative pairs introduces computational overhead. To address these problems, we propose Contrastive Learning with Similarity Enhancement for Dimensionality Reduction (CLSDR), which integrates neighborhood embedding into the contrastive learning framework. Specifically, CLSDR uses k -nearest neighbors sampling to construct positive pairs. We design a multi-level loss function that captures the diversity of data while maintaining the consistency of local and global features. In addition, we propose a nonlinear similarity optimization mechanism based on logarithmic smoothing, which adjusts the gradient of similarity loss, improving the stability during the training process. Experimental results demonstrate that CLSDR significantly outperforms several state-of-the-art methods. Especially, on the Street View House Numbers dataset, CLSDR achieves 66.7% and 62.3% Top-1 accuracy with two classifiers in 64-dimensional embedding space, which have 10.6% and 38.4% improvement over the best competing approach. Thus, CLSDR exhibits strong robustness and scalability across different dimensions.},
  archive      = {J_EAAI},
  author       = {Qi Yang and Changpeng Wang and Linlin Feng and Lizhen Ji and Jiangshe Zhang},
  doi          = {10.1016/j.engappai.2025.112266},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112266},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contrastive learning with similarity enhancement for dimensionality reduction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-modal approach for detecting drivers’ distraction using bio-signal and vision sensor fusion in driver monitoring systems. <em>EAAI</em>, <em>161</em>, 112265. (<a href='https://doi.org/10.1016/j.engappai.2025.112265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to a report by the World Health Organization (WHO), approximately 1.3 million people lose their lives annually owing to traffic accidents. The majority of road traffic accidents stem from driver negligence. Recently, there has been a growing interest in utilizing deep learning and machine learning technologies to enhance the safety and efficiency of road traffic, with the aim of addressing issues arising from driver inattentiveness. Most studies focus on detecting abnormal driver behavior using driving sensors or driver images; however, they often overlook physiological factors such as the driver's bio-signals. Considering that the driver's state, including fatigue, stress, and concentration, can significantly affect driving safety, it is crucial to build models that consider biometric information. Therefore, this study proposes a multi-modal transformer model called Bio-Vision Transformer (BiViT) that comprehensively considers both driver bio-signals and images. The BiViT model uses a vision transformer to extract features from driver images and employs a time-series transformer to capture features from the driver's bio-signals. In addition, the interactions between the extracted features are modeled, and the joint fusion method is employed as the feature-fusion approach. To validate the proposed model, performance comparisons and analyses were conducted using commonly used models in image analysis. The experimental results demonstrated that the proposed BiViT model exhibited high performance, with an accuracy of 0.91 and a harmonic mean of precision and recall (F1-score) of 0.91, surpassing the performance of the comparison models.},
  archive      = {J_EAAI},
  author       = {Byeongjoon Noh and Myeongseok Park and Yechan Han and Jaeyun Kim},
  doi          = {10.1016/j.engappai.2025.112265},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112265},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-modal approach for detecting drivers’ distraction using bio-signal and vision sensor fusion in driver monitoring systems},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural network with generative adversarial training for node classification on class imbalanced data. <em>EAAI</em>, <em>161</em>, 112264. (<a href='https://doi.org/10.1016/j.engappai.2025.112264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Node classification in class-imbalanced graph data remains a critical challenge, as traditional graph neural networks (GNNs) either assume class-balanced graph structures or inadequately address class imbalance. This often results in predictive bias, where majority classes are favored while minority classes are underrepresented. To overcome this limitation, this study introduces a novel graph neural network with generative adversarial training (GNN-GAN), where the GNN extracts latent features from input node attributes balanced through data synthesis using a conditional generative adversarial network (GAN) and data fusion strategy. The GNN and GAN are trained synchronously to ensure GAN synthesizes samples that match real data distribution, while GNN adjusts to the quality of synthesized data in a timely manner. A data fusion strategy combines synthetic and real samples to mitigate class imbalance and maintain classification accuracy. Experiments on several benchmark graph datasets demonstrate that the GNN-GAN consistently outperforms state-of-the-art baselines. A comprehensive ablative study further validates the advantages of the synchronized training procedure, offering insights into the model's robustness across graph datasets with varying structures and imbalance ratios.},
  archive      = {J_EAAI},
  author       = {Xiaoqi Zhou and Peixin Shi},
  doi          = {10.1016/j.engappai.2025.112264},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112264},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph neural network with generative adversarial training for node classification on class imbalanced data},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-based feature absorption approach for improving lightweight object detectors in adverse weather conditions. <em>EAAI</em>, <em>161</em>, 112263. (<a href='https://doi.org/10.1016/j.engappai.2025.112263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although cutting-edge lightweight detectors have achieved desirable performance in favorable weather conditions, they again failed to accurately identify objects within low-quality scenes captured in inclement environments, especially during rainy nighttime. These detectors face difficulties learning beneficial information for detection because objects are obscured by rain and low-light conditions. To address the aforementioned challenges, we introduce an innovative and effective Diffusion-based Feature Absorption Learning (Diff-FAL) approach, to reinforce the performance of lightweight detection models in nighttime with rain interference. By developing an unsupervised training strategy based on the diffusion model, the proposed approach assists lightweight detectors absorb useful features from degraded images. To this end, our Diff-FAL framework comprises three distinct subnetworks: a Feature Optimization (FO) subnetwork, a Feature Mutation (FM) subnetwork, and a Lightweight Detection (LD) subnetwork. The FO subnetwork is designed to produce sharp, detailed features from rainy night images and the FM subnetwork is developed to transfer those features to the LD subnetwork. Comprehensive experiments on various datasets confirmed the superiority of our model, outperforming the compared method by up to 28.01% and 30.16% in accuracy on two published datasets: the rainy nighttime (RNT) and real rainy images (rRain) datasets, respectively, while maintaining high-speed performance during inference.},
  archive      = {J_EAAI},
  author       = {Quoc-Viet Hoang and Trung-Hieu Le},
  doi          = {10.1016/j.engappai.2025.112263},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112263},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Diffusion-based feature absorption approach for improving lightweight object detectors in adverse weather conditions},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-modal model for removal of crack image shadow based on language prior information. <em>EAAI</em>, <em>161</em>, 112262. (<a href='https://doi.org/10.1016/j.engappai.2025.112262'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-vision based crack detection highly depends on the quality of images and it remains to be a challenging task due to the effects of shadow. The utilization of deep learning algorithm, guided by prior information, has been demonstrated effective in the removal of shadows. However, it has limitations in handling images with shadowed cracks. A deep learning method incorporating language prior information and a multi-modal model is proposed in this study to improve the removal of shadow effects in restoring the crack images. Natural language processing (NLP) is used to extract the language prior information from image text description to enhance the crack recognition, and OTSU method is used to obtain the image prior information. A novel multi-modal model, named as the Text-based Shadow Removal Network (TSRNet), for the removal of shadow in crack image, is proposed to have better crack restoration capability. Bayesian optimization approach is also employed to optimize the network architecture improving the prediction precision of TSRNet. The proposed framework for shadow removal is verified using an open-source shadowed concrete crack image dataset and a new dataset from experiment. Results indicate that the language prior information can enhance the TSRNet model with better performances of shadow removal for real-world crack images compared with other existing models.},
  archive      = {J_EAAI},
  author       = {Gang Liu and Xuming Li and Qingshan Yang and S.S. Law and Changjun Deng},
  doi          = {10.1016/j.engappai.2025.112262},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112262},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-modal model for removal of crack image shadow based on language prior information},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development and implementation of a hybrid visual prediction algorithm for robotic smart tomato harvesting. <em>EAAI</em>, <em>161</em>, 112261. (<a href='https://doi.org/10.1016/j.engappai.2025.112261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces new algorithms designed specifically for smart tomato harvesting, which combines predictions from two independently trained YOLOv8 (You Only Look Once version 8) models, each specialized on different datasets to detect tomatoes and classify their ripeness stages—ripe, unripe, and semi-ripe—while also computing their center points. To enhance detection accuracy under varying field conditions, multiple fusion strategies were developed, including a hybrid algorithm that integrates union and confidence-weighted summation methods. The Hybrid Algorithm achieved the best performance, surpassing the original models and other fusion techniques. It attained F1 scores of 0.697 and 0.694 at confidence thresholds of 0.5 and 0.9, respectively, compared to the original models' F1 scores of 0.670 and 0.648 at confidence 0.5, and 0.481 and 0.497 at confidence 0.9. This corresponds to an improvement of 4.0 % and 7.6 % at confidence 0.5, and 44.3 % and 39.6 % at confidence 0.9, demonstrating the hybrid algorithm's stability and superiority, particularly at higher thresholds. Furthermore, the system utilizes a high-resolution RGB (Red, Green, Blue) camera for real-time image capture, enhancing model performance in complex agricultural environments. This study validates the effectiveness of confidence-based fusion in developing robust and accurate vision systems for precision agriculture.},
  archive      = {J_EAAI},
  author       = {Giuseppe Carbone and Angad Singh Gurtatta and Dmitry Malyshev},
  doi          = {10.1016/j.engappai.2025.112261},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112261},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development and implementation of a hybrid visual prediction algorithm for robotic smart tomato harvesting},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal multi-level feature representation learning for flow pattern identification of oil-water two-phase flow. <em>EAAI</em>, <em>161</em>, 112260. (<a href='https://doi.org/10.1016/j.engappai.2025.112260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the difficulty of the traditional experimental methods in real-time monitoring and identification of the flow process, this paper introduces a novel flow pattern identification method of the vertical oil-water two-phase flow based on multi-modal multi-level feature representation. The one-dimensional electromagnetic signals are encoded into two-dimensional feature spaces to explore their structural complexity, evolutionary probability laws and nonlinear characteristics in multimodal domain, thereby generating a multi-modal representation of the electromagnetic signals. Subsequently, a multi-modal multi-level feature fusion network is developed for flow pattern identification network, which flexibly leverages effective information across different modalities and levels, thereby enhancing the identifying accuracy. Experimental results demonstrate that the proposed method achieves high accuracy on the constructed multi-modal dataset, proving its feasibility and effectiveness in identifying the flow pattern of the oil-water two-phase flow in vertical pipes.},
  archive      = {J_EAAI},
  author       = {Weihang Kong and Yaohan Chi and He Liu and Hongbao Tang and He Li},
  doi          = {10.1016/j.engappai.2025.112260},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112260},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-modal multi-level feature representation learning for flow pattern identification of oil-water two-phase flow},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Defining and evaluating decision and composite risk in language models applied to natural language inference. <em>EAAI</em>, <em>161</em>, 112253. (<a href='https://doi.org/10.1016/j.engappai.2025.112253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite their impressive performance, large language models (LLMs) are known to pose important risks. One such set of risks arises from misplaced confidence, whether over-confidence or under-confidence, that the models have in their inference. While the former is well studied, the latter is not, leading to an asymmetry in understanding the comprehensive risk of the model based on misplaced confidence. In this paper, we address this asymmetry by defining two types of risk (decision and composite risk), and proposing an experimental framework consisting of a two-level inference architecture and appropriate metrics for measuring such risks in both discriminative and generative LLMs. The first level relies on a decision rule that determines whether the underlying language model should abstain from inference. The second level (which applies if the model does not abstain) is the model’s inference. This framework has direct implications for error-sensitive LLM-based engineering applications where reliable decision-making is critical, such as healthcare and finance. Through detailed experiments on four natural language commonsense reasoning datasets using both an open-source ensemble-based transformer model and a generative LLM, we demonstrate the practical utility of our evaluation framework. Our results show that the framework can get an LLM to confidently respond to an extra 20.1% of low-risk inference tasks that other methods might misclassify as high-risk, and skip 19.8% of high-risk tasks, which would have been answered incorrectly.},
  archive      = {J_EAAI},
  author       = {Ke Shen and Mayank Kejriwal},
  doi          = {10.1016/j.engappai.2025.112253},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112253},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Defining and evaluating decision and composite risk in language models applied to natural language inference},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced machine learning techniques for predicting wear performance in graphene oxide particulate interpenetrating polymer network composites. <em>EAAI</em>, <em>161</em>, 112252. (<a href='https://doi.org/10.1016/j.engappai.2025.112252'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research investigates the wear behavior of hybrid polymeric composites made from synthetic glass and natural cotton fibers, reinforced with varying proportions of Graphene Oxide (GO) (0 %, 1 %, 3 %, 5 %, 7 %, 9 %). The effect of fiber arrangement and Graphene Oxide (GO) incorporation on wear rate and Coefficient of Friction (CoF) was evaluated using the Pin-On-Disk method, with analysis based on Taguchi's L 32 Orthogonal Array. The optimal parameters were found at 6 min, 5 % GO, 300 revolutions per minute (rpm) speed, 20 mm (mm) track diameter, and 10 N (N) load, achieving a minimum wear rate of 0.612 × 10 −4 cubic millimeters per newton-meter (mm 3 /N-m) and a CoF of 0.151. Predictive modeling was performed to predict the wear rate and coefficient of friction using supervised machine learning algorithms, including Linear Regression, Decision Tree, and Random Forest, to forecast material behavior. Performance evaluation using Confusion Matrix, Distribution Analysis, and various metrics showed that the Decision Tree model excelled, achieving near-perfect predictive power with a Mean Squared Error (MSE) of 0 and an R-squared value of 0.9999. The model demonstrated 100 % accuracy, with precision, recall, and F1-scores all equal to 1. This research demonstrates the effectiveness of combining natural and synthetic fibers with GO, along with the predictive power of machine learning in optimizing material properties.},
  archive      = {J_EAAI},
  author       = {Eastus Russel and S. Madhu and Judy S and Edwin Geo Varuvel and G.B. Santhi and G. Suresh and Femilda Josephin J.S and Mohammed F. Albeshr and Farzad Kiani},
  doi          = {10.1016/j.engappai.2025.112252},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112252},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Advanced machine learning techniques for predicting wear performance in graphene oxide particulate interpenetrating polymer network composites},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Health state evaluation and analysis of equipment considering multi-scale data fusion. <em>EAAI</em>, <em>161</em>, 112251. (<a href='https://doi.org/10.1016/j.engappai.2025.112251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current researches of health state evaluation of equipment have increasingly emphasized the integration of data and knowledge to improve evaluation accuracy and interpretability, which leads to the emergence of hybrid information-based methods as a research hotspot. However, there are issues with redundant health indicators, multi-scale data with different features and measurement units, and interpretability measures in the evaluation. In this paper, an interpretable health state evaluation and analysis method of equipment is proposed based on trustworthy evidential reasoning rule (TERR). To deal with redundancy in health indicators, a multi-scale data analysis model is proposed based on the clustering analysis and Kruskal-Wallis test. It can select the optimal health indicators that effectively preserve the original evaluation information while reducing the model complexity. To integrate the selected indicators with uncertainty, a TERR-based multi-scale data fusion model is proposed, where the evidence weight, reliability, and trustworthiness are simultaneously considered. Also, an interpretable parameter optimization model is constructed to alleviate the uncertainty in initial evidential parameters. To study the interpretability of TERR, two sensitivity analysis methods are proposed, and the performance coefficient matrix of the model output to the perturbation is derived mathematically. This shows how the interpretability of TERR is enhanced and which external parameter has the greatest impact on outputs. Finally, a case study of health state evaluation of laser inertial measurement unit (LIMU) validates the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Shuai-Wen Tang and Jiang Jiang and Jian-Bin Sun and Zhuo-Ting Yu},
  doi          = {10.1016/j.engappai.2025.112251},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112251},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Health state evaluation and analysis of equipment considering multi-scale data fusion},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unmanned surface vehicle autonomous racing and obstacle avoidance with robust adversarial deep reinforcement learning. <em>EAAI</em>, <em>161</em>, 112250. (<a href='https://doi.org/10.1016/j.engappai.2025.112250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an autonomous racing control method for Unmanned Surface Vehicles (USVs) based on robust adversarial deep reinforcement learning (ADRL) algorithm, which leverages the strengths of both deep reinforcement learning and adversarial training. Adversarial obstacles and various tracks are employed to train a policy, so the proposed method can enhance the robustness and generalization of autonomous USV racing while ensuring effective obstacle avoidance. A simulation environment for USV racing was developed to conduct the experiments with Unity3D. The performance of the proposed method in handling diverse track scenarios and obstacle avoidance is demonstrated through simulations. Quantitative results show that ADRL achieves dramatic improvements over baseline DRL methods: collision rates are reduced by 99.85%, task completion rates are improved by 73.75%, and navigation time efficiency is enhanced by approximately 3% while maintaining superior safety performance.},
  archive      = {J_EAAI},
  author       = {Jingyu Liu and Yuanda Wang and Changyin Sun},
  doi          = {10.1016/j.engappai.2025.112250},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112250},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unmanned surface vehicle autonomous racing and obstacle avoidance with robust adversarial deep reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale constitutive modeling of anisotropic plasticity: Coupling the visco-plastic self-consistent model with the recurrent neural network and its implementation in finite element analysis. <em>EAAI</em>, <em>161</em>, 112249. (<a href='https://doi.org/10.1016/j.engappai.2025.112249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anisotropic and nonlinear strain-path-dependent nature of metal plasticity poses a major challenge for accurate constitutive modeling in finite element (FE) analysis. Traditional macroscale models are easily implemented but lack accuracy, while crystal plasticity (CP) models offer high fidelity at the cost of computational efficiency. To bridge this gap, we propose a deep neural network smart constitutive (DNNSC) framework that combines the visco-plastic self-consistent (VPSC) model with a gated recurrent unit (GRU) network. A VPSC model calibrated on pure aluminum generated 14,000 strain-paths for training GRU-based network. The optimized model has a prediction accuracy of up to 96 % on unknown strain-paths. Subsequently, the DNNSC model was implemented into the FE analysis through Fortran programming, and a benchmark simulation for thin sheet stamping was successfully performed. The simulation results demonstrated that the DNNSC model significantly improved prediction performance compared to conventional macroscale constitutive models. Especially, the ear height and plate thickness were accurately predicted with an accuracy of 91.85 % and 95.84 %, compared to only 68.85 % and 86.59 % achieved by the Yld model. Meanwhile, the simulation time was reduced to approximately one-tenth that of the fully coupled CP model, because the latter required calculating and homogenizing the mechanical responses of hundreds of grains at each integration point during the simulation. The DNNSC framework bridges the gap between CP models and FE simulations of plastic forming and breaks down the barrier between modeling and practical application. Furthermore, this framework can be extended to other materials by re-calibrating VPSC parameters and fine-tuning DNN parameters.},
  archive      = {J_EAAI},
  author       = {Ziwei Zhou and Liang Cheng and Huaidong Song and Haijing Guo and Ruolin Li and Lingyan Sun and Bin Tang},
  doi          = {10.1016/j.engappai.2025.112249},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112249},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiscale constitutive modeling of anisotropic plasticity: Coupling the visco-plastic self-consistent model with the recurrent neural network and its implementation in finite element analysis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An online reinforcement learning method to improve control adaptability in robot-aided rehabilitation. <em>EAAI</em>, <em>161</em>, 112248. (<a href='https://doi.org/10.1016/j.engappai.2025.112248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rehabilitation robotics enables consistent and personalized therapy but still relies on complex, expert-driven tuning of control parameters. To address this, a reinforcement learning strategy based on Q-learning is proposed to autonomously adapt key parameters during upper-limb rehabilitation, without requiring prior task-specific knowledge. A systematic evaluation is conducted across combinations of control parameters (radial stiffness and execution time), performance-based reward functions (pointing accuracy and movement smoothness), and exploration strategies ( ɛ - greedy and Upper Confidence Bound). The Q-learning agent selects discrete actions (increase, decrease, or maintain the current value) for each control parameter, enabling real-time adaptation based on observed performance. The method is validated using a Kuka robotic arm in experiments involving 16 right-handed healthy subjects (13 males, 3 females) and 8 right-handed individuals simulating impaired motor behavior (5 males, 3 females). Motion signals are acquired through internal robot sensors, while a wearable physiological monitoring system define the Q-learning agent state. Reward improvement and exploration ratio are analyzed as key performance indicators and statistically compared across all tested conditions using the Mann–Whitney test. The results demonstrate that the proposed algorithm effectively adjusts control parameters online, with performance influenced by the reward function, exploration strategy, and selected control actions. Reward improvements of 0 . 11 ± 0 . 09 ( ɛ - greedy , reward based on pointing ability) and 0 . 13 ± 0 . 11 (reward based on smoothness, Upper Confidence Bound strategy) were observed in healthy subjects, indicating enhancements in pointing accuracy and movement smoothness. In simulated pathological cases, improvements of 0 . 08 ± 0 . 13 and 0 . 06 ± 0 . 16 were observed, respectively.},
  archive      = {J_EAAI},
  author       = {Rita Molle and Christian Tamantini and Clemente Lauretti and Emilio Maria Romano and Loredana Zollo},
  doi          = {10.1016/j.engappai.2025.112248},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112248},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An online reinforcement learning method to improve control adaptability in robot-aided rehabilitation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast prediction and compensation of curing deformation behaviours of composite parts with complex geometry based on neural operator on riemannian manifolds. <em>EAAI</em>, <em>161</em>, 112247. (<a href='https://doi.org/10.1016/j.engappai.2025.112247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling the curing deformation of composite parts is becoming increasingly challenging with the ever-increasing performance requirements of aerospace equipment. Mould surface compensation, which adjusts the mould surface to minimise the discrepancy between the cured part geometry and the nominal part geometry, has become a primary deformation control way in engineering. The existing mirror compensation methods focus on the deformation dominated by spring-in and are challenging for complex deformation modes. Surrogate model-based shape optimisation provides a feasible idea, but establishing a surrogate model to predict curing deformation fields on complex part geometries remains a challenge. Therefore, this study explores a novel neural operator-driven framework for fast curing deformation prediction and compensation. A clustering-based deformation field segmentation method is proposed to manipulate the mould surface morphing using limited design variables. The neural operator on Riemannian manifolds is introduced for the first time to establish the surrogate model between the mould surface and the curing deformation fields on complex part geometries. To control the global error distribution of the composite part, two error metrics are designed to optimise the mould surface by genetic algorithm. The verification results show that the proposed framework exhibits significant potential in predicting and compensating for the curing deformation field of composite parts with complex geometry.},
  archive      = {J_EAAI},
  author       = {Lu Chen and Yingguang Li and Jingyan Su and Weiwei Xu and Lin Hu and Gengxiang Chen and Xu Liu and Xiaozhong Hao},
  doi          = {10.1016/j.engappai.2025.112247},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112247},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast prediction and compensation of curing deformation behaviours of composite parts with complex geometry based on neural operator on riemannian manifolds},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced detection of acute leukemia: A hybrid machine learning framework with adaptive weight-optimized level set evolution. <em>EAAI</em>, <em>161</em>, 112244. (<a href='https://doi.org/10.1016/j.engappai.2025.112244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, a novel, multistage framework is developed for the automated detection of Acute Lymphoblastic Leukemia (ALL) and Acute Myeloid Leukemia (AML), addressing challenges due to the inclusion of overlapping cells, noise, and unwanted cells. It integrates an Adaptive Weight-Optimized Level Set Evolution (AWOLSE) scheme to ensures precise and accurate segmentation, coupled with a marker-controlled watershed algorithm to improve performance in regions of cell overlap and contact. It ensures more reliable cell boundary delineation. For classification, a hybrid model combining the strengths of Random Forest (RF) and Support Vector Machine (SVM) is employed that delivering superior performance by leveraging the complementary advantages of these classifiers. Furthermore, feature extraction with the Gray Level Co-occurrence Matrix (GLCM), followed by feature selection with Principal Component Analysis (PCA), aids in the identification of relevant features. The suggested methodology beats its competitors, providing the best ALL identification results on the Acute Lymphoblastic Leukemia Image Database (ALLIDB), with 99.07% accuracy, 97.96% recall, 100.00% specificity, and 100.00% precision. Similarly, on the American Society of Hematology (ASH) database, the technique achieves superior AML identification results with 96.25% accuracy, 95.00% recall, 97.50% specificity, and 97.44% precision.},
  archive      = {J_EAAI},
  author       = {Pradeep Kumar Das and Adyasha Sahu and Sukadev Meher and Rutuparna Panda and Ajith Abraham},
  doi          = {10.1016/j.engappai.2025.112244},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112244},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced detection of acute leukemia: A hybrid machine learning framework with adaptive weight-optimized level set evolution},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based secure tracking control for nonlinear interconnected systems: An event-triggered solution approach. <em>EAAI</em>, <em>161</em>, 112243. (<a href='https://doi.org/10.1016/j.engappai.2025.112243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a secure tracking control method for nonlinear interconnected systems based on reinforcement learning, addressing both security constraints and mismatched conditions in such systems. By utilizing system augmentation techniques, the tracking control problem is reformulated into a stabilization problem for the augmented system, simplifying the original control task. Drawing inspiration from the Chinese philosophical principle, we further transform the problem into a zero-sum game framework. Moreover, a control barrier function (CBF) is incorporated into a cost function to ensure that system trajectories remain within a predefined safe region. An event-triggered mechanism is introduced, and an event-based safety Hamilton–Jacobi–Isaacs (HJI) equation is established. An adaptive single evaluation network is designed, leveraging experience replay techniques to solve the HJI equation. Finally, the Lyapunov method is employed to prove the uniform ultimate boundedness of both the tracking error and the weight error. The effectiveness of the proposed method is validated through numerical examples.},
  archive      = {J_EAAI},
  author       = {Chunbin Qin and Suyang Hou and Mingyu Pang and Zhongwei Wang and Dehua Zhang},
  doi          = {10.1016/j.engappai.2025.112243},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112243},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning-based secure tracking control for nonlinear interconnected systems: An event-triggered solution approach},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A quantized subtraction-convolution network for industrial lightweight edge interpretable diagnosis. <em>EAAI</em>, <em>161</em>, 112241. (<a href='https://doi.org/10.1016/j.engappai.2025.112241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addressing the prevalent challenges of delayed fault diagnosis, deployment complexity of advanced deep learning models on low-cost edge devices, and limited model interpretability, this study proposed an edge-cloud collaborative interpretable diagnosis based on quantized subtraction-convolution network. Firstly, an interpretable quantized subtraction-convolution network with lightweight three-layer structure is designed. Inspired by the adaptive spectral subtraction, a learnable sparse pulse kernel is designed to extract the fault feature as the subtraction layer. Subsequently, the convolution and classification layers are then integrated to produce interpretable results for efficient identification. To facilitate deployment and updates on edge devices, the quantized subtraction-convolution network is decomposed into a lightweight edge architecture and corresponding parameters. It can be deployed on edge devices, and an edge-cloud collaborative framework addresses its training and compression. Considering the sparse characteristics of quantized subtraction-convolution network, a sparse pulse quantization strategy and quantization-aware training technique were developed to compress the model parameters. Finally, a low-cost edge fault diagnosis node prototype with quantized subtraction-convolution network is designed for real-time edge fault diagnosis. Experiments shown that the proposed method achieved average accuracy of 99.88 percent with compression ratio of 9.5. The memory usage, floating-point operations per second, and average power consumption are respectively only 54 kilo binary byte, 0.053 mega binary byte, and 6.67 mJ. Actual gear edge diagnosis experiments confirmed the effectiveness, which can implement model inference in 0.045 s at the edge fault diagnosis node. It is anticipated that the proposed method will find extensive application in the industrial edge interpretable diagnosis.},
  archive      = {J_EAAI},
  author       = {Qihang Wu and Jun Luo and Wenbin Huang and Xiaoxi Ding},
  doi          = {10.1016/j.engappai.2025.112241},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112241},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A quantized subtraction-convolution network for industrial lightweight edge interpretable diagnosis},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight multi-level feature integration transformer for image super-resolution. <em>EAAI</em>, <em>161</em>, 112240. (<a href='https://doi.org/10.1016/j.engappai.2025.112240'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based methods have attracted significant attention in the field of image super-resolution. However, existing approaches typically concentrate on a single level of information for image reconstruction, and neglect the critical role of multi-level information in feature representation, resulting in the low utilization of the potential capabilities of Transformer. To address this limitation, we propose a novel Transformer model, named as Multi-Level Differential Window Attention Transformer (MLDAT), designed for multi-level information fusion. Specifically, our approach introduces a self-attention module based on differential windows to comprehensively extract and integrate feature information across varying window sizes. Additionally, we introduce a High-order Global Attention Module (HGAB) to combine the second-order attention with global self-attention, which facilitates the establishment of relationships between local features and the overall global feature context within an image while complementing local window information. Extensive experimental results demonstrate that our model can significantly improve the performance of image super-resolution , and achieves the better results compared with existing methods.},
  archive      = {J_EAAI},
  author       = {Shuheng Wang and Ziao Gong and Mengda Li and Shen Wu and Yilin He},
  doi          = {10.1016/j.engappai.2025.112240},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112240},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightweight multi-level feature integration transformer for image super-resolution},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional object detection for autonomous driving via deep learning: A review. <em>EAAI</em>, <em>161</em>, 112238. (<a href='https://doi.org/10.1016/j.engappai.2025.112238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of autonomous driving technology, there is an increasing demand for highly accurate and real-time vehicle perception systems. From an artificial intelligence (AI) perspective, three-dimensional (3D) object detection benefits from recent progress in deep neural networks, convolutional neural networks (CNNs), and transformer architectures, which provide powerful tools for feature extraction, spatial reasoning, and multi-modal data fusion. These AI techniques enable robust, uncertainty-aware predictions by effectively modeling complex sensor data. From an engineering standpoint, 3D object detectors serve as critical components in autonomous driving systems by translating AI-derived insights into real-time, high-accuracy vehicle perception. This paper reviews the research progress of deep learning-based 3D object detection algorithms in autonomous driving. First, commonly used data acquisition sensors are systematically categorized, and the most widely adopted 3D detection datasets and evaluation metrics are introduced; the standard 3D bounding-box representation and core network architectures are also explained. Second, algorithms are classified according to input data type: 1) single-modal methods, including vision-based, 3D data dimensionality reduction, point cloud-based, transformer-based, mamba-based, and hybrid point cloud approaches; 2) multi-modal methods, subdivided into serial fusion and parallel fusion strategies within network pipelines. The characteristics, contributions, and limitations of each category are summarized, and representative algorithms are compared across datasets to identify research trends. Finally, current challenges, such as sparse data handling, domain shifts, and real-time constraints, are examined, and prospective directions for future development are proposed.},
  archive      = {J_EAAI},
  author       = {Jiaqi Cai and Yiquan Wu},
  doi          = {10.1016/j.engappai.2025.112238},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112238},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-dimensional object detection for autonomous driving via deep learning: A review},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unscented kalman filter neural network with double-layer decomposition algorithm applied to the prediction of current efficiency in aluminum electrolysis processes. <em>EAAI</em>, <em>161</em>, 112237. (<a href='https://doi.org/10.1016/j.engappai.2025.112237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive modeling in predictive optimization control technology can effectively reduce energy consumption and improve production efficiency in the electrolytic aluminum process (EAP). Among the various modeling approaches, artificial neural networks (ANN) have been widely adopted in the EAP due to their strong capability to capture nonlinear relationships inherent in complex industrial systems. However, conventional ANN heavily rely on historical data to achieve optimal models, which limits their accuracy and generalization performance under strong disturbances and time-varying conditions. To address these problems, this article proposes a novel dynamic prediction model of unscented Kalman filter neural network with double-layer decomposition (UKFNN-DD), building upon the foundation of Kalman filter neural network (KFNN). First, singular value decomposition (SVD) is adopted to compute the square root of covariance matrices, enhancing the numerical robustness of the prediction algorithm and overcoming the shortcomings of traditional Cholesky decomposition. Furthermore, a dual-layer KFNN strategy is introduced to overcome the absence of one-step-ahead prediction in conventional state-space formulations. By applying a two-stage correction to the state variables using measurement data, the proposed method improves the adaptability of the model to external environmental variations. Finally, the prediction error of the state variables is optimized using a gradient descent algorithm, which improves the stability and reliability of the model’s prediction performance. Experimental results demonstrate that the proposed method significantly outperforms baseline methods, achieving a 4.38-fold reduction in mean absolute error (MAE) and a 77.29-fold reduction in the sum of squared errors (SSE), thereby verifying its superiority in dynamic prediction for aluminum electrolysis.},
  archive      = {J_EAAI},
  author       = {Xiaoyan Fang and Xihong Fei and Zhenyi Xu and Lei Su and Jing Wang},
  doi          = {10.1016/j.engappai.2025.112237},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112237},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unscented kalman filter neural network with double-layer decomposition algorithm applied to the prediction of current efficiency in aluminum electrolysis processes},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature super-resolution-based method for small-scale target detection and segmentation in side-scan sonar. <em>EAAI</em>, <em>161</em>, 112235. (<a href='https://doi.org/10.1016/j.engappai.2025.112235'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of side-scan sonar in underwater target detection plays a significant role in marine engineering construction and ocean resource exploration. However, existing methods for small object detection often suffer from limited accuracy and robustness. To address this issue, we propose a feature super-resolution-based approach for detecting and segmenting small targets in side-scan sonar images. During network training, a feature super-resolution branch is first constructed. Both low-level and high-level features from the backbone of the You Only Look Once (YOLO) network are fed into this branch. After processing through an encoder-decoder architecture, a super-resolved feature map is reconstructed, and the network is optimized via backpropagation to enhance the ability to extract features of small targets. Furthermore, an exponential decay strategy is adopted to define the loss weights of different branches, establishing a branch-aware training mechanism to improve training effectiveness. During inference, the super-resolution branch is discarded to balance detection accuracy and inference efficiency. Experimental results demonstrate that the proposed method achieves superior performance in detecting and segmenting small-scale targets in side-scan sonar imagery, achieving state-of-the-art results on two public side-scan sonar small object datasets. Additionally, this approach can be extended as a training strategy for side-scan sonar target detection and segmentation networks. The source code is available at https://github.com/Yang-Code984/FSR_Sonar .},
  archive      = {J_EAAI},
  author       = {Zhiwei Yang and Jianhu Zhao and Xi Zhao and Chao Huang},
  doi          = {10.1016/j.engappai.2025.112235},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112235},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature super-resolution-based method for small-scale target detection and segmentation in side-scan sonar},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven prediction of thermal and flow fields in magnetized boger-micropolar tri-hybrid nanofluids via deep artificial neural networks. <em>EAAI</em>, <em>161</em>, 112232. (<a href='https://doi.org/10.1016/j.engappai.2025.112232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a deep learning framework for predicting the thermal and flow behavior of Boger micropolar tri-hybrid nanofluids under magnetized axial squeezing flow between two parallel disks. The fluid comprises gold, silver, and diamond nanoparticles dispersed in a water-based solution, forming a high-performance ternary hybrid heat transfer medium. A fully connected artificial neural network with three hidden layers (32–16–8 neurons) and hyperbolic tangent activation functions was trained on synthetic data generated using a boundary value problem solver. The model predicts four key physical quantities: axial velocity, streamwise velocity, microrotation, and temperature profile. Quantitative evaluation reveals excellent agreement between machine learning predictions and numerical benchmarks, with mean absolute errors consistently below 0.02 and coefficients of determination exceeding 0.99 across all outputs. Sensitivity analysis reveals the impact of the solvent fraction and vortex viscosity parameters on flow penetration and thermal stratification near the boundaries. This work introduces a novel combination of Boger–micropolar fluid dynamics, magnetohydrodynamic squeezing flow, and tri-hybrid nanoparticles into a unified ANN (Artificial Neural Networks) based surrogate, enabling accurate multi-output prediction of strongly coupled nonlinear fields. The proposed approach offers a scalable machine learning model for real-time optimization of nanofluid-based thermal management systems in engineering applications.},
  archive      = {J_EAAI},
  author       = {Mohammad Jalili and Hesam Ehsani and Ali Mirzagoli Ganji and Amirali Shateri and Mehdi mahboobtosi and Yuping Wu and Payam Jalili and Bahram Jalili and Davood Domiri Ganji},
  doi          = {10.1016/j.engappai.2025.112232},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112232},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven prediction of thermal and flow fields in magnetized boger-micropolar tri-hybrid nanofluids via deep artificial neural networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable knowledge recommendation for product innovation concept design based on knowledge graph and multi-task learning. <em>EAAI</em>, <em>161</em>, 112231. (<a href='https://doi.org/10.1016/j.engappai.2025.112231'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of product innovation concept design, by enhancing the transparency of the knowledge recommendation process and providing designers with explainable recommendation results, decision-making time can be reduced, and design efficiency can be improved. Existing explainable knowledge recommendation methods can generate textual explanation information, but they often overlook the dynamic nature of the design process, which negatively affects the accuracy of the recommendations. To address this issue, the current study proposes a knowledge recommendation method for product innovation concept design based on knowledge graph (KG) and multi-task learning. Specifically, a TransD-based model is first constructed to perform the knowledge graph embedding (KGE) task. Then, KGE and Gated Recurrent Unit (GRU) are used to obtain dynamic knowledge demands across different temporal scales from the historical interactions of designers to enhance recommendation accuracy. A multi-task learning framework is subsequently introduced to enable feature sharing between the two tasks, improving the generalization and effectiveness of the model. Finally, an explanation strategy is designed by combining embedded knowledge and paths to provide optimal explainability information. Experimental results demonstrate that, compared with other state-of-the-art knowledge recommendation algorithms, the proposed method not only offers explainable recommendation results but also achieves higher accuracy, making it more suitable for real-world recommendation scenarios.},
  archive      = {J_EAAI},
  author       = {Yida Hong and Wenqiang Li and Hai Xiang and Chuanxiao Li and Changfu Wan},
  doi          = {10.1016/j.engappai.2025.112231},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112231},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable knowledge recommendation for product innovation concept design based on knowledge graph and multi-task learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards reproducible machine learning-based process monitoring and quality prediction research for additive manufacturing. <em>EAAI</em>, <em>161</em>, 112223. (<a href='https://doi.org/10.1016/j.engappai.2025.112223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive manufacturing (AM) is increasingly adopted across industries for its ability to support design flexibility, rapid prototyping, and mass customization. Machine learning (ML)-based cyber-physical systems (CPSs) have been extensively developed to improve the print quality of AM. However, the reproducibility of these systems has not been thoroughly investigated due to a lack of formal evaluation methods. Reproducibility, a critical component of trustworthy artificial intelligence, is achieved when an independent team can replicate the findings or artifacts of a study using a different experimental setup and achieve comparable performance. In many publications, critical information necessary for reproduction is often missing due to a lack of comprehensive AM and ML domain knowledge, resulting in systems that fail to replicate the reported performance. Integrating AM and ML domain knowledge, this paper proposes a reproducibility investigation pipeline and a reproducibility checklist for ML-based AM process monitoring and quality prediction systems. Based on the CRoss Industry Standard Process (CRISP) methodology, the pipeline guides researchers through the key steps required to reproduce a study, while the checklist systematically extracts information relevant to reproducibility from the publication. We validated the proposed approach through two case studies: reproducing a fused filament fabrication warping detection system and a laser powder bed fusion melt pool area prediction model. Both case studies confirmed that the pipeline and checklist successfully identified missing information, improved reproducibility, and enhanced the performance of reproduced systems. Based on the proposed checklist and leveraging large language models, a reproducibility survey was conducted to assess the current reproducibility status within this research domain.},
  archive      = {J_EAAI},
  author       = {Jiarui Xie and Mutahar Safdar and Andrei Mircea and Bi Cheng Zhao and Yan Lu and Hyunwoong Ko and Zhuo Yang and Yaoyao Fiona Zhao},
  doi          = {10.1016/j.engappai.2025.112223},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112223},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards reproducible machine learning-based process monitoring and quality prediction research for additive manufacturing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Degradation-based predictive energy management for intelligent fuel cell hybrid electric vehicles with a novel deep reinforcement learning architecture. <em>EAAI</em>, <em>161</em>, 112222. (<a href='https://doi.org/10.1016/j.engappai.2025.112222'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The degradation of fuel cell systems (FCS) affects the energy management performance of fuel cell hybrid electric vehicles (FCHEVs), especially in the case of severe degradation. This study develops a novel predictive energy management architecture, which consists of the Extended Long Short-Term Memory (xLSTM) and Soft Actor-Critic (SAC). Specifically, the speed predictor is built using xLSTM network and leverages the speed and position information of the preceding and following vehicles. In order to provide a reliable basis for energy management in degradation scenarios, an FCS degradation model is developed, which enables the dynamic mapping of output efficiency curves under varying state-of-health (SOH) conditions. Sequentially, a SAC-based agent is employed as the energy management strategy (EMS), which innovatively takes full account of the impact of the FCS SOH on energy allocation, achieving proactive degradation-aware energy allocation. Simulation results demonstrate that the developed xLSTM architecture achieves a 71 % improvement in speed prediction accuracy compared to Transformer-based models within the Next Generation Simulation validated scenario. Moreover, at SOH = 90 %, the newly designed EMS reduces operational costs by 8.7 % and 10.7 % compared to conventional methods under the New European Driving Cycle and Worldwide Harmonized Light Vehicles Test Procedure, while decreasing FCS degradation costs by 17 % and 51 %, respectively. The innovative approach not only elevates energy efficiency but also prolongs FCS operational longevity via intelligent SOH-aware, which establishes a new paradigm for lifecycle-optimized energy management in FCHEVs.},
  archive      = {J_EAAI},
  author       = {Zhigen Nie and Zhuangfeng Shi and Yufeng Lian and Hao Song},
  doi          = {10.1016/j.engappai.2025.112222},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112222},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Degradation-based predictive energy management for intelligent fuel cell hybrid electric vehicles with a novel deep reinforcement learning architecture},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Observer based fault tolerant control design for saturated nonlinear systems with full state constraints via a novel event-triggered mechanism. <em>EAAI</em>, <em>161</em>, 112221. (<a href='https://doi.org/10.1016/j.engappai.2025.112221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety plays a crucial role in many promising applications as they must comply with stringent safety regulations while staying within physical limits. Therefore, safety fault-tolerant systems with saturated nonlinearities and input constraints are investigated in this paper. An event-triggered safety fault tolerant control (FTC) method based on adaptive dynamic programming (ADP) is proposed. The constrained state is modeled using a smooth mapping function, thus transforming the original system into an unconstrained framework. A fault observer is designed for unknown actuator faults occurring in the system. When an unknown fault occurs in the system, the actuator is compensated in real time according to the fault. The optimal safety value function is approximated by constructing a single critic neural network (NN). Then, a novel event-triggered mechanism is proposed, which allows the algorithm to obtain the optimal control law without constructing the event-triggered Hamilton–Jacobi–Bellman (HJB) equation. In addition, by adjusting the size of the parameter τ under the event triggered condition, different demands on the number of event triggers are realized, which in turn ensures the efficient use of resources while leading to the trade-off of optimal control. This paper also incorporates an empirical playback technique in the design of the critic’s update law to address the challenges associated with continuous incentive requirements. It is theoretically proven that all signals of the system are consistent with the limit bounds, thus ensuring the stability of the system.},
  archive      = {J_EAAI},
  author       = {Chunbin Qin and Mingyu Pang and Zhongwei Wang and Suyang Hou and Dehua Zhang},
  doi          = {10.1016/j.engappai.2025.112221},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112221},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Observer based fault tolerant control design for saturated nonlinear systems with full state constraints via a novel event-triggered mechanism},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cybersecurity enhancement using conditional generative adversarial network with transformer-based conditional variational autoencoder. <em>EAAI</em>, <em>161</em>, 112220. (<a href='https://doi.org/10.1016/j.engappai.2025.112220'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since, Artificial Intelligence is highly developing and concatenating into several domains, cybersecurity is an important field of delivering both the advantages and disadvantages. In addition to this, Artificial Intelligence is applied in a wide variety of applications like healthcare sector, content creation and entertainment and financial industries. Therefore, this work finds the efficiency of Artificial Intelligence -oriented cybersecurity metrics in succeeding the digital environment over elevating cyber threats. Here, the developed models consist of two different stages while implementing the model. In the first stage, the essential dataset is assembled from the benchmark data source. These datasets are assembled by using Generative Artificial Intelligence (Gen Artificial Intelligence networks). Consequently, the raw data is given as an input to Conditional Hybrid Network for cybersecurity enhancement. Further, the Transformer-based Conditional Variational Autoencoders with Spatial-temporal Attention are designed for feature extraction that is subjected to the Conditional Generative Adversarial Network for classifying the cyber attacks. Henceforth, the developed network is evaluated and designed with multiple measures. Comparing baseline models, the suggested network obtains higher performance for developing security over cyber networks.},
  archive      = {J_EAAI},
  author       = {Prithvipal Singh and Sandeep Singh and Gurupdesh Singh and Amritpal Singh},
  doi          = {10.1016/j.engappai.2025.112220},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112220},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cybersecurity enhancement using conditional generative adversarial network with transformer-based conditional variational autoencoder},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modal transfer enhanced deep learning for structural dynamic response with sparse spatial data. <em>EAAI</em>, <em>161</em>, 112218. (<a href='https://doi.org/10.1016/j.engappai.2025.112218'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse spatial data in structural health monitoring (SHM) presents significant challenges due to large spatial gaps and high uncertainty, which hinder the generalization ability and performance of traditional data-driven methods that rely on dense sensor networks. To address this issue, this paper proposes a novel modal transfer-enhanced deep learning (MT-DL) model for the reconstruction and prediction of structural dynamic responses. The core idea is to integrate physical modal information (mode shapes) into the deep learning framework via transfer learning. This integration enables the model to capture the spatial correlation among structural nodes, even under extremely limited data conditions. The MT-DL model is initially validated on a simply supported beam with varying stiffness, where it demonstrates significantly higher reconstruction accuracy compared to both conventional deep learning (DL) approaches and the graph convolutional network (GCN) model under sparse sensor conditions. To demonstrate the model's robustness and generalizability, it is further applied to the dynamic response reconstruction of a continuous beam subjected to moving loads, a plate with complex boundary conditions under impact loading, and a slender flexible riser undergoing vortex-induced vibration (VIV). The results show that the proposed MT-DL model, by incorporating physical principles into data-driven learning, not only enhances prediction accuracy with minimal data but also offers improved physical interpretability. This approach provides a promising solution for structural monitoring in scenarios where dense sensor instrumentation is impractical or cost-prohibitive.},
  archive      = {J_EAAI},
  author       = {Yangyang Liao and Yajuan Xie and Hesheng Tang and Zihan Xia and Songtao Xue},
  doi          = {10.1016/j.engappai.2025.112218},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112218},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A modal transfer enhanced deep learning for structural dynamic response with sparse spatial data},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep learning pipeline for coronary artery analysis in X-ray angiography. <em>EAAI</em>, <em>161</em>, 112217. (<a href='https://doi.org/10.1016/j.engappai.2025.112217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X- ray angiography is a primary and essential assistive method for the accurate diagnosis of coronary blockage. Segmentation of coronary arteries and analysis of coronary artery blockage are the two primary tasks performed by cardiologists. We have proposed Coronary Artery Segmentation, Blockage Detection, and Measurement (CASBloDaM) a state-of-the-art pipeline integrated deep learning framework with conventional image processing techniques to achieve accurate coronary artery analysis in X-ray angiographic images. A new private dataset of 214 X-ray angiographic images is prepared for training, validation, and testing of the model by manual pixel annotation. The UNet3+ deep learning model is trained on X-ray angiographic images for accurate artery segmentation while multiple image processing techniques are developed to perform blockage detection and measurement. The model shows excellent performance in artery segmentation and the dice score of 0.989, accuracy of 0.985, specificity of 0.913 and sensitivity of 0.847 is achieved during the testing which is superior when compared against the previous reported works. An accuracy of 0.853, 0.882 and 0.725 are achieved by the proposed catheter detection, sub-artery removal and blockage detection algorithms respectively when evaluated for 150 test images. The proposed methodology achieved a Mean Square Error (MSE) of 28.66 and an R-square of 0.81 for blockage percentage estimation, and an MSE of 69.91 with an R-square of 0.99 for blockage location, compared to manual calculations. The novelty of the present work is the end-to-end integrated framework which can accurately perform coronary artery analysis in X-ray angiographic images and propose its clinical usage.},
  archive      = {J_EAAI},
  author       = {Karan V. Padariya and Abhishek Raval and Pranay Soni and Harsh Kapadia},
  doi          = {10.1016/j.engappai.2025.112217},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112217},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel deep learning pipeline for coronary artery analysis in X-ray angiography},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-teacher knowledge distillation-based framework for long-term respiratory monitoring and prediction with a novel flexible wearable sensor in healthcare engineering. <em>EAAI</em>, <em>161</em>, 112216. (<a href='https://doi.org/10.1016/j.engappai.2025.112216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Respiratory monitoring plays a critical role in early health warnings and preventive care, offering significant potential for advancements in healthcare engineering. Wearable respiratory monitoring devices, known for their compact design, portability, and real-time capabilities, face challenges such as limited long-term comfort, environmental interference, and signal inaccuracies. In this study, we propose a novel wearable respiratory monitoring framework, RAMP, which integrates an innovative artificial muscle-based flexible sensor system with advanced deep learning modules. The system is designed to reconstruct and analyze respiratory data across various human activities and predict long-term respiratory function. Utilizing a multi-teacher knowledge distillation mechanism, the framework optimizes a student model for enhanced prediction accuracy. Experimental results demonstrate the mean absolute percentage error (MAPE) of 7.28 and mean absolute error (MAE) of 11.92, highlighting the feasibility and effectiveness of system. This work advances the development of portable health monitoring devices and provides a robust foundation for long-term respiratory activity assessment and forecasting, contributing to the broader field of healthcare engineering and personalized medicine.},
  archive      = {J_EAAI},
  author       = {Ke Li and Qing Wang and Haoke Liu and Mingke Wang and Suiyuan Zhu and Xiang Wang and Jing Qin},
  doi          = {10.1016/j.engappai.2025.112216},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112216},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-teacher knowledge distillation-based framework for long-term respiratory monitoring and prediction with a novel flexible wearable sensor in healthcare engineering},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic mask network based on spiking neural convolutional model for missing modality brain tumor segmentation. <em>EAAI</em>, <em>161</em>, 112215. (<a href='https://doi.org/10.1016/j.engappai.2025.112215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor segmentation is a medical image processing task aimed at accurately locating and isolating tumor regions from brain scan images (e.g., Magnetic Resonance Imaging, MRI) in order to help doctors in diagnosis, treatment planning and surgical navigation. Automatic brain tumor segmentation is extremely challenging due to incomplete feature representation in the case of missing modalities and insufficient inter-modal information interaction. To this end, this paper proposes a novel dynamic threshold mask Transformer network for the missing modality brain tumor segmentation task, which is designed based on the nonlinear spiking neural convolutional model. The network consists of four independent encoders and a shared decoder to extract the features of each modality and perform shared representation learning. Among them, the dynamic threshold mask Transformer introduces learnable embedding vectors, generates dynamic masks on top of static masks to achieve fine-grained feature filtering, and enhances the ability of inter-modal information interaction. The adaptive gating weighting module and the channel cross spiking neural P attention module fuse modal features layer by layer in both spatial and channel dimensions to strengthen the modeling capability of local and global features. We conducted extensive comparative experiments on different missing modal cases in the BraTS2020 and BraTS2018 datasets. The experimental results show that the method effectively improves the robustness of missing modalities and the performance of brain tumor segmentation while maintaining the computational efficiency, and has good generalization ability and practicality.},
  archive      = {J_EAAI},
  author       = {Junjie Li and Rui Cai and Bing Li and Hong Peng},
  doi          = {10.1016/j.engappai.2025.112215},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112215},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic mask network based on spiking neural convolutional model for missing modality brain tumor segmentation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing accuracy in fall detection and prediction for elderly individuals using ensemble wavelet neural network and maximal overlap discrete wavelet transform. <em>EAAI</em>, <em>161</em>, 112213. (<a href='https://doi.org/10.1016/j.engappai.2025.112213'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Falls are the second-largest risk factor for the health of the elderly. Various researchers have proposed approaches for monitoring health and falls using only the Internet of Things (IoT) and sensors. However, relying on a single sensor limits accuracy in fall risk prediction. Data from multiple sensors can be used to classify human posture through learning-based algorithms stemming from machine learning. Recently, posture-detecting sensors have become increasingly popular, with InvenSense's Inertial Measurement Unit 9250 (IMU 9250) being a notable example for detecting elderly motion and transmitting data to a computer. This paper proposes the Ensemble Wavelet Network Framework (EWNNET) for fall prediction and detection using the Maximal Overlap Discrete Wavelet Transform (MODWT). The inertial measurement unit (IMU) dataset, containing real-time posture data from seven sensors, is split into 80 % for training and 20 % for testing. The EWNNET approach is compared with other machine-learning methods for fall detection, showing improved accuracy, sensitivity, precision, F-score, and specificity, with a 96.7 % classification success rate.},
  archive      = {J_EAAI},
  author       = {Safa Hussein Mohammed and Yangyu Fan and Guoyun Lv and Shiya Liu},
  doi          = {10.1016/j.engappai.2025.112213},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112213},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing accuracy in fall detection and prediction for elderly individuals using ensemble wavelet neural network and maximal overlap discrete wavelet transform},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leakage localization methodology based on dynamic pressure signal for subsea pipeline. <em>EAAI</em>, <em>161</em>, 112212. (<a href='https://doi.org/10.1016/j.engappai.2025.112212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leakage is one of the most critical failure forms of subsea pipeline. The accurate leakage localization is of great significance to ensure the safe and reliable transportation of subsea pipeline. Leakage locations are considered to be discretely distributed along the subsea pipeline. However, an overabundance of nodes in leakage localization model is caused by excessive discretization. The performance of a leakage localization model with much localization points is poor. Furthermore, the data collected in site usually contains a lot of noise which reduce the effectiveness of leakage localization. A leakage localization methodology based on dynamic pressure signal for subsea pipeline is proposed in this paper. A noise reduction model based on variational mode decomposition (VMD) algorithm combined with power spectral density (PSD) is established to reduce noise of leakage signal. An improved K-means grouping model is developed to mining data for inherent similarity and cluster leakage characteristic. It improves robustness of the leakage localization model. A radial basis function (RBF) neural network leakage localization model optimized by the pelican optimization algorithm (POA) is used to identify the location of leakage. A leakage experiment is used to study performance of this methodology. The localization accuracy of the proposed leakage localization methodology is more than 90 %, the localization error is less than 16 cm. After neural network combined with improved grouping model, average leakage localization accuracy increased by 15.65 %, average absolute error decreased 8.64 cm. The proposed methodology provides an effective tool for leakage localization of critical equipment in subsea production system.},
  archive      = {J_EAAI},
  author       = {Guowei Ji and Baoping Cai and Xuelin Liu and Yi Jiang and Yixin Zhao and Qingping Li and Lei Gao and Kaizheng Wu},
  doi          = {10.1016/j.engappai.2025.112212},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112212},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leakage localization methodology based on dynamic pressure signal for subsea pipeline},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing entity and relation extraction with dynamic hard negative augmentation framework. <em>EAAI</em>, <em>161</em>, 112211. (<a href='https://doi.org/10.1016/j.engappai.2025.112211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity and relation extraction, a fundamental task in information extraction, plays a crucial role in modeling unstructured text by identifying meaningful entities and their semantic relationships. While existing methods have shown effectiveness, they still face challenges in accurately identifying entity boundaries and extracting complex relationships. These challenges primarily arise from current contrastive learning approaches, which uniformly handle all negative samples in boundary detection and relation extraction without emphasizing the learning of hard negative samples. Additionally, the scarcity of hard negative samples limits the exploration of the state space near the anchors. To tackle these challenges, we introduce Dynamic Hard Negative Augmentation, an innovative framework designed to strategically explore and generate hard negative samples, thereby enhancing the learning of challenging cases through adaptive contrastive learning. During the negative sample augmentation process, we employ adversarial training to explore underrepresented areas of hard negative samples, generating a comprehensive coverage of the hard negative sample space to effectively explore the state space. We further introduce a dynamic enhancement mechanism that continuously optimizes the proportion of hard negative samples during training, ensuring targeted learning of these challenging cases.},
  archive      = {J_EAAI},
  author       = {Qibin Li and Shengyuan Bai and Nai Zhou and Nianmin Yao},
  doi          = {10.1016/j.engappai.2025.112211},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112211},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing entity and relation extraction with dynamic hard negative augmentation framework},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NashDQNSleep: Nash-based deep Q-network adaptive sleep scheduling for energy efficiency and age of information optimization in industrial internet of things. <em>EAAI</em>, <em>161</em>, 112210. (<a href='https://doi.org/10.1016/j.engappai.2025.112210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fresh and timely data is essential for the sustainable operation of Industrial Internet of Things (IIoT) systems, which support real-time monitoring and decision-making tasks. Sensor nodes typically need to remain active for long durations to maintain data freshness, resulting in high energy consumption. Traditional sleep scheduling methods often trade off energy savings with data freshness, and many rely on centralized sink-node coordination, which can create communication bottlenecks and increase energy use. This paper introduces NashDQNSleep , a novel decentralized sleep scheduling algorithm that uniquely combines game-theoretic modeling with deep reinforcement learning to address these challenges. Unlike conventional DQN approaches that optimize node behavior independently or centrally, NashDQNSleep formulates the scheduling problem as a general-sum stochastic game and uses Deep Q-Networks (DQNs) to compute Nash equilibria. This enables sensor nodes to make autonomous, yet strategically coordinated decisions based on peer-to-peer information exchange, achieving a stable and efficient balance between energy consumption and data freshness without centralized control. Extensive simulations on diverse IIoT network topologies demonstrate that NashDQNSleep improves energy efficiency by up to 35%, reduces Age of Information (AoI) by 40%, and increases successful data transmissions by 15%–20% compared to state-of-the-art decentralized and centralized methods. These results establish NashDQNSleep as an effective, scalable, and practical solution for reliable and sustainable IIoT operations.},
  archive      = {J_EAAI},
  author       = {Partha Sarathi Banerjee and Soumyapriya Goswami and Debashis De},
  doi          = {10.1016/j.engappai.2025.112210},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112210},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {NashDQNSleep: Nash-based deep Q-network adaptive sleep scheduling for energy efficiency and age of information optimization in industrial internet of things},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel contrastive learning framework for multi-parameter optimization in 3D printing. <em>EAAI</em>, <em>161</em>, 112209. (<a href='https://doi.org/10.1016/j.engappai.2025.112209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive manufacturing (3D printing) revolutionizes prototyping and production through unparalleled material efficiency. However, part quality remains highly sensitive to parameter variations, where subtle deviations induce defects, material waste, and process instability. Traditional quality control methods – reliant on rule-based heuristics or manual inspections – fail to address complex multi-parameter interactions and fine-grained anomalies, limiting industrial scalability. This article focuses on an important issue in 3D printing: How can we develop a robust, automated framework to simultaneously detect and classify subtle multi-parameter anomalies in 3D printing, overcoming the limitations of manual and single-defect-focused approaches? We propose a supervised contrastive learning framework integrating Vision Transformers (ViT) to learn discriminative feature representations for multi-parameter optimization. By maximizing intra-class similarity and inter-class separation, our model captures nuanced variations across printing scenarios. The ViT architecture processes real-time printing images, while contrastive loss ensures compact feature clusters for “Low”, “Optimal”, and “High” parameter classes. Experimental evaluations on open-source datasets demonstrate our framework achieves 8.45% accuracy, outperforming conventional CNNs by 10.11%. Real-world validation shows robust performance across critical parameters: flow rate (86.5% accuracy in nominal ranges), feed rate (87% accuracy), and extrusion temperature (90% accuracy at optimal settings). The ViT’s self-attention mechanism enables precise detection of localized anomalies, such as under-extrusion and layer misalignment.},
  archive      = {J_EAAI},
  author       = {Jieyang Peng and Simon Kreuzwieser and Dongkun Wang and Andreas Kimmig and Zhi Fan and Jianing Li and Jivka Ovtcharova},
  doi          = {10.1016/j.engappai.2025.112209},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112209},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel contrastive learning framework for multi-parameter optimization in 3D printing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight model based on multi-scale feature fusion for ultrasonic welding surface defect detection. <em>EAAI</em>, <em>161</em>, 112208. (<a href='https://doi.org/10.1016/j.engappai.2025.112208'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasonic welding technology is crucial in industrial and medical fields, relying on precise surface defect detection for quality assurance. Traditional methods suffer from low accuracy, efficiency, high costs, and complex implementation. Additionally, current neural networks for ultrasonic surface defect detection struggle to balance parameter optimization with detection accuracy. To solve this problem, we proposed a lightweight model based on multi-scale feature fusion for the Ultrasonic Weld Surface Defect Detection Network (UWSDNet). First, the feature extraction module with reparameterization technology (FRT) and application of efficient multi-scale attention (EMA) are proposed to alleviate network redundant parameters and computational overhead brought by welding background. Secondly, the multi-core feature enhancement module (MCM) is introduced. It enhances multi-scale object detection with fewer parameters to cope with the actual edge deployment of ultrasonic welding. Finally, the lightweight asymmetric detection head (LADH) and contextual and spatial feature calibration network (CSFCN) are introduced into the network. To improve the multi-core dimensional feature capture capability, to solve the problem of large size span of ultrasonic welding surface defects. Experimental evaluations on a self-built ultrasonic welding wire harness defect dataset show that UWSDNet achieves the mean average precision (mAP) of 88.9%, the precision of 95.6% with parameters of 12.7M. In addition, UWSDNet achieves excellent performance on the publicly available NEU-DET dataset, demonstrating strong generalization and application potential in industrial defect detection.},
  archive      = {J_EAAI},
  author       = {Rui Liu and Lun Zhao and Yu Ren and Zhonghua Shen and Liya Li and Jianfeng Luo and Zeshan Abbas},
  doi          = {10.1016/j.engappai.2025.112208},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112208},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight model based on multi-scale feature fusion for ultrasonic welding surface defect detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial neural network solution for magnetohydrodynamic ternary hybrid second-grade nanofluid in rotating jeffery-hamel flow under heat generation: Entropy generation analyses. <em>EAAI</em>, <em>161</em>, 112207. (<a href='https://doi.org/10.1016/j.engappai.2025.112207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research-work examines entropy generation in Magnetohydrodynamic (MHD) ternary hybrid nanofluid under rotating Jeffery-Hamel flow with heat generation alongside thermal radiation. Using appropriate similar transformation equations, the original partial differential equations (PDEs) are converted into nonlinear ordinary differential equations (ODEs), while Artificial Neural Networks (ANNs), which highly extensively used as universal function approximators, is considered in this investigation. In fact, to provide efficient solutions for the nonlinear transformed problem of the magnetohydrodynamic ternary hybrid second-grade nanofluid in rotating Jeffery-Hamel flow, solvers consider log-sigmoid, radial basis and tan-sigmoid activation functions, optimized with an interior point method to generate optimal weights of each considered ANN model. The model relies on assumptions of incompressible steady flow together with negligible viscous energy loss and usage of Rosseland radiation approximation. The predictions made through the Artificial Neural Network (ANN) match numerical benchmarks successfully thus demonstrating better accuracy when modeling velocity, temperature and entropy profiles. The research data indicates that systems attaining better thermal qualities operate effectively under elevated nanoparticle levels and radiation conditions which provides fundamental knowledge to enhance thermal system design. The results from the proposed schemes match numerical solutions precisely thus showing their high accuracy for evaluating ternary hybrid nanofluid flow and heat behavior. Results show that the velocity and temperature profiles of the Magnetohydrodynamic (MHD) ternary hybrid nanofluid reveal significant improvements at higher thermal volume fractions of nanoparticles. The rate of flow increases, perhaps because inertial forces prevail over viscous forces, thereby improving flow dynamics. With higher Radiation numbers associated with higher permeability, the local temperature gradients decrease promoting heat transfer rates within the fluid.},
  archive      = {J_EAAI},
  author       = {Nouar Ahcene and Amar Dib and Farhan Lafta Rashid and Kezzar Mohamed and Mohamed Rafik Sari and Manal Elzain and Hamiden Abd El-Wahed Khalifa},
  doi          = {10.1016/j.engappai.2025.112207},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112207},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial neural network solution for magnetohydrodynamic ternary hybrid second-grade nanofluid in rotating jeffery-hamel flow under heat generation: Entropy generation analyses},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent compound fault decoupling of rolling bearing based on parallel capsule network. <em>EAAI</em>, <em>161</em>, 112206. (<a href='https://doi.org/10.1016/j.engappai.2025.112206'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complex working environment of rolling bearings, various components such as inner ring, outer ring, rolling element and cage in bearing may interact with each other, leading to a compound fault formed by a variety of single fault coupling. Most methods generally regard compound faults as single faults, ignoring the interaction between single faults, which is not conducive to decoupling compound faults into multiple single faults and formulating maintenance plans. Moreover, the capsule network requires stacking multiple capsule layers to enhance performance, which significantly increases model parameters and consumes substantial memory resources. Therefore, a compound fault intelligent decoupling method based on parallel capsule network combining dynamic routing and attention routing is proposed in this study. Firstly, the Omni-Scale block is added to the feature extraction part, which can cover different sizes of receptive fields to enhance the feature extraction ability of the network. Secondly, an attention routing module is proposed, which realize the transmission of information from low-level capsules to high-level capsules by calculating the correlation between the same layers. Finally, the parallel capsule decoupling layer is constructed by using dynamic routing and attention routing. This method is especially suitable for practical engineering scenarios where compound bearing fault samples are limited and computational resources are constrained, providing a lightweight and effective solution for intelligent fault diagnosis. Experimental results show that the proposed method significantly reduces model complexity while maintaining high diagnostic performance under small-sample conditions, with the ablation study further confirming the meaningful contribution of each core module.},
  archive      = {J_EAAI},
  author       = {Renwang Song and Chenyu Jiao and Hui Shi and Linying Chen},
  doi          = {10.1016/j.engappai.2025.112206},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112206},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent compound fault decoupling of rolling bearing based on parallel capsule network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning-based strategic bidding in electricity markets via variational autoencoder-assisted competitor behavior learning. <em>EAAI</em>, <em>161</em>, 112205. (<a href='https://doi.org/10.1016/j.engappai.2025.112205'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a deregulated electricity market, self-interested producers have incentives to offer strategically for maximizing their own profits. While deep reinforcement learning (DRL) has shown great potential for solving such strategic bidding problems, existing methods typically oversimplify strategic action spaces and neglect the influence of competitors' offering behaviors. To bridge these gaps, this paper proposes a novel DRL-based framework to model and solve the strategic bidding problem of an individual producer by jointly considering price-quantity offering actions and the dynamic behaviors of market competitors. First, a bilevel optimization model is formulated to incorporate offering actions on price-quantity pairs. Then, a data-driven framework that combines a variational autoencoder with a density-based clustering method is proposed to learn and capture competitors' offering behaviors. Finally, an imitation learning-integrated DRL algorithm is developed to improve learning stability and solution quality for strategic bidding with price-quantity actions and competitors' offering behaviors. Case studies on the IEEE-30 bus system show that the proposed framework obtains a 28.12 k$ (24.25 %) increase in average profit compared to the existing approach, demonstrating its effectiveness and adaptability under dynamic market conditions.},
  archive      = {J_EAAI},
  author       = {Fei Hu and Yong Zhao and Yaowen Yu and Yuanzheng Li},
  doi          = {10.1016/j.engappai.2025.112205},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112205},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement learning-based strategic bidding in electricity markets via variational autoencoder-assisted competitor behavior learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep-supervised framework utilizing edge features and global texture features for distortion rectification in fisheye images. <em>EAAI</em>, <em>161</em>, 112204. (<a href='https://doi.org/10.1016/j.engappai.2025.112204'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fisheye cameras, with their ultra-wide field of view, are increasingly deployed in urban environments. However, the severe radial distortion inherent in fisheye imagery presents formidable challenges for downstream computer vision tasks, including object recognition, motion estimation, and semantic segmentation. To address this issue, a deeply supervised framework for distortion rectification that leverages edge features and global texture information (DR-EGT) is proposed, which uniquely integrates edge-aware structural features with global texture information under a unified deep supervision strategy. Unlike conventional approaches that rely solely on texture priors or geometric assumptions, DR-EGT introduces a hierarchical supervision mechanism that simultaneously leverages low-level edge contours and high-level texture semantics to guide the distortion correction process. This joint supervision enables the network to learn the distortion flow field of the entire image, which facilitates the reconstruction of geometrically accurate and perceptually sharp undistorted images. On the Places2 dataset, DR-EGT outperforms existing advanced methods, achieving a 12.12 % increase in PSNR (Peak Signal-to-Noise Ratio), 7.44 % improvement in SSIM (Structural Similarity Index Measure), 16.42 % reduction in MAE (Mean Absolute Error), and a 78.17 % gain in FID (Fréchet Inception Distance), demonstrating its superior reconstruction fidelity and perceptual quality. The results demonstrate the ability of DR-EGT not only correct complex fisheye distortion but also suppress post-correction artifacts and visual degradation.},
  archive      = {J_EAAI},
  author       = {Yicheng Chen and Shuang Li and Yuhuan Gu and Chang Feng and Changhai Zhai},
  doi          = {10.1016/j.engappai.2025.112204},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112204},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep-supervised framework utilizing edge features and global texture features for distortion rectification in fisheye images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectrum prior-based and visibility fusion method for underwater image enhancement. <em>EAAI</em>, <em>161</em>, 112203. (<a href='https://doi.org/10.1016/j.engappai.2025.112203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When light propagates in water, it undergoes scattering and absorption phenomena, which typically result in haze, high blur, low contrast and color distortion, making it extremely challenging to obtain high-quality images. To address these issues, many existing methods target image enhancement by correcting specific aspects such as color shift or contrast. However, challenges like poor visibility and low-light conditions are often overlooked. In this paper, we proposed a spectrum prior-based and visibility fusion method (SPV) to enhance underwater images in terms of color, contrast, and visibility. Unlike existing methods, SPV complements the advantages of both physical and non-physical models, comprehensively addressing the problems of reduced visual visibility, color distortion, and low contrast caused by low-light environments, thereby significantly improving the overall image quality. We proposed a dehazing module based on spectral information priors, which reliably restores image quality under complex water conditions. Additionally, we introduced a color correction module based on human color perception and employed morphological operations, effectively solving the issues of color shift and unclear contours in underwater images. Furthermore, we proposed a visibility enhancement module based on the fuzzy c-means clustering method to improve image contrast and visibility, particularly under low-light conditions. Finally, through a detail enhancement fusion module, we simultaneously addressed problems related to color shift, low contrast, and low visibility. SPV showed excellent performance in application tests including feature point matching, geometric rotation estimation, and edge detection. Comparative experiments on four real underwater datasets against 14 advanced enhancement methods demonstrated promising results.},
  archive      = {J_EAAI},
  author       = {Qifeng Liu and Xin Yan and Lu Shen and Qiang Li},
  doi          = {10.1016/j.engappai.2025.112203},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112203},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spectrum prior-based and visibility fusion method for underwater image enhancement},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated multi-criteria decision-making approach with unknown weight information under probabilistic dual-hesitant pythagorean fuzzy environment and its application to supplier selection. <em>EAAI</em>, <em>161</em>, 112202. (<a href='https://doi.org/10.1016/j.engappai.2025.112202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preference ranking organization method for enrichment evaluation (PROMETHEE) has been proved to be one of the most effective techniques to rank alternatives of multi-criteria decision-making (MCDM) problems. However, the existing PROMETHEE cannot accurately adjust the representation range of uncertain information. Besides, the weight determination in PROMETHEE heavily relies on the decision matrix of alternatives on the criteria. Moreover, the information aggregation in PROMETHEE models lacks consideration of the interrelationship among criteria. To address the aforementioned shortcomings, this paper introduces a novel MCDM method that integrates the best-worst method (BWM) and PROMETHEE to help the decision-maker (DM) select the optimum alternative under the probabilistic dual-hesitant Pythagorean fuzzy (PDHPF) environment. Firstly, we extend PROMETHEE method to PDHPF scenario, which not only helps the DM depict subjective evaluations, but also provides the DM with a laxer constraint to present decision information. Secondly, the PDHPF power weighted Hamy mean operator (PDHPFPWHM) is utilized to aggregate the preference information of PROMETHEE. Additionally, the BWM method is utilized and extended to the PDHPF environment for acquiring optimal weights of criteria. The high efficiency and consistency of BWM are well-suited for the complex PDHPF environment. Finally, the method is applied to a semiconductor supplier selection case to demonstrate the validity, superiority, and feasibility of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Huzhi Xue and Haihua Xie and Butian Zhao and Jun Wang},
  doi          = {10.1016/j.engappai.2025.112202},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112202},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An integrated multi-criteria decision-making approach with unknown weight information under probabilistic dual-hesitant pythagorean fuzzy environment and its application to supplier selection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach for understanding the parking demand for internal access roads in hub car parks. <em>EAAI</em>, <em>161</em>, 112201. (<a href='https://doi.org/10.1016/j.engappai.2025.112201'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hubs serve as pivotal nodes within urban transport networks, and the car parks associated with these hubs constitute an integral component. The prevalent practice in China of utilizing internal access roads within car parks for passenger pick-up by online car-hailing vehicles has engendered a novel category of parking demand. However, this development presents a significant challenge to the efficient operation of hub car parks. A thorough analysis and comprehension of the parking demand for internal access roads is essential in devising suitable management strategies to enhance parking efficiency. Initially, this study categorizes the parking demand for internal access roads into three distinct groups, applying parking duration and the number of entries as classification criteria. Subsequently, considering the number of train frequencies, the categorized parking demands are forecasted independently utilizing the Long Short-Term Memory (LSTM) model, complemented by the Shapley Additive exPlanations (SHAP) method for model interpretation. Ultimately, Vector Autoregression (VAR) is employed to investigate the interaction mechanism between the parking demand for parking spaces and the parking demand for internal access roads. The findings indicate that optimal predictive performance is attained when employing a time interval of 15 min and an input step size of 4. Competition between the parking demand for internal access roads and the parking demand for parking spaces primarily occurs within respective categories, underscoring the need for external interventions when these demands are imbalanced.},
  archive      = {J_EAAI},
  author       = {Qianyi Hu and Weidong Liu and Chenyu Yan and Chu Zhang and Jun Chen and Changyin Dong},
  doi          = {10.1016/j.engappai.2025.112201},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112201},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel approach for understanding the parking demand for internal access roads in hub car parks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning for disease-specific prediction of high-cost patients. <em>EAAI</em>, <em>161</em>, 112200. (<a href='https://doi.org/10.1016/j.engappai.2025.112200'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-cost patients incur disproportionately high medical expenses, and identifying them proactively is crucial for effective healthcare management. While previous research has focused on identifying high-cost patients based on overall expenditure, there has been a lack of studies analyzing them in the context of specific diseases. This study addressed this gap by leveraging data from the National Health Insurance Service (NHIS) of South Korea, spanning 2015 to 2019, to develop predictive models for identifying these patients. We trained models using data from 880,000 individuals to predict high-cost patients in 2019 using resource-efficient machine learning algorithms such as Extreme Gradient Boosting (XGBoost), Random Forest (RF), and Neural Networks (NN) that minimize computational overhead, with undersampling techniques applied to handle data imbalance. We focused on the six major disease categories that account for the highest medical expenditures in South Korea: diseases of the musculoskeletal system (DMS), circulatory system (DCS), eye and ear (DEA-DEM), digestive system (DDS), genitourinary system (DGS), and respiratory system (DRS). We discovered that disease-specific analyses revealed important predictive factors that were not apparent in aggregate analyses. For example, hemoglobin levels emerged as crucial predictors for DCS, while body mass index (BMI) proved essential for DMS prediction. These findings enhance our understanding of the factors contributing to high medical costs and provide a foundational framework for healthcare providers and policymakers to develop more targeted and effective health management strategies.},
  archive      = {J_EAAI},
  author       = {Inwoo Tae and Hyeongwoo Kong and Junghye Lee and Yongjae Lee},
  doi          = {10.1016/j.engappai.2025.112200},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112200},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning for disease-specific prediction of high-cost patients},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing mean conditional value-at-risk portfolios through deep neural network stock prediction. <em>EAAI</em>, <em>161</em>, 112198. (<a href='https://doi.org/10.1016/j.engappai.2025.112198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio optimization is essential in financial decision-making, requiring a balance between risk minimization and return maximization. Effective stock selection significantly influences portfolio performance. Traditional methods often struggle to effectively integrate advanced risk assessment techniques with stock selection. To enhance portfolio diversification and improve risk-adjusted returns, this study integrates deep learning-based stock selection with the mean conditional Value-at-Risk (MCVaR) model and entropy constraints to enhance portfolio diversification and risk-adjusted returns. Various deep neural networks, including Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), Multi-Layer Perceptrons (MLP), and Radial Basis Function Neural Networks (RBFN), are employed to rank stocks based on risk and return characteristics. The top-ranked stocks with the lowest risk are selected for portfolio construction. The entropy constraint is introduced to prevent excessive weight concentration, ensuring a well-diversified portfolio. Historical datasets from the Bombay Stock Exchange (BSE), India, B3 Stock Exchange, Brazil, and Shanghai Stock Exchange, China, are used for validation, with performance assessed on an out-of-sample dataset. Additionally, the efficacy of the suggested approach is evaluated by contrasting it with other machine learning and conventional portfolio optimization techniques. Experimental results demonstrate that the LSTM+MCVaR model with entropy constraint consistently outperforms other deep learning and conventional optimization methods, achieving superior cumulative returns and Sharpe ratios. The findings highlight the potential of combining LSTM forecasting with MCVaR optimization and entropy regularization for robust, diversified portfolio construction.},
  archive      = {J_EAAI},
  author       = {Jyotirmayee Behera and Pankaj Kumar},
  doi          = {10.1016/j.engappai.2025.112198},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112198},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing mean conditional value-at-risk portfolios through deep neural network stock prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and analysis of an unbiased intelligent recommendation system for all-rounders in cricket based on multiple criteria decision making. <em>EAAI</em>, <em>161</em>, 112197. (<a href='https://doi.org/10.1016/j.engappai.2025.112197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing and analyzing an unbiased intelligent all-rounder recommendation system in cricket is a critical and complex decision-making task, where performance prediction itself is a crucial issue. The majority of existing works on cricket focus on batsmen, bowlers, and teams. However, performance analyses of all-rounders are hardly found. Hence, the motivation of this paper is to propose an artificial intelligence (AI)-based method for assessing the performance of all-rounders utilizing various multiple-criteria decision-making (MCDM) techniques. With this goal in mind, effective attributes are considered for evaluating all-rounder bowling and batting performances. Case studies using a set of 20 all-rounders have been taken from the recent International Cricket Council (ICC) all-rounders list to determine their ranking. The performance of various MCDM techniques is investigated using ICC rankings, with the Spearman Rank Correlation Coefficient applied to the One Day International (ODI) format. The results indicate that the Criteria Importance Through Intercriteria Correlation (CRITIC)-VlseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR) method yields quite promising insights, achieving a higher correlation with ICC rankings (Spearman Rank Correlation: 0.794) and hence can be used as an intelligent AI-based all-rounder recommendation system. Finally, we have also conducted a sensitivity analysis on the ranking outcomes of all-rounders to examine the utility and robustness of our proposed MCDM approach. The proposed approach is beneficial for team selectors, analysts, and fantasy sports platforms, offering a fairer and more reliable ranking of all-rounders.},
  archive      = {J_EAAI},
  author       = {Nayan Ranjan Das and Imon Mukherjee and Goutam Paul},
  doi          = {10.1016/j.engappai.2025.112197},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112197},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design and analysis of an unbiased intelligent recommendation system for all-rounders in cricket based on multiple criteria decision making},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic analysis-based recommender system using sequential clustering and convolutional neural network. <em>EAAI</em>, <em>161</em>, 112196. (<a href='https://doi.org/10.1016/j.engappai.2025.112196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of user preferences and generation of personalized recommendations remain as critical challenges in intelligent recommendation systems. In this study, we propose a novel recommendation model that transforms the rating prediction problem into a single-label multiclass classification task. The model integrates three key components: (1) ordered clustering information derived from user review text similarity, (2) rating rank similarity reflecting users’ behavioral tendencies, and (3) a convolutional neural network (CNN) to extract semantic representations from user textual data. First, user review embeddings are clustered to capture high-level semantic preferences, where cluster indices are utilized as ordered categorical features. Second, rating rank similarity features are constructed by comparing the relative ranking of items rated by similar users. These features are fused and fed into a CNN model, which outputs a predicted rating class (e.g., 1–5 stars) for each unobserved item, treated as a single-label classification target. To generate final Top-N recommendations, we further incorporate user-specific rating habits and item popularity to re-rank the classification outputs. The experimental results on public benchmark datasets indicate that our model substantially improves the prediction accuracy and recommendation quality compared with existing baselines. The proposed method offers a robust and interpretable approach to bridging textual review semantics, user behavior, and deep learning for rating-aware personalized recommendation.},
  archive      = {J_EAAI},
  author       = {Yanjun Xu and Chunqi Tian and Wei Wang and Lizhi Bai},
  doi          = {10.1016/j.engappai.2025.112196},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112196},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semantic analysis-based recommender system using sequential clustering and convolutional neural network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ranking-oriented cross-modal hashing. <em>EAAI</em>, <em>161</em>, 112195. (<a href='https://doi.org/10.1016/j.engappai.2025.112195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep cross-modal hashing has become a mainstream solution for multimedia retrieval. Most methods utilize pair-wise or multi-wise loss as proxies for ranking consistency, focusing primarily on local relational patterns. However, these schemes are not well aligned with global ranking metrics, which consider the relative order among all candidate items. This misalignment may push semantically similar items down the list. Additionally, such methods heavily rely on the selection of negative samples, which can cause training instability and require careful tuning. To address this problem, we propose a novel Ranking-Oriented Cross-Modal Hashing (ROCMH) framework, which performs global ranking optimization based on a vision-language model. Specifically, we design a differentiable ranking-oriented objective, called cross-modal ranking alignment loss. It smoothly simulates discrete ranking and naturally models ranking relations in candidate lists, thereby promoting more consistent cross-modal ranking. Meanwhile, considering the perceptual gap between visual and textual, we suggest a nanoparam training strategy with modality-aware prompts. This strategy greatly reduces the number of trainable parameters while ensuring that each modality provides unique signals for semantic information learning. Extensive experiments on three public datasets demonstrate that the method achieves superior retrieval performance and reduces the number of trainable parameters to less than 0.2% of the vision-language model. The source code is available: https://github.com/QinLab-WFU/ROCMH .},
  archive      = {J_EAAI},
  author       = {Yadong Huo and Qibing Qin and Wenfeng Zhang and Lei Huang},
  doi          = {10.1016/j.engappai.2025.112195},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112195},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ranking-oriented cross-modal hashing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Matching quality-guided model-free satellite pose estimation. <em>EAAI</em>, <em>161</em>, 112194. (<a href='https://doi.org/10.1016/j.engappai.2025.112194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of learning-based techniques and large-scale public datasets, satellite pose estimation has seen significant progress for the past several years. However, most of current methods still rely on a known three-dimensional (3D) model of the object for the pose estimation, limiting its generalization and wide application. To this end, we propose a model-free pose estimation method, which takes as input only a set of images. The proposed method consists of two stages, i.e. the reconstruction stage and pose estimation stage, of which the former reconstructs a 3D model from the input images and the pose is estimated via two-dimensional (2D)-3D feature matching by the latter. More importantly, a matching quality guidance strategy is introduced to further improve the robustness to in-plane rotation during feature matching. Additionally, since no known 3D model is assumed, our method generalizes well to novel objects without retraining. We provide evaluation results on datasets of several satellites with different structures, which demonstrate impressive performances without known models against current methods.},
  archive      = {J_EAAI},
  author       = {Zhaoshuai Qi and Yating Liu and Yanning Zhang},
  doi          = {10.1016/j.engappai.2025.112194},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112194},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Matching quality-guided model-free satellite pose estimation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prebuilt spatiotemporal index: An exploration of efficient real-time data storage in intelligent transportation systems. <em>EAAI</em>, <em>161</em>, 112193. (<a href='https://doi.org/10.1016/j.engappai.2025.112193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread deployment of Internet of Things (IoT) devices in Intelligent Transportation Systems (ITS), real-time spatiotemporal data has grown rapidly. Hybrid data-bases have emerged as the mainstream solution for managing such data. The LSM R*-tree, which integrates Log-Structured Merge-trees (LSM-trees) for time-series ingestion and R*-trees for spatial queries, is now a widely used spatiotemporal index. However, storage schemes based on LSM R*-tree structures involve real-time index construction, leading to significant overhead and write latency. To address these challenges, this paper proposes a prebuilt index-based data storage workflow that shifts index construction ahead of data writing. This approach allows the database to directly apply the prebuilt index at write time, thereby minimizing real-time construction costs and enhancing write performance. To support index prebuild, we propose a lightweight embedding scheme, Index2Vec, specifically designed for R*-tree structures. Based on this, we extend the Transformer architecture and develop the R*-tree Prediction Network for ITS (RTPN4ITS), which achieves efficient inference on resource-constrained edge devices. Experimental results show that the prebuilt R*-tree index improves query efficiency by up to 90% over time-index-only schemes and enhances write performance by nearly 50% compared to real-time indexing. The proposed RTPN4ITS model achieves robust accuracy across varying traffic densities, reaching 85% accuracy in dense conditions. Moreover, the Index2Vec embedding enhances the Transformer’s structural awareness. In summary, this paper proposes an efficient prebuilt indexing strategy and lightweight embedding-based model for real-time spatiotemporal data management in ITS.},
  archive      = {J_EAAI},
  author       = {Yiran Shao and Kangshuai Zhang and Yong Zhou and Zhenwu Chen and Yang Yang and Lei Peng},
  doi          = {10.1016/j.engappai.2025.112193},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112193},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prebuilt spatiotemporal index: An exploration of efficient real-time data storage in intelligent transportation systems},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An error complementarity-based iterative learning approach via categorical boosting for student performance prediction. <em>EAAI</em>, <em>161</em>, 112192. (<a href='https://doi.org/10.1016/j.engappai.2025.112192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting student performance is important in achieving academic success and student development in many educational applications (e.g., academic early warning and early interventions). To accurately predict student performance, we propose an error complementarity-based iterative learning approach for student performance prediction. Our goal is to improve the prediction performance by iteratively reducing the prediction error. Specifically, in model construction, we first select the most important features to train the target estimator. Then, we obtain the errors between the target and predicted values. These errors are used to train the error estimator using the remaining features. Similarly, we iteratively train the model to learn from the errors until the desired conditions are met. In model prediction, we predict the testing sample using the target estimator to obtain the predicted value. Next, we predict the error for the next iteration using the corresponding error estimator. This process is repeated, and the final prediction is obtained by adding the predicted value and the error values. The extensive experiments from different educational datasets show that by using our error complementarity-based iterative learning approach, the proposed model outperforms the competing models for prediction accuracy. Furthermore, statistical testing conducted over 20-run experiments confirms the significant advantage of our proposed model. This suggests the iterative learning is effective for predicting student performance.},
  archive      = {J_EAAI},
  author       = {Zongwen Fan and Jin Gou and Cheng Wang},
  doi          = {10.1016/j.engappai.2025.112192},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112192},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An error complementarity-based iterative learning approach via categorical boosting for student performance prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated cross-device cluster dynamic time planning warping algorithm in the industrial internet of things. <em>EAAI</em>, <em>161</em>, 112191. (<a href='https://doi.org/10.1016/j.engappai.2025.112191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Production lines and heterogeneous devices generate diverse time-series data in the Industrial Internet of Things (IIoT). This diversity necessitates frequent updates of local models when using federated learning (FL). FL has become widespread in the IIoT, these continual model updates can hinder timely information exchange among cross-industry devices. They constrain the system's ability to handle high concurrency in read and write operations. Therefore, we propose a federated cross-device cluster dynamic time planning warping (Fed-cDTW) tailored for the IIoT. We incorporate each device's historical behavior data by constructing a functional characteristic distance matrix. We design a symmetric time warping lower bound function to measure the similarity among multi-source time-series data. This approach enables an adaptive, dynamically organized industrial device cluster. Meanwhile, we employ the federated dynamic (FedD) dual-weight optimization within the device cluster to enhance the models' generalization and robustness. The experimental results evaluated the performance of the proposed method. We compare our method with baselines, Fed-cDTW improves classification accuracy by 0.8 percentage points (pp), 1.7 pp, 9.6 pp, 14.4 pp, and 49.5 pp. Convergence is accelerated by 0.04, 0.05, 0.35, 0.42, and 0.46. Total communication cost is reduced by 40 megabytes (MB), 56 MB, 84 MB, 120 MB, and 168 MB.},
  archive      = {J_EAAI},
  author       = {Yifan Zhao and Shibao Sun and Pengcheng Zhao and Yatong Wang and Jianfeng Liu},
  doi          = {10.1016/j.engappai.2025.112191},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112191},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Federated cross-device cluster dynamic time planning warping algorithm in the industrial internet of things},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based prediction of compressive strength in sustainable self-compacting concrete. <em>EAAI</em>, <em>161</em>, 112190. (<a href='https://doi.org/10.1016/j.engappai.2025.112190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance and durability of conventional concrete (CC) is significantly influenced by supplementary cementitious materials (SCMs) and recycled coarse aggregate (RCA). Thus, the intrusion of enrich SCMs with RCA in the cementitious matrix delivers utmost properties. This research focuses on the use SCMs and RCA in the self-compacting concrete (SCC) system and their sustainability in the development of concrete resources. Standard experimental methods for forecasting the compressive strength (CS) of SCC have constraints in terms of efficiency, time consumption, and cost. Thus, its prediction is crucial without the need for laborious experimental procedures. This work employs and evaluates a multiplicity of machine learning (ML) models to predict the CS of the cementitious matrix to tackle these issues. Thus, considered a more effective and cost-saving solution in comparison with traditional approaches. Therefore, ML approaches like, gene expression programming (GEP), decision trees (DT), and support vector regression (SVR) were employed. The performance of the model is evaluated by employing the coefficient of determination (R 2 ), statistics, and uncertainty analysis. Individual Conditional Expectation (ICE), and Partial Dependence Plot (PDP) are used to analyze the effect of parameters on strength. The findings suggest that GEP performs best achieving superior R 2 > 0.90 for the training, validation, and test data sets with a lower error. While, the uncertainty analysis shows that all modeled values lie below the threshold value. The ICE and PDP graphs confirms that cement, age, and water-cement ratio have highly relation to outcomes. The RCA replacement ratio is more important than the CA one, and SCMs play an essential role in the development of concrete compressive strength, although not as much as cement. In addition, SP depicts major contribution to SCC. Moreover, graphical user interface (GUI) is also developed to help users/researcher that will facilitate them to estimate the strength of SCC in practical applications.},
  archive      = {J_EAAI},
  author       = {Jingguo Gou and Athar Zaman and Furqan Farooq},
  doi          = {10.1016/j.engappai.2025.112190},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112190},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning-based prediction of compressive strength in sustainable self-compacting concrete},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust fuzzy twin support vector machine with kernel-target alignment for binary classification. <em>EAAI</em>, <em>161</em>, 112189. (<a href='https://doi.org/10.1016/j.engappai.2025.112189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many algorithms similar to the twin version of the support vector machine and their variants have shown better results in the binary classification of nonlinear data points. But in the presence of outlier and noise, these algorithms exhibit low generalization efficiency. To alleviate this challenge, recently proposed, kernel-target alignment based fuzzy least square twin bounded support vector machine (KTA-FLSTBSVM) used fuzzy membership values and is solved using least squares. Inspired by this strategy, for further improvement, we propose a novel approach called decision support kernel-target alignment based fuzzy least square twin bounded support vector machine (DS-KFIFTBSVM). DS-KFIFTBSVM considers the kernelized fuzzy membership values with the regularized twin support vector machine and solves for linear and nonlinear data points using a functional iterative approach. In DS-KFIFTBSVM, the solution is obtained by solving a linearly convergent iterative scheme rather than solving quadratic programming problems. The proposed DS-KFIFTBSVM offers better generalization efficiency, which has been evaluated using both linear and Gaussian kernels, mostly on artificially developed and publicly accessible datasets with diverse dimensionalities. In terms of various performance evaluation metrics, including specificity, precision, false positive rate, rate of misclassification error, F_score, and geometric mean in linear and non-linear cases, DS-KFIFTBSVM outperforms various baseline approaches. It shows the highest accuracy in various datasets, including 98.1884 % for musk dataset (linear kernel) and 100 % for the glass dataset (Gaussian kernel). Further statistical analysis confirms its classification efficiency.},
  archive      = {J_EAAI},
  author       = {Deepak Gupta and Barenya Bikash Hazarika and Umesh Gupta and Witold Pedrycz},
  doi          = {10.1016/j.engappai.2025.112189},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112189},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust fuzzy twin support vector machine with kernel-target alignment for binary classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive assessment of pore-scale segmentation techniques for image-based multiphase flow characterization in porous media. <em>EAAI</em>, <em>161</em>, 112188. (<a href='https://doi.org/10.1016/j.engappai.2025.112188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation of multiphase fluid flow behavior based on pore-scale imaging is significantly influenced by the accuracy of the segmentation techniques. This study sheds light on the influence of various traditional and Artificial Intelligence (AI) algorithms on the major static, dynamic, volumetric, and topological properties of the porous media. The traditional methods include the Gaussian Mixture Model (GMM), Multi-Otsu’s thresholding (MOT), and Random Walk (RW), and the AI-based techniques include Trainable Weka (TW), as well as seven deep convolutional autoencoder architectures. The assessment was carried out by comparing the calculated phase fraction, contact angle, capillary pressure, effective permeability, and topology for multiphase flow images of Bentheimer sandstone. The results revealed that combining Residual Networks (ResNet) and UNet structures (UResNet) marginally performs better based on the statistical metrics. Compared to ground-truth watershed images, applying other approaches except TW yielded acceptable static and volumetric parameters. The main discrepancies were in contact angles, capillary pressure, and phase topology. These discrepancies also influenced calculated effective permeabilities, yielding unrealistic trends. UResNet provided the best accuracy, considering the watershed the ground truth. MOT and RW showed similar performance, while GMM performed inconsistently throughout the analysis and TW produced acceptable results for certain fractional flows. The segmentation approaches affected topological features most, whereas properties such as phase fractions were less affected. The inconsistent behavior and effectiveness of used algorithms indicate that the analysis of multiphase images necessitates a meticulous choice of segmentation techniques, emphasizing AI-based algorithms that ensure consistency across all evaluations.},
  archive      = {J_EAAI},
  author       = {Javad Siavashi and Mohammad Sharifi},
  doi          = {10.1016/j.engappai.2025.112188},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112188},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comprehensive assessment of pore-scale segmentation techniques for image-based multiphase flow characterization in porous media},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Land use and land cover change detection from multisource satellite imagery – A hybrid convolutional neural network approach. <em>EAAI</em>, <em>161</em>, 112187. (<a href='https://doi.org/10.1016/j.engappai.2025.112187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing and satellite imagery analysis enable us to observe and understand environmental changes over time. However, such an endeavor can be complex and time-consuming. To overcome this challenge, we propose a framework for leveraging Google Earth Engine (GEE) to analyze Earth's surface changes over time. Our framework starts by assessing land cover changes using satellite imagery, evaluating the effectiveness of vegetation indices in classification, and generating accurate land cover maps for a specific region. We examine the validity of this framework on the area near Rio Do Sul, located in the Santa Catarina district of Brazil, to classify and recognize the alteration in land use and land cover (LULC) from 2019 to 2023. In this effort, we develop a pre-trained Convolutional Neural Network (CNN) for feature extraction from the Landsat 8, Sentinel-1, and Sentinel-2 images and then link those into the random forest (RF) algorithm for spatial morphology and temporal change logic to map the long-term annual time series and detect changes in the region at hand. The novelty of this study arises from developing a CNN-RF hybrid model and implementing a data preprocessing pipeline, which includes progressive techniques for cloud masking and radiometric calibration, to ensure higher accuracy and reliability in land use and land cover classification. This CNN-RF hybrid model successfully traced the increasing and decreasing rate in the built-up area, water bodies, forest, fallow land, plantations, and grassland with an overall accuracy of 96.39 % and 94.15 % for 2019 and 2023, respectively.},
  archive      = {J_EAAI},
  author       = {M.S. Babitha and A. Diana Andrushia and N. Anand and M.Z. Naser and Y. Pari},
  doi          = {10.1016/j.engappai.2025.112187},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112187},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Land use and land cover change detection from multisource satellite imagery – A hybrid convolutional neural network approach},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safety monitoring digital twin-based centralized model consolidation mechanism using dynamic node selection for multi-worker safety prediction. <em>EAAI</em>, <em>161</em>, 112186. (<a href='https://doi.org/10.1016/j.engappai.2025.112186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction industry remains one of the most hazardous sectors, requiring innovative solutions to safeguard workers, especially in complex, dynamic outdoor environments. Digital Twin (DT) technology offers promising capabilities for real-time safety monitoring through virtual replicas of physical systems. However, existing DT frameworks rarely integrate comprehensive safety monitoring via a centralized model consolidation mechanism, such as Federated Learning (FL), which is explicitly tailored for multi-worker scenarios. Addressing this challenge, this paper proposes a FL-based Safety Monitoring Digital Twin (SMDT) framework designed to enhance multi-worker safety in resource-constrained settings. This enables real-time safety monitoring and control by representing on-site workers as virtual objects within a synchronized DT environment. A dynamic node selection mechanism based on client performance is employed to optimize global model convergence in FL. To validate the proposed approach, an edge computing-based experimental testbed using actual Raspberry Pi devices was implemented, using real-world construction safety data including worker status, weather conditions, and building structural parameters. Experimental results demonstrate the effectiveness of the proposed framework in significantly improving safety predictions and real-time monitoring efficiency. This research establishes a foundational work towards safer construction sites through intelligent, synchronized safety monitoring systems.},
  archive      = {J_EAAI},
  author       = {Sa Jim Soe Moe and Atif Rizwan and Anam Nawaz Khan and Rongxu Xu and Do Hyeun Kim},
  doi          = {10.1016/j.engappai.2025.112186},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112186},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Safety monitoring digital twin-based centralized model consolidation mechanism using dynamic node selection for multi-worker safety prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Universal entity linking. <em>EAAI</em>, <em>161</em>, 112185. (<a href='https://doi.org/10.1016/j.engappai.2025.112185'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity linking is a process of connecting mentions of entities in a document to corresponding entries in a knowledge base. Traditional models for entity linking often require specific fine-tuning to work with knowledge bases other than those they were originally pretrained on, which limits their flexibility and scalability. Building on the concept of entity profile generation, we propose a novel approach that enables entity linking across various knowledge bases without the need for such fine-tuning. Our pipeline leverages a fine-tuned Large Language Model, a generic embedding model, and a vector store to achieve high precision on the TweekiGold and Reuters-128 datasets. Additionally, it demonstrates strong retrieval rates across the TweekiGold , Reuters-128 , and ISTEX-1000 Wikidata entity linking datasets. We also illustrate the applicability of our method to other knowledge bases, using the Agrovoc knowledge base as an example. This solution offers a more versatile and scalable approach to entity linking.},
  archive      = {J_EAAI},
  author       = {Adam Aron Rynkiewicz and Raul Palma and Piotr Formanowicz},
  doi          = {10.1016/j.engappai.2025.112185},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112185},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Universal entity linking},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A search method for fractured-vuggy reservoir inter-well connectivity path based on multi-modal multi-agent. <em>EAAI</em>, <em>161</em>, 112184. (<a href='https://doi.org/10.1016/j.engappai.2025.112184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex geological structure of carbonate reservoirs and the intricate fracture-vuggy configurations obscure inter-well connectivity, making its evaluation challenging. Conventional studies primarily rely on seismic static data to delineate fracture-vuggy reservoirs, but the limited recognition accuracy hampers the precise characterization of inter-well connectivity and the spatial configuration of fractures and vugs. To address this, this study constructs a 3D (Three-Dimensional) search environment and use multi-modal static and dynamic data and proposes a multi-agent connected channel search model based on deep reinforcement learning. The model treats multiphase fluid as an agent and incorporates Swin Transformer (Shift Window Transformer) to extract large-scale fracture features from seismic data, providing global prior information for path search. A Graph Attention Network is established based on dynamic response relationships to extract spatial geological features, while a multi-head self-attention mechanism captures real-time fluid interactions in various directions. The model fuses multi-modal features, including seismic attributes and production data, to generate decisions and automatically search for inter-well connectivity channels. Experiments were conducted using the WE1 and WE5 well groups from the fault-controlled karst reservoirs in the Tahe oilfield, with results compared against tracer tests. The findings demonstrate that the proposed model's automatic search paths closely align with seismic data and tracer test results, effectively capturing the spatial distribution of fractures and vugs across different scales. This validates the model's effectiveness in evaluating inter-well connectivity in complex carbonate reservoirs.},
  archive      = {J_EAAI},
  author       = {Wenbin Jiang and Dongmei Zhang and Hong Cao and Xiaofeng Wang},
  doi          = {10.1016/j.engappai.2025.112184},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112184},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A search method for fractured-vuggy reservoir inter-well connectivity path based on multi-modal multi-agent},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continuous spatio temporal prompts for visual tracking. <em>EAAI</em>, <em>161</em>, 112183. (<a href='https://doi.org/10.1016/j.engappai.2025.112183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, visual single-object tracking methods utilize online template updates to combine temporal information. However, these methods rely on confidence scores to evaluate the reliability of the current template, which may result in a template not being updated for an extended period. Moreover, advanced trackers select bounding boxes based solely on the similarity between the template and the search area, which can lead to tracking drift when encountering deformable or similar targets. To alleviate these limitations, we propose a Spatio Temporal Prompt Tracker (STPTrack), which utilizes the prior information about small changes of object state between successive frames. Different from previous tracking methods that mainly rely on templates and similarity scores, STPTrack transfers the object position and shape information of the previous frame to the current frame as continuous spatio temporal prompt for the first time, and realizes the efficient fusion of spatio temporal information through the prompt encoder and the fusion decoder module. Specifically, it encodes the bounding box coordinates or mask information of the previous frame and the response points of the current frame as prompt features, and then combines prompt tokens with search tokens through the fusion decoder to provide the potential location of the object for the search feature map. Our STPTrack sets a new state-of-the-art performance on six tracking benchmark datasets.},
  archive      = {J_EAAI},
  author       = {Meng Sun and Xiaotao Liu and Yifan Li and Hongyu Wang and Dian Yuan and Jing Liu},
  doi          = {10.1016/j.engappai.2025.112183},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112183},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Continuous spatio temporal prompts for visual tracking},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Length-aware center loss for sequence to sequence thai scene text recognition. <em>EAAI</em>, <em>161</em>, 112182. (<a href='https://doi.org/10.1016/j.engappai.2025.112182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thai scene text recognition is a challenging task because Thai can be written in both horizontal and vertical directions, allowing characters to be stacked vertically. To address this issue, our previous work combined vertically stacked characters to create new characters. However, this strategy introduced many similar characters. In this paper, we further investigate this problem and propose the Length-aware Center Loss (LC) for Thai scene text recognition. The original center loss was designed for single object recognition tasks. When applied to multi-label tasks like text recognition, center loss is only effective when the lengths of the labels and prediction results are consistent. This can lead to an extreme case where all images receive incorrect predicted text lengths to minimize loss, severely interfering with the recognition process. Therefore, we propose the Length-aware Center Loss for text recognition. We also design the Length Supervision Module (LSM) and the Feature Clustering Module (FCM) to work alongside the LC loss. LSM predicts text length to provide additional supervision signals, while FCM aims to improve recognition performance by minimizing the distance between the features of corresponding class centers. Since there is no publicly available Thai scene text dataset, we have collected a new dataset containing more than 170,000 samples. Extensive experiments conducted on this dataset show that our method achieves superior performance in both string-level and character-level accuracy compared to other methods.},
  archive      = {J_EAAI},
  author       = {Hongjian Zhan and Chun Li and Bing Yin and Yue Lu},
  doi          = {10.1016/j.engappai.2025.112182},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112182},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Length-aware center loss for sequence to sequence thai scene text recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-based vision-language model for zero-shot anomaly detection in medical images. <em>EAAI</em>, <em>161</em>, 112181. (<a href='https://doi.org/10.1016/j.engappai.2025.112181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of diagnostic technology, the ability to detect pathological areas such as tumors and polyps has significantly improved. This progress provides medical imaging specialists with more precise visual information to support anomaly identification, diagnosis, treatment planning, and patient monitoring. However, existing unsupervised and semi-supervised anomaly detection methods struggle with data privacy constraints, limited annotated medical datasets, and challenges in generalization. Zero-Shot Anomaly Detection (ZSAD), which enables the detection of unseen categories without requiring class-specific training, has emerged as a promising solution by leveraging the vision-language alignment capabilities of Vision-Language Models (VLMs), such as Contrastive Language-Image Pretraining (CLIP). Despite recent progress, ZSAD remains hindered by high noise levels, sparse targets, and poor adaptability in complex medical imaging scenarios. To address these issues, we propose a novel framework: DiffusionCLIP, a diffusion-based VLM for zero-shot anomaly detection in two-dimensional medical images. Specifically, DiffusionCLIP integrates diffusion models into the VLM to progressively denoise multi-level features extracted from the CLIP visual encoder, enhancing feature robustness and discriminability. A multi-level feature fusion strategy is designed to aggregate multi-scale representations from different depths of the visual encoder, ensuring complementary semantic alignment across layers. In addition, a dynamically modulated weight loss function is introduced to adaptively balance the learning of hard and easy samples, further improving model generalization. Extensive experiments on multiple benchmark medical imaging datasets, demonstrate that the proposed method significantly outperforms existing zero-shot anomaly detection approaches in terms of accuracy, robustness, and generalization.},
  archive      = {J_EAAI},
  author       = {Yanhui Chen and Hongkang Tao and Zan Yang and Yunkang Cao and Chen Jiang and Longhua Hu and Pengwen Xiong and Haobo Qiu},
  doi          = {10.1016/j.engappai.2025.112181},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112181},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Diffusion-based vision-language model for zero-shot anomaly detection in medical images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surface roughness prediction in turning processes for grey cast iron: A hybrid machine learning approach integrating infrared thermography. <em>EAAI</em>, <em>161</em>, 112180. (<a href='https://doi.org/10.1016/j.engappai.2025.112180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workpiece surface quality is a critical control parameter in machining processes, influencing functional performance, dimensional precision, and wear resistance. However, accurately predicting surface roughness is complex, often limited by the computational demands of traditional high-precision methods and the reliance of existing models solely on cutting parameters, hindering real-time monitoring. This research introduces a hybrid Artificial Neural Network (ANN) methodology specifically developed for predicting surface roughness of grey cast iron GG-25 workpieces machined in turning processes, a material previously unstudied in this context. The methodology integrates real-time infrared thermal measurements from multiple defined regions of interest (ROIs) within the tool-workpiece contact zone, along with cutting parameters. Experimental results demonstrated that feed rate (f) is the most significant cutting parameter (effect = 0.43) affecting surface quality, followed by its combination with cutting speed (V c ) (effect = −0.25) and cutting speed (effect = 0.18). Correlation and non-linear regression analyses revealed complex, often exponential relationships between temperature and surface roughness, showing temperature an upward trend as machining progressed. The developed ANN achieves a correlation coefficient (R) value of 0.99 both when predicting the roughness arithmetic mean deviation (Ra) parameter in training conditions and when using data from experiments not used in training (validations data). Moreover, the model reaches a correlation coefficient value of 0.85 (test data) under cutting conditions different from those used in experiments, demonstrating robustness, significantly outperforming Support Vector Regression (SVR). This model represents a highly potential tool for real-time online inspection.},
  archive      = {J_EAAI},
  author       = {Sergio Aguado and Marcos Pueo and Raquel Acero and Ana Cristina Majarena and Jorge Santolaria},
  doi          = {10.1016/j.engappai.2025.112180},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112180},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Surface roughness prediction in turning processes for grey cast iron: A hybrid machine learning approach integrating infrared thermography},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Legendre multiwavelet-based feature attention guidance lightweight network for accurate steel surface defect classification. <em>EAAI</em>, <em>161</em>, 112179. (<a href='https://doi.org/10.1016/j.engappai.2025.112179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steel surface defects can significantly affect the quality and appearance of industrial products such as aerospace, construction application fields, and so on. Due to the multi-scale morphology, low contrast, and random positions of the defects, achieving a favorable balance between detection accuracy and speed remains challenging in practical applications. To address these challenges, this paper combines Legendre multiwavelet (LW) with feature attention guidance (FAG) mechanism to devise a novel high-accuracy lightweight network (LWFAG-LNet) for surface defect classification. More precisely, LW bases with rich regularities are first utilized to match complex geometric characteristics across multi-wavelet and multi-scale resolution levels. Subsequently, the FAG module effectively fuses shallow high-resolution detailed features with deep low-resolution contextual features, significantly reducing the depth of the convolutional neural network (CNN). To the third step, a lightweight CNN module with four convolutional blocks is designed to further extract deep features while preserving the most valuable defect information. The proposed model achieves the highest recognition accuracy with a simple structure and a compact parameter configuration. Extensive experiments are conducted on the Northeastern University-Classification (NEU-CLS), Xsteel surface defect dataset (X-SDD), and Kungliga Tekniska Högskolan Royal Institute of Technology Textures under varying Illumination, Pose and Scale (KTH-TIPS) dataset to verify the model's effectiveness and generalization capability. The results reach classification accuracies of 99.80 %, 98.49 %, and 99.06 %, outperforming existing models by about 1.45 %, 3.45 %, and 2.04 %, respectively. In summary, the proposed LWFAG module can be flexibly applied to various lightweight network frameworks, demonstrating great potential for real-time surface defect detection.},
  archive      = {J_EAAI},
  author       = {Xiaoyang Zheng and Weishuo Liu and Yan Huang},
  doi          = {10.1016/j.engappai.2025.112179},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112179},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Legendre multiwavelet-based feature attention guidance lightweight network for accurate steel surface defect classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting object hue bin in the CIECAM02 uniform color space using a multi-layer perceptron for optimal spectrum generation. <em>EAAI</em>, <em>161</em>, 112178. (<a href='https://doi.org/10.1016/j.engappai.2025.112178'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an innovative enhancement to an existing multi-channel light-emitting diode luminaire by integrating artificial intelligence and image analysis capabilities. The system captures an image of the object to be illuminated using a custom-developed Android application. The dominant color in the image is first identified, and then a multi-layer perceptron neural network classifies it into one of 16 hue bins within a uniform color appearance model. This classification process enables the luminaire to select a predefined spectrum designed to enhance the visual appeal of the illuminated object. To ensure robust hue bin classification, we developed a rich dataset with 7920 samples, collected using eleven smartphones under ten distinct light sources. Using this diverse dataset, thirteen multi-layer perceptron neural networks with varying input features were trained and compared, achieving hue classification accuracies, precision, and recall all ranging from 95 % to 99 % on the test set. One of the trained multi-layer perceptron networks was integrated into the Android application, with an inference time of 90 μs on a mid-range smartphone, demonstrating the practical application of artificial intelligence for on-demand hue analysis and lighting optimization. This advancement not only enhances the luminaire's functionality but also enriches the user experience by providing intelligent, on-demand lighting solutions tailored to the object's dominant color.},
  archive      = {J_EAAI},
  author       = {Esmat Kishani Farahani and Kaveh Ahmadian Tazehmahaleh},
  doi          = {10.1016/j.engappai.2025.112178},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112178},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting object hue bin in the CIECAM02 uniform color space using a multi-layer perceptron for optimal spectrum generation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized zero-shot fault diagnosis method for chillers based on cross-modal information compression. <em>EAAI</em>, <em>161</em>, 112177. (<a href='https://doi.org/10.1016/j.engappai.2025.112177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical chiller fault diagnosis applications, target fault training data is often inaccessible, which poses significant challenges to the effectiveness of data-driven diagnostic approaches. Generalized zero-shot fault diagnosis (GZSFD) aims to detect and classify all fault types without relying on fault samples from all categories during training. GZSFD models are trained exclusively on data from seen faults—those with available historical data—making them prone to bias toward these seen classes during inference. However, existing methods fail to exploit the fine-grained semantics of fault attributes, resulting in suboptimal performance when addressing feature bias toward seen classes. In this article, an innovative GZSFD framework for chillers based on cross-modal information compression is proposed to overcome this difficulty. This method constructs a cross-modal feature fusion attention (CmFFA) and information compression module, and integrates them into a variational autoencoder with generative adversarial network (VAEGAN), and establishes a CmFFA-VAEGAN network to synthesize high-quality unseen fault samples. Specifically, the CmFFA module effectively aligns local regions of the virtual samples with key words in the textual attributes, enabling the model to attend to fine-grained semantic information and robustly fuse features from different modalities. This facilitates the generation of virtual samples that more accurately reflect the characteristics of the target modality. In addition, an information bottleneck (IB) layer is introduced at the output of the generator to compress redundant information within the fused features, retaining only the key information most relevant to the data augmentation task. This design enhances cross-modal consistency between the synthesized samples and their corresponding attributes, while alleviating the feature shift of unseen class samples toward seen categories. Extensive experiments are designed and executed on the chiller dataset. Experimental results demonstrate that the proposed framework effectively mitigates the bias of synthesized unseen fault samples toward seen categories, leading to a significant improvement in diagnostic accuracy.},
  archive      = {J_EAAI},
  author       = {Kexin Jiang and Xuejin Gao and Huayun Han and Huihui Gao and Yongsheng Qi and Xi Zhang and Liang Zhao},
  doi          = {10.1016/j.engappai.2025.112177},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112177},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generalized zero-shot fault diagnosis method for chillers based on cross-modal information compression},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing rotation you only look once version 8 for accurate detection of arbitrarily-oriented and multi-scale construction material in complex environment. <em>EAAI</em>, <em>161</em>, 112176. (<a href='https://doi.org/10.1016/j.engappai.2025.112176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Construction material detection is integral to effective material management. While deep learning-based methods have advanced automatic detection, challenges such as arbitrarily oriented objects, similar features, large object scale variations, and noise interference still limit accuracy. This study proposes an enhanced detection method based on improved rotation you only look once version 8, incorporating three key innovations. First, the large selective kernel network employs a spatial selection mechanism to dynamically adjust the network's receptive field, capturing key features and contextual information of various materials in complex construction scenarios. This enhances object detection performance in feature-similar environments. Second, the poly kernel inception network combines non-dilated multi-scale convolutions to extract dense texture features from differently sized objects, while using contextual anchor attention to capture long-range information for small objects. These components work together to improve multi-scale object detection. Third, the rectangular self-calibration module uses horizontal and vertical pooling to model rectangular attention regions, capturing axial global context. Its shape self-calibration function adjusts these regions to better fit arbitrarily oriented construction materials, enhancing focus on objects while suppressing noise interference. Experimental results show a mean average precision of 0.871–2.7 % higher than the baseline model and surpassing other state-of-the-art methods—while maintaining real-time detection speed at 28.3 frames per second. The proposed method improves material detection accuracy in complex construction environments, enabling refined material management on-site. This supports material entry and exit tracking, on-site usage monitoring, inventory management, and procurement planning, while also strengthening lean control of construction progress and costs.},
  archive      = {J_EAAI},
  author       = {Yujie Lu and Yuanjun Nong and Dayu Zhu and Shuo Wang},
  doi          = {10.1016/j.engappai.2025.112176},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112176},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing rotation you only look once version 8 for accurate detection of arbitrarily-oriented and multi-scale construction material in complex environment},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-term forecasting of monthly reservoir inflow using deep and machine-learning-based algorithms. <em>EAAI</em>, <em>161</em>, 112175. (<a href='https://doi.org/10.1016/j.engappai.2025.112175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study provides a method for dynamic flow forecasting to detect how to move between periods with high and low-flow peaks. In other words, the model continues by gaining a deep insight into the long-term stable changes of the time series. Four-time horizons (5, 10, 15 and 20 years) were chosen to forecast the streamflow. These time horizons represent the ability of this method to detect the continuation of its movement in the short, medium, and long term. In this study, a dynamic and recurrent cycle is used to forecast river streamflow based on long-short-term memory (LSTM) and artificial neural network (ANN) models. The 12-month time delay of precipitation and streamflow of the Zayanderud river from 1970 to 2019 was used as input variables for training and validation of the models. In each stage of the forecasting process, 1 year (12 months) is forecasted and used as input for the next stage. The results show that the ANN model performs better in shorter time horizons and the LSTM model in longer time horizons, respectively. The best performance of the ANN model occurs in the 10-year forecast (Mean Absolute Percentage Error (MAPE) = 44.3, Nash–Sutcliffe efficiency coefficient (NSCE) = 0.58, Root Mean Square Error (RMSE) = 43.75) and the best performance of the LSTM model occurs in the 15-year forecast (MAPE = 48.9, NSCE = 0.54, RMSE = 47.12). Finally, the selected period is used to forecast the streamflow in future periods when observational data are not available.},
  archive      = {J_EAAI},
  author       = {Bahram Ghenaati and Mohammad Reza Nikoo and Mohammad G. Zamani},
  doi          = {10.1016/j.engappai.2025.112175},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112175},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long-term forecasting of monthly reservoir inflow using deep and machine-learning-based algorithms},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characteristics detection of surface agglomerated abrasive on electroplated diamond wire: A measurement method based on semantic segmentation. <em>EAAI</em>, <em>161</em>, 112173. (<a href='https://doi.org/10.1016/j.engappai.2025.112173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroplated Diamond Wire (EDW) serves as the primary tool for cutting semiconductor materials. Abrasive agglomeration on its surface induces sudden fluctuations in sawing force, exacerbates material surface damage, and shortens tool lifespan. However, existing testing methods primarily focus on abrasive counts while generally lacking effective means to quantify key characteristics of agglomerated abrasives (e.g., density, maximum size, and number of abrasives contained), leading to substantial limitations in the EDW quality assessment system. To address this critical gap, this study proposes a U-shape Network (UNet)-based semantic segmentation model for EDW surface abrasive grain segmentation, termed Electroplated Diamond Wire U-shape Network (EDW-UNet). By integrating Atrous Spatial Pyramid Pooling (ASPP) and Mamba-like Linear Attention (MLLA), EDW-UNet enhances the detection of multi-scale targets and the accuracy of complex boundary segmentation, enabling precise segmentation of both single and agglomerated abrasives on EDW surfaces. Experimental results demonstrate that EDW-UNet achieves a mean Intersection over Union of 0.917 and a mean Pixel Accuracy of 0.961 on the test set, outperforming the baseline UNet and other mainstream models, with an inference speed of up to 12.82 frames per second. For the first time, a feature extraction algorithm developed from the segmentation results enables measurement of key parameters, including the density, maximum size, and number of abrasives contained in agglomerates. This study not only addresses the technical gap in quantitative detection of agglomerated abrasive features but also provides a novel high-precision, quantitative standard for optimizing EDW manufacturing processes and assessing product quality, thereby enhancing the cutting efficiency and yield of semiconductor materials. The code is available at: https://github.com/huangwenbin123/EDW-UNet .},
  archive      = {J_EAAI},
  author       = {Wenbin Huang and Yufei Gao and Shengtan Hu and Dameng Cheng},
  doi          = {10.1016/j.engappai.2025.112173},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112173},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Characteristics detection of surface agglomerated abrasive on electroplated diamond wire: A measurement method based on semantic segmentation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk-response coupling in underground structures under liquefiable soil conditions: A causality-informed dynamic bayesian network integrated framework. <em>EAAI</em>, <em>161</em>, 112171. (<a href='https://doi.org/10.1016/j.engappai.2025.112171'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underground structures in liquefiable soils face complex seismic risks that can trigger cascading failures. This study proposes a Granger causality-informed Dynamic Bayesian network (G-DBN) framework to capture the temporal propagation of seismic risk in such systems. Firstly, a system risk assessment model integrates multiple performance indicators through Cloud Model (CM) to quantify overall risk levels, considering uncertainties associated with soil liquefaction and structural responses. Subsequently, a structural dynamic risk inference model is established using Dynamic Bayesian network (DBN), combining Granger Causality (GC) analysis with engineering-informed relationships to define the network structure. The input features include key structural state variables such as tunnel cross-section convergence ( T 4 ), tunnel uplift displacement ( T 6 ), station uplift displacement ( S 5 ), and inter-story drift angle ( S 6 ), and the aggregated structural risk indicator serves as the target variable. This framework enables the temporal propagation of risk across interconnected structural nodes, and elucidates the mechanisms by which liquefiable soil deformations and structural responses interact within the soil-structure system. Results showed that the risk characteristic value (Expectation , E x ) decreased from 29.12 % (percentage) to 5.21 % as the Peak Ground Acceleration (PGA, expressed in units of gravitational acceleration g) increased from 0.1 g to 0.7 g. The proposed G-DBN model demonstrates robust predictive capabilities, achieving coefficient of determination ( R 2 ) values exceeding 0.95 across multiple seismic intensity conditions. Additionally, tunnel cross-section convergence ( T 4 ) was identified as the most critical factor affecting risk propagation in the coupled underground systems. By integrating holistic risk quantification with dynamic propagation analysis, this study offers a robust tool for understanding dynamic risk evolution and supports decision-making for seismic resilience of underground infrastructure in liquefiable soils.},
  archive      = {J_EAAI},
  author       = {Heqi Kong and Xiaohua Bao and Jun Shen and Xiangcou Zheng and Xiangsheng Chen},
  doi          = {10.1016/j.engappai.2025.112171},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112171},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Risk-response coupling in underground structures under liquefiable soil conditions: A causality-informed dynamic bayesian network integrated framework},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural operator-enabled forward and inverse modeling of laser-induced surface acoustic waves and applications in nondestructive evaluation. <em>EAAI</em>, <em>161</em>, 112170. (<a href='https://doi.org/10.1016/j.engappai.2025.112170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser-induced surface acoustic wave (SAW)-driven nondestructive evaluation offers high-resolution, non-contact characterization of subsurface microstructures. However, its practical application is often limited by the high computational costs associated with traditional numerical simulation methods. Recently, machine learning has emerged as an attractive alternative to accelerate these simulations. In this paper, we develop a neural operator-enabled framework for both forward and inverse modeling of laser-induced SAW propagation. A general dataset with randomly generated subsurface structures is used to evaluate and quantify the model's performance in both wave propagation and subsurface inversion problems. Three potential applications are then investigated: subsurface crack localization, multilayer structure characterization and polycrystalline grain imaging. The results demonstrate that the neural operator-enabled model achieves satisfactory accuracy even in the presence of noise and source waveform variations, underscoring its potential as an efficient and accurate surrogate model for practical nondestructive evaluation using laser-induced SAWs.},
  archive      = {J_EAAI},
  author       = {Zaiwei Liu and Zhongqing Su},
  doi          = {10.1016/j.engappai.2025.112170},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112170},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural operator-enabled forward and inverse modeling of laser-induced surface acoustic waves and applications in nondestructive evaluation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective double Q-learning-based hyper-heuristic algorithm for aluminum production and transportation integrated scheduling problem. <em>EAAI</em>, <em>161</em>, 112169. (<a href='https://doi.org/10.1016/j.engappai.2025.112169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cooperative process of electrolytic aluminum production and aluminum liquid distribution is a typical distributed integrated scheduling problem. The aluminum production and transportation integrated scheduling problem (APTISP) is a strong coupling problem that is studied with the optimal objectives of total completion time and total energy consumption. A mathematical model is constructed for the APTISP. A multi-objective double Q-learning-based hyper-heuristic (MDQHH) algorithm is designed to solve the APTISP. In the MDQHH algorithm, a heuristic rule-based initialization operation is designed to generate the initial population of the APTISP. Nine problem-specific low-level perturbation heuristics are constructed to explore the APTISP solution space. A dynamically adjustable ε -greedy strategy is designed to select the low-level perturbation heuristics, and ε gradually decreases as the learning process progresses. Two Q-tables are utilized alternately to select actions and update the Q-values based on the current solution in each iteration. The experimental results show that the MDQHH algorithm outperforms several state-of-the-art comparison algorithms in addressing the performance of APTISP.},
  archive      = {J_EAAI},
  author       = {Fuqing Zhao and Ting Yang and Tianpeng Xu and Jianlin Zhang},
  doi          = {10.1016/j.engappai.2025.112169},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112169},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-objective double Q-learning-based hyper-heuristic algorithm for aluminum production and transportation integrated scheduling problem},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable multi-agent reinforcement learning for factory-wide dynamic scheduling in semiconductor manufacturing. <em>EAAI</em>, <em>161</em>, 112168. (<a href='https://doi.org/10.1016/j.engappai.2025.112168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time dynamic scheduling in modern manufacturing is highly complex due to frequent disturbances and intricate operational constraints. While reinforcement learning (RL) has shown promise, existing approaches often rely on extensive dispatching rules and struggle to scale to factory-wide settings. This study introduces a scalable multi-agent RL (MARL) framework with a leader–follower structure, enabling decentralized agents to handle sub-problems while maintaining global coordination through abstract goals. To further enhance robustness, a limited rule-based conversion algorithm is proposed to mitigate performance degradation from poor agent decisions. Our experimental results demonstrate that the proposed model outperforms the state-of-the-art deep RL-based scheduling methods in various aspects. Additionally, the proposed model provides the most robust scheduling performance to demand changes. Overall, the proposed MARL-based scheduling model presents a promising solution to the real-time scheduling problem, with potential applications in various manufacturing industries.},
  archive      = {J_EAAI},
  author       = {Jaeyeon Jang and Diego Klabjan and Han Liu and Nital S. Patel and Xiuqi Li and Balakrishnan Ananthanarayanan and Husam Dauod and Tzung-Han Juang},
  doi          = {10.1016/j.engappai.2025.112168},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112168},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scalable multi-agent reinforcement learning for factory-wide dynamic scheduling in semiconductor manufacturing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on global path planning algorithm based on indoor map partition preprocessing. <em>EAAI</em>, <em>161</em>, 112167. (<a href='https://doi.org/10.1016/j.engappai.2025.112167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robots utilize Simultaneous Localization and Mapping (SLAM) technology to generate environmental maps and determine their locations within these environments. Subsequently, they employ path planning algorithms to complete navigation tasks. Although existing path planning algorithms are relatively mature, they still exhibit inefficiencies in complex indoor environments. To address this issue, this paper introduces an Indoor Map Partitioning Preprocessing (IMPP) algorithm, which identifies and segments irregularly shaped, complex rooms to accelerate the path planning process. The method initially utilizes the Robot Operating System (ROS) to construct an indoor map dataset and subsequently applies an image segmentation model to identify and enclose rooms. By combining image processing techniques with path planning algorithms, this method can obtain room index information and successfully exclude irrelevant areas from the path planning process. Ultimately, the IMPP algorithm is integrated with a variety of global path planning algorithms. Experimental results demonstrate that in complex indoor environments, this method significantly surpasses existing partitioning methods in terms of room recognition accuracy. Moreover, it decreases the number of expansion points in global path planning algorithms, significantly enhancing processing speed and efficiency.},
  archive      = {J_EAAI},
  author       = {Jifan Yang and Xiaoling Li and Xiaoyang Liu and Xunding Pan and Lei Wang},
  doi          = {10.1016/j.engappai.2025.112167},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112167},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on global path planning algorithm based on indoor map partition preprocessing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ensemble transfer learning strategy for short-term electricity load forecasting of data-sparse buildings. <em>EAAI</em>, <em>161</em>, 112166. (<a href='https://doi.org/10.1016/j.engappai.2025.112166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The “data silos” caused by the lack of available historical or shared information is an important reason affecting forecasting performance of building’s short-term power demand, thus limits the flexibility of demand response of building group. Knowledge’s transfer learning (TL) from similar domains has been proved an efficient tool to enhance target prediction’s performance. To improve data-sparse building’s energy forecasting accuracy and robustness simultaneously, an ensemble strategy based on different TL models is proposed in this study. Firstly, a two-stage similar data selection method is proposed for source domain construction. The multi-kernel maximum mean discrepancy (MK-MMD) is used for selecting similar buildings to the target one; the nearest neighbor search (NNS) method is adopted for picking the most helpful data from the similar buildings to form the dataset of source domain. To determine the optimal number of source domains for transfer learning, an objective function is also formulated. Then, two effective TL models, i.e., instance-based TL (IBTL) and model-based TL (MBTL) are both built as sub models. On this basis, a parallel ensemble framework is designed with model weights adjusted by multiple linear regression. For case study, a public data set containing 1,449 buildings is treated as candidate source domain set for knowledge transfer, and two educational buildings with sparse historical data are treated as target buildings for hourly electricity load forecasting. Forecasting results show that compared with the previous reported TL models, the proposed ensemble strategy always achieves the best performance in two cases and the prediction accuracies are improved by 41.8% and 29.3% (MAPE) respectively. The impact of source domain number and target data amount on prediction performance are also analyzed and discussed in details.},
  archive      = {J_EAAI},
  author       = {Xingqiao Liu and Borui Wei and Wenping Xue and Xiaoying Li and Kangji Li},
  doi          = {10.1016/j.engappai.2025.112166},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112166},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An ensemble transfer learning strategy for short-term electricity load forecasting of data-sparse buildings},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent multispectral image recognition by using credibility-based square root cubature kalman filters and broad particle swarm learning. <em>EAAI</em>, <em>161</em>, 112165. (<a href='https://doi.org/10.1016/j.engappai.2025.112165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes intelligent multispectral image recognition by using credibility-based Square Root Cubature Kalman Filters (SRCKF) and broad particle swarm learning to address the issue of low recognition accuracy in multispectral target detection using Kalman filtering. This method initially enhances the estimation accuracy of SRCKF by integrating credibility theory. Secondly, the regression parameters of a Broad Learning System (BLS) are tuned with Particle Swarm Optimization (PSO), forming a PSO-BLS network that offers fast, lightweight feature learning. The PSO-BLS acts as an regressor that compensates residual errors produced by the credibility-based SRCKF, thereby refining the overall filtering precision. Subsequently, a particle swarm-optimized broad learning neural network is employed to rectify the SRCKF results from a compensatory standpoint, thereby enhancing the system’s filtering precision. Ultimately, the adaptive search window generated by Camshift(Continuously adaptive Mean shift) can be employed as an input for the credibility SRCKF, thereby facilitating the acquisition of more reliable real-time observation data. Finally, in the experimental part, the proposed algorithm is validated by the MNIST(Modified National Institute of Standards and Technology) dataset , CIFAR-10(Canadian Institute For Advanced Research) dataset, GTOT(Grayscale-Thermal Object Tracking) dataset and OTB2015(Object Tracking Benckmark 2015) dataset respectively for its generalization ability and robustness in static classification tasks and the effectiveness of dynamic target detection and tracking in real lighting scenes, Occlusion and motion blur scenes, while the performance is more advantageous than some mainstream algorithms.},
  archive      = {J_EAAI},
  author       = {Quanbo Ge and Zijian Xue and Hao Wang and Yuanliang Wang},
  doi          = {10.1016/j.engappai.2025.112165},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112165},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent multispectral image recognition by using credibility-based square root cubature kalman filters and broad particle swarm learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accidents analysis of mining industry through semantic text representation and dimensionality reduction: An integrated clustering framework. <em>EAAI</em>, <em>161</em>, 112164. (<a href='https://doi.org/10.1016/j.engappai.2025.112164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant improvements in worker health and safety in recent decades, the mining industry still experiences fatal and non-fatal accidents. This underscores the critical need for a more nuanced understanding of accident causation patterns through accident data analysis. While conventional analytical approaches have yielded valuable insights, the extensive information embedded within text-based accident narratives remains underutilized. To address this gap, this study presents an artificial intelligence (AI)-based framework that integrates transformer-based natural language processing, nonlinear dimensionality reduction, and unsupervised machine learning to analyze and cluster accident narratives from the U.S. mining industry. Specifically, this study uses Sentence-BERT (SBERT), a sentence embedding model based on Bidirectional Encoder Representations from Transformers (BERT), to extract the high-dimensional semantical representation of accident narratives. These embeddings are then mapped to a low-dimensional space using the Uniform Manifold Approximation and Projection (UMAP) technique, followed by clustering with the k-means algorithm and subsequent hazard-focused cluster analysis. The primary contribution to AI lies in demonstrating the effectiveness of combining modern sentence embedding techniques with dimensionality reduction and clustering for the semantic analysis of safety-related narratives. From an engineering standpoint, this framework enables the identification of latent accident patterns that can inform hazard detection and guide safety interventions in the mining industry. The resulting clusters reveal diverse accident patterns across mining operations. In clusters associated with underground mining, a high proportion of incidents (ranging from 84 to 98 %) involved no equipment, with distinct injury patterns: torso injuries (67 %) from over-exertion, lower extremity injuries (58 %) from slips/falls, and upper extremity injuries from over-exertion (95 %) and material handling (85 %). Equipment-related clusters revealed strong associations with drilling tools (92 %), loaders (98 %), and bolting equipment (96 %). Clusters associated with strip/quarry/open pit operations exhibited a high frequency of vehicle-related accidents (98 % transportation, 99 % loaders), often resulting in multiple body part injuries. Milling operation clusters show 52–97 % no-equipment accidents, with injury patterns similar to those in underground mining. Additionally, noise-induced hearing loss (96–97 %) was observed in clusters spanning all mining operation types. These findings offer actionable insights for safety professionals and support data-driven, targeted interventions in the mining industry.},
  archive      = {J_EAAI},
  author       = {Abid Ali Khan Danish and Snehamoy Chatterjee and Kumar Vaibhav Raj and Rennie Kaunda and Hugh Miller and Aref Majdara},
  doi          = {10.1016/j.engappai.2025.112164},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112164},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Accidents analysis of mining industry through semantic text representation and dimensionality reduction: An integrated clustering framework},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight and improved you only look once model using GhostWise convolution and attention mechanism for accurate plant disease detection. <em>EAAI</em>, <em>161</em>, 112163. (<a href='https://doi.org/10.1016/j.engappai.2025.112163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence enables early plant disease detection to support food security, yet achieving high accuracy with low computational cost on multi-class datasets remains challenging. To bridge this gap and solve the problem, we propose an improved version of the “You Only Look Once version 8 nano” (YOLOv8n) model that integrates a convolutional block attention module and custom coarse-to-fine modules into the baseline YOLOv8n architecture. To improve both efficiency and detection performance, the proposed model incorporates a combination of Ghost module and Depthwise convolution for lightweight feature extraction. Additionally, the attention modules emphasize important spatial and channel-wise features, helping the model focus better on critical information. The performance of the proposed model is compared with YOLO models including YOLOv5n, YOLOv5s, YOLOv7, YOLOv8n, and YOLOv8s. The experimental results show that the improved model outperforms the benchmark YOLO models. In addition, the improved model achieves mean Average Precision at Intersection over Union threshold of 0.5 ( mAP@0.5 ) 0.742, representing an improvement of 3.37 % over the baseline YOLOv8n. For the metric mean Average Precision at thresholds from 0.5 to 0.95 ( mAP@0.5:0.95 ), the improved model shows an improvement of 5.13 % over YOLOv8n. The precision measure reveals an improvement of 8.99 % and F1 score of 0.6856 outperforms YOLOv8n by 5.85 %. In addition, generalization experiments are conducted using commonly preferred plant disease datasets. These results validate the robustness, accuracy and stability of the improved model in effectively detecting plant leaf diseases.},
  archive      = {J_EAAI},
  author       = {Bunyamin Dikici and Mehmet Fatih Bekciogullari and Hakan Acikgoz and Serkan Ozbay},
  doi          = {10.1016/j.engappai.2025.112163},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112163},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight and improved you only look once model using GhostWise convolution and attention mechanism for accurate plant disease detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid optimization approach for syngas-fueled gas turbines: Integrating inverse problem solving and machine learning techniques. <em>EAAI</em>, <em>161</em>, 112162. (<a href='https://doi.org/10.1016/j.engappai.2025.112162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the efficiency of gas turbines powered by syngas derived from gasification, combining a detailed thermodynamic model with a hybrid optimization approach that integrates inverse problem solving via the Levenberg-Marquardt (LM) algorithm and supervised machine learning using Gradient Boosted Trees (GBT). The LM method is used to estimate turbine and compressor performance parameters based on efficiency maps extracted through a custom image processing routine. These maps are applied to calibrate isentropic efficiencies and define the system's operational boundaries. The resulting performance curves enhance the accuracy of the thermodynamic cycle model. To identify optimal operating conditions that maximize thermal efficiency and minimize entropy generation, the inverse problem formulation is integrated with the GBT model, enabling data-driven optimization based on simulated system behavior. All modeling and simulations are conducted in Wolfram Mathematica version 14.0, while verification is performed with the commercial software Gasturb version 14.0, using syngas composition data available in the literature. As a case study to demonstrate the method's applicability, syngas obtained from sewage sludge gasification is analyzed. The findings after optimization indicated an average thermal efficiency of 40 % when using syngas. The analysis revealed that the fuel mass flow rate contributes approximately 45 % to the efficiency gains and more than 70 % to the exergy reduction, while the excess air ratio contributes around 50 % to the cycle's efficiency. The study demonstrates the value of integrating LM-based modeling and GBT optimization, indicating significant potential for enhancing the performance of syngas-fueled turbines. Moreover, it highlights syngas from sewage sludge as a promising sustainable energy source.},
  archive      = {J_EAAI},
  author       = {Hiago David Zogbi Silva Oliveira and Vítor Caldeira de Andrada Bastos and York Castillo Santiago and Isabela Florindo Pinheiro},
  doi          = {10.1016/j.engappai.2025.112162},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112162},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid optimization approach for syngas-fueled gas turbines: Integrating inverse problem solving and machine learning techniques},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-wavelet adaptive basis network for long-term time series forecasting. <em>EAAI</em>, <em>161</em>, 112161. (<a href='https://doi.org/10.1016/j.engappai.2025.112161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based models have demonstrated remarkable efficacy in long-term time series forecasting. Nevertheless, their fixed-scale feature extraction and static spectral processing limit adaptability to inherent multi-scale temporal dependencies. Additionally, conventional self-attention mechanisms struggle to effectively model hierarchical temporal structures. To address these limitations, we propose the Frequency-Wavelet Adaptive Basis Network (FWBNet), a novel framework that integrates three synergistic components including a Multi-scale Adaptive Basis Module (MS-ABM) for multi-resolution feature extraction, a Dual-Stream Wavelet Cross-Attention (DWCA) system with learnable wavelet transformations, and a computationally efficient Frequency-domain Multi-Layer Perceptron bottleneck (FreMLP bottleneck) for selective spectral processing. The MS-ABM innovatively integrates multi-scale features of time series through an adaptive basis function selection mechanism, dynamically fusing characteristics at different scales to form hierarchical representations. These multi-dimensional representations are then processed by the DWCA system, which establishes an efficient modeling framework for cross-scale temporal dependencies by combining bi-directional attention with learnable wavelet transforms. Building upon this foundation, the FreMLP bottleneck layer strategically performs selective feature optimization in the frequency domain, extracting key frequency information through spectral sparsification techniques to form an end-to-end multi-scale temporal feature learning pipeline. Experimental evaluations on six benchmark datasets demonstrate that FWBNet significantly outperforms state-of-the-art models, achieving mean squared error (MSE) reductions of 14% for multivariate and 21% for univariate predictions. This study presents a comprehensive framework for effective multi-scale temporal information integration in complex time series forecasting applications.},
  archive      = {J_EAAI},
  author       = {Qiang Lai and Yang You},
  doi          = {10.1016/j.engappai.2025.112161},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112161},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Frequency-wavelet adaptive basis network for long-term time series forecasting},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balanced sample repository for knowledge distillation in data-free image classification scenario. <em>EAAI</em>, <em>161</em>, 112160. (<a href='https://doi.org/10.1016/j.engappai.2025.112160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address strict data security and privacy requirements in the field of knowledge distillation for image classification, generative network-based data-free knowledge distillation produces fake images for training student models to perform image classification tasks. However, we discover that the datasets consisting of those fake images often suffer from imbalances, such as unclear class margins, uneven intra-class distribution, and skewed label distribution, impeding classification accuracy. To this end, this paper proposes the balanced sample repository method for data-free knowledge distillation in the context of image classification, comprising three components: dynamic pseudo-supervised loss weight (DLW), biased label generator (BLG), and intra-class homogeneity operator (IHO). Specifically, DLW adjusts the pseudo-supervised loss weight to maintain distinct class margins, BLG uses the roulette algorithm to balance label distribution, and IHO employs local outlier factors to remove outliers and homogenize intra-class distributions. The fake images generated by the generative network are initially stored in the sample repository, and those three components achieve a balanced dataset by influencing this sample repository. The experiments conducted across five recognized image classification datasets demonstrate that the proposed method achieves competitive results and produces more balanced samples.},
  archive      = {J_EAAI},
  author       = {Yafeng Sun and Xingwang Wang and Junhong Huang and Shilin Chen},
  doi          = {10.1016/j.engappai.2025.112160},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112160},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Balanced sample repository for knowledge distillation in data-free image classification scenario},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight detection model for green navel oranges in natural environments. <em>EAAI</em>, <em>161</em>, 112157. (<a href='https://doi.org/10.1016/j.engappai.2025.112157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In natural environments, the detection of green navel oranges in the unstructured plantings of Gannan navel oranges presents challenges, including low model accuracy and excessive parameter size. This paper integrates existing technologies to propose a lightweight green tangerine detection model based on You Only Look Once version 5s (YOLOv5s). The aim is to improve the accuracy of green tangerine identification and detection in natural environments through model improvements. Firstly, the original YOLOv5 network model is optimized by replacing the original CSPDarknet53 (Cross Stage Partial Darknet53) backbone network with MobileNetV3 in order to reduce model parameters. Concurrently, the Squeeze-and-Excitation (SE) module in the network is substituted with the Convolutional Block Attention Module (CBAM), resulting in a lightweight network. Secondly, CBAM is integrated into the C3 network (cross-stage partial bottleneck with three convolutional layers) in the neck region to enhance the model's ability to extract green navel orange features after lightweighting. Finally, improve the loss function of the model to reduce the positioning error of the model for low-quality targets. The experimental results demonstrate that the enhanced model attains a 3.6 % enhancement in precision, 2.3 % in recall, and 2.1 % in mean Average Precision (mAP) in comparison with the original YOLOv5 model. The model's size is 3.9 megabytes (MB), representing a reduction of 72.9 % from the original 14.4 MB. Research shows that our method provides an efficient and accurate solution for identifying green navel orange targets in complex environments, with potential application value in agricultural automation for orchard management and monitoring.},
  archive      = {J_EAAI},
  author       = {Dongyuan Zhang and Qiusheng Li and Xindi Yuan},
  doi          = {10.1016/j.engappai.2025.112157},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112157},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight detection model for green navel oranges in natural environments},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient real-time instance segmentation of garment for intelligent robot tie-dye based on you only look once version 11 network. <em>EAAI</em>, <em>161</em>, 112156. (<a href='https://doi.org/10.1016/j.engappai.2025.112156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tie-dye, as an intangible cultural heritage with a long history, has gained global popularity due to its unique artistic value and versatile craftsmanship. However, its reliance on manual operation leads to low production efficiency and inconsistent quality. To address this, we propose an improved You Only Look Once version-11 (YOLOv11) instance segmentation model, Garment-YOLO, to efficiently segment the garment regions of robotic tie-dye by artificial intelligence technology. First, the C3k2_DynamicMixFormer (C3k2_DMF) module introduces dynamic kernel weight selection mechanism and multi-scale fusion to effectively balance local details and global information. Meanwhile, the Dual-Cross Recalibration Feature Pyramid Network (DCR-FPN) is proposed to enhance the detail preservation of edge region by selectively aggregating semantic and boundary information. Furthermore, the Superior-Head replaces depthwise convolution (DWConv) with part convolution (PConv), significantly reducing model complexity while maintaining performance. Experimental results demonstrate that Garment-YOLO achieves 167.4 frames per second (FPS) and maintains an optimal trade-off between inference speed and segmentation accuracy, reaching 91.9 % mean average precision (mAP)50–95 (Box), 91.5 % mAP50-95 (Mask). To further validate its practical performance, we conducted a 72-h production-line comparison, showing that compared to the baseline, we increase the product qualification rate by 24.6 %, reduce dye waste by 19.4 %, and increase the total production by 52.5 % compared to manual tie-dye. This study not only provides a feasible solution for the intelligent transformation of traditional tie-dye but also contributes to the preservation and development of this intangible cultural heritage. The code will be released on GitHub ( https://github.com/fudifu123/GARMENT-YOLO ). A video that intuitively introduces our research ( https://www.bilibili.com/video/BV13MgczAEkB ).},
  archive      = {J_EAAI},
  author       = {Difei Feng and Qihong Zhou and Lei Xiao and Kunfeng Ge and Hangzhou Ma and Li Zhou},
  doi          = {10.1016/j.engappai.2025.112156},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112156},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient real-time instance segmentation of garment for intelligent robot tie-dye based on you only look once version 11 network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep patch network with spatiotemporal meta-parameter learning for soft sensor modeling of industrial processes. <em>EAAI</em>, <em>161</em>, 112155. (<a href='https://doi.org/10.1016/j.engappai.2025.112155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft sensing techniques have been widely employed in industrial processes to predict hardly measurable quality variables using easily measurable process variables. Effective modeling strategies for representing spatiotemporal features are highly desired in soft sensing applications for dynamic industrial processes. Deep networks, such as graph convolutional network and gated recurrent unit, are frequently employed to capture the spatial or temporal characteristics of sequential data. Nevertheless, effectively modeling and utilizing spatiotemporal heterogeneity remains a challenging problem. Thereby, a p atch network with spatiotemporal m eta- p arameter l earning (PMPL) is proposed in this paper, which presents an uniform framework of modeling spatiotemporal heterogeneous feature representations for soft sensing. In PMPL, a patching strategy is utilized to segment times series into sub-series-level patches, allowing the retention of local semantic information while capturing long-term dependencies. Next, a novel spatiotemporal meta-parameter learning approach is proposed to generate specific parameters for a spatial encoder, temporal encoder and spatiotemporal decoder through establishing corresponding embedding layers. In this way, the spatial, temporal and spatiotemporal dependencies within the process data can be adaptively captured and comprehensively refined from a uniform perspective. Extensive experiments are conducted based on two real production processes, which illustrate the feasibility and efficacy of the proposed model.},
  archive      = {J_EAAI},
  author       = {Xudong Shi and Kangping Du and Weili Xiong and Humberto Morales and Adriana Amicarelli},
  doi          = {10.1016/j.engappai.2025.112155},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112155},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep patch network with spatiotemporal meta-parameter learning for soft sensor modeling of industrial processes},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep bioinspired evolutionary stacking algorithm for unpaired multimodal cell classification calibration. <em>EAAI</em>, <em>161</em>, 112153. (<a href='https://doi.org/10.1016/j.engappai.2025.112153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-modality deep learning approaches for cell image classification exhibit inherent limitations in informational diversity when processing cross-institutional datasets acquired under varied imaging protocols. In contrast, multimodal cell imaging has emerged as a promising alternative for addressing data heterogeneity through comprehensive information integration. This study introduces a novel multimodal alternate training decision-making architecture based on a stacking algorithm for unpaired multimodal cell classification calibration. The method leverages deep bioinspired evolutionary networks combined with kernel-based support vector machines. Specifically, deep base classifiers incorporating multimodal concepts are derived from heterogeneous cell datasets. Each base classifier employs a bioinspired strategy to perform alternate training between two evolutionary densely connected attention networks. To mitigate class imbalance, where diseased cells are significantly outnumbered by normal cells, we incorporate a Shannon entropy loss term. Finally, multiple kernel-based support vector machines serve as meta classifiers, transforming high-level multimodal concepts into a separable feature space for robust decision-making. Experimental results demonstrate the superiority of our approach over existing algorithms for unpaired multimodal cell image classification. Our findings emphasize the importance of alternate training intra-modality classifiers and inter-modality fusion calibration for accurate and reliable medical image classification. All source code for this work will be publicly available on GitHub.},
  archive      = {J_EAAI},
  author       = {Lili Zhao and Di Xu and Xueping Tan and Jinzhao Yang and Weiping Ding and Hengde Zhu and Lichi Zhang and Qian Wang},
  doi          = {10.1016/j.engappai.2025.112153},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112153},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep bioinspired evolutionary stacking algorithm for unpaired multimodal cell classification calibration},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal-frequency joint hierarchical transformer with dynamic windows for speech emotion recognition. <em>EAAI</em>, <em>161</em>, 112152. (<a href='https://doi.org/10.1016/j.engappai.2025.112152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech Emotion Recognition (SER) aims to identify the emotional state of a speaker from speech signals, serving as a critical prerequisite for achieving natural human–computer interaction. In speech signals, emotional information is inherently distributed across diverse frequency bands and temporal scales, with emotional cues in distinct regions exhibiting varying levels of heterogeneity or interdependence. Existing Transformer-based methods face limitations in precisely localizing salient temporal-frequency regions and modeling their inter-regional relationships. To address these challenges, a temporal-frequency joint hierarchical Transformer with dynamic window mechanisms, abbreviated as TF-DWFormer, is proposed to capture critical emotional cues and their contextual dependencies across temporal-frequency dimensions. It operates through several principal phases: Firstly, a feature reconstruction module is designed to extract temporal, frequency, and temporal-frequency representations of emotional speech. Secondly, a high-low frequency-based emotion-aware partitioning strategy is designed to achieve the division of emotional regions. Thirdly, a local window within a hierarchical Transformer analyzes static intra-region correlations to capture fine-grained emotional patterns, while a dynamic window adaptively models temporal evolution across regions, learning dynamic inter-region relationships. Lastly, a dual-cross-attention mechanism is employed to synergize comprehensive emotion representation from different domains. Our evaluation experiments demonstrate that the proposed TF-DWFormer method achieves recognition accuracies of 73.68%, 91.67%, 92.59%, 74.42%, and 50.54% on the datasets IEMOCAP, CASIA, EMODB, eNTERFACE05, and MELD, respectively, outperforming existing SER methods. These results confirm the capability of TF-DWFormer to precisely localize salient regions, robustly model inter-region dependencies, and effectively fuse multi-domain information, providing a promising solution for advancing SER technology.},
  archive      = {J_EAAI},
  author       = {Yonghong Fan and Heming Huang and Huiyun Zhang and Ziqi Zhou},
  doi          = {10.1016/j.engappai.2025.112152},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112152},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Temporal-frequency joint hierarchical transformer with dynamic windows for speech emotion recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional reconstruction and fracture segmentation based on X-ray and computed tomography paired dataset. <em>EAAI</em>, <em>161</em>, 112151. (<a href='https://doi.org/10.1016/j.engappai.2025.112151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some orthopedic surgeries, the use of three-dimensional (3D) computed tomography (CT) scanning technology is not feasible due to scene limitations, leaving doctors to rely on two-dimensional (2D) X-ray images for real-time diagnosis. However, X-ray images lack 3D information, making accurate diagnosis challenging. Developing an algorithm to convert 2D X-ray images into 3D CT images, while simultaneously combining high-quality 3D reconstruction with precise fracture segmentation, offers a promising solution to the problem. In this study, we propose a novel artificial intelligence (AI)-driven framework named 3D reconstruction and segment anything model (3DRecSAM). The reconstruction image enhancer (RIE) is designed to achieve high-precision 3D reconstruction and provide high-quality feature initialization for fracture segmentation. Meanwhile, the mamba segment anything model (MSAM), based on the segment anything model (SAM) architecture, is developed for accurate fracture segmentation. We introduce a Kolmogorov–Arnold network (KAN)-based attention fusion module (KAF), which facilitates the joint optimization of the RIE reconstruction network and the MSAM segmentation network. Furthermore, the selective scanning mamba with KAN (SKM) is incorporated to enhance feature extraction for both RIE and MSAM. Mamba efficiently captures long-range dependencies and sequential patterns, while KAN’s learnable activation functions facilitate adaptive feature fusion and non-linear representation. To train and evaluate 3DRecSAM, we introduce the real X-ray and CT paired dataset (XCPData), which is publicly available on GitHub: https://github.com/YuanGao1201/XCPData .},
  archive      = {J_EAAI},
  author       = {Yuan Gao and Yuan Zhou and Da Chen and Jiachen Li and Mingle Zhou and Gang Li and Yunbo Gu and Jean-Louis Coatrieux and Yang Chen},
  doi          = {10.1016/j.engappai.2025.112151},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112151},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-dimensional reconstruction and fracture segmentation based on X-ray and computed tomography paired dataset},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised domain adaptation for lithology classification using dynamic entropy-based prototype learning. <em>EAAI</em>, <em>161</em>, 112150. (<a href='https://doi.org/10.1016/j.engappai.2025.112150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lithology classification plays a crucial role in geological exploration and resource evaluation. However, the significant distribution discrepancies between source and target domains, coupled with the unavailability of source domain data, pose substantial challenges to traditional domain adaptation methods. To address these challenges, we propose an innovative framework, Unsupervised Domain Adaptive Dynamic Entropy Prototype Learning (UDADEPL), which leverages a source-free unsupervised domain adaptation strategy for lithology classification. The UDADEPL framework consists of a frozen source pre-trained model and a trainable target model, incorporating a dynamic entropy-based prototype learning matrix for reliable sample selection and centroid-based pseudo-label learning for iterative optimization. Additionally, an information maximization loss and source domain regularization loss are integrated into a curriculum learning strategy to balance feature extraction and domain adaptation. This approach enables the model to effectively handle complex lithological boundaries and class imbalances in the target domain. Extensive experiments on datasets from the Tarim Oilfield and Hugoton–Panoma field demonstrate the superiority of UDADEPL over traditional machine learning and advanced deep learning models. UDADEPL achieves superior classification accuracy, outperforming the best baseline models, especially in cross-domain adaptation and complex lithology identification.},
  archive      = {J_EAAI},
  author       = {Hengxiao Li and Yahui Liu and Lu Liu},
  doi          = {10.1016/j.engappai.2025.112150},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112150},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised domain adaptation for lithology classification using dynamic entropy-based prototype learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transforming physics-informed machine learning to convex optimization. <em>EAAI</em>, <em>161</em>, 112149. (<a href='https://doi.org/10.1016/j.engappai.2025.112149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Machine Learning (PIML) offers a powerful paradigm of integrating data with physical laws to address important problems in engineering, such as parameter estimation, inferring hidden physics, equation discovery, and state prediction. However, PIML, such as Physics-Informed Neural Networks (PINNs), still lack the necessary accuracy, stability, and interpretability when applying in practical engineering due to many serious optimization challenges including the spectral bias, non-convex optimization, multi-objective optimization, and non-smooth optimization. In this study, we propose the Convex-PIML based on convex optimization and basis functions widely used in well-established numerical solvers to overcome all these limitations. The linear combination of B-splines is utilized to approximate the data, promoting the convexity of the loss function. By dividing variables into blocks and replacing the non-convex loss terms with convex approximations, the problem is further converted into a sequence of successively refined approximated convex optimization problems. This conversion known as Block Successive Convex Approximation (BSCA) allows the use of well-established convex optimization algorithms, obtaining solutions effectively and efficiently. Furthermore, an adaptive knot optimization method is introduced to mitigate the spectral bias issue of PIML, further improving the performance. The proposed fully adaptive framework by combining the adaptive knot optimization and BSCA is tested in scenarios with distinct types of physical prior. The results indicate that optimization problems are effectively solved in these scenarios, highlighting the potential of the framework for broad applications. Note that the Convex-PIML is also flexible since many other basis functions can also be incorporated to handle different systems.},
  archive      = {J_EAAI},
  author       = {Letian Yi and Siyuan Yang and Ying Cui and Zhilu Lai},
  doi          = {10.1016/j.engappai.2025.112149},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112149},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transforming physics-informed machine learning to convex optimization},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time fuzzy tracking control for networked suspension systems under gilbert-elliott fading channels. <em>EAAI</em>, <em>161</em>, 112148. (<a href='https://doi.org/10.1016/j.engappai.2025.112148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the finite-time ℓ 2 − ℓ ∞ fuzzy tracking control problem for networked suspension systems operating under Gilbert-Elliott fading channels. Firstly, the suspension system is established based on interval type-2 fuzzy rules to effectively describe the nonlinearity and uncertainty inherent in the model. Secondly, the Gilbert-Elliott model is employed to characterize the random switching behavior of channel states (good channel and fading channel) under real-world conditions. The timely identification of the current channel state is achieved through a mode detection method. To address channel fading and communication constraints, a novel mode-dependent controller is proposed. Simultaneously, we aim to minimize unnecessary and redundant communication. The hybrid scheduling strategy of the FlexRay protocol is utilized to transmit the measurement output data to the observer, and a saturation function is introduced in the observer to minimize the impact of outliers. Subsequently, the design conditions for stochastic finite-time boundedness and ℓ 2 − ℓ ∞ performance of the augmented system is proposed. Finally, simulation results demonstrate that the proposed algorithm is practically viable in dealing with complex environments, such as Gilbert-Elliott fading channels, outliers, and communication constraints.},
  archive      = {J_EAAI},
  author       = {Li-Juan Cai and Xiao-Heng Chang and Xin-Yue Zhao},
  doi          = {10.1016/j.engappai.2025.112148},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112148},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Finite-time fuzzy tracking control for networked suspension systems under gilbert-elliott fading channels},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RT-FedFlow: An efficient framework for real-time traffic signal optimization using federated multi-agent reinforcement learning. <em>EAAI</em>, <em>161</em>, 112147. (<a href='https://doi.org/10.1016/j.engappai.2025.112147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of Traffic Signal Control (TSC) is a critical component of the Intelligent Transportation System (ITS) in smart cities, aiming to eliminate traffic congestion and improve urban mobility. However, traditional approaches to TSC often rely on centralized data processing, limiting scalability and adaptability to real-time traffic dynamics while raising concerns about data privacy, communication, and computation. To address these challenges, this paper proposes the RT-FedFlow, a novel federated multi-agent reinforcement-learning (FMARL) framework for real-time traffic signal optimization. The framework employs enhanced FMARL techniques to enable decentralized collaboration among multiple traffic signal agents, optimizing traffic flow while seamlessly balancing local adaptability and global coordination. Federated model aggregation enables agents to collaboratively learn a global policy while preserving local data privacy, with each reinforcement learning (RL) agent independently optimizing its policy. Next, an advanced reward mechanism is designed to minimize congestion and reduce waiting times. Moreover, a hierarchical communication and coordination strategy is adopted to facilitate efficient local interaction among agents and global model aggregation to improve overall system performance. In addition, the framework enables real-time optimization and prioritization of emergency vehicles through a dedicated preemption module. Compared to existing TSC models, RT-FedFlow significantly improves traffic signal coordination and response times by dynamically adapting to complex, real-time traffic conditions. The proposed RT-FedFlow framework is implemented and evaluated using the SUMO simulator. Extensive simulation results demonstrate that RT-FedFlow outperforms all benchmark models, achieving a 15.49 % reduction in average inference time, a 3.07 % reduction in average queue length, a 13.04 % reduction in average intersection delay, a 0.20 % improvement in fuel consumption, and a 5.35 % emergency vehicle clearance time.},
  archive      = {J_EAAI},
  author       = {Ayaz Akbar and Syed Sajid Ullah and Abdul Malik and Saeed Mian Qaisar},
  doi          = {10.1016/j.engappai.2025.112147},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112147},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RT-FedFlow: An efficient framework for real-time traffic signal optimization using federated multi-agent reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid data-driven model for state of health estimation of lithium-ion battery with capacity recovery. <em>EAAI</em>, <em>161</em>, 112146. (<a href='https://doi.org/10.1016/j.engappai.2025.112146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The failure of lithium-ion batteries has attracted the attention of researchers. Monitoring the degradation process through sensor-based state-of-health (SOH) assessment enables early detection of anomalies and facilitates timely interventions to prevent catastrophic failures. During battery degradation, the phenomenon of capacity recovery makes it complicated to accurately evaluate the SOH. However, existing works usually neglect this phenomenon. In this paper, we propose a hybrid model focusing on capacity recovery. The model consists of four modules: a feature extraction module, a data decomposition module, a global trend assessment module, and a local fluctuation assessment module. Specifically, in the feature extraction module, a convolutional neural network extracts features from the input data that effectively characterize the capacity degradation process. The data decomposition module applies empirical mode decomposition (EMD) to separate local fluctuations caused by capacity recovery from the global degradation trend. These components are then input into their respective assessment modules. Additionally, the local fluctuation assessment module incorporates an attention mechanism that adaptively identifies the similarity between extracted features and health states, thereby enhancing the evaluation of local fluctuations. The proposed model is validated using the NASA (National Aeronautics and Space Administration) battery dataset, demonstrating its effectiveness in addressing the challenges of SOH prediction under capacity recovery conditions.},
  archive      = {J_EAAI},
  author       = {Yu Lin and Luo Zhou and Jianhai Yan and Shuguang He},
  doi          = {10.1016/j.engappai.2025.112146},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112146},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid data-driven model for state of health estimation of lithium-ion battery with capacity recovery},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel localization algorithm integrated with sensor fusion for position estimation of mobile robot in the road following and roundabout environment. <em>EAAI</em>, <em>161</em>, 112145. (<a href='https://doi.org/10.1016/j.engappai.2025.112145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel Artificial Intelligence algorithm based autonomous mobile robot localization in road environments is presented in this paper. The sensor fusion data, employing camera and odometry, are used to build the local maps for road environment. The localization of the robot is performed using a novel Artificial Intelligence algorithm, called Priori-Posteriori-Laser-Simulator, to find the position and heading-angle of robot along movement in two phases, namely priori and posteriori stages as 1st phase and Kalman filter in 2nd phase. In the priori stage, the path of the robot is planned in the built-map using Laser Simulator through generating a series of points as lines to drive the robot in the middle of the road environments. In the posteriori-stage, the position and robot heading angle are measured using sensor fusion system and the laser-simulator updates the position accordingly through a comparison between the planned and actual positions. The Kalman filter is used in 2nd phase to remove noise and enhance to enhance the localization accuracy. The proposed algorithm has been tested in indoor and outdoor road environments to show its effectiveness and performance for localizing robot in such environments. It is also compared with fuzzy-logic, adaptive H-infinity filter, fuzzy logic with Kalman filter and Oriented-Rotated Binary Simultaneous Localization and Mapping 2 algorithms on localizing robot at road environment. Results show the capability of the proposed algorithm to enable the robot to move effectively in road environments, recognize the features of road terrains and localize the robot during autonomous navigation in road environments.},
  archive      = {J_EAAI},
  author       = {Mohammed A.H. Ali and Nukman Yusoff and Bushroa Abd Razak and Sherzod Turaev and Rawad Abdulghafor and Aisha Muhammad},
  doi          = {10.1016/j.engappai.2025.112145},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112145},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel localization algorithm integrated with sensor fusion for position estimation of mobile robot in the road following and roundabout environment},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electroencephalography-based emotion recognition using a dual-stream multi-scale spatiotemporal convolutional capsule network. <em>EAAI</em>, <em>161</em>, 112144. (<a href='https://doi.org/10.1016/j.engappai.2025.112144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, emotion recognition using electroencephalogram (EEG) signals has gained significant attention. However, shallow convolutional neural networks used in EEG emotion recognition are ineffective at capturing spatial relationships between features, adversely affecting model performance. To solve this problem, this study proposes a dual-stream multi-scale spatiotemporal convolutional capsule network aimed at improving EEG-based emotion recognition. The novelty of our approach is the dual-stream multi-scale spatiotemporal design, which enables parallel extraction and fusion of temporal and spatial EEG features at multiple scales, offering a richer and more discriminative representation for emotion recognition. Specifically, a dual-stream feature construction module is developed to extract multi-scale temporal and spatial features from raw EEG signals. A hybrid spatiotemporal attention mechanism enhances feature fusion, while a capsule-based classifier improves recognition accuracy by modeling relationships between local and global features. Experimental results using subject-dependent 10-fold cross-validation show average accuracies of 97.72%, 97.56%, and 97.82% for valence, arousal, and dominance on the Dataset for Emotion Analysis using Physiological signals(DEAP), with average F1 scores of 97.83%, 97.51%, and 97.68%. For the Dataset for Emotion Analysis using Physiological signals(DREAMER 1 ), the average accuracies are 96.48%, 96.32%, and 96.35%, with corresponding F1 scores of 96.23%, 95.74%, and 95.66%. The proposed method outperforms existing state-of-the-art approaches on both datasets, reducing the number of parameters by 58.07% and decreasing inference time by approximately 50.86% and 33.39%, compared to Residual Network 18. Additionally, in the subject-independent leave-one-subject-out cross-validation, the proposed method demonstrated results that significantly outperformed the baseline model across both datasets. Experiments show that the proposed method enhances spatiotemporal feature extraction and improves emotion recognition accuracy. This method reduces computational resource consumption and enhances recognition accuracy, thereby facilitating efficient algorithm development and deployment for real-time emotion monitoring and related applications.},
  archive      = {J_EAAI},
  author       = {Han Cai and Pengfei Lu and Xiaofang Wang and Yuxing Wang},
  doi          = {10.1016/j.engappai.2025.112144},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112144},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Electroencephalography-based emotion recognition using a dual-stream multi-scale spatiotemporal convolutional capsule network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse structural design with generative and probabilistic autoencoders and diffusion models. <em>EAAI</em>, <em>161</em>, 112143. (<a href='https://doi.org/10.1016/j.engappai.2025.112143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional structural design is a forward trial-and-error process. Designers need to iterate through different design solutions and conduct structural analysis until the design meets the codes and standards. This study proposes and investigates a generative machine learning (ML) framework for inverse design of continuous beam systems. Three generative ML models, including conditional variational autoencoder (CVAE), conditional autoencoder with maximum likelihood estimation (CAE-MLE), and denoising diffusion models (DDMs) are trained and fine-tuned on the CBeamXP (Continuous Beam Cross-section Predictors) dataset with 1,000,000 beam sections to generate the cross sectional properties. Research results show that CAE-MLE achieves the highest generation accuracy and robustness, while CVAE offers more variability through latent space sampling. DDMs provide controllable generation variability via a stochasticity parameter in the inverse diffusion process. The proposed framework enables efficient generation of multiple design solutions and can potentially accelerate the conceptual design workflows in structural engineering. This work also demonstrated the feasibility toward artificial intelligence (AI)-assisted structural design using generative approaches and tabular datasets.},
  archive      = {J_EAAI},
  author       = {Bozhou Zhuang and Adrien Gallet and Danny Smyl},
  doi          = {10.1016/j.engappai.2025.112143},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112143},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inverse structural design with generative and probabilistic autoencoders and diffusion models},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective generative design framework and realization for quasi-serial manipulator: Considering kinematic and dynamic performance. <em>EAAI</em>, <em>161</em>, 112142. (<a href='https://doi.org/10.1016/j.engappai.2025.112142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a framework for optimizing the linkage mechanism of a quasi-serial manipulator for target tasks. The process is illustrated through a case study of a two-degree-of-freedom (2-DOF) linkage mechanism, which significantly influences the workspace of the quasi-serial manipulator. First, a diverse set of quasi-serial mechanisms is generated with workspaces that satisfy the target task and is converted into three-dimensional computer-aided design (3D CAD) models. Then, kinematic and dynamic analyses are conducted to compute workspace and payload torque labels for surrogate model training. Adaptive sampling is employed to identify an appropriate amount of training data for accurate prediction, while ensemble models are utilized to enhance robustness. After model training, a multi-objective optimization problem is formulated under the mechanical and dynamic constraints of the manipulator. The design objective is to recommend quasi-serial mechanisms with optimized kinematic (workspace) and dynamic (payload torque) performance that fulfill the target task. To explore the underlying physics of the Pareto solutions obtained via the Non-Dominated Sorting Genetic Algorithm (NSGA-II), various data mining techniques are applied to extract design rules that offer practical guidance. Finally, a detailed manipulator is realized using 3D-printed parts with topology optimization, and its performance is verified through a payload test. These results demonstrate the potential of the proposed framework for broader mechanism applications and its capability to support practical design decisions through design rule extraction.},
  archive      = {J_EAAI},
  author       = {Sumin Lee and Sunwoong Yang and Namwoo Kang},
  doi          = {10.1016/j.engappai.2025.112142},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112142},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective generative design framework and realization for quasi-serial manipulator: Considering kinematic and dynamic performance},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain and deep learning-enabled IoT device-to-device authentication approach for smart cities using 5th generation technology. <em>EAAI</em>, <em>161</em>, 112141. (<a href='https://doi.org/10.1016/j.engappai.2025.112141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As smart cities evolve, the increasing number of Internet of Things (IoT) devices requires secure authentication mechanisms for device-to-device (D2D) communication, especially within 5G networks. To address security challenges in D2D communication, Blockchain (BC) technology is utilized. Existing methods face issues like single-point failure attacks, high implementation costs, and data privacy concerns. This work aims to develop a secure and efficient authentication model leveraging BC technology and a Deep Q Network (DQN) for key generation to enhance IoT security in smart city applications. A novel authentication model, Deep Q Network-SecAuth (DQN-SecAuth), is proposed for secure D2D communication using BC. The model involves key entities such as the Registration Authority Center (RAC), blockchain, and IoT devices. The authentication process includes six stages: setup, registration, key generation, authentication, new device addition, and formal verification. In the key generation stage, the secret key is generated using a Deep Learning (DL) model named DQN. The proposed model also incorporates encryption, hash functions, Chebyshev polynomials, and XOR operations to ensure security. The DQN-SecAuth model achieved a minimum computational time of 9.525 s and memory usage of 42.897 megabytes (Mb), consensus delay of 0.420 s, energy consumption of 0.715 J, latency of 0.469 s, power consumption of 0.270 kW-hour (kWh), and throughput of 0.804 megabits per second (Mbps). The key novelty of this work is the use of a DQN for adaptive key generation, integrated into a BC-based authentication framework. This combination enhances security, reduces computational overhead, and outperforms traditional static key-generation and authentication methods in smart city IoT environments.},
  archive      = {J_EAAI},
  author       = {K. Prabhu Chandran and Bhuvaneswari P and Sivasankaran V and Vimala S},
  doi          = {10.1016/j.engappai.2025.112141},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112141},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Blockchain and deep learning-enabled IoT device-to-device authentication approach for smart cities using 5th generation technology},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergency medical facility site selection in drone-based relief operations using an enhanced T-spherical fuzzy frank combined compromise solution method. <em>EAAI</em>, <em>161</em>, 112140. (<a href='https://doi.org/10.1016/j.engappai.2025.112140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) play a vital role in disaster response operations, emphasizing the need for efficient site selection for emergency medical facilities (EMFs). This study presents a structured framework for evaluating candidate sites and identifying critical criteria for establishing EMFs in drone-based relief operations. It proposes a novel T-spherical fuzzy (T-SF) multi-criteria group decision-making framework for EMF site selection. The framework integrates the T-SF-Entropy method and a hybrid subjective–objective weighting scheme that combines stepwise weight assessment ratio analysis and the method based on the removal effects of criteria. This integration enables a more reliable aggregation of expert opinions. The framework applies T-SF Frank aggregation operators in the modified combined compromise solution method to rank potential sites under multi-disaster conditions. A real-world case study evaluates alternative sites using the critical criteria and demonstrates the practical utility of the proposed model in the field of emergency engineering logistics. Quantitative analysis shows that the “urban logistics hub” achieves the highest compromise index due to its advantages in proximity, infrastructure, and supply chain access. Sensitivity analysis confirms that variations in parameters do not affect the stability of rankings. This study uses artificial intelligence to support intelligent decision-making in disaster response. It provides an effective engineering application that optimizes UAV-based healthcare deployment, enhances resource allocation, and improves the speed and accuracy of emergency medical responses.},
  archive      = {J_EAAI},
  author       = {Rajdip Mahajan and Saptadeep Biswas and Vladimir Simic and Dragan Pamucar and Abhijit Baidya and Uttam Kumar Bera},
  doi          = {10.1016/j.engappai.2025.112140},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112140},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Emergency medical facility site selection in drone-based relief operations using an enhanced T-spherical fuzzy frank combined compromise solution method},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature description attention: Channel-independent local–global fusion for multi-scale feature representation. <em>EAAI</em>, <em>161</em>, 112139. (<a href='https://doi.org/10.1016/j.engappai.2025.112139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent deep convolutional networks, attention mechanisms rely heavily on global information to generate attention weights, but few methods can effectively recalibrate global features based on local object characteristics. To address this gap, we introduce a masked-averaging strategy that adaptively selects regions of interest from the feature map, allowing local features to encode and reflect global information. By combining these local descriptors with global averages and maximums into a multi-scale Bag-of-Visual-Words (BoVW), our method jointly captures salient point, local region, and global context, resulting in richer and more discriminative feature representations. Additionally, we propose Feature Batch Normalization (FBN) to facilitate cross-channel interactions, further enhancing the performance of attention modules. In terms of engineering applications, to overcome the limitations of traditional channel-dependent attention under model compression and pruning, we design a channel-independent feature recalibration mechanism based on one-dimensional depthwise convolution, termed Feature Description Attention (FDA). It leverages the properties of BoVW and FBN to provide a flexible and lightweight attention module with minimal computational overhead and robust performance under quantization and pruning. Our method demonstrates consistent gains across three vision tasks: classification accuracy improves by 0.72–1.68%, object detection performance increases by 1.8–3.0% mean average precision, and segmentation accuracy rises by 1.9%. These results across different benchmarks confirm the effectiveness and generalizability of our approach. FDA offers a scalable, hardware-friendly solution for modern vision applications, especially valuable in resource-constrained settings such as mobile deployment, autonomous systems, and medical image analysis.},
  archive      = {J_EAAI},
  author       = {Yuanyang Zhu and Guangjie Han and Hongbo Zhu and Fan Zhang},
  doi          = {10.1016/j.engappai.2025.112139},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112139},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature description attention: Channel-independent local–global fusion for multi-scale feature representation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving robustness of transformers for power quality disturbance classification via optimized relevance maps. <em>EAAI</em>, <em>161</em>, 112138. (<a href='https://doi.org/10.1016/j.engappai.2025.112138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power quality disturbances (PQDs) are a critical area of research in the power systems domain. The growing complexity of modern power systems increases the variability of PQDs that may occur, making it challenging to manage power quality using traditional methods, and motivates the inclusion of machine learning models. However, these models are vulnerable to adversarial attacks. The predominant defense approach is adversarial training, which increases robustness at the price of significant increase in computational complexity of the training process, and can often lead to reduced accuracy on non-adversarial examples. In this light, this paper introduces a distinct approach to increase the robustness of Transformer-based PQD classifiers by leveraging their intrinsic explainability derived from the self-attention mechanism. By incorporating the resulting explainable features in the form of relevance maps into the loss function during the fine-tuning stage, we guide the model to focus on salient disturbance features. This method enhances the robustness against adversarial attacks, without compromising accuracy, and avoids the additional computational overhead associated with adversarial training. Experimental results show that when no adversarial attack is applied, the fine-tuning stage increases the PQD classification accuracy from 97.62% to 99.26%, thus overcoming the accuracy-robustness trade-off. Furthermore, the Transformer with the proposed fine-tuning stage is more adversarial robust than a state-of-the-art deep Convolutional neural network (DeepCNN) PQD classifier. The proposed Transformer maintains accuracy and F1 scores slightly above 88%, whereas fo DeepCNN both scores are slightly below 66.60%, thus highlighting the effectiveness of our approach.},
  archive      = {J_EAAI},
  author       = {Itamar Kapuza and Elinor Ginzburg-Ganz and Ram Machlev and Yoash Levron},
  doi          = {10.1016/j.engappai.2025.112138},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112138},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving robustness of transformers for power quality disturbance classification via optimized relevance maps},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive epipolar geometry for robust light field super-resolution. <em>EAAI</em>, <em>161</em>, 112137. (<a href='https://doi.org/10.1016/j.engappai.2025.112137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light field technology captures both spatial and angular information, densely sampled high-resolution light field images contain abundant 3-dimensional geometric information, enabling widespread applications in various industrial fields. However, existing methods for joint spatial and angular super-resolution of light field images face significant challenges when reconstructing scenes with large disparities and significant occlusions. To address this issue, we propose a geometric information enhancement module that enables efficient extraction and preservation of geometric information, and then we propose a non-disparity-based, one-stage approach that allows for the direct reconstruction of densely sampled high-resolution light field images from sparsely sampled low-resolution counterparts. Specifically, we decompose the original 4-dimensional light field image into three distinct 2-dimensional representations: spatial, angular, and epipolar plane image. Among these representations, the epipolar plane image contains abundant geometric information, which inspires us to propose a more efficient feature extractor. In addition, we introduce a progressive feature fusion strategy that better preserves geometric information extracted from epipolar plane images. Finally, to avoid errors introduced by warping operations that complicate the process of enhancing geometric information, we introduce a spatial-angular integrated upsampling module. Extensive experimental results on public datasets demonstrate that our proposed method significantly outperforms state-of-the-art approaches both quantitatively and qualitatively. Specifically, on the Occlusions dataset, our method achieved significant improvement in performance while reducing inference time by approximately 80% compared to the current best method. This efficiency gain is particularly beneficial for practical applications of the artificial intelligence algorithm.},
  archive      = {J_EAAI},
  author       = {Hao Zhang and Hao Sheng and Rongshan Chen and Da Yang and Ruixuan Cong and Zhenglong Cui and Xuefei Huang and Guanqun Su},
  doi          = {10.1016/j.engappai.2025.112137},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112137},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Progressive epipolar geometry for robust light field super-resolution},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring knee joint moment prediction models for landing task with various model architecture: Leveraging inertial measurement unit sensors data and subject-specific attributes. <em>EAAI</em>, <em>161</em>, 112136. (<a href='https://doi.org/10.1016/j.engappai.2025.112136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a comparative evaluation of deep learning models for predicting Three-Dimensional (3D) knee joint moments during landing tasks using Inertial Measurement Unit (IMU) data. We assess a range of architectures, from simple feedforward networks to complex Three-Dimensional Convolutional Neural Networks (3D-CNN), to balance predictive accuracy with computational cost. The 3D-CNN model achieved the highest performance, with relative Root Mean Squared Error (rRMSE) values of 6.08 % for the knee abduction moment, 5.3 % for the external rotation moment, and 4.9 % for the flexion moment. We further explored the effect of adding subject-specific features, which yielded modest performance gains. While these features provided some improvement, model performance primarily depended on sensor data, reinforcing the need to integrate both biomechanical and Artificial Intelligence-driven insights. From an engineering application perspective, our findings guide researchers and clinicians in selecting the most suitable model and sensor placement based on both accuracy and computational complexity. Specifically, we highlight thigh-mounted IMU as the most effective placement for capturing landing dynamics. These insights support the practical deployment of knee joint moment prediction systems in real-world settings, such as gyms or training centers, where compact sensors and limited computational resources are essential.},
  archive      = {J_EAAI},
  author       = {Tommy Sugiarto and Yi-Jia Lin and Ya-Wen Tu and Hsiao-Liang Tsai and Lin-Fen Hsieh and Chi-Tien Sun and Patrik Kutilek and Wei-Chun Hsu},
  doi          = {10.1016/j.engappai.2025.112136},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112136},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring knee joint moment prediction models for landing task with various model architecture: Leveraging inertial measurement unit sensors data and subject-specific attributes},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key region semantic information augmented transformer for image captioning. <em>EAAI</em>, <em>161</em>, 112135. (<a href='https://doi.org/10.1016/j.engappai.2025.112135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing image captioning models often face difficulties in capturing inter-object relationships and generating description that comprehensively understands the entire image content, either relying on object detectors that overlook contextual information or depending on grid features that fail to adequately model spatial interactions. This paper proposes two solutions to these challenges. The first is the introduction of a module for mining semantic information from key regions. Based on the spatial proximity and high co-occurrence between objects, this module identifies the public region covered by these objects as a key region, mines their semantic information, and incorporates it into the modeling process, which compensates for the limitations of grid features. Second, we improve the standard Transformer decoder’s architecture by innovatively introducing an adaptive gating mechanism that dynamically adjusts the alignment between textual and visual features, enhancing the model’s overall comprehension of the image. To validate our approach, we applied these modules to the Transformer framework and proposed a novel method for image captioning, called Key region Semantic information Augmented Transformer (KSAT) for Image Captioning. Extensive experiments on benchmark datasets show that the proposed method outperforms many models. Specifically, our method achieves a score of 139.6% on the offline test, and 138.4% on the official online test server on the Consensus-based Image Description Evaluation (CIDEr) metric. In qualitative evaluation, our method also outperforms other methods at generating captions for complex scenes. Overall, these results confirm the validity of our method and advance the field of artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Fuyun Deng and Wei Li and Zhixin Li},
  doi          = {10.1016/j.engappai.2025.112135},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112135},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Key region semantic information augmented transformer for image captioning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced neural-network-based iterative learning control considering iterative uncertainties for piezoelectric actuated micro-positioning platform. <em>EAAI</em>, <em>161</em>, 112134. (<a href='https://doi.org/10.1016/j.engappai.2025.112134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research aims to developing a new enhanced data-driven sliding-mode iterative learning control (E-DDSILC) strategy for piezoelectric actuated micro-positioning (PAMP) platforms. For the first time, the analysis demonstrating that errors converge to 0 in E-DDSILC is successfully extended from strictly repetitive systems to systems with non-strictly repetitive initial conditions. This generalization expands the practical application range of E-DDSILC. Simultaneously, iterative uncertainties are considered, which are the major factor affecting the performance of iterative learning control. To address these uncertainties, a diagonal recurrent neural network is employed to fit and compensate for them within a dynamic linearization model, thereby further enhancing the tracking accuracy and practicability of E-DDSILC. Finally, Several experiments are performed on a PAMP platform to compare the developed E-DDSILC method with both classical DDSILC and traditional E-DDSILC schemes. Comparative experimental results prove the superiority of the developed controller.},
  archive      = {J_EAAI},
  author       = {Miaolei Zhou and Yulong Sun and Xiuyu Zhang and Wei Gao and Chun-Yi Su},
  doi          = {10.1016/j.engappai.2025.112134},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112134},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced neural-network-based iterative learning control considering iterative uncertainties for piezoelectric actuated micro-positioning platform},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-driven multi-stage stochastic optimization for sustainable humanitarian supply chain using machine learning algorithms. <em>EAAI</em>, <em>161</em>, 112133. (<a href='https://doi.org/10.1016/j.engappai.2025.112133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The frequency and severity of natural disasters have intensified, resulting in significant human, financial, and emotional consequences. Earthquakes, in particular, have caused severe economic losses, deaths, and homelessness among millions. This study is designed to establish a comprehensive plan for managing pre- and post-disaster phases, including preparations, responses, and recovery efforts. It introduces a Multi-Stage Stochastic Programming (MSSP) model for sustainable humanitarian relief operations, optimizing location, allocation, and inventory management. The first and third stages concentrate on minimizing environmental impacts, while the second stage centers on enhancing social welfare. Simultaneously, economic cost reduction is consistently pursued in all three stages. The model's primary advantages include optimized inventory management to avoid shortages and flexible logistics strategies for timely and cost-effective delivery of relief items. Additionally, it ensures continuous aid, addressing both short-term and long-term needs to improve disaster management effectiveness and resilience. The multi-objective model is solved using Augmented Epsilon-Constraint (AEC). Furthermore, this paper employs Multi-Criteria Decision-Making (MCDM) methods to rank suppliers, leveraging Machine Learning (ML) algorithms to enhance ranking precision, thereby leading to a more responsive Supply Chain (SC). A real-world case study is then provided to illustrate the applicability and validity of the proposed model. Focusing on achieving balanced sustainability across all three stages, ensuring seamless logistics for all humanitarian supplies and affected individuals, and addressing uncertainties, the model determines the optimal quantities of all relief items to store. Through comprehensive analysis, the results provide key insights into the importance of MSSP in disaster management plans, enhancing understanding of the model's effectiveness.},
  archive      = {J_EAAI},
  author       = {Farnaz Ansari and Ali Bozorgi-Amiri and Hossein Shakibaei},
  doi          = {10.1016/j.engappai.2025.112133},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112133},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A data-driven multi-stage stochastic optimization for sustainable humanitarian supply chain using machine learning algorithms},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A theme music generation model based on hybrid variational autoencoders and conditional generative adversarial networks. <em>EAAI</em>, <em>161</em>, 112131. (<a href='https://doi.org/10.1016/j.engappai.2025.112131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The musical theme is the core melodic element that runs through a work. It is the main source of recognizable features and the basis of the overall structure of the score. However, existing music generation systems often face problems with missing thematic features and monotonous structure. These systems find it difficult to capture the complex thematic changes and long-term dependencies in music, resulting in a lack of dynamic changes, artistic expression in phrasing, and structural coherence in the generated results. In this paper, we propose a thematic music generation model based on a generative adversarial network, named Thematic Music Conditional Generative Adversarial Network (TM-CGAN), which solves these challenges through three key innovations. First, we propose a thematic fusion degree calculation module based on multi-dimensional feature metrics to overcome the theoretical limitations of existing methods, which lack explicit modeling of thematic features. Subsequently, we construct a two-dimensional image representation learning framework that preserves Musical Instrument Digital Interface (MIDI) symbolic sequences and employs convolutional neural networks (CNNs) to effectively model the multi-dimensional feature dependencies inherent in musical structures. Finally, we design a hybrid variational autoencoder-conditional generative adversarial network architecture that processes latent space modeling of thematic features through variational inference mechanisms while simultaneously optimizing generation quality through adversarial training. We conducted comprehensive experiments across three diverse MIDI music datasets to validate our approach. The experimental results demonstrate that TM-CGAN significantly outperforms state-of-the-art baseline models on multiple evaluation metrics, including generated music quality, theme representativeness, and structural integrity.},
  archive      = {J_EAAI},
  author       = {Fangzhu Jin and Peng Li and Xiaojun Wu},
  doi          = {10.1016/j.engappai.2025.112131},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112131},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A theme music generation model based on hybrid variational autoencoders and conditional generative adversarial networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Malicious detection and trust calculation using residual recurrent neural network for trust with quality of service-aware multicast routing in mobile ad-hoc network system. <em>EAAI</em>, <em>161</em>, 112130. (<a href='https://doi.org/10.1016/j.engappai.2025.112130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Mobile Ad-hoc Network is a collection of mobile nodes without any proper infrastructure. In this work, a novel trust and Quality of Service-aware multicast routing technique for Mobile Ad-hoc Network is introduced. The key scope of this research paper is to evaluate the trust with Quality of Service -aware multicast routing process in Mobile Ad-hoc Network by detecting malicious nodes. For performing the optimal routing without any suspicious attacks initially the malicious node detection is performed by Residual Recurrent Neural Network. Further, if the Mobile Ad-hoc Network model is normal and free from malicious nodes, then the true value is calculated by utilizing the outcome of malicious node detection. If the node is free from malicious then, the trust value becomes high or else the trust value becomes low. Once, the trust calculation is completed the optimal routing is performed in the Mobile Ad-hoc Network with the support of the Enhanced Artificial Rabbits Optimization algorithm. Moreover, different constraints like hop count, throughput, Packet Delivery Ratio, delay, and energy consumption are derived. Further, different experiments are evaluated to prove the effectiveness of the implemented model against several baseline technique. Hence, the developed model accomplishes superior efficiency in detecting the malicious and performs the multicast routing in the Mobile Ad-hoc Network.},
  archive      = {J_EAAI},
  author       = {Sanjaya Kumar Sarangi and Rasmita Lenka and Janmejaya Mishra and Ritarani Sahu and Arabinda Nanda},
  doi          = {10.1016/j.engappai.2025.112130},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112130},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Malicious detection and trust calculation using residual recurrent neural network for trust with quality of service-aware multicast routing in mobile ad-hoc network system},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy management system scheduling optimization based on an improved generative adversarial network deep reinforcement learning algorithm. <em>EAAI</em>, <em>161</em>, 112129. (<a href='https://doi.org/10.1016/j.engappai.2025.112129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Households, as electricity consumers, play a critical role in achieving the carbon peak and carbon neutrality goals. The development of smart grids provides technical support for the efficient integration and distribution of renewable energy, gradually extending to household users. This has led to higher demands for the stability of electricity supply to address the growing electricity demand and the uncertainties associated with renewable energy. To address this, this paper proposes an improved generative adversarial network and an enhanced deep reinforcement learning algorithm to improve the scheduling capability of the energy management system. First, we introduce an improved wasserstein generative adversarial network that combines stochastic differential equations and autocorrelation penalty terms with the generator. The experimental results demonstrate that the proposed method can generate high-quality time series data. The generated data were used to train our scheduling model, effectively enhancing its generalization capability. Secondly, We introduced the Minmax mechanism to address Q-value estimation bias by utilizing multiple Q-networks. This mechanism first divides the target Q-values into several groups, selects the maximum value from each group, and then takes the minimum among these maxima as the final target Q-value. We applied this mechanism to improve deep reinforcement learning algorithms based on multi-Q-value evaluation. Comparison experiments show that this improvement significantly enhances the algorithm’s performance, outperforming traditional algorithms in terms of convergence, volatility, and final rewards. The energy management system demonstrates stronger adaptability when handling uncertainties arising from renewable energy variations, ensuring reliable power supply and achieving balanced energy management.},
  archive      = {J_EAAI},
  author       = {Weipeng Chao and Yuanbo Shi and Yushuai Li and Meng Liu and Xiaoling Leng},
  doi          = {10.1016/j.engappai.2025.112129},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112129},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Energy management system scheduling optimization based on an improved generative adversarial network deep reinforcement learning algorithm},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep ensemble learning and error correction method for remaining useful life prediction of rolling bearings. <em>EAAI</em>, <em>161</em>, 112128. (<a href='https://doi.org/10.1016/j.engappai.2025.112128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearings are critical components of rotating machinery, and the prediction of their remaining useful life (RUL) is important for system reliability and operating efficiency. A novel RUL prediction method based on deep ensemble learning and error correction is here proposed. Firstly, the moving average filter (MAF) is applied to preprocess vibration signals for removing outliers and noise. Then, time-domain features are extracted from the processed vibration signals, and optimized to obtain imperative feature signals. Subsequently, a deep ensemble learning model is built with gated recurrent unit (GRU), bidirectional GRU (BiGRU), long short-term memory (LSTM) and bidirectional LSTM (BiLSTM) as base learners, and the overall performance of the prediction model is enhanced by introducing an error correction strategy. The MAF method is also used to smooth the trend of the RUL prediction outcomes. Finally, the proposed method is applied to two full-lifecycle rolling bearing datasets: the Prognostics and Health Management 2012 (PHM2012) dataset and the Intelligent Maintenance System (IMS) dataset. It is evaluated using mean square error (MSE), mean absolute error (MAE), and the R-square coefficient of determination (R 2 ). The test results demonstrate that the method achieves highly accurate RUL predictions: on the PHM2012 dataset, the MSE, MAE, and R 2 reach 0.000380, 0.013695, and 0.994716, respectively; on the IMS bearing dataset, the corresponding values are 0.001056, 0.015403, and 0.978346. In addition, the method outperforms traditional single models (GRU, BiGRU, LSTM, BiLSTM) as well as the Transformer model in both cases, with R 2 improvements over the Transformer of 0.011065 and 0.008744, respectively. These results highlight the superior generalization capability and robustness of the proposed method, making it applicable to industrial environments requiring reliable RUL prediction.},
  archive      = {J_EAAI},
  author       = {Wenzhe Yin and Hong Xia and Enrico Zio and Xueying Huang},
  doi          = {10.1016/j.engappai.2025.112128},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112128},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep ensemble learning and error correction method for remaining useful life prediction of rolling bearings},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maritime supply chain optimization using robust adversarial reinforcement learning. <em>EAAI</em>, <em>161</em>, 112127. (<a href='https://doi.org/10.1016/j.engappai.2025.112127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores novel strategies for analyzing and managing port productivity in a multi-stage supply chain network by integrating synchronization and reinforcement learning (RL) techniques. Current port management systems face issues with nonlinearity, high interdependency, and vulnerability to market disruptions, which might destabilize port operations. To tackle these issues, seaport operations are examined in four stages of implementation: the terminal operator, inland carrier, inland terminal operator, and consignee. Brownian motion is applied to characterize stochastic disruptions in volatile markets, and the port performance under market disruptions is analyzed using nonlinear data analytics. The dynamical analysis reveals that port management systems exhibit highly coupled nonlinear dynamics with a tendency towards instability. The complex nature of maritime port logistics requires innovative strategies to analyze container handling volumes, optimize the strategic planning of port management, and improve overall efficiency. A novel optimal policy for port operations is realized by integrating a deep deterministic policy gradient into robust adversarial deep learning. A deep reinforcement learning algorithm is employed to learn adaptively from historical port-related data and real-time container handling feedback, enabling intelligent strategies to make informed decisions and dynamically adjust policies in response to stochastic disruptions or changing market conditions. Quantitative results demonstrate that the proposed strategy achieves up to 97.78 % operating efficiency despite disturbances, and the adversarial attacks are shown to decrease port productivity by up to 77.78 % in scenarios without robust deep learning support. This study contributes to the growing field of intelligent port operations by paving the way for more adaptive and smart solutions in the maritime supply chain network.},
  archive      = {J_EAAI},
  author       = {Truong Ngoc Cuong and Sam-Sang You and Le Ngoc Bao Long and Hwan-Seong Kim and Duy Anh Nguyen and Nguyen Duy Tan},
  doi          = {10.1016/j.engappai.2025.112127},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112127},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Maritime supply chain optimization using robust adversarial reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Employing dual-path structure and soft attention mechanism to enhance recognition and classification of wild medicinal licorice in xinjiang. <em>EAAI</em>, <em>161</em>, 112126. (<a href='https://doi.org/10.1016/j.engappai.2025.112126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Licorice is highly valued in traditional Chinese medicine for its anti-inflammatory, antiviral, and immunomodulatory properties, and is widely used in the pharmaceutical, food, and cosmetic industries. Xinjiang, the largest licorice-producing region in China, faces severe overharvesting of wild licorice due to increasing market demand, threatens natural populations and fragile ecosystems. Accurate identification and classification of licorice species are crucial for environmental protection and sustainable resource utilization, as traditional methods relying on experience are inefficient, subjective, and prone to errors. This study builds on the Inception-Residual Network-Version 2 (Inception-ResNet-V2) architecture and proposes an advanced licorice recognition model called Inception-ResNet-V2-Soft Attention, Dual-path Structure, and Focal Loss (IRV2-SDF). The IRV2-SDF model integrates a soft attention mechanism that focuses on key regions, a dual-path structure for multi-scale feature extraction, and a focal loss function to address class imbalance. It aims to improve the identification and classification of three wild licorice species ( Glycyrrhiza glabra , Glycyrrhiza inflata , and Glycyrrhiza uralensis ) and associated weeds in complex environments. Trained on 3,653 images collected from Xinjiang, the model achieves an average recognition accuracy of 91.79%, surpassing traditional models, with accuracy improvements of 4.27%, 2.08%, 2.76%, and 6.36% for G. glabra , G. inflata , G. uralensis , and weeds, respectively. By effectively reducing background noise and enhancing detection capabilities, the model overcomes the limitations of traditional methods and provides a robust solution for wild licorice recognition. This research offers a technical foundation for licorice conservation and sustainable utilization and can serve as a reference for identifying other medicinal plants in complex environments.},
  archive      = {J_EAAI},
  author       = {Yuan Qin and Jianguo Dai and Guoshun Zhang and Miaomiao Xu and Jing Yang and Jinglong Liu},
  doi          = {10.1016/j.engappai.2025.112126},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112126},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Employing dual-path structure and soft attention mechanism to enhance recognition and classification of wild medicinal licorice in xinjiang},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time cooperative target tracking in cluttered environments using multiple drone swarms with adaptive fuzzy emotional learning. <em>EAAI</em>, <em>161</em>, 112125. (<a href='https://doi.org/10.1016/j.engappai.2025.112125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a real-time adaptive trajectory prediction framework for cooperative unmanned aerial vehicle (UAV) swarms engaged in dynamic target tracking within cluttered environments. The proposed system introduces a novel artificial intelligence (AI)-based control architecture combining fuzzy inference, neuro-emotional learning, and distributed multi-agent coordination. At the core of the approach is a Bidirectional Fuzzy Brain Emotional Learning Prediction (BFBEL-P) model, which integrates fuzzy logic and an online adaptive neural structure to enable trajectory forecasting without pre-training or prior knowledge of the environment. From an engineering perspective, this AI model is deployed in UAV swarm navigation, where robust decision-making, predictive coordination, and obstacle avoidance are essential for target interception missions. In contrast to conventional prediction methods, such as curve fitting, nonlinear model predictive control (MPC), and deep learning-based Long Short-Term Memory (LSTM) networks, the BFBEL-P framework offers fast convergence, low computational cost, and high adaptability. The system incorporates multi-threaded data fusion across the swarm to achieve consensus-driven predictions and maintain situational awareness, even under sensor failures or occlusions. Simulation results show that BFBEL-P improves short-term prediction accuracy by 82.2%, reduces prediction time by 15%, and achieves a 100% tracking success rate across benchmark scenarios. These results establish BFBEL-P as a reliable AI technique for distributed control in real-world UAV swarm applications, offering a promising tool for search-and-rescue, surveillance, and defense operations.},
  archive      = {J_EAAI},
  author       = {Lucas William Page and Vu Phi Tran and Duy Luan Nguyen},
  doi          = {10.1016/j.engappai.2025.112125},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112125},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time cooperative target tracking in cluttered environments using multiple drone swarms with adaptive fuzzy emotional learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical multi-scale matched masked autoencoder for industrial multi-rate time series modeling. <em>EAAI</em>, <em>161</em>, 112122. (<a href='https://doi.org/10.1016/j.engappai.2025.112122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical industrial processes, due to sensor hardware limitations, the sampling rates of different variables often vary, leading to multi-rate time series (MRTS) data. However, the distribution of multi-scale dynamics in MRTS data typically follows a step-like pattern, with intricate scale transitions from fine to coarse and complex scale-consistent dependencies across rates. Additionally, the inherent characteristics of MRTS data often result in label scarcity. Both factors present significant challenges for MRTS modeling. To address these issues, we propose a novel self-supervised learning strategy, called H ierarchical M ulti-Scale M atched M asked A utoencoder (H3MAE). Specifically, we design a scale-matching input fusion mechanism where each layer is hierarchically aligned to a specific scale, with the scale-matching integration from two sources, effectively capturing the multi-scale dynamics and cross-rate scale-consistent dependencies in MRTS data. Besides, we introduce a novel auxiliary task that imputes masked positions in the encoded representation space at each layer, aiming to achieve MRTS representation learning and mitigate label scarcity. Furthermore, we propose a unique encoder-imputer structure in each layer to enable multi-scale self-supervised learning while generating temporally aligned features satisfying the input requirements of the next layer. Experimental results on three benchmark datasets and two industrial multi-rate tasks demonstrate that our framework yields better performance in MRTS modeling. The code is publicly available at https://github.com/monolithycq/H3MAE .},
  archive      = {J_EAAI},
  author       = {Changqing Yuan and Yongfang Xie and Shiwen Xie and Jie Wang},
  doi          = {10.1016/j.engappai.2025.112122},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112122},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical multi-scale matched masked autoencoder for industrial multi-rate time series modeling},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised feature selection via latent feature representation and modified graph embedding. <em>EAAI</em>, <em>161</em>, 112121. (<a href='https://doi.org/10.1016/j.engappai.2025.112121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data in practical applications are correlated not only between samples but also between high-dimensional features. Latent representations can effectively represent such correlations. Existing latent representation methods mainly consider inter-instance relationships and rely on constructing similarity graphs. However, the interconnection information obtained by latent representations is redundant due to the noise and irrelevance of the raw data. Therefore, to address the above issues, this paper proposes an unsupervised feature selection by latent feature representation and modified graph (LFRMG, for short) embedding. First, a latent feature representation norm for learning self-representation structure is designed to explore the interconnections among features. Mining feature relationships via self-representation can solve the redundancy caused by fixed similarity graph relationships. Second, the latent feature representation is combined with modified graph regularization to achieve good feature interconnections while maintaining local data information. In addition, the l 2 , 0 -norm is utilized to select the full-row sparse projection of salient features to avoid the drawbacks of sparsity limitation and parameter tunability. A scheme for solving the closed form of l 2 , 0 is constructed. Finally, the presented approach is superior to many state-of-the-art unsupervised methods through comprehensive experiments on nine existing datasets.},
  archive      = {J_EAAI},
  author       = {Jialing Yan and Gang Hu and Guo Wei},
  doi          = {10.1016/j.engappai.2025.112121},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112121},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised feature selection via latent feature representation and modified graph embedding},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coarse-to-fine dual-branch network for ship target recognition in complex environments. <em>EAAI</em>, <em>161</em>, 112120. (<a href='https://doi.org/10.1016/j.engappai.2025.112120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harsh sea conditions and the complex and variable positions of ships significantly impact the capacity of imaging devices to capture high-quality ship images, making ship target recognition challenging in the application of artificial intelligence. Many scholars have recently proposed cascaded recognition models to address this issue. Following this method, in this paper, we propose a novel method for ship target recognition in complex environments called the coarse-to-fine dual-branch (CFDB) network. The CFDB model designs a dual-branch network from coarse to fine to lock the target area fine features and then uses peer-to-peer communication to extract and exchange learning of the target region’s final discriminative contour features, assisting in predicting ship classes in the complex environment. The proposed method is evaluated on the constructed complex in background ships (CIB-ships) dataset and the publicly available Marine Argos Recognition Ships (MAR-ships) and Game-of-Ships datasets. Compared with the suboptimal method, the proposed CFDB network exhibits improvements of 2.11%, 1.33%, and 1.24% accuracy on the CIB-ships, MAR-ships, and Game-of-ships datasets, respectively. The results demonstrate that the proposed method provides useful ideas for the dynamic monitoring of ships in real environments. Our code will be published at https://github.com/yangt1013/CFDB-master .},
  archive      = {J_EAAI},
  author       = {Yang Tian and Hao Meng},
  doi          = {10.1016/j.engappai.2025.112120},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112120},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Coarse-to-fine dual-branch network for ship target recognition in complex environments},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-scale sparse channel transformer network for image reconstruction of astronomical bright source contamination. <em>EAAI</em>, <em>161</em>, 112119. (<a href='https://doi.org/10.1016/j.engappai.2025.112119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bright source contamination has long been a challenging issue in the field of image processing, particularly in applications such as astronomical observations, satellite imaging, and nighttime surveillance. To address this issue, this paper proposes a novel Multi-Scale Sparse Channel Transformer Network (MSCformer) aimed at achieving high-quality image reconstruction under the influence of bright source contamination. The network integrates a Top-k Sparse Attention mechanism with a Channel Attention module, enabling selective focus on the most informative features and adaptive weight allocation across channels. Additionally, a Multi-Scale Dual-Gate Feedforward Network is designed to further enhance the expression of valuable features while suppressing redundant information. Experimental results demonstrate that the proposed method exhibits outstanding performance in practical applications on the Sloan Digital Sky Survey (SDSS) photometric image dataset. Compared to existing state-of-the-art techniques, MSCformer achieves significant performance improvements, with a Peak Signal-to-Noise Ratio (PSNR) of 45.093 decibel(dB), a Structural Similarity Index Measure(SSIM) of 0.978, and a Pixel Average Absolute Error (PAAE) of 0.675. This not only significantly enhances the removal of bright source contamination in the field of astronomy but also provides important reference value for subsequent research in related domains.},
  archive      = {J_EAAI},
  author       = {Yajuan Zhang and Congcong Shen and Xia Jiang and Bo Qiu and Ali Luo and Fuji Ren and Yuanlu Chen},
  doi          = {10.1016/j.engappai.2025.112119},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112119},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-scale sparse channel transformer network for image reconstruction of astronomical bright source contamination},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Seismic damage assessment of reinforced concrete frame structures based on transfer-residual networks. <em>EAAI</em>, <em>161</em>, 112118. (<a href='https://doi.org/10.1016/j.engappai.2025.112118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post-earthquake building damage assessment is a critical research focus in civil engineering due to its vital role in guiding timely and informed rescue operations. This study proposes a rapid seismic damage assessment method for reinforced concrete frame structures based on transfer-residual networks. The methodology involves pre-training a base model on a large dataset generated from computationally efficient simplified model simulations, followed by transfer learning on a smaller, high-fidelity dataset derived from refined finite element model simulations. This approach significantly enhances prediction accuracy while reducing computational costs for seismic damage assessment in new building structures. Optimization of model parameters was performed to find the optimal residual network, which achieves an accuracy of 91.2 % with a remarkable 32-fold speedup over conventional nonlinear time-history analysis methods. Moreover, the transfer-residual network enhances accuracy by 10 % compared to training from scratch. The results conclusively demonstrate the feasibility of utilizing large datasets from simplified models to improve the training accuracy of refined models with limited data, providing a valuable reference for advancing transfer learning-based frameworks in seismic damage assessment of buildings.},
  archive      = {J_EAAI},
  author       = {Chen Xiong and Zhijie Luo and Jie Zheng and Linlin Xie and Liu Mei and Lixiao Li and Wujian Long},
  doi          = {10.1016/j.engappai.2025.112118},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112118},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Seismic damage assessment of reinforced concrete frame structures based on transfer-residual networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-enabled performance-based design of three-dimensional printed engineered cementitious composites. <em>EAAI</em>, <em>161</em>, 112117. (<a href='https://doi.org/10.1016/j.engappai.2025.112117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The superior tensile ductility of engineered cementitious composites (ECC) offers a promising solution to the challenge of integrating conventional steel reinforcement in three-dimensional (3D) concrete printing (3DCP). However, the widespread adoption of 3D printed ECC (3DP-ECC) is hindered by the reliance on trial-and-error design process. The complex material component and inherent anisotropy of 3DP-ECC pose challenges for accurate property prediction and inverse design. This paper introduces a performance-based design strategy for 3DP-ECC, leveraging machine learning (ML) and multi-objective optimization. The anisotropic-mechanical properties including compressive strength and flexural strength were experimentally and statistically investigated; further, ML prediction models conbined with multi-objective optimization algorithm were developed to inversely design 3DP-ECC for specific mechanical performance requirements, while reducing carbon footprint and material cost. Specifically, an extensive database was assembled, followed by grey relational analysis (GRA) to identify the parametric sensitivity of the mechanical properties of 3DP-ECC. Three representative ML techniques were employed, with the back-propagation artificial neural network (BPANN) demonstrating superior predictive accuracy. Model interpretability analyses uncovered the importance of input parameters and their influence on predicted outcomes. Lastly, non-dominated Sorting Genetic Algorithm II (NSGA-II) integrated with the BPANN models was applied to perform the inverse design of 3DP-ECC, showing good effectiveness and accuracy. This work offers an efficient and viable avenue for performance-based design for 3DP-ECC, along with the potential to develop low-carbon cost-effective 3DP-ECC.},
  archive      = {J_EAAI},
  author       = {Wenguang Chen and Long Liang and Junhong Ye and Lingfei Liu and Neven Ukrainczyk and Liqiang Yin and Jiangtao Yu and Kequan Yu},
  doi          = {10.1016/j.engappai.2025.112117},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112117},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning-enabled performance-based design of three-dimensional printed engineered cementitious composites},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized text-to-image generation with large language and vision assistant enhanced training. <em>EAAI</em>, <em>161</em>, 112116. (<a href='https://doi.org/10.1016/j.engappai.2025.112116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized image generation aims to synthesize images of a specific identity. The identity, denoted as V ∗ , refers to an entity with distinctive visual attributes, such as a dog-shaped backpack. However, existing methods like DreamBooth and Custom Diffusion often struggle to generate images of V ∗ that accurately match the input prompts. In this work, we analyze two key issues underlying this limitation: (1) the overbinding problem , where the prompt tokens used to represent V ∗ unintentionally bind to irrelevant visual details from the reference image during training; and (2) the low language prior problem , where insufficient use of pre-trained language prior limits the model’s ability to faithfully generate all the prompt words. To overcome these challenges, we propose LLaVA-Booth, a novel personalization method for diverse, identity-preserving image generation, based on Large Language and Vision Assistant (LLaVA) enhanced training. Our method alleviates the overbinding problem by disentangling background information and solves the low language prior problem by enriching the language context. Additionally, we introduce two auxiliary objectives: (1) an identity (ID) binding loss to strengthen the identity binding and (2) a prior preservation loss to prevent language drift and encourage generation diversity. Experiments demonstrate that LLaVA-Booth effectively mitigates overbinding and enhances language priors to improve prompt fidelity, then generates diverse, high-quality, and identity-preserving images of V ∗ .},
  archive      = {J_EAAI},
  author       = {Junsheng Luan and Zhanjie Zhang and Wei Xing and Lei Zhao},
  doi          = {10.1016/j.engappai.2025.112116},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112116},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Personalized text-to-image generation with large language and vision assistant enhanced training},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-view new energy vehicle form generation design method combining kansei imagery and deep learning. <em>EAAI</em>, <em>161</em>, 112115. (<a href='https://doi.org/10.1016/j.engappai.2025.112115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the competitive landscape of new energy vehicles, exterior design has become a crucial differentiator amid functional homogenization. User preferences are central to shaping vehicle appearance, yet most perceptual design methods rely on a single viewpoint, limiting insights into complex preference patterns. This study proposes a multi-perspective mapping approach that integrates Kansei engineering with deep learning. Firstly, user core imagery is collected and mined through big data. Secondly, Kernels Network (KNet) semantic segmentation model, Residual Networks (ResNet) tri-view (front/side/rear) score prediction model and fully connected network (FCN) feature fusion model are integrated to construct a multi-view feature mapping system. Finally, the optimal combination of morphological elements is explored based on the Elite Genetic Algorithm (EGA), and the scheme is validated through generative artificial intelligence (AI) workflow. The experimental results demonstrate that, employing “Cool” as a case study, the three-view scheme and the combination scheme devised by this research process exhibit substantial superiority over the majority of the samples. Under identical parameters, the scheme with decision constraints surpasses the randomly generated scheme in terms of perceptual scores and stability. The performance of the test set and the experimental results collectively substantiate the model’s validity. This workflow—covering preference extraction, morphological decomposition, AI-driven generation, and validation—provides a scalable framework for new energy vehicle exterior design. It also demonstrates novel applications of Kansei engineering in multi-view fusion and generative form design.},
  archive      = {J_EAAI},
  author       = {Zihao Wang and Le Xi and Yifan Ding and Wenjie Fang and Kaiming Wang and Hongliang Zuo},
  doi          = {10.1016/j.engappai.2025.112115},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112115},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-view new energy vehicle form generation design method combining kansei imagery and deep learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable remaining useful life uncertainty prediction method for rolling bearing. <em>EAAI</em>, <em>161</em>, 112114. (<a href='https://doi.org/10.1016/j.engappai.2025.112114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearing remaining useful life prediction is the core technology of equipment maintenance. Although deep learning-based prediction methods have made significant breakthroughs, the problems of insufficient model explainability and prediction result uncertainty quantification have seriously constrained the credibility of maintenance decisions. Therefore, this research combines prediction uncertainty quantification with model explanation to propose an explainable uncertainty prediction method. The method includes multi-dimensional feature extraction, remaining useful life uncertainty prediction, and Shapley additive explanations interpreter. For feature extraction, multi-dimensional feature vectors are constructed as network inputs by extracting time-domain features and frequency-domain features. Then, the remaining useful life prediction interval for the rolling bearing is compressed by the proposed gated temporal quantile network. Finally, the prediction model is explained using the Shapley additive explanations interpreter. The multi-case validation results based on the Xi'an Jiaotong University and Changxing Sumyoung Technology Co., Ltd. (XJTU-SY) and Intelligent Maintenance Systems (IMS) rolling bearing full life cycle datasets show that the proposed model has an average interval coverage of 93.96 % and an average interval width of 9.92 %, which indicates that the model maintains high accuracy and robustness in different cases. The nonlinear mapping relationship between the prediction results and the features is clarified by analyzing the Shapley values. Finally, the Shapley values are used to rank the importance of the features to locate the position that may cause rolling bearing performance degradation, which provides credible decision support for the development of the predictive maintenance strategy.},
  archive      = {J_EAAI},
  author       = {Ting Zhang and Honglei Wang},
  doi          = {10.1016/j.engappai.2025.112114},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112114},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable remaining useful life uncertainty prediction method for rolling bearing},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based estimation of sound transmission loss in single and double-layered rectangular functionally graded plates. <em>EAAI</em>, <em>161</em>, 112112. (<a href='https://doi.org/10.1016/j.engappai.2025.112112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a robust machine learning (ML) framework for predicting sound transmission loss (STL) in temperature-dependent functionally graded (FG) single- and double-layered plates, combining analytical modeling and data-driven approaches. The FG plates are modeled with material properties varying along the thickness via a power-law distribution, incorporating nonlinear temperature effects. A high-fidelity analytical solution is derived using first-order shear deformation theory (FSDT) and acoustic velocity potential, with governing equations formulated via Hamilton's principle and solved using the weighted residual method. To enable ML training, a large-scale parametric study generates 189,000 data points, covering variations in plate geometry, temperature, acoustic cavity depth, gradient index, and incident wave angles. ML algorithms are trained on this data to predict STL, with the extreme gradient boosting (XGBoost) algorithm demonstrating the highest accuracy (coefficient of determination R 2 = 99.38 % for training data and R 2 = 99.11 % for test data). The validated ML model is then employed to investigate key parameters—temperature, power-law index, incidence angle, cavity depth, and plate thickness—revealing their nonlinear interactions and impact on STL performance. The developed artificial intelligence (AI) framework provides an efficient tool for acoustic design optimization, offering real-time parameter tuning capabilities for engineers working with functionally graded acoustic barriers.},
  archive      = {J_EAAI},
  author       = {Chunfeng Jiang and Masoud Babaei},
  doi          = {10.1016/j.engappai.2025.112112},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112112},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning-based estimation of sound transmission loss in single and double-layered rectangular functionally graded plates},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cubic linguistic T-spherical fuzzy aggregation operator-based multi-attribute group decision-making model and its application to food waste treatment technique selection. <em>EAAI</em>, <em>161</em>, 112111. (<a href='https://doi.org/10.1016/j.engappai.2025.112111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food waste presents significant environmental, economic, and social challenges globally, contributing to resource depletion and greenhouse gas emissions. Effective treatment techniques are essential for minimizing these impacts, promoting sustainability, and supporting circular economy practices. However, selecting the most suitable food waste treatment technique is a complex multi-attribute group decision-making (MAGDM) problem that involves the simultaneous consideration of environmental, economic, and social factors under significant uncertainty. To address this challenge, this study proposes a novel cubic linguistic T-spherical fuzzy sets (CLT-SFSs) framework, which integrates linguistic T-spherical fuzzy sets and linguistic interval-valued T-spherical fuzzy sets to enhance decision-making precision under uncertainty. The proposed CLT-SF framework offers a unified structure capable of capturing both qualitative expert opinions and quantitative uncertainty ranges, offering unprecedented expressiveness for complex sustainability assessments. First, the formal definition and basic operations for CLT-SF numbers, including addition, multiplication, scalar multiplication, and scalar power, and a comparison law are established. Next, to efficiently aggregate cubic linguistic T-spherical fuzzy information, we propose the cubic linguistic T-spherical fuzzy weighted averaging and the cubic linguistic T-spherical fuzzy weighted geometric aggregation operators. These aggregation operators can effectively and comprehensively aggregate attribute values in MAGDM problems. Subsequently, utilizing these operators, a CLT-SFS-based combinative distance-based assessment model is developed to address MAGDM problems. The model's applicability and robustness are demonstrated through a real-world case study on the selection of food waste treatment techniques. A parameter analysis is also conducted to examine the sensitivity of ranking outcomes. Finally, a comparative analysis with existing methods confirms the proposed model's effectiveness, feasibility, and advantages in addressing complex decision-making scenarios. This research not only advances the theoretical framework of fuzzy decision-making but also provides a practical tool for stakeholders in waste management to make informed and sustainable choices.},
  archive      = {J_EAAI},
  author       = {Shahid Hussain Gurmani and Weiping Ding and Rana Muhammad Zulqarnain and Jiangfeng Hao},
  doi          = {10.1016/j.engappai.2025.112111},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112111},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cubic linguistic T-spherical fuzzy aggregation operator-based multi-attribute group decision-making model and its application to food waste treatment technique selection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextual and orientation correction modules enhance weakly-supervised aerial object detection in remote sensing images. <em>EAAI</em>, <em>161</em>, 112110. (<a href='https://doi.org/10.1016/j.engappai.2025.112110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenges of context and orientation ambiguity in weakly supervised aerial object detection. While current research focuses on improving detection accuracy and efficiency, it often encounters difficulties with contextual and rotational variations in aerial imagery. We propose a novel Context and Orientation Correction (COC) framework, which includes two innovative modules: a context correction module and an orientation correction module. The context correction module utilizes style normalization to guide the model in identifying atypical objects within specific contextual scenes by mitigating contextual disparities between instances and refining contextual information. Additionally, the orientation correction module aims to reduce feature distance between instances with varying orientations, leveraging contrastive learning to ensure consistent object representations. Furthermore, we introduce a category-aware aggregation loss to enhance similarity in feature representations of objects from the same category, thereby addressing the class collision issue commonly associated with contrastive learning. Our COC framework achieves 27.6% mean Average Precision and 59.8% mean Average Precision on the Detection in Optical Remote Sensing Image (DIOR) and Northwestern Polytechnical University Very High Resolution 10. v2 (NWPU VHR-10.v2) datasets, respectively, demonstrating its significant effectiveness.},
  archive      = {J_EAAI},
  author       = {Le Yang and Shunzhou Wang and Xuerong Wang and Shutong Wang and Yuting Lu and Binglu Wang},
  doi          = {10.1016/j.engappai.2025.112110},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112110},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contextual and orientation correction modules enhance weakly-supervised aerial object detection in remote sensing images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards detection of anomalous cosmic ray signals for observations acquired from cosmic ray extremely distributed observatory mobile detectors. <em>EAAI</em>, <em>161</em>, 112109. (<a href='https://doi.org/10.1016/j.engappai.2025.112109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose and test a method that allows the detection of anomalous cosmic ray signals acquired using Complementary Metal-Oxide-Semiconductor detectors. The method uses unsupervised embedding based on Principal Component Analysis which we named Eigenhits in apparent analogy to Eigenfaces. The embedding generated using Eigenhits allows the detection of potential anomalies, defined as images whose position described by the embedding relative to a given measure is above a certain distance threshold from other images. Thus, the problem of anomaly detection was reduced to the problem of detecting outliers which can be solved, for example, using clustering algorithms. We conducted tests of our approach on the Cosmic Ray Extremely Distributed Observatory (CREDO) dataset containing 13168 images and obtained satisfactory results demonstrating the stability and effectiveness of the method. The embedding generation method we propose in this paper and the evaluation of its effectiveness in detecting anomalies in images of cosmic ray events from CREDO dataset is a pioneering study with many critical applications.},
  archive      = {J_EAAI},
  author       = {Tomasz Hachaj and Łukasz Bibrzycki and Marcin Piekarczyk and Olaf Bar and Michał Niedźwiecki and Sławomir Stuglik and Piotr Homola and Dmitriy Beznosko and David Alvarez-Castillo and Bożena Poncyljusz and Ophir Ruimi and Oleksandr Sushchov and Krzysztof Rzecki and CREDO collaboration},
  doi          = {10.1016/j.engappai.2025.112109},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112109},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards detection of anomalous cosmic ray signals for observations acquired from cosmic ray extremely distributed observatory mobile detectors},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An uncertainty-aware safe-evolving reinforcement learning algorithm for decision-making and control in highway autonomous driving. <em>EAAI</em>, <em>161</em>, 112108. (<a href='https://doi.org/10.1016/j.engappai.2025.112108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rule-based and optimization-based approaches face challenges in decision-making and control for autonomous vehicles (AVs) in dynamic and complex highway scenarios. In contrast, reinforcement learning (RL) offers a more flexible and adaptable data-driven solution by allowing AVs to learn optimal actions through interactions with the environment, without requiring predefined rules or explicit programming. However, in real-world highway environments characterized by uncertainty, RL algorithm encounter difficulties in ensuring stability and safety. To address these challenges, this paper proposes an uncertainty-aware safe-evolving RL algorithm that integrates internal stability, external stability, and provable safety mechanisms. The internal stability mechanism ensures consistent performance improvements with high probability during policy updates itself, while the external stability leverages a benchmark policy as a reference to ensure the current policy performs at least as well as, if not better than, the benchmark. Furthermore, an action projection mechanism and a mixed learning procedure are incorporated to make minimal modifications to the learned policy, ensuring safety while supporting stable learning from both safe and original actions. The results show that the proposed algorithm maintains stability and safety throughout the learning process, achieves final performance comparable to traditional RL methods, and delivers higher training efficiency in a complex dynamic highway scenario in simulation. This suggests that the algorithm offers a viable solution for self-evolving systems in uncertain real-world environments, where traditional approaches may struggle.},
  archive      = {J_EAAI},
  author       = {Ping Lu and Sunan Zhang and Feihong Tan and Fulin Zhang and Yuxiang Feng and Bo Hu},
  doi          = {10.1016/j.engappai.2025.112108},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112108},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An uncertainty-aware safe-evolving reinforcement learning algorithm for decision-making and control in highway autonomous driving},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning-driven network for joint low-light enhancement and deblurring in maritime surveillance systems. <em>EAAI</em>, <em>161</em>, 112107. (<a href='https://doi.org/10.1016/j.engappai.2025.112107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {—Shipboard video surveillance systems are crucial for maritime environmental perception. However, shipborne cameras are often affected by challenges such as ship rolling and low illumination, causing motion blur and low-light degradation in captured images. These degradations significantly reduce the accuracy and robustness of sea-surface obstacle detection. To address this challenge, this paper presents a deep learning-based joint network model designed to simultaneously deblur and enhance low-light maritime images. Unlike existing step-by-step approaches that treat deblurring and low-light enhancement as separate tasks, the proposed model employs an encoder-decoder architecture to jointly address both tasks within a unified framework, thereby overcoming the limitations of separate processing. Furthermore, the model incorporates a novel adaptive wavelet curve attention mechanism and an extended spatial pyramid pooling module with dynamic global context to mitigate detail loss caused by sea surface reflections and artifacts in dynamic backgrounds. Additionally, a joint loss function is exploited to further enhance image restoration quality. Experiments on a self-constructed synthetic maritime dataset demonstrate that the proposed model achieves a Peak Signal-to-Noise Ratio (PSNR) of 31.81, a Structural Similarity Index Measure (SSIM) of 0.812, and a Learned Perceptual Image Patch Similarity (LPIPS) of 0.246, significantly outperforming existing competing methods. Moreover, evaluations on real-world degraded maritime images confirm the model's strong generalization ability and robustness. This advancement offers practical benefits for improving obstacle perception in autonomous ships navigating complex maritime environments.},
  archive      = {J_EAAI},
  author       = {Zeyuan Shao and Yong Yin and Hongguang Lyu and Qianfeng Jing and Tao Cheng},
  doi          = {10.1016/j.engappai.2025.112107},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112107},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep learning-driven network for joint low-light enhancement and deblurring in maritime surveillance systems},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A double hierarchy hesitant fuzzy forecasting model considering the influence of investor emotion and the co-movement of stock markets. <em>EAAI</em>, <em>161</em>, 112106. (<a href='https://doi.org/10.1016/j.engappai.2025.112106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stock market is a complex system influenced by various internal and external factors. Effective stock index forecasting models must balance interpretability with the ability to integrate multi-source information. While traditional fuzzy models offer high interpretability, they struggle to incorporate multiple dynamic factors. This study proposes a novel forecasting model based on double hierarchy hesitant fuzzy linguistic term sets (DHHFLTS), which integrates investor sentiment and international market co-movement. By constructing fuzzy logic rules, the model captures complex interactions underlying index fluctuations and enhances predictive accuracy in volatile environments. To evaluate its effectiveness, the model was tested on time series data from three major indices: the Shanghai Stock Exchange Composite Index (SSEC), Taiwan Capitalization Weighted Stock Index (TAIEX), and Financial Times Stock Exchange 100 Index (FTSE 100). The Root Mean Square Error (RMSE) achieved was 32.06 for the SSEC, 69.74 for the TAIEX, and 25.27 for the FTSE 100. Compared with existing benchmark methods, the proposed model demonstrates superior predictive accuracy and generalization performance. These findings confirm the model's capability in capturing multidimensional uncertainty and temporal patterns, highlighting its potential for intelligent financial forecasting and decision-making.},
  archive      = {J_EAAI},
  author       = {Liu Zhengmin and Du Chuantao and Zhang Jihao and Gao Shanshan and Liu Peide},
  doi          = {10.1016/j.engappai.2025.112106},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112106},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A double hierarchy hesitant fuzzy forecasting model considering the influence of investor emotion and the co-movement of stock markets},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Style prompt tuning for bridging visual gaps in autonomous driving. <em>EAAI</em>, <em>161</em>, 112105. (<a href='https://doi.org/10.1016/j.engappai.2025.112105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence models for semantic segmentation and image classification in autonomous driving must maintain reliability across adverse conditions such as rain, fog, snow, and nighttime. However, models trained on only clear daytime images often fail to generalize under such domain shifts. Existing unsupervised domain adaptation (UDA) methods employ image-level style transfer using generative adversarial networks (GANs) or diffusion models, which necessitate paired data and risk altering content. Therefore, this study proposes Style Prompt Tuning, a novel UDA framework that utilizes image–text models to automatically generate and optimize textual prompts representing target-domain styles. These prompts guide a U-Net-based style network to synthesize source images in the target style while preserving their semantic content. Our approach employs clustering within the Contrastive Language—Image Pretraining (CLIP) embedding space and a composite loss function, including content, style, transfer, patch, and total variation terms to optimize prompt quality. The generated stylized images augment the source dataset and are used to train more robust task models. Experiments on semantic segmentation benchmarks (Cityscapes-to-Adverse Conditions Dataset with Correspondences (ACDC), DarkZurich, BDD100k-night, and Nighttime Driving) and image classification (Visual Domain Adaptation 2017) reveal our approach to achieve improvements of +3.4 mean intersection-over-union (mIoU) and +0.8% accuracy over prior UDA methods. These results highlight our method’s practical effectiveness for real-world autonomous driving applications under visually challenging scenarios.},
  archive      = {J_EAAI},
  author       = {Suyeon Cha and Giyun Choi and Minji Kwak and Jongwon Choi},
  doi          = {10.1016/j.engappai.2025.112105},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112105},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Style prompt tuning for bridging visual gaps in autonomous driving},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing fuzzy cognitive map convergence through supervised and unsupervised learning algorithms: A case study of operational risk assessment in power distribution networks. <em>EAAI</em>, <em>161</em>, 112104. (<a href='https://doi.org/10.1016/j.engappai.2025.112104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Cognitive Maps (FCMs) are commonly used for modeling complex systems. However, their convergence challenges significantly limit their accuracy and reliability, especially in operational risk assessment. To address this issue, the current study proposes a novel approach that integrates advanced supervised and unsupervised learning algorithms: specifically, the Mesh Adaptive Direct Search (MADS) and Genetic Algorithm (GA). To meet the critical need for accurate risk modeling in power distribution networks, the proposed methodology utilizes ten years of time-series data from the Yazd Power Distribution Network as a real-life case study. This optimizes risk relationships and reduces convergence errors. The main contributions of this research are: (1) the development of an integrated FCM-based framework that improves convergence stability and accuracy through advanced learning algorithms, (2) the demonstration of the effectiveness of MADS in achieving faster convergence and lower error rates compared to GA, and (3) the provision of a data-driven, scalable solution for risk prioritization and decision-making in complex and dynamic systems. The results show a significant decrease in convergence error from 0.126 to 0.005, allowing for more precise risk analysis and mitigation strategies.},
  archive      = {J_EAAI},
  author       = {Elham Fallah Baghemoortini and Davood Shishebori and Mustafa Jahangoshai Rezaee and Armin Jabbarzadeh},
  doi          = {10.1016/j.engappai.2025.112104},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112104},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing fuzzy cognitive map convergence through supervised and unsupervised learning algorithms: A case study of operational risk assessment in power distribution networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised generative adversarial network for plant leaf disease detection. <em>EAAI</em>, <em>161</em>, 112103. (<a href='https://doi.org/10.1016/j.engappai.2025.112103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully supervised plant leaf disease segmentation methods based on convolutional neural networks (CNN) require large quantities of labeled images for training, which are time-consuming and labor-intensive to obtain in practical scenarios. Moreover, most diseases of plant leaf exhibit indistinct edge information and background noise interference, which hinders precise disease localization. To overcome these issues, a semi-supervised generative adversarial network (SSGAN) is proposed for plant leaf disease inspection. Firstly, to learn comprehensive semantic features from limited data, a semi-supervised method based on generative adversarial networks is developed to enhance the interaction of features among labeled and unlabeled disease images. Secondly, a boundary feature attention module (BFAM) is proposed to enhance edge detail representation, which makes the model pay more attention to the boundary feature of plant leaf diseases. Finally, a background noise suppression module (BNSM) is proposed to bolster the differentiation between the normal and disease areas so as to alleviate the adverse impact of background noise. The effectiveness of SSGAN is verified on two plant leaf disease datasets. The mean intersection over union (mIoU) on the apple and tomato leaf datasets improves by 2.07 % and 2.28 % respectively, compared with the suboptimal method. The testing results of experiments show that SSGAN achieves great performance on plant leaf disease segmentation under limited labeled data.},
  archive      = {J_EAAI},
  author       = {Lixiang Zhao and Jun Hao and Demin Li and Jianbo Yu},
  doi          = {10.1016/j.engappai.2025.112103},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112103},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised generative adversarial network for plant leaf disease detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Industrial device-aided data collection for real-time rail defect detection via a lightweight network. <em>EAAI</em>, <em>161</em>, 112102. (<a href='https://doi.org/10.1016/j.engappai.2025.112102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rail defect detection is challenging due to the diverse and irregular nature of defects, along with the limited availability of high-quality datasets. Existing methods struggle with effectively capturing multi-scale features for proper feature allocation and preserving crucial details in deep networks, leading to incomplete defect representation and reduced accuracy. To address these limitations, we propose Rail Defect Detection Network (REDNet), a lightweight deep learning model specifically designed for real-time rail defect detection in manufacturing and maintenance applications. We design the Multi-Scale Deep Feature Aggregation (MSDFA) module to enhance semantic consistency modeling and achieve more precise feature fusion. We develop the Adaptive Task Decomposition Head (ATDH) to address dynamic feature allocation, and we introduce the Reversible Column Network (RevCol) as the backbone to enhance feature extraction and ensure information reconstruction. Additionally, we developed a high-quality dataset using specialized equipment to address data scarcity and utilized it for training. REDNet achieved a high mean Average Precision at an Intersection over Union (IoU) threshold of 0.50 (mAP50) of 94.1% with exceptional real-time performance at 204.1 frames per second (FPS), while keeping an efficient design of 5.70 million parameters and surpassing state-of-the-art (SOTA) methods in accuracy and speed. These features make it suitable for defect detection, facilitating engineering deployment, and improve quality control in rail manufacturing and maintenance. Generalization tests on the public Microsoft Common Objects in Context (MS COCO) dataset yielded a mean Average Precision across IoU thresholds from 0.50 to 0.95 (mAP50–95) of 46.8%, further confirming the effectiveness of REDNet.},
  archive      = {J_EAAI},
  author       = {Qing Dong and Tianxin Han and Gang Wu and Lina Sun and Min Huang and Fu Zhang},
  doi          = {10.1016/j.engappai.2025.112102},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112102},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Industrial device-aided data collection for real-time rail defect detection via a lightweight network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A quantitative multi-dimensional resilience framework in process industries. <em>EAAI</em>, <em>161</em>, 112100. (<a href='https://doi.org/10.1016/j.engappai.2025.112100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process industries face significant safety challenges arising from the handling of hazardous materials, tightly coupled operations, and complex system interdependencies. Addressing these challenges requires management strategies that are both proactive and holistic rather than purely reactive. Resilience engineering embodies this approach by emphasizing a system's ability to anticipate disturbances, adapt under stress, and recover effectively. This study introduces a comprehensive, multi-dimensional framework for assessing resilience in process industries. The framework was developed through content analysis of expert interviews, a systematic literature review, and application of the spherical fuzzy Delphi method. Results revealed five primary dimensions of resilience: the organizational dimension, which encompasses leadership commitment, safety culture, and communication processes; the human resources dimension, focusing on workforce competence, training, and well-being; the individual dimension, addressing cognitive readiness, situational awareness, and decision-making skills; the risk management system dimension, which includes hazard identification, risk assessment, emergency preparedness, and continuous monitoring; and the technical dimension, covering equipment reliability, system redundancy, automation safeguards, and maintenance practices. Within these dimensions, factors such as leadership, effective communication, workforce capability, robust risk governance, and technical robustness emerged as particularly influential. By integrating these dimensions into a unified framework, our study advances theoretical understanding of resilience engineering and offers practical guidance for enhancing safety performance in process plants. Furthermore, this framework lays a foundation for future research aimed at developing standardized assessment tools, evaluating long-term outcomes of resilience interventions, and exploring the integration of emerging technologies—such as artificial intelligence, the internet of things, and advanced automation—into resilience engineering practices.},
  archive      = {J_EAAI},
  author       = {Mojtaba Emkani and Moslem Alimohammadlou and Esmaeil Zarei and Mehdi Jahangiri and Mojtaba Kamalinia},
  doi          = {10.1016/j.engappai.2025.112100},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112100},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A quantitative multi-dimensional resilience framework in process industries},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mutual transfer learning for cuff-less blood pressure estimation using photoplethysmography-based visibility graphs. <em>EAAI</em>, <em>161</em>, 112099. (<a href='https://doi.org/10.1016/j.engappai.2025.112099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cuff-less blood pressure (BP) estimation is critical to cardiovascular disease prevention and management. Photoplethysmography (PPG)-based monitoring technology offers advantages over cuff-based devices, including portability, lower power consumption, and faster measurements. However, current deep learning methods for BP estimation from PPG signals are limited by their analysis only from one-dimensional perspectives, failing to exploration of the underlying physiological patterns of cross-domain visual representations based on higher dimensional perspectives. Furthermore, conventional knowledge distillation techniques necessitate unidirectional knowledge transfer from pre-trained models, rendering it challenging to obtain feedback on the learning state of small networks for optimizing and adjusting the training process. This is inadequate for acquiring a profound understanding of the intricate mapping relationship between PPG and BP values. Therefore, this work presents a novel Transformer-based mutual transfer learning framework (MTL) that estimates BP values from phase-space reconstructed PPG signals using a multi-field complementary approach. The proposed MTL method leverages four phase-space reconstruction techniques to convert PPG signals into visibility graphs (VGs) that provide rich time-variant information. Furthermore, the joint optimization strategy with multiple losses of the soft label and structural knowledge learning enables us to transfer pre-trained knowledge from heterogeneous Transformer models and obtain cumulative multi-field complementary VG features during the fine-tuning process. We evaluate our MTL on three datasets of 1375 subjects using a subject-wise data-splitting paradigm based on five-fold cross-validation, achieving a state-of-the-art performance with estimation errors of 0.50 ± 4.94 millimeter of mercury (mmHg) and 0.21 ± 2.63 mmHg for systolic and diastolic BP, respectively. Our proposed end-to-end MTL offers a computationally efficient solution and elegant generalization ability for BP estimation using PPG-based VGs, providing a novel and innovative approach to BP monitoring that can advance cardiovascular disease prevention and management.},
  archive      = {J_EAAI},
  author       = {Chenbin Ma and Zhenchang Liu and Peng Zhang and Lishuang Guo and Haonan Zhang and Zeyu Liu and Guanglei Zhang},
  doi          = {10.1016/j.engappai.2025.112099},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112099},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mutual transfer learning for cuff-less blood pressure estimation using photoplethysmography-based visibility graphs},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Groundwater parameters estimation: A hybrid approach of convolutional layers with asynchronous and distributed bio-inspired algorithms. <em>EAAI</em>, <em>161</em>, 112098. (<a href='https://doi.org/10.1016/j.engappai.2025.112098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on aquifer hydraulic parameters estimation using bio-inspired algorithms since they can tackle groundwater model non-linearities. We propose two novel hybrid frameworks that combine the advantages of convolutional layers (CL) to enhance pattern recognition with heuristic search of Particle Swarm Optimization (PSO) and Differential Evolution (DE) algorithms. These integrations are implemented using an asynchronous and distributed approach to address efficiency issues in large-scale problems, resulting in ADPSO-CL (Asynchronous and Distributed Particle Swarm Optimization with Convolutional Layers) and ADDE-CL (Asynchronous and Distributed Differential Evolution with Convolutional Layers). The distributed method employs virtual machines, where a server generates and assigns particles to workers, which run in parallel with asynchronous iterative solution exchanges. We assess different algorithm configurations in an integrated water management model by coupling two software: Water Evaluation and Planning (WEAP) and MODFLOW. Results indicate that ADPSO-CL outperforms ADDE-CL by demonstrating more stable asynchronous communication, with fewer incomplete experiments (more than one worker was disconnected before completing all iterations), 33% in contrast to 71%. Additionally, produces results closer to the expected values, with mean absolute percentage error (MAPE) values of 78.25% for hydraulic conductivity ( K ) and 55.56% for specific yield ( S y ), compared to 299% and 209% in ADDE-CL. Moreover, ADPSO-CL has the fastest convergence rate, achieving efficient results in about half of the total iterations. This study introduces a novel and scalable architecture for intricate simulation–optimization problems, demonstrating its potential for future applications in real-world water resources planning and management.},
  archive      = {J_EAAI},
  author       = {Kiara Tesen and Hermilo Cortés and Sebastián Vicuña and Edmundo Molina-Perez and Francisco Suárez},
  doi          = {10.1016/j.engappai.2025.112098},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112098},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Groundwater parameters estimation: A hybrid approach of convolutional layers with asynchronous and distributed bio-inspired algorithms},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting power generation: A novel two-dimensional logistic fractional grey model. <em>EAAI</em>, <em>161</em>, 112097. (<a href='https://doi.org/10.1016/j.engappai.2025.112097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of power generation is essential for the stable operation of power systems, sustained economic growth, and harmonious social development. However, power systems exhibit chaotic characteristics such as complex and nonlinear dynamics during operation; for this reason, this study exploits the fact that two-dimensional logistic mapping helps with the recognition and control of the complex high-dimensional dynamics of the system. Additionally, the fractional-order chaotic system offers a more universal means to describe the chaotic phenomena, etc., and introduces the modelling mechanism of the two-dimensional logistic model and the fractional-order derivative theory into the grey model. A novel two-dimensional logistic fractional-order grey model is developed. The new model can simultaneously analyze two parallel major factors that evolve and are interrelated, and the fractional-order derivatives and nonlinear terms accurately portray the historical state and dynamic evolution process of the system, which can explore the evolution law in the time series of power generation more adequately. Furthermore, the particle swarm optimization algorithm is used to optimize the fractional order derivatives and parameters so that the adjustable model parameters can better capture the change pattern of the original power generation system data. The new model is applied to China's power generation prediction, and its validity is verified from three different perspectives through two different power generation modes as the research objects. Moreover, the new model outperforms the other seven models in its calculations. Finally, the new model effectively forecasts China's power generation for the next five years.},
  archive      = {J_EAAI},
  author       = {Mingyue Weng and Huiming Duan and Derong Xie},
  doi          = {10.1016/j.engappai.2025.112097},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112097},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting power generation: A novel two-dimensional logistic fractional grey model},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep reinforcement learning optimization algorithm based on heterogeneous graph neural network for hybrid flow shop scheduling problem with finite transportation resources. <em>EAAI</em>, <em>161</em>, 112096. (<a href='https://doi.org/10.1016/j.engappai.2025.112096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many actual process industries, transportation equipment represented by automated guided vehicles (AGVs) is widely used. However, current related research rarely considers the coordinated scheduling optimization of AGVs and production equipment. To this end, the hybrid flow shop scheduling problem (HFSP) with finite transportation resources (HFSP-FTR) in process industries is considered in this paper. Since it is necessary to consider the coordinated scheduling optimization of machines and AGVs at the same time, an end-to-end deep reinforcement learning scheduling method based on a heterogeneous graph neural network is proposed. First, a heterogeneous graph model capable of expressing any HFSP-FTR instance is constructed to visually represent the allocation relationship among jobs, machines, and AGVs. Second, a Markov decision process is formulated for solving HFSP-FTR, which specifically encompasses state features based on the heterogeneous graph model and a novel representation method for composite scheduling actions. Then, a novel heterogeneous graph neural network framework that can parallelly embed nodes of various types is proposed, aiming to derive graph-level embeddings for HFSP-FTR instances. Finally, a policy network is designed to obtain the probability distribution of each composite scheduling action being executed, and a deep reinforcement learning framework based on the multi-actor network is proposed for training. The results of numerical simulation experiments conducted on test instances with varying types demonstrate that the proposed method can acquire effective and highly generalized scheduling strategies in terms of makespan performance, outperforming other scheduling algorithms that are widely applied regarding the quality of scheduling solutions and other aspects.},
  archive      = {J_EAAI},
  author       = {Yejian Zhao and Xiaochuan Luo and Weixiang Xu and Yulin Zhang},
  doi          = {10.1016/j.engappai.2025.112096},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112096},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep reinforcement learning optimization algorithm based on heterogeneous graph neural network for hybrid flow shop scheduling problem with finite transportation resources},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unknown fault incremental learning based on shapelet prototypical network for streaming industrial signals. <em>EAAI</em>, <em>161</em>, 112094. (<a href='https://doi.org/10.1016/j.engappai.2025.112094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unknown faults represent faults that have never occurred before, they are constantly emerging due to the changing environments and operations in industrial processes. It is a challenge for existing fault diagnosis methods to continually detect unknown faults and effectively classify known faults in streaming industrial signals. This article proposes an unknown fault incremental learning method for streaming industrial signals. In this work, shapelet prototypical embedding combined with a memory distance matrix is employed to embed streaming industrial signals into a discriminative feature space. Therefore, the category information in the signals can be extracted and is not limited by the size of the sliding window. Besides, a new training paradigm based on meta-learning by sampling simulated-incremental tasks is proposed to obtain generalizable shapelets. Moreover, based on the new training paradigm, the meta-discovery module is proposed to continually detect unknown faults, and the meta-calibrate module can calibrate all prototypes into a distinguishable space. Experiments on the simulated streaming time series, benchmark Tennessee Eastman process, and real-world aluminum electrolysis process illustrate the superiority of the proposed method in terms of accuracy and interpretability. The code is available in https://github.com/XiaoxueWan/UFIL.git .},
  archive      = {J_EAAI},
  author       = {Xiaoxue Wan and Lihui Cen and Xiaofang Chen and Yongfang Xie and Zhaohui Zeng},
  doi          = {10.1016/j.engappai.2025.112094},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112094},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unknown fault incremental learning based on shapelet prototypical network for streaming industrial signals},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive attention graph convolution network with normalized embedded gaussian for rapid serial visualization presentation decoding. <em>EAAI</em>, <em>161</em>, 112093. (<a href='https://doi.org/10.1016/j.engappai.2025.112093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have been widely used in Brain Computer Interface (BCI) and have shown great prowess in identifying electroencephalogram (EEG) spatiotemporal features. However, most GCNs learn channels topological relationship by fixed adjacency matrix. This lacks connectivity strength information and ignores the data dependency. This paper proposes a data-driven adjacency matrix based on normalized embedded Gaussian function, and constructs a Gaussian-Adaptive Attention Graph Convolution Network (Gaussian-AAGCN). Brain regions connectivity is calculated by normalized embedded Gaussian function, and the topological relationship is adaptively learned by input data in a data-driven manner. This data-driven adaptive adjacency matrix avoids brain activity information loss caused by fixed adjacency matrix and improves the flexibility of graph construction. Convolutional block attention module (CBAM) is introduced to adaptive feature refinement in two independent dimensions, improving model representation ability. Experimental results show that the average area under curve (AUC), true positive rate (TPR) and false positive rate (FPR) of Gaussian-AAGCN on 14 subjects are 93.52 %, 91.59 %, and 4.58 % respectively. Compared to Transformer, Event-Related Potential Capsule Network (ERP-CapsNet), Electroencephalogram Convolutional Neural Network (EEGNet), and Multi-Granularity Information Fusion Network (MGIFNet), the AUC of Gaussian-AAGCN is higher by 18.02 %, 5.32 %, 2.62 %, and 1.82 %, respectively. Using the adaptive adjacency matrix, the model AUC and TPR are increased by about 4.8 % and 7.8 % respectively. After integrating CBAM, the AUC and TPR increased by about 3.5 % and 8 % respectively.},
  archive      = {J_EAAI},
  author       = {Mengyuan Zhao and Qingsong Ai and Kun Chen and Quan Liu and Sheng Quan Xie and Li Ma},
  doi          = {10.1016/j.engappai.2025.112093},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112093},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive attention graph convolution network with normalized embedded gaussian for rapid serial visualization presentation decoding},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GREEN: Graph reasoning enhanced encoder network for social intention-aware forecast of vessel navigating trajectory. <em>EAAI</em>, <em>161</em>, 112092. (<a href='https://doi.org/10.1016/j.engappai.2025.112092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have demonstrated that graph neural network (GNN) excel in interactive modeling, particularly by enhancing reasoning capabilities through the construction of interaction graphs, and the application of graph convolutional network (GCN). However, these methods remain heavily dependent on prior features, which limits the ability of vessels to accurately infer each other’s decision-making intentions in encounter situations. Therefore, this paper proposes graph reasoning enhanced encoder network (GREEN), which enables social community insight on multi-ships interactions, and latent intention aware for interactive trajectory forecast. The architecture of GREEN includes two layers of trajectory-graph-embedded encoders layer (TGEEL) and multi-graphs-gated fusion layer (MGGFL). In TGEEL, we respectively design intention trajectory generator unit for graph-embedded multi-ships trajectory representation via random walk process, and latent intention generator unit to forecast future navigating intentions via variational autoencoder. In MGGFL, we also design two units, where one unit is in charge of social aware construction and spatio-temporal features extraction based on interactive multi-graphs, and the other one is responsible for gated fusion of multi-scale features and forecast future trajectory using spatio-temporal attention. Experimental results across five datasets were collected from real-world maritime environments, which demonstrated that GREEN achieved improvements of 39.98%, 38.57%, 38.65%, and 63.33% in average displacement error , final displacement error, maximum displacement error, and miss rate, compared with state-of-the-art methods. The paper highlights GREEN robust potential in complex navigational scenarios, and provides pivotal support for advancing the development of intelligent maritime systems.},
  archive      = {J_EAAI},
  author       = {Junhao Jiang and Yi Zuo},
  doi          = {10.1016/j.engappai.2025.112092},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112092},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GREEN: Graph reasoning enhanced encoder network for social intention-aware forecast of vessel navigating trajectory},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffAT: Effective data augmentation with diffusion models for time series forecasting. <em>EAAI</em>, <em>161</em>, 112091. (<a href='https://doi.org/10.1016/j.engappai.2025.112091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation offers a promising solution to data scarcity in deep learning-based time series forecasting. However, current approaches face dual limitations (1) Hand-designed methods (e.g., cropping/masking): often disrupt the continuity of vital temporal patterns (such as seasonal and trend) by introducing abrupt pattern discontinuities; (2) Generative models often face difficulties in preserving task-critical features that are essential for prediction, especially when aiming to generate diverse augmented series. To tackle these dilemmas, we propose a novel conditional diffusion-based data augmentation framework, named DiffAT, for time series forecasting tasks. DiffAT synergizes: (1) Patch-wise masking reconstruction to capture structural invariants (such as autocorrelation and causality), and (2) encoding hand-designed augmentation prototypes for guiding diversity-preserving generation. DiffAT achieves dual enhancement: maintaining continuity of temporal patterns through progressive denoising process and exposing latent invariant patterns via guided diversity injection. We validate the efficacy of DiffAT through extensive experiments on seven real-world datasets, by comparing DiffAT with six state-of-the-art time series data augmentation methods. The results indicate our method can boost the forecasting performance of Autoformer by up to 6.49 % in 26/28 cases and improve forecasting performance of LightTS by up to 3.11 % in 23/28 cases on 7 real-world benchmarks. Extensive experiments also indicate that DiffAT can improve the accuracy of forecasting models in few-shot scenario (with 1 % training data) in 54/60 cases. We will release the source code upon publication.},
  archive      = {J_EAAI},
  author       = {Yang Yu and Ruizhe Ma and Wenbo Gu and Zongmin Ma},
  doi          = {10.1016/j.engappai.2025.112091},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112091},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DiffAT: Effective data augmentation with diffusion models for time series forecasting},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating reinforcement learning-based neural controllers for quadcopter navigation in windy conditions. <em>EAAI</em>, <em>161</em>, 112090. (<a href='https://doi.org/10.1016/j.engappai.2025.112090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate quadcopter navigation under windy conditions remains challenging for traditional control methods, especially in the presence of unpredictable wind gusts and strict navigational constraints. This paper evaluates Deep Reinforcement Learning (DRL) based controllers under such conditions, analysing the impact of wind domain randomisation, multi-goal training, enhanced state representations with explicit wind information, and the use of temporal data to capture affecting dynamics over time. Experiments in the AirSim simulator across four trajectories — evaluated under both no-wind and windy conditions — demonstrate that DRL-based controllers outperform classical methods, particularly under stochastic wind disturbances. Moreover, we show that training a DRL agent with domain randomisation improves robustness against wind but reduces efficiency in no-wind scenarios. However, incorporating wind information into the agent’s state space enhances robustness without sacrificing performance in wind-free settings. Furthermore, training with stricter waypoint constraints emerges as the most effective strategy, leading to precise trajectories and improved generalisation to wind disturbances. To further interpret the learned policies, we apply Shapley Additive explanations analysis, revealing how different training configurations influence the agent’s feature importance. These findings underscore the potential of DRL-based neural controllers for resilient autonomous aerial systems, highlighting the importance of structured training strategies, informed state representations, and explainability for real-world deployment.},
  archive      = {J_EAAI},
  author       = {Alain Andres and Aritz D. Martinez and Sümer Tunçay and Ignacio Carlucho},
  doi          = {10.1016/j.engappai.2025.112090},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112090},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluating reinforcement learning-based neural controllers for quadcopter navigation in windy conditions},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pixel-level semantics boosted fine-grained bird image classification. <em>EAAI</em>, <em>161</em>, 112089. (<a href='https://doi.org/10.1016/j.engappai.2025.112089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained bird image classification (FBIC) is crucial for endangered bird conservation and biodiversity research. However, existing methods often struggle to capture detailed features and manage the interference caused by complex backgrounds. To address these challenges, we propose a novel Pixel-Level Semantic Boosted Fine-Grained Bird Image Classification (PFIC) framework, which enhances fine-grained bird image classification by incorporating pixel-level semantic information. PFIC consists of two core components: the Grouped Detail Enhancement (GDE) module and the Background–Foreground Enhancement (BFE) strategy. GDE integrates multi-level pixel-level semantic information, derived from a segmentation feature extractor, into classification features via two submodules: grouped aggregation and detail enhancement. This approach enhances the model’s ability to capture fine-grained details. BFE augments training samples by restricting background ranges and applying random shifts to foreground objects, thereby improving the model’s capability to recognize foreground objects in complex environments. Experimental results demonstrate that our method achieves state-of-the-art performance on the CUB-200-2011 and NABirds datasets. Additionally, further experiments on the Stanford Cars dataset validate the framework’s potential for generalization to other fine-grained image classification tasks.},
  archive      = {J_EAAI},
  author       = {Haoxiang Ma and Yongjian Deng and Bochen Xie and Jian Liu and Hai Liu and Youfu Li and Zhen Yang},
  doi          = {10.1016/j.engappai.2025.112089},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112089},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pixel-level semantics boosted fine-grained bird image classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based soft sensor of five day biochemical oxygen demand indicators in the municipal wastewater treatment process. <em>EAAI</em>, <em>161</em>, 112088. (<a href='https://doi.org/10.1016/j.engappai.2025.112088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Five day biochemical oxygen demand (BOD 5 ) is usually used to measure whether wastewater treatment meets the standard. Previously, the development of machine learning technology was applied to predict BOD 5 for future planning of wastewater treatment. In real wastewater treatment, the monitoring of BOD 5 often lags behind for a long time, so neural network-based soft sensor methods are widely used in this field. However, the currently used BOD 5 soft sensor model has the problem of ignoring the synergistic effect of the model and stable information transmission. In order to monitor the BOD 5 concentration more accurately, a Transformer network model with embedded Long Short-Term Memory (LSTM) network is proposed in this article : LSTM is embedded into the calculation of the transformer multi-head attention, and the output method of the multi-head attention is improved so that the attention heads are output one by one in a serial manner, so it is named LSTM-Serial-Transformer (LSformer). Compared with previous models, LSformer optimizes input information through LSTM and Transformer to achieve synergistic effect, thus better capturing the characteristics of BOD 5 time series data, while reducing the risk of gradient vanishing or gradient exploding during data transmission to improve the stability of the model. Finally, the model was verified to have better soft sensor performance on a benchmark simulation model and a real-world dataset.},
  archive      = {J_EAAI},
  author       = {Xiaoling Zhang and Zhi Qi and Peng Chang and Zhiqi Hu},
  doi          = {10.1016/j.engappai.2025.112088},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112088},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer-based soft sensor of five day biochemical oxygen demand indicators in the municipal wastewater treatment process},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ForgetMe: Benchmarking the selective forgetting capabilities of generative models. <em>EAAI</em>, <em>161</em>, 112087. (<a href='https://doi.org/10.1016/j.engappai.2025.112087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of diffusion models in image generation has increased the demand for privacy-compliant unlearning. However, due to the high-dimensional nature and complex feature representations of diffusion models, achieving selective unlearning remains challenging, as existing methods struggle to remove sensitive information while preserving the consistency of non-sensitive regions. To address this, we propose an Automatic Dataset Creation Framework based on prompt-based layered editing and training-free local feature removal, constructing the ForgetMe dataset and introducing the Entangled evaluation metric. The Entangled metric quantifies unlearning effectiveness by assessing the similarity and consistency between the target and background regions and supports both paired ( Entangled-D ) and unpaired ( Entangled-S ) image data, enabling unsupervised evaluation. The ForgetMe dataset encompasses a diverse set of real and synthetic scenarios, including CUB-200-2011 (Birds), Stanford-Dogs, ImageNet, and a synthetic cat dataset. We apply LoRA fine-tuning on Stable Diffusion to achieve selective unlearning on this dataset and validate the effectiveness of both the ForgetMe dataset and the Entangled metric, establishing them as benchmarks for selective unlearning. Our work provides a scalable and adaptable solution for advancing privacy-preserving generative AI. Code is available at: https://github.com/YuZhenyuLindy/ForgetMe .},
  archive      = {J_EAAI},
  author       = {Zhenyu Yu and Mohd Yamani Idna Idris and Pei Wang and Yuelong Xia and Yong Xiang},
  doi          = {10.1016/j.engappai.2025.112087},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112087},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ForgetMe: Benchmarking the selective forgetting capabilities of generative models},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel data generation scheme for surrogate modelling with deep operator networks. <em>EAAI</em>, <em>161</em>, 112086. (<a href='https://doi.org/10.1016/j.engappai.2025.112086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operator-based neural network architectures such as deep operator networks have emerged as a promising tool for the surrogate modelling of physical systems. In general, the training data for operator surrogate modelling are generated by solving partial differential equations using the finite element method. The computationally intensive nature of data generation is one of the major bottlenecks in deploying these surrogate models, hindering the deployment of these surrogate models in practical applications. In this study, we propose a novel methodology to alleviate the computational burden associated with training data generation for deep operator networks. Unlike the existing literature, the proposed framework for data generation does not use any partial differential equation integration strategy, such as the finite element method. In the proposed strategy, the primary field consistent with the boundary conditions is first generated randomly using Gaussian process regression. Thereafter, from the primary field, the input source field is calculated using second-order accurate finite difference techniques. The computation of the derivatives from the finite difference scheme is significantly less computationally intensive and easier to implement compared to integrating the underlying governing equations, thereby reducing the computational cost associated with generating training datasets. To validate the proposed approach, we employ heat equations as a model problem and develop the surrogate model for numerous boundary value problems.},
  archive      = {J_EAAI},
  author       = {Shivam Choubey and Shailendra Rahi and Birupaksha Pal and Manish Agrawal},
  doi          = {10.1016/j.engappai.2025.112086},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112086},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel data generation scheme for surrogate modelling with deep operator networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable generalization diagnosis: Variational causal disentanglement-based coalitional game attribution network. <em>EAAI</em>, <em>161</em>, 112084. (<a href='https://doi.org/10.1016/j.engappai.2025.112084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretability and controllability are the keys to intelligent fault diagnosis in industrial scenarios. However, most intelligent methods have focused on post-hoc feature importance explanations, which cannot constrain the uncontrollable learning behavior or form an interpretable diagnosis process consistent to match expert experience. To address this problem, this paper proposes a variational causal disentanglement-based coalitional game attribution network (VCN) to achieve a controllable and interpretable modeling paradigm that can draw diagnostic conclusions with conforming to expert experience. This model enables independent causal factor disentanglement and model regularization during the training process, as well as fast explanation computation at test time. Variational causal disentanglement is defined and do-operations and variational inference processes are introduced to generate training data with independent causal factors for subsequent attribution. The coalitional game attribution establishes a coalitional game relationship between the model and the independent causal factors, and regularizes the model so that it converges to a state that conforms to logical axioms. Both laboratory and real-world data demonstrate the proposed method enables the provision of interpretable diagnostic conclusions while maintaining controllable performance. The code is available at: https://github.com/cyber-dogy/VCN-code .},
  archive      = {J_EAAI},
  author       = {Junwei Gu and Changhua Hu and Yu Wang and Mingquan Zhang and Yanzhuo Lin and Shangjing Peng and Dongdong Li},
  doi          = {10.1016/j.engappai.2025.112084},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112084},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable generalization diagnosis: Variational causal disentanglement-based coalitional game attribution network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel photovoltaic cell defect detection method: A deep learning model based on multi-scale enhanced feature extraction. <em>EAAI</em>, <em>161</em>, 112083. (<a href='https://doi.org/10.1016/j.engappai.2025.112083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasingly widespread application of clean energy technology, the global demand for photovoltaic cells is gradually increasing, and the status and defects of photovoltaic cells are also being taken seriously. However, there are various types of defects in photovoltaic cells, including those that are difficult to detect, making detection work somewhat challenging. This article proposes a novel improved model for defect detection in photovoltaic cells based on You Only Look Once (YOLO). Firstly, the Multi-Head Self-Attention (MHSA) mechanism is adopted to compensate for the shortcomings of the Cross Stage Partial Bottleneck with 2 Convolutions (C2f) module in channel feature extraction. Secondly, the Receptive-Field Coordinate Attention Convolutional (RFCAConv) operation module is utilized to expand the receptive field of defect detection in the model and increase the range of feature extraction. Finally, the Bi-directional Feature Pyramid Network (BiFPN) and Concat modules are integrated to enhance the feature relationships between the output connections of each module and strengthen the output results. The final experimental results demonstrate that the improved model achieves an accuracy of 90.3%, representing a 5.2% increase compared to the original model. Through experimental verification, the improved model proposed in this paper can not only detect defects in photovoltaic cells in electroluminescence (EL) images but also in infrared thermal images. The model has strong generalization ability.},
  archive      = {J_EAAI},
  author       = {Yu Gao and Zhanying Li and Yinghao Zhang and Kangye Zhang and Haoyang Yu},
  doi          = {10.1016/j.engappai.2025.112083},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112083},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel photovoltaic cell defect detection method: A deep learning model based on multi-scale enhanced feature extraction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wind power prediction based on hybrid deep learning and monte carlo simulation. <em>EAAI</em>, <em>161</em>, 112082. (<a href='https://doi.org/10.1016/j.engappai.2025.112082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a hybrid deep learning model combining Variational Mode Decomposition (VMD), Convolutional Neural Networks (CNN), and a Three-Dimensional Gated Neural Network (TGNN) to enhance wind power prediction accuracy. VMD decomposes wind power time series into intrinsic mode functions, CNN extracts deep features, and TGNN captures temporal dependencies with error feedback control. A Monte Carlo simulation based on the Central Limit Theorem is introduced to evaluate predictive uncertainty and interval coverage. Experimental results from three wind farms in China demonstrate that the proposed model significantly outperforms baseline hybrid models. Specifically, it achieves a coverage probability (CP) of 0.887, an average interval width (AIW) of 200.870, and a normalized mean square error (NMSE) of 0.057. Compared with the VMD-CNN-LSTM model, the proposed VMD-CNN-TGNN reduces root mean error (RMSE) by approximately 50%, indicating its superior accuracy, robustness, and practical value in wind power forecasting.},
  archive      = {J_EAAI},
  author       = {Zhiyong Guo and Qiaoli Han and Fangzheng Wei and Wenkai Qi},
  doi          = {10.1016/j.engappai.2025.112082},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112082},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Wind power prediction based on hybrid deep learning and monte carlo simulation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A parallel memetic algorithm for qubit mapping on noisy intermediate-scale quantum machines. <em>EAAI</em>, <em>161</em>, 112081. (<a href='https://doi.org/10.1016/j.engappai.2025.112081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computer technologies are advancing rapidly, but current devices are still limited to the realm of Noisy Intermediate Scale Quantum (NISQ) systems. Due to the limited set of gates and scarce physical qubit connectivity, most quantum circuit-based programs need to be transpiled to be executed on such hardware. This transpilation, which consists in converting the quantum circuit into a hardware-compliant one includes the critical qubit mapping step, where logical qubits are mapped onto physical qubits to meet the hardware connectivity constraints. In this paper, we investigate the application of Artificial Intelligence (AI) to the qubit mapping problem. More exactly, we propose a Parallel Memetic Algorithm for Qubit Mapping (PMA-QM), designed to tackle this challenge efficiently. Using a fine-tuned parallel model to accelerate this inherently computationally expensive hybrid approach, our algorithm takes problem-specific knowledge into account to optimize circuit depth, reducing execution time, and minimizing error rates consequently. PMA-QM has been experimented using various medium-to-large scale circuit benchmarks. PMA-QM outperforms the widely used SWAP-based BidiREctional (SABRE) algorithm, delivering consistently better solutions.},
  archive      = {J_EAAI},
  author       = {Jérôme Rouzé and Nouredine Melab and Jan Gmys and Daniel Tuyttens},
  doi          = {10.1016/j.engappai.2025.112081},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112081},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A parallel memetic algorithm for qubit mapping on noisy intermediate-scale quantum machines},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing non-orthogonal multiple access systems: A reconfigurable machine learning classification approach. <em>EAAI</em>, <em>161</em>, 112080. (<a href='https://doi.org/10.1016/j.engappai.2025.112080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-Orthogonal Multiple Access (NOMA) is being considered as a Multiple Access (MA) technique for the next-generation systems, due to factors such as a high per-user spectral resource allocation, grant-free transmission, support for millimeter Waves (mmWaves) and massive-MIMO (mMIMO). A practical limitation of the NOMA systems is imperfect Successive Interference Cancellation (SIC); and the involved decoding delay. This work develops a data-driven Machine Learning (ML) model providing the functionality of a SIC receiver. While most of the Deep Learning (DL) algorithms have high complexity and training times, the given ML approach utilizes the received symbol as the only primary predictor. The other two predictors are derived from the primary predictor, and utilized for the Power-Domain (PD)-NOMA symbol-decoding process. The model utilizes a developed low-complexity NOMA-ML-based Decoder (MLbD) dataset for the same. The extensive test simulations confirm the reconfigurable ML-based receiver to be at par with the existing Maximum Likelihood (MLH) decoder in terms of decoding accuracy. Still, the former supports its integration into the next-generation systems due to its reconfigurable nature and removes the drawbacks related to SIC in the NOMA systems.},
  archive      = {J_EAAI},
  author       = {Saurabh Srivastava and Rampravesh Kumar and Prajna Parimita Dash},
  doi          = {10.1016/j.engappai.2025.112080},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112080},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing non-orthogonal multiple access systems: A reconfigurable machine learning classification approach},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaborative energy-saving path planning of unmanned surface vehicle cluster based on multi-head attention mechanism and multi-agent deep reinforcement learning. <em>EAAI</em>, <em>161</em>, 112078. (<a href='https://doi.org/10.1016/j.engappai.2025.112078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a Multi-Agent Deep Reinforcement Learning (MADRL) algorithm to address the overlooked issue of energy consumption optimization in existing cluster path planning methods, enabling collaborative energy-efficient path planning for Unmanned Surface Vehicle (USV) clusters. Meanwhile, it provides an alternative MADRL approach to address practical engineering challenges. We not only consider the problems of avoiding danger, reaching the target point and avoiding path conflicts between USV, but also further consider the energy consumption and speed planning of USV cluster. Specifically, firstly, we establish the USV motion model and the USV cluster conflict model, and propose a new energy consumption model, which considers the relationship among speed, marine environment and propulsion load. Secondly, we propose a multi-head local state relevance capture mechanism-multi-agent proximal policy optimization (MLSRC-MAPPO) algorithm. This algorithm can use multi-head attention mechanism (MHA) to capture the potential dependencies between USV, thus enhancing the convergence performance of multi-agent. Finally, in order to reduce the training difficulty, we propose a multi-dimensional action space method for action networks. The experimental results demonstrate that the proposed multi-dimensional action space method has achieved significant success in the lightweighting of the action network: the number of network parameters was reduced by 89.10%, and the computational complexity was decreased by 88.94%, significantly enhancing training efficiency. Meanwhile, the MLSRC-MAPPO algorithm, by incorporating a multi-head attention mechanism, greatly improved the convergence performance of the multi-agent system. In test scenarios with both identical and different starting points, the method reduced energy consumption by 26.24% and 38.47% respectively, fully validating its effectiveness and superiority. Furthermore, comparative experiments with existing cluster energy-saving path planning methods show that the proposed method exhibits clear advantages in terms of energy consumption and path planning efficiency, further verifying its superiority. The corresponding code for this paper is as follows: https://github.com/xhpxiaohaipeng/Multi_USV_Trajectory_energy_plan},
  archive      = {J_EAAI},
  author       = {Haipeng Xiao and Lijun Fu and Chengya Shang and Yunfeng Lin and Longfei Yue and Yaxiang Fan},
  doi          = {10.1016/j.engappai.2025.112078},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112078},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Collaborative energy-saving path planning of unmanned surface vehicle cluster based on multi-head attention mechanism and multi-agent deep reinforcement learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification of surface subsidence risk in deep foundation pits using a mamba fusion model. <em>EAAI</em>, <em>161</em>, 112077. (<a href='https://doi.org/10.1016/j.engappai.2025.112077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel artificial intelligence–driven neural network model, CNN-Mamba-LSTM-SA, for predicting surface settlement induced by deep foundation pit excavation. The model integrates Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), a Self-Attention (SA) mechanism, and the Mamba architecture to capture both spatial and long-range temporal dependencies in multi-source monitoring data. Bayesian optimization is employed for hyperparameter tuning, and Variational Mode Decomposition (VMD) is used for data denoising, resulting in improved prediction accuracy. To enhance model interpretability, Shapley Additive Explanations (SHAP) are applied to identify key deformation drivers, revealing groundwater level and building settlement as the most influential factors. Model performance is validated using monitoring data from the Nanjing Gemini excavation project, where it achieves superior results compared to conventional models. The CNN-Mamba-LSTM-SA model reduces Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and Root Mean Square Error (RMSE) by up to 69.77 %, 62.45 %, and 79.45 %, respectively. Further analysis through ablation experiments confirms the contribution of each module. Interestingly, the combined removal of CNN and SA results in greater performance degradation than the sum of their individual effects. Finally, a risk warning framework is developed to enable the dynamic transformation of predicted and observed settlement values into actionable risk levels. This integrated artificial intelligence approach offers a robust and interpretable tool for managing excavation-induced risks in urban geotechnical engineering.},
  archive      = {J_EAAI},
  author       = {Chenhe Ge and Pengfei Li and Mingju Zhang and Meng Yang},
  doi          = {10.1016/j.engappai.2025.112077},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112077},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identification of surface subsidence risk in deep foundation pits using a mamba fusion model},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk management in maintenance processes: A spherical fuzzy-based failure mode and effect analysis approach in the glass processing industry. <em>EAAI</em>, <em>161</em>, 112076. (<a href='https://doi.org/10.1016/j.engappai.2025.112076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality management systems are essential tools that aim to increase the competitiveness of businesses and ensure customer satisfaction by creating reliable quality control processes. In this study, the importance of the "risk-based thinking" approach of the International Organization for Standardization (ISO) 9001:2015 standard within the scope of quality management systems was emphasized, and a risk assessment was made for the maintenance process of a business in the glass processing sector. In order to eliminate the deficiencies of the failure mode and effect analysis (FMEA) method, the integration of spherical fuzzy sets (SFSs) and the Technique of Order Preference Similarity to the Ideal Solution (TOPSIS) method was used. Within the scope of the study, 17 different risks were determined by five experts from the maintenance, repair, and quality assurance departments. The experts evaluated these identified risks according to occurrence, severity, and detection factors. Then, these risks were ranked using the Spherical Fuzzy TOPSIS (SF-TOPSIS) method. Finally, different scenarios were created, and their results were discussed to provide a more comprehensive and sensitive risk management approach. This study focuses on maintenance processes in the glass processing industry as a case study. However, the risks related to the maintenance process defined in the study (e.g., machine failures, maintenance inefficiencies, spare parts shortages) are common in the manufacturing sector. Therefore, it can be applied to the sector where the application was carried out and to many different sectors and enterprises.This methodology also serves as a guide for businesses that want to manage process risks within the scope of ISO 9001:2015.},
  archive      = {J_EAAI},
  author       = {Buse Duygu Dağıdır and Barış Özkan},
  doi          = {10.1016/j.engappai.2025.112076},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112076},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Risk management in maintenance processes: A spherical fuzzy-based failure mode and effect analysis approach in the glass processing industry},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot augmentation based on variational auto-generative adversarial network with moving losses: Application to the variable stiffness prediction in composites. <em>EAAI</em>, <em>161</em>, 112075. (<a href='https://doi.org/10.1016/j.engappai.2025.112075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dataset of carbon fiber reinforced plastics (CFRP) materials presents characteristics of high-dimensional, low-rank, and sparse, which pose difficulties in the combination of mechanical modeling. In this paper, a Variational Auto-Generative Adversarial Network (VAGAN) with moving losses is proposed as a data augmentation method, which extends the size of the CFRP dataset covering components, processes, elasticity, and strengths factors, and increases the information conveyed in the surrogate modeling. A compression strength prediction model for CFRP laminates was constructed by combining the component, process, and mechanical tensor with a neural network optimized by the search algorithm. Combined with the data augmentation strategy, not only was the amount of data expanded, but the prediction accuracy was also significantly improved. The allowable value of compression strength is analyzed and calculated by the predicted values, which brings direct benefits in simplifying the test.},
  archive      = {J_EAAI},
  author       = {Zhicen Song and Yunwen Feng and Cheng Lu and Jiaqi Liu},
  doi          = {10.1016/j.engappai.2025.112075},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112075},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Few-shot augmentation based on variational auto-generative adversarial network with moving losses: Application to the variable stiffness prediction in composites},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multivariate time series forecasting based on temporal decomposition and graph neural network. <em>EAAI</em>, <em>161</em>, 112074. (<a href='https://doi.org/10.1016/j.engappai.2025.112074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is quite challenging to forecast the Multivariate Time Series (MTS) accurately due to the high dimensionality of MTS and the entangled correlation between variables. Recently, graph-based networks have been demonstrated to be an effective model to handle the complex correlations between MTS. However, all existing graph-based methods construct the graph model of the MTS using only the shallow correlations from the raw MTS data, ignoring the deep-rooted correlations hidden in the features. In this paper, we propose for the first time to construct a comprehensive graph model of MTS that incorporates both shallow correlations from raw data and hidden correlations from decomposed temporal properties. Then, we propose a novel graph-based MTS forecasting framework, which optimizes the graph structure jointly with the model parameters. By doing so, the graph structure can adaptively model the correlations of MTS at a deep level, while the joint optimization can make the constructed graph compatible with the forecasting tasks of MTS, contributing to a globally optimal solution. Finally, we conduct extensive experiments on seven real-world datasets, the results demonstrate the superiority of our method on MTS forecasting over the state-of-the-art baselines. The source codes of the experiments with datasets are available at https://github.com/ironweng/MF-TDGNN .},
  archive      = {J_EAAI},
  author       = {Yan Qiao and Pei Zhao and Junjie Wang and Rongyao Hu and Minyue Li and Xinyu Yuan and Meng Li and Zhenchun Wei and Cuiying Feng},
  doi          = {10.1016/j.engappai.2025.112074},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112074},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multivariate time series forecasting based on temporal decomposition and graph neural network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified framework for lung disease screening using chest X-ray images. <em>EAAI</em>, <em>161</em>, 112073. (<a href='https://doi.org/10.1016/j.engappai.2025.112073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest X-ray (CXR) imaging is a crucial diagnostic tool for identifying respiratory diseases. The existing methods face challenges such as misclassification caused by overlapping radiologic patterns and the shortage of trained radiologists. However, previous studies have utilized deep learning (DL) models to overcome these limitations, but they struggle with imbalanced datasets, and noise sensitivity. In addition, most of the studies are based on the binary classification of CXR images. Thus, the proposed framework integrates segmentation and multi-class classification for improved generalization and robustness. In this work, artificial intelligence techniques like encoder–decoder and ensemble learning are utilized for segmentation and classification of CXR images that offers reliable, and efficient solution. The output of the presented framework classifies the CXR images into four different classes, along with their corresponding class score. The proposed classification model is ensemble of three pre-trained DL architectures. The last five layers of these base models are fine tuned to match the classification process and combined through a multi-layer perceptron classifier for improved accuracy. The proposed model achieves overall accuracy of 88.98%, and area under curve value of 0.9753, outperforming several state-of-the-art models. It is a lightweight model and demonstrates significant robustness under noisy conditions compared to other models. Moreover, the proposed segmentation and ensemble models are trained and tested on different datasets to obtain greater robustness. The data augmentation is also employed to address class imbalance nature of dataset and enhance the generalization capability. Further, statistical analysis is performed to present the comprehensive comparison among the models.},
  archive      = {J_EAAI},
  author       = {Bhavana Singh and Pushpendra Kumar},
  doi          = {10.1016/j.engappai.2025.112073},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112073},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A unified framework for lung disease screening using chest X-ray images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid bayesian model updating and non-dominated sorting genetic algorithm framework for intelligent mix design of steel fiber reinforced concrete. <em>EAAI</em>, <em>161</em>, 112071. (<a href='https://doi.org/10.1016/j.engappai.2025.112071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steel fiber reinforced concrete (SFRC) improves the strength and toughness of conventional concrete, but the high cost and carbon footprint of fibers challenge the balance among performance, cost and sustainability. To address this, an intelligent mix design framework is proposed to optimize compressive and splitting tensile strengths, cost and emissions. Based on 671 experimental records, posterior models were built using Markov Chain Monte Carlo sampling and Bayesian model updating, enabling accurate strength predictions. Compared to traditional regression methods, R 2 scores improved by 15.7 % and 12.4 %, confirming its predictive advantage. Cost-wise, materials dominate, while emissions mainly arise from production, transport and mixing. A non-dominated sorting genetic algorithm identified optimal designs under given constraints. Results show that reducing water-to-cement and aggregate-to-cement ratios, and increasing sand ratio and fiber reinforcement index, enhances SFRC strength. Larger coarse aggregates reduce compressive strength but have limited effect on tensile strength. Optimization suggests potential cost and emission reductions of up to 60 %. Moreover, for compression-prone components, fiber use is inefficient due to high cost and emissions, whereas for crack-resistant or strength-balanced elements, fiber inclusion offers a more sustainable alternative to merely lowering the water-to-cement ratio. The proposed framework enables tailored SFRC mix designs, guiding the efficient use of steel fibers.},
  archive      = {J_EAAI},
  author       = {Yong Yu and Jie Su and Bo Wu},
  doi          = {10.1016/j.engappai.2025.112071},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112071},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid bayesian model updating and non-dominated sorting genetic algorithm framework for intelligent mix design of steel fiber reinforced concrete},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional human pose estimation based on multi-scale spatial–temporal transformer. <em>EAAI</em>, <em>161</em>, 112068. (<a href='https://doi.org/10.1016/j.engappai.2025.112068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, transformer-based methods have become dominant in the domain of three-dimensional (3D) human pose estimation, yet the U-net model based on convolutional neural networks (CNN) struggles to model long temporal sequences, and sequence-to-frame (Seq2frame) and sequence-to-sequence (Seq2seq) approaches often fail to preserve dependencies at the start and end of sequences. To address these challenges, this paper proposes a Multi-Scale Spatial–Temporal Transformer network (MSST). This network utilizes Sequence Padding Module (SPM) to extract edge features of the first and last frames, and employs Spatial–Temporal Transformer (STT) to model the spatial–temporal correlations of keypoints. Additionally, we design a Multi-Scale Module (MSM) that analyzes the human skeletal topology to extract multi-scale features of keypoints, local information, and global information, and fuse semantic information at different scales. Finally, we utilize regression heads to project the processed keypoint feature information into 3D space. We conduct quantitative evaluations on two benchmark datasets using four evaluation metrics and design multiple sets of comparative experiments to validate the effectiveness of the proposed modules. Experimental results demonstrate that the proposed network achieves excellent performance.},
  archive      = {J_EAAI},
  author       = {Xiaogang Song and Yongxin Cui and Jichen Chen and Xinhong Hei},
  doi          = {10.1016/j.engappai.2025.112068},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112068},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-dimensional human pose estimation based on multi-scale spatial–temporal transformer},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SharpEdge: High-quality data-driven monocular depth estimation for enhanced boundary precision. <em>EAAI</em>, <em>161</em>, 112067. (<a href='https://doi.org/10.1016/j.engappai.2025.112067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While existing monocular depth estimation methods have achieved commendable performance, they often fall short in accurately distinguishing object boundaries. This deficiency largely stems from the inherent noise in dataset acquisition, such as unclear edges and missing depth information. To address these challenges, this paper introduces a novel, high-quality, data-driven monocular depth estimation method tailored for autonomous driving. The approach significantly enhances depth predictions with clearer object boundaries and reduced noise, making it well-suited for real-time, safety-critical applications. Central to our approach is the Self-Adaptive Consistency Filtering mechanism, which dynamically selects high-quality training samples, ensuring that the model learns from the most reliable data and reducing the impact of noise. Additionally, we introduce a Dual-Prior Learning strategy that combines geometric and semantic edge priors. Unlike traditional methods that rely solely on raw depth maps, our approach enhances boundary detection by providing detailed guidance on object contours. This leads to more accurate depth estimation, especially in complex regions where other methods struggle. Empirical evaluations on popular benchmark datasets show that our approach leads to performance improvements of 1.2% on the autonomous driving dataset KITTI and 1.8% on the indoor scene dataset NYU. Compared with recent state-of-the-art methods such as DPT and NewCRFs, our approach achieves superior performance, particularly in recovering fine object boundaries and maintaining spatial consistency across diverse scenes. These results highlight the strong generalization ability of our method, demonstrating that it can enhance depth estimation quality across diverse environments — improving edge precision and spatial coherence, which are critical for autonomous vehicles navigating both complex and dynamic scenarios.},
  archive      = {J_EAAI},
  author       = {Mengke Song and Luming Li and Xu Yu and Chenglizhao Chen and Shanchen Pang},
  doi          = {10.1016/j.engappai.2025.112067},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112067},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SharpEdge: High-quality data-driven monocular depth estimation for enhanced boundary precision},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review on vision-based gaze estimation: Advance in computer vision and deep learning. <em>EAAI</em>, <em>161</em>, 112066. (<a href='https://doi.org/10.1016/j.engappai.2025.112066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eye gaze estimation is all about figuring out where a person is looking by analyzing eye movements. This is usually done using cameras or eye-tracking devices, a key technique in computer vision. Gaze estimation has a wide range of uses—from helping people interact with computers more naturally (HCI), monitoring drivers, enhancing virtual reality experiences, and reading emotional cues in affective computing. Deep learning has improved how accurately and reliably these systems work in recent years. Models like Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Generative Adversarial Networks (GANs) have made it easier to detect and interpret eye movements in complex settings. This review closely examines how gaze estimation works, the datasets commonly used, and both traditional and deep learning-based methods. It also points out what's working well, where current methods fall short, and what researchers still need to solve. The goal is to offer helpful insights for anyone working to improve or apply gaze tracking technologies in real-world scenarios.},
  archive      = {J_EAAI},
  author       = {Sapna Singh Kshatri and Deepak Singh},
  doi          = {10.1016/j.engappai.2025.112066},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112066},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A systematic review on vision-based gaze estimation: Advance in computer vision and deep learning},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel framework for improving railway driver performance based on emotional intelligence and job-driven factors: An artificial neural network method. <em>EAAI</em>, <em>161</em>, 112065. (<a href='https://doi.org/10.1016/j.engappai.2025.112065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient transportation systems critically rely on human factors to ensure safety, reliability, and service quality. This study introduces a novel framework for evaluating and improving the performance of the Tehran Urban and Suburban Railway Company (TRS) drivers by focusing on the role of emotional intelligence (EI) and job-driven (JD) factors. The core of the proposed method is a two-stage hybrid approach: first, an Artificial Neural Network (ANN) is used to model driver performance using EI and JD factors as inputs and outputs, respectively; then, Data Envelopment Analysis (DEA) validates the results and benchmarks performance levels. Data were collected from 146 TRS drivers through a standardized questionnaire. Sensitivity analysis and statistical tests evaluated the impact of EI and JD factors on driver performance. Additionally, a SWOT (Strengths, Weaknesses, Opportunities, Threats) analysis translated the findings into practical recommendations for system improvement. The findings reveal high job satisfaction and low job stress levels among TRS drivers, highlighting the significant contribution of EI and JD factors. By combining data-driven prediction, performance benchmarking, and strategic analysis, this study introduces a novel, human-centered framework for driver Performance Evaluation (PE)—one that fills methodological gaps in the literature and supports enhancing safety, efficiency, and passenger satisfaction in railway systems.},
  archive      = {J_EAAI},
  author       = {Narges Hajloo and Behnaz Salimi and Mahdi Hamid and Masoud Rabbani},
  doi          = {10.1016/j.engappai.2025.112065},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112065},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel framework for improving railway driver performance based on emotional intelligence and job-driven factors: An artificial neural network method},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient fusion-based deep learning framework for land use and land cover image clustering. <em>EAAI</em>, <em>161</em>, 112061. (<a href='https://doi.org/10.1016/j.engappai.2025.112061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land use and land cover (LULC) analysis is vital for understanding spatial dynamics and informing environmental management, urban planning, and sustainable development. Traditional approaches, such as manual surveys and conventional image clustering methods, often face limitations in scalability and adaptability. This paper presents a novel deep learning framework that combines the Vision Transformer (ViT) and Variational Autoencoder (VAE) to extract complementary feature representations for LULC image clustering. The ViT tokenizes image patches to capture high-level semantic features, while the VAE models latent structures to integrate contextual and structural information. To further improve clustering performance, the framework incorporates Uniform Manifold Approximation and Projection (UMAP) for dimensionality reduction followed by k -means++ clustering, enabling a scalable and robust solution for diverse datasets. Experiments on multiple datasets, including the Urban Atlas LULC 2018 dataset and recent LULC maps of Japan and Vietnam, demonstrate the framework’s superior ability to capture complex LULC patterns compared to traditional methods. The datasets and source code will be made publicly available at https://github.com/ClarkDinh/LULCMiner . This framework has broad applications across geospatial and remote sensing engineering, civil and environmental engineering, agricultural planning, transportation, and urban development.},
  archive      = {J_EAAI},
  author       = {Tai Dinh and Dat Tran and Zdena Dobešová and Huynh Van Hong and Daniil Lisik and Rameesh Khan},
  doi          = {10.1016/j.engappai.2025.112061},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112061},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient fusion-based deep learning framework for land use and land cover image clustering},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing multi-objectives urban siting of hydrogen refueling dispenser using fuzzy NSGA-II: A case study in fez, morocco. <em>EAAI</em>, <em>161</em>, 112060. (<a href='https://doi.org/10.1016/j.engappai.2025.112060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To support the growing need for sustainable urban transport, it is essential to reduce the environmental impact of vehicles; this study focuses on optimizing hydromobility through the strategic integration of hydrogen dispensers (HDs) into existing locations, rather than deploying standalone hydrogen refueling stations (HRSs). This approach minimizes costs while enhancing accessibility, addressing the current limitations in hydrogen vehicle (HV) adoption. A novel method combining the non-dominated sorting genetic algorithm II (NSGA-II) with fuzzy logic and Pareto front analysis is proposed to identify optimal HD locations using a real case study of Fez city in Morocco. The results provide actionable strategies for implementing HDs in a way that balances efficiency, accessibility, and budget constraints. The study demonstrates how intelligent planning can support the transition to cleaner energy solutions in urban mobility.},
  archive      = {J_EAAI},
  author       = {Soukayna Abibou and Dounia El Bourakadi and Ali Yahyaouy and Hamid Gualous},
  doi          = {10.1016/j.engappai.2025.112060},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112060},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing multi-objectives urban siting of hydrogen refueling dispenser using fuzzy NSGA-II: A case study in fez, morocco},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic data enhancement using diffusion models for improved miscanthus identification and bioenergy extraction. <em>EAAI</em>, <em>161</em>, 112059. (<a href='https://doi.org/10.1016/j.engappai.2025.112059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Miscanthus, a high-yielding perennial grass pivotal for bioenergy production, requires precise species identification to optimize bioenergy extraction. However, limited annotated spectral datasets hinder robust classification model development. To address this challenge, the paper proposes a novel diffusion probabilistic model tailored for near-infrared spectral synthesis. Unlike conventional generative approaches, the proposed model integrates a bidirectional gated recurrent unit-based temporal encoder and one dimension convolutional neural networks within a diffusion framework, augmented by a spectral attention module to prioritize critical absorption bands. This architecture uniquely addresses the sequential dependencies and subtle biochemical variations inherent in near-infrared spectral, enabling high-fidelity generation of diverse synthetic data. The diffusion process is optimized through a hybrid loss function combining variational lower bound training with mean squared error for pixel-level fidelity and maximum mean discrepancy for distributional alignment. Evaluated on 517 near-infrared spectral samples across three Miscanthus species, the proposed model outperforms traditional variational autoencoders , generative adversarial networks, and standard diffusion models in terms of sample authenticity and diversity. Incorporating synthetic data enhanced the accuracy, precision, and recall of downstream classifiers by 10%–15%, with the convolutional neural networks attaining 87% accuracy using hybrid real-synthetic training data. Remarkably, even with 50% synthetic data substitution, classification accuracy remained robust at 75%, demonstrating the model’s efficacy in mitigating data scarcity and advancing precision agriculture for bioenergy optimization.},
  archive      = {J_EAAI},
  author       = {Xinyue Wang and Xiangdong Chen and Jun Jiang and Ronggao Gong and Biao Wang},
  doi          = {10.1016/j.engappai.2025.112059},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112059},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synthetic data enhancement using diffusion models for improved miscanthus identification and bioenergy extraction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-order feature learning with global–local attention for real-time X-ray security inspection. <em>EAAI</em>, <em>161</em>, 112058. (<a href='https://doi.org/10.1016/j.engappai.2025.112058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X-ray security inspection in high-throughput environments such as airports faces fundamental challenges stemming from the intrinsic complexity of baggage scanning. These challenges include feature entanglement from overlapping objects, visual distortions due to fixed imaging angles, inconsistent pseudo-color representations caused by varying X-ray absorption, and the difficulty of detecting prohibited items across multiple scales. To tackle these challenges, we introduce Multi-Order Gated Network (MoGNet), a lightweight transformer-based architecture that integrates three core innovations. First, a Multi-order Gated Aggregation Block designed for efficient multi-order feature extraction. Second, a Global–Local Self-Attention mechanism that enhances differentiation between foreground and background elements. Finally, a DynamicFusion module for adaptive integration of multi-scale features. Comprehensive evaluations on five challenging datasets establish our proposed framework, MoGNet, as the new state-of-the-art (SOTA). The model demonstrates superior performance, achieving mean Average Precision (mAP) scores at a 50% Intersection over Union (IoU) threshold (mAP 50 ) of 75.4%, 91.9%, 91.2%, 96.6%, and 80.0%, respectively. This high accuracy is maintained while operating at an efficient 64.1 Frames Per Second (FPS). These comprehensive experimental results demonstrate its remarkable capability to optimize the balance between computational efficiency and detection accuracy, establishing it as a preferable solution for real-time contraband detection in practical security screening.},
  archive      = {J_EAAI},
  author       = {Ling Guo and Yangbin Xu and Shouhong Chen},
  doi          = {10.1016/j.engappai.2025.112058},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112058},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-order feature learning with global–local attention for real-time X-ray security inspection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stress-dependent strength neural network model for predicting the true triaxial strength of rocks. <em>EAAI</em>, <em>161</em>, 112057. (<a href='https://doi.org/10.1016/j.engappai.2025.112057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the true triaxial strength of rocks is essential for safe underground engineering, yet existing empirical and data-driven models often fail to capture the nonlinear effects of the intermediate principal stress σ 2 . This study proposes a stress-dependent strength neural network (SDSNN) that integrates physically informed constraints, including monotonicity and boundary conditions, as well as an exponential adaptive weighting strategy to balance data and constraint losses. Cohesion and internal friction angle are used as input features, replacing conventional reliance on uniaxial strength. Compared with a purely data-driven neural network (DDNN) and a constraint-aware variant without adaptive weighting (SDSNN#0), SDSNN achieves significantly better predictive accuracy and robustness across test sets, representative rock types, and five-fold cross-validation. In particular, it maintains consistent strength trends and improved stability across six representative rocks with diverse mechanical properties. Importantly, the model maintains high performance even when trained only on low-to-mid σ 2 data and tested on high σ 2 conditions—demonstrating strong generalization under extrapolation. This capability has received relatively limited attention in data-driven models and is particularly valuable in practical scenarios where high- σ 2 test data are limited or difficult to obtain. Furthermore, ablation analysis demonstrates that removing physical constraints leads to a notable decrease in model accuracy, underscoring the importance of incorporating strength variation characteristics into the model. SDSNN shows particular advantage under boundary stress conditions and when facing noisy or sparse datasets, indicating its potential to serve as a robust and interpretable tool for true triaxial strength prediction in geotechnical applications.},
  archive      = {J_EAAI},
  author       = {Tianzhi Yao and Yunpeng Gao and Jianhai Zhang and Ru Zhang and Li Qian and Qijun Hu and Xianliang Wang and Feng Jiang},
  doi          = {10.1016/j.engappai.2025.112057},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112057},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A stress-dependent strength neural network model for predicting the true triaxial strength of rocks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source contrastive cluster center method for cross-domain bearing fault identification. <em>EAAI</em>, <em>161</em>, 112056. (<a href='https://doi.org/10.1016/j.engappai.2025.112056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the complexity and time-varying attributes of the exterior surroundings, rolling bearings commonly operate under variable working conditions at any time. Therefore, there is a multi-source domain adaptation problem that involves multiple source domains and a target domain. In this circumstance, identifying faults directly in a multi-source domain through a model built in a single source domain will also lead to limited model generalization ability, i.e., due to the incompleteness of the training sample size caused by the singularity of the domain quantity limited access to fault knowledge in a single source domain, the established model may be prone to over-fitting, thus whose generalization ability has been decreased under complex and variable working conditions to a certain extent. Hence, this paper has proposed a Multi-source Contrastive Cluster Center (MS3C) Method for addressing the aforementioned issues. Experimental findings on two datasets have suggested that MS3C has not only considered the domain shifts of the same classes between different source domains and the target domain but also adaptively aligned the feature distributions of the same classses in different source domains, therefore, MS3C has a higher identification rate, a better clustering and classification performance and a superior convergence.},
  archive      = {J_EAAI},
  author       = {Pengfei Chen and Lizhen Wu and Rongzhen Zhao and Kongyuan Wei and Yuqiao Zheng and Linfeng Deng and Yongfei Zhang and Mingkuan Shi and Zhuo Chen},
  doi          = {10.1016/j.engappai.2025.112056},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112056},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-source contrastive cluster center method for cross-domain bearing fault identification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced encoder–decoder network for temporomandibular joint segmentation in magnetic resonance images. <em>EAAI</em>, <em>161</em>, 112054. (<a href='https://doi.org/10.1016/j.engappai.2025.112054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of the condyle, articular disc, and articular eminence from magnetic resonance imaging (MRI) is essential for the diagnosis and treatment planning of temporomandibular joint (TMJ) disorders. However, current deep learning methods for TMJ segmentation face significant challenges: (1) anatomical structures of the TMJ exhibit complex inter-patient variability; (2) structural boundaries are often ambiguous; and (3) large inter-slice spacing in MRI makes it difficult to fully utilize spatial context, limiting the effectiveness of both three-dimensional and two-dimensional approaches. To address these challenges, we propose an edge-enhanced TransUNet-based encoder–decoder framework that effectively integrates local edge features and global contextual information to obtain accurate and robust TMJ segmentation. Specifically, a cross-slice attention transformer (CAT) is introduced to capture inter-slice dependencies, addressing the challenge of large slice spacing and enhancing the utilization of contextual information across slices. Moreover, a feature enhancement module (FEM) is designed to explicitly fuse edge information, facilitating accurate localization where boundaries are blurred or indistinct. In addition, an attention gate (AG) mechanism adaptively highlights salient anatomical structures and suppresses irrelevant background, improving the model’s overall focus and resistance to noise. Evaluated on the private TMJ MRI dataset, our method achieves Dice similarity coefficients (DSC) of 0.922, 0.834, and 0.837 for the condyle, articular disc, and articular eminence, respectively, outperforming baseline and comparison methods. Further validation on a public knee MRI dataset demonstrates the good generalizability of the proposed method. These results demonstrate robust and precise TMJ segmentation, supporting reliable automated analysis in clinical settings.},
  archive      = {J_EAAI},
  author       = {Yilin Hu and Yunan Zhang and Wei Tang and Jixiang Guo},
  doi          = {10.1016/j.engappai.2025.112054},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112054},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An enhanced encoder–decoder network for temporomandibular joint segmentation in magnetic resonance images},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way decision method integrating probabilistic linguistic term sets and prospect theory in large-scale scenarios. <em>EAAI</em>, <em>161</em>, 112053. (<a href='https://doi.org/10.1016/j.engappai.2025.112053'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probability linguistic term sets (PLTSs), owing to their ability to effectively represent the uncertainty and complexity of decision information, have been widely adopted in large-scale multiattribute decision-making (MADM) scenarios. However, existing decision-making methods in the PLTS environment typically suffer from information loss in similarity computation, subjectivity in weight determination, and inadequate consideration of decision-makers’ behavioral psychology, which limits their applicability in real-world complex situations. To address these issues, this paper proposes an innovative hybrid three-way decision (TWD) method that integrates prospect theory with multiobjective optimization on the basis of the ratio analysis (MOORA) approach. Compared with existing studies, the main contributions of this paper include (1) an objective weight determination mechanism based on the information entropy of PLTSs, which improves the scientific validity and computational efficiency of weight allocation compared with subjective or complex traditional methods (2) a novel direct similarity degree based on the probability linguistic Jensen–Shannon (PLJS) divergence, which effectively overcomes the information loss caused by indirect distance measures and achieves accurate similarity characterization between PLTSs (3) a new conditional probability determination strategy utilizing θ -level similarity classes that enhances the dynamic adaptability and accuracy of conditional probability estimation and (4) the integration of prospect theory and the MOORA method within the TWD framework, enabling hierarchical classification of alternatives while fully reflecting decision-makers’ psychological and behavioral characteristics, thereby facilitating the classification and ranking of alternatives. Furthermore, through comparative analysis with large-scale real-world air quality assessment data and mainstream PLTS-based decision-making methods, the effectiveness and rationality of the proposed method are comprehensively verified, demonstrating its superiority, robustness, and practical application value.},
  archive      = {J_EAAI},
  author       = {Zhaxi Pahua and Haidong Zhang and Yizhu Cairang and Yanping He},
  doi          = {10.1016/j.engappai.2025.112053},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112053},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-way decision method integrating probabilistic linguistic term sets and prospect theory in large-scale scenarios},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive feature-level fusion of manifold and deep learning for robust multi-view face recognition. <em>EAAI</em>, <em>161</em>, 112052. (<a href='https://doi.org/10.1016/j.engappai.2025.112052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust face recognition across varying poses, lighting conditions, and viewpoints remains a significant challenge in engineering applications such as surveillance, authentication, and human–computer interaction. This paper presents Dynamic Manifold–Deep Learning Fusion (DM-DLF), an artificial intelligence (AI)-based framework that integrates manifold learning with deep neural networks using an adaptive feature-level weighting strategy. By combining global semantic features and local geometric structures, the proposed AI model enhances identity recognition under real-world multi-view scenarios. Experimental results show that DM-DLF surpasses recent transformer-based and graph-based models, achieving up to 94.00 % classification accuracy. The method also reduces prediction error and improves training efficiency. These findings confirm DM-DLF as a powerful AI solution for multi-view face recognition in engineering systems where labeled data is limited and view diversity is high.},
  archive      = {J_EAAI},
  author       = {Faraein Aeini},
  doi          = {10.1016/j.engappai.2025.112052},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112052},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive feature-level fusion of manifold and deep learning for robust multi-view face recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing long-term load forecasting with convolutional informer-based hybrid model. <em>EAAI</em>, <em>161</em>, 112051. (<a href='https://doi.org/10.1016/j.engappai.2025.112051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term load forecasting (LTLF) is essential for energy management but challenged by the complexity of non-stationary time series. The Informer model struggles to capture localized peak–valley patterns, while Variational Mode Decomposition (VMD) faces issues with feature complexity. This study proposes a hybrid framework integrating VMD, Informer, and a Convolutional Long Short-Term Memory (CNN-LSTM) module for accurate LTLF. VMD decomposes non-stationary load data into multi-scale intrinsic mode functions, refined through spectral and autocorrelation analyses to ensure robust feature extraction. The Informer employs sparse self-attention for efficient long-sequence modeling, with CNN-LSTM enhancing the decoder to capture localized temporal dynamics. Experiments on non-stationary load time series across multiple prediction horizons demonstrate that the proposed framework significantly improves forecasting accuracy and robustness compared to baseline models, including Informer and its derivatives. By excelling in complex load pattern prediction, the framework supports efficient grid scheduling and resource optimization in energy systems.},
  archive      = {J_EAAI},
  author       = {Bin Sun and Xudong Chen and Tao Shen and Liyao Ma},
  doi          = {10.1016/j.engappai.2025.112051},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112051},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing long-term load forecasting with convolutional informer-based hybrid model},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault diagnosis of high-voltage three-phase asynchronous motors using residual neural networks and bidirectional gated recurrent units. <em>EAAI</em>, <em>161</em>, 112049. (<a href='https://doi.org/10.1016/j.engappai.2025.112049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-voltage three-phase asynchronous motors are extensively used in industrial production; however, rotor bar breakage faults are characterized by strong concealment and severe consequences, making early and accurate diagnosis difficult with traditional methods. To address this issue, this paper proposes a deep learning model based on a Residual Neural Network (ResNet) and a Bidirectional Gated Recurrent Unit (Bi-GRU) for motor fault diagnosis. The proposed model integrates the spatial feature extraction advantages of ResNet with the temporal modeling capabilities of Bi-GRU, simultaneously capturing spatiotemporal information from voltage and current signals. The model was trained and tested on a large-scale dataset comprising 324,000 data points under nine distinct operating conditions. Experimental results demonstrate that the proposed method achieves over 99.83 % in key metrics such as accuracy, precision, recall, and F1-score, significantly outperforming traditional approaches and other comparative models. Additionally, it maintains stable performance under varying operating conditions, demonstrating strong robustness and generalization capability. Further ablation experiments also validated the effectiveness of each module within the proposed model. This study indicates that the application of deep learning in industrial motor fault diagnosis has promising prospects and practical value.},
  archive      = {J_EAAI},
  author       = {Huihui Yang and Yuxin Wu},
  doi          = {10.1016/j.engappai.2025.112049},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112049},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis of high-voltage three-phase asynchronous motors using residual neural networks and bidirectional gated recurrent units},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot image translation via query compensation and style enhancement. <em>EAAI</em>, <em>161</em>, 112048. (<a href='https://doi.org/10.1016/j.engappai.2025.112048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In zero-shot image translation methods based on diffusion models, two prevalent challenges are the loss of identity information and insufficient stylization. To address these issues, we propose a zero-shot image translation method. Specifically, we use the edit-friendly noise space for image inversion. By this way, the identity of the input image is largely preserved. Additionally, we introduce an identity compensation mechanism by injecting the source query vectors into the denoising process. Furthermore, to tackle the model’s insufficient stylization ability, we propose cross-attention style modulation (CSM) to transfer style information from the reference to the input image. Finally, to further enhance the style effect of the translated image, we design initial latent self-enhancement (ILS), style supplementation (SS), and style alignment (SA) strategies. Our zero-shot image translation method does not require training samples, optimization, or fine-tuning. We achieve this by manipulating the self-attention features of a pre-trained diffusion model in a manner analogous to cross-attention—by replacing the key and value vectors of the input image with those of the reference image during the denoising process. Extensive in-domain and cross-domain translation experiments demonstrate the effectiveness of our method across a wide range of object categories and show strong robustness to variations in object shape, size, posture and instance between the input and reference image. The proposed method achieves competitive performance in identity preservation, as measured by the mean Intersection over Union (mIoU), and attains the best style transfer in terms of Single Image Fréchet Inception Distance (SIFID). In addition, qualitative comparisons demonstrate that our approach significantly outperforms the baselines.},
  archive      = {J_EAAI},
  author       = {Heng Zhang and Yi-Jun Yang and Wei Zeng},
  doi          = {10.1016/j.engappai.2025.112048},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112048},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-shot image translation via query compensation and style enhancement},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Camouflaged object detection with boundary localization in complex backgrounds. <em>EAAI</em>, <em>161</em>, 112047. (<a href='https://doi.org/10.1016/j.engappai.2025.112047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary challenge of Camouflaged Object Detection (COD) lies in the high similarity between the target and the complex background, making it difficult for the human eye to distinguish them. Based on the phenomenon that human attention shifts between the target and the background when observing objects, we propose a network model named MENet. This model adopts a three-stage decoupled architecture of “localization-interaction-fusion.” In the localization stage, we utilize an attention mechanism-based backbone network (Pyramid Vision Transformer V2, abbreviated as PVT-V2) to generate multi-level features, which can initially locate the target area. In the interaction stage, we design a Contour-Aware Edge Module (CAEM) and an Area Decoder (AD) to capture the target edges and background information, respectively, thereby achieving precise localization of the target boundary and reducing interference from background noise. Furthermore, we developed a Boundary Guidance Module (BGM) that effectively injects boundary cues and relevant background information separately into the multi-level features, enhancing the model’s ability to detect target edges in complex backgrounds. In the fusion stage, we design two Feature Fusion Modules (FFM and KFFM) to effectively merge multi-level features with precise boundaries and de-noised features, thereby enhancing the prediction performance of camouflaged objects. Extensive experiments on three challenging benchmark datasets demonstrate that our MENet outperforms many existing state-of-the-art methods. Our method leverages artificial intelligence (AI) techniques to improve the accuracy of camouflaged object and pest detection in complex visual environments. Our code is publicly available at: https://github.com/yang19950966666/MENet .},
  archive      = {J_EAAI},
  author       = {Guangjian Zhang and Zhengming Yang and Yong Wang and Yuliang Chen and Duoqian Miao},
  doi          = {10.1016/j.engappai.2025.112047},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112047},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Camouflaged object detection with boundary localization in complex backgrounds},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A grid-based boundary sharpening clustering algorithm. <em>EAAI</em>, <em>161</em>, 112045. (<a href='https://doi.org/10.1016/j.engappai.2025.112045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the clustering problem for arbitrary shapes, in this paper, we propose a Grid-based Boundary Sharpening clustering algorithm called as “GBSharp”. This method is grounded in morphology and relies on two fundamental morphological operations: dilation and erosion. The main innovations of the proposed algorithm lie in two aspects. Firstly, we further introduce the concepts of inward dilation and bridge erosion based on the basic morphological operations to reduce the impact of the chain effect. Secondly, a unique indexing structure is designed specifically for non-empty cells in high dimensional space. In addition, to tackle the complex conditional judgments encountered in high-dimensional scenarios, we further utilize the inversion method for bridge-erosion operation. Experiments conducted on synthetic datasets and real-world datasets further validate the effectiveness and efficiency of the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Lin Ma and Qijing Yan and Mengxia Lv and Tiefeng Ma and Mingchang Cheng},
  doi          = {10.1016/j.engappai.2025.112045},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112045},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A grid-based boundary sharpening clustering algorithm},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advances in physics-informed neural networks for solving complex partial differential equations and their engineering applications: A systematic review. <em>EAAI</em>, <em>161</em>, 112044. (<a href='https://doi.org/10.1016/j.engappai.2025.112044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most physical and engineering problems can be described by partial differential equations (PDEs), which are typically solved using numerical methods such as the finite difference method and the finite element method. However, conventional numerical discretization approaches face significant challenges in terms of computational efficiency and convergence speed when dealing with complex nonlinear PDEs, such as high-dimensional nonlinear PDEs, stiff PDEs, PDEs with complex boundary conditions or irregular geometries, and multi-scale PDEs. Recently, physics-informed neural networks (PINNs) have emerged as a transformative methodology for solving complex PDEs by integrating physical laws intrinsically into deep learning architectures. While PINNs effectively overcome mesh dependency and dimensionality constraints inherent in traditional numerical methods, they still encounter persistent challenges related to training convergence and generalization robustness. This paper aims to present a comprehensive review of the state-of-the-art developments in PINNs for solving complex PDE problems. The core ideas, network architectures, and generic implementation frameworks, along with associated open-source Python libraries, are first introduced in detail. Furthermore, a systematic taxonomy of optimization techniques is provided, covering hyperparameter selection, adaptive sampling strategies, physics-constrained loss formulations, hybrid differentiation approaches, and architectural innovations. Subsequently, various coping strategies and research advancements of PINNs in addressing complex nonlinear PDE problems are thoroughly discussed. Real-world engineering applications are then reviewed across multiple domains, including cosmology and quantum mechanics, materials science and manufacturing, fluid mechanics, energy systems, biological and environmental sciences, and power and information technologies. Finally, this paper discusses the current challenges and limitations of PINNs in solving complex PDEs and outlines potential directions for future research. By addressing the current limitations and pursuing targeted improvements in architectures, training, interpretability and generalization, PINNs can become a powerful tool in engineering and scientific applications.},
  archive      = {J_EAAI},
  author       = {Jiangtao Guo and Hao Zhu and Yujie Yang and Chenrui Guo},
  doi          = {10.1016/j.engappai.2025.112044},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112044},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Advances in physics-informed neural networks for solving complex partial differential equations and their engineering applications: A systematic review},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DPMF-net: A dual-path perceptive multi-stage fusion network for skin lesion segmentation. <em>EAAI</em>, <em>161</em>, 112043. (<a href='https://doi.org/10.1016/j.engappai.2025.112043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of skin lesions in dermoscopic images is crucial for skin cancer detection and treatment. Despite progress in deep learning-based methods, challenges remain due to diverse skin lesion shapes, colors, and blurred boundaries. We propose a novel Dual-path Perceptive Multi-stage Fusion Network (DPMF-Net) for skin lesion segmentation. DPMF-Net integrates multiple feature refinement modules. It aims to gradually optimize lesion representations by leveraging the dual-path framework to perceive high-level contextual information. The Spatial Frequency Dual-path Cascaded Perception Module (SFDCP) synergizes spatial and frequency domains to model long-range dependencies and suppress noise, enhancing perception of low-contrast lesions. Subsequent to the SFDCP, the Spatial Channel Dual-path Parallel Perception Module (SCDPP) employs entropy-driven attention and multi-granularity convolutions in skip connections to dynamically select informative channels and extract lesion details across spatial scales. To verify the efficacy of our proposed DPMF-Net, extensive experimental assessments are carried out across four challenging datasets. The outcomes of these quantitative and qualitative experiments confirm that our approach significantly outperforms current state-of-the-art methods in terms of all evaluation metrics.},
  archive      = {J_EAAI},
  author       = {Yuling Huang and Yaoyao Ma and Jing Wang and Chao Xu and Zhiwei Fan and Di Wu},
  doi          = {10.1016/j.engappai.2025.112043},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112043},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DPMF-net: A dual-path perceptive multi-stage fusion network for skin lesion segmentation},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradient surgery: A necessity for robust test-time adaptation for detecting casting defects. <em>EAAI</em>, <em>161</em>, 112039. (<a href='https://doi.org/10.1016/j.engappai.2025.112039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Casting defects pose a significant challenge in the manufacturing industry, leading to material waste, production inefficiencies, and compromised product quality. While deep learning models have shown promise in automating defect detection, their effectiveness is often constrained by domain shifts and variability in real-world data distributions. In this work, we propose Bayesian Test-Time Adaptation (BTTA), a novel framework designed to enhance the robustness and adaptability of machine learning models in such dynamic environments. Unlike traditional Test-Time Adaptation (TTA) methods, our approach employs gradient-guided diversification with Stein Variational Gradient Descent (SVGD) to explore diverse optimization paths. Experimental results on benchmark datasets, including CIFAR-10-C , Casting Defects , and GDXray , demonstrate significant performance improvements across key metrics. Notably, the framework achieves an average accuracy improvement of 2-3% under severe corruption levels and excels in cross-domain generalization, highlighting its ability to handle diverse and unseen defect categories. This dynamic adaptability not only addresses the limitations of static models but also offers a practical and cost-effective solution for real-time defect detection in industrial settings. Our study underscores the potential of BTTA to transform quality assurance processes, ensuring reliable performance across varying operational conditions without the need for extensive retraining or large annotated datasets. The codebase for BTTA is available on: https://github.com/afsharshamsi/GradSurgery .},
  archive      = {J_EAAI},
  author       = {Afshar Shamsi and Rejisa Becirovic and Hamid Alinejad-Rokny and Arash Mohammadi and Ahmadreza Argha},
  doi          = {10.1016/j.engappai.2025.112039},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112039},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Gradient surgery: A necessity for robust test-time adaptation for detecting casting defects},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing real-time detection transformer for small floating targets. <em>EAAI</em>, <em>161</em>, 112038. (<a href='https://doi.org/10.1016/j.engappai.2025.112038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing the challenge of detecting small floating target in complex water environments, where it is difficult to balance real-time performance and end-to-end capabilities, this study introduces a specialized model called the Enhancing Real-Time Detection Transformer (ERT-DETR). This model integrates a Dynamic Feature Pyramid Network (DFPNet) with a Micro-Attention Module (MAM) to achieve refined feature extraction and enhanced object recognition mechanisms. Additionally, it incorporates an Inner Intersection over Union (Inner-IoU) auxiliary bounding box loss function, which accelerates model convergence and improves bounding box accuracy. Experiments conducted on the Floating Object in Water Image Dataset (FloW-Img) demonstrate that the ERT-DETR model achieves a 92.6% Average Precision (AP) and 118.84 Frames Per Second (FPS), outperforming the baseline Real-Time Detection Transformer (RT-DETR) by 4.3% and 19.8%, respectively. The ERT-DETR model’s precision and real-time performance in dynamic water surface environments surpass those of the most advanced You Only Look Once (YOLO) and Detection Transformer (DETR) series detectors. This model is significant for enhancing small floating target detection capabilities in complex water environments and can be extended to applications in marine management, environmental monitoring, and vessel tracking.},
  archive      = {J_EAAI},
  author       = {Guobing Xie and Xinran Wu and Jiefeng Shi and Yixin Su and Binghua Shi},
  doi          = {10.1016/j.engappai.2025.112038},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112038},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing real-time detection transformer for small floating targets},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-contact weight intelligent estimation based on yak skeleton localization. <em>EAAI</em>, <em>161</em>, 112036. (<a href='https://doi.org/10.1016/j.engappai.2025.112036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weight estimation is a vital method for monitoring the growth and health of yaks, however, traditional techniques-such as relying on herders’ experience or using weighbridge-are labor-intensive, time-consuming and pose safety risks. Currently, many studies have shown that yak body size can be an effective indicator of weight. With the advancement of computer vision, non-contact weight estimation has become increasingly feasible for livestock. Yet, studies focusing on yak weight estimation, particularly in high-altitude plateau regions, remain limited. Herein, we propose a novel weight estimation approach based on deep learning and binocular vision technology to address this gap. The method involves four main steps: (1) yak image acquisition, (2) skeletal key point localization, (3) body size calculation (4) weight estimation using Gaussian process regression. To enhance practicality and mobility, we also developed two edge-intelligent devices: an intelligent inspection vehicle and a handheld detection unit, enabling convenient and non-invasive weight estimation. Our models are trained and tested on a yak dataset collected by our team on the Tibetan Plateau. Experimental results demonstrate the effectiveness of our approach, achieving an Mean Absolute Percentage Error (MAPE) of 0.12 percent, a Mean Absolute Error (MAE) of 25.4 kilograms (kg) and a Coefficient of determination ( R 2 ) value of 0.72. It not only provides a new technical solution for the yak industry but also provides innovative insights for advancing intelligent animal husbandry. The code and data can be accessed at https://github.com/FeiWang-swun/YakWeight .},
  archive      = {J_EAAI},
  author       = {Fei Wang and Xinghua Zou and Zhijiang Chen and Qi Tang and Tianshuo Li and Shuiying Wang and Lijun Yang and Dongming Tang},
  doi          = {10.1016/j.engappai.2025.112036},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112036},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Non-contact weight intelligent estimation based on yak skeleton localization},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of the performances of artificial intelligence bots using continuous intuitionistic fuzzy evaluation based on distance from average solution method. <em>EAAI</em>, <em>161</em>, 112033. (<a href='https://doi.org/10.1016/j.engappai.2025.112033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of artificial intelligence (AI) has introduced novel opportunities and challenges in various fields. In this study, we present a pioneering approach known as Continuous Intuitionistic Fuzzy (CINFU) Evaluation based on Distance from Average Solution (EDAS), an innovative extension of the EDAS method tailored to Continuous Intuitionistic Fuzzy Sets. This methodology is designed to compare the performance of AI tools. The capabilities of AI bots have been examined through their success rates in various tasks and uncertainty levels in decision-making processes. The study aims to evaluate the effectiveness of different models in decision-making processes by analyzing the performances of AI bots such as Chat Generative Pre-trained Transformer (ChatGPT), Bard, and Claude based on both objective measurements and fuzzy evaluation criteria. The comparison focuses on key performance criteria such as Bots Triggered, User Engagement, Message Click-Through Rate, Chat Handoff, User Retention, Bounce Rate & Dwell Time, Leads Captured, and Customer Satisfaction Score. Ultimately, the validity and robustness of the approach have been tested with sensitivity analysis.},
  archive      = {J_EAAI},
  author       = {Nurşah Alkan and Umut Aydın and Akın Menekşe and Cengiz Kahraman},
  doi          = {10.1016/j.engappai.2025.112033},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112033},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comparison of the performances of artificial intelligence bots using continuous intuitionistic fuzzy evaluation based on distance from average solution method},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A global linear attention incorporated video transformer for robust sintering condition recognition. <em>EAAI</em>, <em>161</em>, 112032. (<a href='https://doi.org/10.1016/j.engappai.2025.112032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust and accurate sintering condition recognition is a fundamental yet critical issue in the design of image-based intelligent combustion control systems. However, owing to the weak texture and fast changing characteristics of flame videos, capturing the condition indicator using existing gradient-based methods is challenging. To address this issue, we propose a global linear attention incorporated video transformer model for sintering condition recognition. First, to reduce the prediction error and uncertainty, the spatial-temporal features are extracted to describe the dynamic characteristics of the flame video streams based on the video shifted window (Swin) Transformer architecture. Next, to address the problem that the local attention strategy used in the Video Swin Transformer is insufficient for global flame feature extraction, we propose a Video Linear Attention block that obtains the global attention as a supplement. Extensive experiments conducted on a real-world rotary kiln sintering dataset demonstrate the effectiveness of our approach, achieving an overall accuracy of 97.76% and an F1-score of 95.30%. Compared to the Video Swin Transformer model, these results represent improvements of 2.00% in accuracy and 4.96% in F1-score, respectively. This research is particularly significant in the context of real-time identification of combustion process conditions, optimization of control parameters, and realization of more stable and efficient combustion process control.},
  archive      = {J_EAAI},
  author       = {Leyuan Wu and Junlin Wu and Dingxiang Wang and Qiang Fu},
  doi          = {10.1016/j.engappai.2025.112032},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112032},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A global linear attention incorporated video transformer for robust sintering condition recognition},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Markerless gait analysis for parkinson’s disease diagnosis: A study on machine learning integration and features explainability. <em>EAAI</em>, <em>161</em>, 112031. (<a href='https://doi.org/10.1016/j.engappai.2025.112031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease is a common neurodegenerative disorder with progressive loss of dopaminergic and other subcortical neurons that significantly impair motor functions, necessitating accurate diagnostic and monitoring techniques. Researchers commonly use gait analysis to estimate gait parameters to classify diseases and their progression. Traditional gait analysis, while effective, typically requires expensive, specialized equipment and lacks the flexibility for widespread clinical use. Furthermore, many existing studies on markeless approaches do not use public datasets, giving comparable and benchmarking results. Additionally, these methods often do not incorporate explainability, leaving a gap in understanding which specific gait features most significantly impact diagnostic outcomes. To address this issue, we propose a novel system to support diagnosis and analysis of the gait of Parkinson’s disease. The two-step approach involves pose extraction with vision-based pose estimation and classification employing machine learning techniques based on the subject’s temporal, kinematic, and symmetric characteristics. The explainability technique used in this study shows the important role of features such as the knee angle, cadence, and double support duration in influencing diagnostic outcomes. The system shows promising results for non-invasive, low-cost Parkinson’s disease diagnostics, reaching an accuracy of 0.95, a sensitivity of 0.90, a specificity of 0.97, a Matthew’s Correlation Coefficient (MCC) of 0.88, an Area Under the Curve (AUC) of 0.99.},
  archive      = {J_EAAI},
  author       = {Cesare Davide Pace and Alessandro Marco De Nunzio and Claudio De Stefano and Francesco Fontanella and Mario Molinara},
  doi          = {10.1016/j.engappai.2025.112031},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112031},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Markerless gait analysis for parkinson’s disease diagnosis: A study on machine learning integration and features explainability},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Offshore wind power multi-step forecasting based on multi-scale attention mechanism fusion network. <em>EAAI</em>, <em>161</em>, 112026. (<a href='https://doi.org/10.1016/j.engappai.2025.112026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonlinear, unstable, and multi-scale characteristics of offshore wind power present significant challenges for grid scheduling and power forecasting. To address this issue, this paper proposes a multi-step forecasting hybrid model for offshore wind power based on the sequence-to-sequence (Seq2Seq) architecture, which is named Multi-scale, Denoising, Attention Fusion Network (mDAFNet). The model integrates a multi-level learnable wavelet decomposition network, frequency-domain interpolation denoising technique, and dual-attention mechanism, and improves forecasting performance through joint high- and low-frequency dual-branch predictions. The process begins by improving data quality through outlier cleaning and feature selection based on grey correlation analysis and mutual information. Subsequently, a multi-level learnable wavelet decomposition network is introduced to extract high- and low-frequency subsequences from the frequency domain and optimize parameters dynamically through backpropagation. To address the noise impact on high-frequency subsequences, frequency domain interpolation denoising technique is applied for noise reduction. Then, a sequence-to-sequence model based on the dual-attention mechanism is used to forecast the denoised high-frequency subsequences, while a Long Short-Term Memory (LSTM) neural network predicts the low-frequency subsequences. Finally, the dual-branch forecasting network enables joint modeling of high- and low-frequency subsequences. We conducted experiments on two offshore wind power datasets. The results indicate that, compared to baseline models, the proposed mDAFNet reduces Mean Absolute Error, Root Mean Square Error, and Mean Absolute Percentage Error by an average of 33.94 %, 36.62 %, and 39.84 %, respectively, while significantly improving forecasting accuracy and stability. This study provides a new approach and perspective for offshore wind power forecasting.},
  archive      = {J_EAAI},
  author       = {Yizhuang Xiong and Wenbo Wang},
  doi          = {10.1016/j.engappai.2025.112026},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112026},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Offshore wind power multi-step forecasting based on multi-scale attention mechanism fusion network},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted multi-granularity fuzzy probabilistic rough set based on semi-overlapping function and its application in three-way decision. <em>EAAI</em>, <em>161</em>, 112023. (<a href='https://doi.org/10.1016/j.engappai.2025.112023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel model of fuzzy probabilistic rough sets and develops an interesting three-way decision (TWD) applicable to multi-attribute group decision-making and classification problems. First, we simultaneously consider the cut-levels of fuzzy relations and decision-making fuzzy sets, investigating a new fuzzy probabilistic rough set model. This model employs semi-overlapping functions as the range of the membership functions of the fuzzy set, enhancing interpretability since the semi-overlapping functions can act as the truth tables of fuzzy logic. Second, by assigning different weights to various granular fuzzy relations, we propose a weighted multi-granularity fuzzy probabilistic rough set model. It is proven that the proposed (weighted multi-granularity) fuzzy probabilistic rough set model encompasses many existing models as special cases, thereby providing a very broad framework for rough set theory. Third, by integrating the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) method with Bayesian theory, we develop a method for computing the threshold of fuzzy probabilistic rough sets and construct a new TWD. Sorting and classification rules and algorithms for TWD are provided. Finally, we perform parameter analysis and comparative experiments on nine public datasets to verify the effectiveness and rationality of our TWD. The experimental results demonstrate that our approach exhibits superior fault tolerance and noise reduction capabilities. Specifically, the introduction of semi-overlapping functions enhances our TWD model’s performance, with A c c u r a c y improving the most on the Heart dataset, reaching 9.37%, and the F 1 score increasing the most on the Heart and Plrx datasets, reaching 5.3%. In summary, this paper offers a novel solution for applying artificial intelligence in decision-making scenarios.},
  archive      = {J_EAAI},
  author       = {Xinru Li and Lingqiang Li and Chengzhao Jia},
  doi          = {10.1016/j.engappai.2025.112023},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112023},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Weighted multi-granularity fuzzy probabilistic rough set based on semi-overlapping function and its application in three-way decision},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-driven double deep Q-network with iterated greedy for intelligent scheduling optimization in reentrant hybrid flow shops. <em>EAAI</em>, <em>161</em>, 112012. (<a href='https://doi.org/10.1016/j.engappai.2025.112012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reentrant hybrid flow shop scheduling problem (RHFSP) poses significant challenges due to its complex structure and limited research on model accuracy, solution space exploration, and adaptive strategy selection. To address these gaps, this paper proposes a novel feature-driven double deep Q-network with iterated greedy (FD3QNIG) algorithm. First, a five-dimensional mixed-integer linear programming (MILP) model is developed to significantly improve modeling accuracy. Second, a feature-driven initialization strategy (FDNEH) enhances the quality of initial solutions, while an adaptive historical information-driven destruction and reconstruction strategy (AHDDR) effectively balances exploration and exploitation during the search process. Third, multi-scale local search strategies are employed, including the first application of comprehensive exploration-driven mandatory operations local search (CED_MOLS) to RHFSP, substantially deepening the search capability. Fourth, an adaptive strategy selection mechanism based on double deep Q-Network (DDQN_ASS) dynamically guides the algorithm toward more efficient decision-making. Extensive experiments on 285 benchmark instances demonstrate that FD3QNIG achieves a 53 %–94 % improvement in average relative percentage increase ( A R P I ) over state-of-the-art methods, confirming its effectiveness and robustness.},
  archive      = {J_EAAI},
  author       = {Chexiang Li and Yuyan Han and Yuting Wang and Yiping Liu and Biao Zhang and Leilei Meng},
  doi          = {10.1016/j.engappai.2025.112012},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112012},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-driven double deep Q-network with iterated greedy for intelligent scheduling optimization in reentrant hybrid flow shops},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semi-supervised framework for generating multi-dimensional taxonomies from asset maintenance documents. <em>EAAI</em>, <em>161</em>, 112010. (<a href='https://doi.org/10.1016/j.engappai.2025.112010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operation and maintenance of buildings generate large volumes of unstructured textual data, such as inspection reports and service requests. These records contain valuable insights that can support fault detection, cost tracking, and resource planning. However, existing classification approaches often rely on static, expert-defined labels that fail to reflect the complexity of real-world maintenance operations. This paper introduces a hybrid framework that combines sentence embedding, clustering, topic modeling, and network modularization to uncover recurring patterns in maintenance text. The extracted patterns are then reviewed and refined by facility management experts to develop a multi-dimensional taxonomy model tailored to operational needs. The methodology is applied to a case study involving over 30,000 work orders. The results demonstrate how the proposed system captures fine-grained details such as system type, failure mode, and required trade expertise. A proof-of-concept software tool, developed in collaboration with facility managers, showcases the practical value of the taxonomy in enabling data-driven decision-making, such as identifying cost drivers and recurring issues. Additionally, the resulting taxonomy models serve as effective prompts for zero-shot text classification, enabling large language models to classify new maintenance records without requiring retraining or labeled data. This approach provides a scalable and adaptable foundation for text classification systems in asset management.},
  archive      = {J_EAAI},
  author       = {Soroush Sobhkhiz and Tamer El-Diraby},
  doi          = {10.1016/j.engappai.2025.112010},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112010},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A semi-supervised framework for generating multi-dimensional taxonomies from asset maintenance documents},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive review of facial beauty prediction using deep learning techniques. <em>EAAI</em>, <em>161</em>, 112009. (<a href='https://doi.org/10.1016/j.engappai.2025.112009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial beauty prediction (FBP) is an emerging area of artificial intelligence (AI) that focuses on the development of models that analyze facial features to assess beauty, based on human perception. This task is particularly challenging due to the subjective nature of beauty and limited resources. Deep learning methods have proven their exceptional ability to capture complex features and are therefore well suited for FBP tasks. This paper reviews recent advances in FBP, focusing on deep learning techniques and benchmark datasets. A proposed taxonomy organizes the main methods according to their design and applications, and comparative analyzes highlight trends and the performance of different models. Finally, the study outlines future research directions to drive progress in this evolving field.},
  archive      = {J_EAAI},
  author       = {Djamel Eddine Boukhari and Fadi Dornaika and Ali Chemsa and Abdelmalik Taleb-Ahmed},
  doi          = {10.1016/j.engappai.2025.112009},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112009},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comprehensive review of facial beauty prediction using deep learning techniques},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum relevant minimum redundant multi-label feature selection using ant colony optimization. <em>EAAI</em>, <em>161</em>, 112007. (<a href='https://doi.org/10.1016/j.engappai.2025.112007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning tasks involve instances that may belong to multiple categories simultaneously, making feature selection particularly challenging in high-dimensional feature spaces. Existing multi-label feature selection methods often suffer from limitations such as high computational complexity, inadequate handling of feature redundancy, and insufficient modelling of label dependencies. To overcome these challenges, we propose a novel framework called Maximum Relevant Minimum Redundant Multi-Label Feature Selection (MR2MLFS), which integrates a two-layer graph representation with a modified Ant Colony Optimization (ACO) strategy. The first graph layer clusters correlated features using Louvain community detection, while the second constructs a meta-graph to model inter-cluster relationships. ACO then explores this structure, favouring the selection of highly relevant and non-redundant features. To reduce computational overhead, we introduce an information-theoretic metric that estimates both feature-label relevance and feature-feature redundancy, eliminating the need for repeated classifier training during the search. We evaluated the proposed method on ten benchmark multi-label datasets using several multi-label classifiers. Experimental results show that the proposed method outperforms six state-of-the-art methods across multiple evaluation metrics, achieving an average relative improvement of 5–12 % while reducing feature dimensionality by up to 80 %. These results confirm the method's robustness, efficiency, and effectiveness in multi-label feature selection.},
  archive      = {J_EAAI},
  author       = {Mohammad Hatami and Parham Moradi and Sadegh Sulaimany and Mahdi Jalili},
  doi          = {10.1016/j.engappai.2025.112007},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112007},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Maximum relevant minimum redundant multi-label feature selection using ant colony optimization},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage model for unified sentence- and document-level biomedical event extraction. <em>EAAI</em>, <em>161</em>, 112001. (<a href='https://doi.org/10.1016/j.engappai.2025.112001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical event extraction, a cornerstone of information extraction, has increasingly attracted attention within the biomedical research community. Moreover, it is a highly complex task, which not only deals with many sub-tasks but also involves nested events. Currently, the research on biomedical event extraction, whether pipelined model or joint method, needs to be processed for each sub-task. The process of processing each sub-task one by one lead to the degradation of event extraction performance. In addition, most studies focus on extracting sentence-level events and ignore cross-sentence event information. To solve these problems, we simplify the process of event extraction, reduce the processing steps, and combine the two sub-tasks of relation extraction and argument combination as one sub-task. In addition, we consider document-level event extraction, which not only extracts cross-sentence events but also considers broader context information. Experimental results indicate that our novel approach outperforms prior studies. Additionally, the document-level event extraction model attains the top performance on the BioNLP’11 test data and achieves near-leading performance on the BioNLP’13 test data.},
  archive      = {J_EAAI},
  author       = {Fangfang Su and Yue Zhang and Pengfei Jiao and Zhidong Zhao and Bobo Li and Fei Li and Donghong Ji},
  doi          = {10.1016/j.engappai.2025.112001},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {112001},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two-stage model for unified sentence- and document-level biomedical event extraction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A position-aware sets based weakly supervised framework for whole-slide subtype classification. <em>EAAI</em>, <em>161</em>, 111998. (<a href='https://doi.org/10.1016/j.engappai.2025.111998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying cancer subtypes is essential for personalized treatment and accurate prognosis due to the varying sensitivities of subtypes to therapies. However, in cancer subtype classification tasks, normal slides are usually scarce or absent as negative samples, while subtype whole-slide images (WSIs) often contain extensive unannotated normal tissue regions. These regions introduce significant noise during feature fusion and subtype classification, leading to degraded performance of existing weakly supervised methods In this paper, we propose the Position-aware Sets based Weakly Supervised learning framework (PSWS), designed for cancer subtype classification using WSIs, with a two-stage structure to enhance model efficiency. Specifically, it first presents a novel patch organization approach, distinct from the bag concept of traditional Multiple Instance Learning (MIL), called position-aware sets, as basic units for learning. Then, PSWS automatically selects subtype-specific features based on enhanced histological features and mutual-patch relations, mitigating the negative impact of unannotated negative regions. In the experiments, the superior performance of PSWS over representative MILs is validated through subtype classification tasks on both public datasets and our internally constructed dataset. Furthermore, class probabilities of position-aware sets and attention region visualizations demonstrate its post-hoc interpretability, assisting pathologists in locating suspicious areas.},
  archive      = {J_EAAI},
  author       = {Jiuman Song and Bo Yu and Xiaomin Liu and Lele Cong and Zilong Zhou and Xianling Cong and Hongyan Sun and Shuchao Pang and Hechang Chen},
  doi          = {10.1016/j.engappai.2025.111998},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111998},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A position-aware sets based weakly supervised framework for whole-slide subtype classification},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Action understanding in low-light and pitch-dark conditions: A comprehensive survey. <em>EAAI</em>, <em>161</em>, 111996. (<a href='https://doi.org/10.1016/j.engappai.2025.111996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action understanding in low-light and dark environments (AULLD) is a critical and technically demanding challenge at the intersection of computer vision and engineering applications. This task focuses on interpreting human actions using motion cues under visually constrained conditions, such as poor illumination or complete darkness. Since 2010, machine learning and, more notably, deep learning have significantly advanced AULLD by enabling systems to extract and learn discriminative features from complex, low-visibility data. These techniques have resulted in state-of-the-art solutions, with recent methods achieving accuracies on various benchmark datasets of up to 97.10%, and a 73.20% top-1 accuracy on an infrared dataset. These solutions have had applications across domains such as healthcare monitoring, surveillance and security, human–computer interaction, and social computing. In this survey, we provide the first comprehensive overview of the progress of the research and topical developments in AULLD. We cover a broad range of elements, including the datasets, evaluation protocols, methods, challenges, and emerging research directions. To organize and evaluate the literature in a structured, integrated way, we introduce a novel taxonomic framework, grounded in four core dimensions: body representation, temporal representation, feature representation, and neural architectures. Employing this taxonomy, we perform an analysis of AULLD approaches, exploring their methodological foundations, system design considerations, performance outcomes, and inherent trade-offs. The survey concludes with an in-depth discussion of the existing challenges confronting AULLD, highlighting several promising research directions that hold potential for advancing the field and setting the stage for future innovations and improvements in AULLD.},
  archive      = {J_EAAI},
  author       = {Muhammad Munsif and Samee Ullah Khan and Noman Khan and Altaf Hussain and Sung Wook Baik},
  doi          = {10.1016/j.engappai.2025.111996},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111996},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Action understanding in low-light and pitch-dark conditions: A comprehensive survey},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer learning framework integrating attention mechanism and domain adaptation for low earth orbit satellite network traffic prediction. <em>EAAI</em>, <em>161</em>, 111992. (<a href='https://doi.org/10.1016/j.engappai.2025.111992'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction is a crucial prerequisite for planning and even network security in Low Earth Orbit (LEO) satellite networks (LSNs). This paper designed a transfer learning framework for LSN traffic prediction that leverages attention mechanism and domain adaptation. Firstly, by integrating five-dimensional data including global population distribution, local time coefficient, the Internet penetration rate of the country, daily data volume of a single Internet user, and global aeronautical traffic demand, a traffic model that could characterize the traffic situation of the area covered by LEO satellite within a specific time range was constructed. Considering the problem of insufficient online traffic data, knowledge was transferred from terrestrial network traffic (source domain) to satellite network traffic (target domain) by incorporating the Domain-Adversarial Neural Network (DANN) method to tackle the data distribution discrepancies between the source and target domains. Finally, by combining DANN with the attention mechanism, the domain-invariant features of the source domain and the target domain were extracted to predict satellite network traffic accurately. Experimental results show that compared to baseline models, the error of the proposed framework in terms of root mean square error measurement is reduced by 9.57% to 33.47% and 18.85% to 38.99% in the two simulated LSN traffic scenarios. Moreover, this framework has low computational complexity among other transfer learning models, which can lay a foundation for subsequent satellite traffic planning and network security.},
  archive      = {J_EAAI},
  author       = {Yan Zhang and Yong Wang and Qingsong Zhao and Yadi Zhai and Zhi Lin and Luda Zhao and Yihua Hu},
  doi          = {10.1016/j.engappai.2025.111992},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111992},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transfer learning framework integrating attention mechanism and domain adaptation for low earth orbit satellite network traffic prediction},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skeleton-based multi-person action recognition towards real-world violence detection. <em>EAAI</em>, <em>161</em>, 111987. (<a href='https://doi.org/10.1016/j.engappai.2025.111987'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action recognition is crucial in intelligent systems like robotics, healthcare, and surveillance, gaining significant attention with the rise of AI in computer vision. This work presents the Multi-Skeleton Action Recognizer (MSAR), a comprehensive multi-stage process specifically designed to enhance the recognition and classification of violent activities involving multiple individuals. The approach aims to improve accuracy and robustness in real violence detection and classification leveraging skeletal data. The proposed MSAR pipeline consists of five main stages: Human detection, Human tracking, Skeleton extraction, Data pre-processing and Padding, and Action classification. Experimental results demonstrate the effectiveness of our multi-stage process, showing significant improvements in multi-person action recognition in violence detection. In the human detection stage, our integration of multiple detection models provides a comprehensive visual comparison of model performance, offering empirical insights into accuracy, computational efficiency, and processing speed. The fusion Bidirectional Long Short-Term Memory - Gated Recurrent Unit (BiLSTM-GRU) architecture designed for action classification integrating Deep Bidirectional Long Short-Term Memory (BiLSTM) and Gated Recurrent Unit (GRU) components, demonstrated maximum accuracy of 96.46% and an average accuracy of 91.18%. The proposed architecture is explored to potentially enhance the model’s ability to capture temporal dependencies in action sequences. Additionally, our proposed multi-stage pipeline for action recognition exemplifies a modular, systematic approach, where each stage functions as an independent module is expanded, optimized, replaced without affecting others. This modularity enhances the flexibility, adaptability, scalability of the pipeline, providing a solid foundation for future advancements across various tasks, application domains.},
  archive      = {J_EAAI},
  author       = {Minh-Trieu Truong and Van-Dung Hoang},
  doi          = {10.1016/j.engappai.2025.111987},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111987},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Skeleton-based multi-person action recognition towards real-world violence detection},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Malware attack and defense game in fractional-order internet of underwater things: Model-based and model-free approaches. <em>EAAI</em>, <em>161</em>, 111970. (<a href='https://doi.org/10.1016/j.engappai.2025.111970'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the Internet of Underwater Things (IoUT), its cybersecurity faces increasingly severe challenges, as malware attacks have become a common and highly destructive threat. However, most existing studies rely on integer-order models or static defense mechanisms, which fail to capture the memory and hereditary properties of underwater malware propagation and lack adaptability in dynamic adversarial environments. To address this issue, this paper constructs a fractional-order propagation model and introduces differential game theory to investigate the dynamic interactions between malware and system defense, aiming to derive the optimal dynamic strategies and the corresponding Nash equilibrium for both parties. Furthermore, two innovative artificial intelligence strategy learning approaches are proposed: a model-based method and a model-free method, designed to approximate the optimal control strategies in the game. Extensive comparative experiments and simulation results demonstrate the effectiveness of the proposed methods in strategy learning. We further discuss the practical applications of these methods in IoUT as well as their scalability to other domains.},
  archive      = {J_EAAI},
  author       = {Guiyun Liu and Zulong Peng and Tingting Tan and Xiaojing Zhong and Zhongwei Liang},
  doi          = {10.1016/j.engappai.2025.111970},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111970},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Malware attack and defense game in fractional-order internet of underwater things: Model-based and model-free approaches},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised graph contrastive learning for emotion recognition based on electroencephalogram signals. <em>EAAI</em>, <em>161</em>, 111969. (<a href='https://doi.org/10.1016/j.engappai.2025.111969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition plays a crucial role in affective computing, aiming to identify and interpret human emotions. Since electroencephalography (EEG) measures brain electrical activity associated with emotional processing, its use in emotion recognition has garnered significant attention. However, due to the complexity of EEG, capturing the low-dimensional manifold structure from a high-dimensional EEG signal remains a challenge. Moreover, even though EEG labeling is expensive and requires specialization, the development of emotion recognition models has predominantly relied on labeled EEG datasets. To address these issues, we propose a semi-supervised graph contrastive learning (SGCL) model for EEG-based emotion recognition, leveraging the abundance of unlabeled EEG data to generate clearer representations. The proposed SGCL extracts two frequency-domain features from the EEG signal, differential entropy (DE) and power spectral density (PSD), which are integrated through a symmetric similarity network fusion (SSNF) with graph contrastive learning (GCL) to improve the generalization and representation capability of the graph convolutional network (GCN) to complex EEG data in transductive learning tasks. Extensive experimental results on three public datasets reveal that the proposed SGCL consistently outperforms state-of-the-art models. Notably, on the Shanghai Jiao Tong University EEG Emotion dataset (SEED), SGCL achieves an average accuracy of 99.99% using only 3.5% of the data as labeled input, setting a new benchmark in both effectiveness and efficiency. Further analyses confirm our model learns highly discriminative representations and offers insightful explanations, demonstrating its potential for robust emotion recognition.},
  archive      = {J_EAAI},
  author       = {Dae Hyeon Kim and Young-Seok Choi},
  doi          = {10.1016/j.engappai.2025.111969},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111969},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised graph contrastive learning for emotion recognition based on electroencephalogram signals},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable automated wild-orchid identification combining deep neural networks and bayesian networks. <em>EAAI</em>, <em>161</em>, 111961. (<a href='https://doi.org/10.1016/j.engappai.2025.111961'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been shown repeatedly to be a successful method of obtaining accurate classifiers. This also applies to orchid identification from digital photographs. However, deep neural networks possess the major weakness of lack of explainability, missing the ability to explain the reasons behind a decision. Nevertheless, most current research regarding automated orchid identification applies this blackbox approach. By contrast, in this paper we propose a new method for trustworthy automated orchid identification combining two complementary methods: deep neural networks and feature-based Bayesian networks, where the Bayesian network is also utilized for providing an explanation of the generated solutions. We use other deep neural networks to extract flower characteristics, the features, from the images which are subsequently fed into the Bayesian network as uncertain evidence. When combining the deep neural network and the Bayesian network as an ensemble classifier, both reaching the same conclusion, an accuracy of 89.4% is achieved, the most trustworthy outcome. With a human-in-the-loop ensemble classifier, validation results are even better, yielding an accuracy of 98.1%. Our approach also exploits the taxonomic knowledge represented in the Bayesian network to provide an explanation of the solutions for every case, reinforcing further trust in the method. The result is an explainable user-in-the-loop ensemble classifier. Providing explainability can help build user trust in a system and may play a major role when it is used as a learning aid for new orchid enthusiasts. Finally, the proposed method may be also of value in many fields other than plant determination.},
  archive      = {J_EAAI},
  author       = {Diah Harnoni Apriyanti and Luuk J. Spreeuwers and Peter J.F. Lucas},
  doi          = {10.1016/j.engappai.2025.111961},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111961},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable automated wild-orchid identification combining deep neural networks and bayesian networks},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A safe multi-agent reinforcement learning algorithm using constraint update projection approach. <em>EAAI</em>, <em>161</em>, 111929. (<a href='https://doi.org/10.1016/j.engappai.2025.111929'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional reinforcement learning has a major limitation, which is that they optimize agent’s policy purely for maximizing rewards. It completely ignore safety considerations. However, in certain critical engineering fields, ensuring safety is of utmost importance, otherwise it can cause incalculable losses. Therefore, this paper proposes a safe Multi-Agent Constrained Update Projection(MACUP) algorithm, which can safely control agents to complete tasks. We solve this problem from the perspective of policy constraint optimization. Firstly, we derive the new bounds of multi-agent policy performance difference based on a tighter general policy performance difference. It contains generalized advantage estimates, and we utilize these bounds as surrogate functions concerning the objective and constraints. Secondly, to address the coordination issue among multiple agents, we employ a multi-agent sequential policy update framework. Finally, we use a projection method to optimize policies, which has low computational complexity and does not require convex approximation of the surrogate function for solving. It can help us reduce errors. Finally, we have validated our algorithm in two different multi-agent safety environments, and the results show that it is able to satisfy safety constraints while achieving higher rewards.},
  archive      = {J_EAAI},
  author       = {Yang Liu and Xiang Feng and Huiqun Yu},
  doi          = {10.1016/j.engappai.2025.111929},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111929},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A safe multi-agent reinforcement learning algorithm using constraint update projection approach},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-criteria group decision-making method using spherical fuzzy Z-numbers for smart technology revolution in municipal waste management. <em>EAAI</em>, <em>161</em>, 111928. (<a href='https://doi.org/10.1016/j.engappai.2025.111928'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the new phenomenon of globalization and the fast growing cities, there is drastic pressure on the conventional methods of waste management hence the need for innovative management wastage that is proactive to the theme of environmental and economic challenge of the modern world. This paper aims at investigating the following research question: How has the introduction of smart technologies impacted waste management in the context of a mid-sized city that is in the cross-road of generating more wastes while at the same time, concerns over ecological attainability. They present a new type of Spherical Fuzzy Z-Number Sets in organizational environments dealing with multi criteria group decision making where it possess higher order of uncertainty than conventional fuzzy sets. For handling the multi facility nature of multi criteria group decision making in waste management, we propose the so-called Additive Ratio Assessment method when the attribute weights are unknown. To ensure that the criteria weights are determined objectively in this research, the CRITIC (CRiteria Importance Through Intercriteria Correlation) technique is used. The first part of the study provides a theoretical framework of spherical fuzzy Z-numbers concerning accuracy, scoring functions, and operations. Then we introduce this framework to actual multi criteria group decision making cases in municipal waste management to show that how Spherical Fuzzy Z-Number can facilitate decision-making processes by dealing with the vagueness and fuzziness of stakeholder preferences. The TODIM (Tomada de Decisao Iterativa Multicriterio) technique is used in this to validate and compare for efficiency of the proposed additive ratio assessment method. Besides, this research will not only enhance the theoretical aspect of fuzzy decision making but also present a feasible and effective framework for handling unsound and random decision making problems especially within the context of urban waste management.},
  archive      = {J_EAAI},
  author       = {Shahzaib Ashraf and Muhammad Naeem and Chiranjibe Jana and Maria Akram and Gerhard-Wilhelm Weber},
  doi          = {10.1016/j.engappai.2025.111928},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111928},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-criteria group decision-making method using spherical fuzzy Z-numbers for smart technology revolution in municipal waste management},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From image processing to artificial intelligence-driven tools: A comprehensive survey on the evolution of feature extraction methods in paintings. <em>EAAI</em>, <em>161</em>, 111794. (<a href='https://doi.org/10.1016/j.engappai.2025.111794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the computational process of converting qualitative elements of paintings, such as shape, color, texture, and line, into quantitative numerical values, which aid in identifying and extracting features from painting images. These identified features are then used to classify paintings based on artist, art style, genre, and art movements. This review employs a systematic literature review methodology, examining approximately 80 research papers to track trends in this field from 2015 to 2025. With the increasing presence of paintings in online media, museums, and galleries, artificial intelligence (AI) plays a significant role in interpreting these subjective elements. This review examines various image processing techniques in conjunction with AI implementations to extract the local and global features of a painting. These methods are combined with AI models, such as deep learning and computer vision algorithms, to improve feature extraction and provide a more thorough and accurate paintings analysis.},
  archive      = {J_EAAI},
  author       = {Rekha Sharma and Rishi Gupta and Aditya Sinha},
  doi          = {10.1016/j.engappai.2025.111794},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {12},
  pages        = {111794},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {From image processing to artificial intelligence-driven tools: A comprehensive survey on the evolution of feature extraction methods in paintings},
  volume       = {161},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ejor">EJOR - 42</h2>
<ul>
<li><details>
<summary>
(2025). Optimal lot-sizing and service level weighting in sequential multi-attribute global transportation service procurement. <em>EJOR</em>, <em>327</em>(3), 1052-1072. (<a href='https://doi.org/10.1016/j.ejor.2025.05.037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of on-demand global transportation service procurement (oGTSP) through digital trading platforms has accelerated due to frequent fluctuations in transport capacity. In the oGTSP model, the exporter must consider logistics service quality and transport prices when sourcing global logistics services. To satisfy the continuous transport needs, procurement is conducted sequentially throughout multiple auction cycles. For a single auction, we constructed a service-level weight-scoring function and analysed the trading parties’ behavioural strategies to obtain an auction equilibrium strategy in a specific context. Then, we developed a multi-cycle sequential decision method based on a single-cycle equilibrium decision by forwarders that can dynamically adjust the auction lot size to help the exporter obtain optimal utility. Finally, based on the real case of a large electronic product exporter, the proposed approach was verified. The results demonstrated that exporters should pay more attention to the quality of service when choosing freight forwarders to improve the utility of transportation service procurement. The exporter can attract more forwarders to participate in auctions to obtain more capacity supply by increasing the weighting of service levels. Besides, the proposed auction system could effectively accommodate strategic forwarders with learning abilities. The exporter’s utility will significantly improve if the freight forwarders have learning ability. There is a marginal diminishing effect in that the benefits from additional participation of learning-oriented bidders are initially large but eventually stabilized. The strategic auction participation of learning-oriented freight forwarders smooths the capacity supply trend, reduces extreme fluctuations and makes multi-cycle predictions more accurate.},
  archive      = {J_EJOR},
  author       = {Xiang T.R. Kong and Zhan He and Kaize Yu and Pengyu Yan},
  doi          = {10.1016/j.ejor.2025.05.037},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {1052-1072},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal lot-sizing and service level weighting in sequential multi-attribute global transportation service procurement},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Government’s optimal inter-temporal subsidy and manufacturer’s dynamic pricing in the presence of strategic consumers. <em>EJOR</em>, <em>327</em>(3), 1039-1051. (<a href='https://doi.org/10.1016/j.ejor.2025.05.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Governments in many countries offer fiscal incentives—such as subsidies or tax breaks—to consumers to encourage the purchase of environmentally-friendly products like solar panels and electric vehicles. Early adoption by consumers facilitates manufacturers’ learning-by-doing and reduces production cost over time, although the cost reduction itself is subject to uncertainty. Governments face a challenge: should they commit to a multi-period subsidy path (commitment policy) or adjust the subsidy contingent on the realized production cost reduction (dynamic policy)? What are the implications for manufacturers and consumers? We consider a two-period monopoly setting to study these policies. Given the subsidy policy, the manufacturer sets its prices, whereas consumers strategically decide when to purchase the product, if at all. Naturally, the two policies result in different subsidy paths. We find that products with higher initial unit cost (implying higher prices) do not deserve higher subsidies. Our key result is that governments, who seek to maximize expected social welfare, should adopt the dynamic policy. Insightfully, the four components of social welfare—consumer surplus, manufacturer’s profit, environmental benefit and subsidy expenditure—may all be realized higher under the commitment policy than under the dynamic policy when the realized cost reduction falls short of its expected value. This is because the second-period effective price (price minus subsidy) is more sensitive to cost uncertainty under the dynamic policy. Nevertheless, the dominance of the dynamic policy persists also when considering the realized social welfare. We study several extensions demonstrating the robustness of our results, while highlighting certain exceptions.},
  archive      = {J_EJOR},
  author       = {Weichun Chen and Benny Mantin and Bo Li},
  doi          = {10.1016/j.ejor.2025.05.027},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {1039-1051},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Government’s optimal inter-temporal subsidy and manufacturer’s dynamic pricing in the presence of strategic consumers},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated model for predictive maintenance and inventory management under a reliability chance constraint. <em>EJOR</em>, <em>327</em>(3), 1023-1038. (<a href='https://doi.org/10.1016/j.ejor.2025.05.018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new model that integrates opportunistic maintenance and routine maintenance to enhance the effectiveness of predictive maintenance and inventory management in complex manufacturing systems subject to a reliability chance constraint. It considers both hard and soft failure modes and their mutual dependence. When a machine experiences a hard failure, an opportunistic maintenance policy is utilized on the machine’s components. When the soft failure degradation level of a machine component surpasses a threshold, imperfect preventive maintenance or replacement maintenance is carried out. The choice of component supplier, including OEM and aftermarket suppliers, significantly impacts the joint decision model. To improve the model’s realism and applicability, a random variable representing supplier availability intervals is introduced, reflecting a more nuanced understanding of supply chain dynamics. We develop a simulation optimization method to determine the degradation thresholds for opportunistic and regular maintenance, the component inventory policy, and supplier selection. The objective is to minimize the total maintenance and inventory cost, while ensuring a high level of system reliability. The proposed algorithm effectively addresses the system reliability chance constraint by formulating a surrogate model of the quantile of system downtime. A numerical study is conducted to verify the efficacy of the proposed model and to demonstrate the efficiency of the solution method in finding the optimal feasible solution. Furthermore, the influence of critical factors in the model on the optimal policy is analyzed to derive useful managerial insights.},
  archive      = {J_EJOR},
  author       = {Kuo-Hao Chang and Xin-Pei Wu and Robert Cuckler},
  doi          = {10.1016/j.ejor.2025.05.018},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {1023-1038},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An integrated model for predictive maintenance and inventory management under a reliability chance constraint},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ordinal regression meets online learning: Interactive preference learning for multiple criteria choice and ranking with provable guarantees. <em>EJOR</em>, <em>327</em>(3), 1003-1022. (<a href='https://doi.org/10.1016/j.ejor.2025.05.045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a theoretical and practical bridge between ordinal regression for multiple criteria choice and ranking problems and the framework of sequential prediction, also known as online learning. By reframing the ordinal regression as a sequential prediction task, we study a general class of algorithms that assign probabilities to a sequence of the preferences expressed by the Decision Maker (DM). This approach allows us to evaluate various statistical algorithms on a common basis, providing theoretical guarantees on their regret. To model the likelihood, we employ an additive value function that scores pairwise comparisons given by the DM. We explore two likelihood models: (1) a linear model, which we demonstrate is analogous to sequential investment, and (2) the Bradley–Terry model, widely used in statistics and preference learning. For both models, we establish theoretical bounds for the Bayesian method and the Regularized Maximum Likelihood algorithm (also known as Follow the Regularized Leader). We design Monte Carlo Markov Chain methods based on Metropolis–Hastings and Nested Sampling for efficient approximation of the posterior in Bayesian methods. Extensive empirical testing on synthetic and real-world data shows that our methods outperform the best existing approaches in the literature.},
  archive      = {J_EJOR},
  author       = {Marco Grillo and Wojciech Kotłowski and Miłosz Kadziński},
  doi          = {10.1016/j.ejor.2025.05.045},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {1003-1022},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Ordinal regression meets online learning: Interactive preference learning for multiple criteria choice and ranking with provable guarantees},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Alternative ranking in trust network group decision-making: A distributionally robust optimization method. <em>EJOR</em>, <em>327</em>(3), 986-1002. (<a href='https://doi.org/10.1016/j.ejor.2025.05.052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In group decision making problems, preference information can be conveniently and productively used to express the decision-makers’ evaluations over the given set of alternatives. However, the inherent imprecision of preference information may lead to fragile priority weights and unreliable alternative ranking. In this study, we propose a distributionally robust ranking model based on social networks to derive stable priorities, which takes into account the influence of uncertain preference information and the strength of relationships among decision-makers. Specifically, to capture the true data-generating distribution of uncertain parameters, we first develop a distributionally robust ranking model with a moment-based ambiguity set that contains all possible probability distributions over a support set. Then, we verify that the solutions exhibit strong finite-sample performance guarantees. Additionally, the developed model can be reformulated into an equivalent semidefinite programming model. To account for the strength of relationships among decision-makers, we employ propagation efficiency based on Shannon’s theorem, and develop the trust propagation and aggregation operators to obtain decision-makers’ weights. Finally, a numerical experiment is provided, in which the justification and robustness of the distributionally robust ranking model outperform several benchmark models by comparative discussions and robustness analyses.},
  archive      = {J_EJOR},
  author       = {Longlong Shao and Jinpei Liu and Chenyi Fu and Ning Zhu and Huayou Chen},
  doi          = {10.1016/j.ejor.2025.05.052},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {986-1002},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Alternative ranking in trust network group decision-making: A distributionally robust optimization method},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When and should streamers choose high-quality products? effects of streamer types. <em>EJOR</em>, <em>327</em>(3), 971-985. (<a href='https://doi.org/10.1016/j.ejor.2025.05.057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of live-streaming commerce, research has largely focused on manufacturers, leaving streamer decision-making underexplored. This study uses game theory to analyze streamers’ product selection strategies, while also examining how streamer types influence these decisions. The findings reveal that: (a) Streamers do not always prioritize high-quality products. Their choices are shaped by various factors, including product pricing, quality gaps, commission ratios, fan-shoppers’ trust, and sales abilities. High-quality manufacturers are advised to collaborate with knowledge-based streamers, while low-quality manufacturers should partner with entertainment-based streamers. Moderate commission ratios can optimize profits for all parties. (b) For well-known products, knowledge-based streamers with strong sales abilities are more likely to select high-quality items, as they can leverage fan-shoppers' willingness to pay. In contrast, entertainment-based streamers do not exhibit this preference. For unknown products, entertainment-based streamers with strong sales abilities may promote low-quality items, even resorting to deception. Interestingly, entertainment-based streamers with weaker sales abilities may promote high-quality products, while knowledge-based streamers may opt for lower-quality options. (c) When product quality is endogenous, streamers with lower sales abilities should focus on entertainment-based content to attract attention. As their sales abilities improve and fan-shoppers’ trust grows, they should transition to knowledge-based content.},
  archive      = {J_EJOR},
  author       = {Shengyan Cheng and Qiang Guo and Chris K Anderson},
  doi          = {10.1016/j.ejor.2025.05.057},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {971-985},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {When and should streamers choose high-quality products? effects of streamer types},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting two-dimensional projection-efficient units in data envelopment analysis under big data scenarios. <em>EJOR</em>, <em>327</em>(3), 957-970. (<a href='https://doi.org/10.1016/j.ejor.2025.05.053'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the age of big data, traditional estimation methods may struggle to process large datasets efficiently. Ali (1993) laid the foundation for improving efficiency assessment using Data Envelopment Analysis (DEA). Building on this work, we demonstrate how to detect two-dimensional projection-efficient units. This is achieved by projecting the multidimensional DEA production frontier onto two-dimensional subspaces and utilizing slope analysis to identify key efficient units. These units are then linked to their full-dimensional counterparts to define projection-efficient units. We propose using these key efficient units as a preliminary step to speed up the identification of full-dimensional efficient units or to estimate the relative density of datasets. Simulations show that our method reduces computation time for the two fastest approaches by an average of 54.2 % across different datasets.},
  archive      = {J_EJOR},
  author       = {Shuqi Xu and Qingyuan Zhu and Zhiyang Shen and Michael Vardanyan and Yinghao Pan},
  doi          = {10.1016/j.ejor.2025.05.053},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {957-970},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Detecting two-dimensional projection-efficient units in data envelopment analysis under big data scenarios},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deck of cards method for hierarchical, robust and stochastic ordinal regression. <em>EJOR</em>, <em>327</em>(3), 937-956. (<a href='https://doi.org/10.1016/j.ejor.2025.05.025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the recently introduced application of the Deck of Cards Method (DCM) to ordinal regression proposing two extensions related to two main research trends in Multiple Criteria Decision Aiding, namely scaling and ordinal regression generalizations. On the one hand, procedures, different from DCM (e.g. AHP, BWM, MACBETH) to collect and elaborate Decision Maker’s (DM’s) preference information are considered to define an overall evaluation of reference alternatives. On the other hand, Robust Ordinal Regression and Stochastic Multicriteria Acceptability Analysis are used to offer the DM more detailed and realistic decision-support outcomes. More specifically, we consider preference imprecision and indetermination through a set of admissible comprehensive evaluations of alternatives provided by the whole set of value functions compatible with DM’s preference information rather than relying on a single definitive evaluation based on one value function. In addition, we also consider alternatives evaluated on a set of criteria hierarchically structured. The methodology we propose allows the DM to provide precise or imprecise information at different levels of the hierarchy of criteria. Like scaling procedures, the compatible value function we consider can be of a different nature, such as weighted sum, linear or general monotone value function, or Choquet integral. Consequently, the approach we propose is versatile and well-equipped to be adapted to DM’s characteristics and requirements. The applicability of the proposed methodology is shown by a didactic example based on a large ongoing research project in which Italian regions are evaluated on criteria representing Circular Economy, Innovation-Driven Development and Smart Specialization Strategies.},
  archive      = {J_EJOR},
  author       = {Salvatore Corrente and Salvatore Greco and Silvano Zappalà},
  doi          = {10.1016/j.ejor.2025.05.025},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {937-956},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Deck of cards method for hierarchical, robust and stochastic ordinal regression},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum likelihood probability measures over sets: Existence, computation, and convergence. <em>EJOR</em>, <em>327</em>(3), 922-936. (<a href='https://doi.org/10.1016/j.ejor.2025.07.054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider maximum likelihood estimation of a distribution over a general measurable space where realizations of the uncertainty are not directly observable but instead are known to lie within observable sets. We show that maximum likelihood estimates concentrate on a collection of maximal intersections (CMI) and can be found by solving a convex optimization problem whose size is linear in the size of the CMI. We provide an enumerative algorithm to compute the estimates and show that there are estimates that assign positive weight only to T + 1 elements of the CMI ( T being the number of observed sets). Motivated by this, we provide a column generation algorithm to compute the estimates that avoids enumerating the CMI. Under the assumption that either the observed sets are mixed-integer representable, or that the range of the underlying distribution is finite and known, we provide formulations of the algorithms that can be solved with commercial solvers. We study convergence properties of the maximum likelihood estimate both in terms of traditional notions of converge, as well as in terms of Wasserstein distances. Our results show that convergence to the underlying distribution cannot be guaranteed in general, but we identify sufficient conditions for convergence. We also perform numerical experiments that show that the estimates can be computed within minutes, that column generation can significantly reduce computational times, and that there is convergence even in cases where no theoretical guarantees are known.},
  archive      = {J_EJOR},
  author       = {Juan S. Borrero and Denis Sauré},
  doi          = {10.1016/j.ejor.2025.07.054},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {922-936},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Maximum likelihood probability measures over sets: Existence, computation, and convergence},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Worst-case values of target semi-variances with applications to robust portfolio selection. <em>EJOR</em>, <em>327</em>(3), 905-921. (<a href='https://doi.org/10.1016/j.ejor.2025.07.057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expected regret and target semi-variance are two of the most important risk measures for downside risk. When the distribution of a loss is uncertain, and only partial information of the loss is known, their worst-case values play important roles in robust risk management for finance, insurance, and many other fields. Jagannathan (1977) derived the worst-case expected regrets when only the mean and variance of a loss are known and the loss is arbitrary, symmetric, or non-negative. While Chen et al. (2011) obtained the worst-case target semi-variances under similar conditions but focusing on arbitrary losses. In this paper, we first complement the study of Chen et al. (2011) on the worst-case target semi-variances and derive the closed-form expressions for the worst-case target semi-variance when only the mean and variance of a loss are known and the loss is symmetric or non-negative. Then, we investigate worst-case target semi-variances over uncertainty sets that represent undesirable scenarios faced by an investor. Our methods for deriving these worst-case values are different from those used in Jagannathan (1977) and Chen et al. (2011). As applications of the results derived in this paper, we propose robust portfolio selection methods that minimize the worst-case target semi-variance of a portfolio loss over different uncertainty sets. To explore the insights of our robust portfolio selection methods, we conduct numerical experiments with real financial data and compare our portfolio selection methods with several portfolio selection models related to the models proposed in this paper.},
  archive      = {J_EJOR},
  author       = {Jun Cai and Zhanyi Jiao and Tiantian Mao},
  doi          = {10.1016/j.ejor.2025.07.057},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {905-921},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Worst-case values of target semi-variances with applications to robust portfolio selection},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint model for longitudinal and spatio-temporal survival data. <em>EJOR</em>, <em>327</em>(3), 892-904. (<a href='https://doi.org/10.1016/j.ejor.2025.07.060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In credit risk analysis, survival models with fixed and time-varying covariates are commonly used to predict a borrower’s time-to-event. When time-varying covariates are endogenous, jointly modeling their evolution with the event time — known as the joint model for longitudinal and time-to-event data — provides a principled approach. In addition to temporal dynamics, incorporating borrowers’ geographical information can enhance predictive accuracy by capturing spatial clustering and its variation over time. We propose the Spatio-Temporal Joint Model (STJM), a Bayesian hierarchical model that accounts for spatial and temporal effects and their interaction. The STJM captures the impact of unobserved heterogeneity across regions, affecting borrowers residing in the same area at a given time. To ensure scalability to large datasets, we implement the model using the Integrated Nested Laplace Approximation (INLA) framework. We apply the STJM to predict the time to full prepayment on a large dataset of 57,258 US mortgage borrowers with more than 2.5 million observations. Empirical results indicate that including spatial effects consistently improves the performance of the joint model. However, the gains are less definitive when we additionally include spatio-temporal interactions.},
  archive      = {J_EJOR},
  author       = {Victor Medina-Olivares and Finn Lindgren and Raffaella Calabrese and Jonathan Crook},
  doi          = {10.1016/j.ejor.2025.07.060},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {892-904},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Joint model for longitudinal and spatio-temporal survival data},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Staggered routing in autonomous mobility-on-demand systems. <em>EJOR</em>, <em>327</em>(3), 875-891. (<a href='https://doi.org/10.1016/j.ejor.2025.06.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In autonomous mobility-on-demand systems, effectively managing vehicle flows to mitigate induced congestion and ensure efficient operations is imperative for system performance and positive customer experience. Against this background, we study the potential of staggered routing, i.e., purposely delaying trip departures from a system perspective, in order to reduce congestion and ensure efficient operations while still meeting customer time windows. We formalize the underlying planning problem and show how to efficiently model it as a mixed integer linear program. Moreover, we present a matheuristic that allows us to efficiently solve large-scale real-world instances both in an offline full-information setting and its online rolling horizon counterpart. We conduct a numerical study for Manhattan, New York City, focusing on low- and highly-congested scenarios. Our results show that in low-congestion scenarios, staggering trip departures allows mitigating, on average, 98 % of the induced congestion in a full information setting. In a rolling horizon setting, our algorithm allows us to reduce 82 % of the induced congestion. In high-congestion scenarios, we observe an average reduction of 60 % as the full information bound and an average reduction of 30 % in our online setting. Surprisingly, we show that these reductions can be reached by shifting trip departures by a maximum of six minutes in both the low and high-congestion scenarios.},
  archive      = {J_EJOR},
  author       = {Antonio Coppola and Gerhard Hiermann and Dario Paccagnan and Maximilian Schiffer},
  doi          = {10.1016/j.ejor.2025.06.008},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {875-891},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Staggered routing in autonomous mobility-on-demand systems},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The storage location assignment and picker routing problem: A generic branch-cut-and-price algorithm. <em>EJOR</em>, <em>327</em>(3), 857-874. (<a href='https://doi.org/10.1016/j.ejor.2025.05.041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Storage Location Assignment Problem (SLAP) and the Picker Routing Problem (PRP) have received significant attention in the literature due to their pivotal role in the performance of the Order Picking (OP) activity, the most resource-intensive process of warehousing logistics. The two problems are traditionally considered at different decision-making levels: tactical for the SLAP, and operational for the PRP. However, this paradigm has been challenged by the emergence of modern practices in e-commerce warehouses, where decisions are more dynamic. This shift makes the integrated problem, called the Storage Location Assignment and Picker Routing Problem (SLAPRP), pertinent to consider. Scholars have investigated several variants of the SLAPRP, including different warehouse layouts and routing policies. Nevertheless, the available computational results suggest that each variant requires an ad-hoc formulation. Moreover, achieving a complete integration of the two problems, where the routing is solved optimally, remains out of reach for commercial solvers, even on trivial instances. In this paper, we propose an exact solution framework that addresses a broad class of variants of the SLAPRP, including all the previously existing ones. This paper proposes a Branch-Cut-and-Price framework based on a novel formulation with an exponential number of variables, which is strengthened with a novel family of non-robust valid inequalities. We have developed an ad-hoc branching scheme to break symmetries and maintain the size of the enumeration tree manageable. Computational experiments show that our framework can effectively solve medium-sized instances of several SLAPRP variants and outperforms the state-of-the-art methods from the literature.},
  archive      = {J_EJOR},
  author       = {Thibault Prunet and Nabil Absi and Diego Cattaruzza},
  doi          = {10.1016/j.ejor.2025.05.041},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {857-874},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The storage location assignment and picker routing problem: A generic branch-cut-and-price algorithm},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust parallel machine selection and scheduling with uncertain release times. <em>EJOR</em>, <em>327</em>(3), 838-856. (<a href='https://doi.org/10.1016/j.ejor.2025.05.032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a parallel machine selection and scheduling (PMSS) problem with uncertain release times. To handle uncertain release times, we propose a two-stage robust PMSS model where the release time deviation (RTD) is characterized by a budget uncertainty set. In the first stage, machine selection and job assignment decisions are made to minimize startup costs before the uncertainties are revealed. In the second stage, once release times are known, job sequences are optimized to minimize the makespan on each machine. Robust constraints are introduced to ensure that the worst-case minimum makespan on each machine does not exceed a pre-specified due date. The proposed model is a tri-level min–max–min optimization problem with mixed-integer recourse decisions, which cannot be solved efficiently by existing algorithms. To this end, we propose a novel logic-based Benders decomposition (LBBD) algorithm with strengthened Benders cuts and speedup techniques. Specifically, we first provide an equivalent mixed-integer linear programming reformulation for the max–min subproblem by analyzing an optimality condition of the worst-case RTD. Second, we design novel combinatorial and analytical Benders cuts, which dominate cuts found in the literature, and we further strengthen them by lifting procedures. Third, we design a relaxation-and-correction procedure and a warm-start procedure to speed up the LBBD algorithm. Numerical experiments show the proposed robust model greatly reduces job tardiness compared with the deterministic model. The proposed cuts efficiently reduce the runtime, and the LBBD algorithm is at least three orders of magnitude faster than the state-of-the-art column-and-constraint-generation algorithm.},
  archive      = {J_EJOR},
  author       = {Linyuan Hu and Yuli Zhang and Muyang Wen and Roel Leus and Ningwei Zhang},
  doi          = {10.1016/j.ejor.2025.05.032},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {838-856},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust parallel machine selection and scheduling with uncertain release times},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast optimization approach for a complex real-life 3D multiple bin size bin packing problem. <em>EJOR</em>, <em>327</em>(3), 820-837. (<a href='https://doi.org/10.1016/j.ejor.2025.05.016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a real-life air cargo loading problem which is a variant of the three-dimensional Variable Size Bin Packing Problem with special bin forms of cuboid and non-cuboid unit load devices (ULDs). Packing is constrained by additional practical restrictions, such as load stability, (non-)stackable items, and weight distribution constraints. To solve the problem, we present an insertion heuristic embedded into a Randomized Greedy Search. The solution space is limited by only considering certain candidate points (so-called extreme points), which are promising positions to load an item. We extend the concept of extreme points proposed in the literature and allow moving extreme points for non-cuboid ULDs. A special sorting of the items, which combines a layered structure and free packing, is suggested. Moreover, we propose dividing the space of each ULD into smaller cells to accelerate the collision, non-floating, and stackability check while loading items. In a computational study, we analyze individual algorithm components and show the effectiveness of our method on adapted real-life instances from the literature.},
  archive      = {J_EJOR},
  author       = {Katrin Heßler and Timo Hintsch and Lukas Wienkamp},
  doi          = {10.1016/j.ejor.2025.05.016},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {820-837},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A fast optimization approach for a complex real-life 3D multiple bin size bin packing problem},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning assisted differential evolution for the dynamic resource constrained multi-project scheduling problem with static project schedules. <em>EJOR</em>, <em>327</em>(3), 808-819. (<a href='https://doi.org/10.1016/j.ejor.2025.05.059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large modular construction projects, such as shipbuilding, multiple similar projects arrive stochastically. At project arrival, a schedule has to be created, in which future modifications are difficult and/or undesirable. Since all projects use the same set of shared resources, current scheduling decisions influence future scheduling possibilities. To model this problem, we introduce the Dynamic Resource Constrained Multi-project Scheduling Problem with Static project Schedules. To find schedules, both a greedy approach and simulation-based approach with varying scenarios are introduced. Although the simulation-based approach schedules projects proactively, the computing times are long, even for small instances. Therefore, a method is introduced that learns from schedules obtained in the simulation-based method and uses a neural network to estimate the objective function value. It is shown that this method achieves a significant improvement in objective function value over the greedy algorithm, while only requiring a fraction of the computation time of the simulation-based method.},
  archive      = {J_EJOR},
  author       = {T. van der Beek and J.T. van Essen and J. Pruyn and K. Aardal},
  doi          = {10.1016/j.ejor.2025.05.059},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {808-819},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Machine learning assisted differential evolution for the dynamic resource constrained multi-project scheduling problem with static project schedules},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A flexible mathematical model for home health care problems. <em>EJOR</em>, <em>327</em>(3), 791-807. (<a href='https://doi.org/10.1016/j.ejor.2025.05.055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the health and social care sectors it is common for some specialized teams to travel to patients homes to provide care. These teams are typically made up of by a number of staff members with varying skills, starting locations and working hours. Patients require different types of care, during specific time windows, and may have special requirements, such as needing two staff members, or multiple visits with some sort of temporal dependency between them. Since teams need to decide which staff member will visit each patient, as well as the routes they will take to do so, this kind of planning problem is known in the literature as the Home Health Care Routing and Scheduling Problem (HHCRSP). We introduce a new mixed integer linear programming formulation for the HHCRSP that extends previous models. Our formulation can readily be adapted to address more specific variants in the scientific literature, proving a larger number of optimal solutions and stronger lower bounds on benchmark instances using the same computational framework. We further propose an instance generator for producing scenarios that closely resemble those of the National Health Service in the United Kingdom.},
  archive      = {J_EJOR},
  author       = {Miguel Reula and Consuelo Parreño-Torres and Carlos Lamas-Fernandez and Antonio Martinez-Sykora},
  doi          = {10.1016/j.ejor.2025.05.055},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {791-807},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A flexible mathematical model for home health care problems},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The dial-a-ride problem with limited pickups per trip. <em>EJOR</em>, <em>327</em>(3), 776-790. (<a href='https://doi.org/10.1016/j.ejor.2025.05.051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Dial-a-Ride Problem (DARP) is an optimization problem that involves determining optimal routes and schedules for several vehicles to pick up and deliver items at minimum cost. Motivated by real-world carpooling and crowdshipping scenarios, we introduce an additional constraint imposing a maximum number on the number of pickups per trip. This results in the Dial-a-Ride Problem with Limited Pickups per Trip (DARP-LPT). We apply a fragment-based method for DARP-LPT, where a fragment is a partial path. Specifically, we extend two formulations from Rist and Forbes (2021): the Fragment Flow Formulation (FFF) and the Pickup-Space Fragment Formulation (PSFF). Furthermore, our results show that PSFF outperforms FFF, which in turn surpasses traditional arc-based formulations in both solution quality and computational efficiency. Additionally, we compare several existing fragment sets that differ in the length of their partial paths and find that the sets with shorter partial paths yield the best solution times when used with PSFF. In addition, we propose a new mixed fragment set, which is useful when the sets with longer partial paths become too large. In such cases, it yields the lowest CPU time.},
  archive      = {J_EJOR},
  author       = {Boshuai Zhao and Kai Wang and Wenchao Wei and Roel Leus},
  doi          = {10.1016/j.ejor.2025.05.051},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {776-790},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The dial-a-ride problem with limited pickups per trip},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new class of lower bounds for scheduling a batch processing machine to minimize makespan. <em>EJOR</em>, <em>327</em>(3), 754-775. (<a href='https://doi.org/10.1016/j.ejor.2025.05.047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of minimizing makespan on a batch-processing machine with limited capacity. Each job has a size and processing time, and multiple jobs can be processed simultaneously in a batch, provided the machine’s capacity is not exceeded. The batch processing time is determined by the longest processing time in batch. We show that the existing lower bound method has a worst-case performance ratio of 1/2, and propose a class of lower bound procedures ( LB m ) and its improved variant ( ILB m ). The new procedures take integer m , used to partition jobs depending on whether their sizes are greater than B / m or not, and provide tighter bounds as m increases. We prove that the worst-case performance ratio of LB m and ILB m is no worse than 4/7. Additionally, we show that they can be computed efficiently for m ≤3. Based on the structure of the proposed lower bound procedures, we introduce different valid inequalities ( VI ) and embed them into an existing MILP model to achieve a formulation with a tighter LP bound. To gain understanding on the quality of the bounds, we employ them in a branch and bound ( B & B ) algorithm. Results indicate that the B&B with new lower bound methods increases the number of optimally solved problem instances by 44% and 35% compared to the existing B&B and branch and price algorithms, respectively. Furthermore, the lower bound-driven VI s help increase the number of solved problems by more than 30%, achieving an optimality rate exceeding 96% across a wide range of problem instances.},
  archive      = {J_EJOR},
  author       = {Ali Husseinzadeh Kashan and Onur Ozturk},
  doi          = {10.1016/j.ejor.2025.05.047},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {754-775},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new class of lower bounds for scheduling a batch processing machine to minimize makespan},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EATKG: An open-source efficient exact algorithm for the two-dimensional knapsack problem with guillotine constraints. <em>EJOR</em>, <em>327</em>(3), 735-753. (<a href='https://doi.org/10.1016/j.ejor.2025.05.033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the Two-Dimensional Knapsack Problem with Guillotine Constraints, which is a famous NP -hard problem and is commonly encountered in industries where rectangular raw materials are cut into smaller pieces using guillotine cuts. We propose an efficient exact algorithm (EATKG) to solve this problem, which incorporates advanced techniques and novel elements, including an adapted preprocessing procedure, two enhanced upper bounds, an improved bidirectional tree search approach, and an iterative combination enumeration process. These components effectively balance the computation of upper and lower bounds and handle the issue of memory overflow. We extensively evaluate EATKG on eight classic benchmark sets, comprising 1,277 instances. Our algorithm solves 87% of the instances with an average computing time of 7 seconds, and 93% with an average computing time of 49 seconds. Moreover, EATKG efficiently solves nearly all small- and medium-sized instances, providing better solutions for 46 instances and tighter upper bounds for 109 instances. These results demonstrate the superior performance of our algorithm compared to leading algorithms. To support future research, we have made the source code for the proposed algorithm, along with the corresponding instance data, aggregated results, and detailed solutions, publicly available. This will facilitate further investigations and comparisons of solution methods.},
  archive      = {J_EJOR},
  author       = {Sunkanghong Wang and Roberto Baldacci and Qiang Liu and Lijun Wei},
  doi          = {10.1016/j.ejor.2025.05.033},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {735-753},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {EATKG: An open-source efficient exact algorithm for the two-dimensional knapsack problem with guillotine constraints},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Greedy randomized adaptive search procedures with path relinking. an analytical review of designs and implementations. <em>EJOR</em>, <em>327</em>(3), 717-734. (<a href='https://doi.org/10.1016/j.ejor.2025.02.022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a comprehensive review of the Greedy Randomized Adaptive Search Procedure (GRASP) metaheuristic and its hybridization with Path Relinking (PR). GRASP with PR has become a widely adopted approach for solving hard optimization problems since its proposal in 1999. The paper covers the historical development of GRASP with PR and its theoretical foundations, as well as recent advances in its implementation and application. The review includes a careful analysis of PR variants, paying special attention to memory-based and randomized designs, with a total of ten different implementations. It identifies the design questions that are still open in the scientific literature. The experimental section applies advanced PR implementations on two well-known combinatorial optimization problems, linear ordering and max-cut, in an effort to answer these open questions. The paper also explores the hybridization of PR and other metaheuristics, such as tabu search, scatter search, and random-keys genetic algorithms. Overall, this review provides valuable insights for researchers and practitioners seeking to implement GRASP with PR for solving optimization problems.},
  archive      = {J_EJOR},
  author       = {Manuel Laguna and Rafael Martí and Anna Martínez-Gavara and Sergio Pérez-Peló and Mauricio G.C. Resende},
  doi          = {10.1016/j.ejor.2025.02.022},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {717-734},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Greedy randomized adaptive search procedures with path relinking. an analytical review of designs and implementations},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The devil in the details: Dynamic prediction of loan portfolio profitability with macroeconomic drivers through multi-state modelling. <em>EJOR</em>, <em>327</em>(2), 703-715. (<a href='https://doi.org/10.1016/j.ejor.2025.07.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In typical loan portfolios such as mortgages and credit cards, many accounts often experience different stages of delinquency before eventually recovering, fully repaying their balance, or defaulting. From the lender perspective, these events, coupled with the state of the economy, can affect cash-flow and profitability significantly. This paper presents a novel framework for dynamic monitoring future expected profit margins and cash flows of loan accounts, taking into account (i) individual risk profiles, (ii) macroeconomic trends, and (iii) transitions between different stages of delinquency. We make three contributions. First, we show a method to predict future cash flows and profit margins over the life of a loan where the predicted probabilities of an account jumping between delinquency states are obligor specific, time varying, adjusted to be competing risks and dependent on predictions from a macroeconomic model. This model is much more comprehensive model than those in the literature. Second, we investigate different methods to compute optimised cut-offs to be used with the transition probabilities to predict jumps an account is expected to make between different states of delinquency. Third, we illustrate the method using a large sample of 30-year term mortgages and show the expected profit margins for segments of the portfolio. The method will be particularly useful to lenders, who must comply with IFRS9 or CECL.},
  archive      = {J_EJOR},
  author       = {Viani B. Djeundje and Jonathan Crook and Galina Andreeva},
  doi          = {10.1016/j.ejor.2025.07.008},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {703-715},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The devil in the details: Dynamic prediction of loan portfolio profitability with macroeconomic drivers through multi-state modelling},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bankruptcy prediction with fractional polynomial transformation of financial ratios. <em>EJOR</em>, <em>327</em>(2), 690-702. (<a href='https://doi.org/10.1016/j.ejor.2025.07.036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that simple nonlinear transformations of financial ratios, within a multivariate fractional polynomial approach, yield substantial improvements in bankruptcy prediction. The approach selects optimal power functions balancing parsimony and complexity. Focusing on a dataset comprising of non-financial firms, we develop a parsimonious nonlinear logit model with minimal parameter specification and clear interpretability, outperforming linear logit models. The model improves the in-sample fit, while out-of-sample it significantly reduces costly misclassification errors and improves discriminatory power. Similar insights are obtained when applying fractional polynomials on a secondary dataset consisting of banking firms. Interestingly, the fractional polynomial model compares favourably with other nonlinear models. By simulating a competitive loan market, we demonstrate that the bank using the fractional polynomial model builds a higher-quality loan portfolio, resulting in superior risk-adjusted profitability compared to banks employing alternative models.},
  archive      = {J_EJOR},
  author       = {Zenon Taoushianis},
  doi          = {10.1016/j.ejor.2025.07.036},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {690-702},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bankruptcy prediction with fractional polynomial transformation of financial ratios},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entrepreneurs’ optimal decisions in equity crowdfunding campaigns. <em>EJOR</em>, <em>327</em>(2), 673-689. (<a href='https://doi.org/10.1016/j.ejor.2025.07.004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equity crowdfunding is a method of financing an initiative whereby an entrepreneur sells shares in her firm to a group of people (the crowd) on a dedicated platform. Understanding the forces that shape the behavior of both buyers in the crowd and entrepreneurs in equity crowdfunding platforms can help design more efficient platforms and increase the welfare of all participants. We therefore develop a common value sequential crowdfunding game-theoretic model, where the entrepreneur sells a percentage of her firm in order to raise money for its establishment and then shares the future value of the firm with the crowd. Buyers on the platform who visit the campaign decide whether or not to invest in it. Each buyer’s decision depends on the amount that has already been invested before him and on his own knowledge about the firm and the market in which it operates (which we model as a noisy signal that he obtains regarding the true value of the firm). By offering a different percentage in the firm, the entrepreneur leads the crowd to a different equilibrium. We characterize these equilibria and then analyze the entrepreneur’s decision. We show that the entrepreneur’s optimal percentage she offers for sale is non monotonic in the ex-ante probability of success. This is in-line with recent empirical findings. We further show that when buyers’ signals are very noisy, the entrepreneur may prefer buyers that have a less accurate signal regarding the true value of the firm over buyers with a more accurate signal.},
  archive      = {J_EJOR},
  author       = {Hana Tzur and Ella Segev},
  doi          = {10.1016/j.ejor.2025.07.004},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {673-689},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Entrepreneurs’ optimal decisions in equity crowdfunding campaigns},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision-making framework for supporting an equitable global vaccine distribution under humanitarian perspectives. <em>EJOR</em>, <em>327</em>(2), 655-672. (<a href='https://doi.org/10.1016/j.ejor.2025.05.007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is motivated by the occurrence of vaccine nationalism in the setting of pandemics. Certain high-income countries (HICs) aggressively accumulated vaccinations while showing little concern for the vaccination challenges faced by low- and middle- income countries. This disparity fosters the proliferation and mutation of viruses, thus risking the global population’s health and welfare. Hence, we create a data-driven framework to tackle this humanitarian problem by facilitating the provision of vaccines. The framework comprises of two models: a network model named multi-strain Susceptible–Vaccinated–Infected–Removed–Susceptible and a vaccine distribution model with equitable constraints. The latter also encompasses the diverse uncertainty associated with vaccination hesitancy in different countries, in order to avoid potential wastage of resources. The vaccine distribution from our framework is based on greedy thought, thus enabling decision-makers to actively engage in the real-time vaccine allocation process. When the suggested framework is applied to the scenario of the COVID-19 pandemic, the simulation results indicate that fair distributions could accelerate the end of the pandemic. Additional scenarios, such as equitable levels and traveling intensity, are also examined in the sensitivity analysis. The progression of the epidemic under vaccine nationalism is moreover simulated to highlight its harmfulness and validate the efficacy of our framework. We demonstrate that the inequitable advantage experienced by HICs is temporary, as HICs are bound to suffer from virus variants in due course when vaccinations become less efficacious against them.},
  archive      = {J_EJOR},
  author       = {Jian Zhou and Junyang Cai and Athanasios A. Pantelous and Zhen Li and Musen Kingsley Li},
  doi          = {10.1016/j.ejor.2025.05.007},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {655-672},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A decision-making framework for supporting an equitable global vaccine distribution under humanitarian perspectives},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effects of geopolitical strain on global pharmaceutical supply chain design and drug shortages. <em>EJOR</em>, <em>327</em>(2), 641-654. (<a href='https://doi.org/10.1016/j.ejor.2025.05.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging geopolitical risks have begun to threaten global supply chains, including those that produce life-saving drugs. Export bans may prevent a company from shipping products internationally, and it is unclear how these new dynamics may affect company plans and persistent, worldwide drug shortages. To address these questions, we present a global pharmaceutical supply chain design model that considers the risk of export bans that are induced by supplier capacity disruptions and corresponding price increases. The model takes the company’s perspective as a decision-maker looking to locate plants and distribute drugs globally. It is a two-stage stochastic program that includes uncertainty in capacity, ability-to-export, and demand. The model is solved by integrating the Sample Average Approximation and L-shaped methods. We present conditions related to when demand will be met and a case study of a generic oncology drug. We find that preparing for geopolitical strain may increase resilience and profits as well as reduce shortages in the short term. At baseline, expected global shortages are high (17.2%) with disparities across country income levels (0.3%, 0.8%, 87.2%, and 87.6% for high, upper-middle, lower-middle, and low income countries, respectively). Pricing policies may improve drug access overall, back-shoring may slightly improve access for the country where it is implemented, and bilateral alliances may not be effective at improving access.},
  archive      = {J_EJOR},
  author       = {Martha L. Sabogal De La Pava and Emily L. Tucker},
  doi          = {10.1016/j.ejor.2025.05.002},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {641-654},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Effects of geopolitical strain on global pharmaceutical supply chain design and drug shortages},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling consumer stickiness in online platform pricing. <em>EJOR</em>, <em>327</em>(2), 623-640. (<a href='https://doi.org/10.1016/j.ejor.2025.04.041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the operational practice of JD.com, China’s largest online retailer, our study delves into the phenomenon of consumer stickiness. It measures the probability that consumers will remain loyal to a specific product, refraining from purchasing alternatives, even in the temporary absence of the focal product. Based on real data from JD.com, we show that consumer stickiness has a significantly positive impact on online sales, which is used to justify our formulation of the demand function in theoretical analysis. Specifically, we adopt a game-theoretical approach to analyze the impact of consumer stickiness on two-period pricing strategies in monopolistic and competitive markets. Findings reveal that incorporating consumer stickiness leads to differentiated pricing strategies, with low-quality products reducing prices in the second period and high-quality products increasing them. Stickiness enhances total sales in monopolistic markets with high-quality products and in competitive markets with high market potential. Furthermore, stickiness contributes to increased revenue and improvements in consumer surplus and social welfare under large or small market conditions, underscoring its strategic importance for pricing and welfare outcomes. These findings contribute valuable insights into the dynamics of online platform competition and highlight the strategic implications of consumer stickiness in influencing pricing and platform revenue.},
  archive      = {J_EJOR},
  author       = {Nina Yan and Tingting Tong and Gangshu (George) Cai},
  doi          = {10.1016/j.ejor.2025.04.041},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {623-640},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modeling consumer stickiness in online platform pricing},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning for the real-time inventory rack storage assignment and replenishment problem. <em>EJOR</em>, <em>327</em>(2), 606-622. (<a href='https://doi.org/10.1016/j.ejor.2025.05.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The e-commerce industry is quickly transforming towards more automation and technological advancements. With the growing intricacy of warehouse operations, there is a need for control systems that can efficiently handle this complexity. This study considers a Robotic Mobile Fulfillment System (RMFS), a semi-automated warehousing system. This system employs autonomous mobile robots (AMRs) to retrieve inventory racks from the storage area; this way, human activity is eliminated within the storage area itself. The fleet of robots both store and retrieve the inventory racks to either workstations, where human pickers are stationed that pick items from the racks, or replenishment stations, where depleted inventory racks can be restocked with items. An attractive characteristic of the RMFS is that it dynamically changes the positioning of the inventory racks based on the frequency of inventory rack requests and the state of their stock levels. The optimization objective considered in this study for the dynamic positioning problem of the racks within the storage area is to minimize the average cycle time of the mobile robots to perform retrieval and replenishment activities. We propose a deep reinforcement learning approach to train a decision-making agent to learn a policy for the storage assignment and replenishment of inventory racks. The learned policy is compared to the commonly used decision rules in the academic literature on this problem. The experimental results show the potential benefits of training an agent to learn a storage and replenishment policy. Cycle time improvements up to 5.4 % can be achieved over the best-performing decision rules. This research contributes to advancing the understanding of intelligent storage assignment and replenishment strategies for the real-time decision-making process within an RMFS.},
  archive      = {J_EJOR},
  author       = {Sander Teck and Tú San Phạm and Louis-Martin Rousseau and Pieter Vansteenwegen},
  doi          = {10.1016/j.ejor.2025.05.008},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {606-622},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Deep reinforcement learning for the real-time inventory rack storage assignment and replenishment problem},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying hidden critical elements in interconnected systems: An influence dynamics analysis approach considering structural constraints. <em>EJOR</em>, <em>327</em>(2), 592-605. (<a href='https://doi.org/10.1016/j.ejor.2025.05.038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The systems analysis field has traditionally focused on identifying the essential elements within an interconnected system and analyzing the cause-and-effect relationships among them. However, most decision-making methods in system analysis have been one-sided. They primarily rely on the interactions between elements to make decisions, neglecting to account for the non-uniform influence attenuation among elements and unequal importance diffusion. Furthermore, these two factors are closely tied to the topological structure of systems, which has been an often-overlooked aspect in previous research, leading to inaccurate identification and omission of hidden key elements. In response to these challenges, this paper introduces a novel method called SIDA ( S tructural-constrained I nfluence D ynamic A nalysis). We utilize structural constraint coefficients derived from structural hole theory to describe the non-uniform attenuation. Furthermore, we integrate an influence and distance-weighted PageRank algorithm to manage the unequal importance diffusion taking into account both the influence and the distance between elements within systems. We validated our proposed method through a comprehensive analysis of a pharmaceutical industry ecosystem, comparing its performance with previous approaches to validate its effectiveness and practicality. The case study results demonstrate that SIDA produces more reasonable element analysis and ranking outcomes.},
  archive      = {J_EJOR},
  author       = {Caibo Zhou and Wenyan Song and Huiwen Wang and Lihong Wang},
  doi          = {10.1016/j.ejor.2025.05.038},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {592-605},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Identifying hidden critical elements in interconnected systems: An influence dynamics analysis approach considering structural constraints},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust binary and multinomial logit models for classification with data uncertainties. <em>EJOR</em>, <em>327</em>(2), 577-591. (<a href='https://doi.org/10.1016/j.ejor.2025.05.013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary logit (BNL) and multinomial logit (MNL) models are the two most widely used discrete choice models for travel behavior modeling and prediction. However, in many scenarios, the collected data for those models are subject to measurement errors. Previous studies on measurement errors mostly focus on “better estimating model parameters” with training data. In this study, we focus on using BNL and MNL for classification problems, that is, to “better predict the behavior of new samples” when measurement errors occur in testing data. To this end, we propose a robust BNL and MNL framework that is able to account for data uncertainties in both features and labels. The models are based on robust optimization theory that minimizes the worst-case loss over a set of uncertainty data scenarios. Specifically, for feature uncertainties, we assume that the ℓ p -norm of the measurement errors in features is smaller than a pre-established threshold. We model label uncertainties by limiting the number of mislabeled choices to at most Γ . Based on these assumptions, we derive a tractable robust counterpart. The derived robust-feature BNL and the robust-label MNL models are exact. However, the formulation for the robust-feature MNL model is an approximation of the exact robust optimization problem. An upper bound of the approximation gap is provided. We prove that the robust estimators are inconsistent but with a higher trace of the Fisher information matrix. They are preferred when out-of-sample data has errors due to the shrunk scale of the estimated parameters. The proposed models are validated in a binary choice data set and a multinomial choice data set, respectively. Results show that the robust models (both features and labels) can outperform the conventional BNL and MNL models in prediction accuracy and log-likelihood. We show that the robustness works like “regularization” and thus has better generalizability.},
  archive      = {J_EJOR},
  author       = {Baichuan Mo and Yunhan Zheng and Xiaotong Guo and Ruoyun Ma and Jinhua Zhao},
  doi          = {10.1016/j.ejor.2025.05.013},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {577-591},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust binary and multinomial logit models for classification with data uncertainties},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalarisation-based risk concepts for robust multi-objective optimisation. <em>EJOR</em>, <em>327</em>(2), 559-576. (<a href='https://doi.org/10.1016/j.ejor.2025.04.054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust optimisation is a well-established framework for optimising functions in the presence of uncertainty. The inherent goal of this problem is to identify a collection of inputs whose outputs are both desirable for the decision maker, whilst also being robust to the underlying uncertainties in the problem. In this work, we study the multi-objective case of this problem. We identify that the majority of all robust multi-objective algorithms rely on two key operations: robustification and scalarisation. Robustification refers to the strategy that is used to account for the uncertainty in the problem. Scalarisation refers to the procedure that is used to encode the relative importance of each objective to a scalar-valued reward. As these operations are not necessarily commutative, the order that they are performed in has an impact on the resulting solutions that are identified and the final decisions that are made. The purpose of this work is to give a thorough exposition on the effects of these different orderings and in particular highlight when one should opt for one ordering over the other. As part of our analysis, we showcase how many existing risk concepts can be integrated into the specification and solution of a robust multi-objective optimisation problem. Besides this, we also demonstrate how one can principally define the notion of a robust Pareto front and a robust performance metric based on our “robustify and scalarise” methodology. To illustrate the efficacy of these new ideas, we present two insightful case studies which are based on real-world data sets.},
  archive      = {J_EJOR},
  author       = {Ben Tu and Nikolas Kantas and Robert M. Lee and Behrang Shafei},
  doi          = {10.1016/j.ejor.2025.04.054},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {559-576},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scalarisation-based risk concepts for robust multi-objective optimisation},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A structured framework for supporting the participatory development of consensual scenario narratives. <em>EJOR</em>, <em>327</em>(2), 540-558. (<a href='https://doi.org/10.1016/j.ejor.2025.04.048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High levels of uncertainty faced by decision makers can be alleviated by characterizing multiple possible ways in which the future might unfold with scenario narratives. Aiming at describing alternative plausible chains of outcomes of key uncertainty factors, scenario narratives are often associated with graphical networks describing the relationships between the outcomes of the factors. We present a participatory framework for bottom-up development of such networks, the PACNAP (PArticipatory development of Consensual narratives through Network Aggregation and Pruning) framework. In this framework, relationships of influence between factor outcomes are judged by a group of scenario process participants. We develop an optimization model for pruning an aggregated graph based on these judgments. The model selects those edges of the aggregate graph that the participants most agree upon and can be tailored to identify compact graphs of varying degrees of cyclicity. As a result, a variety of graphical representations of varying structural richness can be explored to arrive at a succinct representation of a consensus view on the structure of a joint narrative. To this end, the main formal results are the representation of the participants’ agreement lexicographically in a linear objective function of a 0-1 program, and the translation of the requisites of the compactness and cyclicity of the resulting pruned graphs into a set of network flow constraints. The problem of identifying a consensus graphical representation is a general one and our graph pruning method has application potential outside the specific domain of narrative development as well.},
  archive      = {J_EJOR},
  author       = {Teemu Seeve and Eeva Vilkkumaa and Alec Morton},
  doi          = {10.1016/j.ejor.2025.04.048},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {540-558},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A structured framework for supporting the participatory development of consensual scenario narratives},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Index policies for campaign promotion strategies in reward-based crowdfunding. <em>EJOR</em>, <em>327</em>(2), 515-539. (<a href='https://doi.org/10.1016/j.ejor.2025.07.020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reward-based crowdfunding plays a crucial role in fundraising for start-up entrepreneurs. Recent studies, however, have shown that the actual success rate of fundraising projects is surprisingly low across multiple crowdfunding platforms. This paper considers crowdfunding platforms’ decision-making of selecting projects to highlight on their homepage to boost the chance of success for projects, and investigates promotion strategies aiming at maximizing platforms’ revenue over a fixed period. We characterize backers’ investment decisions by a discrete choice model with a time-varying coefficient of herding effect, and formulate the problem as a stochastic dynamic program, which is however computationally intractable. To address this issue, we follow the Whittle’s Restless Bandit approach to decompose the problem into a collection of single-project problems and prove indexability for each project under some mild conditions. We show that the index values of the proposed index policy can be directly derived from the value-to-go of each project under the non-promotion policy, which is calculated recursively offline with a linear-time complexity. Moreover, to further enhance the scalability we develop a closed-form approximation to calculate the index values online. To the best of our knowledge, this work is the first in the literature to develop index policies for campaign promotions in reward-based crowdfunding. It is also the first attempt to provide indexability analysis of bi-dimensional restless bandits coupled by not only resource but also demand. Extensive numerical experiments show that the proposed index policies outperform the other benchmark heuristics in most of the scenarios considered.},
  archive      = {J_EJOR},
  author       = {Chenguang Wang and Dong Li and Baibing Li},
  doi          = {10.1016/j.ejor.2025.07.020},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {515-539},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Index policies for campaign promotion strategies in reward-based crowdfunding},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Singular control in a cash management model with ambiguity. <em>EJOR</em>, <em>327</em>(2), 500-514. (<a href='https://doi.org/10.1016/j.ejor.2025.07.023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a singular control model of cash reserve management, driven by a diffusion under ambiguity. The manager is assumed to have maxmin preferences over a set of priors characterized by κ -ignorance. A verification theorem is established to determine the firm’s cost function and the optimal cash policy; the latter taking the form of a control barrier policy. In a model driven by arithmetic Brownian motion, we use Dynkin games to show that an increase in ambiguity leads to higher expected costs under the worst-case prior and a narrower inaction region. The latter effect can be used to provide an ambiguity-driven explanation for observed cash management behavior. Our findings can be applied to broader applications of singular control in managing inventories under ambiguity.},
  archive      = {J_EJOR},
  author       = {Arnon Archankul and Giorgio Ferrari and Tobias Hellmann and Jacco J.J. Thijssen},
  doi          = {10.1016/j.ejor.2025.07.023},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {500-514},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Singular control in a cash management model with ambiguity},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fair and profitable even when serving different customer classes: How pricing and lead-time quotation can help. <em>EJOR</em>, <em>327</em>(2), 491-499. (<a href='https://doi.org/10.1016/j.ejor.2025.05.034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we model a production/inventory system serving two classes of customers with a single type of product. Demand from each class depends on the price and the lead-time quoted. One class comprises customers sensitive to delays who are willing to pay higher prices for shorter lead times. Customers of the other class are price sensitive who can tolerate waiting longer for product delivery if they are charged lower prices. By modeling the system as an M n / M / 1 type make-to-stock queue, we propose four fair policies. These fair policies assure that customers are charged lower prices when they are quoted longer lead times and a high proportion of the deliveries is made during the quoted lead times. Two FCFS (first-come, first-served) policies ignore class differences. Two multilevel rationing (MR) policies prioritize the delay-sensitive class over the other. While determining the price and the lead-time, the refined FCFS and MR policies additionally consider the order in which a customer enters the queue. With a numerical study, we explore when the MR policies taking customer differences into consideration are more profitable than the FCFS policies.},
  archive      = {J_EJOR},
  author       = {Sinan Dede and Barış Balcıog̃lu},
  doi          = {10.1016/j.ejor.2025.05.034},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {491-499},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fair and profitable even when serving different customer classes: How pricing and lead-time quotation can help},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nested branch-and-price for multi-mode nanosatellite task scheduling with interior-point regularization and GPU acceleration. <em>EJOR</em>, <em>327</em>(2), 469-490. (<a href='https://doi.org/10.1016/j.ejor.2025.05.020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capabilities of nanosatellites are constrained by their limited power availability and size, which poses challenges for mission planning and operation. This study addresses the Offline Nanosatellite Task Scheduling (ONTS) problem by introducing multi-mode capability into the scheduling process, enhancing its relevance for more realistic, adaptable, and robust mission planning. We propose a Mixed-Integer Linear Programming (MILP) model for this problem that accommodates conventional resource and temporal constraints across multiple operational modes. The MILP model is improved with valid inequalities incorporating auxiliary variables alongside multi-mode cover cuts enhanced with lifting procedures. Furthermore, we introduce a Nested Branch-and-Price (NB&P) algorithm that enhances the standard branch-and-price approach by incorporating a dual-level optimization structure for handling hierarchical scheduling. This dual framework simultaneously facilitates job allocation and mode selection, employing dynamic column generation influenced by dual prices to progressively refine task schedules towards optimality. Additionally, enhanced interior-point methods have been effectively adapted for tackling large-scale instances, aligned with a GPU-accelerated dynamic programming solution utilizing CUDA technology. Empirical evaluations show that the modified MILP approach, combined with the NB&P algorithm, significantly improves computational efficiency, demonstrating up to a 629-fold reduction in computation time and consistently achieving zero-gap solutions.},
  archive      = {J_EJOR},
  author       = {Laio Oriel Seman and Cezar Antônio Rigo and Eduardo Camponogara and Pedro Munari},
  doi          = {10.1016/j.ejor.2025.05.020},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {469-490},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nested branch-and-price for multi-mode nanosatellite task scheduling with interior-point regularization and GPU acceleration},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An exact algorithm for fleet co-deployment and slot co-chartering in a sustainable shipping alliance under emissions trading system. <em>EJOR</em>, <em>327</em>(2), 450-468. (<a href='https://doi.org/10.1016/j.ejor.2025.05.021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shipping alliances have emerged as a cooperation platform between independent shipping companies, aiming to enhance customer satisfaction and exploit the economies of scale through capacity and information sharing. A sustainable shipping alliance should operate in a profitable, fair and environmentally friendly way under emerging Emissions Trading System (ETS). A non-convex mixed-integer nonlinear programming model is suggested to jointly optimize the fleet co-deployment in the network, sailing speed in each shipping leg, schedule design for each shipping service, and the slot allocation and co-chartering for each alliance member. These decisions ultimately determine each company’s carbon emissions. Under the ETS, companies are charged for emissions that exceed their allowances, while any surplus allowances can be traded for revenue in carbon markets. In addition to maximizing the alliance’s total profit, this study minimizes profit margin variation among members in proportion to their investment, promoting fairness in a novel way. A tailored spatial branch-and-bound (SB&B) algorithm is developed to deliver the global optimal solution for the problem. Novel problem relaxation and branching strategies are suggested based on the structure of the programming model. The SB&B algorithm significantly outperforms an existing non-convex nonlinear solver. Compared to case which do not consider slot co-chartering and fairness, our study improves total profit by 3.13 %, meets 0.52 % more freight demand, and ensures a fairer profit distribution on average. Under the ETS, carbon emissions can be reduced by up to 54.3 %, with smaller ships being used and average sailing speeds decreasing as the emission trading price rises from $0/tonne to $300/tonne.},
  archive      = {J_EJOR},
  author       = {Yadong Wang and Shenghui Zhu and Çağatay Iris},
  doi          = {10.1016/j.ejor.2025.05.021},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {450-468},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An exact algorithm for fleet co-deployment and slot co-chartering in a sustainable shipping alliance under emissions trading system},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lagrangian relaxation and branch-and-price algorithm for resource assignment problem in divisional seru systems. <em>EJOR</em>, <em>327</em>(2), 432-449. (<a href='https://doi.org/10.1016/j.ejor.2025.02.038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses seru formation problem in divisional seru production system (SPS), which focuses on job-seru assignment, worker-seru assignment and operation-worker assignment in each seru. The problem is formulated as a mixed-integer nonlinear programming (MINLP) model with the objective of minimizing training and processing costs of workers. Once the job-seru assignment is determined, we employ a mixed-integer linear programming (MILP) model to describe worker-seru and operation-worker assignment in each seru. To tackle this challenge, we propose a two-phase approach to deal with this problem. In the first phase, we propose a Lagrangian relaxation algorithm to determine job-seru assignment, this approach can quickly compute the lower bound of the MILP by enumerating all possible job-seru assignments and eliminate unpromising ones. Subsequently, in the second phase, for each remaining job-seru assignment, we develop a branch-and-price algorithm to solve the MILP exactly. It is in the branch-and-bound framework, each node is solved by column generation (CG) algorithm. In CG, we apply a Dantzig Wolfe decompose to divide the original problem into a master problem and the pricing problems. A novel label-setting algorithm is employed based on the characteristics of the pricing problem. Additionally, we introduce effective acceleration strategies such as dominance rules and heuristic pricing. It facilitates the selection of the optimal job-seru assignment and obtains the optimal solution for the entire problem. Finally, extensive experiments validate the effectiveness and superiority of our proposed algorithm. We also discuss the impact of selected parameters on the cost and offer managerial insights.},
  archive      = {J_EJOR},
  author       = {Shiming Chen and Chengkuan Zeng and Yu Zhang and Jiafu Tang and Chongjun Yan},
  doi          = {10.1016/j.ejor.2025.02.038},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {432-449},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Lagrangian relaxation and branch-and-price algorithm for resource assignment problem in divisional seru systems},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The generalized assignment problem with fixed processing times and uniform processing costs to minimize total cost. <em>EJOR</em>, <em>327</em>(2), 420-431. (<a href='https://doi.org/10.1016/j.ejor.2025.05.031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generalized assignment problem (GAP) is a foundational problem in operations research, but its progress is quite limited. In this paper we study an important special case of the GAP with fixed processing times and uniform processing costs, where the upper bound of the makespan is given, and the objective to minimize the total processing cost. We prove a critical technical lemma, which enables us to develop an approximation algorithm with an improved performance ratio of 1 + ( γ − 1 ) ϵ , where ϵ ∈ ( 0 , 1 3 ] can be any small constant and γ is the maximum to the minimum processing cost per unit time on a machine, improving on the existing performance ratio of 2 + γ 3 in the literature. For the general problem when γ is arbitrarily, we show that it is NP-hard to approximate within a constant performance ratio. For the special case when γ is a constant, we present an efficient PTAS (polynomial time approximation scheme) by applying the technical lemma. Our techniques and results bring new insights into the GAP research.},
  archive      = {J_EJOR},
  author       = {Weidong Li and Jinwen Ou},
  doi          = {10.1016/j.ejor.2025.05.031},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {420-431},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The generalized assignment problem with fixed processing times and uniform processing costs to minimize total cost},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using helical polyhedron for online irregular strip packing problem with free rotations. <em>EJOR</em>, <em>327</em>(2), 407-419. (<a href='https://doi.org/10.1016/j.ejor.2025.05.019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The packing of irregular pieces is widely applied across various industries including metalworking, woodworking, clothing manufacturing, and leather goods production. Allowing rotation during packing, particularly in scenarios where materials are homogeneous, can yield superior outcomes by reducing material wastage, thus contributing to cost-saving and environmental preservation. This study investigates the online irregular strip packing problem allowing free rotation, inspired by a leather handicraft workshop, where orders arrive infrequently and vary widely in content. The objective is to minimize the sheet length utilized. Most existing literature models irregular strip packing problem with rotation as a nonlinear programming problem, making it challenging to obtain the optimal position and orientation of every single input piece despite advancements in optimization solvers. In this paper, a novel approach is proposed to solve online irregular strip packing problem with rotation. We rotate the input polygon while simultaneously translating it along the z -axis, forming a helix. Thus, the problem of selecting the rotation angle is transformed into determining the z -coordinate of the helix’s cross-section. Subsequently, meshing the helix into a polyhedron allows us to propose a mixed integer linear formulation based on its Minkowski sum with other polygons. To ensure guaranteed optimality, we introduce a branch-and-bound algorithm tailored to the problem. Extensive numerical experiments indicate the effectiveness and competitiveness of our algorithm over state-of-the-art nonlinear formulations for irregular strip packing problem with rotation.},
  archive      = {J_EJOR},
  author       = {Yulin Liu and Li Zheng},
  doi          = {10.1016/j.ejor.2025.05.019},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {407-419},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using helical polyhedron for online irregular strip packing problem with free rotations},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Presolving and cutting planes for the generalized maximal covering location problem. <em>EJOR</em>, <em>327</em>(2), 394-406. (<a href='https://doi.org/10.1016/j.ejor.2025.05.017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the generalized maximal covering location problem (GMCLP) which establishes a fixed number of facilities to maximize the weighted sum of the covered customers, allowing customer weights to be positive or negative. Due to the huge number of linear constraints to model the covering relations between the candidate facility locations and customers, and particularly the poor linear programming (LP) relaxation, the GMCLP is extremely difficult to solve by state-of-the-art mixed integer programming (MIP) solvers. To improve the computational performance of MIP-based approaches for solving GMCLPs, we propose customized presolving and cutting plane techniques, which are isomorphic aggregation, dominance reduction, and two-customer inequalities. The isomorphic aggregation and dominance reduction can not only reduce the problem size but also strengthen the LP relaxation of the MIP formulation of the GMCLP. The two-customer inequalities can be embedded into a branch-and-cut framework to further strengthen the LP relaxation of the MIP formulation on the fly. By extensive computational experiments, we show that all three proposed techniques can substantially improve the capability of MIP solvers in solving GMCLPs. In particular, for a testbed of 40 instances with identical numbers of customers and candidate facility locations in the literature, the proposed techniques enable us to provide optimal solutions for 13 previously unsolved benchmark instances; for a testbed of 336 instances where the number of customers is much larger than the number of candidate facility locations, the proposed techniques can turn most of them from intractable to easily solvable.},
  archive      = {J_EJOR},
  author       = {Wei Lv and Cheng-Yang Yu and Jie Liang and Wei-Kun Chen and Yu-Hong Dai},
  doi          = {10.1016/j.ejor.2025.05.017},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {394-406},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Presolving and cutting planes for the generalized maximal covering location problem},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fifty years of research in scheduling — Theory and applications. <em>EJOR</em>, <em>327</em>(2), 367-393. (<a href='https://doi.org/10.1016/j.ejor.2025.01.034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an overview of scheduling research done over the last half century. The main focus is on what is typically referred to as machine scheduling. The first section describes the general framework for machine scheduling models and introduces the notation. The second section discusses the basic deterministic machine scheduling models, including single machine, parallel machines, flow shops, job shops, and open shops. The third section describes more elaborate models, including multi-objective and multi-agent scheduling models, scheduling with controllable processing times, scheduling with rejection, just-in-time scheduling, scheduling with due date assignments, time-dependent scheduling, and scheduling with batching and setups. The two subsequent sections consider scheduling under uncertainty; section four goes into online and robust scheduling and section five covers stochastic scheduling models. The next section describes a variety of important scheduling applications, including applications in manufacturing, in services, and in information processing. The last section presents the main conclusions and discusses future research directions.},
  archive      = {J_EJOR},
  author       = {Alessandro Agnetis and Jean-Charles Billaut and Michael Pinedo and Dvir Shabtay},
  doi          = {10.1016/j.ejor.2025.01.034},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {367-393},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fifty years of research in scheduling — Theory and applications},
  volume       = {327},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="eswa">ESWA - 158</h2>
<ul>
<li><details>
<summary>
(2026). Technology foresight in china’s industrial robotics with MLWS-TF: A machine learning and weak signal-based system. <em>ESWA</em>, <em>298</em>, 129779. (<a href='https://doi.org/10.1016/j.eswa.2025.129779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technology foresight analyses technological trends and potential impacts to provide strategic guidance. However, existing methods either rely on experts to discover emerging directions leading to subjective bias or adopt machine learning to predict without explanation. We propose a Machine Learning and Weak Signal-based Technology Forecasting System (MLWS-TF), which is entirely data-driven to enhance the objectivity of technology foresight and can interpret emerging directions through weak signals. The system adopts a two-phase machine learning model (2P-ML), the first phase identifies papers related to the robotics field, while the second further classifies them into fine-grained research directions. Keywords are extracted from the papers using a Word2Vec-based approach, and a three-dimensional signal classification method (DVI) is developed to quantify the foresight value of keywords across the Diffusion, Visibility, and Impact dimensions, identifying weak signals for technology forecasting. Experiments evaluate various machine learning algorithms, and XGBoost outperforms in constructing the 2P-ML classifier. The model achieved over 90% accuracy, demonstrating its effectiveness in identifying the theme of scientific documents based on textual features. For each research theme, the DVI provides a more comprehensive assessment of signal strength to detect weak signals. Finally, MLWS-TF analyses the growth potential of themes and successfully identifies critical development directions. Our approach offers a novel automated technology foresight system, which completely avoids the subjectivity and dependence on expert judgment that characterize traditional technology foresight approaches, and extends weak signal theory by introducing the Impact dimension to evaluate signal strength.},
  archive      = {J_ESWA},
  author       = {Ruihan Wang and Yuhao Zhu},
  doi          = {10.1016/j.eswa.2025.129779},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129779},
  shortjournal = {Expert Syst. Appl.},
  title        = {Technology foresight in china’s industrial robotics with MLWS-TF: A machine learning and weak signal-based system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding. <em>ESWA</em>, <em>298</em>, 129766. (<a href='https://doi.org/10.1016/j.eswa.2025.129766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reversible data hiding in encrypted images (RDHEI) is a promising technique for multimedia cloud computing that enables the embedding of secret data into encrypted images while preserving confidentiality. However, the existing RDHEI algorithms fail to meet the high-security requirements of distributed storage systems in the cloud. Although, secret sharing based RDHEI (SS-RDHEI) may solve this problem, the current methods have weakness such as insufficient embedding capacity and unsatisfactory balance between image security and redundancy. To enhance the algorithm’s ability to carry information, this paper proposes a SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding. Firstly, pixel-difference preservation based modulation (PDPM) ensures secure encryption by modifying all pixels except for a reference block, minimizing damage; moreover, an improved block-level pixel predictor enhances carrier redundancy. Secondly, auxiliary data free coding (ADFC) marks prediction errors directly in the binary sequence of the original pixel without auxiliary information while maintaining accuracy, and reduces the impact of different textures on embedding performance byselecting optimal parameters for each share image. Finally, by combining PDPM with secret sharing, it achieves independent embedding for multiple data hiders while ensuring fair information embedding. Experimental results demonstrate that the proposed algorithm outperforms existing state-of-the-art schemes in terms of information-carrying capability.},
  archive      = {J_ESWA},
  author       = {Zhihua Gan and Zongwei Tang and Yalin Song and Gongyao Cao and Xiuli Chai and Yushu Zhang},
  doi          = {10.1016/j.eswa.2025.129766},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129766},
  shortjournal = {Expert Syst. Appl.},
  title        = {SS-RDHEI for embedding capacity enhancement by PDPM and auxiliary data free coding},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quadrotor navigation considering attitude: A deep reinforcement learning method using tangent path rewards. <em>ESWA</em>, <em>298</em>, 129762. (<a href='https://doi.org/10.1016/j.eswa.2025.129762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous navigation of quadrotors is a fundamental prerequisite for numerous applications. This work proposes a novel deep reinforcement learning (DRL) framework that explicitly addresses quadrotor attitude dynamics during autonomous navigation, a critical yet underexplored challenge in existing learning-based UAV navigation studies. In the proposed method, high-level velocity commands will be generated by a deep neural network policy and translated by a low-level control algorithm to achieve precise control of both positions and rotations of quadrotors. A specialized network structure is designed to effectively extract environmental obstacle features and quadrotor sequence features to improve navigation performance. In addition, a novel tangent path reward (TPR) calculation method is developed to adequately utilize the known contours and positions of obstacles during the training phase. Experimental results demonstrate that the proposed method enables quadrotors to autonomously navigate complex virtual obstacle environments with superior efficiency compared with other algorithms. Furthermore, the feasibility and adaptability of the proposed method are validated through simulations by varying obstacle density and map size, as well as replicating real-world obstacle distributions.},
  archive      = {J_ESWA},
  author       = {Qizhang Luo and Yuqi Li and Jiaheng Zeng and Guohua Wu and Yalin Wang},
  doi          = {10.1016/j.eswa.2025.129762},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129762},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quadrotor navigation considering attitude: A deep reinforcement learning method using tangent path rewards},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-based CNN for lithological identification from logging curves: A case study in the qaidam basin, china. <em>ESWA</em>, <em>298</em>, 129740. (<a href='https://doi.org/10.1016/j.eswa.2025.129740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subsurface lithological distribution is essential for extrapolating geological information from core to block or basin scales. Given the limited availability of core data, there is a critical need to develop a reliable method for establishing robust correlations between logging curves and lithologies in cores, thereby maximizing the value of large historical logging data. Here, we propose a novel attention-based convolutional neural network (ATT-CNN), which employs a 1D-CNN to transform six types of logging curves into high-dimensional feature space at each depth, and applies an attention mechanism to the 1D-CNN outputs along both the depth and feature dimensions. The architecture is designed to mimic human perceptual processing for lithology identification, leveraging curve combination, thresholding, and local pattern recognition within this enriched and high-dimensional feature representation. In addtion, the study employs wavelet-based preprocessing on logging curves to eliminate the impact of compaction-induced data drift on model generalization—an issue rarely considered in prior studies. The result showes that: ① The proposed ATT-CNN model demonstrates superior performance over benchmark models—the bidirectional gated recurrent unit (BiGRU) and an ensemble of machine learning models (En-ML)—across all evaluation metrics; ②Wavelet-based preprocessing enhances the generalization capability of both ATT-CNN and BiGRU, yielding higher metric scores and improved predictions, particularly in shallow-depth intervals; ③ For blind wells, the ATT-CNN outperforms BiGRU and En-ML in both accuracy and its ability to capture lithological variations even from low-amplitude curve deviations. The integration of ATT-CNN with wavelet-based preprocessing demonstrates significant potential for accurately characterizing subsurface lithological distribution, then provides critical support for key petroleum geology workflows, including provenance analysis, sedimentary facies mapping, and reservoir property prediction.},
  archive      = {J_ESWA},
  author       = {Jianguo Yin and Shuai Zhang and Zhixiong Wu and Shouji Pang and Rui Wang},
  doi          = {10.1016/j.eswa.2025.129740},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129740},
  shortjournal = {Expert Syst. Appl.},
  title        = {Attention-based CNN for lithological identification from logging curves: A case study in the qaidam basin, china},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Clustering-based brain functional segmentation via deep collapsed nonparametric von mises-fisher mixture models. <em>ESWA</em>, <em>298</em>, 129739. (<a href='https://doi.org/10.1016/j.eswa.2025.129739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a clustering-based framework for the analysis of functional magnetic resonance imaging (fMRI) data, with a particular focus on brain segmentation into functional sub-regions. The proposed approach comprises two key modules: representation learning and brain functional segmentation. To extract meaningful latent representations from high-dimensional fMRI signals while preserving temporal dependencies, we introduce the Spherical Variational Recurrent Autoencoder (SVRAE), a deep generative model built upon the Variational Autoencoder (VAE) architecture. Unlike conventional VAEs that assume a Gaussian prior, SVRAE employs the von Mises-Fisher (vMF) distribution to model latent variables on a unit hypersphere, which is more suitable for L 2 -normalized data. To further enhance temporal modeling, we replace standard fully connected layers with Long Short-Term Memory (LSTM) networks. For the segmentation module, we adopt a Collapsed Nonparametric von Mises-Fisher Mixture Model (Co-vMFMM), formulated within a Bayesian nonparametric framework. This model automatically adapts its complexity to the input data without requiring a predefined number of clusters. An efficient variational Bayes learning algorithm is developed to perform inference in a collapsed parameter space. Extensive experiments on publicly available fMRI datasets demonstrate the effectiveness and robustness of the proposed method in delineating functionally coherent brain sub-regions.},
  archive      = {J_ESWA},
  author       = {Wentao Fan and Wenchuan Zhang and Xiao Dong and Nizar Bouguila},
  doi          = {10.1016/j.eswa.2025.129739},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129739},
  shortjournal = {Expert Syst. Appl.},
  title        = {Clustering-based brain functional segmentation via deep collapsed nonparametric von mises-fisher mixture models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing liver cancer detection: An innovative deep learning approach combining GAN, ResNet, and vision transformer. <em>ESWA</em>, <em>298</em>, 129734. (<a href='https://doi.org/10.1016/j.eswa.2025.129734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver cancer is a complex and life-threatening disease with significant diagnostic and therapeutic challenges. Automated liver cancer detection assists radiologists in identifying tumors and their severity accurately. In recent years, several deep-learning techniques have been implemented for diagnosing liver tumors and classification. Despite advancements in deep learning for medical imaging, existing liver cancer detection approaches continue to face several critical limitations. These include suboptimal diagnostic accuracy due to inadequate feature extraction, excessive computational demands that hinder real-time deployment, significant class imbalance within medical datasets leading to biased predictions, and overfitting caused by limited annotated training data. To address these challenges, this study introduces a novel and automated deep learning framework called CustomLiverNet, specifically designed for accurate and efficient liver cancer diagnosis using Computed Tomography images. The Generative Adversarial Network is introduced for generating realistic synthetic images, effectively improving the performance of the proposed technique and reducing class imbalance problems. The proposed technique integrates the strengths of Residual Networks and Vision Transformer to extract significant information from the input images and further enhance the performance of the proposed framework. The Residual Networks capture both low-level and high-level semantic features, whereas the Vision Transformer derives global and contextual feature representations from the input images. The model designs a customized fusion layer for combining the extracted features from both Residual Networks and Vision Transformer models. The classification layer predicts whether the liver tumor is benign or malignant. Further, Gradient-Weighted Class Activation Mapping is applied to highlight the critical regions of the image to enhance model transparency. The CustomLiverNet framework was trained and validated on two publicly available liver cancer datasets, including the liver tumor segmentation dataset, which contains 131 contrast-enhanced abdominal Computed Tomography scans, and the 3D image reconstruction for comparison of algorithm database, which includes 20 computed tomography scans. Experimental evaluation using standard metrics shows that CustomLiverNet achieved an accuracy of 98.79 %, precision of 98.64 %, recall of 98.58 %, and specificity of 98.35 %. These results demonstrate that the proposed model holds strong potential for enhancing early and accurate liver cancer diagnosis compared to previous studies.},
  archive      = {J_ESWA},
  author       = {Shivani Joshi and Avinash Dwivedi and Rajiv Kumar and Ashish Kumar and Raju Kumar and Amrita},
  doi          = {10.1016/j.eswa.2025.129734},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129734},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing liver cancer detection: An innovative deep learning approach combining GAN, ResNet, and vision transformer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploring intra- and inter-organizational collaboration opportunities across a technological knowledge ecosystem: A metapath2vec approach. <em>ESWA</em>, <em>298</em>, 129724. (<a href='https://doi.org/10.1016/j.eswa.2025.129724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing complexity and scale of technological knowledge ecosystems, organizations face challenges in identifying intra- and inter-organizational collaboration opportunities. In this respect, prior studies have proposed patent-based approaches, but they are subject to several limitations: (1) insufficient consideration of technological relationships within the ecosystem, (2) simplified unit of analysis, and (3) limited organization-centric assessments. This study proposes a network embedding and text-reranking approach to explore potential intra- and inter-organizational collaboration opportunities. First, the technological knowledge ecosystem is represented as a heterogeneous patent network comprising patents, inventors, assignees, and technology classification codes. Second, inventor nodes are embedded using metapath2vec, which performs random walks along predefined metapaths to capture diverse knowledge flows within the ecosystem. Third, potential collaborators are explored through (1) screening candidates based on technological reachability, which measures the possibility of knowledge exploration based on contextual similarity within the network, and (2) reranking candidates based on technological relevance, which quantifies the possibility of knowledge exploitation based on the similarity of technological know-how and experiences. Finally, ten quantitative patent indicators are developed to assess the implications of these opportunities at both the inventor and organization levels. The validity of the proposed approach is demonstrated through a case study involving 28,888 US patents and 9,196 inventors in the field of energy storage technology. This study contributes to advancing the theoretical understanding of technological knowledge ecosystems while also serving as a supplementary tool to explore organizational collaboration opportunities.},
  archive      = {J_ESWA},
  author       = {Jaemin Chung and Jaewoong Choi and Janghyeok Yoon},
  doi          = {10.1016/j.eswa.2025.129724},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129724},
  shortjournal = {Expert Syst. Appl.},
  title        = {Exploring intra- and inter-organizational collaboration opportunities across a technological knowledge ecosystem: A metapath2vec approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated recognition and measurement of cellular and dendritic microstructures in alloys via machine learning. <em>ESWA</em>, <em>298</em>, 129717. (<a href='https://doi.org/10.1016/j.eswa.2025.129717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dendritic or cellular morphologies of alloys and metals formed during casting processes significantly influence key properties such as mechanical strength, toughness, hardness, and electrical or thermal conductivities. The literature presents correlations between these properties and the microstructural length scale, which requires accurate characterization at the micrometer level. However, traditional evaluation methods demand extensive experimental efforts, including careful metallographic preparation, high-quality imaging, and a large number of measurements for statistical reliability - often relying on analyst proficiency. This study proposes a machine learning-based workflow tailored for the automated processing of microstructure images. The approach enables the autonomous measurement of key microstructural features while minimizing bias and inconsistencies among analysts. By integrating advanced image processing techniques with object detection algorithms based on Convolutional Neural Networks (CNNs), the method autonomously identifies microstructural morphologies and quantifies their spacing scales. Three model types-Cell, Dendrite, and Hybrid (exhibiting both dendritic and cellular features)-were trained and validated on using a dataset of 200 images. Among them, the Cell detection model achieved the highest performance, with a mean Average Precision (mAP) of 78.77 %, followed by the Hybrid (75.63 %) and Dendrite (72.87 %) models. Finally, the automated measurements models were applied to literature images and compared to reported microstructural growth correlations.},
  archive      = {J_ESWA},
  author       = {Guilherme Marim da Silva and Rafael Kakitani and Carlos Henrique da Silva Santos and Amauri Garcia and Noé Cheung},
  doi          = {10.1016/j.eswa.2025.129717},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129717},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated recognition and measurement of cellular and dendritic microstructures in alloys via machine learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Online reinforcement learning strategies driven artificial bee colony algorithm for bi-objective distributed reentrant flowshops scheduling problem with sequence-sependent setup time. <em>ESWA</em>, <em>298</em>, 129716. (<a href='https://doi.org/10.1016/j.eswa.2025.129716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of manufacturing systems, reentrancy has become prevalent in many production environments. This study investigates a bi-objective distributed reentrant flow shop scheduling problem with sequence-dependent setup times (DRFSP-SDST). The objectives are to minimize the total energy consumption (TEC) and the maximum completion time (makespan), simultaneously. First, a bi-objective mathematical model for the DRFSP-SDST is formulated based on practical reentrant production scenarios. Second, the artificial bee colony (ABC) algorithm and its variants are employed to solve the DRFSP-SDST. According to the characteristics of the DRFSP-SDST, six local search operators are specifically designed to enhance the performance of the proposed algorithms. For promoting greener and more energy-efficient production, two speed-scaling strategies are developed. Third, two reinforcement learning (RL) algorithms, Q-learning and State-Action-Reward-State-Action (SARSA), are integrated into the iterative process as online learning strategies to guide the selection of high-quality local search strategies during the iterations of the proposed algorithms. For each RL algorithm, two distinct selection strategies for local search operators are designed. Finally, the effectiveness of the proposed enhancement strategies is evaluated through comprehensive numerical experiments on 36 benchmark instances. The performance of the proposed algorithms is further validated via the Friedman test. The experimental results and analysis demonstrate that the ABC algorithm enhanced by SARSA-based local search exhibits superior competitiveness in solving the DRFSP-SDST.},
  archive      = {J_ESWA},
  author       = {Ao Yao and Kaizhou Gao and Ponnuthurai Nagaratnam Suganthan and Hongyan Sang},
  doi          = {10.1016/j.eswa.2025.129716},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129716},
  shortjournal = {Expert Syst. Appl.},
  title        = {Online reinforcement learning strategies driven artificial bee colony algorithm for bi-objective distributed reentrant flowshops scheduling problem with sequence-sependent setup time},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Defects inspection system for building facades using drones and deep learning method. <em>ESWA</em>, <em>298</em>, 129715. (<a href='https://doi.org/10.1016/j.eswa.2025.129715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular inspection and maintenance of building facades are essential for preserving structural integrity and aesthetic quality, especially in aging urban high-rises. While drone-based visual inspection powered by artificial intelligence (AI) offers benefits in speed, safety, and scalability, existing methods are typically limited to single defect types or uniform facade categories due to the challenges of detecting multi-scale defects in complex, heterogeneous environments. This study introduces an automated multiclass defects inspection system for building facades by integrating drone technology, an AI-driven segmentation platform, and automatic report generation. Central to the system is a segmentation AI model capable of detecting multiclass defects with orders-of-magnitude differences in scale across diverse facade backgrounds. To handle the pixel imbalance of defects ranging from fine cracks to large spalling and glass breakage, the model is built upon EfficientUNet++, trained on a carefully curated dataset and optimized using adjustable batch sizes and active learning rates to improve multi-scale feature learning and mitigate overfitting. Evaluations on validation and out-of-sample datasets demonstrate that the proposed model achieves superior performance across all defect classes. Real-world drone experiments further confirm the model’s practical applicability, with high recall rates in detecting spalling, water seepage, cracks, and glass breakage across different types of facades. This work pioneers a robust, scalable, and efficient AI-based framework for automated multiclass facade defect inspection, providing actionable information for engineers and supporting urban infrastructure maintenance.},
  archive      = {J_ESWA},
  author       = {Xiaoling Zhou and Robert Lee Kong Tiong},
  doi          = {10.1016/j.eswa.2025.129715},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129715},
  shortjournal = {Expert Syst. Appl.},
  title        = {Defects inspection system for building facades using drones and deep learning method},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-modal multitask learning for automated quantitative characterization of infrastructure airhole defects. <em>ESWA</em>, <em>298</em>, 129713. (<a href='https://doi.org/10.1016/j.eswa.2025.129713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative characterization of apparent quality defects in infrastructure is a crucial component of operations and maintenance. It enables rapid assessment of defect severity and supports the timely formulation of preventive strategies. However, a singular visual modality struggles to simultaneously ensure the dual tasks of defect detection and measurement accuracy. To solve these problems, this paper proposes a novel framework for cross-modal multitask learning networks, which comprehensively integrates the advantages of image detection and point cloud measurement. The pixel points identified in the image are mapped to their corresponding three-dimensional coordinates in the point cloud through intensive feature matching. A measurement strategy for the inherent characteristics of the defect is subsequently proposed. Based on prior knowledge of the defect, the area and volume of defects are quantified accurately. Finally, extensive experiments on detection, matching and measurement demonstrate the efficacy of the proposed method. The results provide a valuable reference for the quantitative characterization of infrastructure defects.},
  archive      = {J_ESWA},
  author       = {Yu Wang and Yingchao Dai and Xiaodong Gan and Zhengtao Yang and Zhou Wu},
  doi          = {10.1016/j.eswa.2025.129713},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129713},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-modal multitask learning for automated quantitative characterization of infrastructure airhole defects},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Language proficiency assessment of autistic children using large language models. <em>ESWA</em>, <em>298</em>, 129712. (<a href='https://doi.org/10.1016/j.eswa.2025.129712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language impairment is a common comorbidity in children with autism spectrum disorder (ASD), and language proficiency assessment is a primary method for identifying such impairments. However, traditional assessment tools are often subjective and inefficient, while existing computer-assisted methods are limited by a narrow focus and insufficient use of natural language samples. To address these issues, this study proposes a framework for assessing children’s language abilities based on large language models (LLMs). We first preprocess the natural language samples from children and design multiple assessment dimensions and workflows. To enhance the stability of the assessment, we introduce a multi-expert voting mechanism and perform a comparative analysis of various large language models’ performance. The experimental results demonstrate a strong correlation between the framework’s assessment results and the Mullen Scales of Early Learning (MSEL) verbal developmental quotients, with a Pearson correlation coefficient of 0.8 ( p < 0.001). Furthermore, the results show that the multi-dimensional evaluation can accurately differentiate between ASD and typically developing (TD) children, achieving a classification accuracy of 0.98. These findings suggest that the proposed framework has significant potential for improving the accuracy of ASD identification.},
  archive      = {J_ESWA},
  author       = {Saige Qin and Min Liu and Tongquan Wei and Qiaoyun Liu},
  doi          = {10.1016/j.eswa.2025.129712},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129712},
  shortjournal = {Expert Syst. Appl.},
  title        = {Language proficiency assessment of autistic children using large language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EQUINAS: Equilibrium-guided differentiable neural architecture search. <em>ESWA</em>, <em>298</em>, 129711. (<a href='https://doi.org/10.1016/j.eswa.2025.129711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has significantly mitigated the performance collapse issue in Differentiable Architecture Search (DARTS) by either refining architecture parameters to better reflect the true strengths of operations or developing alternative metrics for evaluating operation significance. However, the actual role and impact of architecture parameters remain insufficiently explored, creating critical ambiguities in the search process. To address this gap, we conduct a rigorous theoretical analysis demonstrating that the change rate of architecture parameters reflects the sensitivity of the supernet’s validation loss in architecture space, thereby influencing the derived architecture’s performance by shaping supernet training dynamics. Building on these insights, we introduce the concept of a Stable Equilibrium State to capture the stability of the bi-level optimization process and propose the Equilibrium Influential ( E I ) metric to assess operation importance. By integrating these elements, we propose EQUINAS, a differentiable NAS approach that leverages the Stable Equilibrium State to identify the optimal state during the search process and derives the final architecture using the E I metric. Extensive experiments across diverse datasets and search spaces demonstrate that EQUINAS achieves competitive test accuracy compared to state-of-the-art methods while significantly reducing search costs. Additionally, EQUINAS shows remarkable performance in Transformer-based architectures and excels in real-world applications such as image classification and text recognition.},
  archive      = {J_ESWA},
  author       = {Weisheng Xie and Xiangxiang Gao and Xuwei Fang and Hui Li and Chen Hang and Shaoyuan Li},
  doi          = {10.1016/j.eswa.2025.129711},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129711},
  shortjournal = {Expert Syst. Appl.},
  title        = {EQUINAS: Equilibrium-guided differentiable neural architecture search},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Companion learning networks: A deep reinforcement learning algorithm with partner networks. <em>ESWA</em>, <em>298</em>, 129709. (<a href='https://doi.org/10.1016/j.eswa.2025.129709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep reinforcement learning (DRL) agents suffer from severe reward instability during late-stage exploration, particularly when encountering novel states in complex continuous environments. A variety of existing studies focus on improving an agent’s reward exploration. However, they ignore the instability problem that arises when the agent faces new states in the later stages of exploration. This paper proposes a novel companion learning network (CLN) based on the idea that the guidance can accelerate human learning efficiency and reduce the risk of making mistakes. The CLN integrates a short-term partner network to intensively learn localized environmental patterns, offering adaptive action guidance for recent states. Simultaneously, a global Q-network dynamically incorporates the partner’s decaying guidance signals, balancing autonomous exploration with error mitigation. As training progresses, the partner’s influence gradually diminishes, allowing the Q-network to solidify robust policies without persistent dependence. Extensive experiments on four OpenAI Gym environments demonstrate that the CLN can significantly improve the exploration stability in most tested scenarios, achieving up to 49% reduction in late-stage reward standard deviation compared to baseline DRL methods.},
  archive      = {J_ESWA},
  author       = {Jin Xu and Jinfeng Bu and Yu Zhang and Jia-Dong Zhang and Chi-Yin Chow},
  doi          = {10.1016/j.eswa.2025.129709},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129709},
  shortjournal = {Expert Syst. Appl.},
  title        = {Companion learning networks: A deep reinforcement learning algorithm with partner networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Talk with graph: A fuzzy sentiment-aware framework for explainable recommendation. <em>ESWA</em>, <em>298</em>, 129707. (<a href='https://doi.org/10.1016/j.eswa.2025.129707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User reviews reflect user preferences and item characteristics, optimizing the predictive accuracy and explanation generation of personalized recommendation systems. However, existing models face challenges due to subjective uncertainty in user feedback and a lack of transparency. Reviews often contain ambiguous emotional expressions, with the same product receiving positive, neutral, and negative sentiments. Many recommendation models assume alignment between ratings and review sentiments, but in practice, users may give high ratings while expressing dissatisfaction or vice versa. These inconsistencies complicate accurate modeling of user preferences. To address these issues, a Large Language Model (LLM)-driven sentiment-enhanced heterogeneous graph neural network framework is proposed. This framework jointly models interaction data and fuzzy sentiment information from reviews to improve both recommendation accuracy and explainability. By leveraging LLM with dual-prompt strategies, high-quality sentiment distributions and semantic insights are extracted. Review sentiments are then quantified using intuitionistic fuzzy numbers to address data sparsity and uncertainty, capturing implicit relationships between users, items, and entities in a sentiment-enhanced heterogeneous relational graph. A fuzzy sentiment-weighted graph convolutional network (FSGCN) is introduced for dynamic higher-order feature learning, adjusting sentiment weights based on user-item interactions and emotional context. The framework also integrates LLM-driven query interpretation to generate recommendations with transparent, context-aware rationales. This approach enables users to understand the reasoning behind recommendations, significantly enhancing explainability and trust.},
  archive      = {J_ESWA},
  author       = {Zhinan Li and Zhenyu Liu and Guodong Sa and Mingjie Hou and Jiacheng Sun and Jianrong Tan},
  doi          = {10.1016/j.eswa.2025.129707},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129707},
  shortjournal = {Expert Syst. Appl.},
  title        = {Talk with graph: A fuzzy sentiment-aware framework for explainable recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Geodesic-based path planning for port transfer robots on riemannian manifolds. <em>ESWA</em>, <em>298</em>, 129706. (<a href='https://doi.org/10.1016/j.eswa.2025.129706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid intelligent transformation of the automotive industry and the surge in production volume, intelligent autonomous robots equipped with integrated perception and planning systems are playing an increasingly vital role in vehicle transfer operations. Optimizing dispatch paths of robots is essential for improving overall operational efficiency, yet achieving a balance among path length, feasibility, and safety margin remains a significant challenge. To address this issue, we propose a geodesic-based path planning method formulated on Riemannian manifolds. The approach jointly considers directional motion constraints, steering effort, and obstacle accessibility boundaries to construct a Riemannian metric tensor that encodes local path cost structures. This transforms the planning task into a geodesic shortest path problem, which is efficiently solved using the Geometric heat flow (GHF) method. The resulting paths naturally comply with kinematic constraints and exhibit strong obstacle-avoidance capabilities, significantly enhancing safety and executability. Extensive simulations and real-world experiments in high-density port yard environments demonstrate the practicality and robustness of the proposed method under complex spatial constraints and obstacle configurations.},
  archive      = {J_ESWA},
  author       = {Runjiao Bao and Junzheng Wang and Shoukun Wang},
  doi          = {10.1016/j.eswa.2025.129706},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129706},
  shortjournal = {Expert Syst. Appl.},
  title        = {Geodesic-based path planning for port transfer robots on riemannian manifolds},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A social balance theory-based modeling framework for group-to-empirical decision-making transition with cognitive inertia and trust propagation. <em>ESWA</em>, <em>298</em>, 129705. (<a href='https://doi.org/10.1016/j.eswa.2025.129705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by empirical decision-making (EDM) processes, we propose a novel modeling framework where agents iteratively integrate social neighbors’ opinions into their cognitive inertia sequences (CISs), gradually prioritizing their accumulated CISs over time. This framework simulates the transition from group decision-making (GDM) to EDM through dynamic trust/distrust propagation and aggregation mechanisms grounded in social balance theory–capturing relational scenarios such as “a friend of a friend is a friend”, “a friend of an enemy is an enemy”, “an enemy of a friend is an enemy”, and “an enemy of an enemy is a stranger”. The paradigm incorporates two core mechanisms: (1) an endogenous cognitive inertia mechanism that uses the psychological serial-positioning effect to model cognitive inertia weights, accounting for primacy, recency, and U-shaped memory effects; and (2) an exogenous mechanism that quantifies comprehensive trust/distrust degrees via opinion similarity, stability similarity, and network structure similarity. To prevent followers from falling into cognitive freezing, a cluster leader-based consensus-reaching strategy is introduced. Extensive comparative experiments on real-world network datasets confirm the model’s effectiveness and robustness.},
  archive      = {J_ESWA},
  author       = {Jianglin Dong and Yiyi Zhao and Shangqun Mu and Haixia Mao and Jiangping Hu},
  doi          = {10.1016/j.eswa.2025.129705},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129705},
  shortjournal = {Expert Syst. Appl.},
  title        = {A social balance theory-based modeling framework for group-to-empirical decision-making transition with cognitive inertia and trust propagation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OTPS-VO: Enhanced RGB-D odometry for indoor service robots leveraging structural features. <em>ESWA</em>, <em>298</em>, 129704. (<a href='https://doi.org/10.1016/j.eswa.2025.129704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) is essential for indoor service robots to achieve reliable navigation and mapping. While point and line features have been extensively utilized to enhance the accuracy of visual odometry (VO), current methods often overlook the rich geometric information embedded in the spatial relationships among structural lines. In particular, the parallelism and collinearity within groups of line segments are underexploited, and geometric constraints are typically applied only heuristically or post hoc, limiting robustness in low-texture and repetitive environments. To address these challenges, a robust VO system is proposed that integrates structural feature grouping with adaptive MW tracking. A unified feature extraction strategy is introduced to detect point and line features simultaneously, improving computational efficiency. To mitigate pose drift caused by unreliable line segments, a set of parallel line features is constructed based on local geometric constraints, and a novel reprojection error model is formulated to enhance pose estimation. Furthermore, a tracking strategy based on local Manhattan World (MW) structure is developed to ensure low-drift estimation across various structured indoor scenes. Extensive experiments on multiple public datasets and a custom-built service robot platform demonstrate that the proposed method outperforms existing state-of-the-art approaches under dynamic lighting conditions and in environments rich in lines and planes. The system also operates at a real-time speed of 30 frames per second, meeting the requirements of practical robotic applications.},
  archive      = {J_ESWA},
  author       = {Zhiyu Wang and Weili Ding and Ying Zhang and Changchun Hua},
  doi          = {10.1016/j.eswa.2025.129704},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129704},
  shortjournal = {Expert Syst. Appl.},
  title        = {OTPS-VO: Enhanced RGB-D odometry for indoor service robots leveraging structural features},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive gated meta graph retention network: A model for urban traffic flow prediction. <em>ESWA</em>, <em>298</em>, 129703. (<a href='https://doi.org/10.1016/j.eswa.2025.129703'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is crucial for urban transportation systems. Existing models are still deficient in training efficiency and modeling dynamic spatial-temporal dependencies, various external factors, time-varying topology. Based on this, this paper introduces the Adaptive Gated Meta Graph Retention Network (AGMGRN), a novel model for spatial-temporal traffic flow prediction. Specifically, the AGMGRN integrates the attention mechanism with the retention network to model spatial-temporal dependencies. The AGMGRN proposes a gated dynamic connection block to enhance the model’s dynamic modeling capabilities. The AGMGRN considers the influence of external factors on traffic conditions through meta-learning approaches. The AGMGRN proposes an adaptive graph block to construct time-varying topologies. Experiments on four actual large-scale datasets demonstrate that the AGMGRN achieves superior prediction accuracy and high applicability.},
  archive      = {J_ESWA},
  author       = {Xing Li and Yuequan Bao},
  doi          = {10.1016/j.eswa.2025.129703},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129703},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive gated meta graph retention network: A model for urban traffic flow prediction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DASF-GRL: Dynamic agent-scaling framework with game-augmented reinforcement learning for defensive counter-air operations. <em>ESWA</em>, <em>298</em>, 129702. (<a href='https://doi.org/10.1016/j.eswa.2025.129702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defensive Counter-Air (DCA) operations are pivotal for modern air defense, but existing studies are limited by static defender populations and oversimplified attacker models. We address these limitations with the Dynamic Agent-Scaling Framework with Game-Augmented Reinforcement Learning (DASF-GRL), which dynamically scales defender populations based on real-time threat levels. Specifically, we introduce a hybrid imitation-reinforcement training strategy that integrates attention mechanisms into critic networks to enable dynamic agent scaling. By incorporating a safety barrier function rooted in differential game theory, we constrain agents’ action spaces and enhance policy reliability. Furthermore, we developed a DCA simulation platform supporting reinforcement learning validation and designed a novel Apollonius-based penetration strategy for attackers to improve algorithmic robustness. Experiments demonstrate that DASF-GRL adaptively adjusts defender populations across scenarios involving 20, 40, and 60 attackers, markedly outperforming baseline methods in convergence speed and defense success rates. This framework offers novel theoretical paradigms and practical tools for intelligent decision-making in DCA environments.},
  archive      = {J_ESWA},
  author       = {Yuxuan Chen and He Luo and Guoqiang Wang},
  doi          = {10.1016/j.eswa.2025.129702},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129702},
  shortjournal = {Expert Syst. Appl.},
  title        = {DASF-GRL: Dynamic agent-scaling framework with game-augmented reinforcement learning for defensive counter-air operations},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Coordinated low-carbon economic scheduling of integrated electricity-heat-gas-hydrogen-methanol multi-microgrids considering electricity-methanol transaction. <em>ESWA</em>, <em>298</em>, 129701. (<a href='https://doi.org/10.1016/j.eswa.2025.129701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uneven spatial and temporal distribution of renewable energy resources poses significant challenges for multi-microgrid (MG) systems, resulting in high operational costs and low renewable energy utilization. To overcome these challenges, this work investigates a peer-to-peer electricity transaction and hydrogen-methanol-hydrogen technology-based methanol transaction among multi-MG. Besides, to realize net-zero emissions and carbon cycle utilization, the carbon capture system and hydrogen blending system are introduced into MG to reduce carbon dioxide emissions and capture and reform carbon dioxide for methanol synthesis equipment. Additionally, a cooperative operation model based on the Nash bargaining theory for multi-MGs under the transaction amount and price constraints of electricity and methanol is constructed. Due to the characteristics of non-convex and non-linear, the Nash bargaining is transformed into minimizing operation costs (sub-problem one) and maximizing payment benefits (sub-problem two). During the process of benefit allocation in sub-problem two, this work adopts a nonlinear energy sharing mapping method to quantify the comprehensive contribution rate of each MG to the multi-MG system, thereby achieving fair allocation of benefits. Finally, the alternating direction multiplier method is used to solve the model, effectively protecting the privacy of each MG. The simulation results demonstrate that a multi-MG system considering electricity and methanol transactions can effectively decrease carbon emissions and the total operational costs by 21.53% and 27.01% compared to only considering electricity transactions, respectively. Overall, the proposed electricity and methanol transactions strategy simultaneously reduces the overall system operation costs and carbon emissions, underscoring its advantages and significance.},
  archive      = {J_ESWA},
  author       = {Jiale Li and Bo Yang and Yiming Zhou and Hongchun Shu and Hongbiao Li and Dengke Gao and Lin Jiang},
  doi          = {10.1016/j.eswa.2025.129701},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129701},
  shortjournal = {Expert Syst. Appl.},
  title        = {Coordinated low-carbon economic scheduling of integrated electricity-heat-gas-hydrogen-methanol multi-microgrids considering electricity-methanol transaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Heterogeneous cloud resource allocation: A case study on real-time transcoding in live streaming. <em>ESWA</em>, <em>298</em>, 129700. (<a href='https://doi.org/10.1016/j.eswa.2025.129700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosion in popularity of crowdsourced live streaming (CLS) has led to a huge increase in demand for cloud resources to support real-time video transcoding. CLS transcoding is real-time, geographically distributed and computationally intensive. Therefore, transcoding service providers need to cost-effectively utilize diverse heterogeneous cloud resources, while guaranteeing quality of service standards to ensure a good streaming experience for the viewers. To support the above, we developed a novel proactive-reactive resource allocation framework that optimizes the overall cost of supporting the CLS transcoding service using heterogeneous edge and cloud computing resources. The offline proactive policy evaluator aims to provide a good and adaptable resource usage plan in advance, matching the predicted demand with the heterogeneous resources. The reactive execution module monitors the actual demand online and controls the resource usage to compensate for deviations from the offline prediction. Our experiments show that the proposed approach leads to a cost reduction of 42 % compared to the fixed usage ratio strategy based on expert knowledge.},
  archive      = {J_ESWA},
  author       = {Yinuo Li and Jin-Kao Hao and Kwong Meng Teo and Liwei Song},
  doi          = {10.1016/j.eswa.2025.129700},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129700},
  shortjournal = {Expert Syst. Appl.},
  title        = {Heterogeneous cloud resource allocation: A case study on real-time transcoding in live streaming},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive multi-step path planning for multi-robot in dynamic environments based on hybrid optimization approach. <em>ESWA</em>, <em>298</em>, 129699. (<a href='https://doi.org/10.1016/j.eswa.2025.129699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-robot path planning problem requires algorithms with high convergence speed and accuracy, as well as the completeness of the search probability for the optimal path. The integration of metaheuristic algorithms in path planning has proven to be remarkably efficient. This paper introduces a novel hybrid metaheuristic algorithm, Beluga Whale-Crayfish Optimization (BWCOA), for enhanced global optimization in path planning applications. While the Crayfish Optimization (COA) demonstrates superior convergence speed, its inherent probabilistic path completeness remains suboptimal. To address this limitation, we present three key innovations: a dynamic probability completion mechanism, adaptive convergence acceleration factors, and balanced exploration–exploitation trade-off parameters. The proposed BWCOA synergizes Beluga Whale Optimization (BWO)’s basin-hopping capability with COA’s swarm intelligence through parallel combined exploration strategies. To prove its powerfulness, a series of comparative analyses were conducted between BWCOA and other leading algorithms across two comprehensive test function suites. The numerical experiment results underscore the significant superiority of BWCOA over its counterparts. In the context of path planning simulations, BWCOA demonstrated notable improvements over COA within the same number of function evaluations, with average enhancement rates of 6.49 %, 7.42 %, 15.09 %, 76.42 %, and 0.73 % across five evaluation metrics. Similarly, when compared to BWO on the same set of indicators, BWCOA showed average improvement rates of 22.39 %, 27.71 %, 70.53 %, 260.86 %, and 41.22 %. Furthermore, the running time of BWCOA is comparable to that of similar algorithms.},
  archive      = {J_ESWA},
  author       = {Liguo Yao and Guanghui Li and Taihua Zhang and Abdelazim G. Hussien and Yao Lu},
  doi          = {10.1016/j.eswa.2025.129699},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129699},
  shortjournal = {Expert Syst. Appl.},
  title        = {Adaptive multi-step path planning for multi-robot in dynamic environments based on hybrid optimization approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Critical commentary on “Reptile search algorithm (RSA): A nature-inspired meta-heuristic optimizer”. <em>ESWA</em>, <em>298</em>, 129697. (<a href='https://doi.org/10.1016/j.eswa.2025.129697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ESWA},
  author       = {Ngaiming Kwok},
  doi          = {10.1016/j.eswa.2025.129697},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129697},
  shortjournal = {Expert Syst. Appl.},
  title        = {Critical commentary on “Reptile search algorithm (RSA): A nature-inspired meta-heuristic optimizer”},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 2PADMS: Two-stage prediction and data migration strategy based on hard disk failure time. <em>ESWA</em>, <em>298</em>, 129696. (<a href='https://doi.org/10.1016/j.eswa.2025.129696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of global data volume, the usage of hard disk drives (HDDs) is also increasing rapidly. Consequently, the number of failed disks is continuously rising, which can affect storage service quality and even lead to data loss when failures occur.In recent years, the active fault-tolerant technology, which collects hard disks’ Self Monitoring Analysis and Reporting Technology (SMART) data-set, predicts hard disk failure by machine learning model, and repairs near-failure disks’ data to health disks in advance, has become a common research hotspot in both academia and industry. Aiming at the existing problems such as interference characteristics, inaccurate failure time prediction, competition of system resources between data migration and front service, this paper researches the two-stage prediction model and data migration strategy based on hard disk failure time, including the two-stage hard disk information feature selection method, the two-stage prediction method of hard disk failure time, and the data migration elastic system resource allocation strategy. Feature selection is performed by combining embedding methods with visualization, and the importance of the selected features is evaluated using a random forest model. Based on the feature importance, further refinement is carried out to obtain the final feature set. Before predicting the failure time of hard drives, XGBoost is first used in a voting manner to identify drives predicted to be faulty. Then, a trained Bidirectional Long Short-Term Memory network (Bidirectional LSTM) enhanced with a self-attention mechanism is employed to predict the exact failure time.Experimental results show that on the Backblaze dataset, the model achieves a mean absolute error of 1.24 when predicting failure times. The recall rate for predicting failures within 7 days reaches 98.79 %, the error rate is 0.30 %, the F1 score is 99.24 %, and the precision is 99.69 %. The elastic system resource allocation strategy for data migration improves business IOPS by 47.19 % and reduces latency by 38.68 %.},
  archive      = {J_ESWA},
  author       = {Huiyuan Qiang and Yuequan Li and Hongzhang Yang and Ping Wang and Yaofeng Tu and Shang Yang},
  doi          = {10.1016/j.eswa.2025.129696},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129696},
  shortjournal = {Expert Syst. Appl.},
  title        = {2PADMS: Two-stage prediction and data migration strategy based on hard disk failure time},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An acoustic-electromagnetic detection system based on joint parameter estimation of atomic norm algorithm. <em>ESWA</em>, <em>298</em>, 129692. (<a href='https://doi.org/10.1016/j.eswa.2025.129692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time delay and Doppler shift parameters in radar system echo signals serve as effective tools for multi-target identification and localization in covert environments. However, the nonlinear characteristics of stationary targets are often masked by surrounding environmental factors, and traditional joint parameter estimation algorithms tend to suffer from high computational complexity and errors during demodulation. To address these challenges, this paper proposes an acoustic-electromagnetic intermodulation detection system based on a novel atomic-paradigm algorithm, which ensures localization accuracy with minimal computational complexity and zero false alarms. Specifically, the system excites the target by introducing acoustic field energy coupling, generating discernible micromotion features. The resulting acoustically modulated signal is then modeled as a two-dimensional line spectral estimation problem, capturing the target’s time delay and Doppler shift. Furthermore, the joint parameter estimation algorithm is enhanced by relaxing dyadic constraints under sufficient conditions. In our experiments, a harmonic radar physical system is constructed to simultaneously localize and measure multiple non-clustered micromotion targets. The recognition accuracy is quantitatively evaluated using a classical neural network model, achieving 86.9 % accuracy across five classified targets. The improved algorithm’s performance in joint parameter estimation is also assessed under varying signal-to-noise ratios and demodulation error rates, with a detailed time complexity analysis provided.},
  archive      = {J_ESWA},
  author       = {Sheng Wu and Yilin Cai and Yijing Zheng and Dingzhao Li and Hongjun Lai and Haixin Sun},
  doi          = {10.1016/j.eswa.2025.129692},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129692},
  shortjournal = {Expert Syst. Appl.},
  title        = {An acoustic-electromagnetic detection system based on joint parameter estimation of atomic norm algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel convex-hull-based algorithm for classification problems with imbalanced and overlapping data. <em>ESWA</em>, <em>298</em>, 129691. (<a href='https://doi.org/10.1016/j.eswa.2025.129691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is a fundamental task in supervised machine learning. This problem becomes challenging when dealing with imbalanced and overlapping datasets. In such cases, learning algorithms often perform well in identifying the labels of majority class data points but exhibit high error rates in predicting the minority class. This paper proposes an innovative method based on the convex-hull concept to enhance classification for imbalanced and overlapping datasets. Unlike undersampling approaches that may lead to the loss of valuable information, our method focuses on preserving the data. The process begins by clustering the data points for each class separately in such a way that no points from the opposite class fall within the convex-hull of each cluster. Then, the support vector machine (SVM) is used to separate every cluster of a given class from the data points of the opposite class. Afterward, data points inside the SVM boundaries are considered as non-overlapping, while those outside the SVM boundaries are identified as overlapping data. The XGBoost algorithm is then employed to classify the data points within the overlapping region. Extensive experiments on a variety of simulated and real-world datasets confirm the effectiveness of the proposed method in terms of various evaluation metrics, compared to existing relevant algorithms for handling imbalanced and overlapping datasets.},
  archive      = {J_ESWA},
  author       = {Farnaz Hooshmand and Sogol Peik-Mortazavi},
  doi          = {10.1016/j.eswa.2025.129691},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129691},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel convex-hull-based algorithm for classification problems with imbalanced and overlapping data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated prompt engineering pipelines: Fine-tuning LLMs for enhanced response accuracy. <em>ESWA</em>, <em>298</em>, 129689. (<a href='https://doi.org/10.1016/j.eswa.2025.129689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presented an Automatic Role Prompting System that seeks to improve the performance of the Large Language Model (LLM) by allowing models to assume varied roles through role-based prompting and, as a result, qualitatively improve the relevance of outputs. Our Automatic Role Prompting System’s target audience is people who do not have domain knowledge. The guiding framework (consisting of an Automated Script for discovering roles and fields layered on top of prompt engineering, and Natural Language Inference (NLI) models trained in advance), was robustly tested through the use of three datasets: our set of 1990 curated prompts, WikiQA, and the AwesomeChatGPTPrompts. We implemented a novel evaluation strategy using GPT-Eval, which scales prompts according to completeness, clarity, and relevance. We found substantially better performance than traditional rule- and template-based approaches, yielding accuracy improvements as high as 97.6 %. Overall, this work demonstrates the promise of an Automated Role Prompting System to help people engage and work more effectively and efficiently with Large Language Models (LLMs).},
  archive      = {J_ESWA},
  author       = {Samar Hendawi and Tarek Kanan and Mohammed Elbes and Ala Mughaid and Shadi Alzu’bi},
  doi          = {10.1016/j.eswa.2025.129689},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129689},
  shortjournal = {Expert Syst. Appl.},
  title        = {Automated prompt engineering pipelines: Fine-tuning LLMs for enhanced response accuracy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid fusion network using convolutional vision transformers for landslide identification. <em>ESWA</em>, <em>298</em>, 129688. (<a href='https://doi.org/10.1016/j.eswa.2025.129688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNN) have made great strides in the segmentation of remote sensing images, but they still have certain inherent drawbacks when working with small targets and complex geological structures. These drawbacks include incomplete contextual information integration, blurry edges, and inaccurate target localisation. This study suggests using a hybrid CNN-Transformer network to improve the segmentation of landslide regions in high-resolution remote sensing images in order to overcome these difficulties. A comprehensive investigation has been conducted on the use of CNN and transformers to accomplish the task of semantic segmentation. According to experimental data, our model outperforms the state-of-the-art CNN-based, Transformer-based, and even CNN-plus-Transformer combination models for image segmentation tasks by a large margin. When it comes to landslide area segmentation, it performs exceptionally well.},
  archive      = {J_ESWA},
  author       = {S. Sreelakshmi and S.~S. Vinod Chandra},
  doi          = {10.1016/j.eswa.2025.129688},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129688},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid fusion network using convolutional vision transformers for landslide identification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GCMF-net: Global-aware cross-attention and mask-guided fusion for multispectral object detection. <em>ESWA</em>, <em>298</em>, 129679. (<a href='https://doi.org/10.1016/j.eswa.2025.129679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multispectral Object Detection has shown significant advantages under various lighting and weather conditions, with efficient fusion of RGB and thermal information playing a key role. Previous studies have demonstrated the effectiveness of feature fusion based on convolutional neural networks, but limited local feature interactions hinder the capture of global complementary information. To address these limitations, some methods adopt complex fusion strategies to enhance complementary feature extraction, yet fail to mitigate feature redundancy, which negatively impacts detection performance. In this paper, we propose a novel Global-aware Cross-attention and Mask-guided Fusion (GCMF) module for Multispectral Object Detection, following a fusion-refinement paradigm. In the fusion stage, we first introduce Efficient Channel Attention with Weighted Max-Pooling (ECA-WM) to focus on key information within each modality and achieve implicit alignment before fusion. Subsequently, the Global-aware Cross-Attention Transformer (GCAT) effectively captures complementary cross-modal information and models global features. In the refinement stage, the Mask-guided Refinement Strategy (MRS) generates segmentation masks to distinguish target features from the background. These masks are applied before and after cross-modal interaction to highlight target-relevant information while suppressing irrelevant features, resulting in highly discriminative fused representations. Extensive experimental comparisons demonstrate that the proposed GCMF fusion strategy achieves state-of-the-art performance on the publicly available FLIR, LLVIP and DVTOD datasets, with absolute improvements of 2.8 %, 4.2 % and 4.0 % over the previous methods, respectively. Moreover, the proposed strategy is general and effective, making it adaptable to various detection frameworks.},
  archive      = {J_ESWA},
  author       = {Zhong Qu and Jin Yang and Shufang Xia},
  doi          = {10.1016/j.eswa.2025.129679},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129679},
  shortjournal = {Expert Syst. Appl.},
  title        = {GCMF-net: Global-aware cross-attention and mask-guided fusion for multispectral object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Oriented bounding box detection algorithm for dense scenarios of robotic arm operation. <em>ESWA</em>, <em>298</em>, 129678. (<a href='https://doi.org/10.1016/j.eswa.2025.129678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the national promotion of intelligent manufacturing and the ’Industry4.0’ strategy, the demand for intelligent robotic arms in industrial production has steadily increased. However, challenges such as occlusion, significant object scale variations, and strict real-time requirements have made target detection in densely packed environments more challenging. This study, based on the YOLOv11 algorithm, proposes an efficient oriented bounding box detection method aimed at improving the model’s performance in feature extraction, computational efficiency, and network lightweighting to tackle target detection challenges in dense industrial settings. A Dynamic-Cross-Stage-Dual-Conv module was designed to enhance the Bottleneck section, employing a parallel dual-branch structure for local feature extraction and global context fusion. Simultaneously, a CIoU loss function with geometric perception was introduced to improve object localization accuracy and strengthen the network’s ability to handle densely stacked objects. Next, a Modulated-Deform-Conv deformable convolution module was integrated into the Backbone structure, dynamically adjusting the convolution kernel sampling positions, enabling the network to learn deformation features in dense scenes, improving adaptability to shape and scale variations while reducing computational load. Additionally, a C3K2_FasterBlock lightweight structure, utilizing partial convolutions and sparse connections, was proposed to minimize redundant calculations and optimize feature interactions. On a custom-built dense object dataset, the model achieved a 2.9 % increase in mAP@0.5 and reduced computational cost by 14 %. Finally, the improved model was deployed on the Jetson Orin Nano development board, demonstrating its practical value in robotic arm recognition and grasping tasks in dense industrial environments, offering a new paradigm for future applications.},
  archive      = {J_ESWA},
  author       = {Jinshun Dong and Lixia Deng and Dapeng Wan and Chenxu Liu and Jianqin Yin and Meiqi Guo and Hongyu Zhang and Shoujun Lin and Haiying Liu and Lida Liu},
  doi          = {10.1016/j.eswa.2025.129678},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129678},
  shortjournal = {Expert Syst. Appl.},
  title        = {Oriented bounding box detection algorithm for dense scenarios of robotic arm operation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CrossModalNet: A dual-modal object detection network based on cross-modal fusion and channel interaction. <em>ESWA</em>, <em>298</em>, 129677. (<a href='https://doi.org/10.1016/j.eswa.2025.129677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in complex environments, particularly under conditions such as low illumination or adverse weather, remains a significant challenge. Multispectral detection techniques that integrate visible and infrared imagery offer a promising solution by leveraging complementary modality information. However, substantial discrepancies between these modalities hinder traditional fusion strategies, which often fail to adaptively align and integrate features, resulting in information loss and diminished detection performance. To overcome this limitation, we propose CrossModalNet, a novel cross-modal fusion and channel interaction framework. CrossModalNet comprises two key modules: Convolutional Attention Interaction Module (CAIM) and Bidirectional Cross-Modal Attention Module (BiCAM). CAIM enables effective cross-modal integration across varying semantic levels by employing convolutional attention mechanisms combined with pixel-wise channel guidance. In parallel, BiCAM enhances inter-modal feature complementarity by modeling channel-level interactions through bidirectional attention pathways. Extensive experiments conducted on four public multispectral datasets, FLIR, LLVIP, M3FD, and VEDAI, demonstrate that the proposed method consistently outperforms existing state-of-the-art approaches across multiple performance metrics. Moreover, with an inference speed of 12.6 FPS on embedded platforms, the proposed model is suitable for real-time deployment.},
  archive      = {J_ESWA},
  author       = {Hanyun Li and Linsong Xiao and Lihua Cao and Di Wu and Yangfan Liu and Yi Li and Yunfeng Zhang and Haiyang Bao},
  doi          = {10.1016/j.eswa.2025.129677},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129677},
  shortjournal = {Expert Syst. Appl.},
  title        = {CrossModalNet: A dual-modal object detection network based on cross-modal fusion and channel interaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IPMMG: Information propagation with multi-granularity morphology-guided for nuclear segmentation and classification. <em>ESWA</em>, <em>298</em>, 129676. (<a href='https://doi.org/10.1016/j.eswa.2025.129676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclear segmentation and classification play a crucial role in pathological image analysis. However, it is frequently challenged by blurred nuclear boundaries and complex structures in digital pathology slides, due to factors such as staining techniques and imaging methods, posing a significant challenge for accurate segmentation and classification. To this end, we propose a novel and efficient approach for nuclear identification, termed Information Propagation with Multi-Granularity Morphology-Guided Network (IPMMG). Specifically, IPMMG progressively captures edge morphology information from different network layers while simultaneously incorporating structural morphology features at multiple granularities. By explicitly propagating features related to both the edge and the structure, our approach constrains semantic features to focus on contours of the region of interest in the nuclear segmentation task, thus mitigating the challenge of blurred morphology. Experiments on public datasets demonstrate that IPMMG achieves state-of-the-art (SOTA) performance in segmentation, as measured by Dice and IoU scores, while also attaining competitive results in classification with DQ, SQ, and PQ metrics. In particular, our proposal IPMMG excels in handling nuclei with blurred edges and complex structures.},
  archive      = {J_ESWA},
  author       = {Dawei Fan and Jun Li and Chengfei Cai and Lihui Lin and Riqing Chen and Yanping Chen and Lifang Wei},
  doi          = {10.1016/j.eswa.2025.129676},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129676},
  shortjournal = {Expert Syst. Appl.},
  title        = {IPMMG: Information propagation with multi-granularity morphology-guided for nuclear segmentation and classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable hybrid bio-inspired feature selection framework using RSVP-evoked p300 EEG signals for identity authentication. <em>ESWA</em>, <em>298</em>, 129674. (<a href='https://doi.org/10.1016/j.eswa.2025.129674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EEG-based personal identification confronts critical hurdles, including high dimensionality, noise, and real-time variability. While RSVP and P300 paradigms provide cognitive-response-driven security, feature extraction challenges prevent practical deployment. Although deep learning has addressed unstructured EEG data, pinpointing optimal RSVP and P300-specific features remains an unresolved issue. To overcome these limitations, we introduced a hybrid GWO-MSE-XAI framework integrating Grey Wolf Optimization (GWO), Multiscale Entropy (MSE), and SHAP-based Explainable AI (XAI) to select the most relevant features from RSVP-evoked P300 EEG signals. The framework prioritizes discriminative feature selection, improves class separability, and incorporates a hybrid cross-entropy loss function fused with Fisher’s score-based feature selection. Benchmark-driven optimization refines EEG-specific feature subsets, while evaluation using classifiers (Random Forest, LightGBM, CatBoost, XGBoost) demonstrates substantial dimensionality reduction, faster convergence, and superior performance (98.89% accuracy). Experimental results confirm robustness, scalability, and enhanced interpretability, positioning the framework as a viable solution for EEG-based identity authentication in real-world RSVP and P300 applications.},
  archive      = {J_ESWA},
  author       = {S Abinayaa and S.S. Sridhar},
  doi          = {10.1016/j.eswa.2025.129674},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129674},
  shortjournal = {Expert Syst. Appl.},
  title        = {An explainable hybrid bio-inspired feature selection framework using RSVP-evoked p300 EEG signals for identity authentication},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EKT-ML: An efficient knowledge tracing model with multi-task learning. <em>ESWA</em>, <em>298</em>, 129671. (<a href='https://doi.org/10.1016/j.eswa.2025.129671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) aims to trace a student’s mastery of knowledge, known as knowledge states, and has become a popular research area, with Self-Attention (SA)-based KT models achieving the state-of-the-art performance. However, existing SA-based KT models seem to still have issues that need further investigation. Firstly, there commonly exists incorrect question-knowledge concept (Q-KC) mapping, yet most models fail to address this issue. Secondly, existing SA-based KT models suffer from high time complexity due to their extensive use of the SA mechanism. Finally, from real-world datasets, we observe that there exists a repeated attempts pattern which is often overlooked by existing KT models. Motivated by the above observations, we propose a novel Efficient Knowledge Tracing Model with Multi-task Learning (EKT-ML), an SA-based model with three crucial features. Firstly, we formulate the KT as a Multi-task Learning, with Q-task and KC-task as two tasks; by training them simultaneously and treating Q-KC mapping as shared information, the proposed EKT-ML tends to mitigate the impact of incorrect Q-KC mapping. Moreover, we propose an SVD-MLP component to replace the initial SA layers commonly used in existing SA-based KT models, thereby reducing the time complexity of EKT-ML. Finally, experimental results show that EKT-ML improves performance by up to 8.84 % across four metrics on three widely used datasets. Furthermore, it demonstrates that the EKT-ML has reduced time complexity compared with the benchmark baseline.},
  archive      = {J_ESWA},
  author       = {Wei Liu and Bo Yang and Haotian Su and Yaowei Wang and Qing Li},
  doi          = {10.1016/j.eswa.2025.129671},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129671},
  shortjournal = {Expert Syst. Appl.},
  title        = {EKT-ML: An efficient knowledge tracing model with multi-task learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new edge detection method for noisy image based on discrete fractional wavelet transform and improved canny algorithm. <em>ESWA</em>, <em>298</em>, 129668. (<a href='https://doi.org/10.1016/j.eswa.2025.129668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge detection is a key technique for extracting object structures and region boundaries in images, serving as an important foundation for visual tasks such as image segmentation and object recognition. However, during real-world image acquisition, various types of noise are inevitably introduced into the images. Traditional edge detection methods suffer significant performance degradation in noisy environments, often resulting in false edges or missing true edges. To address this issue, this paper proposes a novel edge detection method for noisy images. The method begins by adaptively selecting an optimal fractional order p , based on the distribution characteristics of the image’s subband modulus coefficients. This order is then used to perform a p -order discrete fractional wavelet transform (DFRWT) on the noisy image. Then, within the DFRWT domain, an enhanced Canny algorithm is applied to detect edges. This algorithm improves upon the standard method by replacing the traditional gradient operator with a more robust fractional-order Sobel operator to compute the gradient magnitude. This detection process is performed on both the low- and high-frequency subbands to capture features at different scales. Finally, the edge images from the low- and high-frequency components are reconstructed to obtain the final edge detection result. Experimental results demonstrate that, compared to four representative edge detection algorithms, the proposed method exhibits superior noise robustness and edge preservation capability in noisy environments.},
  archive      = {J_ESWA},
  author       = {Xiaozhong Yang and Chunmeng Li},
  doi          = {10.1016/j.eswa.2025.129668},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129668},
  shortjournal = {Expert Syst. Appl.},
  title        = {A new edge detection method for noisy image based on discrete fractional wavelet transform and improved canny algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-constrained EBSD image inpainting via adversarial graph learning: Bridging crystallographic rules and multimodal deep learning. <em>ESWA</em>, <em>298</em>, 129667. (<a href='https://doi.org/10.1016/j.eswa.2025.129667'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electron Backscatter Diffraction (EBSD) is a crucial characterisation method in materials engineering. The reliability of EBSD data is essential in the aerospace, nuclear, and automotive industries, as material performance greatly affects operational safety. While industrial practice makes perfect EBSD data difficult, with sample preparation errors, beam drift, and instrumental noise corrupting up to one-third of datasets. Automated crystallographic fidelity restoration solutions are needed because corrupted data force engineers to abandon valuable experiments or manually restore datasets at risk of errors. Current image inpainting techniques fail to maintain crystallographic constraints, resulting in restorations that violate the basic rules for crystalline materials. A novel physics-constrained framework is proposed to fill this gap. It integrates adversarial learning with graph neural networks (GNNs) for crystallographically consistent EBSD image inpainting. The proposed GTRG method consists of three elements: i ) a generative adversarial network (GAN) for reconstructing grain boundaries; i i ) a crystallography-guided graph transformer (T) that converts pixel data into orientation-boundary graphs; and i i i ) a regression graph convolutional network (RGCN) that links grain, orientation and boundaries to predict missing crystal orientations. The framework mandates a single orientation per grain and preserves grain boundary structure through structured graph representations. A strategy for creating automated EBSD datasets that incorporates realistic corruption patterns supports effective model training and evaluation. Experimental validation shows better performance than current methods, with a 3.5 % improvement in SSIM (0.950 vs. 0.918) and a 63.0 % reduction in FID (16.55 vs. 44.70) compared to AOT-GAN. The study on aerospace niobium alloys further validates practical utility, showing statistically consistent grain orientation and size distributions (Kolmogorov-Smirnov D = 0.02 , p > 0.98 ). This work introduces two key advancements: 1) the first integration of graph neural networks with adversarial learning for topology-aware image inpainting, and 2) a physics-informed framework bridging computer vision and materials science, enabling effective restoration of corrupted EBSD data for subsequent engineering applications.},
  archive      = {J_ESWA},
  author       = {Baiyang Zheng and Jiongran Wen and Yat-Sze Choy and Chengwei Fei},
  doi          = {10.1016/j.eswa.2025.129667},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129667},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-constrained EBSD image inpainting via adversarial graph learning: Bridging crystallographic rules and multimodal deep learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Three-way large-scale group decision-making under incomplete multi-scale information systems: A perspective of quantum social networks. <em>ESWA</em>, <em>298</em>, 129666. (<a href='https://doi.org/10.1016/j.eswa.2025.129666'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The gathering and sharing of information lay the groundwork for decision-making, while large-scale group decision-making (LSGDM) strategies address biases, promoting a more comprehensive evaluation of alternatives. Regarding information representation, incomplete multi-scale information systems (MSISs), as an application of granular computing, combine inputs from decision-makers (DMs) and tackle data gaps through multi-level analysis to foster LSGDM. Furthermore, given the interference effect among DMs, quantum social networks (SNs) and three-way decisions (TWD) are vital for effective decision-making. Quantum SNs provide a framework for modeling complex trust relationships among DMs, while TWD offers a structured approach to manage uncertainty. Therefore, this paper seeks to investigate quantum SN-guided three-way LSGDM under incomplete MSISs. First, MSISs are designed to gather information across spatial dimensions. Second, trust propagation paths within SNs are aggregated using quantum theory. Following community clustering through the Leiden algorithm, each community is further divided into core and fringe regions by three-way clustering (TWC), where core alternatives reflect the central members and fringe alternatives represent uncertain members. Third, to achieve intra-group consensus, the weights of DMs in fringe regions and those with low consensus levels are adjusted, while for inter-group consensus, the weight and decision information of community representatives with low consensus levels are modified. Fourth, alternatives are classified using the TWD method, which is grounded in the Dempster-Shafer theory and incorporates the enhanced belief Jensen-Sharma-Mittal ( E B J S M ) divergence. Finally, air quality datasets are used to validate the practicality of this method through sensitivity analysis, simulation analysis, comparative analysis, and statistical analysis.},
  archive      = {J_ESWA},
  author       = {Rui Li and Chao Zhang and Hamido Fujita and Wentao Li and Witold Pedrycz and Oscar Castillo},
  doi          = {10.1016/j.eswa.2025.129666},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129666},
  shortjournal = {Expert Syst. Appl.},
  title        = {Three-way large-scale group decision-making under incomplete multi-scale information systems: A perspective of quantum social networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GDCR: Geometry-enhanced directional consistency representation for point cloud analysis. <em>ESWA</em>, <em>298</em>, 129665. (<a href='https://doi.org/10.1016/j.eswa.2025.129665'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point clouds provide discrete representations of 3D scenes. The relative positions and directions between points collectively describe the objects. Variations in sampling angles, distances, or noises can introduce perturbations, disrupting these spatial and directional relationships. These pose significant challenges for achieving robust feature representations. However, research on the robust representation of point clouds is limited. Although advanced models achieve impressive performance, they exhibit poor robustness to perturbations. To address this issue, we propose Geometry-enhanced Directional Consistency Representation (GDCR), a novel method designed to enhance robustness. In GDCR, we introduce Statistic-based Geometric Reasoning (SGR) to achieve precise spatial geometric estimation for discrete point sets, explicitly enriching spatial geometric information. Furthermore, GDCR vectorizes features embedded with SGR information and applies feature rotation and relative direction refinement in the expanded feature space for robust directional representation. GDCR improves the flexibility and directional expressiveness of point cloud features, significantly improving robustness against perturbations. Extensive experiments demonstrate that GDCR exhibits outstanding robustness while surpassing or matching the performance of state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Ziming Wang and Boxiang Zhang and Ming Ma and Yue Wang and Taoli Du and Ying Wang and Wenhui Li},
  doi          = {10.1016/j.eswa.2025.129665},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129665},
  shortjournal = {Expert Syst. Appl.},
  title        = {GDCR: Geometry-enhanced directional consistency representation for point cloud analysis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). APMoE-net: Fourier amplitude-phase joint enhancement and MoE compensation for low-light image enhancement. <em>ESWA</em>, <em>298</em>, 129664. (<a href='https://doi.org/10.1016/j.eswa.2025.129664'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-Light Image Enhancement (LLIE) plays a crucial role in computer vision applications. Beyond spatial-based approaches, recent works have explored the Fourier domain. To better preserve structural details in extremely dark scenes, infrared modality has also been introduced as a robust prior for capturing scene geometry. However, existing methods suffer from limited enhancement performance due to the independent modeling of Fourier amplitude and phase, the limitations of cross-modal guidance, and the information loss in sequential feature extraction. To address these challenges, we propose APMoE-Net, a dual-stage Fourier network framework with amplitude-phase joint enhancement and spatial Mixture of Experts (MoE) compensation. Stage one performs coarse enhancement by leveraging infrared images to jointly optimize Fourier amplitude and phase, enabling mutual guidance learning between them. Subsequently, a Modality Refinement Module leverages edge information to refine infrared inputs, producing a refined modality map as a more accurate cross-modal prior for subsequent processing. The second stage employs a dual-branch design for texture refinement. Our key innovation lies in the MoE Compensation Module integrated within the Multi-scale Convolution Branch. This module employs a dynamic routing network to selectively activate specialized experts, enabling the recovery of fine-grained textures that are lost during sequential processing. Meanwhile, the Fourier Branch integrates the refined modality map to improve overall detail and contrast. Comprehensive experiments demonstrate that APMoE-Net surpasses state-of-the-art (SOTA) methods in both qualitative and quantitative evaluations. Notably, APMoE-Net achieves outstanding performance with a lightweight design, offering an efficient LLIE solution.},
  archive      = {J_ESWA},
  author       = {Mengen Cai and Tongshun Zhang and Pingping Liu and Qiuzhan Zhou},
  doi          = {10.1016/j.eswa.2025.129664},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129664},
  shortjournal = {Expert Syst. Appl.},
  title        = {APMoE-net: Fourier amplitude-phase joint enhancement and MoE compensation for low-light image enhancement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced edge detection of harmful algal blooms using diffusion probability models and sobel-convolutional attention mechanisms. <em>ESWA</em>, <em>298</em>, 129663. (<a href='https://doi.org/10.1016/j.eswa.2025.129663'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection and identification of harmful algal bloom (HAB) images are crucial for developing effective early warning systems for HABs. However, existing edge detection models, primarily designed for natural scenes, struggle with HAB-specific challenges such as blurred cell contours and interference from impurity bubbles. To address these issues, we propose a novel edge detection approach tailored for marine HABs, integrating a diffusion probability model with Sobel convolutional inter-layer attention mechanisms. Firstly, we develop an image enhancement algorithm specifically for HABs images, significantly improving real-time dynamic sampling data by enhancing contrast, edges, and texture features. Next, we introduce the SIAnet network, which utilizes inter-layer attention and convolutional operations to generate comprehensive global information. This network enhances feature correlation by aggregating shared features across multiple layers and modeling both long-range and short-range dependencies, effectively suppressing noise and background interference. This facilitates precise extraction of algae boundaries and morphological characteristics. Additionally, an improved Sobel operator is employed to generate supplementary edge features, accelerating the training process. Experimental results demonstrate that the proposed method achieves robust performance on the HABs dataset, with an Optimal Dataset Scale (ODS) of 0.645, an Optimal Image Scale (OIS) of 0.702, and an Average Precision (AP) of 0.813. Compared to existing methodologies, our approach demonstrates strong generalization on BSDS and BIPED datasets, significantly enhancing performance and mitigating typical CNN issues of edge thickening and fragmentation. It offers essential technical support for efficient HAB early warning system development.},
  archive      = {J_ESWA},
  author       = {Gengkun Wu and Yining Fan and Xin Tian and Chao Cui and Jiazheng Han},
  doi          = {10.1016/j.eswa.2025.129663},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129663},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhanced edge detection of harmful algal blooms using diffusion probability models and sobel-convolutional attention mechanisms},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predictive modeling of biogeographical ancestry using a novel SNP panel and supervised learning approaches. <em>ESWA</em>, <em>298</em>, 129662. (<a href='https://doi.org/10.1016/j.eswa.2025.129662'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring an individual’s BioGeographical Ancestry (BGA) through DNA analysis is a valuable tool in various fields such as forensic science, especially when traditional methods fail to identify suspects or victims. Advances in Next-Generation Sequencing (NGS) have revolutionized genomic data acquisition, enabling the development of comprehensive Single Nucleotide Polymorphism (SNP) panels for ancestry inference. This study assessed the effectiveness of a novel panel containing 3234 SNPs at both inter-continental and a more detailed BGA level, using various supervised Machine Learning (ML) models, including Categorical Naive Bayes, Penalized Multinomial Logistic Regression, Linear Support Vector Machines, Random Forest, and tree-based Gradient Boosting. A nested cross-validation approach was employed for model tuning and evaluation, with balanced accuracy as the main performance metric to address class imbalance. At the inter-continental level, all ML models demonstrated high balanced accuracy, confirming their reliability for BGA inference. However, performance declined at the more detailed continental level, likely due to a combination of factors including increased class imbalance, reduced sample sizes for certain populations, and the inherent complexity of distinguishing genetically and geographically proximate groups. Nonetheless, promising results were observed for South Asians, Northeast Asians, Europeans, and West Africans classes. In contrast, performance was notably lower for underrepresented classes such as Inner Asians. Misclassification patterns at both levels appeared to reflect known geographical and historical relationships, although further analysis revealed that these were often concentrated in underrepresented or genetically complex groups. These findings highlighted the potential of this SNP panel and ML approaches as valuable tools for forensic investigations.},
  archive      = {J_ESWA},
  author       = {Cosimo Grazzini and Giorgia Spera and Stefania Morelli and Daniele Castellana and Giulia Cosenza and Michela Baccini and Giulia Cereda and Elena Pilli},
  doi          = {10.1016/j.eswa.2025.129662},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129662},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predictive modeling of biogeographical ancestry using a novel SNP panel and supervised learning approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RL-CoSeg: A reinforcement learning-based collaborative localization and segmentation framework for medical image. <em>ESWA</em>, <em>298</em>, 129661. (<a href='https://doi.org/10.1016/j.eswa.2025.129661'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmenting small regions of interest (ROIs) from abdominal CT images presents significant challenges, particularly due to class imbalance and variations in the sizes of foreground objects. A commonly adopted solution is the two-stage segmentation. However, this approach has two key limitations: i) Difficulty in balancing localization accuracy and target preservation. To reduce information loss in the first stage, existing methods typically enlarge the predicted bounding boxes, which improves coverage but compromises localization precision. ii) Independent optimization of the two stages, which lacks a collaborative mechanism. This fragmented pipeline limits the flow of information between stages, thereby constraining performance improvements. To address these limitations, we propose a reinforcement learning-based collaborative localization and segmentation (RL-CoSeg) framework, which comprises three sub-networks: localization network (LN), segmentation network, and localization-segmentation collaboration network (LSCN). The LN integrates prior knowledge and incorporates a dynamic reward mechanism to enhance the accuracy and efficiency of target detection through reinforcement learning (RL) strategies. The LSCN further introduces segmentation predictions as a reward signal, which, together with the localization reward, jointly drives policy learning. In addition, a heuristic exploration strategy is employed to avoid local optima and improve training stability. This design strengthens the information interaction and collaborative performance between the two tasks. Experimental results demonstrate that the proposed method achieves superior collaborative performance in small-target medical image segmentation.},
  archive      = {J_ESWA},
  author       = {Feilong Xu and Feiyang Yang and Xiaoli Zhang and Zhaojun Liu},
  doi          = {10.1016/j.eswa.2025.129661},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129661},
  shortjournal = {Expert Syst. Appl.},
  title        = {RL-CoSeg: A reinforcement learning-based collaborative localization and segmentation framework for medical image},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SH-ETRs:Learning soft-hard rules with entity type constraints for document-level relation extraction. <em>ESWA</em>, <em>298</em>, 129660. (<a href='https://doi.org/10.1016/j.eswa.2025.129660'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction (DocRE) aims to extract relations between entity pairs across the entirety of a document. Current methods have begun to adopt logical rules to enhance the performance of DocRE models. However, the pipeline’s rule learning framework will suffer from the issue of error propagation, and the end-to-end method may lead to mistakes in rule reasoning. Additionly, they ignore entity type information when learning the rules. To address these issues, we propose a novel framework named Soft-Hard Rules with Entity Type Constraints (SH-ETRs) for improving the rules’ expressiveness and quality. Specifically, we first propose a Hard Entity Type Rules Module (H-ETRs) to learn entity type information and provide hard rule constraints. Then, we propose a Soft Entity Type Rule Reasoning Module (S-ETRs), which parameterizes the rule inference process and reduces error propagation during the process. Furthermore, by applying a rule consistency loss function to S-ETRs, we achieve the learning of soft rules under hard rule constraints, thereby aiming to prevent the learning of inaccurate rules during the training process. The experimental results demonstrate that our method outperforms existing rule learning frameworks, achieving state-of-the-art performance with an F1 score of 74.39 and an IgnF1 score of 67.43 across three public datasets and two baseline models.},
  archive      = {J_ESWA},
  author       = {Haisong Chen and Nisuo Du and Qing He and Yuji Wang},
  doi          = {10.1016/j.eswa.2025.129660},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129660},
  shortjournal = {Expert Syst. Appl.},
  title        = {SH-ETRs:Learning soft-hard rules with entity type constraints for document-level relation extraction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable knowledge tracing with dual-level knowledge states. <em>ESWA</em>, <em>298</em>, 129658. (<a href='https://doi.org/10.1016/j.eswa.2025.129658'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) is a critical technology for achieving personalized learning. It estimates learners’ knowledge states and predicts future performance using historical interaction data. Despite recent advances, two significant challenges remain. First, the accuracy of knowledge state modeling is limited by the insufficient fusion of multi-scale information across temporal and spatial dimensions. Second, a trade-off persists between improving predictive performance and enhancing interpretability. This paper proposes an interpretable knowledge tracing method based on dual-level knowledge states (DIKT) to address these challenges. From the temporal perspective, DIKT incorporates a forgetting-aware RoLinear Transformer and a semantic similarity-based review mechanism to model learners’ problem-level knowledge states. From the spatial perspective, it leverages a Knowledge Concept (KC) relational graph to propagate influence among related KCs and dynamically update learners’ concept-level knowledge states through three sequential learning phases: forgetting, aggregation, and updating. Student performance is predicted using a two-parameter Item Response Theory (IRT) model, which incorporates guess and slip parameters to account for response anomalies. We conduct extensive comparisons between DIKT and 20 state-of-the-art KT models on five widely used public datasets. Experimental results demonstrate that DIKT achieves superior performance while preserving interpretability, highlighting its practical potential for real-world educational applications. The code is available at https://github.com/ting214/DIKT .},
  archive      = {J_ESWA},
  author       = {Yanting Li and Tao Zhou and Tianyu Cai and Shenggen Ju},
  doi          = {10.1016/j.eswa.2025.129658},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129658},
  shortjournal = {Expert Syst. Appl.},
  title        = {Interpretable knowledge tracing with dual-level knowledge states},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RASpan: Improving toponym recognition through span representation model with retrieval augmentation. <em>ESWA</em>, <em>298</em>, 129657. (<a href='https://doi.org/10.1016/j.eswa.2025.129657'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Toponym recognition aims to identify place names from natural language texts, which is vital for various applications including geographic information retrieval, emergency response, and natural disaster analysis. Currently, mainstream studies mainly adopt deep learning models for toponym recognition. However, these approaches encounter significant limitations due to the inherent ambiguity, variation, and abbreviation of toponyms. To address these issues, we propose a novel Span Representation Model with R etrieval A ugmentation ( RASpan ) that leverages more accurate span representation and effective external geo-entity information to enhance the semantic representation of place names for improving the performance of toponym recognition. On the one hand, RASpan retrieves diverse geo-entities and concatenates geo-entity knowledge with an input sequence to construct a new prompt sequence. On the other hand, RASpan utilizes the prompt encoder based on the language model to encode this prompt sequence and employs a dedicated span representation module to obtain more accurate span representations. In addition, a new geo-entity prediction task is designed to learn the entire representation of each geo-entity while minimizing noise interference. Experiments on three publicly available datasets demonstrate that our model achieves new state-of-the-art results, highlighting the effectiveness of RASpan in toponym recognition by introducing prior geo-entity knowledge.},
  archive      = {J_ESWA},
  author       = {Hui Wu and Anran Yang and Zhinong Zhong and Ye Wu and Fei Yang and Luo Chen and Ning Jing},
  doi          = {10.1016/j.eswa.2025.129657},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129657},
  shortjournal = {Expert Syst. Appl.},
  title        = {RASpan: Improving toponym recognition through span representation model with retrieval augmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An interpretable automated optimized machine learning for predicting concrete compressive strength. <em>ESWA</em>, <em>298</em>, 129656. (<a href='https://doi.org/10.1016/j.eswa.2025.129656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel, interpretable, and automated machine learning (AutoML) framework for accurately predicting the compressive strength of environmentally sustainable concrete mixtures that incorporate supplementary cementitious materials (SCMs) by addressing the growing need for transparent and data driven tools in structural material design, particularly for concrete mixes enriched with various SCMs. A robust unified dataset of 1,317 samples was curated by integrating peer-reviewed experimental studies for this study. The proposed methodology incorporates feature contribution ranking through mutual information, model screening with AutoML to identify the most effective regression models, Bayesian optimization for fine-tuning model parameters, and interpretability techniques including SHAP and counterfactual analysis. The best performance metrics, in training include R 2 of 0.999, a mean absolute error 0.114, root mean squared error 0.7094, and mean absolute percentage error of 0.51 %, in testing phase R 2 of 0.944, a mean absolute error 3.479, root mean squared error 4.8173, and mean absolute percentage error of 9.86 %. The weakest performance, with a training R 2 of 0.982 and a mean absolute error of 1.911 MPa, root mean squared error 2.7990 and mean absolute percentage error 5.43 %, in testing phase R 2 of 0.786 and a mean absolute error of 5.754 MPa, root mean squared error 9.4336 and mean absolute percentage error 16.16 %. The interpretability analysis values provided insights into the most important features, such as curing time and cement are crucial in predicting the strength. Counterfactual analysis further validated the model by illustrating the significant impact of cement, age and water on concrete strength.},
  archive      = {J_ESWA},
  author       = {Aparna Kamarthi and Baskar Kaliyamoorthy},
  doi          = {10.1016/j.eswa.2025.129656},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129656},
  shortjournal = {Expert Syst. Appl.},
  title        = {An interpretable automated optimized machine learning for predicting concrete compressive strength},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT. <em>ESWA</em>, <em>298</em>, 129655. (<a href='https://doi.org/10.1016/j.eswa.2025.129655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative AI paraphrased text can be used for copyright infringement and the AI paraphrased content can deprive substantial revenue from original content creators. Despite this recent surge of malicious use of generative AI, there are few academic publications that research this threat. In this article, we demonstrate the ability of pattern-based similarity detection for AI paraphrased news recognition. We propose an algorithmic scheme, which is not limited to detect whether an article is an AI paraphrase, but, more importantly, to identify that the source of infringement is the ChatGPT. The proposed method is tested with a benchmark dataset specifically created for this task that incorporates real articles from BBC, incorporating a total of 2,224 articles across five different news categories, as well as 2,224 paraphrased articles created with ChatGPT. Results show that our pattern similarity-based method, that makes no use of deep learning, can detect ChatGPT assisted paraphrased articles at percentages 96.23% for accuracy, 96.25 for precision, 96.21% for sensitivity, 96.25% for specificity and 96.23% for F1 statistic.},
  archive      = {J_ESWA},
  author       = {Konstantinos F. Xylogiannopoulos and Petros Xanthopoulos and Panagiotis Karampelas and Georgios A. Bakamitsos},
  doi          = {10.1016/j.eswa.2025.129655},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129655},
  shortjournal = {Expert Syst. Appl.},
  title        = {The power of text similarity in identifying AI-LLM paraphrased documents: The case of BBC news articles and ChatGPT},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic collaborative evolutionary network: A novel spatio-temporal feature extraction framework for EEG emotion recognition. <em>ESWA</em>, <em>298</em>, 129654. (<a href='https://doi.org/10.1016/j.eswa.2025.129654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, significant progress has been made in emotion recognition research based on electroencephalogram (EEG) signals. However, existing methods face two key limitations: on one hand, the reliance on fixed physical connections or static topological relationships makes it difficult to effectively represent the dynamic non-Euclidean spatial characteristics between EEG electrodes; on the other hand, spatiotemporal feature extraction is often conducted independently. This lack of a collaborative mechanism for spatiotemporal features results in insufficient fine-grained emotional representation capability. To address these issues, a dynamic collaborative evolutionary network (DCENet) is proposed based on graph-aware enhancement and global convolutional Transformer for EEG emotion recognition. DCENet constructs the causal relationship between electrodes by constructing the graph-aware enhancement (GAE) module, obtains spatial features with the causal relationship, and enhances key features. At the same time, DCENet constructs the global convolutional Transformer (GCT) module, which utilizes the global modeling advantage of the Transformer and the local perception ability of the convolutional operation to capture the temporal features with different scales. In addition, DCENet adaptively fuses temporal and spatial features through the local differential fusion (LDF) module to achieve cross-domain feature alignment and feature alignment of emotion categories to collaboratively evolve emotion representation features with more fine-grained information. This paper conducts experiments on the SEED, SEED-IV, and MPED datasets to validate the effectiveness of DCENet. The experimental results show that the model achieves cross-subject average accuracies of 87.55 %, 73.04 %, and 27.72 % on SEED, SEED-IV, and MPED, respectively, outperforming the state-of-the-art methods. The source code is publicly available at: https://github.com/cvmdsp/DCENet .},
  archive      = {J_ESWA},
  author       = {Shuaiqi Liu and Zhihui Gu and Yuan Zhang and Yanling An and Shuhuan Zhao and Bing Li and Yudong Zhang},
  doi          = {10.1016/j.eswa.2025.129654},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129654},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic collaborative evolutionary network: A novel spatio-temporal feature extraction framework for EEG emotion recognition},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Med-D3CG: Wavelet-based diffusion in the difference domain for cross-modality medical image generation. <em>ESWA</em>, <em>298</em>, 129651. (<a href='https://doi.org/10.1016/j.eswa.2025.129651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The synthesis of cross-modal medical images plays a vital role in bridging diagnostic gaps between imaging modalities such as CT, MRI, and PET. This integration enables a more comprehensive evaluation of a patient’s condition, improving diagnostic accuracy and aiding clinical decision-making. However, the performance of conditional denoising diffusion probabilistic models is often hindered by pronounced structural and intensity discrepancies between modalities, as well as the inherently slow nature of the diffusion process. To address these challenges, this paper proposes Wavelet-Based Diffusion in the Difference Domain for Cross-Modality Medical Image Generation (Med-D3CG), a novel framework that transforms the synthesis process by emphasizing the difference domain. Instead of directly generating target images like conventional methods, Med-D3CG models the residual information between conditioned and target images. This strategy allows the framework to accurately capture essential structural and intensity variations between modalities, leading to more precise and realistic image synthesis. Additionally, Med-D3CG integrates the Discrete Wavelet Transform (DWT) to improve efficiency, accelerating the diffusion process while maintaining high image fidelity. On SynthRAD2023 and HMIFD datasets, state-of-the-art performance is achieved on pelvis and HMIFD using Med-D3CG , with the best Learned Perceptual Image Patch Similarity (LPIPS) and competitive FID observed on brain. Code and pretrained models are provided at https://github.com/ZgzTTTer/Med-D3CG .},
  archive      = {J_ESWA},
  author       = {Guangzhen Zhu and Midi Wan and Wenming Cao and Zhiwen Yu and Jin Hu and Bing Li and Xiaotao Fan},
  doi          = {10.1016/j.eswa.2025.129651},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129651},
  shortjournal = {Expert Syst. Appl.},
  title        = {Med-D3CG: Wavelet-based diffusion in the difference domain for cross-modality medical image generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Two-stage feature selection utilizing three-way adaptive neighborhood characteristic measure and optimal combination search. <em>ESWA</em>, <em>298</em>, 129650. (<a href='https://doi.org/10.1016/j.eswa.2025.129650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neighborhood rough set model(NRSM) has shown its powerful capacity in feature selection. However, a challenge still exists in describing the diversity between the attributes deeply while avoiding the impact caused by the neighborhood parameters. To address this problem, in this paper, we propose a two-stage feature selection by utilizing a three-way adaptive characteristic measure and an optimal combination search. First, we define a fitness function for applying the Stochastic Fractal Search(SFS) to design an novel adaptive neighborhood rough set model(ANRSM). To better utilize the construction characteristic of the adaptive model and reduce the computational cost, the lower and upper approximations of the SFS-based ANRSM are redefined through the fitness function. Second, based on the two approximations, we analyze the fitness function thresholds that can partition the universe into three regions and design the three-way adaptive neighborhood characteristic regions, which provide a more direct classification of samples without the inclusion and union operations. Third, we design different measures for the samples in diverse regions based on their corresponding characteristic. Afterward, a three-way adaptive characteristic measure is designed by integrating the three measures to evaluate the uncertainty of attributes. Then, we apply the measure to design a feature selection approach with greedy search. Considering that the greedy strategy may output redundant attributes, we introduce an optimal combination search approach through a novel wrapper technology to explore the potential optimal feature combinations. Compared with nine algorithms on fourteen public datasets, the experimental results show the effectiveness of our algorithm.},
  archive      = {J_ESWA},
  author       = {Bowen Lin and Duoqian Miao and Caihui Liu and Hongyun Zhang and Ruizhi Wang and Witold Pedrycz},
  doi          = {10.1016/j.eswa.2025.129650},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129650},
  shortjournal = {Expert Syst. Appl.},
  title        = {Two-stage feature selection utilizing three-way adaptive neighborhood characteristic measure and optimal combination search},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New semi-supervised fuzzy C-means clustering with asymmetric deviation constraints and fast algorithm. <em>ESWA</em>, <em>298</em>, 129648. (<a href='https://doi.org/10.1016/j.eswa.2025.129648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised clustering leverages prior information to improve algorithm performance and is widely valued by researchers. This paper analyzes the traditional semi-supervised fuzzy C-means (SFCM) objective function, noting that as a labeled sample’s membership degree aligns with its prior information, the impact of this information on the deviation constraint weakens. This reduces its supervisory effect on optimizing the membership partition matrix, especially with a large regularization factor. To overcome this, we propose a novel semi-supervised fuzzy C-means method based on an asymmetric deviation constraint and develop a two-level alternating iterative optimization algorithm, supported by theoretical convergence analysis using Zangwill’s theorem and the bordered Hessian matrix. To address the slow convergence and high computational cost typical of semi-supervised fuzzy clustering, we further enhance the algorithm with affinity filtering and a membership scaling scheme for improved efficiency. Experimental results demonstrate that our methods significantly outperform existing state-of-the-art techniques, advancing semi-supervised fuzzy C-means clustering.},
  archive      = {J_ESWA},
  author       = {Chengmao Wu and Jun Hou},
  doi          = {10.1016/j.eswa.2025.129648},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129648},
  shortjournal = {Expert Syst. Appl.},
  title        = {New semi-supervised fuzzy C-means clustering with asymmetric deviation constraints and fast algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predictive modeling and multi-objective optimization of screw whirling milling based on ISSA-BP embedded NSGA-III algorithm. <em>ESWA</em>, <em>298</em>, 129644. (<a href='https://doi.org/10.1016/j.eswa.2025.129644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In screw whirling milling, the relationship between machining quality and processing parameters exhibits highly nonlinear characteristics. The traditional multiple regression models may not be able to capture this complex relationship accurately. Therefore, it is necessary to consider more flexible and applicable algorithms to establish their connections and optimize processing parameters. It can improve the accuracy and reliability of products, and provide more scientific method guidance for screw whirling milling processing. The originality of this article lies in proposing an adaptive dynamic optimization hybrid model. This model combines improved sparrow search algorithm optimized backpropagation (ISSA-BP) and non-dominated sorting genetic algorithm (NSGA-III). It can effectively adapt to dynamic data and find the optimal balance point among multiple objectives to better predict and optimize responses (cutting force, vibration, roughness, and residual compressive stress) in screw whirling milling. Firstly, a suitable network structure is identified by comparing the effects of five improvement strategies, population size, and the ratio of producers to scouters on the sparrow search algorithm. Then, an ISSA-BP prediction model is developed for four responses based on this structure. On this basis, the superiority of the established ISSA-BP model is verified by comparing prediction performance of five algorithms, and the relative prediction errors are all within 2%. The R 2 values of the models are all above 0.99, and they also perform well in indicators such as MAE (Mean Absolute Error), MSE (Mean Squared Error), MAPE (Mean Absolute Percentage Error), and RMSE (Root Mean Squared Error). Then, ISSA-BP model is encapsulated and embedded into the optimization algorithm as the fitness function of NSGA-III. Finally, with the processing parameters of whirling milling as constraints, the NSGA-III algorithm is used to solve the proposed model and obtain the Pareto optimal solution set. Choosing appropriate processing parameters according to different needs in actual machining can help improve the quality and efficiency of screw machining.},
  archive      = {J_ESWA},
  author       = {Chao Liu and Hao Ding and Juanjuan Zheng and Yan He and Shaofu Huang and Junbo Tuo and Zuqing Luo and Gang Shen},
  doi          = {10.1016/j.eswa.2025.129644},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129644},
  shortjournal = {Expert Syst. Appl.},
  title        = {Predictive modeling and multi-objective optimization of screw whirling milling based on ISSA-BP embedded NSGA-III algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A survey of large language models for data challenges in graphs. <em>ESWA</em>, <em>298</em>, 129643. (<a href='https://doi.org/10.1016/j.eswa.2025.129643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are a widely used paradigm for representing non-Euclidean data, with applications ranging from social network analysis to biomolecular prediction. While graph learning has achieved remarkable progress, real-world graph data presents a number of challenges that significantly hinder the learning process. In this survey, we focus on four fundamental data-centric challenges: (1) Incompleteness , real-world graphs have missing nodes, edges, or attributes; (2) Imbalance , the distribution of the labels of nodes or edges and their structures for real-world graphs are highly skewed; (3) Cross-domain Heterogeneity , graphs from different domains exhibit incompatible feature spaces or structural patterns; and (4) Dynamic Instability , graphs evolve over time in unpredictable ways. Recently, Large Language Models (LLMs) offer the potential to tackle these challenges by leveraging rich semantic reasoning and external knowledge. This survey focuses on how LLMs can address four fundamental data-centric challenges in graph-structured data, thereby improving the effectiveness of graph learning. For each challenge, we review both traditional solutions and modern LLM-driven approaches, highlighting how LLMs contribute unique advantages. Finally, we discuss open research questions and promising future directions in this emerging interdisciplinary field. To support further exploration, we have curated a repository of recent advances on graph learning challenges: https://github.com/limengran98/Awesome-Literature-Graph-Learning-Challenges .},
  archive      = {J_ESWA},
  author       = {Mengran Li and Pengyu Zhang and Wenbin Xing and Yijia Zheng and Klim Zaporojets and Junzhou Chen and Ronghui Zhang and Yong Zhang and Siyuan Gong and Jia Hu and Xiaolei Ma and Zhiyuan Liu and Paul Groth and Marcel Worring},
  doi          = {10.1016/j.eswa.2025.129643},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129643},
  shortjournal = {Expert Syst. Appl.},
  title        = {A survey of large language models for data challenges in graphs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Region-aware prediction strategy based on shared points and multiple scales for dynamic multi-objective optimization. <em>ESWA</em>, <em>298</em>, 129642. (<a href='https://doi.org/10.1016/j.eswa.2025.129642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic multi-objective optimization problems, effectively predicting and tracking the Pareto optimal front (POF) under environmental changes has been one of the core challenges. In this paper, we propose a region-aware prediction strategy based on shared points and multiple scales (RADMOEA) that combines global and local characteristics, aiming to enhance the algorithm’s ability to sense and adapt to POF. Firstly, the center-point movement strategy is used to move the non-dominated solution set from the previous moment to obtain the non-dominated solution set after the movement. The actual non-dominated solution set at the current moment and the non-dominated solution set after the movement share points in the objective space, and these shared points divide the non-dominated solution set at the current moment into several subregions. Within each region, all individuals are appropriately rescaled, and a local coordinate system is established. Then, within the local coordinate system, each individual is associated with the nearest post-movement non-dominated individual. Finally, new populations adapted to environmental changes are generated by combining centroid movement directions, Gaussian perturbations, and multi-scale individual association relationships. The proposed strategy is compared with six advanced algorithms, and the experimental results demonstrate that RADMOEA is effective in tracking the POF under dynamic environments.},
  archive      = {J_ESWA},
  author       = {Yaru Hu and Sitong Wang and Junwei Ou and Zhenlin Mei and Juan Zou and Shengxiang Yang},
  doi          = {10.1016/j.eswa.2025.129642},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129642},
  shortjournal = {Expert Syst. Appl.},
  title        = {Region-aware prediction strategy based on shared points and multiple scales for dynamic multi-objective optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A transformer network for multi-dimensional nonuniform aperture synthesis radiometer image inversion. <em>ESWA</em>, <em>298</em>, 129641. (<a href='https://doi.org/10.1016/j.eswa.2025.129641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Passive microwave remote sensing plays a vital role in Earth observation, with applications in soil moisture, ocean salinity, and atmospheric monitoring. However, improving spatial resolution at low frequencies remains challenging. Recently, combining multiple small antenna arrays into a larger one has emerged as a technological approach to enhance spatial resolution. Nevertheless, aperture synthetic radiometers formed by such combinations usually consist of non-uniform antenna arrays (one-dimensional, two-dimensional, or three-dimensional). Compared with regular antenna arrays, they complicate the inversion of brightness temperature (BT) images. This paper proposes NASRT, a transformer-based inversion method designed for multi-dimensional non-uniform ASRs. The network extracts and fuses spectral and UVW spatial distribution features from the visibility function (VF), and introduces a learnable position weight matrix during training to capture spatial information of the non-uniform array. Through supervised learning, NASRT effectively maps the VF to BT images. Simulations across 1-D, 2-D, and 3-D NASR scenes demonstrate that NASRT achieves higher accuracy and stability than traditional methods. In a 1-D NASR indoor experiment, the proposed method also shows improved inversion accuracy and lower sidelobes, validating its effectiveness.},
  archive      = {J_ESWA},
  author       = {Jian Dong and Jiaxin Li and Chengwang Xiao and Rigeng Wu and Haofeng Dou and Wenjing Wang and Yuanchao Wu and Liangbing Chen},
  doi          = {10.1016/j.eswa.2025.129641},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129641},
  shortjournal = {Expert Syst. Appl.},
  title        = {A transformer network for multi-dimensional nonuniform aperture synthesis radiometer image inversion},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OceanAgent: A small-scale multi-modal assistant for ocean exploration. <em>ESWA</em>, <em>298</em>, 129640. (<a href='https://doi.org/10.1016/j.eswa.2025.129640'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extraction of key information and the subsequent generation of actionable knowledge from multimodal data are critical for ocean exploration. Traditional knowledge generation methods rely heavily on expert experience and are labor-intensive. Recently, Large Multimodal Models (LMMs) have shown exceptional capabilities for knowledge generation from multimodal data in many complex tasks. These models also have potential to assist knowledge mining in ocean exploration. However, two major challenges faced by the LMMs when used in ocean exploration include the scarcity of ocean instruction-following data and the degradation of underwater visual environments. In this paper, a small-scale LMM for ocean exploration, named the OceanAgent, is designed. First, a swarm-intelligence-based leaderless multi-agent collaboration framework is proposed to generate visual instruction-following data. Subsequently, we present a visual-language connector to simultaneously extract multi-scale features. It is formed by integrating a multi-scale residual network with a multi-layer perceptron, which can enhance the model’s performance on severely low-quality images. Experiments show that the proposed method for constructing visual instruction-following datasets improves both the textual quality and visual dialogue. When severely degraded ocean visual data are processed using the trained OceanAgent, the image description accuracy and image comprehension are improved by 23.6 % and 21.6 %, respectively, compared to existing models. Additionally, the model demonstrates superior domain expertise, with a 95.7 % win rate in dialogue quality assessments.},
  archive      = {J_ESWA},
  author       = {Yun Xu and Yue Liu and Junpeng Shang and Jianmin Lin and Dongfang Ma},
  doi          = {10.1016/j.eswa.2025.129640},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129640},
  shortjournal = {Expert Syst. Appl.},
  title        = {OceanAgent: A small-scale multi-modal assistant for ocean exploration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPS-GAD: Spectral-spatial graph structure learning for anomaly detection in heterophilic graphs. <em>ESWA</em>, <em>298</em>, 129639. (<a href='https://doi.org/10.1016/j.eswa.2025.129639'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection(GAD) plays a critical role in fields such as fraud detection and network security. Although existing graph anomaly detection methods have achieved promising performance, most graph neural networks (GNNs) rely on the homophily assumption, which presumes that connected nodes share similar labels. However, real-world graphs frequently exhibit pronounced heterophily. Owing to class imbalance, normal nodes tend to have lower heterophily while anomalous nodes display higher heterophily. Furthermore, feature inconsistency induced by node camouflage exacerbates the detection challenge, rendering many existing approaches ineffective. To overcome these limitations, we propose SPS-GAD, a spectral-spatial graph structure learning framework specifically designed for detecting anomalous nodes in heterophilic graphs. First, to alleviate the feature inconsistency resulting from node camouflage, we develop a node reconstruction module that learns intermediate node representations to mitigate camouflage-induced bias, and applies spectral filters to extract the graph’s inherent structural features. Second, to address the heterophily disparities arising from class imbalance, we introduce a subgraph-type-aware spectral filtering module that leverages edge scores generated by an edge partitioner to segregate the graph into homophilic, ambiguous, and heterophilic subgraphs. Distinct spectral filters are subsequently applied to capture features across various frequency bands. Additionally, we integrate a neighbor-type-aware graph attention module that employs edge scores within an attention mechanism to guide the feature aggregation process, thereby enhancing spatial representation learning. Experimental evaluations on six real-world datasets reveal that SPS-GAD significantly outperforms all baseline methods in key metrics such as F1-Macro and AUC, thereby confirming its effectiveness in graph anomaly detection. The source code is publicly available at https://github.com/cozy24/SPS-GAD .},
  archive      = {J_ESWA},
  author       = {Chen Zhu and Yaying Zhang},
  doi          = {10.1016/j.eswa.2025.129639},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129639},
  shortjournal = {Expert Syst. Appl.},
  title        = {SPS-GAD: Spectral-spatial graph structure learning for anomaly detection in heterophilic graphs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid fleet composition and scheduling for road-based cross-border logistics under cost differentiation: A bi-level programming approach. <em>ESWA</em>, <em>298</em>, 129636. (<a href='https://doi.org/10.1016/j.eswa.2025.129636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the dual pressure of explosive growth in cross-border e-commerce demand and increasing timeliness requirements from overseas customers, cross-border logistics service providers are compelled to establish logistics facilities and deploy fleets across multiple regions to ensure rapid response. However, during freight transportation, the lack of effective management over these complex and heterogeneous fleets—particularly in terms of fleet composition and routing decisions—has led to high transportation costs and low operational efficiency. This study is grounded in the practical operational context of cross-border logistics in the Guangdong–Hong Kong–Macau Greater Bay Area and models a multi-level, multi-node cross-border transportation network. To minimize the overall operational cost, the problem is addressed from two interrelated decision-making perspectives: fleet composition at the strategic level and routing planning at the operational level. Thus, a bi-level programming model is proposed to systematically capture the hierarchical structure and the logical relationship between these two decision layers. Furthermore, the model incorporates cost differences among trucks with different functional capabilities to reflect the significant disparity in logistics cost structures between domestic and overseas operations. To address the above multi-objective mixed-integer linear programming (MILP) problem, a tailored Non-dominated Sorting Genetic Algorithm II (MNSGA-II) is developed. Several key components of the algorithm are modified and enhanced to improve its search efficiency and solution quality in handling the problem’s complexity. Comparative experiments against classical algorithms demonstrate the superior solution quality and robustness of the proposed approach. The influence of cost differentials on composition and scheduling decisions is further analyzed, providing practical insights for the strategic planning of cross-border logistics systems.},
  archive      = {J_ESWA},
  author       = {Zhi Tang and Ting Qu and Yanghua Pan and George Q. Huang},
  doi          = {10.1016/j.eswa.2025.129636},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129636},
  shortjournal = {Expert Syst. Appl.},
  title        = {Hybrid fleet composition and scheduling for road-based cross-border logistics under cost differentiation: A bi-level programming approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A diversity-based niching differential evolution with neighborhood competition for nonlinear equation systems. <em>ESWA</em>, <em>298</em>, 129635. (<a href='https://doi.org/10.1016/j.eswa.2025.129635'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving nonlinear equation systems (NESs) has long been a fundamental challenge in the field of optimization. Due to the existence of multiple roots, such problems often exhibit complex and multimodal characteristics. Although numerous differential evolution-based algorithms have been developed to solve NESs, most of them employ only a single mutation operator, which is not adaptable to different problem scenarios. To this end, a diversity-based niching differential evolution with neighborhood competition (DNDE) is proposed to solve NESs. First, a control mechanism that takes into account population diversity and the evolutionary stage is proposed to adaptively assign appropriate mutation strategies to each subpopulation (niche), thereby enhancing the efficiency of root-finding. Second, a neighborhood priority competition mechanism is proposed to reduce cross-peak competition between populations, which ensures local convergence while improving global convergence. Finally, a reinitialization strategy based on opposition learning is introduced to guide the population toward more promising areas of the search space. Experimental results on 18 complex NESs and two real-world engineering problems show that DNDE outperforms many advanced algorithms in both root rate and success rate, demonstrating its effectiveness and value in practical applications.},
  archive      = {J_ESWA},
  author       = {Jianwei Li and Xinchao Zhao and Lingyu Wu and Yizhan Wu and Lingjuan Ye},
  doi          = {10.1016/j.eswa.2025.129635},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129635},
  shortjournal = {Expert Syst. Appl.},
  title        = {A diversity-based niching differential evolution with neighborhood competition for nonlinear equation systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TGNet: Texture-enhanced guidance network for RGB-D salient object detection. <em>ESWA</em>, <em>298</em>, 129633. (<a href='https://doi.org/10.1016/j.eswa.2025.129633'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D salient object detection achieves salient region localization in complex scenes by fusing RGB images and depth images. Existing methods typically employ two-stream networks to extract features separately followed by cross-modal fusion. However, differences between heterogeneous modalities can easily lead to feature degradation during cross-modal fusion, while the inherent noise interference in low-quality depth maps may generate cumulative effects during multi-stage propagation, severely constraining detection performance. To address these challenges, this paper proposes a texture-enhanced guided network. The core innovations lie in three aspects: during the feature encoding stage, a texture-enhanced module is constructed to utilize high-frequency texture information from RGB images through attention mechanisms for hierarchical optimization of depth features; in the feature fusion stage, a dual-path adaptive interaction module is designed to establish cross-modal semantic correlations via channel-spatial cooperative driving mechanisms, effectively suppressing redundant feature interference; for the decoding reconstruction stage, a dynamic hierarchical guidance mechanism is proposed to drive progressive calibration of low-level spatial details by high-level semantic features through learnable cross-scale transformation modules. Extensive experiments conducted on five benchmark datasets demonstrate that our method achieves competitive performance compared to other approaches.},
  archive      = {J_ESWA},
  author       = {Xiaogang Song and Hexiang Huang and Qin Zhao and Xinwei Guo and Xinhong Hei},
  doi          = {10.1016/j.eswa.2025.129633},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129633},
  shortjournal = {Expert Syst. Appl.},
  title        = {TGNet: Texture-enhanced guidance network for RGB-D salient object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-stream temporal-spatial forgery detection via phase-consistent edge features and 3D visual state-space modeling. <em>ESWA</em>, <em>298</em>, 129632. (<a href='https://doi.org/10.1016/j.eswa.2025.129632'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deepfake, as a generative technology, has opened up new avenues for the development of the film, television, and art industries. However, its abusive use has triggered serious social security threats, such as infringement of portrait rights and the spread of misinformation, which has drawn widespread attention to research on deepfake detection techniques. Current deep learning-based face forgery detection methods face critical challenges: 1) insufficient focus on common forgery traces leads to poor generalization performance on datasets generated by unknown forgery methods; 2) traditional spatio-temporal feature fusion mechanisms struggle to balance the representational weights of spatial details and temporal dynamics, and exhibit inadequate robustness against post-processing operations like compression and cropping. To address these issues, this paper first designs a phase consistency edge artifact mining module is designed to extract common forgery traces from edge textures by leveraging the deep-phase information of images, significantly enhancing the model’s generalization ability. Second, a multi-frame synthesis strategy is designed to effectively integrate spatial and temporal features while balancing the network’s attention to these two feature domains. Third, a visual state-space model based on 3D scanning is designed, which for the first time employs the Mamba model to analyze spatio-temporal forgery patterns, notably improving the robustness of the model against unknown perturbations. Experimental results on standard benchmarks–FaceForensics++, Celeb-DFv2, WildDeepfake and DFDC(Preview)–demonstrate that the proposed method achieves state-of-the-art performance in three core dimensions: detection accuracy, cross-dataset generalization, and robustness against perturbations.},
  archive      = {J_ESWA},
  author       = {Zhong Chen and Siyang Wang and Zuxi Wang},
  doi          = {10.1016/j.eswa.2025.129632},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129632},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dual-stream temporal-spatial forgery detection via phase-consistent edge features and 3D visual state-space modeling},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LSTT: Long short-term feature enhancement transformer for video small object detection. <em>ESWA</em>, <em>298</em>, 129631. (<a href='https://doi.org/10.1016/j.eswa.2025.129631'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging temporal information is crucial for small object detection in videos. Existing methods typically incorporate long-term or short-term temporal information uniformly, neglecting distinct cues from different frames that are essential for small object detection. In this paper, we propose LSTT, an end-to-end multi-frame fusion network that concurrently extracts global scene context from long-term frames and fine-grained appearance and motion cues from short-term frames. First, we introduce a progressive spatiotemporal sampling module that sparsely samples long-range frames and densely samples short-range frames. Second, we design a spatiotemporal alignment encoder module to extract frame-level temporal and spatial pixel features. Finally, We propose a long short-term feature aggregation module that employs a dynamic query generator to derive adaptive queries by implicitly modeling motion relationships among short-term frames, and guides a cascaded fusion of aggregated features from long-term, short-term, and current frames to fuse temporal information. Compared to state-of-the-art methods, our LSTT achieves absolute gains of 1.4 % and 2.1 % in detection precision on VisDrone-VID and UAVDT datasets, respectively.},
  archive      = {J_ESWA},
  author       = {Jinsheng Xiao and Wenbo Liu and Ruidi Chen and Yuchen Yan and Wei Yang},
  doi          = {10.1016/j.eswa.2025.129631},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129631},
  shortjournal = {Expert Syst. Appl.},
  title        = {LSTT: Long short-term feature enhancement transformer for video small object detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scale-invariant information bottleneck for domain generalization. <em>ESWA</em>, <em>298</em>, 129628. (<a href='https://doi.org/10.1016/j.eswa.2025.129628'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One significant challenge in deep learning is the inability to effectively generalize to new data whose distribution differs from that of the training data. Hence, domain generalization has received increasing attention in related fields. Classical methods aim to identify an invariant predictor that can recognize invariant representations across all the training domains. However, these methods limit the model to rely solely on invariant representations, which hinders the learning of important finer details. To address this challenge, we propose a Scale-invariant Information Bottleneck (SIB) method to identify both invariant and scale-invariant features. We subsequently introduce a tractable loss function derived from the variational analysis. This novel method captures more detailed information, including fine textures and unique characteristics, while also eliminating irrelevant or spurious representations by using information bottleneck. Finally, extensive experiments conducted on Rotated MNIST, Colored MNIST, Colored Fashion-MNIST, PACS, Office-Home and Camelyon17-WILDS validate the effectiveness of our SIB method in addressing the domain generalization problems. Notably, our approach outperforms 14 existing methods with an average improvement of 4.74 %. More significantly, it surpasses 6 recent, related methods by an average of 2.21 %. Furthermore, we demonstrate the superiority of our method through the analysis of hidden feature maps and representations.},
  archive      = {J_ESWA},
  author       = {Mengyao Li and Jiangshe Zhang and Chunxia Zhang and Junmin Liu and Lizhen Ji},
  doi          = {10.1016/j.eswa.2025.129628},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129628},
  shortjournal = {Expert Syst. Appl.},
  title        = {Scale-invariant information bottleneck for domain generalization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal pricing for transfer of development rights under risk sharing: The context of china’s inter-provincial construction land quota trading. <em>ESWA</em>, <em>298</em>, 129627. (<a href='https://doi.org/10.1016/j.eswa.2025.129627'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific and rational prices are determinant for the success of transfer of development rights (TDR). Nevertheless, previous studies largely overlook the multifaceted impacts of risks on pricing, hampering market participation and value revelation. This is especially relevant in the context of China’s inter-provincial construction land quota trading due to its broader scope and dynamic complexities. This study addresses this gap by proposing an integrated decision-making framework to identify TDR risk factors and determine the optimal pricing for TDR under risk sharing. Results show that among 28 identified risk factors across the trading lifecycle, pre-transaction (remediation application and remediation acceptance) risk factors exhibit lower weights (0.017 and 0.218) but demand greater responsibility from quota-sending governments (80.5% and 73.0%); quota transfer risk factors hold the highest weight (0.306), with nearly balanced responsibility sharing between trading parties; while post-transaction (remediation acceptance and post monitoring) risk factors (weighted at 0.215 and 0.218) should be borne mainly by quota-receiving governments (64.1% and 60.9%). A paradigmatic trading case study between Muli and Jiashan Counties empirically reveals that risk factors elevate the optimal price to 621171.89 yuan/mu—24.23% above the current national standard price—by increasing costs, reducing profits, decreasing the supply–demand ratio, and complicating ecological compensation. These findings underscore the importance of risk responsibility management and risk-based pricing mechanisms.},
  archive      = {J_ESWA},
  author       = {Jia-He Zhou and Yu-Jia Wei and Yu-Ming Zhu and Hong-Li Lin},
  doi          = {10.1016/j.eswa.2025.129627},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129627},
  shortjournal = {Expert Syst. Appl.},
  title        = {Optimal pricing for transfer of development rights under risk sharing: The context of china’s inter-provincial construction land quota trading},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent urban on-street parking space management for autonomous vehicles. <em>ESWA</em>, <em>298</em>, 129626. (<a href='https://doi.org/10.1016/j.eswa.2025.129626'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curbside lanes are valuable spatial assets, with on-street parking, driving, and other travel modes competing for the space. Autonomous vehicle (AV) transport is expected to park at the curbside for diverse purposes, raising conflicts between driving and parking in the city centre. This study presents a framework to determine on-street parking configurations under different traffic flow and parking supply scenarios for the downtown region. The main contribution stems from solving the macro-level parking configuration problem using customised metaheuristics while considering microscopic AV operations. We tested the framework using a road network comprising a downtown central business district and adjacent urban areas. Among the considered metaheuristics, the discrete particle swarm optimisation outperformed the genetic algorithm in minimising network-level travel delays but at the cost of higher computational time. Three main empirical findings are derived. First , parking lanes are more likely to be assigned to edges in downtown areas or those with lower traffic and driving speeds. Second , high parking supply negatively affects the macroscopic fundamental diagram by increasing congestion and reducing flow efficiency, but such an effect diminishes in congested networks. Third , there exists an optimal parking supply level (40 % in the case study) for most flow rate conditions that can help reduce congestion. The proposed framework was validated through a case study in Midtown Manhattan, New York City. This study provides valuable insights for urban and transportation agencies to manage on-street parking lane assignments to balance parking and driving demands in the AV transport era. The approach has broader applicability as it is transferable to human-driven vehicles and mixed autonomy scenarios.},
  archive      = {J_ESWA},
  author       = {Qiming Ye and Prateek Bansal and Yuxiang Feng and Simon Hu and Panagiotis Angeloudis},
  doi          = {10.1016/j.eswa.2025.129626},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129626},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent urban on-street parking space management for autonomous vehicles},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-session interest extraction for recommendation. <em>ESWA</em>, <em>298</em>, 129625. (<a href='https://doi.org/10.1016/j.eswa.2025.129625'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, due to device privacy restrictions, sometimes we can only obtain anonymous users’ interaction behavior within a single session. This type of recommendation is called session-based recommendation. Modeling users’ interest based on session data is one of the core issues in session-based recommendation. However, most existing methods only model users’ interest within individual sessions, neglecting information propagation across sessions. This paper addresses this challenge by designing a contrastive learning module based on clustering to model inter-session information propagation. Specifically, in addition to propagating information within sessions using hypergraph convolution, a cluster algorithm is applied to group all nodes across sessions. Then a contrastive learning loss is designed based on the clustering results to facilitate information propagation across sessions, thereby explicitly modeling the semantic similarity of similar items across different sessions. We call our model Clustering Hypergraph Neural Network (CluHNN). CluHNN explicitly learns the correlation between similar items across different sessions, improving the quality of item representations and, consequently, yielding better interest representations through cross-session information propagation. Experimental results on two real-world datasets show the effectiveness of the proposed CluHNN. For example, in terms of MRR@20, CluHNN achieves significant improvements of 1.3 % and 2.0 % relative gains over the strongest baseline, respectively.},
  archive      = {J_ESWA},
  author       = {Jin Jin and Chaoqun Li and Liangxiao Jiang},
  doi          = {10.1016/j.eswa.2025.129625},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129625},
  shortjournal = {Expert Syst. Appl.},
  title        = {Cross-session interest extraction for recommendation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Incorporating estimated depth maps and multi-modal pretraining to improve salient object detection in optical remote sensing images. <em>ESWA</em>, <em>298</em>, 129624. (<a href='https://doi.org/10.1016/j.eswa.2025.129624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a burgeoning theme in optical remote sensing image (ORSI) analysis, salient object detection (SOD) plays a vital role in traffic monitoring, agriculture, disaster management, and other fields. However, the existing ORSI-SOD methods are all single-modal (RGB images primarily), which suffer from performance drop when facing complex scenes (e.g., intricate backgrounds, low contrast scenes, and similar objects). To address this challenge, we introduce estimated depth map to complement RGB image in ORSI-SOD for the first time, which provides 3D geometric cues to improve detection accuracy in complex scenes, thus advancing ORSI-SOD from single-modal to multi-modal. Furthermore, we design a novel pretraining framework: multi-modal reconstructed image pretraining (MMRIP) to pretrain SOD model in multi-modal ORSI-SOD. MMRIP initially utilizes a masked autoencoder (MAE) to restore the masked RGB image; subsequently, it feeds the restored RGB image and clean depth map to the SOD model to generate the saliency map, which can help SOD model more effectively integrate cross modal information and extract better feature. Besides, we present a simple RGB-D SOD model, namely SimSOD, which is pretrained by MMRIP for ORSI-SOD. SimSOD has two major components: DFormer (encoder) and MLP head (decoder). Specifically, we first input RGB image and depth data into the encoder to generate four multi-scale features, then use the decoder to fuse these features and yield the prediction result. Without bells and whistles, our proposed method outperforms the state-of-the-art methods on three public ORSI-SOD datasets. The code can be accessed at: https://github.com/Voruarn/MMRIP .},
  archive      = {J_ESWA},
  author       = {Yuxiang Fu and Wei Fang},
  doi          = {10.1016/j.eswa.2025.129624},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129624},
  shortjournal = {Expert Syst. Appl.},
  title        = {Incorporating estimated depth maps and multi-modal pretraining to improve salient object detection in optical remote sensing images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An approach for linking dynamic network information models based on ontology matching. <em>ESWA</em>, <em>298</em>, 129622. (<a href='https://doi.org/10.1016/j.eswa.2025.129622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic network information models are typically heterogeneous and isolated systems that impede effective interoperability, significantly hindering end-to-end service integration and data sharing across network segments. To address this challenge, we propose a new approach for linking heterogeneous dynamic network models based on ontology matching, which can be applied in various domains utilizing dynamic networks. For ontologies matching we use different existing duplicate detection algorithms but we reduce the computational complexity of ontology matching due to splitting initial set of matched entities into a number of subsets using domain knowledge. Using telecommunications as case study, we represent operator networks as knowledge graphs and match them with standardized model ontologies using business process context to create an Extended Operator Network Ontology. Our approach ensures linking of dynamic network models used in operators information systems that is of primary importance for implementing complex business processes, and providing integrated services while maintaining existing models.},
  archive      = {J_ESWA},
  author       = {Tianxing Man and Igor Kulikov and Jiafeng Yang and Nataly Zhukova},
  doi          = {10.1016/j.eswa.2025.129622},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129622},
  shortjournal = {Expert Syst. Appl.},
  title        = {An approach for linking dynamic network information models based on ontology matching},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved differential evolution algorithm combined with vector NFP and mixed-integer programming for solving 2D irregular layout problem. <em>ESWA</em>, <em>298</em>, 129621. (<a href='https://doi.org/10.1016/j.eswa.2025.129621'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-dimensional irregular layout problem, which involves placing convex or non-convex components within a confined boundary without overlaps, is NP-complete and widely encountered in industrial applications such as glass cutting, garment manufacturing, and packaging. To overcome the limitations of existing methods in computational efficiency and material utilization, we propose a new hybrid algorithm IDE-V-NFP-MIP: (1) An improved differential evolution (IDE) algorithm combines the memory mechanism to guide the crossover and mutation operations; (2) A vector No-Fit Polygon (V-NFP) algorithm effectively handles complex geometric constraints, including voids and degradation; (3) A mixed-integer programming (MIP) model ensures accurate layout and non-overlapping constraints. Experimental results demonstrate superior performance: IDE ranked first in CEC2022 Friedman tests, while practical applications show 22.10% reduction in board length and 41.47% improvement in filling rate. The framework successfully handles real-world garment cutting applications and large-scale problems up to 1,280 polygons, demonstrating significant improvements in both computational efficiency and solution quality for industrial layout optimization. The source code for the algorithm is available at https://github.com/xhj-6/IDE-V-NFP-MIP .},
  archive      = {J_ESWA},
  author       = {Huijie Xu and Qifang Luo and Yongquan Zhou},
  doi          = {10.1016/j.eswa.2025.129621},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129621},
  shortjournal = {Expert Syst. Appl.},
  title        = {An improved differential evolution algorithm combined with vector NFP and mixed-integer programming for solving 2D irregular layout problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent localization of FDIA in smart grids: A multi-level wavelet spatio-temporal graph embedding approach. <em>ESWA</em>, <em>298</em>, 129620. (<a href='https://doi.org/10.1016/j.eswa.2025.129620'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of smart grid security, the precise identification of False Data Injection Attack (FDIA) is crucial for ensuring the stable operation of power systems. Existing approaches for handling measurement data often overlook the correlation between local time–frequency variations caused by FDIA nodes and global spatial information in analyzing measurement data, leading to inaccurate localization. To address this issue, we propose a novel approach: a multilevel wavelet spatio-temporal map embedded FDIA localization method. Initially, a multi-resolution time–frequency signal decomposition model is utilized to separate the time–frequency mutation signals induced by FDIA from the measurement data using fast wavelet transform. Subsequently, a multi-channel time–frequency feature extraction technique is developed to capture the mutation characteristics of FDIA in time–frequency signals. This involves extracting detailed features of the time–frequency signals pre and post-attack via a multi-channel convolution operation encompassing “temporal-local-global” aspects. Finally, we propose an FDIA localization model based on multi-level graph wavelet embedding. The model embeds spatio-temporal information into time–frequency features via graph wavelet convolution and builds a spatio-temporal dependency map through multi-level neighborhood sampling. To mitigate measurement loss and noise, graph smoothing regularization and graph dropout are introduced during training. A graph attention mechanism further captures spatio-temporal dependencies among nodes, enabling accurate FDIA localization. Experimental results verify the effectiveness of the proposed method.},
  archive      = {J_ESWA},
  author       = {Zhaoyang Qu and Feng Liang and Nan Qu and Tao Jiang and Xiaoyu Xu},
  doi          = {10.1016/j.eswa.2025.129620},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129620},
  shortjournal = {Expert Syst. Appl.},
  title        = {Intelligent localization of FDIA in smart grids: A multi-level wavelet spatio-temporal graph embedding approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-driven 5G-IoT optimization: Q-learning for real-time energy and network resource management. <em>ESWA</em>, <em>298</em>, 129619. (<a href='https://doi.org/10.1016/j.eswa.2025.129619'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the integration of the 5G-enabled Internet of Things has revolutionized through high-speed data transmission, ultra-low latency, and interconnectivity of massive devices. However, the proliferation of 5G-enabled Internet of Things introduces major challenges, such as energy inefficiency and unreliable data delivery in the resource constrained Internet of Things devices. This research proposes a novel Q-Learning-based optimization framework tailored to address these challenges by integrating Radio Frequency energy harvesting, adaptive beamforming, and dynamic resource allocation within the massive Multiple-Input-Multiple-Output system. The proposed model utilizes reinforcement learning to manage the network resources including modulation schemes, beamforming, and energy allocation. By modeling the optimization problem as a Markov Decision Process, the proposed framework dynamically adapts to real-time network conditions to enhance energy efficiency, reliable data delivery, and throughput. The experimental validation demonstrates that the Q-Learning-based strategy effectively optimizes the energy efficiency as well as data transmission and achieves a higher energy efficiency of 98.87 %, higher packet delivery ratio of 98.85 %, lower latency of 1.5 ms, and higher throughput of 200Mbps compared to existing methodologies. This result indicates that the proposed Q-Learning-based framework has the potential to enhance the sustainability and reliability of the 5G-enabled Internet of Things.},
  archive      = {J_ESWA},
  author       = {Bavethra Murthy and Palani Uthirapathy},
  doi          = {10.1016/j.eswa.2025.129619},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129619},
  shortjournal = {Expert Syst. Appl.},
  title        = {AI-driven 5G-IoT optimization: Q-learning for real-time energy and network resource management},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-behavioral recommendation algorithm based on decoupled graph convolution. <em>ESWA</em>, <em>298</em>, 129618. (<a href='https://doi.org/10.1016/j.eswa.2025.129618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommendation models primarily rely on display feedback and typically utilize a single type of user-item interaction data, which often results in significant data sparsity issues. In contrast, multi-behavioral recommendation models leverage various behaviors such as browsing, favoriting, and other interactions. These additional behaviors help improve the prediction of user-item interactions. Existing multi-behavioral recommendation methods often overlook the potential factors influencing multi-behavioral interactions and the differences between various behavior types. In this study, we introduce a multi-behavioral recommendation algorithm utilizing decoupled graph convolution (MBR-DGC), which effectively mitigates the data sparsity of the target behaviors and improves recommender system performance by capturing the differences between the semantics of different behaviors. Specifically, we construct multiple non-overlapping independent isomorphic graphs and separate potential factors affecting the interactions among users, items, and behaviors using decoupled convolutional networks to reconstruct the node features of users in different behaviors. Afterwards, multi-behavioral features of users are aggregated using contrastive learning to achieve personalized multi-behavioral information aggregation. Experimental results on multiple datasets show that MBR-DGC effectively leverages multi-behavioral data, significantly enhancing recommendation performance compared to other state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xu Yu and Pengju Ding and Jie Yu and Junyu Lin and Lei Guo and Guanfeng Liu and Liang Xi},
  doi          = {10.1016/j.eswa.2025.129618},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129618},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-behavioral recommendation algorithm based on decoupled graph convolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An information aggregation decision making method for UAV swarm intelligence system based on joint communication and proximal strategy. <em>ESWA</em>, <em>298</em>, 129617. (<a href='https://doi.org/10.1016/j.eswa.2025.129617'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swarm intelligence aggregation system represents a key capability in current-generation UAV swarm, demonstrating robust collective intelligence. Currently, leveraging Multi-Agent Deep Reinforcement Learning (MADRL) offers a promising approach for building UAV swarm intelligence aggregation systems. However, the MADRL methods are difficult to cope with the challenge of exponential increase in computation when facing the collaboration problem of large-scale swarms, and the agents also have the problem of partial observability of the environment. This paper proposes an Information Aggregation Decision Method for UAV swarm based on Joint Communication and Proximal Strategy (IADM-JCPS). This method designs a communication information aggregation (CIA) network to enable UAVs to gather observation information from neighbor UAVs, and uses the attention mechanism to screen important information. Then, the aggregated information is used as part of the input of the policy network to increase the information diversity of the decision-making process. Finally, the gradient clipping mechanism is used to trim the policy gradient to enhance the stability of the training process. A UAV swarm multi-target tracking (MTT) mission scenario is designed to verify the effectiveness of the proposed IADM-JCPS algorithm. Experimental results show that the proposed algorithm is superior to the baseline algorithm in terms of task collaboration and scalability.},
  archive      = {J_ESWA},
  author       = {Zhaotian Wei and Ruixuan Wei},
  doi          = {10.1016/j.eswa.2025.129617},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129617},
  shortjournal = {Expert Syst. Appl.},
  title        = {An information aggregation decision making method for UAV swarm intelligence system based on joint communication and proximal strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning-based trajectory planning for AGVs in dynamic environment. <em>ESWA</em>, <em>298</em>, 129616. (<a href='https://doi.org/10.1016/j.eswa.2025.129616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a learning-based framework for rapid trajectory planning of autonomous ground vehicles (AGVs) in dynamic environments. The approach integrates optimization techniques with deep learning to design a real-time planner capable of generating kinematically feasible trajectories. A continuous iterative method is first developed for dataset construction, enabling efficient generation of optimal trajectory sets. Based on this dataset, a neural network is trained to learn the mapping between AGV states and actions while capturing their temporal dependencies. During online planning, the trained model produces decision actions from the current state and sensor feedback, enabling real-time planning of safe and feasible trajectories. Results demonstrate the effectiveness of the proposed framework.},
  archive      = {J_ESWA},
  author       = {Runda Zhang and Zhida Xing and Senchun Chai and Yuanqing Xia and Runqi Chai},
  doi          = {10.1016/j.eswa.2025.129616},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129616},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning-based trajectory planning for AGVs in dynamic environment},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Model-agnostic post-hoc explainability for recommender systems. <em>ESWA</em>, <em>298</em>, 129608. (<a href='https://doi.org/10.1016/j.eswa.2025.129608'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems often benefit from complex feature embeddings and deep learning algorithms, which deliver sophisticated recommendations that enhance user experience, engagement, and revenue. However, these methods frequently reduce the interpretability and transparency of the system. In this research, we develop a systematic application, adaptation, and evaluation of deletion diagnostics in the recommender setting. The method compares the performance of a model to that of a similar model trained without a specific user or item, allowing us to quantify how that observation influences the recommender, either positively or negatively. To demonstrate its model-agnostic nature, the proposal is applied to both Neural Collaborative Filtering (NCF), a widely used deep learning-based recommender, and Singular Value Decomposition (SVD), a classical collaborative filtering technique. Experiments on the MovieLens and Amazon Reviews datasets provide insights into model behavior and highlight the generality of the approach across different recommendation paradigms.},
  archive      = {J_ESWA},
  author       = {Irina Arévalo and Jose L. Salmeron},
  doi          = {10.1016/j.eswa.2025.129608},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129608},
  shortjournal = {Expert Syst. Appl.},
  title        = {Model-agnostic post-hoc explainability for recommender systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AERO-net: AutoEncoder-driven residual optimization network for latent bias correction of WRF-ROMS. <em>ESWA</em>, <em>298</em>, 129607. (<a href='https://doi.org/10.1016/j.eswa.2025.129607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable assessment of precipitation is crucial for incorporating meteorological and hydrological research into industrial and agricultural applications. Accurately estimating precipitation is a challenging task. In addressing this problem, we propose to develop AERO-Net, a novel deep learning framework designed to correct spatial, temporal, and amplitude biases in WRF-ROMS precipitation data. The integration of the Weather Research and Forecasting (WRF) model with the Regional Ocean Modeling System (ROMS) makes it a valuable tool for precipitation forecasting. AERO-Net incorporates autoencoders (AEs) for handling fluctuation and generalizing latent space representations, a latent module (LM) for transforming WRF-ROMS data into bias-corrected representations, a residual module (RM) for error minimization via boost, and a calibration module (CM) for improving near-zero precipitation. Empirical results show that AERO-Net achieves a balanced error reduction across precipitation cohorts grouped by intensity, reducing the macro-averaged root mean square error (macro RMSE) by 3.6 mm/day and the macro-averaged mean absolute deviation (macro MAD) by 0.68 mm/day compared to the original WRF-ROMS. AERO-Net is seen to improve the correlation coefficient (CC) by 26.32 %, increasing it from 0.38 to 0.48, in comparison to the original WRF-ROMS. These findings underscore its potential as an effective solution for enhancing precipitation estimates in high-resolution modeling systems.},
  archive      = {J_ESWA},
  author       = {Passin Pornvoraphat and Kanoksri Sarinnapakorn and Ken-Ichi Fukui and Peerapon Vateekul},
  doi          = {10.1016/j.eswa.2025.129607},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129607},
  shortjournal = {Expert Syst. Appl.},
  title        = {AERO-net: AutoEncoder-driven residual optimization network for latent bias correction of WRF-ROMS},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Contrastive learning and physics oriented evaluation for advanced segmentation in electron tomography. <em>ESWA</em>, <em>298</em>, 129606. (<a href='https://doi.org/10.1016/j.eswa.2025.129606'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods are now achieving strong results for segmentation tasks, and the standard metric for evaluating methods is the Intersection over Union (IOU). However, we show in this paper that IOU is not efficient in evaluating the quality of segmentation for electron tomography (ET) images of zeolites. We perform a physics-oriented evaluation to ensure that the segmentation results yield coherent physical measures. We also formalize Mixed Supervised / Self-Supervised Contrastive Learning Segmentation (M3S-CLS), a semi-supervised approach using a contrastive learning approach that uses expert annotations to train the neural network model. A detailed comparison of this method with a standard cross-entropy-based model is provided. In addition, we publish a database of five fully segmented ET volumes along with corresponding baseline results. The code and the database is available at http://gitlab.univ-st-etienne.fr/labhc-iscv/M3S-CLS .},
  archive      = {J_ESWA},
  author       = {Cyril Li and Christophe Ducottet and Maxime Moreaud and Sylvain Desroziers and Valentina Girelli Consolaro and Virgile Rouchon and Ovidiu Ersen},
  doi          = {10.1016/j.eswa.2025.129606},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129606},
  shortjournal = {Expert Syst. Appl.},
  title        = {Contrastive learning and physics oriented evaluation for advanced segmentation in electron tomography},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DSANet: Deep surrounding-aware network for camouflaged object detection via cross-refinement mirror strategy. <em>ESWA</em>, <em>298</em>, 129605. (<a href='https://doi.org/10.1016/j.eswa.2025.129605'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged objects often closely resemble their surroundings, causing standard RGB images to be confounded by background, texture, and color variations. This often leads to incomplete or absent target segmentation, reducing overall accuracy. To address this issue, we present a Deep Surrounding-Awareness Mirror Network (DSANet) for camouflaged object detection, leveraging depth information to expose objects incongruent with their environment, thus improving localization accuracy. First, a Convolutional Spatial Gating module processes batched RGB and depth inputs, suppressing extraneous background noise while isolating fine-grained segmentation and structural features and unifying channel representation. Subsequently, a Deep Surrounding-Awareness Localization module and a Contour-Guided Integrity Aggregation module collaboratively refine and merge multi-level features, focusing on the global form of camouflaged objects while iteratively enhancing segmentation detail. Finally, a Guided Residual Channel Attention module further refines low-layer structural cues. Extensive experiments on ten challenging benchmark datasets using four widely used evaluation metrics demonstrate that our method exhibited superior performance, outperforming 40 state-of-the-art methods. The results demonstrate the versatility of our model. The source code and results of our method are available at https://github.com/lixu11/DSANet.},
  archive      = {J_ESWA},
  author       = {Xu Li and Xiaosheng Yu and Peng Chen},
  doi          = {10.1016/j.eswa.2025.129605},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129605},
  shortjournal = {Expert Syst. Appl.},
  title        = {DSANet: Deep surrounding-aware network for camouflaged object detection via cross-refinement mirror strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FTUAttack: Feature truncation unrestricted attack based on stable diffusion model. <em>ESWA</em>, <em>298</em>, 129604. (<a href='https://doi.org/10.1016/j.eswa.2025.129604'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of adversarial example generation and defense, compared to restricted attacks with L p -norm constraints, unrestricted attacks without L p -norm constraints emanate better visual imperceptibility. Existing unrestricted attacks typically manipulate the semantic content of examples (e.g. texture or color) to generate adversarial examples. However, current works usually ignore multifaceted features or loss optimization strategy, which limits attack performance. In this paper, we draw inspiration from stable diffusion model and propose a unrestricted attack method called Feature Truncation Unrestricted Attack (FTUAttack) to achieve both better transferability and imperceptibility. Specifically, we promote the performance of unrestricted attacks from the perspectives of both diffusion principle and feature truncation for the first time. Firstly, we propose a Global Deep Feature Extractor (GDFE) module to truncate global feature for the subsequent diffusion denoising process. Secondly, to further boost the transferability, we design a novel Critical Latent Feature Extractor (CLFE) module to obtain critical local feature that need to be truncated during the denoising process and investigate the influence of the different segmentation ways on critical local feature. Thirdly, we propose Multi-Loss Fusion (MLF) strategy to balance the conflict between perturbations and examples’ quality by guiding the optimization direction. Extensive experiments on various model structures and datasets demonstrate the superiority of our attack over the existing attack methods.},
  archive      = {J_ESWA},
  author       = {Shaojie Han and Gangzheng Zhai and Kun Chen and Shihui Zhang},
  doi          = {10.1016/j.eswa.2025.129604},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129604},
  shortjournal = {Expert Syst. Appl.},
  title        = {FTUAttack: Feature truncation unrestricted attack based on stable diffusion model},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial-temporal hierarchical decoupled masked autoencoder: A self-supervised learning framework for electrocardiogram. <em>ESWA</em>, <em>298</em>, 129603. (<a href='https://doi.org/10.1016/j.eswa.2025.129603'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difficulty of labeling Electrocardiogram (ECG) has prompted researchers to use self-supervised learning to enhance diagnostic performance. Masked autoencoders (MAE) are a mainstream paradigm where models learn a latent representation of the signal by reconstructing masked portions of the ECG. However, existing methods lack a specific design for the spatial–temporal characteristics of ECG. Specifically, leads represent spatial projections of cardiac activity, while timestamps capture temporal patterns, and the two correspond to different axes of information. Existing MAE frameworks tend to unify them prematurely, potentially weakening critical local dependencies. In this paper, we propose a Spatial-Temporal Hierarchical Decoupled Masked Autoencoder (STHD-MAE). This framework decouples ECG into isolated leads or time steps in the shallow layer to capture local dependencies with different views, then aligns spatial–temporal representations and re-establishes global dependencies in the deep layer to comprehensively represent pathological information. We also design a medical report fusion module during pre-training, which uses cross-attention to align the ECG report text encoded by a medical language model with the signal’s latent representation, thereby guiding the encoder to focus on pathological information through implicit cross-modal learning. We validate the effectiveness of STHD-MAE on multiple downstream classification and reconstruction tasks. The results show that STHD-MAE outperforms existing self-supervised learning methods by approximately 2% in F1-scores for both coarse-grained and fine-grained classification performance, and its reconstruction quality also exceeds the baseline generative model.},
  archive      = {J_ESWA},
  author       = {Xiaoyang Wei and Zhiyuan Li and Yuanyuan Tian and Mengxiao Wang and Yanrui Jin and Weiping Ding and Chengliang Liu},
  doi          = {10.1016/j.eswa.2025.129603},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129603},
  shortjournal = {Expert Syst. Appl.},
  title        = {Spatial-temporal hierarchical decoupled masked autoencoder: A self-supervised learning framework for electrocardiogram},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GARE-net: Geometric contextual aggregation and regional contextual enhancement network for image-text matching. <em>ESWA</em>, <em>298</em>, 129602. (<a href='https://doi.org/10.1016/j.eswa.2025.129602'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The local correspondence learning has gained increasing attention in image-text matching, which establishes fine-grained alignments between image regions and textual words to improve both interpretability and accuracy. While these approaches have made significant progress in identifying meaningful semantic correspondences, one critical limitation persists in current methods, i.e., overlooking the crucial spatial position information of visual regions in cross-modal interaction. To address this challenge, we propose a novel Geometric contextual Aggregation and Regional contextual Enhancement Network (GARE-Net) that introduces two innovative components: the Geometric Contextual Feature Aggregation (GCFA) module and the Regional Contextual Feature Enhancement (RCFE) module. Specifically, GCFA generates the spatial geometric information of visual regions to enhance the region features by feature aggregation. RCFE further refines the aggregated region features by constructing a region graph and graph convolution. Extensive experiments and analyses are conducted on Flickr30k and MSCOCO to evaluate the importance of our framework. The results demonstrate the superiority of our method in image-text matching. Moreover, the ablation studies and visualization case studies also highlight the importance of geometric contextual feature aggregation and regional contextual feature enhancement. The code is available at https://github.com/chinaBoy123/GARE-Net .},
  archive      = {J_ESWA},
  author       = {Fangming Zhong and Tao Zhou and Zhikui Chen and Suhua Zhang},
  doi          = {10.1016/j.eswa.2025.129602},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129602},
  shortjournal = {Expert Syst. Appl.},
  title        = {GARE-net: Geometric contextual aggregation and regional contextual enhancement network for image-text matching},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation for engineering bid evaluation. <em>ESWA</em>, <em>298</em>, 129600. (<a href='https://doi.org/10.1016/j.eswa.2025.129600'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing quantum group decision-making models face significant challenges in the bid evaluation of engineering projects, including the strong subjectivity of expert evaluations, the difficulty in aggregating expert opinions, the large gap of expert opinions, and the complexity of expert psychological behaviors. To address these issues, this paper proposes a novel quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation. Firstly, a quantum Bayesian network is constructed to aggregate expert opinions and capture the interference effect among experts. Secondly, the matrix fluctuation grey correlation degree is defined and applied to the calculation of quantum interaction terms that reflect the intricate psychological behavior of experts. Subsequently, a decision item search model is proposed and applied to adjust preferences during the consensus reaching process, thereby narrowing the gap of expert opinions. The consensus effect optimization model is utilized to determine optimal values for unknown parameters within this process, effectively reducing the subjectivity of expert evaluations. Finally, the proposed model is applied to a bid evaluation of bridge anti-collision engineering project, which verifies the feasibility and effectiveness of the model, and evaluates the stability and superiority of the model through sensitivity analysis and comparative analysis.},
  archive      = {J_ESWA},
  author       = {Jiuru Zhu and Xinping Xiao and Congjun Rao},
  doi          = {10.1016/j.eswa.2025.129600},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129600},
  shortjournal = {Expert Syst. Appl.},
  title        = {Quantum probabilistic group consensus decision-making model based on matrix fluctuation grey correlation for engineering bid evaluation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DPCND: A dual-population based evolutionary approach for critical node detection problem in complex networks. <em>ESWA</em>, <em>298</em>, 129599. (<a href='https://doi.org/10.1016/j.eswa.2025.129599'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Critical node detection is an important tool for measuring network robustness. The main purpose of critical node detection is to detect a set of nodes that cause the greatest damage to the network connectivity, and it has been applied in many fields such as social network analysis and traffic network management. As a classic non-deterministic polynomial time complete problem, critical node detection faces enormous challenges with the continuous expansion of network size. The existing methods are difficult to achieve a good balance between effectiveness and efficiency, especially when the scale of complex networks becomes larger. To this end, this paper proposes a dual population based critical node detection method (DPCND) to effectively and efficiently obtain a set of critical nodes, which utilizes the co-evolution of auxiliary population generated from reduced graph and main population generated from original graph to find the optimal solution. In the proposed algorithm, a dual population interaction mechanism consists of influence and expansion strategies is proposed for information exchange, where the influence strategy transfers candidate good solutions from the auxiliary population to the main population to improve search efficiency, and the expansion strategy provides node information of the main population to guide the expansion of search space for the auxiliary population. Finally, the experimental results on 20 real-world complex networks clearly demonstrate the effectiveness of the proposed algorithm comparing to the state-of-the-arts.},
  archive      = {J_ESWA},
  author       = {Lei Zhang and Xinyi Feng and Yuanyuan Ge and Zhanpeng Wang and Haipeng Yang},
  doi          = {10.1016/j.eswa.2025.129599},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129599},
  shortjournal = {Expert Syst. Appl.},
  title        = {DPCND: A dual-population based evolutionary approach for critical node detection problem in complex networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage evolutionary algorithm with restart scheme for an integrated robot-task-scheduling and vehicle-dispatch-scheduling problem. <em>ESWA</em>, <em>298</em>, 129598. (<a href='https://doi.org/10.1016/j.eswa.2025.129598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern agriculture, efficiently picking and distributing fresh product is crucial for the competitiveness of smart farms within the globalized agricultural market. However, the integrated scheduling problem involving both picking and distribution processes has received limited attention in existing research. To bridge this gap, this study establishes a mathematical model with dual objectives: (1) minimizing the picking completion time and (2) reducing penalties incurred due to early or delayed deliveries. A novel two-stage evolutionary algorithm incorporating a restart mechanism is proposed to effectively balance the optimization of these objectives with a high degree of consistency. The algorithm features an efficient encoding scheme and advanced genetic operators, specifically designed to enhance exploration and exploitation based on the characteristics of the problem. A comprehensive set of test instances is generated and the proposed method is benchmarked against several state-of-the-art metaheuristics from the literature. Experimental results demonstrate that the proposed algorithm outperforms the competing approaches by a significant margin for solving the problem under consideration.},
  archive      = {J_ESWA},
  author       = {Yiran Pan and Xuan He and Nan Li and Zhonghua Miao},
  doi          = {10.1016/j.eswa.2025.129598},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129598},
  shortjournal = {Expert Syst. Appl.},
  title        = {A two-stage evolutionary algorithm with restart scheme for an integrated robot-task-scheduling and vehicle-dispatch-scheduling problem},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An initial value insensitive method for phase equilibrium calculation: Constrained quadratic interpolation optimization algorithm. <em>ESWA</em>, <em>298</em>, 129597. (<a href='https://doi.org/10.1016/j.eswa.2025.129597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The successful simulation of constrained differential evolution (CDE) algorithm for solving phase equilibrium calculation has first verified that heuristic optimization algorithms are effective ways to solve this kind of problems. Their insensitivity to initial values overcomes the limitations associated with two kinds of traditional methods, i.e., direct solution methods based on Newton’s method and indirect solution methods based on thermodynamic principles. This article proposes a constrained quadratic interpolation optimization algorithm (CQIO) for obtaining the satisfactory solutions of phase equilibrium calculation under given volume, temperature, and moles (NVT-flash). The proposed CQIO regards the total Helmholtz free energy of a NVT-flash problem as its objective function, while the moles vector and volume of a certain phase as its decision variables. The consistency between the four cases’ experimental results of CQIO and those of published articles demonstrates the effectiveness of CQIO in solving NVT-flash problems. Then the computational overhead and algorithmic stability of CQIO were analyzed. In Cases 1, 2 and 3, the average CPU time of CQIO compared to CDE has increased by 46.98 % , 54.56 % and 21.02 % respectively. The Std values of CQIO are significantly smaller than those of CDE in all cases except for Example 2. The proposed CQIO greatly promotes the application of heuristic algorithm in the field of phase equilibrium calculation.},
  archive      = {J_ESWA},
  author       = {Wangyu Tong and Baoduo Su and Yaqian Zhan},
  doi          = {10.1016/j.eswa.2025.129597},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129597},
  shortjournal = {Expert Syst. Appl.},
  title        = {An initial value insensitive method for phase equilibrium calculation: Constrained quadratic interpolation optimization algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Research on multi-objective optimization of multi-endpoint VRP with time window for the distribution of seasonal products by multi-homing heterogeneous fleets. <em>ESWA</em>, <em>298</em>, 129595. (<a href='https://doi.org/10.1016/j.eswa.2025.129595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a novel VRP variant integrating seasonal demand fluctuations, heterogeneous vehicle sources, and multi-endpoint constraints, focusing on the distribution of seasonal products in a steel parts enterprise. It tackles the complex vehicle routing problem with time windows involving heterogeneous fleets, which encompass different vehicle sources (owned and rented), types (fuel-powered and electric), capacities, ranges, and endpoints. To balance enterprise profitability, greenhouse gas emissions, and environmental quality, we develop a mathematical model centered on optimizing distribution costs, greenhouse gas emissions, and vehicle utilization. Drawing inspiration from ancient competitive activities, we propose a novel Huashan Swords Algorithm (HSSA). Through simulations using real enterprise data, we demonstrate the HSSA’s effectiveness, with comparative experiments against existing advanced algorithms highlighting its superiority. Applying the algorithm to design logistics distribution schemes, we conduct in-depth tests considering different customer groups and fuel station distributions. Analyzing the results from the perspectives of profitability, emissions, and environmental quality, we offer targeted operational suggestions for the enterprise based on its situation, geographical characteristics, and fiscal policies. Moreover, we provide recommendations to local governments on fuel station construction and vehicle subsidy policies, contributing practical solutions to both enterprise operations and regional development.},
  archive      = {J_ESWA},
  author       = {Zhang Yanhu and Yan Lijuan and Kong ShuMei and Miao Decheng},
  doi          = {10.1016/j.eswa.2025.129595},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129595},
  shortjournal = {Expert Syst. Appl.},
  title        = {Research on multi-objective optimization of multi-endpoint VRP with time window for the distribution of seasonal products by multi-homing heterogeneous fleets},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revealing the correlation between economic indicators and gold prices for forecasting: Medium term forecast framework with data patch. <em>ESWA</em>, <em>298</em>, 129594. (<a href='https://doi.org/10.1016/j.eswa.2025.129594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting gold prices through the analysis of key economic indicators such as inflation rates, Government Bond Yields, and the U.S. Dollar Index, alongside historical Gold Prices, is crucial for enabling investors to better understand market dynamics and make vital decisions to maximize returns. However, previous studies have faced challenges in extracting hidden factors related to gold price prediction from diverse economic indicators, and the comprehensive exploration of gold price data is yet to be fully achieved. To address this, the present study introduces a mid to long-term gold price prediction model named DPformer. This model utilizes a patching strategy to investigate the relationships between different economic indicators and Gold Prices. It also employs a decomposition approach to discover the mid to long-term trend characteristics and yearly seasonal patterns of Gold Prices. The core of the model integrates a Transformer module, which is solely based on an Encoder structure, and enhances it with multiple attention mechanisms and convolutions. This enhancement allows the improved Transformer model to more effectively capture the long-term dependencies of Gold Prices. The empirical results demonstrate that DPformer consistently outperforms a suite of advanced models widely adopted in terms of mid to long-term forecasting accuracy, including LSTM, GRU, Transformer, DLinear, and PatchTST. Notably, for the 30-step gold price prediction task, DPformer achieves a 21.78 % reduction in Mean Squared Error compared to PatchTST. Moreover, by quantitatively analyzing how various economic indicators influence gold price forecasts, this study provides substantial support for investors in making informed decisions at critical moments.},
  archive      = {J_ESWA},
  author       = {Guanhao Bao and Yunbo Niu and Baisheng Cui and Wanying Ji},
  doi          = {10.1016/j.eswa.2025.129594},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129594},
  shortjournal = {Expert Syst. Appl.},
  title        = {Revealing the correlation between economic indicators and gold prices for forecasting: Medium term forecast framework with data patch},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overview of machine learning in class imbalance scenarios: Trends, challenges, and approaches. <em>ESWA</em>, <em>298</em>, 129592. (<a href='https://doi.org/10.1016/j.eswa.2025.129592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a systematic mapping of machine learning in class imbalance scenarios, offering a broad overview of key challenges, promising emerging techniques, and established methodologies across various application domains. The investigation stands out by employing a hybrid search and selection protocol that combines methodological rigor with technical innovation. The adopted strategy integrated manual searches in reference sources with automated processes based on machine learning, semantic embeddings, and graph-based ranking algorithms. To enhance selection quality, the Quasi-Golden Set (QGS) method was used to build a reference set from manually selected articles – a critical foundation for calibrating and evaluating automated search strings. This combination ensured broad coverage of the topic while improving sensitivity and precision in identifying relevant studies. The initial analysis reviewed 25,593 publications. After screening and applying eligibility criteria, 468 articles were included in the final dataset. The results indicate that 55 % of the studies address multiple domains, with a strong predominance of tabular data ( 84 % ). SMOTE and hybrid approaches were among the most common techniques, present in 61 % of the studies. In terms of evaluation metrics, ROC-AUC was the most frequently used, followed by F1-score and accuracy – the latter noted for limitations in highly imbalanced scenarios. Building on these findings, we derive an empirically grounded taxonomy that links problem context, solution algorithms, and scenario-appropriate evaluation metrics, and we provide a minimal selection guideline table to support applied use. While sampling-based methods remain prevalent, deep learning approaches such as convolutional neural networks and graph-based models are increasingly adopted. Additionally, federated, contrastive, and semi-supervised learning are emerging as relevant paradigms, particularly suited for privacy-aware or low-label environments. This study consolidates current knowledge, identifies methodological and application gaps, and highlights trends that are likely to shape future research. It contributes both a comprehensive synthesis of the field and strategic insights for advancing machine learning techniques in the presence of class imbalance.},
  archive      = {J_ESWA},
  author       = {Gilberto Sussumu Hida and André Câmara Alves Do Nascimento},
  doi          = {10.1016/j.eswa.2025.129592},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129592},
  shortjournal = {Expert Syst. Appl.},
  title        = {Overview of machine learning in class imbalance scenarios: Trends, challenges, and approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective multi-product process planning with reconfigurable machines: Exact and metaheuristic approaches. <em>ESWA</em>, <em>298</em>, 129591. (<a href='https://doi.org/10.1016/j.eswa.2025.129591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process planning in reconfigurable manufacturing systems usually considers a single product, this reduces the efficiency of the overall production plan when multiple products are combined. This paper tackles the Multi-Product Process Planning Problem (MPPP), optimizing both individual process plans and their sequencing. We propose a 0–1 LP model, the model is relaxed by fixing the product sequencing variables and implemented in a Normal-Boundary Intersection method (NBI-es), the method uses a function for iteratively updating β values. Three metaheuristics are also developed: NSGA-II, and two variants of MOEA/D, one enhanced by Opposition-based learning (OBL). Computational experiments show that the update function enhances the performance of NBI over simple Normalized-Weighted Sum (NWS) method. Additionally, NBI-es performs better in HV metric for small size instances if it is given enough CPU times, while MOEA/D significantly outperforms NSGA-II on larger instances on most convergence and spread based metrics. OBL further enhances solution diversity for MOEA/D, albeit with less convergence. A special case of the MPPP is investigated, involving identical products: the Multi-Unit Process Planning (MUPP). An integrated approach was compared with a sequential separated approach. Results indicate that the integrated approach outperforms the separated method for smaller problem instances. Moreover, the analysis of high-quality MUPP solutions revealed a tendency towards diverse process plan combinations rather than repetitive identical ones.},
  archive      = {J_ESWA},
  author       = {Abdelkader Mechaacha and Fayçal Belkaid and Nadjib Brahimi},
  doi          = {10.1016/j.eswa.2025.129591},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129591},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective multi-product process planning with reconfigurable machines: Exact and metaheuristic approaches},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A slack-based two-stage improved particle swarm optimization algorithm for robust scheduling of a flexible job-shop with new and remanufacturing jobs. <em>ESWA</em>, <em>298</em>, 129590. (<a href='https://doi.org/10.1016/j.eswa.2025.129590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remanufacturing has attracted increasing attention for its environmental and economic benefits. Since it is difficult to achieve economies of scale when processing small amounts of remanufacturing jobs alone, these jobs are processed in the same job-shop for new jobs in some enterprises. The processing times of remanufacturing jobs are uncertain due to unpredictable status, leading to certain impacts on scheduling performance. Therefore, we address a flexible job-shop scheduling problem with new and remanufacturing jobs to minimize makespan. To solve this problem, a slack-based two-stage improved particle optimization algorithm is proposed. The first stage aims to yield a solution set with minimum makespan, while the second stage aims to search the best robust solution with maximum total slack from the set. Both stages are executed alternately to optimize makespan and total slack. Moreover, a position updating mechanism with genetic operators and a tabu search inspired local search strategy are implemented to improve algorithmic performance. Computational experiments are conducted using adapted benchmark problems and an industrial case to validate the proposed algorithm.},
  archive      = {J_ESWA},
  author       = {Jun Liu and Zhui Gui and An Li and Qiong Liu},
  doi          = {10.1016/j.eswa.2025.129590},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129590},
  shortjournal = {Expert Syst. Appl.},
  title        = {A slack-based two-stage improved particle swarm optimization algorithm for robust scheduling of a flexible job-shop with new and remanufacturing jobs},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evaluating and predicting green economic efficiency in chinese cities: A three-stage network SBM and machine learning approach. <em>ESWA</em>, <em>298</em>, 129589. (<a href='https://doi.org/10.1016/j.eswa.2025.129589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper evaluates and predicts green economic efficiency (GEE) across 248 Chinese cities from 2010 to 2021 using a three-stage network SBM model based on subsystems of economic production, social development, and environmental governance. To enhance accuracy in both assessment and forecasting, machine learning methods are incorporated, and the Dagum Gini coefficient is employed to analyze regional disparities. This study innovatively proposes a three-stage network SBM model to resolve the “black box” limitation of conventional DEA approaches, while a DEA-ML model is developed to achieve enhanced prediction accuracy. The results reveal that GEE in Chinese cities remains low, with the eastern region leading and the western region trailing. However, efficiency has improved since 2016, primarily driven by advancements in environmental governance. Regional disparities, largely attributed to interregional differences, are gradually decreasing. Among forecasting models, the backpropagation neural network (BPNN) delivers the highest accuracy, predicting sustained leadership in the east, strong growth in the northeast, and a reduction in national disparities. This study offers a comprehensive framework for evaluating and predicting GEE, providing valuable insights for sustainable development policies.},
  archive      = {J_ESWA},
  author       = {Zhishuo Zhang and Hu Liu and Yunpeng Gong and Huayong Niu},
  doi          = {10.1016/j.eswa.2025.129589},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129589},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evaluating and predicting green economic efficiency in chinese cities: A three-stage network SBM and machine learning approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HAEA: A heterogeneous alternating evolutionary algorithm for numerical optimization. <em>ESWA</em>, <em>298</em>, 129587. (<a href='https://doi.org/10.1016/j.eswa.2025.129587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid algorithm integrating a couple of individual evolutionary algorithms (sub-algorithms) is widely recognized as an effective approach to enhance both robustness and optimization performance. Nevertheless, such integration often destroys the structure of the sub-algorithm and makes it difficult to incorporate additional evolutionary algorithms. To address these limitations, this study introduces a novel framework, the Heterogeneous Alternating Evolutionary Algorithm (HAEA), designed to integrate multiple evolutionary algorithms while enabling the flexible addition, removal, and replacement of internal sub-algorithms. To facilitate the integration of a broad spectrum of sub-algorithms, this study draws inspiration from the particle swarm optimization algorithm to devise a suite of information indicators for the transmission of optimization information between sub-algorithms with disparate structures. Furthermore, HAEA is endowed with an adaptive mechanism that dynamically modifies the selection probabilities of its sub-algorithms based on their long-term and short-term performance throughout the evolutionary process. We conducted a comparative analysis of HAEA against all its sub-algorithms across three widely recognized function test sets: CEC2013, CEC2017, and CEC2022. Meanwhile, we applied the HAEA separately to basic metaheuristic algorithms and advanced evolutionary algorithms in recent years and conducted two comparative experiments. Both experimental results show that HAEA outperforms all sub-algorithms in terms of robustness and optimization performance. Its distinctive flexibility allows for the incorporation of additional superior evolutionary algorithms in the future, thereby enhancing its overall performance.},
  archive      = {J_ESWA},
  author       = {Taiyong Li and Tianhao Yi and Zhenda Hu and Wu Deng and Donglin Zhu and Zhilong Xie and Jiang Wu},
  doi          = {10.1016/j.eswa.2025.129587},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129587},
  shortjournal = {Expert Syst. Appl.},
  title        = {HAEA: A heterogeneous alternating evolutionary algorithm for numerical optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep analysis on MLSY for fractional-order higher-dimension-valued neural networks under the action of free quadratic coefficients. <em>ESWA</em>, <em>298</em>, 129586. (<a href='https://doi.org/10.1016/j.eswa.2025.129586'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, free quadratic coefficients are proposed in order to deeply study the flexible criteria of synchronization problem for two kinds of fractional-order higher-dimension-valued neural networks (FOHDVNN) with usual neurons and threshold ones, respectively. First, the uniform system is constructed for two kinds of FOHDVNN which contains both fractional-order octonion-valued neural networks (FOOVNN) and fractional-order quaternion-valued neural networks (FOQVNN). Based on higher-dimension algebra multiplication rules, the studied FOHDVNN are directly decomposed into the eight or four subsystems in real-valued field. Subsequently, free quadratic coefficients are taken into the establishment of two types of Lyapunov-Krasovskii functional (LKF) which is newer and more general. Then, mainly based on the very recent lemmas and Lyapunov theories, the flexible criteria are generally acquired for the global Mittag-Leffler synchronization (MLSY) problem of FOHDVNN. The final criteria have the advantage in being easily calculated and widely used. It is worth noting that the optimal solutions of these criteria can be obtained through the genetic algorithm and the synchronization performance can be improved by optimizing the quadratic coefficients. Finally, three simulation examples are presented to express the availability and progress of the derived results.},
  archive      = {J_ESWA},
  author       = {Jianying Xiao and Yongtao Li},
  doi          = {10.1016/j.eswa.2025.129586},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129586},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep analysis on MLSY for fractional-order higher-dimension-valued neural networks under the action of free quadratic coefficients},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complex-order darwinian particle swarm optimization. <em>ESWA</em>, <em>298</em>, 129584. (<a href='https://doi.org/10.1016/j.eswa.2025.129584'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Particle Swarm Optimization (PSO) algorithm has been one of the most effective methods for solving various complex optimization problems. However, non-adaptive versions of the PSO do not use historical information for performance enhancement and suffer from performance degradation problems. This paper presents a Complex-Order Darwinian PSO (CoDPSO) algorithm, which effectively enhances the performance of the PSO. A complex-order derivative mechanism is introduced into the velocity update rule to improve local exploitation using historical velocity information. Additionally, a Degradation Elimination (DE) strategy is designed to mitigate performance drop during the optimization process. Sensitivity analysis is conducted to evaluate the impact of control parameters on the algorithm’s behavior, demonstrating its robustness across a wide range of settings. Comparative experiments on CEC 2022 benchmark functions show that the CoDPSO outperforms other PSO variants in terms of accuracy, stability, and convergence. Wilcoxon statistical tests further confirm the significance of these improvements. The experimental results indicate the feasibility and efficiency of the CoDPSO.},
  archive      = {J_ESWA},
  author       = {Xiaobo Wu and Liping Chen and Huafeng Li and António M. Lopes and Chuang Liu and Yangquan Chen and Yi Chai},
  doi          = {10.1016/j.eswa.2025.129584},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129584},
  shortjournal = {Expert Syst. Appl.},
  title        = {Complex-order darwinian particle swarm optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-objective framework for predicting public opinion trends on infectious diseases using NSGA-II and interval predictions. <em>ESWA</em>, <em>298</em>, 129583. (<a href='https://doi.org/10.1016/j.eswa.2025.129583'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting public opinion trends during major infectious disease outbreaks is critical for guiding effective public health responses. However, predicting public opinion remains challenging because it is influenced by socio-economic, psychological, and media factors. This paper presents a novel framework for predicting public opinion trends related to significant infectious diseases, with a focus on COVID-19 as a case study. The proposed framework identifies the key factors influencing public opinion development and enables both point and interval predictions. The framework uses information ecology theory and applies the NSGA-II algorithm to select the features that best drive public opinion trends. By incorporating this framework, accurate point forecasts are produced alongside prediction intervals, effectively quantifying the uncertainty inherent in public opinion dynamics. This approach minimizes the quality-driven loss function to generate precise prediction intervals, providing decision-makers with critical insights into public opinion fluctuations during epidemics. The results offer valuable, real-time public sentiment warnings, supporting timely and effective interventions in epidemic prevention and control efforts.},
  archive      = {J_ESWA},
  author       = {Futian Weng and Meng Su and Petr Hajek and Mohammad Zoynul Abedin},
  doi          = {10.1016/j.eswa.2025.129583},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129583},
  shortjournal = {Expert Syst. Appl.},
  title        = {A multi-objective framework for predicting public opinion trends on infectious diseases using NSGA-II and interval predictions},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep reinforcement learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism. <em>ESWA</em>, <em>298</em>, 129581. (<a href='https://doi.org/10.1016/j.eswa.2025.129581'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core challenge for multimodal multi-objective problem (MMOP) resolution lies in maintaining synergistic interactions between convergence and diversity. However, the existing algorithms usually consider convergence-first, which neglect to consider both diversity and convergence into account during the evolutionary process. Likewise, the optimization methods tend to gravitate toward locally optimal regions rapidly, leading to lose diversity for the local PS. This paper proposes a Deep Reinforcement Learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism (DRLMMEA) to investigate the impact of different operator selection on the performance of MMEAs, which greatly helps to balance the convergence and diversity. DRLMMEA utilizes Q-Network to select the operator with the highest reward to enhance the population’s search ability. An improved sorting method (ISM) based on neighborhood dominance updates the population by sorting individuals according to their convergence quality, thereby enhancing convergence performance in the objective space. Moreover, this study proposes a series-parallel mechanism, a series structure enhances the diversity in the decision space, while the parallel structure reduces the computational burden of the algorithm evidently. The proposed Deep Reinforcement Learning-assisted operator selection mechanism, which enables effective balance between diversity and convergence, and an improved crowding distance approach that enhances convergence performance. DRLMMEA undergoes comprehensive testing against 6 contemporary approaches using MMF and IDMP benchmark problems, achieving supremacy in 4 principal performance metrics according to experimental findings. The multimodal gearbox parameter optimization is addressed using the proposed DRLMMEA, which demonstrates superior performance against 6 algorithms in comparative evaluations. It has demonstrated a significant role in solving the MMOPs with the imbalance between convergence and diversity.},
  archive      = {J_ESWA},
  author       = {Ying Huang and Xiaojian Cao and Benben Zhou and Wei Li and Shuling Yang and S.M. Shafi and Zhou Yang},
  doi          = {10.1016/j.eswa.2025.129581},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129581},
  shortjournal = {Expert Syst. Appl.},
  title        = {A deep reinforcement learning-guided multimodal multi-objective evolutionary algorithm with a serial-parallel mechanism},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evolutionary multitasking optimization based on cross-task association mapping strategy. <em>ESWA</em>, <em>298</em>, 129580. (<a href='https://doi.org/10.1016/j.eswa.2025.129580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multitasking optimization, knowledge transfer between tasks through subspace generation has been widely employed to enhance the convergence performance of algorithms. However, this approach fails to account for the inter-task knowledge mapping relationships. Therefore, cross-task knowledge transfer during the optimization process remains inherently blind, potentially leading to mismatched subspace information and consequently degrading the algorithm’s performance. To address this issue, this paper proposes a multitask evolutionary algorithm based on an association mapping strategy and an adaptive population reuse mechanism, namely PA-MTEA. Specifically, to fully represent the correlations between multitask domains and enhance the adaptability of transfer solutions in target tasks, this paper introduces a subspace projection strategy based on partial least squares, which achieves the correlation mapping between the source and target tasks during the dimensionality reduction of the search space. Additionally, to further enhance knowledge transfer across tasks, an alignment matrix is obtained by adjusting the subspace Bregman divergence after deriving the respective subspaces, minimizing variability between task domains. Finally, to balance the global exploration of algorithms with local exploitation, an adaptive population reuse mechanism based on the residual structure is designed. This mechanism reuses historically successful individuals to guide the evolutionary direction of the population, thus improving the algorithm’s convergence performance. Experimental results on various benchmark suites and real-world cases demonstrate that PA-MTEA exhibits significantly superior performance compared to six other advanced multitask optimization algorithms.},
  archive      = {J_ESWA},
  author       = {Tao Yin and Lizhong Yao and Xin Zong and Pengjie Qin and Haoming Dong},
  doi          = {10.1016/j.eswa.2025.129580},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129580},
  shortjournal = {Expert Syst. Appl.},
  title        = {Evolutionary multitasking optimization based on cross-task association mapping strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UniTask+: Exploring and unifying strong and weak task-aware consistency for semi-supervised blastocyst image segmentation. <em>ESWA</em>, <em>298</em>, 129578. (<a href='https://doi.org/10.1016/j.eswa.2025.129578'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of different tissues within blastocysts is essential for embryologists to objectively observe and evaluate embryos, thereby contributing to a higher success rate of in vitro fertilization treatment. Inspired by the primary observation of skeletal patterns and boundary information by clinical doctors, we present an interesting task-aware view for blastocyst segmentation with semi-supervised learning, focusing on task-invariant and task-specific dependencies of segmentation. Firstly, we explore one strong-correlation task with bidirectional transformation between its outputs and the segmentation results, and another weak-correlation task with monodirectional transformation from segmentation maps. The correlation among different tasks inspires us to propose Task-Aware Smoothness (TAS) Assumption , thereby deducing different types of task-aware consistency. Then, a new Unified Task-aware Consistency Interaction (UniTask+) framework is developed to unify and fully take advantage of these strong, weak, and strong-to-weak task-aware consistency. It is comprised of a medical segmentation (MS) branch to implement segmentation and two extra branches performing strong/weak-correlation tasks based on the same backbone. Concretely, a level-set (LS) branch promotes the strong consistency while a point-set (PS) branch stimulates the weak consistency with underlying task perturbations. Numerous experiments have been conducted on the inner cell mass (ICM), blastocyst, proving the effectiveness of our tactics. Furthermore, we have also conducted experiments with datasets from the left atrium (LA), which shares similar structural features with embryos, to validate the robustness of the model. Our methods have shown prominent improvements over up-to-date SSL methods, which advocates our precedent hypothesis.},
  archive      = {J_ESWA},
  author       = {Hua Wang and Linwei Qiu and Jingfei Hu and Jicong Zhang},
  doi          = {10.1016/j.eswa.2025.129578},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129578},
  shortjournal = {Expert Syst. Appl.},
  title        = {UniTask+: Exploring and unifying strong and weak task-aware consistency for semi-supervised blastocyst image segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep asymmetric semantic hashing with probability shifting for multi-label image retrieval. <em>ESWA</em>, <em>298</em>, 129577. (<a href='https://doi.org/10.1016/j.eswa.2025.129577'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing has been widely used in large-scale multimedia retrieval due to its advantages in terms of low storage cost and computational efficiency. Deep hashing algorithms can jointly learn semantic features and hash functions, encoding the original data into compact binary codes with significant discriminative power. However, in multi-label scenarios, especially when the number of samples is extremely large, a high negative-positive imbalance may occur, particularly when the proportion of negative samples is too high, which can lead to bias in the semantic relationships between the learned images. To solve this problem, symmetric losses such as focal loss were proposed, which treat positive and negative samples equally, but the retrieval results are suboptimal. This may be because the equal-weighted processing strategy causes the model to over-focus on hard negative samples and ignore the learning of positive sample features. Besides, mislabeled negative samples, especially those with a probability close to 1, can lead the model to learn incorrect features, harming its discrimination ability, reducing accuracy and recall, and causing overfitting and poor generalization. Accordingly, this paper proposes a novel hashing model, Deep Asymmetric Semantic Hashing with Probability Shifting framework (DASH-PS), for discriminative binary code learning. Specifically, by combining asymmetric focusing strategy and probability shifting strategy, asymmetric semantic loss is designed to solve negative-positive imbalance and ground-truth mislabeling. To keep the contribution of positive samples while focusing on hard negative samples, asymmetric focusing strategy is proposed to decouple negative and positive samples and assign different attenuation factors. By offsetting the probability of negative samples, probability shifting strategy completely discards easy negative samples and very hard negative samples suspected of being mislabeled. Additionally, an adaptive asymmetric learning mechanism is proposed to reduce the fixed difference in average probabilities between positive and negative samples, thereby simplifying hyperparameter selection and improving retrieval efficiency. Extensive experimental results on multiple benchmark datasets validate that our DASH-PS outperforms various state-of-the-art hashing methods. The code for the implementation of our DASH-PS framework is available at https://github.com/QinLab-WFU/DASH-PS.},
  archive      = {J_ESWA},
  author       = {Yongyue Fu and Qibing Qin and Jinkui Hou and Congcong Zhu and Lei Huang and Wenfeng Zhang},
  doi          = {10.1016/j.eswa.2025.129577},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129577},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep asymmetric semantic hashing with probability shifting for multi-label image retrieval},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-informed tensor autoencoder with memory for video anomaly detection. <em>ESWA</em>, <em>298</em>, 129576. (<a href='https://doi.org/10.1016/j.eswa.2025.129576'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video data can be naturally represented as tensors. Despite great progress in anomaly detection with memory-augmented autoencoders, the memory module therein can only handle vectors and inevitably breaks tensor structures, thus leading to performance degradation. Moreover, after the mapping of the encoder, some abnormal features may directly fall into the normal convex polytope, as autoencoders only use the output error to guide the construction of latent variables without imposing any constraint. The memory module can not handle these abnormal features, so that the abnormal observations may not be identified. To solve these problems, we propose a Physics-Informed Tensor AutoEncoder (PITAE) framework, which incorporates both neural networks and physical laws, i.e., tensor operation rules. Specifically, we design a tensor decomposition network followed by an explicit tensor operation to decompose the latent variable into low-rank and sparse components, and only the low-rank component is inputted to the decoder. In this way, we reserve the tensor structure and meanwhile impose a low-rank constraint on the latent variable, thereby compressing the features of normal samples into a ”smaller” region where anomalies are less likely to fall into. Consequently, the non-low-rank anomalies can be identified. But the low-rank anomalies may still not be identified. To further solve this problem, we design a tensor Memory module, and the overall model is named as PITAEM. Finally, based on the proposed framework, we design a novel composite anomaly score to identify anomalies of various kinds. Experiments on various video datasets demonstrate the effectiveness of the proposed method, especially in the small data regime.},
  archive      = {J_ESWA},
  author       = {Jianan Liu and Chunguang Li},
  doi          = {10.1016/j.eswa.2025.129576},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129576},
  shortjournal = {Expert Syst. Appl.},
  title        = {Physics-informed tensor autoencoder with memory for video anomaly detection},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A robust medical image encryption technique using inverse cosine chaotic map. <em>ESWA</em>, <em>298</em>, 129574. (<a href='https://doi.org/10.1016/j.eswa.2025.129574'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid proliferation of digital imaging technologies, the need for robust and lightweight image encryption techniques has become increasingly critical, particularly for medical, military, and personal data applications. In this paper, we propose a novel image encryption scheme based on a one-dimensional inverse cosine chaotic map (1D-ICC), which introduces a highly sensitive and structurally complex nonlinear dynamical system. The proposed method integrates a dynamic Josephus-based intra-block scrambling mechanism, a global zigzag permutation strategy, and an adaptive diffusion process guided by chaotic sequences, thereby enhancing the confusion and diffusion characteristics of the cipher. Unlike conventional approaches, our scheme dynamically derives the encryption key from the SHA-512 hash of the original image, ensuring both sensitivity to plaintext changes and resistance to known-plaintext and chosen-plaintext attacks. The use of the 1D-ICC map, featuring a tunable control parameter r 5 enables rich chaotic behavior even in one dimension, reducing computational complexity without sacrificing security. Comprehensive experiments validate the robustness and efficiency of the encryption scheme, with performance metrics including correlation coefficients below 0.003, information entropy of 7.9993, a Number of Pixels Change Rate (NPCR) of 99.61 %, and a Unified Averaged Changed Intensity (UACI) of 33.42 %. These results demonstrate that our method surpasses several existing techniques in both security strength and computational performance, underscoring the potential of the 1D-ICC map for practical image encryption applications.},
  archive      = {J_ESWA},
  author       = {Jackson J and Perumal R},
  doi          = {10.1016/j.eswa.2025.129574},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129574},
  shortjournal = {Expert Syst. Appl.},
  title        = {A robust medical image encryption technique using inverse cosine chaotic map},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing text classification with neural label embedding and weakly-supervised learning. <em>ESWA</em>, <em>298</em>, 129569. (<a href='https://doi.org/10.1016/j.eswa.2025.129569'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the widespread adoption of deep-learning-based models in a range of linguistic tasks including the fundamental text classification. These deep neural networks, however, often face challenges due to the limited availability of large-scale training data with high-quality label annotations. Furthermore, while supervised learning has proven to be superior in training sentence representations for downstream tasks like text classification, this aspect has received relatively little attention. In this study, a novel model named L abel Em bedding joint with We akly-supervised C lassification ( LemWec ) is proposed, which aims to establish a unified framework by combining supervised sentence embedding with multiclass classification. For supervised sentence embeddings, the model incorporates seed information such as label names and designs an encoder network with a new pooling layer. Additionally, the model adopts a pseudo-labeling approach to leverage a substantial amount of unlabeled samples. This approach specifically addresses the drawback of generating pseudo-labels with the highest confidence and introduces a noise adaptation method to mitigate this issue. The results of extensive experiments conducted on four real-world datasets demonstrate that the proposed LemWec model can significantly enhance the performance of text classification when compared to a comprehensive set of baselines.},
  archive      = {J_ESWA},
  author       = {Xiao Jing and Zhe Li and Zhiang Wu and Dejun Mu},
  doi          = {10.1016/j.eswa.2025.129569},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129569},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing text classification with neural label embedding and weakly-supervised learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Self-supervised ZINB-based kernel representation learning of single-cell RNA sequencing data. <em>ESWA</em>, <em>298</em>, 129568. (<a href='https://doi.org/10.1016/j.eswa.2025.129568'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell clustering plays a vital role in single-cell RNA sequencing (scRNA-seq) data analysis. Although many deep cell clustering methods have been proposed to cluster the scRNA-seq data, they overlook the structural partitioning objectives during the representation learning process, leading to challenges with non-linearly separable structures. In this paper, we present a novel end-to-end deep kernel cell clustering model for scRNA-seq data based on self-supervised ZINB-based kernel representation learning, named scDKC, which simultaneously learns cell kernel representations and identifies cell clusters. Specifically, a kernel-aid hybrid representation learning encoder is developed to effectively learn the separable kernel representation of cells, consisting of cells’ expression characteristics and cell-cell topological interactions. To guide the direction of kernel representation learning, a ZINB-based kernel representation learning decoder is designed by capturing the global probabilistic structure, the representation and the cell graph structure of the scRNA-seq data. By leveraging the clustering self-supervised strategy, representation self-supervised strategy, ZINB-based distribution self-supervised strategy, and kernel self-supervised strategy, scDKC optimizes cell cluster label assignment and learns cell kernel representations through a joint mutual self-supervised mechanism. Extensive experiments on 15 real scRNA-seq datasets, comparing scDKC with 10 competing methods, highlight its competitive advantages.},
  archive      = {J_ESWA},
  author       = {Lina Ren and Maoxuan Yao and Ruizhang Huang and Yongbin Qin},
  doi          = {10.1016/j.eswa.2025.129568},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129568},
  shortjournal = {Expert Syst. Appl.},
  title        = {Self-supervised ZINB-based kernel representation learning of single-cell RNA sequencing data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A dual uncertainty-aware fusion framework for face expression recognition in the wild. <em>ESWA</em>, <em>298</em>, 129567. (<a href='https://doi.org/10.1016/j.eswa.2025.129567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Expression Recognition(FER) is a key task in the broader landscape of affective computing and human-computer interaction, enabling machines to interpret human emotions. To better learn discriminative features under complex facial variations, recent FER research has increasingly adopted multi-branch fusion architectures that aim to capture complementary features from diverse perspectives. However, existing multi-branch fusion strategies, including static weighting, simple concatenation, or uncertainty-aware modeling, lack the capacity to comprehensively capture and reconcile the reliability variations across both individual instances and structural branches. To overcome these limitations, we propose a novel multi-branch fusion strategy, named Dual Uncertainty-Aware Fusion Framework(DUAFF), which improves the discriminability of integrated features by simultaneously modeling instance-wise uncertainty and inter-branch correlations. Specifically, the proposed method comprises two complementary modules: Instance-Discrepant Uncertainty-Aware Fusion Module (ID-UAFM) and Branch-Discrepant Uncertainty-Aware Fusion Module (BD-UAFM). ID-UAFM is introduced to perform channel-wise entropy analysis between semantically distinct samples to estimate instance-level uncertainty, enabling selective channel-wise fusion that emphasizes reliable representations while suppressing uncertain responses. BD-UAFM is further proposed to capture structural uncertainty by evaluating the relative reliability of features across multiple branches and adaptively weighting their contributions based on inter-branch discrepancies. Experimental results demonstrate that the proposed DUAFF consistently outperforms POSTER across three benchmark datasets, achieving accuracy improvements of 0.23 % on RAF-DB, 0.69 % on FER2013, and 0.29 % on AffectNet (7-class), thereby confirming its effectiveness in enhancing the reliability and discriminability of facial representations.},
  archive      = {J_ESWA},
  author       = {Wenfeng Jiang and Ziyi Zhao and Lin Wang and Fang Liu and Chunmei Qing and Xiaofen Xing and Xiangmin Xu and Weiquan Fan and Zhanpeng Jin},
  doi          = {10.1016/j.eswa.2025.129567},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129567},
  shortjournal = {Expert Syst. Appl.},
  title        = {A dual uncertainty-aware fusion framework for face expression recognition in the wild},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Forecasting tourism stock index dynamics: A multiscale deep learning framework integrating emerging media data. <em>ESWA</em>, <em>298</em>, 129566. (<a href='https://doi.org/10.1016/j.eswa.2025.129566'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel multiscale and multivariable deep learning framework for tourism stock index forecasting. To address the research gap concerning emerging media’s impact on the tourism sector, our study innovatively integrate multi-source data, including Douyin (China’s prominent short video platform), into our predictive model. Our methodology employs a multiscale decomposition strategy to streamline feature extraction complexity, coupled with an enhanced temporal convolutional network model incorporating soft-thresholding denoising to mitigate noise interference. Furthermore, we implement an adaptive differentiated prediction strategy to optimize model flexibility. Empirical analysis utilizing the CSI Tourism Stock Index demonstrates that our proposed model outperforms benchmark models in both predictive accuracy and stability, thereby validating its efficacy in tourism stock index forecasting.},
  archive      = {J_ESWA},
  author       = {Feng Shen and Shuai Huang and Wanqing Zhao and Dao Lan},
  doi          = {10.1016/j.eswa.2025.129566},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129566},
  shortjournal = {Expert Syst. Appl.},
  title        = {Forecasting tourism stock index dynamics: A multiscale deep learning framework integrating emerging media data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing adversarial transferability through frequency-domain boundary samples tuning. <em>ESWA</em>, <em>298</em>, 129565. (<a href='https://doi.org/10.1016/j.eswa.2025.129565'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer-based attacks evaluate the robustness of deep learning models and advance adversarial research to improve the security and reliability of deep learning and its applications. Previous efforts have improved the transferability through advanced gradients, augmented models, or augmented data. In this paper, we understand and enhance the transferability from a new perspective. Delving into intermediate features, we empirically find a difference between the distances of adversarial and original samples from cluster centers of the original classes. The adversarial samples are simultaneously far from both the original samples and the cluster centers, close to generalized decision boundaries. Based on this observation, we propose a novel spectrum tuning attack. Boundary samples are utilized to guide the generation of adversarial samples that are far away from the cluster centers. Specifically, randomized boundary samples are generated by frequency-domain transformations. With the gradients of the diverse boundary samples, the adversarial perturbation moves the examples away from cluster centers, thus approaching generalized decision boundaries. In the optimization process, conjugate directions are employed to avoid oscillations and stabilize the update direction. Given the strong Wolfe parameters, the analysis of the descent direction and current gradient further ensures the convergence speed and stability of the optimization. In addition, Gaussian preprocessing is introduced to smooth the update direction, further stabilize the direction and enhance the transferability. The proposed method is flexible enough to be combined with existing methods to further improve the transferability. Experiments conducted on the ImageNet-compatible dataset validate the effectiveness of the proposed method, e.g., 92.6 % success rate against nine defense methods.},
  archive      = {J_ESWA},
  author       = {Shuyan Cheng and Peng Li and Keji Han and Yangjun Xiong and He Xu and Ruchuan Wang},
  doi          = {10.1016/j.eswa.2025.129565},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129565},
  shortjournal = {Expert Syst. Appl.},
  title        = {Enhancing adversarial transferability through frequency-domain boundary samples tuning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). When graph anomaly breaks the coherence: A multi-evidence approach with language models. <em>ESWA</em>, <em>298</em>, 129557. (<a href='https://doi.org/10.1016/j.eswa.2025.129557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection is critical in domains such as healthcare and economics, where identifying deviations can prevent substantial losses. However, current detection methods, primarily reliant on Graph Neural Networks (GNNs), suffer from a critical limitation: they make judgment on a single piece of evidence – the classification of learned node representations. This “single-verdict” approach is inherently susceptible to misjudgments arising from noisy or biased representations. To address this limitation, we introduce Multi-AD, a novel Multi-evidence-based graph Anomaly Detection framework that leverages the power of Language Models (LMs) to enable more robust and reliable anomaly detection. We provide a paradigm shift by constructing multiple evidence sequences for each target node, and employing LMs to assess the coherence of these sequences. By aggregating coherence scores across multiple sequences, Multi-AD leverages converging evidence to make more informed decisions about anomaly status as the presence of anomalous nodes disrupts coherence. Furthermore, we introduce a coherence-aware edge representation method to enhance the discriminative power of the constructed sequences and a multi-round adaptive integration strategy to handle challenging scenarios where normal nodes might be surrounded by anomalies. Extensive experiments demonstrate that Multi-AD consistently outperforms state-of-the-art methods.},
  archive      = {J_ESWA},
  author       = {Xuan Cheng and Jiahui Lu and Chunjing Xiao and Meiyi Yang and Meihui Zhong and Fan Zhou},
  doi          = {10.1016/j.eswa.2025.129557},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129557},
  shortjournal = {Expert Syst. Appl.},
  title        = {When graph anomaly breaks the coherence: A multi-evidence approach with language models},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal joint subspace model for parkinson’s disease diagnosis. <em>ESWA</em>, <em>298</em>, 129556. (<a href='https://doi.org/10.1016/j.eswa.2025.129556'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is an irreversible neurodegenerative disorder that significantly impacts patients’ lives. Accurate early diagnosis prediction is crucial for providing timely treatment to delay disease progression. However, current diagnostic methods predominantly rely on the experience and judgment of clinicians, introducing subjectivity and a lack of standardized, quantitative measures. Sparse subspace learning, as a machine learning technique, can extract critical information from multimodal data while addressing issues such as noise, high-dimensional complexity, and class imbalance. Our study utilizes longitudinal, multimodal neuroimaging data collected at multiple time points to develop a diagnostic model for PD. The approach involves extracting latent local features and leveraging deep learning techniques to generate a comprehensive global feature subset. Adaptive sparse selection is employed to reduce feature redundancy. Finally, support vector machine is used for classification and regression tasks, specifically for PD diagnosis and disease progression score prediction. Extensive experiments were conducted on the PPMI dataset, achieving an accuracy of 90.78 % for Scan Without Evidence of Dopaminergic Deficit (SWEDD) vs. Normal Control (NC) classification, 83.79 % for PD vs. NC, and 91.50 % for PD vs. SWEDD. The results demonstrate that the proposed method improves PD classification and prediction performance, showing promise for early diagnostic applications.},
  archive      = {J_ESWA},
  author       = {Haojie Song and Haijun Lei and Yukang Lei and Zhongwei Huang and Jiaqiang Li and Tianfu Wang and Peng Yang and Baiying Lei},
  doi          = {10.1016/j.eswa.2025.129556},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129556},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multimodal joint subspace model for parkinson’s disease diagnosis},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A spectral relevance analysis approach to pattern recognition of financial time series. <em>ESWA</em>, <em>298</em>, 129555. (<a href='https://doi.org/10.1016/j.eswa.2025.129555'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding patterns in financial time series is crucial for improving prediction accuracy in algorithmic trading and risk management. This paper presents a novel AI-based computer vision approach for classifying financial time series. Historical price sequences are transformed into Gramian Angular Difference Field (GADF) images and fed into a convolutional neural network (CNN) for pattern recognition. To interpret the CNN’s decision-making process, we apply Spectral Relevance Analysis (SpRAy), enabling the identification of distinct clusters based on relevance maps. Clustering the images according to their relevance profiles reveals groups with significantly higher predictive performance compared to the full dataset. The corresponding relevance patterns highlight favorable price movement structures and are identified via the associated clusters.},
  archive      = {J_ESWA},
  author       = {Christine Distler and Yarema Okhrin and Jonathan Pfahler},
  doi          = {10.1016/j.eswa.2025.129555},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129555},
  shortjournal = {Expert Syst. Appl.},
  title        = {A spectral relevance analysis approach to pattern recognition of financial time series},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel object detection system for computer night vision images using residual 3D transformer-based YoloV8 with adaptive GRU in edge and cloud sector. <em>ESWA</em>, <em>298</em>, 129554. (<a href='https://doi.org/10.1016/j.eswa.2025.129554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object identification is one of the computer vision-based methods used in locating and labelling objects in images. Object detection has been greatly advanced as it is now applicable for detecting night vision images with great accuracy. Most accurate object detection at night can be useful in many applications like nighttime driving, regulating harsh traffic in harsh weather conditions, and surveillance. Object detection in normal conditions can be smoother, but low illumination and harsh weather can lead to low versatility. Images captured at night can reflect a lot of noise with low visual features. Due to its challenging nature, a highly effective object detection model is a challenge for high-level applications. Traditional models still face issues and challenges related to uneven light conditions, brightness variations, different light sources, and noisy backgrounds that need to be addressed. Thus, it is necessary to develop an object detection model for dealing with images with low illumination and varying light conditions. Hence, in this work, an effective object detection framework is implemented for night vision images. At first, from the standard datasets, the significant night vision images are fetched and fed into the proposed model as a Residual 3D Transformer-based YoloV8 with an Adaptive Gated Recurrent Unit (R3DT-YAGRU) for detecting the objects. This includes combining spatial–temporal modelling capabilities into YOLOv8, particularly using 3D transformers for improved feature extraction and an adaptive GRU to manage temporal dependencies at night. Here, the Modified Random Variable-based Dollmaker Optimization Algorithm (MRV-DOA), which is a metaheuristic algorithm motivated by the doll-making procedure. Also, it helps in balancing the exploration phase and exploitation phase to discover the best solutions and is used for tuning the parameters of the R3DT-YAGRU model. At last, the experimental validation is carried out for the recommended object detection process by comparing with other models to establish the supremacy of the suggested work. From the study, the suggested framework achieves an accuracy of 96%, leading to enhanced decision making and better accuracy than other conventional models. The work has prepared its implementation accessible at https://github.com/charlesvprabhu56/Object-Detection .},
  archive      = {J_ESWA},
  author       = {V.Charles Prabu and Queen Mary Vidya. M and V. Sathiyamoorthi and P. Durgadevi and M. Gowthami},
  doi          = {10.1016/j.eswa.2025.129554},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129554},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel object detection system for computer night vision images using residual 3D transformer-based YoloV8 with adaptive GRU in edge and cloud sector},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning diversified features for pulmonary hypertension detection using chest X-ray. <em>ESWA</em>, <em>298</em>, 129553. (<a href='https://doi.org/10.1016/j.eswa.2025.129553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to traditional Computed Tomography (CT) scans and floatation catheters, chest X-ray offers an efficient, safe and timely examination paradigm, with broader range of scenarios (including intensive care units), for the detection of Pulmonary Arterial Hypertension (PAH). However, it is difficult to learn the variable radiological features of PAH from X-rays due to its low resolution and low contrast. To address the above issues, we propose a diversified features learning framework to fully explore the PAH-related representation from chest X-ray. We first employ a Chest Feature Enhancement Attention (CFEA) module to enhance the initial feature representation. Then, we employ the Deep Temporal Anti-Interference Metric Learning (TAIML) module to fully explore the PAH-related features. We incorporate the information on the temporal evolution of patients’ conditions. Specifically, a patient x , after undergoing treatment, may exhibit two possible states: x + (ill) and x − (cured). Therefore, we can define the distance d ( x , x + ) as the intra-class structural distance, and the distance d ( x , x − ) as the inter-class safe distance. Unlike existing metric learning, we adopt a new strategy: we push positive samples towards negative samples, but ensure distance between them is no less than d ( x , x − ) , thereby enhancing intra-class diversity while maintaining discriminability. Meanwhile, we ensure that the distance between positive samples is greater than d ( x , x + ) , thereby preserving the intra-class structure. Through these two steps, we can learn a diversified but discriminative representation of PAH. Comprehensive experiments showed the our model achieved an impressive accuracy of 86.27 % and an AUC of 0.857 in identifying PAH patients. The code is available at https://github.com/zgfdmn/PAH .},
  archive      = {J_ESWA},
  author       = {Chengjin Yu and Huanghui Wang and Yuanting Yan and Zhuyang Chu and Dongsheng Ruan},
  doi          = {10.1016/j.eswa.2025.129553},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129553},
  shortjournal = {Expert Syst. Appl.},
  title        = {Learning diversified features for pulmonary hypertension detection using chest X-ray},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TriHAtt-BERT-DBiLSTM: Deep learning model for medical emergency prediction from the unstructured data. <em>ESWA</em>, <em>298</em>, 129552. (<a href='https://doi.org/10.1016/j.eswa.2025.129552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the emergency triage has faced several challenges, including insufficient manual triage with physicians, limited medical resources contributing to incorrect triage, overcrowding in the emergency department (ED), and extended patient waiting time. Hence, the Medical Emergency prediction remains the major research area that identifies emergencies about specific diseases using the Medical Transcriptions (MT) provided by physicians. However, the existing methods face the challenges of handling the ambiguity of words, unstructured data, and increased computation complexity. Consequently, this research proposes the Tri-Head Attention-based Bidirectional Encoder Representations from Transformers enabled Distributed Bidirectional Long-Short Term Memory (TriHAtt-BERT-DBiLSTM) for predicting medical emergencies. Specifically, the proposed approach integrates the Tri-Head Attention mechanisms into BERT, which is further hybridized with the DBiLSTM model that offers the synergic strength of providing the dense feature representations to capture the complex dependencies, and enhancement of model ability with the structured parameters to facilitate the medical emergency prediction. Besides, the utilization of BERT in the proposed approach assists in capturing more complex language representations and further executes a better embedding representation of words. The TriHAtt-BERT-DBiLSTM model surpasses other state-of-the-art techniques and achieves 96.40% of accuracy, 96.12% of F1-score, 96.09% of precision, and 96.15% of recall for medical emergency prediction.},
  archive      = {J_ESWA},
  author       = {Amita Mishra and Sunita Soni},
  doi          = {10.1016/j.eswa.2025.129552},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129552},
  shortjournal = {Expert Syst. Appl.},
  title        = {TriHAtt-BERT-DBiLSTM: Deep learning model for medical emergency prediction from the unstructured data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). System-level integration of deep learning and computer vision for contact ring seal defect detection in semiconductor manufacturing. <em>ESWA</em>, <em>298</em>, 129551. (<a href='https://doi.org/10.1016/j.eswa.2025.129551'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contact ring seals (CRSs) used in electroplating processes during semiconductor manufacturing are susceptible to degradation through chemical etching, electrochemical dissolution, and mechanical wear mechanisms. Despite the implementation of state-of-the-art surface treatment and coating technologies to mitigate CRS corrosion, manual intervention remains frequently required to address this problem. Conventional static defect detection systems for CRSs rely on predefined regions of interest (ROIs) and threshold-based defect area calculations, with surface anomalies identified by comparing the percentage of defective areas within these ROIs. However, this approach exhibits detection failures for millimeter-scale defects, low-contrast anomalies, and geometrically irregular patterns, especially under complex or dynamic environmental conditions. To address these systematic detection failures, we developed a dynamic defect detection system for CRSs by integrating artificial intelligence and traditional computer vision algorithms, achieving a 5.2x improvement in defect detection sensitivity. This system achieved detection accuracy and recall values of over 99 % as well as a response time of 1.43 s average latency, thereby demonstrating a substantial performance improvement compared to a static system, which achieved a recall rate of 18.9 % on the adopted dataset. The system satisfies real-time processing requirements while substantially reducing the need for manual intervention in defect detection and increases production efficiency. Finally, the experimental results of this study indicated that the postprocessing approaches used in the developed system enabled it to flexibly adapt to the different requirements of various production environments.},
  archive      = {J_ESWA},
  author       = {Ting-Han Chen and Hsin-Hung Chou and Shuang Zou and Yu-Han Chen and Sun-Yuan Hsieh},
  doi          = {10.1016/j.eswa.2025.129551},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129551},
  shortjournal = {Expert Syst. Appl.},
  title        = {System-level integration of deep learning and computer vision for contact ring seal defect detection in semiconductor manufacturing},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complementary information-guided interactive fusion network for HSI and LiDAR data joint classification. <em>ESWA</em>, <em>298</em>, 129549. (<a href='https://doi.org/10.1016/j.eswa.2025.129549'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of land remote sensing using single-modal data has reached a bottleneck, which has spurred significant interest in the joint utilization of multimodal remote sensing data to enhance classification performance. However, existing methods exhibit limitations in extracting intricate local and global features. Furthermore, achieving effective information interaction and deep fusion between multimodal datasets remains an unresolved challenge. To address these issues, we propose a Complementary Information-Guided Interactive Fusion Network (CIGIF-Net) for the classification of hyperspectral image (HSI) and light detection and ranging (LiDAR) data. The core idea of our approach leverages the capability of Convolutional Neural Networks (CNNs) to extract local spatial features while utilizing the strengths of Transformers in modeling long-range dependencies. Furthermore, our method facilitates deep fusion by designing mechanisms for the interactive integration of multimodal local spatial features, complemented by guidance from multimodal data during long-range dependency modeling, thereby improving overall classification performance. Specifically, CIGIF-Net incorporates multiscale feature learning, interactive feature fusion, and the complementary information-guided attention mechanism. Initially, CNNs are used to learn multiscale local spatial features. Subsequently, we perform an interactive fusion of multimodal spatial information based on channel attention techniques. Finally, the complementary information-guided attention mechanism dynamically utilizes complementary insights to inform deeper attention distributions, which guide global feature construction and enable efficient information aggregation. This methodology allows for the comprehensive extraction and synergistic utilization of complementary information across multimodal datasets. Extensive experiments conducted on three widely recognized HSI and LiDAR datasets demonstrate that the proposed CIGIF-Net achieves superior classification performance.},
  archive      = {J_ESWA},
  author       = {Shufang Xu and Qiyuan Xue and Zhonghao Chen and Shuyu Fei and Hongmin Gao},
  doi          = {10.1016/j.eswa.2025.129549},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129549},
  shortjournal = {Expert Syst. Appl.},
  title        = {Complementary information-guided interactive fusion network for HSI and LiDAR data joint classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A decision support system for open-pit mining optimisation with dynamic uncertainty and GPU-based parallel repair approach. <em>ESWA</em>, <em>298</em>, 129544. (<a href='https://doi.org/10.1016/j.eswa.2025.129544'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an advanced Decision Support System (DSS) for long-term open-pit mine planning that integrates established optimization techniques—Large Neighborhood Search (LNS), Simulated Annealing (SA), and Dantzig-Wolfe decomposition—within a novel GPU-accelerated framework addressing geological uncertainty and computational complexity. The key methodological contributions include dynamic uncertainty modelling with time-dependent factors capturing geological confidence degradation and GPU-parallelized evaluation architecture enabling industrial-scale mine planning. Validation using 50,000 blocks across 10 geological scenarios demonstrates robust economic performance, achieving mean NPV of $1.514 billion with limited variability (standard deviation $16 million). The GPU-parallelized architecture achieves 29.6 % average computational speedup with peaks of 37 % compared to CPU implementations, enabling concurrent evaluation of 262,144 mining scenarios. Risk analysis reveals P90 Value-at-Risk of $1.488 billion, indicating strong downside protection. The system maintains profit margins exceeding 95 % across all scenarios with cumulative cash flow reaching $1.789.4 million by period 6. Narrow risk envelopes (P10-P90 spread <$60 M) demonstrate robust performance under uncertainty, providing mining companies with practical tools for risk-informed strategic decision-making.},
  archive      = {J_ESWA},
  author       = {Iman Rahimi},
  doi          = {10.1016/j.eswa.2025.129544},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129544},
  shortjournal = {Expert Syst. Appl.},
  title        = {A decision support system for open-pit mining optimisation with dynamic uncertainty and GPU-based parallel repair approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TriHID: Towards verifiable domain adaptation-based IoT intrusion detection in heterogeneous environment. <em>ESWA</em>, <em>298</em>, 129543. (<a href='https://doi.org/10.1016/j.eswa.2025.129543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread deployment of IoT devices in daily applications, securing them against intrusions has become increasingly critical. Domain adaptation (DA)-based intrusion detection is a promising approach that transfers knowledge from a source domain to improve detection in a target IoT domain. However, effective DA methods must address various types of domain heterogeneity - such as differences in feature representation, intrusion distribution, and attack strategies. Existing intrusion detection datasets rarely consider these aspects, limiting their utility for evaluating heterogeneous DA approaches. To bridge this gap, we introduce TriHID , a new dataset specifically designed to capture heterogeneities from three perspectives. We evaluate four types of DA-based IoT intrusion detectors - multi-source, semi-supervised, unsupervised, and open-set on TriHID. Experimental results demonstrate that TriHID enables robust training and comprehensive evaluation of DA-based intrusion detection methods in heterogeneous IoT settings.},
  archive      = {J_ESWA},
  author       = {Jiashu Wu and Yang Wang},
  doi          = {10.1016/j.eswa.2025.129543},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129543},
  shortjournal = {Expert Syst. Appl.},
  title        = {TriHID: Towards verifiable domain adaptation-based IoT intrusion detection in heterogeneous environment},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-objective dynamic flexible job shop scheduling using multi-head network-based deep reinforcement learning. <em>ESWA</em>, <em>298</em>, 129542. (<a href='https://doi.org/10.1016/j.eswa.2025.129542'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern manufacturing environments, job shop scheduling systems are characterized by heightened complexity and ever-changing dynamics, often involving multi-objective optimization and the need to accommodate unanticipated events like new job insertions and uncertain machine availability, underscores the necessity for effective real-time multi-objective scheduling approaches. Therefore, to tackle the multi-objective dynamic flexible job shop scheduling problem (MODFJSP) involving new job insertions, this paper introduces an online scheduling framework called multi-head deep Q network (MHDQN), designed to simultaneously minimize both total tardiness and total machine idle time. The core architecture of MHDQN framework is an innovative multi-head network agent based on Dueling deep Q network (Deuling DQN), consisting of a shared network layer and objective-specific network layers. The shared network layer extracts and transforms the input global state features layer by layer, generating a high-dimensional, semantically rich shared feature. This provides a unified input foundation for the objective-specific network layers, which are responsible for extracting the specialized information related to each objective from the shared features and calculating the corresponding Q -values, thereby enabling the parallel optimization of each objective. Six combined scheduling rules are developed to form the action set, each incorporating both job and machine selection. An improved multi-objective action selection strategy is proposed, incorporating inverse sigmoid ϵ decay and Q -value maximum absolute (max-abs) normalization to optimize decision-making. Additionally, a multi-head network training mechanism leveraging the Double deep Q network (Double DQN) architecture has been developed. Extensive computational experiments demonstrate that the MHDQN outperforms widely used traditional scheduling rules, multi-objective metaheuristic algorithms, and other reinforcement learning (RL) based scheduling methods, showing significant advantages and strong generalizability in multi-objective optimization tasks.},
  archive      = {J_ESWA},
  author       = {Kai Li and Bao Zheng and Liping Xu and Fulong Xie and Zhicheng Wang},
  doi          = {10.1016/j.eswa.2025.129542},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129542},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multi-objective dynamic flexible job shop scheduling using multi-head network-based deep reinforcement learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A possibilistic programming approach in an integrated fuzzy periodic review model and clustering strategy for optimizing platelet supply chain. <em>ESWA</em>, <em>298</em>, 129539. (<a href='https://doi.org/10.1016/j.eswa.2025.129539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Managing platelet supply chains poses significant challenges due to the product’s short shelf life, highly uncertain demand, and the critical nature of its medical use. Previous studies in the blood supply chain rely on fixed-order quantities and ignore collaborative inventory-sharing strategies, which can lead to either excessive waste or severe shortages. However, in many real-world situations, fixed order quantities are often insufficient to accommodate fluctuating demand, especially in healthcare systems. Moreover, existing distribution models in the literature often overlook the equitable allocation of services across hospitals, leading to disparities in access to critical healthcare resources. This study proposes a novel two-phase decision-making framework that integrates a fuzzy periodic review inventory model with a cluster-based reactive transshipment strategy to optimize platelet supply and distribution. In Phase I, a fuzzy periodic review model determines optimal order quantities under uncertain demand using a possibilistic chance-constrained programming approach. In Phase II, hospitals are clustered based on service levels, enabling equitable transshipment among facilities to reduce disparities and improve overall responsiveness. A real-world case study from Tehran province is used to evaluate the model’s effectiveness. Results show an approximate 6% reduction in total shortages and a 2% improvement in average service levels. The proposed framework offers actionable insights for healthcare managers aiming to enhance resilience, equity, and efficiency in critical medical supply chains.},
  archive      = {J_ESWA},
  author       = {Seyyed-Mahdi Hosseini-Motlagh and Mohammad Reza Ghatreh Samani and Hannaneh Kordhaghi},
  doi          = {10.1016/j.eswa.2025.129539},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129539},
  shortjournal = {Expert Syst. Appl.},
  title        = {A possibilistic programming approach in an integrated fuzzy periodic review model and clustering strategy for optimizing platelet supply chain},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep-insights guided evolutionary algorithm for optimization. <em>ESWA</em>, <em>298</em>, 129538. (<a href='https://doi.org/10.1016/j.eswa.2025.129538'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) are a class of optimization algorithms inspired by the theory of biological evolution. They solve optimization problems by emulating the processes of natural selection. EAs produce abundant data during evolution, which contains valuable information that reflects their evolutionary patterns. Effectively utilizing this information can enhance the algorithms’ effectiveness and efficiency. Deep learning excels at extracting knowledge from data. Inspired by this, we propose a novel insights-infused framework that utilizes deep neural networks to learn the evolutionary processes of EAs and extract useful synthesis insights from the evolutionary data. These synthesis insights not only guide the algorithm to evolve in a better direction on the original problems, but also improve its performance on new problems. The choice of neural networks is important. During pre-training, to reduce the inductive bias introduced by human prior knowledge, we design an MLP model to process the data. Additionally, we develop a variable-length encoding method to enable MLP networks to handle variable-length data. To verify the transfer evolution ability of synthesis insights, we devise a self-evolution strategy that fine-tunes the network using only the data generated by the algorithm itself, without introducing any external knowledge, when dealing with new problems. Experimental results demonstrate that the synthesis insights extracted from the CEC2014 dataset guide the algorithms to evolve in a better direction for the CEC2014 problems, and in addition enhance their performance on new problems like CEC2017, CEC2022 and the real-world optimization problems.},
  archive      = {J_ESWA},
  author       = {Kun Bian and Juntao Zhang and Hong Han and Jun Zhou and Yifei Sun and Shi Cheng},
  doi          = {10.1016/j.eswa.2025.129538},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129538},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep-insights guided evolutionary algorithm for optimization},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MambaGen: Efficient visual representation learning for automatic radiology report generation. <em>ESWA</em>, <em>298</em>, 129537. (<a href='https://doi.org/10.1016/j.eswa.2025.129537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation focuses on producing comprehensive and clinically precise medical reports based on radiographic images, thereby improving medical efficiency and alleviating the burden on radiologists. Although existing deep learning methods have demonstrated superior performance, they are constrained by the local receptive field of convolutional neural networks and are inadequate for modeling long-range dependencies, making it challenging to detect critical lesion features in medical images. Recently, State Space Models (SSMs), particularly Mamba, have shown great potential in modeling long-range dependencies with linear computational complexity. Inspired by this, we propose MambaGen, the enhanced Mamba model specifically designed for radiology report generation tasks. Specifically, we design a Mamba-Visual Recalibration Module (MVRM), which utilizes a two-stage training strategy to effectively capture the efficient visual representation of medical images. This first stage combines convolutional layers with SSMs to model long-sequence dependencies and learn multi-level visual feature information. This second stage introduces local convolution and a channel attention mechanism to further recalibrate the local feature and mitigate channel redundancy. Comprehensive experiments on widely available datasets, such as IU X-Ray and MIMIC-CXR, demonstrate our model’s superior performance compared to existing methods, particularly with an improvement of 2.7 % on the BLEU-4 metric. The code is available at https://github.com/Eleanorhxd/MambaGen.git .},
  archive      = {J_ESWA},
  author       = {Xiaodi Hou and Xiaobo Li and Simiao Wang and Mingyu Lu and Hongfei Lin and Yijia Zhang},
  doi          = {10.1016/j.eswa.2025.129537},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129537},
  shortjournal = {Expert Syst. Appl.},
  title        = {MambaGen: Efficient visual representation learning for automatic radiology report generation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multistep diesel vehicle emissions forecasting with an efficient transformer enhanced by temporal-frequency fusion and covariate interaction. <em>ESWA</em>, <em>298</em>, 129532. (<a href='https://doi.org/10.1016/j.eswa.2025.129532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling nitrogen oxide (NO x ) emissions from diesel vehicles is a critical environmental challenge. Advanced SCR strategies depend on accurate multistep forecasting of NO x and ammonia (NH 3 ), but existing models often struggle with error accumulation and the non-stationary dynamics of emissions data. In this work, we first establish a new benchmark for this task, confirming that handling data non-stationarity is essential for robust prediction. Building on this insight, we propose FiTformer, a novel Transformer architecture that adopts an encoder-only framework to jointly forecast both NO x and NH 3 concentrations, where we introduce Intra-series Temporal-Frequency Fusion mechanism to capture intrinsic emissions dynamics and Inter-series Covariate Interaction mechanism to model external influences. Validated on real-world engine data, FiTformer consistently outperforms baseline models across all evaluated prediction horizons, with up to 44.1 % MAE and 36.9 % SMAPE reductions in 24-step NO x prediction and similarly strong gains for NH 3 prediction, compared to the state-of-the-art baseline TimesNet. Its high computational efficiency (0.30G MACs and 8.3 ms/iter) along with robust generalization and high resilience to data imperfections, underscores its suitability for real-time embedded SCR control, enabling more effective strategies for NO x reduction and NH 3 slip minimization.},
  archive      = {J_ESWA},
  author       = {Yuhan Luo and Yujun Zhang and Ying He and Kun You and Wei Huang and Wenqing Liu and Hao Xie},
  doi          = {10.1016/j.eswa.2025.129532},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129532},
  shortjournal = {Expert Syst. Appl.},
  title        = {Multistep diesel vehicle emissions forecasting with an efficient transformer enhanced by temporal-frequency fusion and covariate interaction},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An EEG-based dual-stream spatial-spectral-temporal large model for self-limited epilepsy with centrotemporal spikes. <em>ESWA</em>, <em>298</em>, 129530. (<a href='https://doi.org/10.1016/j.eswa.2025.129530'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-limited epilepsy with centrotemporal spikes (SeLECTS) is the most common form of focal epilepsy in childhood, accounting for 20–25 % of all childhood epilepsy cases and may be associated with cognitive dysfunction and behavioral issues. Accurate detection and assessment of epileptic discharges in EEG signals, particularly the spike-wave index (SWI), are crucial for timely intervention and treatment. Manual analysis of EEG data is labor-intensive and prone to errors, underscoring the need for automated methods. In the present study, we propose a novel D ual-Str e am Sp a tial- S pectral- T emporal L arge model (DeaSTL) that leverages a large-scale EEG architecture to effectively capture the multidimensional characteristics of EEG signals associated with SeLECTS syndrome. Our model integrates multi-view temporal representations and spatial-spectral representations through a dual-stream approach, enhancing the learning of complex patterns in EEG data. We introduce the S JTU Se L ECTS E EG D ataset (SLED), a comprehensive EEG dataset from 212 patients diagnosed with SeLECTS, including annotations for abnormal discharge detection, wake-sleep period classification, and SWI estimation. Addressing the previously unexplored problem of SWI prediction, we provide a novel method for quantifying the severity of epileptic discharges during sleep. Extensive experiments demonstrate that our DeaSTL model significantly outperforms several state-of-the-art methods across multiple tasks, showcasing its potential for clinical application in assisting diagnosis and treatment planning.},
  archive      = {J_ESWA},
  author       = {Lin Zhang and Yun Ren and Fang Yuan and Xuqin Chen and Shikui Tu and Lei Xu},
  doi          = {10.1016/j.eswa.2025.129530},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129530},
  shortjournal = {Expert Syst. Appl.},
  title        = {An EEG-based dual-stream spatial-spectral-temporal large model for self-limited epilepsy with centrotemporal spikes},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic learning of sample ambiguity-driven sample weighting for medical image classification. <em>ESWA</em>, <em>298</em>, 129527. (<a href='https://doi.org/10.1016/j.eswa.2025.129527'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have delivered impressive results in medical image classification tasks. However, their performance is still challenging in medical scenarios with limited data, where training set biases such as label noise or class imbalance impede model learning. Dynamic learning based sample weighting achieves adaptive adjustment of sample importance through learnable weight functions and shows great potential in improving model robustness. Nevertheless, existing methods directly employ model states such as loss value or training accuracy to evaluate sample importance, ignoring the role of ambiguous samples in model optimization. This limitation hinders the performance of dynamic learning based sample weighting in medical image classification. In this paper, we propose a new sample weighting approach based on sample ambiguity and dynamic learning for improving medical image classification, named DLSA-SW. We introduce a dual-space sample ambiguity method by evaluating the category proximity in the feature space and the prediction confidence in the label space. Subsequently, to dynamically calculate sample weights according to sample ambiguity, a learnable sample weighting network is developed to adaptively adjust the weights during training to guide the task model. DLSA-SW performs alternate optimization to enable mutual adaptation of the sample weighting network and the task network. We evaluate the effectiveness of our approach on three medical image classification benchmarks: PatchCamelyon for lymph node histopathology classification, ISIC 2020 for skin lesion classification, and MTC for medullary thyroid cancer classification. DLSA-SW outperforms existing state-of-the-art sample weighting methods on all three datasets and yields substantial improvements over methods without sample weighting. These results demonstrate the robustness and practical applicability of our approach in clinical diagnostic tasks.},
  archive      = {J_ESWA},
  author       = {Guanxiu Yi and Xiabi Liu and Ling Ma and Mengqiao Han and Lijuan Niu},
  doi          = {10.1016/j.eswa.2025.129527},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129527},
  shortjournal = {Expert Syst. Appl.},
  title        = {Dynamic learning of sample ambiguity-driven sample weighting for medical image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LST-rPPG: A long-range spatio-temporal model for high-accuracy heart rate variability measurement. <em>ESWA</em>, <em>298</em>, 129526. (<a href='https://doi.org/10.1016/j.eswa.2025.129526'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG) is a non-contact manner of measuring heart rate variability (HRV) by deriving blood volume pulse (BVP) signals from facial videos. The performance of rPPG-based HRV measurement is challenging due to short-range noises (e.g., head movements) suppression and sufficient-duration BVP signal generation. Recent Transformer-based rPPG methods have shown advantages of global spatio-temporal feature modeling in eliminating noise and recovering high-quality BVP signals. However, these methods often face significant computational and memory constraints, limiting duration scalability of the generated BVP signals that might decrease HRV measurement performance. To address the above issue, this paper proposes a duration-scalable Transformer-based rPPG method, capable of global Long-range Spatio-Temporal modelling (LST), termed LST-rPPG, to generate high-quality BVP signals with a much longer duration. On the one hand, by employing spatial and temporal encoders, the original image-based rPPG issue is converted to a time-series problem. Besides, a sparse computation mechanism is integrated into the temporal encoder. This combination allows LST-rPPG to recover flexible-duration BVP signals, supporting continuous modeling of segments beyond 30 s with low computation and memory overhead. On the other hand, a dynamic loss function with stringent temporal constraints is designed to guarantee the quality of the generated BVP signals. Comprehensive experiments are performed on two public datasets, PURE and UBFC-RPPG, and the results demonstrate the feasibility of LST-rPPG for generating high-quality BVP signals with a much longer duration while requiring substantially fewer computational resources. Besides, LST-rPPG achieves at least the second-best results during all experiments.},
  archive      = {J_ESWA},
  author       = {Jiajie Li and Juan Cheng and Rencheng Song and Yu Liu},
  doi          = {10.1016/j.eswa.2025.129526},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129526},
  shortjournal = {Expert Syst. Appl.},
  title        = {LST-rPPG: A long-range spatio-temporal model for high-accuracy heart rate variability measurement},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Functional consistency of LLM code embeddings: A self-evolving data synthesis framework for benchmarking. <em>ESWA</em>, <em>298</em>, 129523. (<a href='https://doi.org/10.1016/j.eswa.2025.129523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding models have demonstrated strong performance in tasks like clustering, retrieval, and feature extraction while offering computational advantages over generative models and cross-encoders. Benchmarks such as MTEB have shown that text embeddings from large language models (LLMs) capture rich semantic information, but their ability to reflect code-level functional semantics remains unclear. Existing studies largely focus on code clone detection, which emphasizes syntactic similarity and overlooks functional understanding. In this paper, we focus on the functional consistency of LLM code embeddings, which determines if two code snippets perform the same function regardless of syntactic differences. We propose a novel data synthesis framework called Functionality-Oriented Code Self-Evolution to construct diverse and challenging benchmarks. Specifically, we define code examples across four semantic and syntactic categories and find that existing datasets predominantly capture syntactic properties. Our framework generates four unique variations from a single code instance, providing a broader spectrum of code examples that better reflect functional differences. Extensive experiments on three downstream tasks-code clone detection, code functional consistency identification, and code retrieval-demonstrate that embedding models significantly improve their performance when trained on our evolved datasets. These results highlight the effectiveness and generalization of our data synthesis framework, advancing the functional understanding of code.},
  archive      = {J_ESWA},
  author       = {Zhuohao Li and Wenqing Chen and Jianxing Yu and Zhichao Lu},
  doi          = {10.1016/j.eswa.2025.129523},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129523},
  shortjournal = {Expert Syst. Appl.},
  title        = {Functional consistency of LLM code embeddings: A self-evolving data synthesis framework for benchmarking},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semisupervised graph U-net with G-ConvLSTM for hyperspectral image classification. <em>ESWA</em>, <em>298</em>, 129522. (<a href='https://doi.org/10.1016/j.eswa.2025.129522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have demonstrated the effectiveness for hyperspectral image (HSI) classification, but still face challenges, such as insufficient exploitation of data structure information, limited labeled samples, and high susceptibility to noise and outliers. To address these issues, a semisupervised graph U-Net with graph convolutional long short-term memory is proposed for HSI classification, abbreviated as SSGU-Net. Specifically, we design a novel graph convolutional long short-term memory feature extractor to learn discriminative spatial-spectral joint features by simultaneously modeling the correlations in the spatial and spectral domains. Then, we develop a semisupervised graph U-Net with mutually inverse operation of the graph pooling and the graph unpooling modules which uses both labeled samples and unlabeled samples to train a well-parameterized network for HSI classification. In particular, to suppress the effects of noise and outliers, the graph pooling module is designed to selectively retain discriminative samples and fully learn the optimal correlation between these retained samples. Meanwhile, the graph unpooling module employs the local spatial context to reconstruct the reduced samples, thus restoring the pooled data to its original scale for classification task. Extensive experiments show the effectiveness of the proposed method, achieving overall accuracy gains of 5.22 %, 1.58 %, and 1.57 % over the state-of-the-art competitors on the Indian Pines, University of Pavia, and Houston datasets, respectively.},
  archive      = {J_ESWA},
  author       = {Jin-Yu Yang and Heng-Chao Li and Xin-Ru Feng and Feng Gao and Qian Du and Antonio Plaza},
  doi          = {10.1016/j.eswa.2025.129522},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129522},
  shortjournal = {Expert Syst. Appl.},
  title        = {Semisupervised graph U-net with G-ConvLSTM for hyperspectral image classification},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Chat with one voice: Mitigating semantic disparity across languages for multilingual open-domain dialogue response generation systems. <em>ESWA</em>, <em>298</em>, 129521. (<a href='https://doi.org/10.1016/j.eswa.2025.129521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the Internet, building a multilingual dialogue generation system to attract more users while reducing costs in the global market has become increasingly important. However, current end-to-end multilingual approaches often face semantic disparity issues across languages. When given parallel queries with the same semantics but in different languages, the generated responses may vary in meaning across languages, which may greatly affect the stability and reliability of multilingual systems in different language scenarios. We attribute this issue to open-domain/model uncertainty and language differences. To mitigate this issue, we first propose a novel Anchor-based Semantic Constraint (ASC) designed to reduce semantic disparity across languages for Encoder-Decoder Transformers. ASC employs language-independent anchor signal to guide the behaviors in both the encoder and decoder, thereby reducing uncertainty. Additionally, ASC incorporates a two-stage tuning process to further minimize the impact of language differences by ensuring the encoder remains language-independent. Extensive experiments and in-depth analyses conducted on XDailyDialog demonstrate that ASC can effectively mitigate semantic disparity across languages and will not compromise dialogue response quality like the previous related baselines.},
  archive      = {J_ESWA},
  author       = {Sixing Wu and Jiahao Chen and Jiong Yu and Wei Zhou},
  doi          = {10.1016/j.eswa.2025.129521},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129521},
  shortjournal = {Expert Syst. Appl.},
  title        = {Chat with one voice: Mitigating semantic disparity across languages for multilingual open-domain dialogue response generation systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards CPU performance prediction: New challenge benchmark dataset and novel approach. <em>ESWA</em>, <em>298</em>, 129520. (<a href='https://doi.org/10.1016/j.eswa.2025.129520'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CPU performance prediction based on hardware characteristics is crucial for system design and resource management. However, this field faces two major challenges. First, collecting real-world data is challenging due to the diversity of CPU products and the specialized nature of hardware characteristics. This field lacks a standard dataset with unified hardware characteristics, wide data coverage, and comprehensive benchmarks. Second, existing methods based on hardware simulation models or machine learning exhibit notable shortcomings, such as lengthy simulation test cycles and low prediction accuracy. To bridge these gaps, we first collect, preprocess, and standardize historical data from the 4th Generation Intel® Xeon® Scalable Processors across multiple benchmark suites to create a new dataset, named PerfCastDB. Subsequently, we design a deep learning based model called Nova CPU Performance Predictor (NCPP) as the baseline for this new dataset. The NCPP network is designed based on group attention mechanism. It effectively quantifies the implicit relationships between hardware characteristics within and across groups and comprehensively models the impact of various hardware characteristics on CPU performance prediction. We conduct comparative experiments using the proposed PerfCastDB dataset. Compared to existing approaches, NCPP achieves superior evaluation results, demonstrating its effectiveness. Furthermore, we have open-sourced part of the dataset and the NCPP network code to facilitate subsequent research. The resources can be accessed at https://github.com/xiaoman-liu/NCPP .},
  archive      = {J_ESWA},
  author       = {Xiaoman Liu},
  doi          = {10.1016/j.eswa.2025.129520},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129520},
  shortjournal = {Expert Syst. Appl.},
  title        = {Towards CPU performance prediction: New challenge benchmark dataset and novel approach},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Glyph graph isomorphism network for structure recognition of oracle bone inscription. <em>ESWA</em>, <em>298</em>, 129519. (<a href='https://doi.org/10.1016/j.eswa.2025.129519'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structure recognition of oracle bone inscription glyphs plays an important role in studying the evolutionary process of oracle bone inscriptions and the history of the Shang Dynasty. Currently, most methods have decomposed oracle bone inscription glyphs into multilevel features, which are used to recognize hierarchical feature fusion. This strategy cannot recognize the primitive internal structures of keypoints, strokes, and components. Moreover, mainstream graph neural networks cannot fully utilize the rich structural information of oracle bone inscription glyphs, resulting in their inability to meet the needs of structure recognition. So we have developed a graph structure recognition method to implement structure recognition of oracle bone inscription glyphs. A graph extraction method is given to get the structure of oracle bone inscription glyphs; each graph structure’s representation vector can be learned by a glyph graph isomorphism network, which is developed to recognize the graph of oracle bone inscription glyphs to enhance the discriminability representation of the structure. Our model has achieved advanced results across structure recognition experiments in the HWOBC dataset and the Oracle-50K dataset.},
  archive      = {J_ESWA},
  author       = {Zhan Zhang and Hanbin Liu and Xingkun Zhang and Yiyuan Wang and Feng Gao and An Guo and Han Zhang and Qingju Jiao and Bang Li and Yongge Liu},
  doi          = {10.1016/j.eswa.2025.129519},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129519},
  shortjournal = {Expert Syst. Appl.},
  title        = {Glyph graph isomorphism network for structure recognition of oracle bone inscription},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An integrated decision-making framework to evaluate the route alternatives in overweight/oversize transportation. <em>ESWA</em>, <em>298</em>, 129516. (<a href='https://doi.org/10.1016/j.eswa.2025.129516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overweight and oversized transport (O&OT) has become one of the most critical elements of project logistics, driven by advancements in transportation and lifting technologies that now allow high-volume loads to be moved across long distances. This type of transportation operation, also called abnormal transportation, is greatly affected by technical factors such as the weight and geometry of the load, road surface, axle load limitations, slope, and ground strength, as well as external variables such as weather conditions, traffic density, and legal regulations. In planning and operational processes, Decision-Makers (DMs) and practitioners who plan and execute operations without adequately considering these factors and variables can lead to delays in operations, serious risks, and loss of productivity. This research proposes a flexible decision support model that integrates Step-wise Weight Assessment Ratio Analysis (SWARA) and Logarithmic Percentage Change-driven Objective Weighting (LOPCOW), and a ranking technique; i.e., Mixed Aggregation by Comprehensive Normalization Technique (MACONT) techniques to address the decision problems related to route selection, one of the most critical problems in transporting heavy and bulky loads, and to produce reasonable solutions. The proposed model significantly reduces information losses by processing subjective and objective information and integrating subjective (SWARA) and objective (LOPCOW) methods. Unlike traditional ranking approaches, the MACONT method combines three different normalization techniques to determine the ranking performance of alternatives. In this way, it provides more reliable and accurate results by reducing the deviations of the results provided by the single normalization technique. In addition, it shows each alternative’s good and bad performance compared to the others and is more convincing about the results obtained. According to the results obtained by applying the proposed model, fuel consumption (0.096) is determined as the most effective and critical factor in selecting the route on which heavy and bulky loads will be transported. In this context, choosing routes that allow lower fuel consumption can contribute to reducing carbon emissions and external costs arising from transportation. The extensive robustness and validation check to test the proposed model prove that the proposed model is a reliable, robust, and practical decision-making tool for making reasonable and rational decisions in O&OT.},
  archive      = {J_ESWA},
  author       = {Ömer Faruk Görçün and Pradip Kundu and Hande Küçükönder and Gürkan Doğan and Erfan Babaee Tirkolaee},
  doi          = {10.1016/j.eswa.2025.129516},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129516},
  shortjournal = {Expert Syst. Appl.},
  title        = {An integrated decision-making framework to evaluate the route alternatives in overweight/oversize transportation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EvoMapX: An explainable framework for metaheuristic optimization algorithms. <em>ESWA</em>, <em>298</em>, 129514. (<a href='https://doi.org/10.1016/j.eswa.2025.129514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population-based optimization algorithms (POAs) are widely adopted solutions for NP-hard and complex high-dimensional optimization problems. However, their internal dynamics often remain opaque, limiting trust and insight into how solutions evolve. This paper introduces EvoMapX, a novel explainable framework designed to interpret the internal dynamics of population-based optimization algorithms. EvoMapX includes three interpretable structures to visualize evolutionary optimization dynamics: the Operator Attribution Matrix (OAM) quantifies the contribution of specific operators over iterations; the Population Evolution Graph (PEG) traces the ancestry and transformation of candidate solutions; and the Convergence Driver Score (CDS) identifies which operators drive convergence, helping interpret why the algorithm improved. EvoMapX was evaluated across four POAs on the CEC 2021 test suite in order to demonstrate how it reveals meaningful textual and graphical insights into algorithm behavior. EvoMapX paves the way for interpretable metaheuristic optimization. The source code of EvoMapX is available at https://www.github.com/Bilal20252025/EvoMapX},
  archive      = {J_ESWA},
  author       = {Bilal H. Abed-Alguni},
  doi          = {10.1016/j.eswa.2025.129514},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129514},
  shortjournal = {Expert Syst. Appl.},
  title        = {EvoMapX: An explainable framework for metaheuristic optimization algorithms},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BDOS: An orthogonal sum based on belief of permutation events and element distances in random permutation set. <em>ESWA</em>, <em>298</em>, 129513. (<a href='https://doi.org/10.1016/j.eswa.2025.129513'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random permutation set (RPS) extends Dempster-Shafer evidence theory by incorporating event order information, providing a powerful framework for modeling uncertainty. However, existing orthogonal sum methods within the RPS framework may encounter loss of order information and counterintuitive belief distribution during permutation event fusion. To address these two issues, this paper proposes a new method termed belief-distance-based orthogonal sum (BDOS). BDOS operates through three core mechanisms: order-information preservation via mathematical constructs like order-space and inverse mapping; belief-value weighting that prioritizes events with high belief mass for rational outcomes; and element-distance weighting that incorporates dissimilarity among permutations to improve ordinal accuracy. Numerical examples validate the effectiveness of BDOS in permutation event fusion, with comparative results demonstrating its advantages in order retention and belief distribution. Furthermore, BDOS is applied to threat assessment, illustrating its rationality and effectiveness in handling uncertainty and threat ranking.},
  archive      = {J_ESWA},
  author       = {Xiaoyan Su and Xu Chen and Hong Qian and Cheng Jiang},
  doi          = {10.1016/j.eswa.2025.129513},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129513},
  shortjournal = {Expert Syst. Appl.},
  title        = {BDOS: An orthogonal sum based on belief of permutation events and element distances in random permutation set},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fine-grained similarity retrieval of lesion areas in lung CT images based on visual similarity matching of image blocks. <em>ESWA</em>, <em>298</em>, 129510. (<a href='https://doi.org/10.1016/j.eswa.2025.129510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Objective With the rapid growth in the number of medical images, the need for content- based medical image retrieval (CBMIR) in clinical aid diagnosis is becoming increasingly important. Most current content-based CT image similarity retrieval methods use the entire CT image, ignoring the fact that the localized lesion region is the main target of similarity retrieval; Methods To address this issue, the paper proposes a fine-grained similarity retrieval method for lung CT images based on image block( IB ) similarity matching, taking lung CT images as an example. In this method, two enabling techniques are introduced: 1) a hybrid Convolution and Vision Transformer Model(CVTM) that effectively captures both local texture and global context features of lesion regions; 2) the iDS high-dimensional index designed to accelerate retrieval among IB ; Results With the aid of these techniques, fine-grained similarity retrieval optimization of lung CT images can be achieved, which facilitates more accurate lesion-level comparison and supports clinical decision-making; Conclusions Extensive experiments are conducted to indicate that the proposed fine-grained similarity retrieval method achieves excellent performance, with a mAP of 91.33%. Meanwhile, the retrieval efficiency of the iDS high-dimensional index is about 150% higher than that of sequential retrieval, especially when the retrieval radius is large and the database size is substantial.},
  archive      = {J_ESWA},
  author       = {Yi Zhuang and Jiayu Zhang and Yujia Ge and Nan Jiang},
  doi          = {10.1016/j.eswa.2025.129510},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129510},
  shortjournal = {Expert Syst. Appl.},
  title        = {Fine-grained similarity retrieval of lesion areas in lung CT images based on visual similarity matching of image blocks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Traffic prediction using an active causality recurrent graph convolutional network. <em>ESWA</em>, <em>298</em>, 129506. (<a href='https://doi.org/10.1016/j.eswa.2025.129506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of our daily lives is significantly influenced by traffic conditions, highlighting the importance of incorporating complex spatiotemporal dependencies in interconnected traffic data for effective prediction. Although recent advancements have demonstrated prediction accuracy using graph convolutional networks, their depends heavily on the accuracy of the graph structures that represent the spatial relationships within the traffic network. To address this challenge, we introduce a novel approach to traffic prediction, the Active Causal Recurrent Graph Convolution Network (ACRGCN), as shown in Fig. 2. ACRGCN offers a new framework that effectively integrates a causal-embedded approach for traffic prediction, leveraging both structural and feature information from correlated traffic time series. Additionally, it incorporates a time-varying dynamic Bayesian network to capture the intricate spatiotemporal topology of traffic data. The model extracts spatiotemporal dependencies from traffic signals using the Active Causality Graph Recurrent Module (ACGRM), while efficiently modeling nonlinear traffic propagation patterns. Furthermore, ACRGCN employs a deep learning-based module that functions as a hyper-network, progressively generating dynamic causal graphs. Finally, extensive experiments on multiple real-world traffic graph datasets validate ACRGCN, and the results demonstrate its superiority over state-of-the-art method},
  archive      = {J_ESWA},
  author       = {Jinde Zhu and Junhao Yuan and Fulan Ye and Trong-The Nguyen and Ruoxi Wang and Wu Zeng and Chien-Chun Liu},
  doi          = {10.1016/j.eswa.2025.129506},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129506},
  shortjournal = {Expert Syst. Appl.},
  title        = {Traffic prediction using an active causality recurrent graph convolutional network},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Shielding federated learning: Mitigating label transferability against poisoning attacks in cloud-edge-client system. <em>ESWA</em>, <em>298</em>, 129502. (<a href='https://doi.org/10.1016/j.eswa.2025.129502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical computing architecture of cloud-edge-client (CEC) formed with the combination of cloud computing and edge computing can provide processing, storage and low-latency services close to end devices. To protect data privacy, federated learning (FL), as a novel intelligent edge computing framework with localized training mechanisms, has been integrated into edge computing to form a system called CEC-FL and is widely studied. However, they are susceptible to potential poisoning attacks. Existing poisoning attack methods are mostly explored by performing malicious operations on training samples or labels directly and implementing corresponding defense strategies: they are designed to ignore the label transferability and diverse attack environments and are not work against stealthy security threats, mainly because they do not take into account the inherent vulnerabilities of the attack environment. Yet few general defense schemes have been developed. In response to the above vulnerabilities, in this work, we explore a B arycenter Po isoning method with L abel T ransferability (BPoLT) initiated by malicious attackers, resulting in a dynamic attack capability on the CEC-FL system. To address poisoning attacks, we provide a two-phase defense algorithm Res isting L abel T ransferability Pois oning called ResLT-Pois to distinguish malicious attackers from benign participants. Extensive experimental results demonstrate that our scheme is feasible and effective in dealing with the vulnerability of the CEC-FL system.},
  archive      = {J_ESWA},
  author       = {Yaru Zhao and Yihao Cao and Jianbiao Zhang and Zhaoqian Zhang and Weiru Wang},
  doi          = {10.1016/j.eswa.2025.129502},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129502},
  shortjournal = {Expert Syst. Appl.},
  title        = {Shielding federated learning: Mitigating label transferability against poisoning attacks in cloud-edge-client system},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SAMForecast: A hybrid model of self-attention and mamba with adaptive wavelet transform for time series forecasting. <em>ESWA</em>, <em>298</em>, 129498. (<a href='https://doi.org/10.1016/j.eswa.2025.129498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting faces significant challenges due to the variability and complexity of real-world data. Traditional methods often require manual adjustments of wavelet transform parameters, which are labor-intensive and prone to over-fitting or inadequate feature extraction. To address these limitations, this study proposes SAMForecast, a novel hybrid model that integrates Adaptive Wavelet Transform, self-attention mechanisms, and the selective state space model. We introduce an Adaptive Wavelet Block that dynamically adjusts decomposition levels and basis functions using a Mixture of Experts network and lifting scheme, eliminating the need for manual parameter tuning. Furthermore, the model deeply integrates the attention mechanism of the Transformer architecture, leveraging its advantages in capturing complex dependencies to identify correlations between time series data. By combining self-attention with Mamba, SAMForecast effectively captures both global dependencies and local key features in time series, enhancing robustness against noise and redundant information. SAMForecast demonstrates promising performance in multivariate time series forecasting tasks, showcasing an average 2 % performance improvement compared to existing models across datasets in energy, transportation, and other fields. The code is available at https://github.com/Kiki-V/SAMForecast-main .},
  archive      = {J_ESWA},
  author       = {Dunlu Peng and Qiqi Lin},
  doi          = {10.1016/j.eswa.2025.129498},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129498},
  shortjournal = {Expert Syst. Appl.},
  title        = {SAMForecast: A hybrid model of self-attention and mamba with adaptive wavelet transform for time series forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive hypergraph-based convolution network with dual spatiotemporal attention for PM2.5 forecasting. <em>ESWA</em>, <em>298</em>, 129497. (<a href='https://doi.org/10.1016/j.eswa.2025.129497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate PM2.5 prediction is crucial for effective environmental management and public health protection, yet current models show limited dynamic adaptability to complicated air pollution scenarios. Robust models are essential to support timely interventions in response to sudden pollution events or rapidly changing air quality patterns. However, existing models predominantly rely on predefined graph structures and pairwise spatial relationships, limiting their ability to capture the complex and dynamic interactions inherent in PM2.5 pollution. Furthermore, such models often assume equal contributions from neighboring nodes, neglecting heterogeneity and compromising predictive accuracy. To address these limitations, we propose an Adaptive Hypergraph-based Convolution Network with a Dual Spatiotemporal Attention mechanism (AHCN-DA) for PM2.5 forecasting. This framework leverages representation learning and hypergraph structures to capture and integrate pairwise as well as higher-order spatial interactions, producing richer spatial-feature representations. The dual spatiotemporal attention mechanism dynamically assigns time-varying weights to neighboring nodes based on their relevance to target nodes, effectively mitigating the impact of irrelevant inputs. Additionally, AHCN-DA integrates a dilated convolution network with multi-scale kernels to capture temporal patterns effectively across varying scales. Extensive experiments on the 2023 China National Air Quality Dataset show significant improvements in predictive accuracy, particularly in enhancing the proportion of high-precision monitoring stations, with an R 2 of 0.9224, outperforming baseline models. Our findings underscore the effectiveness of AHCN-DA in enhancing prediction accuracy under complex pollution response patterns, contributing to more informed decision-making in environmental management.},
  archive      = {J_ESWA},
  author       = {Haipeng Gao and Chonghui Qian and Yang Su and Wei Zhang and Hengjun Huang},
  doi          = {10.1016/j.eswa.2025.129497},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129497},
  shortjournal = {Expert Syst. Appl.},
  title        = {An adaptive hypergraph-based convolution network with dual spatiotemporal attention for PM2.5 forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Solving equilibrium for adversarial team games utilizing fictitious team play with refined team plans. <em>ESWA</em>, <em>298</em>, 129496. (<a href='https://doi.org/10.1016/j.eswa.2025.129496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial team games represent scenarios where cooperation and competition coexist and hold numerous applications in the real world. These scenarios are particularly challenging due to asymmetric information among team members and limited communication capabilities. Fictitious team-play extend self-play algorithms to these scenarios, offering a novel approach to obtain equilibrium. However, it depends on normal-form team plans, which expand exponentially with game size, significantly constraining their applicability in large games. To overcome the challenge of computing equilibrium in large scale imperfect information team games, we propose a team self-play algorithm that utilizes refined team plans. Specifically, we pre-solve the equilibrium in a perfect recall environment to extract essential team plans from the original strategy space. To adapt these plans to an imperfect recall environment, we construct an auxiliary game with transformed ex ante coordinated information based on the original game and then solve equilibrium in auxiliary game to derive equilibrium for the original game. The experiments demonstrate the effectiveness of our team self-play algorithm in eight different Kuhn poker scenarios. Compared to existing team self-play algorithms, our method efficiently handles large games and exhibits superior convergence compared to reinforcement learning based algorithms. Additionally, our experiments offer valuable insights and guidance on adapting equilibrium strategies from perfect recall environments to those with imperfect recall.},
  archive      = {J_ESWA},
  author       = {Jinheng Xiao and Chen Qiu and Yingying Xu and Jiajia Zhang and Shuhan Qi and Xuan Wang},
  doi          = {10.1016/j.eswa.2025.129496},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129496},
  shortjournal = {Expert Syst. Appl.},
  title        = {Solving equilibrium for adversarial team games utilizing fictitious team play with refined team plans},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Proactive-BiLSTM: Glaucoma detection using FUNDUS and OCT retinal images. <em>ESWA</em>, <em>298</em>, 129490. (<a href='https://doi.org/10.1016/j.eswa.2025.129490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma detection identifies the early signs of eye conditions that can lead to vision loss by analyzing the retinal images to detect abnormalities, such as increased intraocular pressure, changes in the optic nerve head, or structural alterations in the retina. The challenges faced by the existing models include the difficulty in detecting subtle features, variability in image quality, and complex patterns that may resemble normal variations. Moreover, the traditional models struggle to adapt to the evolving patient data, capture long-term dependencies, and often suffer from lower accuracy. Hence, this research proposes the Proactive Hybridized Bidirectional Long Short-Term Memory (BiLSTM) model for Glaucoma detection. The proactive hybridized BiLSTM model is designed to enhance the detection of glaucoma by processing the retinal images. The proactive hybridized BiLSTM model enables the model to capture complex temporal dependencies and relationships within the data, which are crucial for identifying subtle patterns indicative of glaucoma, for which multifaceted feature extraction is employed. Moreover, the Proactive Hybridized BiLSTM model adapts to dynamic changes in the data to learn and predict glaucoma-related features, ultimately improving detection performance over time. The proposed Proactive hybridized BiLSTM model attains higher accuracy, sensitivity, and specificity of 96.65%, 96.51%, and 96.79% using the OCT and FUNDUS image dataset.},
  archive      = {J_ESWA},
  author       = {M.Kiran Mayee and M.Humera Khanam and Shaik Lathifa Tabasum},
  doi          = {10.1016/j.eswa.2025.129490},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129490},
  shortjournal = {Expert Syst. Appl.},
  title        = {Proactive-BiLSTM: Glaucoma detection using FUNDUS and OCT retinal images},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DBCD: Deep balanced community detection via consensus-guided joint optimization in attributed networks. <em>ESWA</em>, <em>298</em>, 129487. (<a href='https://doi.org/10.1016/j.eswa.2025.129487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current deep learning methods for community detection in attributed networks face a critical limitation: they often fail to identify communities that are both structurally cohesive and semantically similar, thereby falling short of the balance typically observed in human-labeled partitions. This shortcoming stems from the absence of explicit mechanisms to jointly optimize these two objectives. In this paper, this challenge is addressed by proposing Deep Balanced Community Detection (DBCD), a novel unsupervised framework for community detection that balances topology and semantics. DBCD first constructs a powerful topology-semantic clustering consensus by integrating insights from both structural and attribute spaces. This consensus then steers a Graph Neural Network to simultaneously maximize global neural modularity and local cross-view consistency, while adaptively determining the number of communities. Extensive experiments reveal a striking result: DBCD consistently discovers communities that surpass the topology-semantic balance of the ground truth across multiple real-world networks. An empirical Pareto frontier analysis further validates that DBCD achieves a non-dominated solution, establishing it as a strong competitor among state-of-the-art methods. The source code of DBCD is available at https://github.com/wy980125/DBCD .},
  archive      = {J_ESWA},
  author       = {Yan Wang and Yupeng Liu and Xiaojie Sun and Jun Fu},
  doi          = {10.1016/j.eswa.2025.129487},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129487},
  shortjournal = {Expert Syst. Appl.},
  title        = {DBCD: Deep balanced community detection via consensus-guided joint optimization in attributed networks},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Network traffic forecasting with transfer learning-based algorithm for long continuous missing data. <em>ESWA</em>, <em>298</em>, 129484. (<a href='https://doi.org/10.1016/j.eswa.2025.129484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate network traffic forecasting is critical for power dispatch networks. Network traffic forecasting aims to use historical data to predict future network traffic trends. Different from other networks, the traffic data of the power dispatch network is mainly composed of the port traffic from routers and switches. However, network accidents in power enterprises can cause long periods of missing network traffic data, reducing the number of learning samples for network traffic prediction models and making the forecasting results unreliable. Due to the long periods of missing data, this paper uses transfer learning (TL) to impute missing data with the knowledge from a relevant task, which has ample samples. However, the imputation result contains complex source and target data characteristics. Therefore, this paper introduces the idea of frequency decomposition to decompose the imputation results into different sub-sequences through variational mode decomposition (VMD). Additionally, this paper uses long short-term memory (LSTM) networks to extract the potential features of decomposition results. Finally, this paper combines TL, VMD, and LSTM to design the TL-VMD-LSTM algorithm. The effectiveness of the proposed algorithm is validated using inflow and outflow traffic data from two State Grid Corp. of China networks. The results demonstrate that TL-VMD-LSTM has excellent generalization performance, with mean absolute percentage errors (MAPEs) of 0.380 % and 0.734 % for the Provincial access network and Information region network, respectively.},
  archive      = {J_ESWA},
  author       = {Yang Yang and Zhihao Chen and Yuchao Gao and Zijin Wang and Zhe Ding and Jinran Wu},
  doi          = {10.1016/j.eswa.2025.129484},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129484},
  shortjournal = {Expert Syst. Appl.},
  title        = {Network traffic forecasting with transfer learning-based algorithm for long continuous missing data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-dimensional multi-objective feature selection with niche-based binary differential evolution. <em>ESWA</em>, <em>298</em>, 129478. (<a href='https://doi.org/10.1016/j.eswa.2025.129478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a critical step in machine learning and data mining, aiming to identify the most relevant features from a dataset to improve model performance while reducing computational costs. In high-dimensional data, as the dimensionality of data increases rapidly, feature selection faces an enormous search space, limiting the efficiency and effectiveness of traditional methods. To address these challenges, multi-objective optimization algorithms have emerged as a promising strategy for feature selection due to their ability to optimize multiple conflicting objectives simultaneously. We propose a niche-based binary differential evolution algorithm (MONBDE) for high-dimensional multi-objective feature selection. MONBDE enhances feature selection performance through several mechanisms: a niche-based binary differential evolution operator, redundant solution repair mechanism and an environmental selection strategy. In experiments, the proposed algorithm was compared with five advanced multi-objective optimization algorithms and tested on 15 benchmark datasets using three common metrics. Experimental results show that the MONBDE algorithm outperforms comparative algorithms in terms of classification accuracy and feature subset size across most datasets. The proposed strategy effectively eliminates redundant and irrelevant solutions in feature selection, leading to a significant improvement in model classification performance.},
  archive      = {J_ESWA},
  author       = {Xuezhi Yue and Xiang Zuo and Pengfei Ling and Chao Xiong and Hu Peng and Yuan Zeng},
  doi          = {10.1016/j.eswa.2025.129478},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129478},
  shortjournal = {Expert Syst. Appl.},
  title        = {High-dimensional multi-objective feature selection with niche-based binary differential evolution},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DFCNet: Dual-path fusion with intra-slice features and cross-slice constraints for cervical cancer CTV segmentation. <em>ESWA</em>, <em>298</em>, 129477. (<a href='https://doi.org/10.1016/j.eswa.2025.129477'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and rapid segmentation of the clinical target volume (CTV) is essential for cervical cancer radiotherapy. However, due to the soft boundaries of CTV, complex connections with surrounding tissues, and high interpatient variability, existing deep learning methods still face significant challenges, particularly for image slices that lack clear boundary information or where applicators are distant from CTV edges. Hence, we introduce DFCNet, a dual-path fusion network with cross-slice consistency constraints for CTV segmentation. The first path employs a dual-stream intra-slice feature encoding module to capture local and inter-regional details, thereby refining boundary delineation amidst the complex interplay with adjacent tissues. The second path integrates a cross-slice consistency constraint module to address soft boundaries and high interpatient variability, while ensuring the coherence and smoothness of the segmentation results. A feature fusion and decoding module combines semantic features from both paths, improving CTV region accuracy. Tests on 432 cervical cancer brachytherapy cases show DFCNet outperforms eighteen state-of-the-art segmentation methods, with Dice score improvements over two percentage points. The second path and feature fusion module can enhance other U-Net-based models, boosting their CTV segmentation performance. DFCNet excels in high-precision CTV segmentation, particularly for challenging slices, demonstrating its potential to improve cervical cancer radiotherapy accuracy, efficiency, and patient outcomes.},
  archive      = {J_ESWA},
  author       = {Mingxu Huang and Deyu Sun and Chaolu Feng and Ming Cui and Dazhe Zhao and Yuhua Gao},
  doi          = {10.1016/j.eswa.2025.129477},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129477},
  shortjournal = {Expert Syst. Appl.},
  title        = {DFCNet: Dual-path fusion with intra-slice features and cross-slice constraints for cervical cancer CTV segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Competitive e-commerce platforms’ data provision and pricing strategies with different attribution behaviors of users. <em>ESWA</em>, <em>298</em>, 129466. (<a href='https://doi.org/10.1016/j.eswa.2025.129466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of data, numerous e-commerce platforms are actively collecting consumer data to obtain business insights. However, consumers and merchants on platforms exhibit diverse attribution behaviors, including single-homing and multi-homing (access to only one platform/multiple platforms), not only affecting the platform’s market scale but also complicating their data provision strategies and data pricing strategies. Inspired by this practice, this paper considers varying attribution behaviors and studies the data operation strategies of competitive platforms. By constructing a two-period game model, we capture the entire process of platform’s data collection and provision, and solve the equilibrium decisions by reverse solution method. This research aims to identify the impact of attribution behaviors on platforms’ data strategies, thereby filling the gap in analyzing this issue from the perspective of two-sided platforms. Results show that when both groups of users (consumers and merchants) are multi-homing, platform facing higher operational costs may benefit more from implementing low data provision but high data pricing strategy, while more cost-efficient platform may choose the opposite strategy. This strategy is still applicable when only one group of users (consumers) becomes single-homing. However, once both groups of users are single-homing, both platforms’ strategies will change. Specifically, when merchant’s cross-side network effect (CNE) intensity is relatively low (high), compared with less cost-efficient platform, platform enjoying cost efficiencies should provide more (less) data at a relatively high (low) price. Moreover, platforms should cautiously provide data when both groups of users are single-homing, as it may hurt profits.},
  archive      = {J_ESWA},
  author       = {Wei Chen and Yijia Hu and Ronghua Sui and Zili Guan and Yi Liu},
  doi          = {10.1016/j.eswa.2025.129466},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129466},
  shortjournal = {Expert Syst. Appl.},
  title        = {Competitive e-commerce platforms’ data provision and pricing strategies with different attribution behaviors of users},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Emergency logistics planning through optimizing the multi-trip vehicle routing with time windows and limited trip duration. <em>ESWA</em>, <em>298</em>, 129465. (<a href='https://doi.org/10.1016/j.eswa.2025.129465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the multi-trip vehicle routing problem with time windows (MTVRPTW) and its variants have been extensively studied, their application in natural disaster contexts remains underexplored. This study addresses this gap by developing a model and solution algorithm for the MTVRPTW with limited trip duration (MTVRPTW-LD), tailored to emergency supplies distribution in the early post-disaster phase. First, we replace the service-dependent loading time in traditional models with service-dependent unloading time and formulate an MTVRPTW-LD model to minimize total operational time, encompassing travel, service, and unloading times, based on the characteristics of emergency supplies distribution. Furthermore, a more practical method for calculating travel time is proposed to enhance the model’s applicability. Subsequently, a branch-and-price algorithm is designed to solve the MTVRPTW-LD model, in which the cumulative relative deprivation cost (CRDC) is introduced to improve equity in emergency supplies distribution. Finally, we conduct numerical experiments on Solomon instances and test instances generated based on emergency scenarios. The results show that, in the test instances, incorporating CRDC can improve the equity by up to 34.3 %.},
  archive      = {J_ESWA},
  author       = {Longfei Fan and Zhongming Wu and Zaiwu Gong and David Z.W. Wang},
  doi          = {10.1016/j.eswa.2025.129465},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129465},
  shortjournal = {Expert Syst. Appl.},
  title        = {Emergency logistics planning through optimizing the multi-trip vehicle routing with time windows and limited trip duration},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Regularity model-driven large-scale multi-objective evolutionary algorithm based on dual-information offspring reproduction strategy. <em>ESWA</em>, <em>298</em>, 129460. (<a href='https://doi.org/10.1016/j.eswa.2025.129460'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Pareto set (PS) of a continuous multi-objective optimization problem exhibit a distribution along a low-dimensional manifold structure. This regularity property significantly contributes to generating high-quality offspring in large-scale multi-objective evolutionary algorithms (LSMOEAs). However, conventional regularity model-based algorithms face several challenges when dealing with large-scale multi-objective optimization problems (LSMOPs), including high computational costs for modeling, difficulty in capturing the true PS structure, and neglecting individual directional information. To address these challenges, we propose a dual-information offspring reproduction strategy that considers both the distribution information of the population and the directional information of the outstanding individuals. Specifically, this strategy comprises a sampling approach based on an augmented regularity model specifically designed for LSMOPs. Leveraging this model, we explore and exploit the decision space to sample a promising set of solutions. Additionally, the strategy also involves a search method based on competitive learning among individuals. By assigning a positive evolutionary direction to losing solutions, we update the losing solutions to generate high-quality offspring. We continuously refine the proposed regularity model to approximate the true PS more closely. In extensive experiments on large-scale multi-objective benchmark functions, we compare our algorithm with eight state-of-the-art algorithms. The results demonstrate that our approach excels in handling LSMOPs.},
  archive      = {J_ESWA},
  author       = {Ying Wu and Ziliang Du and Gonglin Yuan and Zhenzhou Tang and Ferrante Neri and Yaqing Hou},
  doi          = {10.1016/j.eswa.2025.129460},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129460},
  shortjournal = {Expert Syst. Appl.},
  title        = {Regularity model-driven large-scale multi-objective evolutionary algorithm based on dual-information offspring reproduction strategy},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GlobalCLIP: Zero-shot manufacturing anomaly detection with adaptive self-cyclic emsemble learning. <em>ESWA</em>, <em>298</em>, 129448. (<a href='https://doi.org/10.1016/j.eswa.2025.129448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately identifying product defects and process anomalies in manufacturing processes is a critical task for product quality and system stability. Although the existing unsupervised anomaly detection methods do not require the annotation of anomalies, they are difficult to deal with the zero-shot scenario faced by multi-variety and small-batch production where there is no available data. In addition, many zero-shot detection algorithms need to represent the image features in tensor form with multiple local feature vectors, and then measure each local feature to infer the overall anomaly of the object. In this paper, we propose GlobalCLIP, a novel approach for zero-shot anomaly detection using only global feature vectors to enhance performance. Specifically, we use CLIP model to aggregate the global features, and design two kinds of adaptive modules from the error level and uncertainty level to realize the series integration of different discriminant models. The adaptive modules encourage the model to learn both normal and abnormal patterns with different granularity, and the self-cyclic training progressively improves model performance. Experiments show that compared to many unsupervised/weakly supervised methods, the performance of GlobalCLIP maintains its advantage even without known samples, and achieves significant improvement over available zero-shot methods.},
  archive      = {J_ESWA},
  author       = {Haoyuan Shen and Enrico Zio and Jiawei Xiong and Yizhong Ma},
  doi          = {10.1016/j.eswa.2025.129448},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129448},
  shortjournal = {Expert Syst. Appl.},
  title        = {GlobalCLIP: Zero-shot manufacturing anomaly detection with adaptive self-cyclic emsemble learning},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Key performance indicator-related process monitoring for irregular scenarios with incomplete data. <em>ESWA</em>, <em>298</em>, 129440. (<a href='https://doi.org/10.1016/j.eswa.2025.129440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern industries exhibit irregular characteristics due to factors such as mode transitions, incomplete data and outliers. Accurate monitoring of key performance indicators (KPIs) in irregular processes is essential for improving product quality and reducing scrap rates. This paper proposes a novel KPI-related process monitoring method that leverages the multiple kernel learning (MKL) technique, designed specifically for irregular scenarios with incomplete data. First, a novel MKL-based nonlinear matrix completion is proposed that utilizes a hierarchical strategy-based algorithm to estimate the missing values in incomplete data and the linear coefficients of multiple kernels. In addition, the corresponding convergence analysis is given. Based on the estimated completed data matrix, a novel MKL-based feature correlation analysis is proposed for indirect prediction of KPIs. Two statistics are established for detecting KPI-related and KPI-unrelated faults, respectively. A numerical case and an industrial example demonstrate that the proposed method not only accurately identifies the missing data, but also effectively detects the KPI-related faults.},
  archive      = {J_ESWA},
  author       = {Yanyu Chen and Hao Ma and Yan Wang and Xiang Liu},
  doi          = {10.1016/j.eswa.2025.129440},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129440},
  shortjournal = {Expert Syst. Appl.},
  title        = {Key performance indicator-related process monitoring for irregular scenarios with incomplete data},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel approach to anomaly detection in critical CPSs: The ERXAI-MS algorithm. <em>ESWA</em>, <em>298</em>, 129437. (<a href='https://doi.org/10.1016/j.eswa.2025.129437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, practical machine learning methodologies are extensively employed for the automation of detecting the intrusion available in the network. In key infrastructure scenarios involving communication strategies, the interplay between different industrial control systems and the inherent connection to the Internet environment through the Internet of Things renders them vulnerable to cyber threats. Considering the substantial volume of network traffic within critical Cyber-Physical Systems, conventional machine-learning approaches utilized for detecting anomalies prove to be ineffective. Hence, newly designed machine learning methods, with a focus on deep learning, are demonstrating effective applications in identifying and categorizing anomalies on both network and individual device levels. This article introduces an innovative Ensemble Random Explainable Artificial Intelligence Meerkat Search algorithm designed for the identification of cyber threats. To augment the effectiveness of the suggested method, it employs a dual-step process for the detection of network irregularities. During the initial phase, the approach involves data pre-processing and dimensionality reduction through the application of Kernel Principal Component Analysis to select the most suitable features. In the subsequent stage, the novel Ensemble Random Explainable Artificial Intelligence Meerkat Search algorithm is employed for classification. The effectiveness of the approach presented in this study is evaluated on diverse datasets, encompassing information collected within the Internet of Things context, specifically IoT-23 and LITNET-2020 datasets. The findings of the assessment of the suggested method are deliberated upon, including the examination of statistical significance and a comparative analysis with contemporary approaches in the field of network anomaly detection. Evaluations confirmed this robust model attained 98.56% accuracy, 97.78% precision, 98.2% F1-score, and produced less FPR of 1.55%.},
  archive      = {J_ESWA},
  author       = {Prabakeran Saravanan and Annamalai Balaji and Hemalatha Murugan and Manickam Muruganantham and Indumathi Varadharajan},
  doi          = {10.1016/j.eswa.2025.129437},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129437},
  shortjournal = {Expert Syst. Appl.},
  title        = {A novel approach to anomaly detection in critical CPSs: The ERXAI-MS algorithm},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved DQN-based recommender system on three-way decision. <em>ESWA</em>, <em>298</em>, 129431. (<a href='https://doi.org/10.1016/j.eswa.2025.129431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems, which utilize algorithms and data analysis to provide personalized suggestions to users, have become an indispensable part of modern life. However, traditional recommendation algorithms face challenges such as the cold start problem, lack of diversity, and limited scalability. Reinforcement learning (RL), particularly deep reinforcement learning (DRL), emerges as a promising solution to these problems by allowing agents to learn optimal strategies through interaction with their environment. Nevertheless, as the scale of data increases, RL-based recommendation systems often struggle to achieve a good balance between exploration and exploitation, impacting the overall performance of the algorithms. In this paper, we propose a reinforcement learning-based recommendation algorithm enhanced by a three-way decision (3WD) framework to address the exploration-exploitation balance challenge. The 3WD algorithm, rooted in rough set theory, categorizes decision outcomes into acceptance, rejection, and uncertainty regions. By applying 3WD in the action selection process of RL, we optimize the trade-off between exploration and exploitation, thereby improving the quality and computational efficiency of recommendations. Additionally, we introduce a dynamic threshold adjustment mechanism to adaptively refine the decision boundary during the action selection process in reinforcement learning, further enhancing the algorithm’s performance. Using the MovieLens dataset as a foundation, we conduct extensive experiments with several randomly generated data sets to evaluate the proposed method. Our results demonstrate that the 3WD-based RL algorithm outperforms traditional methods, such as epsilon-greedy and Softmax, in terms of runtime, recommendation accuracy, and error rate. Notably, the dynamic threshold adjustment model exhibits greater stability and surpasses static methods in recommendation success rates. These findings highlight the effectiveness of combining 3WD with RL in recommendation systems, providing a powerful and efficient solution to the challenges faced by traditional methods. Finally, we analyze the limitations of the model based on the experimental results and propose avenues for future research.},
  archive      = {J_ESWA},
  author       = {Zian Chen and Bao Qing Hu},
  doi          = {10.1016/j.eswa.2025.129431},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129431},
  shortjournal = {Expert Syst. Appl.},
  title        = {Improved DQN-based recommender system on three-way decision},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IntegralGP: Volumetric estimation of subterranean geochemical properties in mineral deposits by fusing assay data with different spatial supports. <em>ESWA</em>, <em>298</em>, 129429. (<a href='https://doi.org/10.1016/j.eswa.2025.129429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an Integral Gaussian Process (IntegralGP) framework for volumetric estimation of subterranean properties in mineral deposits. It provides a unified representation for data with different spatial supports, which enables blasthole geochemical assays to be properly modelled as interval observations rather than points. This approach is shown to improve regression performance and boundary delineation. A core contribution is a description of the mathematical changes to the covariance expressions which allow these benefits to be realised. The gradient and anti-derivatives are obtained to facilitate learning of the kernel hyperparameters. Numerical stability issues are also discussed. To illustrate its application, an IntegralGP data fusion algorithm is described. The objective is to assimilate line-based blasthole assays and update a block model that provides long-range prediction of Fe concentration beneath the drilled bench. Heteroscedastic GP is used to fuse chemically compatible but spatially incongruous data with different resolutions and sample spacings. Domain knowledge embodied in the structure and empirical distribution of the block model must be generally preserved while local inaccuracies are corrected. Using validation measurements within the predicted bench, our experiments demonstrate an improvement in bench-below grade prediction performance. For material classification, IntegralGP fusion reduces the absolute error and model bias in categorical prediction, especially instances where waste blocks are mistakenly classified as high-grade.},
  archive      = {J_ESWA},
  author       = {Anna Chlingaryan and Arman Melkumyan and Raymond Leung},
  doi          = {10.1016/j.eswa.2025.129429},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129429},
  shortjournal = {Expert Syst. Appl.},
  title        = {IntegralGP: Volumetric estimation of subterranean geochemical properties in mineral deposits by fusing assay data with different spatial supports},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep multi-view least squares support vector machine with consistency and complementarity principle based on cross-output knowledge transfer. <em>ESWA</em>, <em>298</em>, 129406. (<a href='https://doi.org/10.1016/j.eswa.2025.129406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a Deep Multi-view Least Squares Support Vector Machine with Consistency and Complementarity Principles based on Cross-Output Knowledge Transfer (MDCTM), which has four distinctive features: 1) It integrates the idea of deep stacking architecture, which is the first attempt to use transfer learning to form deep architectures in multi-view learning. It can enhance the ability to handle complex problems. Starting from the second layer, it incorporates extra input attributes that consider the predictions made by all preceding layers, effectively revealing the manifold structure of the original data. 2) Each layer follows the consistency and complementarity principles, which can fully excavate the information in multi-view data. In each layer, the model is solved by an alternating optimization strategy. 3) Cross-output knowledge transfer leverages predictions from earlier layers to improve the learning of subsequent ones, which can improve the classification performance of the model. Additionally, the extent of cross-output knowledge transfer between sequential layers can be assessed autonomously and effectively by utilizing a fast leave-one-out cross-validation method. 4) The model allows random assignment of model parameters in each layer, such as weights and kernel widths, boosting learning speed. Numerical experiments demonstrate the model’s effectiveness and efficiency.},
  archive      = {J_ESWA},
  author       = {Shuangrui Jia and Sijie Liang and Ziyi Mo and Chunxiao Liu and Huiru Wang and Chen Chen},
  doi          = {10.1016/j.eswa.2025.129406},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129406},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep multi-view least squares support vector machine with consistency and complementarity principle based on cross-output knowledge transfer},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A study on the modeling of long-term trend and short-term fluctuation: Fourier-enhanced adaptive koopman operator for carbon emission forecasting. <em>ESWA</em>, <em>298</em>, 129388. (<a href='https://doi.org/10.1016/j.eswa.2025.129388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Koopman operator provides a new way to model complex data patterns, revealing the intrinsic dynamics of time series from a dynamical system perspective. Despite its potential, the Koopman operator has received limited attention in time series forecasting, particularly in addressing these complex, real-world challenges such as carbon emission dynamics characterized by nonlinearity, non-stationarity, and multi-scale coupling effects. To this end, this study proposes a novel forecasting paradigm, Fourier-Enhanced adaptive Koopman operator for carbon emission forecasting (F-KOCE). This approach conceptually extends traditional Koopman frameworks by embedding a spectral-decoupled time series representation into a dual Koopman learning structure, which enables the model to linearize nonlinear dynamics across multiple time scales in a theoretically grounded and practically adaptive manner. By integrating Fourier filter decomposition into Koopman operator theory, F-KOCE separates raw emissions into long-term trends and short-term fluctuations while achieving global linearization of system dynamics. A learnable Koopman operator captures intrinsic temporal structures, while a multi-granularity adaptive weight learning strategy enhances resilience against data variability. To further improve robustness, we introduce an adaptive residual fusion structure for block-level feature compression, noise suppression, and cross-scale information fusion. Additionally, the effective Trend Corrector mechanism dynamically modulates the influence of trend and fluctuation components, refining predictive accuracy. Beyond point forecasting, the framework is also extended to interval forecasting, providing uncertainty-aware predictions. Extensive experiments conducted on 36 Carbon Monitor datasets across six regions and six sectors demonstrate the superiority of F-KOCE over advanced existing models across multiple evaluation metrics. These results confirm the framework’s efficacy in capturing high-dimensional emission dynamics and underscore the potential of Koopman operator theory in carbon forecasting. By offering a robust, interpretable, and data-driven approach, F-KOCE provides valuable insights for climate policy formulation.},
  archive      = {J_ESWA},
  author       = {Jinxing Che and Wei Dong and Qian Sun and Yuhua Zhang},
  doi          = {10.1016/j.eswa.2025.129388},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129388},
  shortjournal = {Expert Syst. Appl.},
  title        = {A study on the modeling of long-term trend and short-term fluctuation: Fourier-enhanced adaptive koopman operator for carbon emission forecasting},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A cooperative co-evolutionary algorithm with core-based grouping strategy for large-scale 0–1 knapsack problems. <em>ESWA</em>, <em>298</em>, 129364. (<a href='https://doi.org/10.1016/j.eswa.2025.129364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 0–1 knapsack problem (KP) is a well-known combinatorial optimization problem with wide real-world applications. While evolutionary algorithms have demonstrated promise in solving 0–1 KPs, their performance deteriorates as the problem dimension increases. Cooperative co-evolution (CC) is an algorithmic framework based on a divide-and-conquer strategy, which has been used in solving large-scale optimization problems. Inspired by the similarity between item grouping in the 0–1 KP and decomposition strategies in CC, this paper proposes a novel grouping strategy that uses the position information of break items and profit-to-weight ratio to solve large-scale 0–1 KP. The strategy aims to divide the large-scale 0–1 KP into multiple subproblems, thus having a reduced search space for each subproblem. To enhance population diversity and search efficiency, the profit-to-weight ratio is used to generate an initial elite population. Additionally, to obtain the complete solution for the original large-scale KP, a subgroup merging method is designed to accelerate convergence and further improve population diversity. A three-phase repair operator is developed to fix infeasible solutions directly to create more feasible solutions. The resulting cooperative co-evolutionary algorithm is compared with ten state-of-the-art algorithms for solving 0–1 KPs with variables ranging from 100 to 5,000, including EAs, CC-based approaches, and a deep reinforcement learning method. Experimental results show that the proposed algorithm exhibits higher solution accuracy and faster convergence than other competing algorithms. The CC framework takes considerably less running time than high-performing algorithms, providing an overall novel approach for solving large-scale 0–1 KPs.},
  archive      = {J_ESWA},
  author       = {Xiaotong Li and Shuwei Zhu and Wei Fang and Kalyanmoy Deb},
  doi          = {10.1016/j.eswa.2025.129364},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129364},
  shortjournal = {Expert Syst. Appl.},
  title        = {A cooperative co-evolutionary algorithm with core-based grouping strategy for large-scale 0–1 knapsack problems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Balancing forecast accuracy and switching costs in online optimization of energy management systems. <em>ESWA</em>, <em>298</em>, 129305. (<a href='https://doi.org/10.1016/j.eswa.2025.129305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the integration of forecasting and optimization in energy management systems, focusing on how switching costs, penalties incurred from frequent operational adjustments, affect the balance between forecast accuracy and stability in online decision-making. We develop a theoretical framework analyzing Fixed Horizon Control (FHC) algorithms under switching costs, deriving performance bounds that reveal trade-offs between commitment periods and forecast properties. We introduce a novel Scenario Distribution Change (SDC) metric for measuring temporal consistency in probabilistic forecasts. The framework is validated through empirical evaluation using a real-world battery scheduling case study based on the CityLearn 2022 challenge, comparing deterministic and stochastic optimization approaches across different commitment periods. Theoretical analysis reveals that switching costs create a U-shaped relationship between commitment period and performance, with optimal commitment depending on forecast stability. Empirical results demonstrate that switching costs significantly alter the accuracy-stability trade-off: while traditional approaches favor frequent updates (1-hour commitment), incorporating switching costs makes longer commitment periods (3+ hours) optimal when combined with stable forecasts. Stochastic optimization with scenario averaging reduces forecast error sensitivity by up to 2.9 % in grid costs compared to deterministic approaches. This work contributes the first theoretical bounds linking forecast stability to switching costs in energy systems, the SDC metric for evaluating probabilistic forecast stability, empirical evidence that longer commitment periods can outperform frequent updates under switching costs, and practical guidelines showing that forecast stability should be factored into decision-making frameworks for energy management systems in the presence of switching costs.},
  archive      = {J_ESWA},
  author       = {Evgenii Genov and Julian Ruddick and Christoph Bergmeir and Majid Vafaeipour and Thierry Coosemans and Salvador García and Maarten Messagie},
  doi          = {10.1016/j.eswa.2025.129305},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129305},
  shortjournal = {Expert Syst. Appl.},
  title        = {Balancing forecast accuracy and switching costs in online optimization of energy management systems},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid bee colony algorithm for crack repair trajectory planning based on focal attention guided lightweight segmentation. <em>ESWA</em>, <em>298</em>, 129267. (<a href='https://doi.org/10.1016/j.eswa.2025.129267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic arm trajectory planning of crack repair is critical for automated road maintenance. However, existing crack repair face two main challenges: loss of trajectory edge information and redundant planned distances. This study introduces an automated pavement crack repair system that integrates a lightweight crack segmentation model (Lightweight Focal Modulation, LFM-Net) and a repair trajectory planning algorithm (Fixed Neighborhood Search-Artificial Bee Colony, FNS-ABC). Specifically, LFM-Net incorporates conformer-based focal modulation attention (CFMA), enhancing the detailed information during the decoding phase. Additionally, the FNS-ABC enhances the ABC algorithm by incorporating a fixed neighborhood search strategy, effectively reducing redundant planning paths. The system is executed using a self-developed robotic arm with an edge computing unit. Extensive testing in three typical road scenarios-independent cracks, intersection cracks, and complex cracks-demonstrated that the system achieved a mean Intersection over Union (mIoU) of 83.93 %. Finally, the system exhibited an idle trajectory of 79.51 mm when addressing complex cracks, highlighting its superior performance in repair trajectory planning.},
  archive      = {J_ESWA},
  author       = {Jianqi Zhang and Xu Yang and Wei Wang and Yuhang Zhao and Hainian Wang and Yixue Chen},
  doi          = {10.1016/j.eswa.2025.129267},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129267},
  shortjournal = {Expert Syst. Appl.},
  title        = {A hybrid bee colony algorithm for crack repair trajectory planning based on focal attention guided lightweight segmentation},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep-learning based big data analysis for developing a smart supply chain for increased efficiency. <em>ESWA</em>, <em>298</em>, 129246. (<a href='https://doi.org/10.1016/j.eswa.2025.129246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data analysis (BDA) in supply chain management (SCM) is receiving growing attention in the present business environment. This is due to the fact that BDA has a wide range of applications in SCM, including customer behaviour analysis, trend analysis, and demand prediction. The increase in information volume has caused the efficiency and effectiveness of traditional procedures to decline, considering this, researchers have developed techniques that have a high capacity to investigate and comprehend vast amounts of data due to the limitations of these tactics in dissecting and interpreting a lot of information. This study represents a hybrid paper that combines a systematic literature review, a methodological proposal using BP neural networks. The main objective of this paper is to recognize the uses of deep learning in SCM. By fostering a calculated system, this paper recognizes the commitments of deep learning strategies in choosing and sectioning providers, foreseeing store network gambles, and assessing requests and deals, creation, stock administration, transportation and circulation, manageable turn of events, and roundabout economy. The novelty in this paper is the Backpropagation (BP) neural networks with big data-driven demand forecasting in supply chains. This method can improve the accuracy of demand forecasting in supply chain management. The study includes a thorough survey of the applications of predictive BDA in SC request gauging. The review highlighted the BDA methodologies used for production network request estimation and comparatively classified them. We collected and analysed these studies as tactics and methodologies for the popular forecast. Seven standard tactics were selected and studied, along with their benefits and drawbacks. Finally, the box-cox transformation representation over years in which for the year 2011–01, it starts with a box-cox value of 9.7 and it inclined till 2011–06 and then declined very exponentially in 2012–07 at 9 and then it keeps on incrementing and reached at 11 at the year 2013–07. Then from 2014 to 2015, the pattern didn’t lower below the box-cox value 10.},
  archive      = {J_ESWA},
  author       = {Sreekumar Narayanan and Sudhir Ramadass and K. Thilagavathi and Rajiv Kumar},
  doi          = {10.1016/j.eswa.2025.129246},
  journal      = {Expert Systems with Applications},
  month        = {3},
  pages        = {129246},
  shortjournal = {Expert Syst. Appl.},
  title        = {Deep-learning based big data analysis for developing a smart supply chain for increased efficiency},
  volume       = {298},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="iandc">IANDC - 9</h2>
<ul>
<li><details>
<summary>
(2025). Polynomial turing compressions for some graph problems parameterized by modular-width. <em>IANDC</em>, <em>307</em>, 105355. (<a href='https://doi.org/10.1016/j.ic.2025.105355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A polynomial Turing compression (PTC) for a parameterized problem L is a polynomial time Turing machine that has access to an oracle for a problem L ′ such that a polynomial in the input parameter bounds each query. Meanwhile, a polynomial compression (PC) can be regarded as a restricted variant of PTC where the machine can query the oracle exactly once and must output the same answer as the oracle. Bodlaender et al. (ICALP 2008) and Fortnow and Santhanam (STOC 2008) initiated an impressive hardness theory for PC under the assumption coNP ⊈ NP/poly. Let C be the set of all problems with PTCs but without PCs assuming coNP ⊈ NP/poly. Fernau et al. (STACS 2009) identified Leaf Out-tree( k ) as the first problem in C . However, little is known about C , with only a dozen problems confirmed in it over the last fifteen years. Open questions remain, such as whether CNF-SAT( n ) and k -path are in C , requiring novel ideas to clarify the differences between PTCs and PCs. In this paper, we enrich our knowledge about C by demonstrating that 17 problems parameterized by modular-width ( mw ), such as Chromatic Number( mw ) and Hamiltonian Cycle( mw ) , belong to C . Additionally, we develop a general recipe to prove the existence of PTCs for a class of problems, including these 17.},
  archive      = {J_IANDC},
  author       = {Weidong Luo},
  doi          = {10.1016/j.ic.2025.105355},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105355},
  shortjournal = {Inf. Comput.},
  title        = {Polynomial turing compressions for some graph problems parameterized by modular-width},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On cardinalities of rogers semilattices for families in the ershov hierarchy. <em>IANDC</em>, <em>307</em>, 105354. (<a href='https://doi.org/10.1016/j.ic.2025.105354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of numberings provides classification results for families of sets in various computability-theoretic hierarchies. The algorithmic content of numberings is typically calibrated via the reducibility between numberings. For a given family of sets S , this reducibility gives rise to an upper semilattice of degrees that is often called the Rogers semilattice of S . This paper studies the cardinalities of Rogers semilattices for families of sets at finite levels of the Ershov hierarchy. The classical result of Khutoretskii (1971) shows that the Rogers semilattice of a family of c.e. sets is either one-element or countably infinite. Badaev and Lempp (2009) constructed a family of d.c.e. sets that demonstrates that the methods of Khutoretskii cannot be applied to obtain a similar result for Rogers semilattices already at the second level of the Ershov hierarchy. We prove that for any finite family of sets S at any finite level of the Ershov hierarchy, the corresponding Rogers semilattice is either one-element or countably infinite. We also obtain another sufficient condition for a Rogers semilattice to be infinite. This condition implies that the Rogers semilattice of Badaev and Lempp is also infinite.},
  archive      = {J_IANDC},
  author       = {Keng Meng Ng and Nikolay Bazhenov and Birzhan Kalmurzayev and Dias Nurlanbek},
  doi          = {10.1016/j.ic.2025.105354},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105354},
  shortjournal = {Inf. Comput.},
  title        = {On cardinalities of rogers semilattices for families in the ershov hierarchy},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact counting of subtrees with diameter no more than d in trees: A generating function approach. <em>IANDC</em>, <em>307</em>, 105353. (<a href='https://doi.org/10.1016/j.ic.2025.105353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network motifs, regarded as fundamental building blocks, offer crucial insights into the structure and function of complex networks, with broad applications across disciplines including sociology, computer science, bioinformatics, chemoinformatics, and pharmaceutics. However, the identification of network motifs remains a significant and computationally challenging problem. Among various motifs, subtree enumeration has garnered substantial attention in recent years, particularly due to its relevance in network science and bioinformatics. For an n -vertex tree T , by introducing novel generating functions with ( d + 2 ) variables, we propose an innovative algorithm for the exact enumeration of T 's subtrees rooted at fixed vertex v , where the distance between v and the farthest leaf is k = 0 , 1 , … , d , and the distance between any two leaves is no more than d . Building on this algorithm, we develop novel recursive algorithms for exact enumerating various diameter no more than d subtrees (abbreviated as DNMT- d subtrees) of T . As applications, we apply these algorithms to derive the number of DNMT- d subtrees in a full binary tree B h with h ≥ 2 levels, and briefly discuss the density of DNMT- d subtrees in general trees. Our research generalizes the work of Frank Ruskey on Listing and Counting Subtrees of a Tree in 1981 and makes it a special case of our study where d equals the diameter of the tree T . Moreover, the proposed O ( d n 2 ) algorithms introduce new approaches for enumerating subtrees under diameter constraints and lay the groundwork for counting diameter-constrained subgraphs (motifs) in complex networks.},
  archive      = {J_IANDC},
  author       = {Yu Yang and Bang-Bang Jin and Xiaoming Sun and Xiao-Dong Zhang and Bo Li and Kai Zhao and Hua Wang},
  doi          = {10.1016/j.ic.2025.105353},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105353},
  shortjournal = {Inf. Comput.},
  title        = {Exact counting of subtrees with diameter no more than d in trees: A generating function approach},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision problems for systems of language equations and inequations. <em>IANDC</em>, <em>307</em>, 105344. (<a href='https://doi.org/10.1016/j.ic.2025.105344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systems of language equations φ ( X 1 , … , X n ) = ψ ( X 1 , … , X n ) and inequations φ ( X 1 , … , X n ) ≠ ψ ( X 1 , … , X n ) are studied, where φ and ψ may contain Boolean operations and concatenation. It is proved that the problem whether such a system has a solution is Σ 2 0 -complete in the arithmetical hierarchy (cf. the earlier studied case of equations only, where it is co-r.e.-complete), the problem whether it has a unique solution is in Σ 3 0 ∩ Π 3 0 , and is both Σ 2 0 -hard and Π 2 0 -hard, existence of a finite or regular solution is an r.e.-complete problem, while testing whether a system has finitely many solutions is Σ 3 0 -complete. Furthermore, it is shown that the class of languages representable by unique solutions of such systems is exactly the class of recursive sets, but decision procedures for the set cannot be algorithmically constructed out of a system. All results hold already for equations over a unary alphabet.},
  archive      = {J_IANDC},
  author       = {Alexander Okhotin},
  doi          = {10.1016/j.ic.2025.105344},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105344},
  shortjournal = {Inf. Comput.},
  title        = {Decision problems for systems of language equations and inequations},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards a theoretical understanding of why local search works for clustering with fair-center representation. <em>IANDC</em>, <em>307</em>, 105343. (<a href='https://doi.org/10.1016/j.ic.2025.105343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The representative k -median problem generalizes the classical clustering formulations in that it partitions the data points into ℓ disjoint demographic groups and imposes a lower-bound constraint on the number of opened facilities from each group, such that all the groups are fairly represented by the opened facilities. Due to its simplicity, the local-search heuristic, which iteratively swaps a bounded number of closed facilities for the same number of opened ones to improve the solution, has been frequently used in the representative k -median problem. It is known that the local-search heuristic, when restricted to constant-size swaps, yields a constant-factor approximation if ℓ = 2 , and has an unbounded approximation ratio if ℓ is super-constant. However, for any constant ℓ > 2 , the existence of a constant-factor approximation under constant-size swaps remained an open question for a long time. In response to this question, we demonstrate that the local-search heuristic guarantees a ( 4 ℓ + 5 ) -approximation when up to ℓ ( ℓ + 1 ) facilities are allowed to be swapped in each iteration, thus providing an affirmative answer to the question. Our main technical contribution is a novel approach for theoretically analyzing the local-search heuristic, which bounds its approximation ratio by linearly combining the clustering cost increases induced by a set of hierarchically organized swaps. Our techniques also generalize to the k -means clustering formulation and reveal similar approximation guarantees for the local-search heuristic.},
  archive      = {J_IANDC},
  author       = {Zhen Zhang and Junfeng Yang and Limei Liu and Xuesong Xu and Guozhen Rong and Qilong Feng},
  doi          = {10.1016/j.ic.2025.105343},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105343},
  shortjournal = {Inf. Comput.},
  title        = {Towards a theoretical understanding of why local search works for clustering with fair-center representation},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The billaud conjecture for alphabet size 4. <em>IANDC</em>, <em>307</em>, 105342. (<a href='https://doi.org/10.1016/j.ic.2025.105342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Billaud Conjecture, first stated in 1993, is a fundamental problem on finite words and their heirs, i.e., the words obtained by a projection deleting a single letter. The conjecture states that every morphically primitive word, i.e., a word that is not a fixed point of any non-identity morphism, has at least one morphically primitive heir. The correctness of the conjecture has so far been established in a few special cases, which mainly restrict the alphabet size. In this paper we give a proof for the next such case, i.e., for alphabet size 4.},
  archive      = {J_IANDC},
  author       = {Szymon Łopaciuk and Daniel Reidenbach},
  doi          = {10.1016/j.ic.2025.105342},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105342},
  shortjournal = {Inf. Comput.},
  title        = {The billaud conjecture for alphabet size 4},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The g-good-neighbor diagnosability of product networks under the PMC model. <em>IANDC</em>, <em>307</em>, 105341. (<a href='https://doi.org/10.1016/j.ic.2025.105341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of neighbor connectivity originated from the assessment of the subversion of espionage networks caused by underground resistance movements, and it has now been applied to measure the disruption of networks caused by cascading failures through neighbors. In this paper, we give two necessary and sufficient conditions of the existence of g -good-neighbor diagnosability. We introduce a new concept called g -good neighbor cut-component number (gc number for short), which has close relation with g -good-neighbor diagnosability. Sharp lower and upper bounds of the gc number of general graphs in terms of the g -good neighbor connectivity have been proposed, which provide a formula to compute the g -good-neighbor diagnosability for general graphs (therefore for Cartesian product graphs). As their applications, we get the exact values or bounds for the gc numbers and g -good-neighbor diagnosability of grid, torus networks and generalized cubes.},
  archive      = {J_IANDC},
  author       = {Zhao Wang and Yaping Mao and Sun-Yuan Hsieh and Ralf Klasing},
  doi          = {10.1016/j.ic.2025.105341},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105341},
  shortjournal = {Inf. Comput.},
  title        = {The g-good-neighbor diagnosability of product networks under the PMC model},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-state spin systems with negative interactions. <em>IANDC</em>, <em>307</em>, 105340. (<a href='https://doi.org/10.1016/j.ic.2025.105340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the approximability of computing the partition functions of two-state spin systems. The problem is parameterized by a 2 × 2 symmetric matrix. Previous results on this problem were restricted either to the case where the matrix has non-negative entries, or to the case where the diagonal entries are equal, i.e. Ising models. In this paper, we study the generalization to arbitrary 2 × 2 interaction matrices with real entries. We show that in some regions of the parameter space, it's #P-hard to even determine the sign of the partition function, while in other regions there are fully polynomial approximation schemes for the partition function. Our results reveal several new computational phase transitions.},
  archive      = {J_IANDC},
  author       = {Yumou Fei and Leslie Ann Goldberg and Pinyan Lu},
  doi          = {10.1016/j.ic.2025.105340},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105340},
  shortjournal = {Inf. Comput.},
  title        = {Two-state spin systems with negative interactions},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competition among parallel contests. <em>IANDC</em>, <em>307</em>, 105339. (<a href='https://doi.org/10.1016/j.ic.2025.105339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the model of multiple rank-order contests held in parallel, where each contestant only selects one contest to join and each contest designer decides the prize structure to compete for the participation of contestants. We first analyze the strategic behaviors of contestants and completely characterize the symmetric Bayesian Nash equilibrium. As for the strategies of contest designers, when other designers' strategies are known, we show that computing the best response is NP-hard and propose a fully polynomial time approximation scheme to output the ϵ -approximate best response. When other designers' strategies are unknown, we provide a worst-case analysis on one designer's strategy. We give an upper bound on the worst-case utility of any strategy and propose a method to construct a strategy whose utility can guarantee a constant ratio of this upper bound in the worst case.},
  archive      = {J_IANDC},
  author       = {Xiaotie Deng and Ningyuan Li and Weian Li and Qi Qi},
  doi          = {10.1016/j.ic.2025.105339},
  journal      = {Information and Computation},
  month        = {11},
  pages        = {105339},
  shortjournal = {Inf. Comput.},
  title        = {Competition among parallel contests},
  volume       = {307},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="icv">ICV - 11</h2>
<ul>
<li><details>
<summary>
(2025). Mining fine-grained attributes for vision–semantics integration in few-shot learning. <em>ICV</em>, <em>163</em>, 105739. (<a href='https://doi.org/10.1016/j.imavis.2025.105739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Few-Shot Learning (FSL) have been significantly driven by leveraging semantic descriptions to enhance feature discrimination and recognition performance. However, existing methods, such as SemFew, often rely on verbose or manually curated attributes and apply semantic guidance only to the support set, limiting their effectiveness in distinguishing fine-grained categories. Inspired by human visual perception, which emphasizes crucial features for accurate recognition, this study introduces concise, fine-grained semantic attributes to address these limitations. We propose a Visual Attribute Enhancement (VAE) mechanism that integrates enriched semantic information into visual features, enabling the model to highlight the most relevant visual attributes and better distinguish visually similar samples. This module enhances visual features by aligning them with semantic attribute embeddings through a cross-attention mechanism and optimizes this alignment using an attribute-based cross-entropy loss. Furthermore, to mitigate the performance degradation caused by methods that supply semantic information exclusively to the support set, we propose a semantic attribute reconstruction (SAR) module. This module predicts and integrates semantic features for query samples, ensuring balanced information distribution between the support and query sets. Specifically, SAR enhances query representations by aligning and reconstructing semantic and visual attributes through regression and optimal transport losses to ensure semantic–visual consistency. Experiments on five benchmark datasets, including both general datasets and more challenging fine-grained Few-Shot datasets consistently demonstrate that our proposed method outperforms state-of-the-art methods in both 5-way 1-shot and 5-way 5-shot settings.},
  archive      = {J_ICV},
  author       = {Juan Zhao and Lili Kong and Deshang Sun and Deng Xiong and Jiancheng Lv},
  doi          = {10.1016/j.imavis.2025.105739},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105739},
  shortjournal = {Image Vis. Comput.},
  title        = {Mining fine-grained attributes for vision–semantics integration in few-shot learning},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable deepfake detection across different modalities: An overview of methods and challenges. <em>ICV</em>, <em>163</em>, 105738. (<a href='https://doi.org/10.1016/j.imavis.2025.105738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing use of deepfake technology enables the creation of realistic and deceptive content, raising concerns about several serious issues, including biometric authentication, misinformation, politics, privacy, and trust. Many Deepfake Detection (DD) models are entering the market to combat the misuse of deepfakes. With these developments, one primary issue occurs in ensuring the explainability of the proposed detection models to understand the rationale of the decision. This paper aims to investigate the state-of-the-art explainable DD models across multiple modalities, including image, video, audio, and text. Unlike existing surveys that focus on detection methodologies with minimal attention to explainability and limited modality coverage, this paper directly focuses on these gaps. It offers a comprehensive analysis of advanced explainability techniques, including Grad-CAM, LIME, SHAP, LRP, Saliency Maps, and Anchors, for detecting deceptive content across the modalities. It identifies the strengths and limitations of existing models and outlines research directions to enhance explainability and interpretability in future works. By exploring these models, we aim to enhance transparency, provide deeper insights into model decisions, and bridge the gap between detection accuracy with explainability in DD models.},
  archive      = {J_ICV},
  author       = {MD Sarfaraz Momin and Abu Sufian and Debaditya Barman and Marco Leo and Cosimo Distante and Naser Damer},
  doi          = {10.1016/j.imavis.2025.105738},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105738},
  shortjournal = {Image Vis. Comput.},
  title        = {Explainable deepfake detection across different modalities: An overview of methods and challenges},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MITS: A large-scale multimodal benchmark dataset for intelligent traffic surveillance. <em>ICV</em>, <em>163</em>, 105736. (<a href='https://doi.org/10.1016/j.imavis.2025.105736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {General-domain large multimodal models (LMMs) have achieved significant advances in various image-text tasks. However, their performance in the Intelligent Traffic Surveillance (ITS) domain remains limited due to the absence of dedicated multimodal datasets. To address this gap, we introduce MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale multimodal benchmark dataset specifically designed for ITS. MITS includes 170,400 independently collected real-world ITS images sourced from traffic surveillance cameras, annotated with eight main categories and 24 subcategories of ITS-specific objects and events under diverse environmental conditions. Additionally, through a systematic data generation pipeline, we generate high-quality image captions and 5 million instruction-following visual question-answer pairs , addressing five critical ITS tasks : object and event recognition, object counting, object localization, background analysis, and event reasoning. To demonstrate MITS’s effectiveness, we fine-tune mainstream LMMs on this dataset, enabling the development of ITS-specific applications. Experimental results show that MITS significantly improves LMM performance in ITS applications, increasing LLaVA-1.5’s performance from 0.494 to 0.905 (+83.2%), LLaVA-1.6’s from 0.678 to 0.921 (+35.8%), Qwen2-VL’s from 0.584 to 0.926 (+58.6%), and Qwen2.5-VL’s from 0.732 to 0.930 (+27.0%). We release the dataset, code, and models as open-source , providing high-value resources to advance both ITS and LMM research.},
  archive      = {J_ICV},
  author       = {Kaikai Zhao and Zhaoxiang Liu and Peng Wang and Xin Wang and Zhicheng Ma and Yajun Xu and Wenjing Zhang and Yibing Nan and Kai Wang and Shiguo Lian},
  doi          = {10.1016/j.imavis.2025.105736},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105736},
  shortjournal = {Image Vis. Comput.},
  title        = {MITS: A large-scale multimodal benchmark dataset for intelligent traffic surveillance},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UNIR-net: A novel approach for restoring underwater images with non-uniform illumination using synthetic data. <em>ICV</em>, <em>163</em>, 105734. (<a href='https://doi.org/10.1016/j.imavis.2025.105734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restoring underwater images affected by non-uniform illumination (NUI) is essential to improve visual quality and usability in marine applications. Conventional methods often fall short in handling complex illumination patterns, while learning-based approaches face challenges due to the lack of targeted datasets. To address these limitations, the Underwater Non-uniform Illumination Restoration Network (UNIR-Net) is proposed. UNIR-Net integrates multiple components, including illumination enhancement, attention mechanisms, visual refinement, and contrast correction, to effectively restore underwater images affected by NUI. In addition, the Paired Underwater Non-uniform Illumination (PUNI) dataset is introduced, specifically designed for training and evaluating models under NUI conditions. Experimental results on PUNI and the large-scale real-world Non-Uniform Illumination Dataset (NUID) show that UNIR-Net achieves superior performance in both quantitative metrics and visual outcomes. UNIR-Net also improves downstream tasks such as underwater semantic segmentation, highlighting its practical relevance. The code is available at https://github.com/xingyumex/UNIR-Net .},
  archive      = {J_ICV},
  author       = {Ezequiel Pérez-Zarate and Chunxiao Liu and Oscar Ramos-Soto and Diego Oliva and Marco Pérez-Cisneros},
  doi          = {10.1016/j.imavis.2025.105734},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105734},
  shortjournal = {Image Vis. Comput.},
  title        = {UNIR-net: A novel approach for restoring underwater images with non-uniform illumination using synthetic data},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FFENet: A frequency fusion and enhancement network for camouflaged object detection. <em>ICV</em>, <em>163</em>, 105733. (<a href='https://doi.org/10.1016/j.imavis.2025.105733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of camouflaged object detection (COD) is to accurately find camouflaged objects hidden in their surroundings. Although most of the existing frequency-domain based COD models can boost the performance of COD to a certain extent by utilizing the frequency domain information, the frequency feature fusion strategies they adopt tend to ignore the complementary effects between high-frequency features and low-frequency features. In addition, most of the existing frequency-domain based COD models also do not consider enhancing camouflaged objects using low-level frequency-domain features. In order to solve these problems, we present a frequency fusion and enhancement network (FFENet) for camouflaged object detection, which mainly includes three stages. In the frequency feature extraction stage, we design a frequency feature learning module (FLM) to extract corresponding high-frequency features and low-frequency features. In the frequency feature fusion stage, we design a frequency feature fusion module (FFM) that can increase the representation ability of the fused features by adaptively assigning weights to the high-frequency features and the low-frequency features using a cross-attention mechanism. In the frequency feature guidance information enhancement stage, we design a frequency feature guidance information enhancement module (FGIEM) to enhance the contextual information and detail information of camouflaged objects in the fused features under the guidance of the low-level frequency features. Extensive experimental results on the COD10K, CHAMELEON, NC4K and CAMO datasets show that our model is superior to most existing COD models.},
  archive      = {J_ICV},
  author       = {Haishun Du and Wenzhe Zhang and Sen Wang and Zhengyang Zhang and Linbing Cao},
  doi          = {10.1016/j.imavis.2025.105733},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105733},
  shortjournal = {Image Vis. Comput.},
  title        = {FFENet: A frequency fusion and enhancement network for camouflaged object detection},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UpAttTrans: Upscaled attention based transformer for facial image super-resolution. <em>ICV</em>, <em>163</em>, 105731. (<a href='https://doi.org/10.1016/j.imavis.2025.105731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image super-resolution (SR) aims to reconstruct high-quality images from low-resolution inputs, a task particularly challenging in face-related applications due to extreme degradations and modality differences (e.g., visible, low-resolution, near-infrared). Conventional convolutional neural networks (CNNs) and GAN-based approaches have achieved notable success; however, they often struggle with preserving identity and fine structural details at high upscaling factors. In this work, we introduce UpAttTrans, a novel attention mechanism that connects original and upsampled features for better detail recovery based on vision transformer for SR. The core generator leverages a custom UpAttTrans module that translates input image patches into embeddings, processes them through transformer layers enhanced with connector-up attention, and reconstructs high-resolution outputs with improved detail retention. We evaluate our model on the CelebA dataset across multiple upscaling factors ( 4 × , 8 × , 16 × , 32 × , and 64 × ). UpAttTrans achieves a 24.63% increase in PSNR, 21.56% in SSIM, and 19.61% reduction in FID for 4 × and 8 × SR, outperforming state-of-the-art baselines. Additionally, for higher magnification levels, our model maintains strong performance, with average gains of 6.20% in PSNR and 21.49% in SSIM, indicating its robustness in extreme SR settings. These findings suggest that UpAttTrans holds significant promise for real-world applications such as face recognition in surveillance, forensic image enhancement, and cross-spectral matching, where high-quality reconstruction from severely degraded inputs is critical.},
  archive      = {J_ICV},
  author       = {Neeraj Baghel and Shiv Ram Dubey and Satish Kumar Singh},
  doi          = {10.1016/j.imavis.2025.105731},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105731},
  shortjournal = {Image Vis. Comput.},
  title        = {UpAttTrans: Upscaled attention based transformer for facial image super-resolution},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel extraction of discriminative fine-grained feature to improve retinal vessel segmentation. <em>ICV</em>, <em>163</em>, 105729. (<a href='https://doi.org/10.1016/j.imavis.2025.105729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vessel segmentation is a vital early detection method for several severe ocular diseases. Despite significant progress in retinal vessel segmentation with the advancement of Neural Networks, there are still challenges to overcome. Specifically, retinal vessel segmentation aims to predict the class label for every pixel within a fundus image, with a primary focus on intra-image discrimination, making it vital for models to extract more discriminative features. Nevertheless, existing methods primarily focus on minimizing the difference between the output from the decoder and the label, but ignore fully using feature-level fine-grained representations from the encoder. To address these issues, we propose a novel Attention U-shaped Kolmogorov–Arnold Network named AttUKAN along with a novel Label-guided Pixel-wise Contrastive Loss for retinal vessel segmentation. Specifically, we implement Attention Gates into Kolmogorov–Arnold Networks to enhance model sensitivity by suppressing irrelevant feature activations and model interpretability by non-linear modeling of KAN blocks. Additionally, we also design a novel Label-guided Pixel-wise Contrastive Loss to supervise our proposed AttUKAN to extract more discriminative features by distinguishing between foreground vessel-pixel pairs and background pairs. Experiments are conducted across four public datasets including DRIVE, STARE, CHASE_DB1, HRF and our private dataset. AttUKAN achieves F1 scores of 82.50%, 81.14%, 81.34%, 80.21% and 80.09%, along with MIoU scores of 70.24%, 68.64%, 68.59%, 67.21% and 66.94% in the above datasets, which are the highest compared to 11 networks for retinal vessel segmentation. Quantitative and qualitative results show that our AttUKAN achieves state-of-the-art performance and outperforms existing retinal vessel segmentation methods. Our code will be available at https://github.com/stevezs315/AttUKAN .},
  archive      = {J_ICV},
  author       = {Shuang Zeng and Chee Hong Lee and Micky C. Nnamdi and Wenqi Shi and J. Ben Tamo and Hangzhou He and Xinliang Zhang and Qian Chen and May D. Wang and Lei Zhu and Yanye Lu and Qiushi Ren},
  doi          = {10.1016/j.imavis.2025.105729},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105729},
  shortjournal = {Image Vis. Comput.},
  title        = {Novel extraction of discriminative fine-grained feature to improve retinal vessel segmentation},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence content detection techniques using watermarking: A survey. <em>ICV</em>, <em>163</em>, 105728. (<a href='https://doi.org/10.1016/j.imavis.2025.105728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement in AI-generated content has catalyzed artistic creation, advertising, and media dissemination. Despite their widespread applications across several domains, AI-generated content inherently poses risks of identity fraud, copyright violation and unauthorized use. Watermarking has emerged as a critical tool for copyright protection, allowing embedding of identification information in AI-generated content, and enhances traceability and verification without hurting user experience. In this study, we provide a systematic literature review of the technique for detecting AI content, especially text and images, using watermarking, spanning studies from 2010 to 2025. Studies included in this review were peer-reviewed articles that applied watermarking to effectively distinguish AI-generated content from real or human-written content. We report strong past and current approaches to detecting watermarking-based AI content, especially text and images. This includes an analysis of how watermarking methods are used on AI-generated content, their role in enhancing performance, and a detail comparative analysis of notable techniques. Furthermore, we discuss how these methods have been evaluated, identify the research gaps and potential solutions. Our findings provide valuable insights for future watermarking-based AI content detection researchers, applications and organizations seeking to implement watermarking solutions in potential applications. To the best of our knowledge, we are the first to explore the detection of AI content, especially text and image, detection using watermarking.},
  archive      = {J_ICV},
  author       = {Nishant Kumar and Amit Kumar Singh},
  doi          = {10.1016/j.imavis.2025.105728},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105728},
  shortjournal = {Image Vis. Comput.},
  title        = {Artificial intelligence content detection techniques using watermarking: A survey},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Your image generator is your new private dataset. <em>ICV</em>, <em>163</em>, 105727. (<a href='https://doi.org/10.1016/j.imavis.2025.105727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative diffusion models have emerged as powerful tools to synthetically produce training data, offering potential solutions to data scarcity and reducing labelling costs for downstream supervised deep learning applications. However, existing approaches for synthetic dataset generation face significant limitations: previous methods like Knowledge Recycling rely on label-conditioned generation with models trained from scratch, limiting flexibility and requiring extensive computational resources, while simple class-based conditioning fails to capture the semantic diversity and intra-class variations found in real datasets. Additionally, effectively leveraging text-conditioned image generation for building classifier training sets requires addressing key issues: constructing informative textual prompts, adapting generative models to specific domains, and ensuring robust performance. This paper proposes the Text-Conditioned Knowledge Recycling (TCKR) pipeline to tackle these challenges. TCKR combines dynamic image captioning, parameter-efficient diffusion model fine-tuning, and Generative Knowledge Distillation techniques to create synthetic datasets tailored for image classification. The pipeline is rigorously evaluated on ten diverse image classification benchmarks. The results demonstrate that models trained solely on TCKR-generated data achieve classification accuracies on par with (and in several cases exceeding) models trained on real images. Furthermore, the evaluation reveals that these synthetic-data-trained models exhibit substantially enhanced privacy characteristics: their vulnerability to Membership Inference Attacks is significantly reduced, with the membership inference AUC lowered by 5.49 points on average compared to using real training data, demonstrating a substantial improvement in the performance-privacy trade-off. These findings indicate that high-fidelity synthetic data can effectively replace real data for training classifiers, yielding strong performance whilst simultaneously providing improved privacy protection as a valuable emergent property. The code and trained models are available in the accompanying open-source repository .},
  archive      = {J_ICV},
  author       = {Nicolò Francesco Resmini and Eugenio Lomurno and Cristian Sbrolli and Matteo Matteucci},
  doi          = {10.1016/j.imavis.2025.105727},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105727},
  shortjournal = {Image Vis. Comput.},
  title        = {Your image generator is your new private dataset},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the noise robustness of class activation maps: A framework for reliable model interpretability. <em>ICV</em>, <em>163</em>, 105717. (<a href='https://doi.org/10.1016/j.imavis.2025.105717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class Activation Maps (CAMs) are one of the important methods for visualizing regions used by deep learning models. Yet their robustness to different noise remains underexplored. In this work, we evaluate and report the resilience of various CAM methods for different noise perturbations across multiple architectures and datasets. By analyzing the influence of different noise types on CAM explanations, we assess the susceptibility to noise and the extent to which dataset characteristics may impact explanation stability. The findings highlight considerable variability in noise sensitivity for various CAMs. We propose a robustness metric for CAMs that captures two key properties: consistency and responsiveness. Consistency reflects the ability of CAMs to remain stable under input perturbations that do not alter the predicted class, while responsiveness measures the sensitivity of CAMs to changes in the prediction caused by such perturbations. The metric is evaluated empirically across models, different perturbations, and datasets along with complementary statistical tests to exemplify the applicability of our proposed approach.},
  archive      = {J_ICV},
  author       = {Syamantak Sarkar and Revoti P. Bora and Bhupender Kaushal and Sudhish N. George and Kiran Raja},
  doi          = {10.1016/j.imavis.2025.105717},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105717},
  shortjournal = {Image Vis. Comput.},
  title        = {Assessing the noise robustness of class activation maps: A framework for reliable model interpretability},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InceptionWTMNet: A hybrid network for alzheimer’s disease detection using wavelet transform convolution and mixed local channel attention on finely fused multimodal images. <em>ICV</em>, <em>163</em>, 105693. (<a href='https://doi.org/10.1016/j.imavis.2025.105693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion has emerged as a critical technique for the diagnosis of Alzheimer’s Disease (AD), with the aim of effectively extracting and utilising complementary information from diverse modalities. Current fusion methods frequently cause the precise alignment of source images and do not adequately address parallax issues. This oversight can result in artifacts during the fusion process when images are misaligned. In response to this challenge, we propose a refined registration fusion technique, termed MURF, which integrates multimodal image registration and fusion within a cohesive framework. The Vision Transformer (ViT) has inspired the application of large-kernel convolutions in the diagnosis of Alzheimer’s disease (AD) because of its ability to model long-range dependencies. This approach aims to expand the receptive field and enhance the performance of diagnostic models. Despite requiring a minimal number of floating-point operations (FLOPs), these deep operators encounter challenges associated with over-parameterisation because of high memory access costs, which ultimately compromises computational efficiency. By utilising wavelet transform convolutions (WTConv), we decompose large-kernel depth-wise convolutions into four parallel branches. One branch employs a wavelet-transform convolution with square kernels, while the other two branches incorporate orthogonal wavelet-transform kernels with an identity mapping. This innovative method, with a Mixed Local Channel Attention mechanism, has facilitated the development of the InceptionWTConvolutions network. This network maintains a receptive field comparable to that of large-kernel convolutions, while concurrently minimising over-parameterisation and enhancing computational efficiency. InceptionWTMNet classified AD, MCI, and NC using MRI and PET data from ADNI dataset with 98.69% accuracy, 98.65% recall, 98.70% F1-score, and 98.98% AUC. and provide Graphical abstract in correct format.},
  archive      = {J_ICV},
  author       = {Zenan Xu and Zhengyao Bai and Han Ma and Mingqiang Xu and Qiqin Huang and Tao Lin},
  doi          = {10.1016/j.imavis.2025.105693},
  journal      = {Image and Vision Computing},
  month        = {11},
  pages        = {105693},
  shortjournal = {Image Vis. Comput.},
  title        = {InceptionWTMNet: A hybrid network for alzheimer’s disease detection using wavelet transform convolution and mixed local channel attention on finely fused multimodal images},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="ijar">IJAR - 1</h2>
<ul>
<li><details>
<summary>
(2026). Choosing the center of star-shaped set-valued data compatible with measure-preserving arithmetic. <em>IJAR</em>, <em>188</em>, 109575. (<a href='https://doi.org/10.1016/j.ijar.2025.109575'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set-valued data has traditionally been represented by considering non-empty compact and convex subsets of R d with the usual Minkowski addition. An alternative and flexible setting that admits a functional representation are the star-shaped sets. A framework based on a center-radial characterization has been introduced to treat these sets from a statistical point of view. The arithmetic is defined directionally, which is more natural for representing imprecision propagation in higher dimensions. Nevertheless, the problem of determining a center for star-shaped sets coherent with the arithmetic and sound for statistical purposes has not been fully addressed yet. The aim is to advance on the directional characterization for star-shaped sets by considering a measure-preserving arithmetic together with a center selection fully compatible with this arithmetic. The practicability of the new framework will be illustrated using a classical dataset in set-valued statistics.},
  archive      = {J_IJAR},
  author       = {Gil González-Rodríguez},
  doi          = {10.1016/j.ijar.2025.109575},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109575},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Choosing the center of star-shaped set-valued data compatible with measure-preserving arithmetic},
  volume       = {188},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="ipl">IPL - 10</h2>
<ul>
<li><details>
<summary>
(2026). Tighter bounds on non-clairvoyant parallel machine scheduling with prediction to minimize makespan. <em>IPL</em>, <em>191</em>, 106598. (<a href='https://doi.org/10.1016/j.ipl.2025.106598'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the non-clairvoyant parallel machine scheduling problem with prediction, with the objective of minimizing the makespan. Improved lower bounds for the problem and competitive ratios of online algorithms with respect to the prediction error are presented for both the non-preemptive and preemptive cases on m identical machines.},
  archive      = {J_IPL},
  author       = {Tianqi Chen and Zhiyi Tan},
  doi          = {10.1016/j.ipl.2025.106598},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106598},
  shortjournal = {Inf. Process. Lett.},
  title        = {Tighter bounds on non-clairvoyant parallel machine scheduling with prediction to minimize makespan},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Note on pancake sorting. <em>IPL</em>, <em>191</em>, 106597. (<a href='https://doi.org/10.1016/j.ipl.2025.106597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present generalized approach to the proof of the lower bound for unburnt pancake sorting problem, where we search for the number f ( n ) of prefix reversals required to sort a stack (permutation) of n pancakes. For this purpose we introduce a new concept of guarded pancake blocks. Gates and Papadimitriou proved that f ( n ) ≥ 17 n / 16 for n a multiple of 16. Heydari and Sudborough improved this bound to f ( n ) ≥ 15 n / 14 for n a multiple of 14. We extend that result to f ( n ) ≥ ⌊ ( 15 n + 9 ) / 14 ⌋ for every n ≥ 6 .},
  archive      = {J_IPL},
  author       = {Marcin Peczarski},
  doi          = {10.1016/j.ipl.2025.106597},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106597},
  shortjournal = {Inf. Process. Lett.},
  title        = {Note on pancake sorting},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Logical characterization of branching bisimilarity over random processes. <em>IPL</em>, <em>191</em>, 106596. (<a href='https://doi.org/10.1016/j.ipl.2025.106596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative aspects like probabilities play an important role in concurrent processes. Providing a (modal) logic for a randomized concurrency model can augment the toolbox of analyzing probabilistic processes, and thus is a frequent topic in the field. In this paper, we are interested in logically characterizing uniformly randomized processes, whose semantical behavior is defined in a model-independent manner. Specifically, we present two modal logics for the uniformly randomized version of finite-state CCS (RCCS fs for short). Our logics extend the Hennessy-Milner logic, and one of them is equipped with the μ operator. Indeed, we prove that both logics characterize the branching bisimilarity for RCCS fs , i.e., two RCCS fs processes are branching bisimilar if and only if they are logically equivalent. To facilitate the proof, we also develop for RCCS fs an up-to proof method, which may be of independent interest.},
  archive      = {J_IPL},
  author       = {Xian Xu and Wenbo Zhang},
  doi          = {10.1016/j.ipl.2025.106596},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106596},
  shortjournal = {Inf. Process. Lett.},
  title        = {Logical characterization of branching bisimilarity over random processes},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Notes about the linear complexity of quaternary cyclotomic sequences of order four. <em>IPL</em>, <em>191</em>, 106595. (<a href='https://doi.org/10.1016/j.ipl.2025.106595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the linear complexity of quaternary cyclotomic sequences with period p , where p > 2 is a prime. Considered sequences are based on classical cyclotomic classes of order four modulo p . We show that any balanced quaternary cyclotomic sequence of order four with period p has high linear complexity over finite ring of order four. Our results generalize those obtained earlier by other authors.},
  archive      = {J_IPL},
  author       = {Vladimir Edemskiy and Zeyu Cao},
  doi          = {10.1016/j.ipl.2025.106595},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106595},
  shortjournal = {Inf. Process. Lett.},
  title        = {Notes about the linear complexity of quaternary cyclotomic sequences of order four},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Finding the cyclic covers of a string. <em>IPL</em>, <em>191</em>, 106594. (<a href='https://doi.org/10.1016/j.ipl.2025.106594'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the concept of cyclic covers, which generalizes the classical notion of covers in strings. Given any string X , a factor W of X is called a cyclic cover if each position of X belongs to an occurrence of a cyclic shift of W in X . Two cyclic covers are distinct if one is not a cyclic shift of the other. The cyclic covers problem asks for all distinct cyclic covers of an input string X . We present an algorithm that solves the cyclic covers problem in O ( n log ⁡ n ) time, where n is the length of X . It is based on finding a well-structured set of standard occurrences of a constant number of factors of a cyclic cover candidate W , computing the regions of X covered by cyclic shifts of W , extending those factors, and taking the union of the results.},
  archive      = {J_IPL},
  author       = {Roberto Grossi and Costas S. Iliopoulos and Jesper Jansson and Zara Lim and Wing-Kin Sung and Wiktor Zuba},
  doi          = {10.1016/j.ipl.2025.106594},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106594},
  shortjournal = {Inf. Process. Lett.},
  title        = {Finding the cyclic covers of a string},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rank-2 module-LIP with special matrices. <em>IPL</em>, <em>191</em>, 106593. (<a href='https://doi.org/10.1016/j.ipl.2025.106593'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lattice isomorphism problem (LIP) has been studied since 1990s. In 2023, a post-quantum signature scheme known as HAWK was submitted in the NIST standardization of additional signature scheme, which is based on the module lattice isomorphism problem (module-LIP). Module-LIP was formally defined by Mureau et al. at Eurocrypt'24 and Luo et al. reduced the problem of solving module-LIP over CM number fields to a problem of finding the special type of symplectic automorphism. In this paper, we extend this idea further by establishing a reduction of the module-LIP to a problem of finding special types of matrices.},
  archive      = {J_IPL},
  author       = {Manoj Gyawali},
  doi          = {10.1016/j.ipl.2025.106593},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106593},
  shortjournal = {Inf. Process. Lett.},
  title        = {Rank-2 module-LIP with special matrices},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Corrigendum to “On the complexity of co-secure dominating set problem” [Inf. process. lett. 185 (2024) 106463]. <em>IPL</em>, <em>191</em>, 106592. (<a href='https://doi.org/10.1016/j.ipl.2025.106592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We correct an error in Theorem 4 in our published paper Panda et al. [3] .},
  archive      = {J_IPL},
  author       = {Bhawani Sankar Panda and Soumyashree Rana and Sounaka Mishra},
  doi          = {10.1016/j.ipl.2025.106592},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106592},
  shortjournal = {Inf. Process. Lett.},
  title        = {Corrigendum to “On the complexity of co-secure dominating set problem” [Inf. process. lett. 185 (2024) 106463]},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On some families of binary codes. <em>IPL</em>, <em>191</em>, 106591. (<a href='https://doi.org/10.1016/j.ipl.2025.106591'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give further results on the weight distributions of the two families of binary codes recently constructed by simplicial complexes by (Wu, Lee, 2020), and show that the converse of the above results is also correct, that is, the binary codes with such weight distributions properties must be these two families of codes. Based on the above results, we also construct another family of binary self-orthogonal codes and present their separating properties and applications to the secret sharing scheme, cryptography and other aspects of information security.},
  archive      = {J_IPL},
  author       = {Zihui Liu},
  doi          = {10.1016/j.ipl.2025.106591},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106591},
  shortjournal = {Inf. Process. Lett.},
  title        = {On some families of binary codes},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The complexity of computing the period and the exponent of a digraph. <em>IPL</em>, <em>191</em>, 106590. (<a href='https://doi.org/10.1016/j.ipl.2025.106590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The period of a strongly connected digraph is the greatest common divisor of the lengths of all its cycles. The period of a digraph is the least common multiple of the periods of its strongly connected components. These notions play an important role in the theory of Markov chains and the analysis of powers of nonnegative matrices. While the time complexity of computing the period is well-understood, little is known about its space complexity. We show that the problem of computing the period of a digraph is NL -complete, even if all its cycles are contained in the same strongly connected component. However, if the digraph is strongly connected, we show that this problem becomes L -complete. For primitive digraphs (that is, strongly connected digraphs of period one), there always exists a number m such that there is a path of length exactly m between every two vertices. We show that computing the smallest such m , called the exponent of a digraph, is NL -complete. The exponent of a primitive digraph is a particular case of the index of convergence of a nonnegative matrix, which we also show to be computable in NL , and thus NL -complete.},
  archive      = {J_IPL},
  author       = {Stefan Kiefer and Andrew Ryzhikov},
  doi          = {10.1016/j.ipl.2025.106590},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106590},
  shortjournal = {Inf. Process. Lett.},
  title        = {The complexity of computing the period and the exponent of a digraph},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A simple supercritical tradeoff between size and height in resolution. <em>IPL</em>, <em>191</em>, 106589. (<a href='https://doi.org/10.1016/j.ipl.2025.106589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe CNFs in n variables which, over a range of parameters, have small resolution refutations but are such that any small refutation must have height larger than n (even exponential in n ), where the height of a refutation is the length of the longest path in it. This is called a supercritical tradeoff between size and height because, if we do not care about size, every CNF is refutable in height n . Our proof method uses a simple construction, based on or-ification and base d representations of integers, to reduce the number of variables. A similar result appeared in [Fleming, Pitassi and Robere, ITCS '22], for different formulas using a more complicated construction for reducing the number of variables. Small refutations of our formula are necessarily highly irregular, making it a plausible candidate to separate resolution from pool resolution, which amounts to separating CDCL with restarts from CDCL without restarts. We are not able to show this. In the other direction, we show that a simpler version of our formula, with a similar irregularity property, does have polynomial size pool resolution refutations and thus does not provide such a separation for CDCL.},
  archive      = {J_IPL},
  author       = {Sam Buss and Neil Thapen},
  doi          = {10.1016/j.ipl.2025.106589},
  journal      = {Information Processing Letters},
  month        = {1},
  pages        = {106589},
  shortjournal = {Inf. Process. Lett.},
  title        = {A simple supercritical tradeoff between size and height in resolution},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="isat">ISAT - 39</h2>
<ul>
<li><details>
<summary>
(2025). Voltage tracking and regulation of vehicle PEMFC system under low load condition based on fuzzy LQG hybrid strategy. <em>ISAT</em>, <em>165</em>, 510-523. (<a href='https://doi.org/10.1016/j.isatra.2025.06.008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In automotive fuel cell systems, high-voltage operation accelerates carbon support and platinum catalyst degradation, significantly compromising system durability. This study develops a dynamic system model with active cathode recirculation to capture the transient response of voltage, and proposes a hybrid control scheme that combines a proportional compensator with a fuzzy LQG controller to effectively enhance voltage regulation and disturbance tracking capabilities. Extensive simulation and hardware-in-the-loop (HiL) confirm the precision and rapid response of the developed controller. Compared to single LQG and fuzzy LQG controllers, the error reduction achieved is 49.3 % and 40.3 %, respectively, and the overall control benefit ratio improves by 19.2 % and 11 %. This method balances dynamic response with control efforts, effectively reducing the risk of high voltage-induced degradation under low-load conditions.},
  archive      = {J_ISAT},
  author       = {Ze Liu and Sichuan Xu and Baitao Zhang and Sida Guo},
  doi          = {10.1016/j.isatra.2025.06.008},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {510-523},
  shortjournal = {ISA Trans.},
  title        = {Voltage tracking and regulation of vehicle PEMFC system under low load condition based on fuzzy LQG hybrid strategy},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cascade alarm systems: A study on singular value analysis. <em>ISAT</em>, <em>165</em>, 497-509. (<a href='https://doi.org/10.1016/j.isatra.2025.06.023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel alarm system designed for use with both Independent and Identically Distributed (IID) and non-IID variables. The proposed algorithm, termed the Cascade Alarm System (CAS), utilizes the largest singular value of the signal as the basis for fault detection, employing k alarm subsystems. The greatest singular values extracted from the Lagged Covariance Matrix (LCM) of a sliding window constitute the output of the first alarm subsystem. The CAS offers two primary advantages. First, each subsystem independently generates its own alarm signal, resulting in a more flexible multilevel architecture. Second, the multilevel structure, founded on singular value decomposition (SVD), exhibits a filtering property that enhances its resilience to noise and inaccuracies. The maximum singular value effectively captures the essential information of the signal, ensuring that the filtering capabilities of the proposed method do not significantly compromise the performance of the alarm system or the integrity of critical signal information. The experimental results from the implementation of the proposed alarm system under various fault conditions demonstrate satisfactory performance. Additionally, the performance of the Cascade Alarm System has been compared with leading contemporary alarm system design methodologies, including median, moving average filters, delay timers, Cumulative Sum Control Chart (CUSUM), and serial method.},
  archive      = {J_ISAT},
  author       = {J. Taheri-Kalani and M. Aliyari-Shoorehdeli and Gh. Latif-Shabgahi},
  doi          = {10.1016/j.isatra.2025.06.023},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {497-509},
  shortjournal = {ISA Trans.},
  title        = {Cascade alarm systems: A study on singular value analysis},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flow pulsation compensation based composite adaptive active disturbance rejection control for electro-hydrostatic actuators. <em>ISAT</em>, <em>165</em>, 486-496. (<a href='https://doi.org/10.1016/j.isatra.2025.06.014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the residual pressure accumulated during the reciprocating movement of the plunger pump, there is a deviation between the flow pulsation and the theoretical calculation value. Current nonlinear control methods for the electro-hydrostatic actuator (EHA) often oversimplify and compensate for flow pulsation linearly, neglecting its nonlinear characteristics and deviation effects. This approach increases matching uncertainties and amplifies noise due to higher control gains, thus limiting the improvement of control performance. To address this issue, this paper proposes a composite adaptive disturbance rejection control method based on flow pulsation compensation for the EHA. This method equates the flow pulsation model of the pump to a combination of a theoretical flow pulsation control input term and a bounded disturbance term (the difference between the theoretical and actual flow pulsation), followed by the design of a composite adaptive law to handle parameter uncertainties, and the design of the expanded state observers based on position and pressure signals to estimate and compensate for the uncertainties nonlinearly. Finally, the effectiveness of the proposed method is verified by comparing with other control methods through experiments.},
  archive      = {J_ISAT},
  author       = {Yaowen Ge and Xiaowei Yang and Weilin Zhu and Wenxiang Deng and Jianyong Yao},
  doi          = {10.1016/j.isatra.2025.06.014},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {486-496},
  shortjournal = {ISA Trans.},
  title        = {Flow pulsation compensation based composite adaptive active disturbance rejection control for electro-hydrostatic actuators},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polytopic inclusion-based model predictive control for quasi-LPV systems using vertex system models and gain scheduling. <em>ISAT</em>, <em>165</em>, 474-485. (<a href='https://doi.org/10.1016/j.isatra.2025.05.051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a Model Predictive Control (MPC) strategy for a class of Quasi-Linear Parameter-Varying (quasi-LPV) systems characterized by a measurable time-varying parameter. The core of the proposed quasi-LPV-MPC controller lies in the utilization of a polytopic representation along with a gain-scheduled controller. A terminal cost that depends explicitly on the scheduling parameter is used. However, for the implementation, a complementary cost function is used to frame the optimization problem at each vertex level so that the requirement of updating the varying parameters over the prediction horizon is relaxed. Though the resulting suboptimal controller involves more computational burden, the proposed method demonstrates improvement in control performance over traditional MPC schemes. Experimental validation on a cascaded coupled tank system underscores the practical efficacy of the proposed quasi-LPV-MPC controller, while simulation studies on a twin rotor multi-input multi-output system serve as an additional demonstration example case. Comparative performance evaluations against both linear and nonlinear MPCs clearly illustrate that the quasi-LPV-MPC offers better control precision, adaptability, and the overall system responsiveness, thus positioning it as an effective solution for quasi-LPV systems.},
  archive      = {J_ISAT},
  author       = {Rangoli Singh and Sandip Ghosh and Devender Singh},
  doi          = {10.1016/j.isatra.2025.05.051},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {474-485},
  shortjournal = {ISA Trans.},
  title        = {Polytopic inclusion-based model predictive control for quasi-LPV systems using vertex system models and gain scheduling},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on the global energy optimization of multi-source and multi-actuator hydraulic systems based on dynamic programming and improved adaptive genetic algorithm. <em>ISAT</em>, <em>165</em>, 450-473. (<a href='https://doi.org/10.1016/j.isatra.2025.06.010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-source and multi-actuator hydraulic systems (MSAHSs) are widely used in high-power energy transmission and construction machinery. However, individual control of each component without considering the overall power matching leads the system to the low-efficiency zone, results in environmental pollution and huge economic loss. Therefore, it is highly desirable to find a way of obtaining energy-saving green MSAHSs. In this paper, the power consumption model of closed MSAHSs is established firstly to analyze theoretical factors affecting the component efficiency and find that the hydraulic pressure is the key factor. On this basis, a multi-algorithm integration global power matching method is then proposed, which consist of back propagation (BP) neural network, dynamic programming (DP) and improved adaptive genetic algorithm (IAGA). BP is used to construct efficiency prediction models for power elements (pumps, motors and engines) respectively, DP is used for elements’ high efficiency zone preliminary search, and IAGA is used to realize the global power matching of the multiple power units with energy conversion and transfer finally through optimal control parameters precise searching. Experiment is conducted on the closed MSAHS in a hydraulic fracturing vehicle. Results demonstrate that the MSAHS applied with multi-algorithm integration method improves the overall efficiency to a highest fuel savings of 35.5 % under normal conditions compared with local power matching control.},
  archive      = {J_ISAT},
  author       = {Yuhang Zhong and Wenting Chen and Zihao Chen and Guanyu Zhai and Chao Ai and Gexin Chen},
  doi          = {10.1016/j.isatra.2025.06.010},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {450-473},
  shortjournal = {ISA Trans.},
  title        = {Research on the global energy optimization of multi-source and multi-actuator hydraulic systems based on dynamic programming and improved adaptive genetic algorithm},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent energy adaptive control of loader shoveling system. <em>ISAT</em>, <em>165</em>, 437-449. (<a href='https://doi.org/10.1016/j.isatra.2025.06.021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loaders are often faced with various working objects during the shoveling process. The differences in working resistance and its time-varying unpredictability when shoveling different objects are the main causes of high energy consumption during the shoveling stage. In this paper, through the analysis of the shoveling process, the influence of the compacted layer on the working resistance is obtained. The constructed Discrete Element Method (DEM) simulation model is used to elucidate that the timely lifting of the boom can have a destructive effect on the compacted layer. Moreover, considering the diversity of working objects, a study was carried out on the effect of different boom lifting ranges on the destruction of the compacted layer. The loader shoveling system's intelligent Energy Adaptive Control (EAC) strategy is constructed by integrating the material recognition model based on the Back Propagation (BP) neural network algorithm. This control strategy can output the set pilot pressure according to the material type, realize the intelligent adjustment of the lifting range of the boom with the change of material type, and reduce the working resistance during the shoveling stage. The peak engine power consumed while shoveling sand, gravel, and boulders decreased by 20.6 %, 19.1 %, and 10.9 %, respectively, improving the energy utilization rate of the loader shoveling system when facing different working objects.},
  archive      = {J_ISAT},
  author       = {Bingwei Cao and Changhao Mu and Jiaqi Dong and Guangliang Tian and Yuqi Wang},
  doi          = {10.1016/j.isatra.2025.06.021},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {437-449},
  shortjournal = {ISA Trans.},
  title        = {Intelligent energy adaptive control of loader shoveling system},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis and design of oscillation frequency correction for servo resonance suppression. <em>ISAT</em>, <em>165</em>, 422-436. (<a href='https://doi.org/10.1016/j.isatra.2025.06.011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical resonance poses significant hazards to the normal operation of the servo systems. To mitigate mechanical resonance, online adaptive notch filter is extensive used, thus the precise determination of resonant frequency holds significant importance. However, in certain scenarios involving the high-bandwidth servo system, a phenomenon known as frequency shift can make the notch filter ineffective in addressing servo resonance. To solve this problem, an oscillation frequency correction scheme based on two improved sliding-mode observers (ISMOs) utilizing a dual-power approximation law is proposed. First, the oscillation frequency shift is analyzed around the system delay, which can be equivalently modeled using a Pade approximation method. Subsequently, a feedback loop featuring two adaptive feedback coefficients is designed to automatically tune the time factor. Remarkably, the scheme can dynamically correct oscillation frequency, thereby promoting resonance suppression. At the same time, ISMOs-identified mechanical parameters provide critical foundations for feedback coefficient adjustment. It is worth noting that the dual-power approximation law effectively suppresses high-frequency chatter while maintaining parameter identification accuracy. Finally, the effectiveness of the scheme is validated through simulation and experimental results.},
  archive      = {J_ISAT},
  author       = {Yanan Tang and Shaowu Lu and Puliang Yu and Bao Song},
  doi          = {10.1016/j.isatra.2025.06.011},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {422-436},
  shortjournal = {ISA Trans.},
  title        = {Analysis and design of oscillation frequency correction for servo resonance suppression},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A segmented model based internal model control scheme of electromagnetic micro-mirror systems. <em>ISAT</em>, <em>165</em>, 408-421. (<a href='https://doi.org/10.1016/j.isatra.2025.06.003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a segmented internal model control (SIMC) scheme based on the segmented combination model of the electromagnetic micro-mirror system (EMMS) is established. Notice that highly underdamped oscillation and rate-dependent hysteresis exist in the EMMS, so it is a complex nonlinear dynamic system. In order to control the deflection angle of the EMMS using the internal model control strategy, it is necessary to establish the inverse model of the EMMS. Therefore, a new model structure that is convenient for inversion is proposed in this paper to describe the characteristics of the EMMS with underdamped and rate-dependent hysteresis. In the proposed scheme, the model is a combination of a group of weighted sub-models based on the segmentation of the system's operating frequency. The weight of each segmented sub-model is not a constant but a new type of function which is also called the smoothing factor. Its function is to smooth the switching between sub-models, thereby reducing the dynamic error caused by model switching. In addition, the particle swarm optimization (PSO) algorithm is used to determine the optimal frequency segmentation points, which helps to obtain the optimal model for describing the system characteristics. Based on the proposed segmented combination model, the corresponding segmented internal model control with two-degree-of-freedom filters is proposed, and the corresponding filters in the internal model control are designed based on the small gain theorem. Finally, the proposed control strategy is applied to the control of the deflection angle of the electromagnetic micro-mirror to verify the proposed control method. Moreover, the non-smooth internal model control strategy is also used for comparison in the experiments.},
  archive      = {J_ISAT},
  author       = {Ruili Dong and Qingyuan Tan and Yonghong Tan and Xiaoli Song and Tianyu Wang},
  doi          = {10.1016/j.isatra.2025.06.003},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {408-421},
  shortjournal = {ISA Trans.},
  title        = {A segmented model based internal model control scheme of electromagnetic micro-mirror systems},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PPAC-pilot: Prescribed-performance augmented control for fixed-wing autopilots. <em>ISAT</em>, <em>165</em>, 395-407. (<a href='https://doi.org/10.1016/j.isatra.2025.06.001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a Prescribed-Performance Augmented Control (PPAC) framework designed for fixed-wing Unmanned Aerial Vehicle (UAV) autopilots. The PPAC strategy aims to enhance, rather than replace, existing PID control loops in open-source autopilots. Although traditional autopilots effectively manage routine tasks in most applications, their reliance on meticulous tuning remains a limitation. To address this, PPAC leverages historical flight data, a frequently overlooked resource, to derive dynamic linearization models and control laws without requiring explicit UAV models. The PPAC framework is then integrated with the Total Energy Control System (TECS) for practical deployment in takeoff and cruising scenarios. Comprehensive numerical simulations and Hardware-in-the-Loop (HIL) tests validate the strategy by comparing baseline autopilot performance with PPAC-augmented systems. Results confirm that PPAC ensures prescribed performance bounds for altitude tracking errors across evaluated scenarios, demonstrating its effectiveness in augmenting autopilots with minimized redesign efforts.},
  archive      = {J_ISAT},
  author       = {Qiuyang Tian and Zelin Wang and Tianjiang Hu},
  doi          = {10.1016/j.isatra.2025.06.001},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {395-407},
  shortjournal = {ISA Trans.},
  title        = {PPAC-pilot: Prescribed-performance augmented control for fixed-wing autopilots},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hysteresis observer enhanced integral terminal sliding mode control of piezoelectric platform for precision tracking applications. <em>ISAT</em>, <em>165</em>, 384-394. (<a href='https://doi.org/10.1016/j.isatra.2025.06.022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonlinearity of piezo-actuated positioning platforms significantly impacts their performance in high-precision applications. In this work a dynamic model of piezoelectric platform was developed firstly with the asymmetric Bouc-Wen model. Next, a terminal sliding mode observer with the super-twisting mechanism was designed to accurately estimate the state of the system. Then, a novel control strategy named Hysteresis Observer Enhanced Integral Terminal Sliding Mode Controller (HO-ITSMC) was proposed to achieve precise displacement tracking. Its stability is theoretically proved by the Lyapunov theorem. A key feature of this controller lies in its ability to drive the state of the system into zero in finite time, regardless of the initial state. Extensive experiments have thoroughly validated the effectiveness of the proposed control method, demonstrating its superior precision-tracking performance compared to traditional controllers.},
  archive      = {J_ISAT},
  author       = {Jie Chen and Lei Ni and Xuan Liao and Geng Wang and Lanqiang Zhang and Na Yao and Yijun Li and Sumeet S. Aphale},
  doi          = {10.1016/j.isatra.2025.06.022},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {384-394},
  shortjournal = {ISA Trans.},
  title        = {Hysteresis observer enhanced integral terminal sliding mode control of piezoelectric platform for precision tracking applications},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive robust control for ball-screw drives with flexible transmission and nonlinear friction via dynamic surface control approach. <em>ISAT</em>, <em>165</em>, 372-383. (<a href='https://doi.org/10.1016/j.isatra.2025.05.050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible deformation and nonlinear friction in ball-screw drive systems are important factors that restrict the improvement of tracking performance. In this paper, a high-performance adaptive controller is presented for ball screw drives to suppress vibration and improve tracking accuracy. A two-inertia model with torsional vibration state is established to fit the dynamics of the drive system while the continuously differentiable LuGre model characterizes the nonlinear friction disturbance. Based on the established nonlinear model, an adaptive robust controller (ARC) is designed by using the backstepping approach to overcome the parametric uncertainties and hard-to-model dynamics. The dual-observer is employed in the controller to observe and compensate for the nonlinear friction, which improves the low-velocity tracking performance of the ball-screw drives. Meanwhile, first-order filters are introduced by dynamic surface control (DSC) technique to eliminate the “complexity explosion” problem caused by the backstepping method. The controller theoretically guarantees that all signals of the closed-loop system are bounded, and the convergence of tracking error is also ensured via Lyapunov analysis. The effectiveness of the proposed controller is verified through simulation and experimental results.},
  archive      = {J_ISAT},
  author       = {Yanliang Sheng and Guofeng Wang and Fei Wang and Decai Li and Mantang Hu},
  doi          = {10.1016/j.isatra.2025.05.050},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {372-383},
  shortjournal = {ISA Trans.},
  title        = {Adaptive robust control for ball-screw drives with flexible transmission and nonlinear friction via dynamic surface control approach},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-sensing framework for weak fault detection of planetary gearbox. <em>ISAT</em>, <em>165</em>, 358-371. (<a href='https://doi.org/10.1016/j.isatra.2025.06.009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planetary gearbox fault detection has attracted wide attention due to the planetary gearbox’s key role in modern electro-mechanic equipment. However, traditional fault detection technologies still heavily rely on additional sensors. The resulting enormous cost of sensors restricts the application of those technologies. Given this situation, a self-sensing fault detection framework to explore the weak fault impulses of the planetary gearbox is presented without additional sensors. In this framework, we first capture the preliminary signals from the servo control systems. Then, the hole control model of the motor driving planetary gearbox is constructed. After this step, the feasibility of fault detection for the planetary gearbox through the motor servo control signals is investigated. With the measured servo control signals, a multi-signal assisting adaptive time synchronous averaging method is first proposed to explore fault impulses. This method first introduces a periodic enhanced Gini to select optimal parameters adaptively. Finally, experiments on a weak fault of three components in the planetary gearbox are carried out separately, certifying our framework's validation of planetary gearbox fault detection. This framework hopes to provide a novel scheme for the weak fault self-sensing of planetary gearboxes.},
  archive      = {J_ISAT},
  author       = {Dexin Chen and Ming Zhao and Shudong Ou and Sen Li and Xiaolong Han},
  doi          = {10.1016/j.isatra.2025.06.009},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {358-371},
  shortjournal = {ISA Trans.},
  title        = {A self-sensing framework for weak fault detection of planetary gearbox},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear self-triggered MPC without terminal conditions for trajectory tracking. <em>ISAT</em>, <em>165</em>, 347-357. (<a href='https://doi.org/10.1016/j.isatra.2025.06.005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a trajectory tracking problem for a class of nonlinear discrete-time systems is investigated by a model predictive control (MPC) strategy. Compared with the standard MPC strategy, the proposed MPC strategy removes terminal conditions, including terminal penalty terms and terminal state constraints. This novel design requires fewer parameters to be determined, which leads to high practicability. Moreover, to reduce the computational burden, a self-triggered mechanism is presented by using the discrepancy in the cost function between adjacent time instants. Then, an additional compensation variable is designed for the redundancy from the self-triggered mechanism. Finally, we present a mathematical proof for the recursive feasibility of the optimization problem. The effectiveness and practicality of the proposed self-triggered MPC strategy are verified through simulation examples and experimental results on a mobile vehicle experimental platform.},
  archive      = {J_ISAT},
  author       = {Hai Zhao and Hongjiu Yang and Yuanqing Xia and Jinhui Zhang},
  doi          = {10.1016/j.isatra.2025.06.005},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {347-357},
  shortjournal = {ISA Trans.},
  title        = {Nonlinear self-triggered MPC without terminal conditions for trajectory tracking},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal control of multi-bus DC microgrids based on distributed dual-projection-layer recurrent neural network considering bus voltage regulation. <em>ISAT</em>, <em>165</em>, 335-346. (<a href='https://doi.org/10.1016/j.isatra.2025.06.029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the broad application of plug-and-play loads, it brings new challenges to conventional control issues in DC microgrids. This work addresses the joint optimization of generation costs and transmission line power losses considering bus voltage regulation. Specifically, the concept of virtual load nodes is first introduced so that loads can be implemented as plug-and-play. Through Kron Reduction, bus voltage of load nodes is indirectly controlled by DG nodes. Then, a distributed dual-projection-layer recurrent neural network (DRNN) is proposed for real-time optimal control. The coupled voltage and current are simultaneously maintained within safe bounds. By using Lyapunov synthesis, the convergence of the DRNN is demonstrated. The effectiveness of the proposed methods is evaluated by simulations in terms of plug-and-play test and comparative analysis.},
  archive      = {J_ISAT},
  author       = {Yuanyuan Zhu and Fan Yang and Guoyu Lin},
  doi          = {10.1016/j.isatra.2025.06.029},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {335-346},
  shortjournal = {ISA Trans.},
  title        = {Optimal control of multi-bus DC microgrids based on distributed dual-projection-layer recurrent neural network considering bus voltage regulation},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic nonlinear system modelling and parametric oscillation response characteristics of gas turbines. <em>ISAT</em>, <em>165</em>, 320-334. (<a href='https://doi.org/10.1016/j.isatra.2025.06.028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas turbines, as highly complex thermal systems, exhibit significant nonlinearity and stochastic coupling in process control. Under closed-loop automatic speed regulation, persistent parametric oscillations may arise, posing serious threats to system reliability and safety. Aiming to reveal the stochastic response characteristics of parametric oscillations in gas turbines, this paper proposes a novel framework for analyzing the evolution law of parametric oscillation and multi-source stochastic excitations based on stochastic dynamics model, which is derived from thermodynamic equations and verified by measurement data. The internal stochastic excitation is determined by information entropy, while the form of the stochastic process of the external stochastic excitation is identified through data-driven reverse identification. The PDF evolution law of parametric oscillation is studied for different excitation forms, and the bifurcation behavior and sensitivity analysis of them are carried out. Under typical operating conditions, the synergistic effect of internal and external stochastic excitations reduces parametric oscillation amplitude by approximately 31 % compared to internal excitation alone. Moreover, the originally tri-modal distribution evolves into a unimodal pattern, revealing the transition trend of parametric oscillation behavior in gas turbines. These findings offer an effective approach to analyze parametric oscillation.},
  archive      = {J_ISAT},
  author       = {Xingyun Jia and Dengji Zhou},
  doi          = {10.1016/j.isatra.2025.06.028},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {320-334},
  shortjournal = {ISA Trans.},
  title        = {Stochastic nonlinear system modelling and parametric oscillation response characteristics of gas turbines},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy modal time-scheduled control and l2-gain analysis for switched nonlinear systems. <em>ISAT</em>, <em>165</em>, 308-319. (<a href='https://doi.org/10.1016/j.isatra.2025.06.026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the fuzzy modal time-scheduled control problem for switched nonlinear systems with L 2 -gain performance. Combined with the hybrid dwell time method, we propose a switched fuzzy modal time-scheduled control (FMTSC) strategy, and establish a criterion for H ∞ performance in systems comprising both unstable and stable subsystems. Meanwhile, we further develop a class of time-scheduled multiple discontinuous Lyapunov functions (TMDLFs) for the switched Takagi-Sugeno (T-S) fuzzy system with L 2 -gain property. Finally, comparative and practical examples are provided to demonstrate the validity of derived theoretical result.},
  archive      = {J_ISAT},
  author       = {Jinling Wang and Jun-Guo Lu and Jiarong Li and Qinghao Zhang and Cheng Hu},
  doi          = {10.1016/j.isatra.2025.06.026},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {308-319},
  shortjournal = {ISA Trans.},
  title        = {Fuzzy modal time-scheduled control and l2-gain analysis for switched nonlinear systems},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving a class of resource allocation problem under dynamic constraints: A predefined-time distributed optimization scheme. <em>ISAT</em>, <em>165</em>, 295-307. (<a href='https://doi.org/10.1016/j.isatra.2025.05.045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a predefined-time distributed optimization algorithm is designed to solve the resource allocation problem (RAP) with dynamic constraints. This algorithm updates auxiliary variables in real time through a distributed approach and allocates resources to each node based on dynamic constraints. Its advantages include ensuring all nodes quickly converge to the optimal value within a predefined time, thereby enhancing algorithm efficiency. Moreover, the auxiliary variables exchanged between nodes do not contain any real physical information, effectively preventing privacy data leakage. In addition, the convergence of the algorithm is analyzed strictly by the Lyapunov method, which ensures the accuracy of the algorithm. Finally, application examples in smart grids and multi-UAV dynamic collaboration are provided to demonstrate the effectiveness and advantages of the algorithm in different application scenarios.},
  archive      = {J_ISAT},
  author       = {Chuxiong Su and Zhongxu Chen and Zhengyuan Zhu and Hao Dai and Jing Chang},
  doi          = {10.1016/j.isatra.2025.05.045},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {295-307},
  shortjournal = {ISA Trans.},
  title        = {Solving a class of resource allocation problem under dynamic constraints: A predefined-time distributed optimization scheme},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-optimal global path planning and collision-avoidance local path planning for USVs in traffic separation scheme-implemented coastal waters. <em>ISAT</em>, <em>165</em>, 280-294. (<a href='https://doi.org/10.1016/j.isatra.2025.06.030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under multiple constraints including unmanned surface vehicle (USV) dynamics, traffic separation scheme (TSS) requirements, navigable water boundaries, and safety thresholds for collision risks, time-optimal path planning and collision-avoidance (COLAV) path planning for USVs in TSS-implemented coastal waters remain challenging. To overcome this challenge, we innovatively develop a hierarchical Gaussian-process-based nonlinear programming (GPNLP) approach for the USV time-optimal global path planning and COLAV local path planning. We model irregular static obstacles using Gaussian process regression for the first time, such that navigable waters are more sufficiently utilized for path planning. A TSS compliance assessment function is created to output violation penalties for the TSS requirements that should be satisfied as far as practicable. Accordingly, we plan the time-optimal global path and the COLAV local path hierarchically by minimizing two integral objective functions (with respect to the TSS violation penalties) subject to the multiple constraints. Simulations and simulation comparison results demonstrate that both the planned USV time-optimal global path and COLAV local path under the proposed hierarchical GPNLP approach are USV dynamics compliant and TSS compliant.},
  archive      = {J_ISAT},
  author       = {Yihan Tao and Jialu Du},
  doi          = {10.1016/j.isatra.2025.06.030},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {280-294},
  shortjournal = {ISA Trans.},
  title        = {Time-optimal global path planning and collision-avoidance local path planning for USVs in traffic separation scheme-implemented coastal waters},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time switching tracking control for unmanned helicopter with multiple constraints. <em>ISAT</em>, <em>165</em>, 268-279. (<a href='https://doi.org/10.1016/j.isatra.2025.06.017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a fixed-time switching tracking control scheme based on the fixed-time disturbance observer (FTDO) is proposed for a 6-DOF unmanned helicopter (UH) with multiple constraints and composite disturbances. The developed fixed-time controller guarantees that the system tracks the desired trajectory within a certain time, regardless of initial conditions. The multiple constraints include input saturation and time-varying output constraints. An improved fixed-time auxiliary system is applied to compensate for the effects of input saturation nonlinearity. By developing a novel switching boundary protection algorithm, a switching control scheme is further designed to solve the output constraints better. An improved FTDO is developed to estimate composite disturbances containing saturation function approximation errors and external disturbances. On this basis, a fixed-time switching back-stepping control method is employed for the position and attitude loops, which enables the UH to track the desired trajectory within the flight path constraints. The experimental results verify the effectiveness of the proposed scheme.},
  archive      = {J_ISAT},
  author       = {Haibo Wang and Shuang Shi and Ziyang Zhen and Ju Jiang},
  doi          = {10.1016/j.isatra.2025.06.017},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {268-279},
  shortjournal = {ISA Trans.},
  title        = {Fixed-time switching tracking control for unmanned helicopter with multiple constraints},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leaderless attitude synchronization control of multiple flexible spacecraft on SO(3). <em>ISAT</em>, <em>165</em>, 254-267. (<a href='https://doi.org/10.1016/j.isatra.2025.06.031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents adaptive controllers for leaderless attitude synchronization of multiple flexible spacecraft on S O ( 3 ) under communication topologies containing spanning tree(s). To provide a reference attitude for each spacecraft, distributed observers in 9-dimensional Euclidean space are proposed based on a smooth mapping from Euclidean space ℝ 3 × 3 to Lie group S O ( 3 ) . Both the scenarios with arbitrary and almost zero final angular velocities are considered. Subsequently, adaptive continuous controllers on S O ( 3 ) are presented to achieve the leaderless attitude synchronization subject to external disturbance, while guaranteeing boundedness of flexible vibration. Rigorous proofs are presented to show the convergence of the proposed control methods. The effectiveness of the proposed strategies is further demonstrated by numerical simulations.},
  archive      = {J_ISAT},
  author       = {Chenlu Feng and Weicheng Jin and Ti Chen and Lifeng Wang},
  doi          = {10.1016/j.isatra.2025.06.031},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {254-267},
  shortjournal = {ISA Trans.},
  title        = {Leaderless attitude synchronization control of multiple flexible spacecraft on SO(3)},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust predefined fixed-time formation-containment control for multiple unmanned surface vehicles with input saturation. <em>ISAT</em>, <em>165</em>, 241-253. (<a href='https://doi.org/10.1016/j.isatra.2025.06.019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The predefined fixed-time formation-containment (PFTFC) control problem for unmanned surface vehicles (USVs) under unknown disturbances and input saturation is investigated, where the leaders form a formation configuration and the followers converge to the predefined convex hull formed by the leaders within a fixed time. To address this issue, a two-layer framework is introduced, decomposing the problem into trajectory estimation and trajectory tracking components. In the first layer, a novel fixed-time trajectory estimator is proposed for the leaders and the followers to estimate the desired trajectory. In the second layer, to eliminate the effects of unknown disturbances and input saturation, a fixed-time disturbance observer and an auxiliary system are proposed. Then combining fixed-time Lyapunov stability and integral sliding mode control, fixed-time control laws are proposed for both the leaders and the followers, respectively. Finally, a numerical simulation example is presented to illustrate the effectiveness of the method introduced in this paper.},
  archive      = {J_ISAT},
  author       = {Yong Chen and Jinlong Huang and Fuxi Niu and Xunhua Dai and Haoyue Huang},
  doi          = {10.1016/j.isatra.2025.06.019},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {241-253},
  shortjournal = {ISA Trans.},
  title        = {Robust predefined fixed-time formation-containment control for multiple unmanned surface vehicles with input saturation},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constraint-following control for follow-up support systems under model deviation and time delay. <em>ISAT</em>, <em>165</em>, 232-240. (<a href='https://doi.org/10.1016/j.isatra.2025.06.015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Follow-up support technology can flexibly and effectively suppress machining chatter in thin-walled components. This paper proposes a servo collaborative constraint handling scheme that focuses on achieving coordinated control for the follow-up support system under multi-source coupled constraints and uncertainties. Firstly, a four-point constraint method is introduced, which simplifies the description of pose coordination through the introduction of auxiliary points, and constructs the coordinated relationship of the dual robots’ end-effectors under complex geometric constraints in an intuitive and analytical manner. Secondly, a robust controller based on constraint-following theory is designed, providing an effective means to parameterize the total uncertainty boundary structure caused by model deviation and time delay. Finally, the practical stability of the control algorithm is proven, and its effectiveness and strong robustness are validated through comparative simulations.},
  archive      = {J_ISAT},
  author       = {Fangfang Dong and Zhao Liu and Xiaomin Zhao and Jiang Han and Xiaoyong Huang},
  doi          = {10.1016/j.isatra.2025.06.015},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {232-240},
  shortjournal = {ISA Trans.},
  title        = {Constraint-following control for follow-up support systems under model deviation and time delay},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability analysis of delayed neural networks via novel delay-dependent LKF and integral inequality. <em>ISAT</em>, <em>165</em>, 222-231. (<a href='https://doi.org/10.1016/j.isatra.2025.06.027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current paper is concerned with the stability analysis of delayed neural networks. In the case that the delay derivative is restricted with an upper bound only, the augmented LKFs often contain high-degree terms of the time-varying delay, resulting in the non-convex derivatives of LKFs, which can be solved by introducing extra delay-multiplied state variables to transform the non-convex delay-dependent terms into convex ones. To make fuller use of the delay-multiplied state variables and the delay-derivative-dependent information, these delay-multiplied state variables are introduced into an LKF and the integral inequality through the proper augmentation in this paper. Meanwhile, some free-matrix-based zero equations are introduced into this delay-dependent inequality to provide more freedom. By applying the augmented LKF and the novel integral inequality, a delay-dependent stability criterion of delayed neural networks with less conservatism is established, whose advantages are verified by three examples.},
  archive      = {J_ISAT},
  author       = {Fei Long and Chuan-Ke Zhang and Yanjun Shen and Qicheng Mei and Qing Chen},
  doi          = {10.1016/j.isatra.2025.06.027},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {222-231},
  shortjournal = {ISA Trans.},
  title        = {Stability analysis of delayed neural networks via novel delay-dependent LKF and integral inequality},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predefined-time adaptive learning control of nonlinear strict-feedback systems via dynamic regressor extension and mixing. <em>ISAT</em>, <em>165</em>, 209-221. (<a href='https://doi.org/10.1016/j.isatra.2025.06.016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a parameter identification algorithm and a novel adaptive tracking control strategy for a specific group of nonlinear strict-feedback systems incorporating the concept of predefined time under model uncertainties. A three-layer transformation-based parameter estimation method with predefined-time convergence properties is proposed to relax the strict persistent excitation condition imposed by conventional approaches. The singular terms that may occur in traditional backstepping design procedures are avoided by using a hyperbolic tangent function to design new control laws and filters. Composite learning control approach that incorporates the algorithm for parameter identification into the framework for adaptive dynamic surface control can achieve error convergence within a practical predefined time. By using Lyapunov analysis, the semi-global uniformly predefined-time boundedness for the closed-loop dynamics is demonstrated. Numerical experiments demonstrate the viability of developed control scheme.},
  archive      = {J_ISAT},
  author       = {Zhonghua Wu and Kuncheng Ma and Junkang Ni},
  doi          = {10.1016/j.isatra.2025.06.016},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {209-221},
  shortjournal = {ISA Trans.},
  title        = {Predefined-time adaptive learning control of nonlinear strict-feedback systems via dynamic regressor extension and mixing},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive PI nonlinear cooperative control for motor cluster. <em>ISAT</em>, <em>165</em>, 191-208. (<a href='https://doi.org/10.1016/j.isatra.2025.05.047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the effects of nonlinearities and uncertainties in the speed regulation of permanent magnet synchronous motors (PMSMs), an adaptive PI nonlinear control strategy is introduced. First, a nonlinear system model is developed using the PMSM mathematical model, and an adaptive PI nonlinear control approach is designed. Numerical simulations are conducted to demonstrate that this control method effectively tracks the system’s desired values. Then, through a group of comparative simulation experiments, the comparison effect of the designed adaptive PI nonlinear control method and the traditional PI control method is analyzed and compared. Additionally, four PMSM collaborative control system models, including the speed tracking and speed synchronization control structures, are constructed. Finally, a simulation model for a cooperative PMSM control system is developed to evaluate the system’s speed tracking capability and the synchronization between multiple motors. The results show that in the designed motor cluster cooperative control system, the PMSM motor cluster using adaptive PI nonlinear control method can achieve cooperative control in speed tracking and speed synchronization, and can maintain stable operation against nonlinear problems and unknown disturbances.},
  archive      = {J_ISAT},
  author       = {Yiting Chen and Yushen Wu and Kairui Chen and Jianhui Wang and Zian Wang},
  doi          = {10.1016/j.isatra.2025.05.047},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {191-208},
  shortjournal = {ISA Trans.},
  title        = {Adaptive PI nonlinear cooperative control for motor cluster},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven parallel linear controllers for reference tracking in nonlinear systems. <em>ISAT</em>, <em>165</em>, 183-190. (<a href='https://doi.org/10.1016/j.isatra.2025.05.048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reference tracking control for nonlinear systems presents significant challenges, particularly when system models are unavailable and real-time computation is required. We present a purely data-driven approach for reference tracking control, referred to as parallel linear controllers (PLIC), which leverages an architecture composed of two linear controllers operating concurrently in distinct dimensional spaces. These controllers are employed for inverse control and mismatch error compensation, respectively. The first controller utilizes the Koopman operator for lifting the system to a high dimension and solves a quadratic program that facilitates constraint handling. The second controller, which works in the original state space, employs the direct data-driven virtual reference tuning approach with some appropriate modifications. The closed-loop properties of the proposed PLIC are analyzed, and the efficacy of the proposed method is exemplified through benchmark simulation.},
  archive      = {J_ISAT},
  author       = {Yao Shi and José M. Maestre and Lei Xie and Hongye Su},
  doi          = {10.1016/j.isatra.2025.05.048},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {183-190},
  shortjournal = {ISA Trans.},
  title        = {Data-driven parallel linear controllers for reference tracking in nonlinear systems},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time random reference tracking nonlinear model predictive control: A case study on wind turbines. <em>ISAT</em>, <em>165</em>, 170-182. (<a href='https://doi.org/10.1016/j.isatra.2025.06.018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a research effort to extend nonlinear model predictive control methods from setpoint stabilization to reference tracking has been felt increasingly. On the other hand, uncertainty in the reference signal and the requirement for its dynamic forecasting in applications such as wind turbine control motivate the need for robust tracking nonlinear model predictive control approaches more and more. Therefore, this study proposes a random reference tracking nonlinear model predictive control with dynamic forecasting of stochastic references. Convergence to a robust invariant set is guaranteed by an additional constraint limiting the previous step’s tracking stage cost function. The proposed predictive approach is implemented using a parallel Newton-type method to make it more efficient and applicable. The proposed approach for wind turbine control is designed considering the random wind speed reference. Simulations are performed for extreme and fatigue load scenarios. The results show that the proposed controller performs more robustly than the nominal nonlinear model predictive control approach, performing better in optimal power extraction and reducing aerodynamic loads.},
  archive      = {J_ISAT},
  author       = {Mohammad Soleymani and Nooshin Bigdeli and Mehdi Rahmani},
  doi          = {10.1016/j.isatra.2025.06.018},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {170-182},
  shortjournal = {ISA Trans.},
  title        = {Real-time random reference tracking nonlinear model predictive control: A case study on wind turbines},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel MPC-based cascaded control for multi-area smart grids: Tackling renewable energy and EV integration challenges. <em>ISAT</em>, <em>165</em>, 143-169. (<a href='https://doi.org/10.1016/j.isatra.2025.06.024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an advanced cascaded control scheme for load frequency regulation in multi-area power systems incorporating renewable energy sources (RES) and electric vehicles (EVs). The proposed design (Model predictive control cascaded with one plus proportional-integral control cascaded with tilt control in parallel with one plus fractional-order integral derivative controller (MPC-((1+PI)-(T+(1+I λ D μ )))) combines predictive, tilt, and fractional-order dynamics to improve adaptability and robustness under uncertainties. Controller parameters are tuned using the Lyrebird Optimization Algorithm (LOA), ensuring fast convergence and effective global search. Simulation results under varying operational conditions, including nonlinearity effects such as Generation Rate Constraints (GRC), Governor Dead Band (GDB), and Communication Time Delays (CTD), confirm the controller’s superiority. It achieves a 96.4 % ITAE reduction, 98.6 % undershoot mitigation, and a settling time of just 5.8 s outperforming existing benchmark strategies (GOA: PDf+(0.75+PI), CBOA: PI-PD, JSA: PI, and ARA: 1+PID).},
  archive      = {J_ISAT},
  author       = {Muhammad S. Tolba and Muhammad Majid Gulzar and Ali Arishi and Mohamed Soliman and Ali Faisal Murtaza},
  doi          = {10.1016/j.isatra.2025.06.024},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {143-169},
  shortjournal = {ISA Trans.},
  title        = {A novel MPC-based cascaded control for multi-area smart grids: Tackling renewable energy and EV integration challenges},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency handling by reinforcement of predictive 2DoF-MPC and state observer LADRC for smart power system. <em>ISAT</em>, <em>165</em>, 128-142. (<a href='https://doi.org/10.1016/j.isatra.2025.05.046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preservation of stability is essential for the efficient and reliable functioning of the electrical transmission system. Frequency oscillations are prevalent in interconnected power systems (IPS) and may lead to instability; therefore, it is crucial to monitor and examine them meticulously. Effective frequency management is essential for regulating frequency output in an interconnected smart power system (ISPS) that includes renewable energy sources (RESs), redox flow batteries (RFBs) and static synchronous series compensators (SSSCs). In view of the challenge presented, this research introduces an efficient control architecture that utilizes a 2 degree of freedom-based model predictive controller (2DoF-MPC) to enhance system performance. Additionally, it integrates a linear active disturbance rejection control (LADRC) to employ a state observer alongside the evolving frequency management. The convergence of the predictive and state observer frameworks results in a robust 2DoF-MPC-LADRC to manage frequency disturbances and uncertainties in the power system. The suggested technique is thoroughly validated across several parameters for ISPS, instilling confidence in its capacity to attain minimal frequency variation in multiple scenarios. The performance of the proposed controller design shows that the frequency performance in area 1 and area 2 settles in 5.085 sec and 3.965 sec, when the load changes by 3 %, and it settles in 4.655 sec and 4.050 sec, respectively, when the load changes by 5 %.},
  archive      = {J_ISAT},
  author       = {Muhammad Majid Gulzar},
  doi          = {10.1016/j.isatra.2025.05.046},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {128-142},
  shortjournal = {ISA Trans.},
  title        = {Frequency handling by reinforcement of predictive 2DoF-MPC and state observer LADRC for smart power system},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fractional-order sliding mode coordinated controller using super-twisting disturbance observer for an NSSS with predefined-time stability. <em>ISAT</em>, <em>165</em>, 111-127. (<a href='https://doi.org/10.1016/j.isatra.2025.06.032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a fractional-order sliding mode coordinated control (FOSMCC) strategy incorporating dual super-twisting disturbance observers (STDOs) to enhance the control performance, stability, and reliability of the nuclear steam supply system (NSSS) under complex, time-varying operating conditions and compound disturbances. The FOSMCC strategy synthesizes the fractional-order control and predefined-time theory with sliding mode control, augmented by the disturbance feedforward compensation loop driven by dual STDOs. Such control framework provides enhanced control performance guarantees, including fast transient response, high steady-state precision, and reinforced disturbance rejection. Furthermore, by employing Lyapunov’s direct approach, it is theoretically demonstrated that the entire NSSS, under the developed coordinated strategy, achieves superior predefined-time stability. Finally, comprehensive numerical validation and comparative studies reveal that the developed FOSMCC strategy with STDOs significantly outperforms both the latest fractional-order fixed-time sliding mode controller (FOFTSMC) and the practically adopted coordinated controller (PACC), exhibiting better transient/steady-state control response and stronger robustness against disturbances. Simulation results validate that, in the presence of compound disturbances, the proposed FOSMCC strategy reduces the integral absolute control error of nuclear power and water level by 89.37 % and 87.67 %, respectively, compared to FOFTSMC, and by 99.97 % and 99.99 %, respectively, compared to PACC.},
  archive      = {J_ISAT},
  author       = {Jiuwu Hui},
  doi          = {10.1016/j.isatra.2025.06.032},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {111-127},
  shortjournal = {ISA Trans.},
  title        = {Fractional-order sliding mode coordinated controller using super-twisting disturbance observer for an NSSS with predefined-time stability},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time observer-based saturated nonsingular terminal sliding mode controller design for an over-actuated ROV with time-varying saturation limits. <em>ISAT</em>, <em>165</em>, 98-110. (<a href='https://doi.org/10.1016/j.isatra.2025.06.025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Input saturation is critical in over-actuated systems when multiple degrees of freedom (DOF) with different levels of disturbance rejection are controlled simultaneously by a set of actuators. The current study introduces a novel saturated non-singular terminal sliding mode controller to address input saturation for an over-actuated remotely-operated vehicle (ROV). The proposed controller consists of a tuning algorithm to ensure that the control commands do not violate the time-varying saturation limits of each DOF. In addition, a fixed-time extended-state observer is designed to estimate the vehicle’s velocity along with the lumped unknown dynamics of the system. The observer is also employed as a tool to maintain the orientation of the ROV in extreme environmental conditions. The stability analysis shows that all system’s states, except for yaw angle, are globally finite-time stable and the yaw angle is globally asymptotically stable. Several sets of simulations are carried out and the results demonstrate the superiority of the proposed controller in terms of positioning accuracy, saturation compensation and transient behaviour under different environmental conditions.},
  archive      = {J_ISAT},
  author       = {Alireza Hosseinnajad and Navid Mohajer},
  doi          = {10.1016/j.isatra.2025.06.025},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {98-110},
  shortjournal = {ISA Trans.},
  title        = {Fixed-time observer-based saturated nonsingular terminal sliding mode controller design for an over-actuated ROV with time-varying saturation limits},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nonsingular fast terminal sliding mode control scheme for robust trajectory tracking of the underactuated EvoBot modular mobile robot in the vertical plane. <em>ISAT</em>, <em>165</em>, 83-97. (<a href='https://doi.org/10.1016/j.isatra.2025.06.013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust control strategy for the vertical plane motion of an underactuated EvoBot mobile robot, modeled as a serial double inverted pendulum, is presented in this study. The control objectives include controlling both the directly actuated generalized coordinates and the non-actuated generalized coordinate, which is controllable through dynamic coupling with the actuated coordinates. In this regard, the system's dynamic equations are derived using the Lagrangian approach. A new nonlinear and nonsingular sliding manifold is introduced, based on which a nonsingular fast terminal sliding mode control scheme is proposed for the trajectory tracking control of the robot. This approach addresses the challenges posed by underactuation, system nonlinearities, instability, parameter uncertainties, and external disturbances. Through Lyapunov stability analysis, it is proven that finite-time asymptotic convergence of the tracking error to zero is ensured when the uncertainty upper bound is known, and convergence to a residual set is achieved when the upper bound is unavailable. The theoretical guarantees provided by the proposed control scheme are further validated through comprehensive MATLAB simulations, where its effectiveness is demonstrated under both low- and high-frequency disturbances as well as parameter uncertainties.},
  archive      = {J_ISAT},
  author       = {H. Jokar and S. Amini Serajgah},
  doi          = {10.1016/j.isatra.2025.06.013},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {83-97},
  shortjournal = {ISA Trans.},
  title        = {A nonsingular fast terminal sliding mode control scheme for robust trajectory tracking of the underactuated EvoBot modular mobile robot in the vertical plane},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time event-triggered sliding mode control for fuzzy singular systems under cyber-attacks. <em>ISAT</em>, <em>165</em>, 72-82. (<a href='https://doi.org/10.1016/j.isatra.2025.06.012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a novel secure control scheme for a particular class of Takagi–Sugeno (TS) fuzzy singular systems susceptible to deception attacks. During these attacks, adversaries can randomly introduce erroneous data into the output and control signals. The proposed strategy addresses the impact of attacks and disturbances using an observer-based sliding mode control (SMC) approach. Moreover, an event-triggering protocol is implemented to manage network resources efficiently. Furthermore, by employing the stochastic Lyapunov theory and the finite-time analysis method, sufficient conditions are established to ensure the finite-time boundedness of the resulting closed-loop system throughout both the reaching and sliding motion phases. To mitigate the attack’s effects and improve the system’s performance, the Secretary Bird Optimization Algorithm (SBOA) with the linear matrix inequality (LMI) is explored as a new approach for designing the optimal gains of controllers and observers. Finally, a simulation study based on a disc rolling on a surface is performed to showcase the efficacy and resilience of the proposed control scheme.},
  archive      = {J_ISAT},
  author       = {Mourad Kchaou and Rabeh Abassi and Houssem Jerbi},
  doi          = {10.1016/j.isatra.2025.06.012},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {72-82},
  shortjournal = {ISA Trans.},
  title        = {Finite-time event-triggered sliding mode control for fuzzy singular systems under cyber-attacks},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory-based dynamic event-triggered secure control of active suspension systems against deception attacks. <em>ISAT</em>, <em>165</em>, 64-71. (<a href='https://doi.org/10.1016/j.isatra.2025.06.007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study deals with the issue of a memory-based dynamic event-triggered control strategy for active quarter-vehicle suspension systems (QVSSs). The main objective is to design an effective event-triggered mechanism (ETM) that ensures suspension performance while reducing network resource usage, even under deception attacks. To this end, an innovative memory-based dynamic ETM is proposed to coordinate sensor data transmission efficiently in the presence of such attacks. The proposed transmission scheme integrates historical release information, which helps suppress false triggering by utilizing averaged data. Additionally, the proposed ETM dynamically updates triggering conditions over time, facilitating dynamic scheduling of network data transmission. Sufficient conditions are derived to guarantee satisfactory performance of the QVSS under the proposed control strategy. A numerical example is provided to validate the effectiveness of the approach.},
  archive      = {J_ISAT},
  author       = {Wangrui Cheng and Tingting Yin and Zhou Gu},
  doi          = {10.1016/j.isatra.2025.06.007},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {64-71},
  shortjournal = {ISA Trans.},
  title        = {Memory-based dynamic event-triggered secure control of active suspension systems against deception attacks},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-varying formation control for heterogeneous multi-agent systems in the presence of actuator faults and deception attacks. <em>ISAT</em>, <em>165</em>, 54-63. (<a href='https://doi.org/10.1016/j.isatra.2025.06.004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the control of time-varying formations in a class of heterogeneous multi-agent systems. The key innovation lies in the simultaneous consideration of hybrid actuator faults and deception attacks. To achieve the control objective, a novel distributed double-layer control scheme, comprising a network layer and a physical layer, is proposed. In the network layer, a distributed observer with secure output feedback control is developed to mitigate severe deception attacks, ensuring that the mean square observer error remains within an acceptable range. In the physical layer, fault compensators are designed to address both additive and multiplicative faults. As a result, the followers achieve time-varying formation control, and closed-loop stability analysis is conducted using the Lyapunov method. Finally, to verify the validity of the theoretical findings, numerical simulations are subsequently conducted.},
  archive      = {J_ISAT},
  author       = {Shicheng Cao and Yanhui Yin and Wenyu Li and Zhongxin Liu and Zengqiang Chen},
  doi          = {10.1016/j.isatra.2025.06.004},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {54-63},
  shortjournal = {ISA Trans.},
  title        = {Time-varying formation control for heterogeneous multi-agent systems in the presence of actuator faults and deception attacks},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-triggered consensus of multi-agent systems with uncertain control gain via distributed fuzzy logic observer. <em>ISAT</em>, <em>165</em>, 40-53. (<a href='https://doi.org/10.1016/j.isatra.2025.06.020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An event-triggered adaptive backstepping control methodology is proposed to achieve leader-following consensus of uncertain nonlinear high-order multi-agent systems with unknown control gains. In light of the partial observability limitation, adaptive distributed observers are employed to estimate the unobservable states of the leader, whereas local state observers are utilized to reconstruct the states of the followers. By integrating fuzzy logic systems, the unknown nonlinear dynamics are modeled, guaranteeing reliable state prediction in complex and partially observable scenarios. Moreover, the novel relative threshold event-triggered scheme is designed to reduce the frequency of data interactions while ensuring that the tracking error approaches near-zero. Eventually, the effectiveness and superiority of the devised controller are clearly demonstrated through comprehensive simulation results.},
  archive      = {J_ISAT},
  author       = {Konghao Xie and Xiujuan Zhao and Shiming Chen and Zheng Zhang and Yuanshi Zheng},
  doi          = {10.1016/j.isatra.2025.06.020},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {40-53},
  shortjournal = {ISA Trans.},
  title        = {Event-triggered consensus of multi-agent systems with uncertain control gain via distributed fuzzy logic observer},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consensus seeking in large-scale multi-agent systems with homogeneous connections by incorporating two-hop neighbor states. <em>ISAT</em>, <em>165</em>, 27-39. (<a href='https://doi.org/10.1016/j.isatra.2025.06.002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of multi-agent consensus raises the importance of network topology. As the number of agents increases, multi-agent systems (MAS) in a large-scale and high-density topology demand higher resources, which consequently degrades efficiency of consensus. Existing approaches that consider only direct point-to-point neighbors may overlook potential topological information, further hindering consensus performance. To achieve fast consensus in large-scale and high-density topologies, a framework named Homogeneous Connections Based on Agents State Fusions MAS (HCASFMAS) is proposed. The framework extracts broader topology information of consensus degree by fusing states of two-hop neighbors. Leveraging homogeneous idea, agents establish homogeneous connections with neighbors that exhibit a higher consensus degree, ultimately accelerating the consensus process while preserving connectivity. First, a neighbor selection strategy based on consensus degree of agent state fusion is introduced to construct candidate neighbors, aiming to reduce redundant connections. Second, an adaptive consensus algorithm is formulated to flexibly adapt to the distribution of neighbors. Finally, a candidate constraints set is established to accelerate consensus by expanding the scope of constraints while preserving connectivity. In this study, connectivity and convergence of the system are theoretically analyzed from a geometric perspective. Simulation experiments are conducted to compare the proposed method with existing approaches under different densities and topologies. Simulation results demonstrate the superiority of this method in achieving fast convergence, particularly in large-scale and high-density scenarios.},
  archive      = {J_ISAT},
  author       = {Guangqiang Xie and Chaohao Shen and Yang Li and Yanda Feng and Fengyang Qiu},
  doi          = {10.1016/j.isatra.2025.06.002},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {27-39},
  shortjournal = {ISA Trans.},
  title        = {Consensus seeking in large-scale multi-agent systems with homogeneous connections by incorporating two-hop neighbor states},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic formation tracking and fault-tolerant control of multi-agent systems based on distance and topology reconstruction methods. <em>ISAT</em>, <em>165</em>, 15-26. (<a href='https://doi.org/10.1016/j.isatra.2025.06.006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a distributed approach for dynamic formation tracking and formation fault-tolerant control within the port-Hamiltonian energy framework for multi-agent system (MAS) affected by Coulomb friction. The coupling relationships between agents are equivalently modeled as virtual springs, which simulate the interaction forces between agents to reflect the relative positions and motion states of the agents. A distance-based distributed control scheme is designed, to ensure that the formation composed of multiple agents can continuously adjust the direction and size of the formation while achieving target tracking. Additionally, considering the possibility of communication failure due to agent motion faults, a fault-tolerant algorithm based on topological reconstruction is proposed to reconstruct the formation topology after faults. The feasibility of this control method is verified through numerical simulations.},
  archive      = {J_ISAT},
  author       = {Lu Liu and Yu Cui and Yonghua Wang and Jinglong Wen and Shuaishuai Kong and Yuhang Ma and Dan Liu and Peng Shi and Chenyang Xue},
  doi          = {10.1016/j.isatra.2025.06.006},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {15-26},
  shortjournal = {ISA Trans.},
  title        = {Dynamic formation tracking and fault-tolerant control of multi-agent systems based on distance and topology reconstruction methods},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast actuator fault-tolerant control for a class of nonlinear sampled-data systems via deterministic learning. <em>ISAT</em>, <em>165</em>, 1-14. (<a href='https://doi.org/10.1016/j.isatra.2025.05.049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the fast fault-tolerant control (FTC) problem based on deterministic learning approach (DLA) for a class of nonlinear sampled-data systems with actuator faults, which consist of two stages: incipient faults with small magnitudes and faults with larger magnitudes. First, a learning controller and a learning identifier are constructed. Based on DLA and the exponential stability of a class of linear time-varying (LTV) discrete-time systems, the control knowledge and the diagnosis knowledge of the actuator faults are obtained. Second, a set of controllers and a set of diagnosis estimators are constructed based on the learnt control and diagnosis knowledge. When an incipient actuator fault occurs, fast fault detection and isolation (FDI) can be achieved using the diagnosis estimators. Then, the pattern-based FTC scheme is implemented to improve the control performance. When the small fault grows to a larger one, the rapid FDI and FTC are implemented again, providing fast responses to the occurred larger fault. The advantages of the proposed method are that: (i) a simple adaptive learning controller with the filtering technique is designed, in which the exponential convergence of the tracking error and parameter estimation errors can be achieved simultaneously; (ii) the sensitivity to small actuator faults is enhanced, and the fast FTC to larger actuator faults is achieved by utilizing the learnt knowledge. Simulation results are also included to illustrate the effectiveness of these schemes.},
  archive      = {J_ISAT},
  author       = {Yu Zeng and Tianrui Chen and Fukai Zhang and Cong Wang},
  doi          = {10.1016/j.isatra.2025.05.049},
  journal      = {ISA Transactions},
  month        = {10},
  pages        = {1-14},
  shortjournal = {ISA Trans.},
  title        = {Fast actuator fault-tolerant control for a class of nonlinear sampled-data systems via deterministic learning},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="isci">ISCI - 35</h2>
<ul>
<li><details>
<summary>
(2026). Robust watermarking for diffusion model generated images. <em>ISCI</em>, <em>723</em>, 122686. (<a href='https://doi.org/10.1016/j.ins.2025.122686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide application of diffusion models in the field of image generation, image copyright protection and traceability have become increasingly complex and challenging. To address these problems, this paper proposes a robust watermarking method for diffusion model generated images to achieve their copyright protection and traceability. The method designs an invertible mapping module to replicate and cryptographically map the watermark information into an approximately Gaussian distributed noise, which is highly consistent with the distribution of the original generation model. The mapped watermark noise serves as the latent space vector of the generative model, preserving both image generation quality and model performance. In the watermark extraction stage, the original watermark information can be accurately recovered from the generated image through the reverse extraction and voting mechanism. Experimental results show that the proposed method demonstrates excellent performance in terms of image watermark extraction accuracy, robustness and watermark image generation quality. It can still maintain 99 % true positive rate and 97.5 % bit accuracy under various attacks, and the overall performance in the detection and traceability scenarios is significantly better than the existing baseline methods.},
  archive      = {J_ISCI},
  author       = {Ziqi Liu and Yuan Guo and Liansuo Wei},
  doi          = {10.1016/j.ins.2025.122686},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122686},
  shortjournal = {Inf. Sci.},
  title        = {Robust watermarking for diffusion model generated images},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SEAD-MGFE-net: Schrödinger equation-based adaptive dropout multi-granular feature enhancement network for conversational aspect-based sentiment quadruple analysis. <em>ISCI</em>, <em>723</em>, 122684. (<a href='https://doi.org/10.1016/j.ins.2025.122684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on enhancing the extraction of sentiment quadruples consisting of target, aspect, opinion, and sentiment from multi-turn dialogs, which remains a challenging problem in conversational sentiment analysis. Existing methods frequently encounter challenges with complex sentence structures, presence of multiple sentiment quadruples, and interference from irrelevant contextual information. These challenges often result in suboptimal performance. These limitations are addressed by introducing Schrödinger equation-based adaptive dropout multi-granular feature enhancement network (SEAD-MGFE-Net), a novel framework that synergizes multigranular feature extraction with quantum-inspired adaptive regularization. The proposed methodology incorporates a multi-layer tree structure to segment sentences into semantically coherent fragments, thereby improving the alignment between aspect and opinion terms while simultaneously mitigating noise impact. Moreover, we engineer a multi-angle dynamic adjacency learning enhancement module that adeptly captures both local and global features inherent in graph-structured representations. Additionally, we devise an adaptive dropout mechanism based on the Schrödinger equation, facilitating automatic modulation of the regularization strength throughout training. Extensive evaluations on benchmark datasets in both Chinese and English validate the state-of-the-art effectiveness of our proposed SEAD-MGFE-Net model, achieving Micro-F1 scores of 46.53 % (Chinese) and 40.97 % (English), surpassing the strongest baseline models by 2.04 % and 1.57 %, respectively. SEAD-MGFE-Net exhibits efficacy in extracting cross-utterance quadruples and managing long-range dependencies. These findings confirm the effectiveness and broad applicability of SEAD-MGFE-Net for conversational sentiment analysis.},
  archive      = {J_ISCI},
  author       = {Wei Liu and Xiaoliang Chen and Duoqian Miao and Hongyun Zhang and Xiaolin Qin and Shangyi Du and Peng Lu},
  doi          = {10.1016/j.ins.2025.122684},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122684},
  shortjournal = {Inf. Sci.},
  title        = {SEAD-MGFE-net: Schrödinger equation-based adaptive dropout multi-granular feature enhancement network for conversational aspect-based sentiment quadruple analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Byzantine-resilient federated learning with dynamic scoring matrix and variant PBFT consensus under differential privacy. <em>ISCI</em>, <em>723</em>, 122682. (<a href='https://doi.org/10.1016/j.ins.2025.122682'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing concerns regarding data privacy exacerbate the challenges associated with “data silos”. Federated learning (FL) effectively addresses these issues by facilitating distributed machine learning without necessitating direct data exchange. However, the dependence on a central server in conventional FL architectures exacerbates privacy risks and limits cross-domain data sharing. Existing blockchain-based FL frameworks often employ static consensus protocols, such as classical Practical Byzantine Fault Tolerance (PBFT), which typically rely on fixed weight aggregation strategies. While these methods simplify implementation, they fail to adaptively adjust aggregation weights according to heterogeneous privacy budgets. Attempts to implement adaptive weight aggregation often require achieving consensus for each individual weight, significantly reducing efficiency and creating scalability challenges in large-scale networks. To address these gaps, we propose DSM-PBFT, a variant PBFT consensus enhanced with dynamic scoring matrices (DSM), which enables parallelized validation of multiple models while adaptively adjusting aggregation weights based on differential privacy budgets. Our noise-aware aggregation mechanism dynamically reweights models through cross-validation of accuracy, F1 score, and loss-transformed metrics, effectively decoupling privacy guarantees from model utility degradation. Security analyses affirm the robustness of this framework against Byzantine attacks, with experimental results on MNIST, FashionMNIST and CIFAR-10 demonstrating superior model accuracy across diverse privacy budgets while effectively curbing accuracy degradation under attack scenarios.},
  archive      = {J_ISCI},
  author       = {Wentai Yang and Xian Xu and Kai Yu and Guoqiang Li},
  doi          = {10.1016/j.ins.2025.122682},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122682},
  shortjournal = {Inf. Sci.},
  title        = {Byzantine-resilient federated learning with dynamic scoring matrix and variant PBFT consensus under differential privacy},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Subsequence heterogeneity contrastive learning for time series anomaly detection. <em>ISCI</em>, <em>723</em>, 122680. (<a href='https://doi.org/10.1016/j.ins.2025.122680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection is widely applied across various real-world scenarios. Recently, contrastive learning has shown remarkable ability in learning discriminative representations for detecting anomalies. However, most existing contrastive-based methods rely on complex contrastive mechanisms and specially designed model architectures, which make it difficult to maintain efficiency and flexibility across various application scenarios. To address this limitation, we introduce Subsequence-Heterogeneity that defined as the discrepancies in variation patterns and statistical characteristics between subsequences obtained through fixed-interval sampling, which are more pronounced in anomalous sequences than in normal ones. It can serve as a natural discrimination criterion and eliminate the need for complex contrastive mechanisms and specialized model architectures. Specifically, we adopt an efficient temporal hierarchical masking strategy with linear complexity to construct two branches for learning representations at different granularities. The Subsequence-Heterogeneity Contrastive Learning (SHCL) is implemented with different neural networks and enables flexible application to anomaly detection across diverse scenarios. Experiments on eight benchmark datasets demonstrate that SHCL not only achieves state-of-the-art performance with reduced time and resource costs but also significantly improves the ability of different neural networks to distinguish normal from anomalous patterns. The source code is publicly available at https://github.com/Zhangzzbzzb/SHCL/ .},
  archive      = {J_ISCI},
  author       = {Zhibin Zhang and Xiaohong Zhang and Qiang Li and Chun Huang and Tao Yin and Meng Yan},
  doi          = {10.1016/j.ins.2025.122680},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122680},
  shortjournal = {Inf. Sci.},
  title        = {Subsequence heterogeneity contrastive learning for time series anomaly detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Escrow-free attribute based signature with constant-size for the internet of things. <em>ISCI</em>, <em>723</em>, 122679. (<a href='https://doi.org/10.1016/j.ins.2025.122679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute based signature (ABS) provides a promising solution for anonymous authentication. However, numerous prevailing ABS algorithms are ill-suited for anonymous authentication in the Internet of Things (IoT), due to problems such as key escrow, high computational overhead, inflexible access policies, and vulnerability to collusion attacks. Considering these shortcomings, we present an escrow-free attribute based signature with constant-size signature for IoT. Our proposal uses the linear secret-sharing scheme (LSSS) and the notion of certificateless cryptography to restrict the authorities of each attribute authority and the system authority. In addition, it generates a constant-size signature and achieves high verification efficiency by aggregating attribute keys. Theoretical analyses demonstrate that our proposal achieves anonymous authentication and is provably secure under the standard model. Simulation experiments show that the execution time of our algorithm is less than 50 ms to run during both the signature and verification phases, making it well-suited for applications with limited resources.},
  archive      = {J_ISCI},
  author       = {Xudong Liu and Xiaojun Tong and Yihui Wang},
  doi          = {10.1016/j.ins.2025.122679},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122679},
  shortjournal = {Inf. Sci.},
  title        = {Escrow-free attribute based signature with constant-size for the internet of things},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep dual contrastive learning for multi-view subspace clustering. <em>ISCI</em>, <em>723</em>, 122678. (<a href='https://doi.org/10.1016/j.ins.2025.122678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MVSC) aims to learn a consistent shared self-representation by utilizing the consistency and complementarity of all views, numerous MVSC algorithms have attempted to obtain the optimal representation directly from raw features. However, they might overlook the noisy or redundant information in raw feature space, resulting in learning suboptimal self-representation and poor performance. To address this limitation, an intuitive idea is introducing deep neural networks to eliminate the noise and redundancy, yielding a potential embedding space. Nevertheless, existing deep MVSC methods merely focus on either the embeddings or self-expressions to explore the complementary information, which hinders subspace learning. In this paper, we present a deep multi-view dual contrastive subspace clustering framework to exploit the complementarity to learn latent self-representations effectively. Specifically, multi-view encoders are constructed to eliminate noise and redundancy of the original features and capture low-dimensional subspace embeddings, from which the self-representations are learned. Moreover, two diverse specific fusion methods are conducted on the latent subspace embeddings and the self-expressions to learn shared self-representations, and dual contrastive constraints are proposed to fully exploit the complementarity among views. Extensive experiments are conducted to verify the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Xincan Lin and Jie Lian and Zhihao Wu and Jielong Lu and Shiping Wang},
  doi          = {10.1016/j.ins.2025.122678},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122678},
  shortjournal = {Inf. Sci.},
  title        = {Deep dual contrastive learning for multi-view subspace clustering},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Parameter-free discrete clustering via adaptive hypergraph fusion. <em>ISCI</em>, <em>723</em>, 122677. (<a href='https://doi.org/10.1016/j.ins.2025.122677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based clustering has garnered significant attention due to its outstanding performance in uncovering sample structures. However, existing graph-based methods face two major challenges: 1) In graph construction, they typically focus only on direct connections between samples or an exact high-order relationship, neglecting the impact of hidden complex relationships on clustering performance; 2) The separation of spectral analysis and category acquisition into two distinct stages often results in a loss of effectiveness. To handle these problems, we propose a parameter-free discrete clustering method, called parameter-free discrete clustering via adaptive hypergraph fusion (DCAHF). Specifically, DCAHF first produces multiple different hypergraphs, each serving as a biased approximation of the data's intrinsic manifold. These complementary approximations capture distinct local-to-global geometric patterns. Then, it introduces an adaptive fusion strategy that learns optimal weights to combine them into a single consensus hypergraph on manifold space, effectively reconstructing the real manifold structure with reduced bias and improved integrity. Finally, discrete spectral analysis is performed directly on the consensus hypergraph to generate discrete sample categories, thereby avoiding the performance loss associated with two-stage approaches. Thus, DCAHF is a high-performance, parameter-free clustering model that can flexibly adapt to various clustering tasks. Since the DCAHF model cannot be solved using gradient descent methods, we develop a coordinate descent-based optimization algorithm to efficiently solve the model. Extensive experimental results demonstrate that DCAHF significantly enhances clustering effectiveness while maintaining comparable efficiency to state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yu Zhou and Ben Yang and Xuetao Zhang and Badong Chen},
  doi          = {10.1016/j.ins.2025.122677},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122677},
  shortjournal = {Inf. Sci.},
  title        = {Parameter-free discrete clustering via adaptive hypergraph fusion},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-branch semantic alignment for few-shot image classification. <em>ISCI</em>, <em>723</em>, 122676. (<a href='https://doi.org/10.1016/j.ins.2025.122676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable progress of deep learning in computer vision has significantly stimulated research interest in few-shot image classification. This field aims to transfer knowledge from previous experiences to recognize new concepts with limited samples. However, most existing approaches primarily concentrate on aligning semantic information at high-level features, neglecting the importance of middle-level or low-level feature representations. In this paper, we propose a novel approach called Multi-Branch Semantic Alignment (MBSA) for few-shot image classification, with the objective of investigating the role of multi-level features. Instead of using standard convolutional layers, we employ diverse convolutional layers to generate enhanced representations in each branch. These representations are then utilized by a dense classifier, which is supervised by a powerful guidance mechanism to incorporate semantic information into their spatial locations. During the inference stage, the multi-branch semantic alignment is designed to align multi-level features between query images and support images. This alignment process effectively establishes semantic correspondences between representations at different levels, thereby enhancing the ability to recognize novel categories. Comprehensive experiments are conducted on various few-shot benchmarks to demonstrate the superiority of our approach compared to those of several previous approaches, and ablation studies are performed to analyze the impact of different components.},
  archive      = {J_ISCI},
  author       = {Zijun Zheng and Heng Wu and Laishui Lv and Changchun Zhang and Hongcheng Guo and Shanzhou Niu and Gaohang Yu},
  doi          = {10.1016/j.ins.2025.122676},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122676},
  shortjournal = {Inf. Sci.},
  title        = {Multi-branch semantic alignment for few-shot image classification},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Partition-based differentially private synthetic data generation. <em>ISCI</em>, <em>723</em>, 122675. (<a href='https://doi.org/10.1016/j.ins.2025.122675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private synthetic data sharing is beneficial as it better retains the distribution and nuances of the original data compared to summary statistics such as means and frequencies. Current state-of-the-art methods follow a select-measure-generate paradigm, but measuring large-domain marginals often leads to significant errors, and managing the privacy budget poses challenges. Our partition-based approach addresses these issues, effectively reducing errors and improving the quality of synthetic data, even with a limited privacy budget. Experimental results show that our method outperforms existing approaches, yielding synthetic data with enhanced quality and utility, making it a preferred option for private data sharing.},
  archive      = {J_ISCI},
  author       = {Meifan Zhang and Dihang Deng and Lihua Yin},
  doi          = {10.1016/j.ins.2025.122675},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122675},
  shortjournal = {Inf. Sci.},
  title        = {Partition-based differentially private synthetic data generation},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Transferable adversarial attacks on human pose estimation: A regularization and pruning framework. <em>ISCI</em>, <em>723</em>, 122674. (<a href='https://doi.org/10.1016/j.ins.2025.122674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Pose Estimation (HPE) is a core component in real-time decision systems, supporting critical applications such as healthcare monitoring, autonomous driving, and sports analytics. While deep learning models—particularly CNNs and Transformer-based architectures—have significantly improved HPE accuracy, they remain vulnerable to adversarial perturbations that subtly distort keypoint localization, thereby undermining system reliability. To address this challenge, we propose regularization and pruning transferable adversarial attack (RPA), a novel framework designed to enhance the transferability of adversarial samples in Transformer-based HPE models. RPA integrates two synergistic strategies: gradient regularization, which suppresses dominant feature correlations to reduce overfitting, and adaptive weight pruning, which removes redundant parameters to reduce model-specific noise. This dual mechanism enables the generation of transferable adversarial attacks that are effective across diverse model architectures. Extensive experiments on state-of-the-art HPE networks demonstrate that RPA consistently outperforms existing attack methods. In white-box settings, RPA reduces average precision (AP) by 0.05-0.30; in black-box scenarios, it yields AP drops of 0.01-0.04. These findings expose critical vulnerabilities in IoT-enabled HPE applications and establish a new benchmark for evaluating adversarial robustness in real-time perception systems.},
  archive      = {J_ISCI},
  author       = {Renguang Chen and Xuechao Yang and Xun Yi and Zhide Chen and Chen Feng and Xu Yang and Kexin Zhu and Iqbal Gondal},
  doi          = {10.1016/j.ins.2025.122674},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122674},
  shortjournal = {Inf. Sci.},
  title        = {Transferable adversarial attacks on human pose estimation: A regularization and pruning framework},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CF2M-net: Cross-feature fusion and memory-constraint network for video anomaly detection. <em>ISCI</em>, <em>723</em>, 122673. (<a href='https://doi.org/10.1016/j.ins.2025.122673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection (VAD) aims to automatically identify anomalous events in surveillance videos that are significantly different from the normal pattern. Most existing methods learn the spatial-temporal distribution of normal features and detect deviations as anomalies. Typically, they employ autoencoders to independently learn appearance and motion features, but this separate learning limits the exploitation of their interrelation in real-world scenarios. To enhance the representation of normal patterns by capturing feature interrelation, we propose a cross-feature fusion and memory-constraint network (CF 2 M-Net) for VAD. Specifically, inspired by the representational ability of cross-attention in multimodal fusion, we design a cross-attention and memory-constraint (CM) module to enrich appearance features with motion information. To prevent overfitting to anomalous events, the memory-constraint module further constrains fused features within the distribution of normal patterns. We design an attention fusion (AF) decoder to predict normal features closer to the normal distribution, enhancing their separability from anomalies. By jointly modeling appearance and motion through feature fusion and memory constraints, CF 2 M-Net provides more discriminative normal representations for anomaly detection. Experimental evaluations on three benchmark datasets show that the CF 2 M-Net performs comparably with leading approaches. Moreover, the detailed evaluations indicate the effectiveness of normal representation based appearance-motion fusion features for VAD.},
  archive      = {J_ISCI},
  author       = {Qiming Ma and Chengyou Wang and Xiao Zhou},
  doi          = {10.1016/j.ins.2025.122673},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122673},
  shortjournal = {Inf. Sci.},
  title        = {CF2M-net: Cross-feature fusion and memory-constraint network for video anomaly detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed data-driven event-triggered secure consensus control of MASs: A global preset-time performance constraint method. <em>ISCI</em>, <em>723</em>, 122672. (<a href='https://doi.org/10.1016/j.ins.2025.122672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed data-driven event-triggered secure consensus control issue for model-free multi-agent systems (MASs) under sensor faults and denial-of-service (DoS) attacks, while satisfying prescribed performance constraints. First, a global preset-time performance function (PTPF) is constructed to guarantee the global stability of model-free MASs within the preset time. The proposed PTPF ensures that the preset time remains unaffected by variations in the sampling period. Second, a proportional-integral-derivative (PID) sliding surface is designed to enhance MAS performance regulation, while a novel generalized fuzzy hyperbolic model (GFHM) is constructed to eliminate the dependency on fault information and achieve high-accuracy estimation of unknown fault signals. Third, a hybrid event-triggered mechanism integrating both dynamic and memory features is developed to optimize communication resource utilization while guaranteeing robust performance at extremes. Furthermore, an event-triggered secure control scheme leveraging the memory feature is proposed to reduce communication overhead while avoiding the dangerous open-loop scenario, where control inputs must be zeroed under DoS attacks as in the existing methods. Finally, the stability proof together with simulations confirms the feasibility of the control strategy.},
  archive      = {J_ISCI},
  author       = {Run-Ze Chen and Xiang-Gui Guo and Yuan-Xin Li},
  doi          = {10.1016/j.ins.2025.122672},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122672},
  shortjournal = {Inf. Sci.},
  title        = {Distributed data-driven event-triggered secure consensus control of MASs: A global preset-time performance constraint method},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MPCMO: An improved multi-population co-evolutionary algorithm for many-objective optimization. <em>ISCI</em>, <em>723</em>, 122671. (<a href='https://doi.org/10.1016/j.ins.2025.122671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective optimization problems (MaOPs) are widely used in scientific research and engineering practices, which mainly consider joint optimization of multiple objectives simultaneously. Despite the numerous multi-objective evolutionary algorithms proposed in recent years, they often struggle with challenges in fitness assignment arising from objective conflicts. Meanwhile, they tend to perform well in only one aspect of convergence, diversity, and computational complexity. To address these issues, this paper proposes an improved multi-population co-evolutionary algorithm for many-objective optimization (termed MPCMO), which leverages the advantages of multi-population co-evolutionary techniques. The primary objective of MPCMO is to achieve a more balanced performance across convergence, diversity, and complexity. MPCMO comprises three essential components. Initially, an adaptive evolutionary strategy is employed to dynamically allocate evolutionary opportunities to subpopulations so as to conserve computational resources and enhance convergence. Subsequently, a migration strategy is developed to ensure a more global approximation of whole Pareto front. Additionally, an archive update-truncation strategy, based on angle selection and shift-based density estimation, is adopted to enhance diversity. We conduct comprehensive comparative experiments on a variety of many-objective benchmark problems with complicated characteristics. Experimental results demonstrate that the proposed method outperforms existing state-of-the-art algorithms in terms of both diversity and convergence.},
  archive      = {J_ISCI},
  author       = {Weichao Ding and Jiahao Liu and Wenbo Dong and Fei Luo and Chunhua Gu},
  doi          = {10.1016/j.ins.2025.122671},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122671},
  shortjournal = {Inf. Sci.},
  title        = {MPCMO: An improved multi-population co-evolutionary algorithm for many-objective optimization},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforced heterogeneous graphlet design for knowledge graph representation learning. <em>ISCI</em>, <em>723</em>, 122670. (<a href='https://doi.org/10.1016/j.ins.2025.122670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are practical tools that represent and integrate plentiful structural and semantic information in mainstream industrial scenarios. Despite their potential, the heterogeneity and complexity of KGs pose a formidable obstacle, especially for graph representation learning. Most existing KG embedding models omit dynamic high-order connectivity patterns to gain insights into heterogeneous networks and heavily rely on handcrafted patterns to handle complex semantic relationships, which limits their capability to adaptively capture the nuanced and intricate relationships of KGs in different tasks. To fill this gap, we present Reinforced Heterogeneous Graphlet Design (ReHGD)—a model designed for KGs that focuses on the adaptive design of typed graphlets (heterogeneous chains and motifs) through a cooperative multi-agent reinforcement learning algorithm. This task-driven approach can learn discriminative graph representations tailored to specific downstream tasks. Specifically, ReHGD engages in the creation of typed graphlets through a two-stage process: it (1) establishes a reinforced chain design module to generate chains without predefined rules and (2) employs a buffer-aware sampling technique to derive episodic chains from prior experiences. Subsequently, motifs are deduced through the application of commute count and Hadamard product operations to the episodic chain-based subgraphs. In the final step toward learning graph representations, ReHGD undertakes chain and motif aggregations. Experimental results and analyses reveal that ReHGD outperforms strong baselines on three real-world graph data and practical tasks.},
  archive      = {J_ISCI},
  author       = {Jibing Gong and Yuting Lin and Yi Zhao and Tianyu Lin and Xiaohan Fang and Xinchao Feng and Jiquan Peng},
  doi          = {10.1016/j.ins.2025.122670},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122670},
  shortjournal = {Inf. Sci.},
  title        = {Reinforced heterogeneous graphlet design for knowledge graph representation learning},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatio-frequency texture analysis using wavelet increment entropy: Methodology and application to MRI in multiple sclerosis. <em>ISCI</em>, <em>723</em>, 122669. (<a href='https://doi.org/10.1016/j.ins.2025.122669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Texture analysis is crucial for understanding images by extracting features that define spatial patterns. Recently, bi-dimensional extensions of entropy measures have gained attention due to their simplicity and strong theoretical foundations. However, existing methods primarily operate in the spatial domain and thus overlook frequency-domain and multiscale information. To address this, we introduce bidimensional wavelet increment entropy (wavelet IncrEn 2 D ). A one-level discrete wavelet transform (DWT) with the Haar wavelet decomposes each image into approximation (low-frequency) and, for some neuroimaging data, detail (high-frequency) subbands; IncrEn 2 D is then applied both to capture global structural patterns and fine, detailed texture variations. We evaluated wavelet IncrEn 2 D on synthetic and real datasets, demonstrating its effectiveness in distinguishing between different noise types (white Gaussian, salt-and-pepper, and speckle noise). Comparisons between periodic and synthesized images revealed lower wavelet IncrEn 2 D values for periodic textures. Tests on real texture datasets highlight the method's ability to differentiate various patterns. In particular, wavelet IncrEn 2 D achieved 86.69% accuracy in distinguishing MRI images of healthy versus multiple sclerosis–affected brains. Overall, wavelet IncrEn 2 D offers a robust, frequency-aware descriptor that outperforms existing 2D entropy methods.},
  archive      = {J_ISCI},
  author       = {Muqaddas Abid and Muhammad Suzuri Hitam and Rozniza Ali and Hamed Azami and Anne Humeau-Heurtier},
  doi          = {10.1016/j.ins.2025.122669},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122669},
  shortjournal = {Inf. Sci.},
  title        = {Spatio-frequency texture analysis using wavelet increment entropy: Methodology and application to MRI in multiple sclerosis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved query specialization for transformer-based visual relationship detection. <em>ISCI</em>, <em>723</em>, 122668. (<a href='https://doi.org/10.1016/j.ins.2025.122668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Relationship Detection (VRD) has significantly advanced with Transformer-based architectures. However, we identify two fundamental drawbacks in conventional label assignment methods used for training Transformer-based VRD models, where ground-truth (GT) annotations are matched to model predictions. In conventional assignment, queries are trained to detect all relations rather than specializing in specific ones, resulting in ‘unspecialized’ queries. Also, each ground-truth (GT) annotation is assigned to only one prediction under conventional assignment, suppressing other near-correct predictions by labeling them as ‘no relation’. To address these issues, we introduce a novel method called Groupwise Query Spe ci a lization and Q uality-Aware Multi-Assignment (SpeaQ). Groupwise Query Specialization clusters queries and relations into exclusive groups, promoting specialization by assigning a set of relations only to a corresponding query group. Quality-Aware Multi-Assignment enhances training signals by allowing multiple predictions closely matching the GT to be positively assigned. Additionally, we introduce dynamic query reallocation, which transfers queries from high- to low-performing groups for balanced training. Experimental results demonstrate that SpeaQ+, combining SpeaQ with dynamic query reallocation, consistently improves performance across seven baseline models on five benchmarks without additional inference cost.},
  archive      = {J_ISCI},
  author       = {Jongha Kim and Jihwan Park and Jinyoung Park and Jinyoung Kim and Sehyung Kim and Hyunwoo J. Kim},
  doi          = {10.1016/j.ins.2025.122668},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122668},
  shortjournal = {Inf. Sci.},
  title        = {Improved query specialization for transformer-based visual relationship detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ConvDiff: Multi-scale spatio-temporal convolutional networks with latent diffusion models for dynamic system modeling. <em>ISCI</em>, <em>723</em>, 122656. (<a href='https://doi.org/10.1016/j.ins.2025.122656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modeling of spatio-temporal dynamic systems, tasks such as fluid dynamics, weather forecasting, and traffic flow prediction face highly complex spatio-temporal dependencies and nonlinear dynamics. These characteristics make it challenging for traditional physical models and data-driven methods to balance accuracy and computational efficiency. To address these challenges, we propose a multi-scale spatio-temporal convolutional network named ConvDiff, optimized specifically for dynamic system modeling tasks by integrating a latent space denoising diffusion model. ConvDiff effectively captures complex spatio-temporal features and handles uncertainties in physical systems by introducing multi-scale convolutional modules combined with a physics-guided diffusion mechanism. Specifically, our model incorporates eight temporal modules and four spatial modules, using a hierarchical convolutional and diffusion structure to capture the intricate dynamics of physical systems. The experiments involved different spatio-temporal data, such as those from TaxiBJ and the Navier-Stokes dataset. According to the findings, ConvDiff demonstrates substantial improvements in essential performance indicators. For example, in the TaxiBJ dataset, ConvDiff obtained a mean squared deviation of 0.29 and a PSNR value of 40.31, outperforming the best-performing models. Moreover, on the Navier-Stokes dataset, ConvDiff reduced the MSE by 51.15% compared to the best baseline model. These results indicate that ConvDiff effectively captures complex spatio-temporal dependencies and improves prediction accuracy, particularly in physics-driven dynamic systems. Our code is available at https://github.com/Ray-zyy/ConvDiff .},
  archive      = {J_ISCI},
  author       = {Yuyang Zhao and Yuhan Wu and Yongmei Wang},
  doi          = {10.1016/j.ins.2025.122656},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122656},
  shortjournal = {Inf. Sci.},
  title        = {ConvDiff: Multi-scale spatio-temporal convolutional networks with latent diffusion models for dynamic system modeling},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A semi-heterogeneous ensemble forecasting method for stock returns based on sentiment analysis. <em>ISCI</em>, <em>723</em>, 122655. (<a href='https://doi.org/10.1016/j.ins.2025.122655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing influence of investor sentiment on market dynamics, sentiment analysis has emerged as an effective tool for enhancing financial forecasting models. This study proposes a diversity-enhanced semi-heterogeneous ensemble forecasting framework that integrates sentiment analysis into the forecasting of stock index returns. A supervised stock market sentiment index set is constructed, in which prior knowledge regarding term importance is integrated into the data augmentation process. This enables higher weights to be assigned to sentiment-related terms with superior predictive capacity, thereby allowing the model to prioritize more informative features and enhance its forecasting performance. A series of diverse base models are generated through the integration of multiple attention-PCA techniques and forecasting algorithms based on variable perturbation strategies. These base models are subsequently combined through a suite of ensemble strategies, forming a semi-heterogeneous ensemble model for forecasting S&P 500 returns. The experiment results demonstrate that the proposed approaches significantly outperform benchmark methods, with notable improvements in both accuracy and diversity.},
  archive      = {J_ISCI},
  author       = {Xiao Zhang and Peide Liu and Jing Feng},
  doi          = {10.1016/j.ins.2025.122655},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122655},
  shortjournal = {Inf. Sci.},
  title        = {A semi-heterogeneous ensemble forecasting method for stock returns based on sentiment analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Energy-related controllability of corona product networks. <em>ISCI</em>, <em>723</em>, 122654. (<a href='https://doi.org/10.1016/j.ins.2025.122654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the energy-related controllability for a category of ‘large’ composite networks generated by ‘small’ simple factor networks with Laplacian dynamics under a leader-follower framework via corona product. Different from most existing literature on network controllability, this work characterizes the controllability of corona product networks (CPNs) from an energy point of view. This can quantify the difficulty of controlling CPNs based on controllability Gramian measures, involving average controllability and volumetric control energy, etc., where the energy is triggered by the leaders. The energy-related controllability of a CPN can be explored from the eigenvalues and eigenvectors of its factor networks. An algorithm for solving the maximum average controllability is provided, which can help one select the leaders to optimize network control and be applied in practice.},
  archive      = {J_ISCI},
  author       = {Qiang Zhang and Junjie Huang and Bo Liu and Housheng Su and Alatancang Chen},
  doi          = {10.1016/j.ins.2025.122654},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122654},
  shortjournal = {Inf. Sci.},
  title        = {Energy-related controllability of corona product networks},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SeqRFM: Fast RFM analysis in sequence data. <em>ISCI</em>, <em>723</em>, 122652. (<a href='https://doi.org/10.1016/j.ins.2025.122652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, data mining technologies have been well applied to many domains, including e-commerce. In customer relationship management (CRM), the Recency-Frequency-Monetary (RFM) analysis model is one of the most effective approaches to increase the profits of major enterprises. However, with the rapid development of e-commerce, the diversity and abundance of e-commerce data pose a challenge to mining efficiency. Moreover, in actual market transactions, the chronological order of transactions reflects customer behavior and preferences. To address these challenges, we develop an effective algorithm called SeqRFM, which combines sequential pattern mining with RFM models. SeqRFM considers each customer's R, F, and M scores to represent the significance of the customer and identifies sequences with high recency, high frequency, and high monetary value. A series of experiments demonstrates the superiority and effectiveness of the SeqRFM algorithm compared to the most advanced RFM algorithms based on sequential pattern mining. Moreover, another algorithm named MSeqRFM is developed to compress the result of SeqRFM. The experiments demonstrate the effectiveness of MSeqRFM in compressing sequences. The source code and datasets are available at GitHub https://github.com/DSI-Lab1/SeqRFM .},
  archive      = {J_ISCI},
  author       = {Yanxin Zheng and Wensheng Gan and Zefeng Chen and Pinlyu Zhou and Philippe Fournier-Viger},
  doi          = {10.1016/j.ins.2025.122652},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122652},
  shortjournal = {Inf. Sci.},
  title        = {SeqRFM: Fast RFM analysis in sequence data},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic event-triggered finite-time actor-critic-identifier-based approximate optimal control for unknown nonlinear drifted systems. <em>ISCI</em>, <em>723</em>, 122651. (<a href='https://doi.org/10.1016/j.ins.2025.122651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a finite-time dynamic event-triggered actor-critic-identifier (FT-DET-ACI) framework for the optimal control problem of nonlinear systems with uncertain drift dynamics. A theoretical foundation is established by reformulating the value function within a finite-time stable space, which facilitates system state stabilization within predetermined temporal constraints. The proposed approach derives finite-time optimal controllers through a transformed Hamilton-Jacobi-Bellman (HJB) equation. To address unknown system dynamics, an integrated actor-critic-identifier architecture is constructed to concurrently approximate the value function, synthesize the finite-time optimal controller, and identify system parameters. A dynamic event-triggering rule is designed to reduce computational and communication loads by selectively updating the control signal. Lyapunov stability analysis is provided to demonstrate the finite-time convergence properties of the closed-loop system. Numerical experiments are conducted to validate the efficacy of the proposed FT-DET-ACI methodology.},
  archive      = {J_ISCI},
  author       = {Shuangsi Xue and Junkai Tan and Zihang Guo and Qingshu Guan and Hui Cao and Badong Chen},
  doi          = {10.1016/j.ins.2025.122651},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122651},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered finite-time actor-critic-identifier-based approximate optimal control for unknown nonlinear drifted systems},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Set membership filter with nonlinear state inequality constraints. <em>ISCI</em>, <em>723</em>, 122650. (<a href='https://doi.org/10.1016/j.ins.2025.122650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set membership filter is a promising method to provide a bounding estimation containing the true state for dynamic systems with unknown but bounded noises. In this paper, we investigate the state bounding estimation problem of nonlinear dynamic systems with nonlinear state inequality constraints. Three types of ellipsoidal state bounding estimation methods are proposed by incorporating nonlinear state inequality constraints into nonlinear set membership filter. They are called model reduction method, system measurement method, and constraint dimension reduction method, respectively. We analyze the computation complexity of the three methods, which decrease in the order of model reduction method, system measurement method, and constraint dimension reduction method. Due to the nonlinearity of the dynamic systems, all the three methods are approximation algorithms and the state estimation accuracy cannot be analyzed explicitly. Consequently, a typical illustrative numerical experiment is conducted to compare the performance of the three methods. The results show that the accuracy increases in the order of the model reduction method, the constraint dimension reduction method, and the system measurement method.},
  archive      = {J_ISCI},
  author       = {Xiaowei Li and Xuqi Zhang and Zhiguo Wang and Xiaojing Shen},
  doi          = {10.1016/j.ins.2025.122650},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122650},
  shortjournal = {Inf. Sci.},
  title        = {Set membership filter with nonlinear state inequality constraints},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bi-objective optimization for electric vehicle scheduling under vehicle-to-grid integration. <em>ISCI</em>, <em>723</em>, 122649. (<a href='https://doi.org/10.1016/j.ins.2025.122649'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle-to-grid (V2G) technology leverages the distributed energy-storage potential of electric vehicles (EVs), transforming the challenges of large-scale EV integration into opportunities to enhance grid flexibility and reliability. This study investigates the optimization of EV charging-discharging schedules by exploiting V2G capabilities. First, considering the spatiotemporal distribution of EVs, a Markov chain is constructed to describe probabilistic transitions between spatiotemporal states, which is then embedded in a traffic-network-based path decision model. Second, a dynamic battery energy consumption model is established, incorporating multiple factors that influence battery performance. Using Monte Carlo simulation results, a bi-objective optimization model is formulated to schedule charging and discharging, simultaneously minimizing (i) total cost — including user recharging time and battery degradation — and (ii) grid-load fluctuation. Given the NP-hard nature of the problem, an improved multi-objective bitterling fish optimization (IMOBFO) algorithm is developed to balance global exploration and local exploitation. Empirical studies in a region of Shanghai compare three strategies: disordered charging, ordered charging, and the proposed optimized charging–discharging strategy. Experimental results confirm the feasibility of the proposed model and the effectiveness of IMOBFO. Comparative analysis with seven other algorithms further validates the superior performance and stability of IMOBFO according to multiple multi-objective evaluation metrics.},
  archive      = {J_ISCI},
  author       = {Bing Yu and Yong Liu and Liang Ma},
  doi          = {10.1016/j.ins.2025.122649},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122649},
  shortjournal = {Inf. Sci.},
  title        = {Bi-objective optimization for electric vehicle scheduling under vehicle-to-grid integration},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unified graph-based framework for visual explainability in convolutional neural networks. <em>ISCI</em>, <em>723</em>, 122648. (<a href='https://doi.org/10.1016/j.ins.2025.122648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deep learning, understanding the decision-making processes of complex models is essential for advancing interpretability and trust in artificial intelligence systems. We introduce Causal Relational Attribution Graph (C-RAG), designed to deliver comprehensive, multi-perspective explanations of convolutional neural networks (CNNs) via a graph representation. C-RAG integrates gradient-based local attribution with global feature importance by constructing a graph-based representation that captures hierarchical feature inter-dependencies. In this framework, feature clusters are represented as graph nodes, and their interactions are quantified through combined localized and global attribution metrics, ensuring interpretable insights into model behavior. We evaluate C-RAG across diverse benchmark datasets (ImageNet, CIFAR-10, MNIST) and CNN architectures (ResNet18, VGG19, DenseNet201, LeNet), demonstrating significant advancements over state-of-the-art explainability methods in faithfulness, robustness, and computational efficiency. The proposed approach facilitates accurate spatial feature localization, robust dependency mapping, and efficient explanation generation, making it a valuable tool for critical applications such as medical imaging and autonomous systems. We provide a novel graph-based explainability framework, which bridges the gap between local and global interpretability, C-RAG addresses key limitations in existing methods, establishing a robust foundation for explainable AI in computer vision.},
  archive      = {J_ISCI},
  author       = {Basim Azam and Pubudu Sanjeewani and Brijesh Verma and Ashfaqur Rahman and Lipo Wang},
  doi          = {10.1016/j.ins.2025.122648},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122648},
  shortjournal = {Inf. Sci.},
  title        = {Unified graph-based framework for visual explainability in convolutional neural networks},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting. <em>ISCI</em>, <em>723</em>, 122647. (<a href='https://doi.org/10.1016/j.ins.2025.122647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting (MTSF) has been a significant research focus across various domains. Recent studies have utilized deep neural networks to identify pattern relationships in MTSF. Despite these developments, accurately forecasting multivariate time series remains challenging due to the trend of time series and spatial-temporal heterogeneity. In this paper, we propose a unified multivariate time series forecasting framework for long-term, short-term, and spatial-temporal forecasting with attention-based spatial-temporal interactive coupled neural networks (ASTIC). Specifically, we proposed a spatial-temporal interactive couple block that contains both temporal and spatial branches to investigate the relationships between global and local patterns in temporal and spatial perspectives. In the temporal branch, we design a hybrid network module capable of enhancing representation learning using convolution and attention mechanisms, which dynamically capture the local trendiness and long-term time dependence implicit in time series. In the spatial branch, a novel dynamic graph learners are designed to learn global and local spatial patterns. Then a novel interactive coupling method is proposed to link the two branches together. ASTIC predicts time series effectively by using a multilevel structure to model the trendiness of the series and mining the spatial-temporal heterogeneity. Experimental results show that our method outperforms state-of-the-art baseline methods on nine real-world datasets.},
  archive      = {J_ISCI},
  author       = {Bingsheng Wei and Yonghua Hei and Yuan Wan},
  doi          = {10.1016/j.ins.2025.122647},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122647},
  shortjournal = {Inf. Sci.},
  title        = {Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New solutions based on the generalized eigenvalue problem for the data collaboration analysis. <em>ISCI</em>, <em>723</em>, 122642. (<a href='https://doi.org/10.1016/j.ins.2025.122642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the data collaboration (DC) analysis, a privacy-preserving method for analyzing decentralized datasets held by multiple parties. In this method, privacy-preserving intermediate representations of original datasets are collected from multiple parties and then converted into collaboration representations for collaborative data analysis. However, conventional methods for creating collaboration representations suffer from several challenges; namely, the optimization problem being considered is not well defined, and the process of solving it is very difficult to understand. We thus propose a new solution for creating high-quality collaboration representations for the DC analysis. Specifically, we formulate a revised optimization problem for creating collaboration representations and then transform this optimization problem into a generalized eigenvalue problem. We also propose a reduction of the generalized eigenvalue problem to a singular value decomposition through the QR decomposition. Computational experiments using publicly available datasets demonstrate that our method can outperform the conventional methods for the DC analysis in terms of both prediction accuracy and computational efficiency.},
  archive      = {J_ISCI},
  author       = {Yuta Kawakami and Yuichi Takano and Akira Imakura},
  doi          = {10.1016/j.ins.2025.122642},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122642},
  shortjournal = {Inf. Sci.},
  title        = {New solutions based on the generalized eigenvalue problem for the data collaboration analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable, multidimensional evaluation framework for causal discovery from observational i.i.d. data. <em>ISCI</em>, <em>723</em>, 122641. (<a href='https://doi.org/10.1016/j.ins.2025.122641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear causal discovery from observational data imposes strict identifiability assumptions on the formulation of structural equations utilized in the data-generating process. However, in real-life settings, the ground-truth mechanism responsible for cause-effect transformations is unknown. Thus, it is impossible to verify its identifiability. This is the first research to assess the performance of structure learning algorithms from seven different families in non-identifiable settings with an increasing degree of nonlinearity. The evaluation of structure learning methods under assumption violations requires a rigorous and interpretable approach that quantifies both the structural similarity of the estimation with the ground truth and the capacity of the discovered graphs to be used for causal inference. Motivated by the lack of a unified performance assessment indicator, we propose an interpretable, multidimensional evaluation framework, specifically tailored to the field of causal discovery from i.i.d. data. In particular, we introduce a six-dimensional evaluation metric, called distance to the optimal solution, which aims at providing a holistic overview of the performance of structure learning techniques. Our large-scale simulation study, which incorporates seven experimental factors, shows that hybrid Bayesian networks outperform most recently introduced continuous optimization techniques under certain conditions. Additionally, causal order-based methods yield results with comparatively high proximity to the optimal solution.},
  archive      = {J_ISCI},
  author       = {Georg Velev and Stefan Lessmann},
  doi          = {10.1016/j.ins.2025.122641},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122641},
  shortjournal = {Inf. Sci.},
  title        = {Interpretable, multidimensional evaluation framework for causal discovery from observational i.i.d. data},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantization-aware matrix factorization for low bit rate image compression. <em>ISCI</em>, <em>722</em>, 122646. (<a href='https://doi.org/10.1016/j.ins.2025.122646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lossy image compression is essential for efficient transmission and storage. Traditional compression methods mainly rely on discrete cosine transform (DCT) or singular value decomposition (SVD), both of which represent image data in continuous domains and, therefore, necessitate carefully designed quantizers. Notably, these methods consider quantization as a separate step, which prevents quantization errors from being incorporated into the compression process and degrades the reconstruction quality, particularly in SVD-based methods. To address this issue, we introduce a quantization-aware matrix factorization (QMF) to develop a novel lossy image compression method. QMF provides a low-rank representation of the image data as a product of two smaller matrices, with elements constrained to bounded integer values, thereby effectively integrating quantization with low-rank approximation. We propose an efficient, provably convergent iterative algorithm for QMF using a block coordinate descent scheme, with subproblems having closed-form solutions. Our experiments demonstrate that our method consistently outperforms JPEG at low bit rates below 0.25 bits per pixel. We also demonstrated that our method has an improved capability to preserve visual semantics compared to JPEG at low bit rates by evaluating an ImageNet pre-trained classifier on compressed images. The project is available at https://github.com/pashtari/qmf .},
  archive      = {J_ISCI},
  author       = {Pooya Ashtari and Pourya Behmandpoor and Fateme Nateghi Haredasht and Jonathan H. Chen and Panagiotis Patrinos and Sabine Van Huffel},
  doi          = {10.1016/j.ins.2025.122646},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122646},
  shortjournal = {Inf. Sci.},
  title        = {Quantization-aware matrix factorization for low bit rate image compression},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An attack detection mechanism in smart contracts based on deep learning and feature fusion. <em>ISCI</em>, <em>722</em>, 122645. (<a href='https://doi.org/10.1016/j.ins.2025.122645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of Ethereum has spurred widespread adoption of smart contracts, enabling substantial financial transactions. Once deployed on the blockchain, smart contracts are immutable, rendering them unmodifiable even if vulnerabilities are present. In recent years, numerous attacks exploiting these vulnerabilities have caused significant financial losses. Although prior research has improved vulnerability detection in source code or bytecode before deployment, identifying attacks that exploit vulnerabilities during the execution phase after deployment remains a significant challenge. These challenges arise from the limited adaptability of predefined detection rules and an overreliance on opcode sequence names, which often neglects a comprehensive analysis of opcode sequence properties. In this study, we propose an advanced multidimensional feature fusion technique designed to detect attacks during the execution phase of smart contracts. By leveraging deep learning, our approach enhances detection accuracy through a comprehensive analysis of attack behaviors across four dimensions: operation objects, action behaviors, functional categories, and gas consumption. Extensive experiments demonstrate that our method achieves a detection accuracy of 97.21% and a weighted F1-score of 97.21%, confirming its effectiveness in identifying attacks.},
  archive      = {J_ISCI},
  author       = {Peiqiang Li and Guojun Wang and Wanyi Gu and Xubin Li and Xiangyong Liu and Yuheng Zhang},
  doi          = {10.1016/j.ins.2025.122645},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122645},
  shortjournal = {Inf. Sci.},
  title        = {An attack detection mechanism in smart contracts based on deep learning and feature fusion},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mean square event-triggered formation control for multi-agent systems under stochastic switching topologies. <em>ISCI</em>, <em>722</em>, 122643. (<a href='https://doi.org/10.1016/j.ins.2025.122643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the challenging issue of privacy-preserving formation control for second-order multi-agent systems under stochastic switching topologies, mainly protecting privacy of true initial formation errors. Considering the circumstances of communication noises among agents, distributed intermittent event-triggered privacy-preserving formation algorithms including the fuzzy logic system are given. Meanwhile, a novel privacy-preserving mask function is proposed, where indistinguishable space is increased by 26.2% than ones in existing literatures. Based on stochastic stability analysis and graph theory, sufficient conditions of mean square formation with the bound error are derived. Moreover, optimal controllers for the leader are proposed within the intermittent event-triggered privacy-preserving framework. In order to deal with nonlinear and unknown function, we exploit the idea of adaptive control to parameterize partial derivative of corresponding cost function, which is another different technique rather than the adaptive dynamic programming one. Finally, two simulation examples are given to indicate feasibility of our proposed theoretical results.},
  archive      = {J_ISCI},
  author       = {Guoying Miao and Yiming Zhao and Tao Li and Jinde Cao and Hanen Karamti},
  doi          = {10.1016/j.ins.2025.122643},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122643},
  shortjournal = {Inf. Sci.},
  title        = {Mean square event-triggered formation control for multi-agent systems under stochastic switching topologies},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Particle swarm optimization with problem-aware hyperparameter design for feature selection in high dimensions. <em>ISCI</em>, <em>722</em>, 122638. (<a href='https://doi.org/10.1016/j.ins.2025.122638'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a data dimensionality reduction method commonly used to handle high-dimensional datasets. It improves classification accuracy by selecting relevant features, as well as removing irrelevant and redundant ones. However, due to the vast search space, effectively selecting features remains a challenge. Particle swarm optimization (PSO) has been successfully applied to feature selection due to its excellent global search capability and ease of implementation. Existing PSO methods typically use predefined or self-adaptive inertia weights and predefined acceleration coefficients for all datasets. The diversity across datasets means that uniform hyperparameter settings are often suboptimal. To address this, this paper introduces a novel PSO variant, termed PAPSO, which emphasizes a problem-aware hyperparameter design for improved adaptability. Specifically, PAPSO leverages each dataset's intrinsic properties via two mechanisms: an inertia weight adjustment driven by PSO's optimization process for tailored search behavior, and an initialization strategy that sets acceleration coefficients based on the dataset's specific characteristics. This data-driven approach is central to PAPSO's problem-aware' capabilities, allowing the datasets's specific properties themselves to directly guide the hyperparameter design and optimization process more effectively than predefined settings. Extensive experiments on 15 high-dimensional datasets demonstrate that PAPSO achieves a superior balance between the number of selected features and classification accuracy.},
  archive      = {J_ISCI},
  author       = {Jinrui Gao and Zhenyu Lei and Tao Zheng and Lijun Guo and Yirui Wang and Shangce Gao},
  doi          = {10.1016/j.ins.2025.122638},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122638},
  shortjournal = {Inf. Sci.},
  title        = {Particle swarm optimization with problem-aware hyperparameter design for feature selection in high dimensions},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Durrmeyer deep neural networks: Bridging deep learning and dynamic brain functional connectivity. <em>ISCI</em>, <em>722</em>, 122623. (<a href='https://doi.org/10.1016/j.ins.2025.122623'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new family of Durrmeyer Deep Neural Networks (DDNN), characterized by its deep multi-layer architecture and the integration of Gaussian-Based Density (GBD) functions as sigmoidal activation mechanisms. Unlike shallow neural network (NN) operators, which often struggle with higher-order dependencies, this deep-layered approach significantly enhances approximation accuracy and adaptability. We rigorously analyze the convergence properties of DDNN in L p spaces, demonstrating its superior stability over Bernstein-type operators. Importantly, extensive numerical experiments consistently show that DDNN achieves significantly smaller approximation errors compared to shallow-type NN operators, confirming its superior performance in function approximation. The deep structure of DDNN enables the modeling of complex, higher-order dependencies, while the GBD-based activations provide flexibility and adaptability in capturing transient neural interactions. This design enables the operator to effectively balance signal preservation and noise reduction through integral-based smoothing techniques. By bridging classical approximation theory and deep learning, this study establishes DDNN as a powerful tool for dynamic signal processing. Moreover, we apply the DDNN framework to dynamic functional connectivity (DFC) analysis, where it effectively uncovers time-varying connectivity patterns in key brain regions by circumventing the limitations of conventional moving window techniques. The results highlight DDNN's ability to preserve low-frequency components while substantially reducing high-frequency noise, providing a more accurate representation of evolving brain states. Further, in its robust application to fMRI data for Independent Component Analysis (ICA), DDNN consistently and markedly enhanced spatial sparsity: raw component sparsity values (ranging from approximately 0.16 to 0.24) are significantly improved to a much higher range (0.77 to 0.85), representing an average increase of over 0.60 across components. This substantial improvement in spatial localization, coupled with DDNN's capacity for selective temporal modulation, provides a more accurate representation of evolving brain states, advancing the methodological landscape of functional neuroimaging and signal processing.},
  archive      = {J_ISCI},
  author       = {Ugur Kadak},
  doi          = {10.1016/j.ins.2025.122623},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122623},
  shortjournal = {Inf. Sci.},
  title        = {Durrmeyer deep neural networks: Bridging deep learning and dynamic brain functional connectivity},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Minimum initial state estimation of labeled time petri nets in the presence of unobservable transitions. <em>ISCI</em>, <em>722</em>, 122618. (<a href='https://doi.org/10.1016/j.ins.2025.122618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the estimation of minimum initial states (MISs) for partially observable labeled time Petri net (LTPN) systems. Particularly, an MIS is defined by two components: a minimal initial marking possessing the minimum achievable total token count, and a set of timing constraints that explicitly define the static firing delays for every transition enabled under this initial marking. The number of logic transition sequences (LTSs) consistent with a given time-label sequence (TLS) can be infinite. To ensure tractability, we adopt the assumption that only a finite number of unobservable transition firings can occur prior to the firing of any observable transition. Within this framework, the initial step involves deriving the set of minimal initial markings. This derivation is based on LTSs that exhibit logical consistency with the provided TLS. Subsequently, we define a route-modified state class graph (R-MSCG) that is generated by firing the logic consistent LTSs attached to minimal initial markings. By utilizing the transitions-related timing constraints in R-MSCGs, a method is presented to detect whether these logic consistent LTSs are timing consistent with the given TLS. Moreover, we report an algorithm to implement the MISs estimation. Finally, a part processing unit is provided to illustrate how to apply the proposed algorithms to estimate the MIS that allows the specified task sequence to be completed with the least required resources while meeting the timing constraints on the task executions.},
  archive      = {J_ISCI},
  author       = {Liang Li and Chen Wang and Huimin Zhang and Ding Liu},
  doi          = {10.1016/j.ins.2025.122618},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122618},
  shortjournal = {Inf. Sci.},
  title        = {Minimum initial state estimation of labeled time petri nets in the presence of unobservable transitions},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Environment interval type-2 fuzzy sets. <em>ISCI</em>, <em>722</em>, 122612. (<a href='https://doi.org/10.1016/j.ins.2025.122612'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that words not only have different meanings to different people, but also have different meanings in different environments. Interval type-2 fuzzy sets can effectively model intra-personal and inter-personal uncertainties, but their membership functions cannot adjust themselves with the change of environments. In this paper, a generalized interval type-2 fuzzy set called environment interval type-2 fuzzy set (EIT2 FS) is proposed firstly, which can simultaneously model intra-personal, inter-personal and environmental uncertainties well. Next, the equality, containment, intersection, union, and complement of EIT2 FSs are given, and their relationships are strictly analyzed and proven. Then, a method to encode a word into an EIT2 FS is introduced, which is based on the data collected from a group of subjects. Finally, five-word codebook examples are provided to illustrate the EIT2 FSs of the five words using the proposed method.},
  archive      = {J_ISCI},
  author       = {Xianliang Liu and Zhihuan Hu and Weidong Zhang and Mingzhi Liu},
  doi          = {10.1016/j.ins.2025.122612},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122612},
  shortjournal = {Inf. Sci.},
  title        = {Environment interval type-2 fuzzy sets},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel framework for handling uncertainty: Intuitionistic fuzzy rough soft sets. <em>ISCI</em>, <em>722</em>, 122592. (<a href='https://doi.org/10.1016/j.ins.2025.122592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy sets extend traditional fuzzy sets by incorporating degrees of membership, non-membership, and indeterminacy, making them particularly useful in contexts where uncertainty and hesitancy are prevalent. Rough soft sets combine rough sets' approximation capabilities with soft sets' flexible, parameterized approach to managing uncertainty. This study introduces Intuitionistic Fuzzy Rough Soft (IFRS) sets, integrating these advantages to create a robust framework for handling uncertainty, vagueness, and ambiguity in complex decision-making environments. The paper meticulously defines operations, operators, and measures between IFRS sets, establishing their characteristic properties through rigorous mathematical demonstrations. An innovative algorithm is proposed to address multi-criteria decision-making problems within this framework. The algorithm's effectiveness is thoroughly evaluated through comparisons with state-of-the-art algorithms using reputable datasets in medical consultation, agricultural land evaluation, educational support, and sensitivity analysis experiments. The results demonstrate the proposed algorithm's superior performance and robustness in complex decision-making scenarios, highlighting its potential as a valuable practical tool.},
  archive      = {J_ISCI},
  author       = {Quang-Thinh Bui and Thanh Nha Nguyen and Hung Son Nguyen and Bay Vo},
  doi          = {10.1016/j.ins.2025.122592},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122592},
  shortjournal = {Inf. Sci.},
  title        = {A novel framework for handling uncertainty: Intuitionistic fuzzy rough soft sets},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jaim">JAIM - 6</h2>
<ul>
<li><details>
<summary>
(2025). A non-archimedean theory of complex spaces and the cscK problem. <em>JAIM</em>, <em>481</em>, 110543. (<a href='https://doi.org/10.1016/j.aim.2025.110543'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we develop an analogue of the Berkovich analytification for non-necessarily algebraic complex spaces. We apply this theory to generalize to arbitrary compact Kähler manifolds a result of Chi Li, [42] , proving that a stronger version of K-stability implies the existence of a unique constant scalar curvature Kähler metric.},
  archive      = {J_JAIM},
  author       = {Pietro Mesquita-Piccione},
  doi          = {10.1016/j.aim.2025.110543},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110543},
  shortjournal = {Adv. Math.},
  title        = {A non-archimedean theory of complex spaces and the cscK problem},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An almost kurepa suslin tree with strongly non-saturated square. <em>JAIM</em>, <em>481</em>, 110540. (<a href='https://doi.org/10.1016/j.aim.2025.110540'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For uncountable downwards closed subtrees U and W of an ω 1 -tree T , we say that U and W are strongly almost disjoint if their intersection is a finite union of countable chains. The tree T is strongly non-saturated if there exists a strongly almost disjoint family of ω 2 -many uncountable downwards closed subtrees of T . In this article we construct a Knaster forcing which adds a Suslin tree together with a family of ω 2 -many strongly almost disjoint automorphisms of it (and thus the square of the Suslin tree is strongly non-saturated). To achieve this goal, we introduce a new idea called ρ-separation , which is an adaptation to the finite context of the notion of separation which was recently introduced by Stejskalová and the first author for the purpose of adding automorphisms of a tree with a forcing with countable conditions.},
  archive      = {J_JAIM},
  author       = {John Krueger and Eduardo Martinez Mendoza},
  doi          = {10.1016/j.aim.2025.110540},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110540},
  shortjournal = {Adv. Math.},
  title        = {An almost kurepa suslin tree with strongly non-saturated square},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sharp localized weighted inequality related to gagliardo and sobolev seminorms and its applications. <em>JAIM</em>, <em>481</em>, 110537. (<a href='https://doi.org/10.1016/j.aim.2025.110537'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we establish a nearly sharp localized weighted inequality related to Gagliardo and Sobolev seminorms, respectively, with the sharp A 1 -weight constant or with the specific A p -weight constant when p ∈ ( 1 , ∞ ) . As applications, we further obtain a new characterization of Muckenhoupt weights and, in the framework of ball Banach function spaces, an inequality related to Gagliardo and Sobolev seminorms on cubes, a Gagliardo–Nirenberg interpolation inequality, and a Bourgain–Brezis–Mironescu formula. All these obtained results have wide generality and are proved to be (nearly) sharp.},
  archive      = {J_JAIM},
  author       = {Pingxu Hu and Yinqin Li and Dachun Yang and Wen Yuan},
  doi          = {10.1016/j.aim.2025.110537},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110537},
  shortjournal = {Adv. Math.},
  title        = {A sharp localized weighted inequality related to gagliardo and sobolev seminorms and its applications},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). K-moduli spaces of log del pezzo pairs. <em>JAIM</em>, <em>481</em>, 110536. (<a href='https://doi.org/10.1016/j.aim.2025.110536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish the full explicit wall-crossings for K-moduli space P ‾ K ( c ) of degree 8 del Pezzo pairs ( X , c C ) , where generically X ≅ F 1 and C ∼ − 2 K X . We also show that the K-moduli spaces P ‾ K ( c ) coincide with the Hassett-Keel-Looijenga (HKL) models F ( s ) of an 18-dimensional locally symmetric space associated with the lattice E 8 ⊕ U 2 ⊕ E 7 ⊕ A 1 under the transformation s ( c ) = 1 − 2 c 56 c − 4 . This implies that the K-moduli spaces interpolate the GIT partial compactification and the Baily-Borel compactification for the moduli space of smooth Del Pezzo pairs. Some discussions concerning the relationship to KSBA moduli spaces are also provided.},
  archive      = {J_JAIM},
  author       = {Long Pan and Fei Si and Haoyu Wu},
  doi          = {10.1016/j.aim.2025.110536},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110536},
  shortjournal = {Adv. Math.},
  title        = {K-moduli spaces of log del pezzo pairs},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrality of mirror maps and arithmetic homological mirror symmetry for Greene–Plesser mirrors. <em>JAIM</em>, <em>481</em>, 110535. (<a href='https://doi.org/10.1016/j.aim.2025.110535'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove the ‘integrality of Taylor coefficients of mirror maps’ conjecture for Greene–Plesser mirror pairs as a natural byproduct of an arithmetic refinement of homological mirror symmetry. We also prove homological mirror symmetry for Greene–Plesser mirror pairs in all characteristics such that the B-side family has good reduction, generalizing work of the fifth author and Smith over the complex numbers. A key technical ingredient is a new versality argument which allows us to work throughout over a Novikov-type ring with integer coefficients.},
  archive      = {J_JAIM},
  author       = {Sheel Ganatra and Andrew Hanlon and Jeff Hicks and Daniel Pomerleano and Nick Sheridan},
  doi          = {10.1016/j.aim.2025.110535},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110535},
  shortjournal = {Adv. Math.},
  title        = {Integrality of mirror maps and arithmetic homological mirror symmetry for Greene–Plesser mirrors},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intermediate subalgebras of cartan embeddings in rings and c*-algebras. <em>JAIM</em>, <em>481</em>, 110534. (<a href='https://doi.org/10.1016/j.aim.2025.110534'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let D ⊆ A be a quasi-Cartan pair of algebras. Then there exists a unique discrete groupoid twist Σ → G whose twisted Steinberg algebra is isomorphic to A in a way that preserves D . In this paper, we show there is a lattice isomorphism between wide open subgroupoids of G and subalgebras C such that D ⊆ C ⊆ A and D ⊆ C is a quasi-Cartan pair. We also characterize which algebraic diagonal/algebraic Cartan/quasi-Cartan pairs have the property that every subalgebra C with D ⊆ C ⊆ A has D ⊆ C a diagonal/Cartan/quasi-Cartan pair. In the diagonal case, when the coefficient ring is a field, it is all of them. Beyond that, only pairs that are close to being diagonal have this property. We then apply our techniques to C*-algebraic inclusions and give a complete characterization of which Cartan pairs D ⊆ A have the property that every C*-subalgebra C with D ⊆ C ⊆ A has D ⊆ C a Cartan pair.},
  archive      = {J_JAIM},
  author       = {Jonathan H. Brown and Lisa Orloff Clark and Adam H. Fuller},
  doi          = {10.1016/j.aim.2025.110534},
  journal      = {Advances in Mathematics},
  month        = {12},
  pages        = {110534},
  shortjournal = {Adv. Math.},
  title        = {Intermediate subalgebras of cartan embeddings in rings and c*-algebras},
  volume       = {481},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jat">JAT - 2</h2>
<ul>
<li><details>
<summary>
(2026). Asymptotics of the humbert functions Ψ1 and Ψ2. <em>JAT</em>, <em>314</em>, 106233. (<a href='https://doi.org/10.1016/j.jat.2025.106233'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A compilation of new results on the asymptotic behaviour of the Humbert functions Ψ 1 and Ψ 2 , and also on the Appell function F 2 , is presented. As a by-product, we confirm a conjectured limit which appeared recently in the study of the 1 D Glauber–Ising model. We also propose two elementary asymptotic methods and confirm through some illustrative examples that both methods have great potential and can be applied to a large class of problems of asymptotic analysis. Finally, some directions of future research are pointed out in order to suggest ideas for further study.},
  archive      = {J_JAT},
  author       = {Peng-Cheng Hang and Malte Henkel and Min-Jie Luo},
  doi          = {10.1016/j.jat.2025.106233},
  journal      = {Journal of Approximation Theory},
  month        = {3},
  pages        = {106233},
  shortjournal = {J. Approx. Theory},
  title        = {Asymptotics of the humbert functions Ψ1 and Ψ2},
  volume       = {314},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nevai’s condition for measures with unbounded supports. <em>JAT</em>, <em>314</em>, 106232. (<a href='https://doi.org/10.1016/j.jat.2025.106232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study Nevai’s condition from the theory of orthogonal polynomials on the real line. We prove that a large class of measures with unbounded Jacobi parameters satisfies Nevai’s condition locally uniformly on the support of the measure away from a finite explicit set. This allows us to give applications to relative uniform and weak asymptotics of Christoffel–Darboux kernels on the diagonal and to limit theorems for unconventionally normalized global linear statistics of orthogonal polynomial ensembles.},
  archive      = {J_JAT},
  author       = {Grzegorz Świderski},
  doi          = {10.1016/j.jat.2025.106232},
  journal      = {Journal of Approximation Theory},
  month        = {3},
  pages        = {106232},
  shortjournal = {J. Approx. Theory},
  title        = {Nevai’s condition for measures with unbounded supports},
  volume       = {314},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jde">JDE - 47</h2>
<ul>
<li><details>
<summary>
(2026). Fine boundary regularity for fully nonlinear mixed local-nonlocal problems. <em>JDE</em>, <em>452</em>, 113780. (<a href='https://doi.org/10.1016/j.jde.2025.113780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider Dirichlet problems for fully nonlinear mixed local-nonlocal non-translation invariant operators. For a bounded C 2 domain Ω ⊂ R d , let u ∈ C ( R d ) be a viscosity solution of such Dirichlet problem. We obtain global Lipschitz regularity and fine boundary regularity for u by constructing appropriate sub and supersolutions coupled with a Harnack type inequality. We apply these results to obtain Hölder regularity of Du up to the boundary.},
  archive      = {J_JDE},
  author       = {Mitesh Modasiya and Abhrojyoti Sen},
  doi          = {10.1016/j.jde.2025.113780},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113780},
  shortjournal = {J. Diff. Equ.},
  title        = {Fine boundary regularity for fully nonlinear mixed local-nonlocal problems},
  volume       = {452},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weak and mild solutions to the MHD equations and the viscoelastic Navier–Stokes equations with damping in wiener amalgam spaces. <em>JDE</em>, <em>452</em>, 113777. (<a href='https://doi.org/10.1016/j.jde.2025.113777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the three-dimensional incompressible magnetohydrodynamic (MHD) equations and the incompressible viscoelastic Navier–Stokes equations with damping. Building on techniques developed by Bradshaw, et al. (2024) [1] , we prove the existence of mild solutions in Wiener amalgam spaces that satisfy the corresponding spacetime integral bounds. In addition, we construct global-in-time local energy weak solutions in these amalgam spaces using the framework introduced by Bradshaw and Tsai (2021) [4] . As part of this construction, we also establish several properties of local energy solutions with L uloc 2 initial data, including initial and eventual regularity as well as small-large uniqueness, extending analogous results obtained for the Navier–Stokes equations by Bradshaw and Tsai (2020) [3] .},
  archive      = {J_JDE},
  author       = {Chen-Chih Lai},
  doi          = {10.1016/j.jde.2025.113777},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113777},
  shortjournal = {J. Diff. Equ.},
  title        = {Weak and mild solutions to the MHD equations and the viscoelastic Navier–Stokes equations with damping in wiener amalgam spaces},
  volume       = {452},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Positive periodic solutions to the planar lp dual minkowski problem in the critical case. <em>JDE</em>, <em>452</em>, 113776. (<a href='https://doi.org/10.1016/j.jde.2025.113776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the planar L p dual Minkowski problem x ″ + x = x p − 1 ( x 2 + x ′ 2 ) 2 − q 2 f ( t ) , where p and q are two constants, f ∈ L 1 ( R / T Z ; R + ) , and T > 0 . Notice that in the critical case T = π , the L p dual Minkowski problem is closely related to the half-period symmetry problem in convex geometry. By using Krasnosel'skii-Guo fixed point theorem and Schauder's fixed point theorem, we derive sufficient conditions for the existence of positive π -periodic solutions to this equation. In addition, we employ numerical bifurcation analysis to explore the dynamical behavior of positive π -periodic solutions.},
  archive      = {J_JDE},
  author       = {Zhibo Cheng and Shujing Yuan and Qigang Yuan and Jingli Ren},
  doi          = {10.1016/j.jde.2025.113776},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113776},
  shortjournal = {J. Diff. Equ.},
  title        = {Positive periodic solutions to the planar lp dual minkowski problem in the critical case},
  volume       = {452},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discrete lyapunov functional for cyclic systems of differential equations with time-variable or state-dependent delay. <em>JDE</em>, <em>452</em>, 113768. (<a href='https://doi.org/10.1016/j.jde.2025.113768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider nonautonomous cyclic systems of delay differential equations with variable delay. Under suitable feedback assumptions, we define an integer-valued Lyapunov functional related to the number of sign changes of the coordinate functions of solutions. We prove that this functional possesses properties analogous to those established by Mallet-Paret and Sell for the constant delay case and by Krisztin and Arino for the scalar case. We also apply the results to equations with state-dependent delays.},
  archive      = {J_JDE},
  author       = {István Balázs and Ábel Garab},
  doi          = {10.1016/j.jde.2025.113768},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113768},
  shortjournal = {J. Diff. Equ.},
  title        = {Discrete lyapunov functional for cyclic systems of differential equations with time-variable or state-dependent delay},
  volume       = {452},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Thermo-elasticity problems with evolving microstructures. <em>JDE</em>, <em>452</em>, 113764. (<a href='https://doi.org/10.1016/j.jde.2025.113764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the mathematical analysis and homogenization of a moving boundary problem posed for a highly heterogeneous, periodically perforated domain. More specifically, we are looking at a one-phase thermo-elasticity system with phase transformations where small inclusions, initially periodically distributed, are growing or shrinking based on a kinetic under-cooling-type law and where surface stresses are created based on the curvature of the phase interface. This growth is assumed to be uniform in each individual cell of the perforated domain. After transforming to the initial reference configuration (utilizing the Hanzawa transformation), we use the contraction mapping principle to show the existence of a unique solution for a possibly small but ε independent time interval ( ε is here the scale of heterogeneity). In the homogenization limit, we recover a macroscopic thermo-elasticity problem which is strongly non-linearly coupled (via an internal parameter called height function) to local changes in geometry. As a direct by-product of the mathematical analysis work, we present an alternative equivalent formulation which lends itself to an effective pre-computing strategy that is very much needed as the limit problem is computationally expensive.},
  archive      = {J_JDE},
  author       = {Michael Eden and Adrian Muntean},
  doi          = {10.1016/j.jde.2025.113764},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113764},
  shortjournal = {J. Diff. Equ.},
  title        = {Thermo-elasticity problems with evolving microstructures},
  volume       = {452},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Travelling wave solutions to a microtube-driven glioma invasion model. <em>JDE</em>, <em>452</em>, 113759. (<a href='https://doi.org/10.1016/j.jde.2025.113759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we establish the existence of travelling wave solutions for a non-cooperative reaction-diffusion model representing glioma cell invasion. The model describes the microtube-driven migration of glioma consisting of an ODE equation describing the dynamics of the tumour bulk and a reaction-diffusion equation for the tumour microtubes. We derive an explicit formula for the minimum wave speed c ¯ based on system parameters such that travelling waves exist for speeds c ≥ c ¯ while no travelling wave solution exists for c < c ¯ . We prove the existence of travelling wave solutions by constructing upper and lower solutions and employing Schauder's fixed point theorem. We obtain non-existence for small speeds by use of the negative one-sided Laplace transform. Our result is one of the few complete results on travelling waves of a non-cooperative partially degenerate reaction-diffusion systems. The findings have implications for understanding glioma spread dynamics and potential modelling applications in predicting tumour progression based on cellular migration speeds.},
  archive      = {J_JDE},
  author       = {Ryan Thiessen and Thomas Hillen},
  doi          = {10.1016/j.jde.2025.113759},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113759},
  shortjournal = {J. Diff. Equ.},
  title        = {Travelling wave solutions to a microtube-driven glioma invasion model},
  volume       = {452},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Global well-posedness of the compressible electrically conducting viscoelastic fluids subject to the coulomb force in the half space. <em>JDE</em>, <em>451</em>, 113766. (<a href='https://doi.org/10.1016/j.jde.2025.113766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the compressible elastic Navier-Stokes-Poisson equations in the three-dimensional upper half space, which describe the dynamics of some kind of compressible electrically conducting viscoelastic fluids subject to the Coulomb force. Under the Hodge boundary condition for the velocity and the Neumann boundary condition for the electrostatic potential, we obtain the unique global solution near a constant equilibrium state in H 2 space by a delicate energy method. To capture the loss of boundary information for the deformation gradient, we propose the Hodge boundary condition for the deformation which can be preserved over time. Moreover, we use the effective electric field instead of the original one which is proved to have a regularization effect for unbounded problems.},
  archive      = {J_JDE},
  author       = {Rong Shen and Yong Wang},
  doi          = {10.1016/j.jde.2025.113766},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113766},
  shortjournal = {J. Diff. Equ.},
  title        = {Global well-posedness of the compressible electrically conducting viscoelastic fluids subject to the coulomb force in the half space},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Global existence results for coupled parabolic systems with general sources and some extensions involving degenerate coefficients. <em>JDE</em>, <em>451</em>, 113765. (<a href='https://doi.org/10.1016/j.jde.2025.113765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents optimal conditions for the existence of global solutions for the coupled parabolic system: u t − Δ u = h ( t ) f ( v ) and v t − Δ v = l ( t ) g ( u ) in Ω × ( 0 , T ) with the Dirichlet boundary conditions. Here, Ω ⊂ R N is a bounded or unbounded domain, the initial data belong to [ C 0 ( Ω ) ] 2 , and the functions f , g , h , l ∈ C [ 0 , ∞ ) . We also study the coupled parabolic system with degenerate coefficients: u t − div ( ω ( x ) ∇ u ) = h ( t ) f ( v ) and v t − div ( ω ( x ) ∇ v ) = l ( t ) g ( u ) in R N × ( 0 , T ) , where ω belong to the class A 2 of Muckenhoupt functions and may exhibit singularities along the line x 1 = 0 . This problem is related to the fractional Laplacian through the Caffarelli-Silvestre extension given in [2] . In addition, critical Fujita-type exponents are derived for both systems.},
  archive      = {J_JDE},
  author       = {Brandon Carhuas-Torre and Ricardo Castillo and Kerven Cea and Ricardo Freire and Alex Lira and Miguel Loayza},
  doi          = {10.1016/j.jde.2025.113765},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113765},
  shortjournal = {J. Diff. Equ.},
  title        = {Global existence results for coupled parabolic systems with general sources and some extensions involving degenerate coefficients},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The boundedness of almost-periodic oscillators with asymmetric potentials via normal form theorem. <em>JDE</em>, <em>451</em>, 113763. (<a href='https://doi.org/10.1016/j.jde.2025.113763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the boundedness of solutions for the semilinear asymmetric oscillator x ¨ + a x + − b x − = p ( t ) , where p is real analytic and almost-periodic function with infinitely many rationally independent frequencies. A key contribution is the development of a novel normal form theorem for planar almost-periodic mappings under a weighted Diophantine-type nonresonance condition (1.7) . Unlike prior approaches relying on twist conditions or spatial averaging, our framework eliminates geometric constraints by leveraging the spatial structure of infinite-dimensional frequencies. As a direct consequence, we prove two main results: 1. The existence of infinitely many almost-periodic solutions; 2. The boundedness of all solutions for the asymmetric oscillator, even when traditional twist integrals (e.g., (1.5) ) vanish. This work unifies periodic/quasi-periodic boundedness theories and extends them to the almost-periodic regime, resolving long-standing limitations in planar Hamiltonian systems with asymmetric potentials.},
  archive      = {J_JDE},
  author       = {Shuyi Wang and Min Li and Daxiong Piao},
  doi          = {10.1016/j.jde.2025.113763},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113763},
  shortjournal = {J. Diff. Equ.},
  title        = {The boundedness of almost-periodic oscillators with asymmetric potentials via normal form theorem},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stable solutions to the maxwell-chern-simons model. <em>JDE</em>, <em>451</em>, 113762. (<a href='https://doi.org/10.1016/j.jde.2025.113762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider an elliptic system arising from the study of the Maxwell-Chern-Simons model, which involves two distinct parameters: the Chern-Simons mass scale μ and the inverse Chern-Simons parameter λ . We first establish the equivalence between stable solutions and topological solutions with respect to the two distinct parameters in the Chern-Simon type regime. To address stability of our elliptic system, we study a reduced functional involving the Laplacian, and biharmonic terms appear in the corresponding linearized operator of the second Fréchet derivative. So, meticulous analysis is required to handle the biharmonic terms as well as the disparate scales of the two parameters. Furthermore, we show the uniqueness of stable solutions in the Chern-Simon type regime.},
  archive      = {J_JDE},
  author       = {Soojung Kim and Youngae Lee and Juhee Sohn},
  doi          = {10.1016/j.jde.2025.113762},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113762},
  shortjournal = {J. Diff. Equ.},
  title        = {Stable solutions to the maxwell-chern-simons model},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sobolev regularity theory for stochastic reaction-diffusion-advection equations with spatially homogeneous colored noises and infinitesimal generators of subordinate brownian motions. <em>JDE</em>, <em>451</em>, 113761. (<a href='https://doi.org/10.1016/j.jde.2025.113761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the existence, uniqueness, and regularity of solutions to nonlinear stochastic reaction-diffusion-advection equations (SRDAEs) with spatially homogeneous colored noises and infinitesimal generators of subordinate Brownian motions in mixed norm L q ( L p ) -spaces. We introduce a new condition—strongly reinforced Dalang's condition—on colored noise, which facilitates a deeper understanding of the complicated relation between nonlinearities and stochastic forces. Additionally, we establish the space-time Hölder type regularity of solutions.},
  archive      = {J_JDE},
  author       = {Jae-Hwan Choi and Beom-Seok Han and Daehan Park},
  doi          = {10.1016/j.jde.2025.113761},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113761},
  shortjournal = {J. Diff. Equ.},
  title        = {Sobolev regularity theory for stochastic reaction-diffusion-advection equations with spatially homogeneous colored noises and infinitesimal generators of subordinate brownian motions},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attractors for second order in time non-conservative dynamics with nonlinear damping. <em>JDE</em>, <em>451</em>, 113760. (<a href='https://doi.org/10.1016/j.jde.2025.113760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A long-time behavior of solutions to a nonlinear plate model subject to non-conservative and non-dissipative effects and nonlinear damping is considered. The model under study is a prototype for a suspension bridge under the effects of unstable flow of gas. To counteract the unwanted oscillations a damping mechanism of a nonlinear nature is applied. From the point of view of nonlinear PDEs, we are dealing with a non-dissipative and nonlinear second order in time dynamical system of hyperbolic nature subjected to nonlinear damping. One of the first goals is to establish ultimate dissipativity of all solutions, which will imply an existence of a weak attractor . The combined effects of non-dissipative forcing with nonlinear damping-leading to an overdamping-give rise to major challenges in proving an existence of an absorbing set. Known methods based on equipartition of the energy do not suffice. A rather general novel methodology based on “barrier's” method will be developed to address this and related problems. Ultimately, it will be shown that a weak attractor becomes strong, and the nonlinear PDE system has a coherent finite-dimensional asymptotic behavior.},
  archive      = {J_JDE},
  author       = {I. Lasiecka and J.H. Rodrigues and M. Roy},
  doi          = {10.1016/j.jde.2025.113760},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113760},
  shortjournal = {J. Diff. Equ.},
  title        = {Attractors for second order in time non-conservative dynamics with nonlinear damping},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the critical behavior for the semilinear biharmonic heat equation with forcing term in exterior domain. <em>JDE</em>, <em>451</em>, 113758. (<a href='https://doi.org/10.1016/j.jde.2025.113758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the critical behavior of solutions to the semilinear biharmonic heat equation with forcing term f ( x ) , under six homogeneous boundary conditions. This paper is the first since the seminal work by Bandle et al. (2000) [24] , to focus on the study of critical exponents in exterior problems for semilinear parabolic equations with a forcing term. By employing a method of test functions and comparison principle, we derive the critical exponents p C r i t in the sense of Fujita. Moreover, we show that p C r i t = ∞ if N = 2 , 3 , 4 and p C r i t = N N − 4 if N ⩾ 5 . The impact of the forcing term on the critical behavior of the problem is also of interest, and thus a second critical exponent in the sense of Lee-Ni, depending on the forcing term is introduced. We also discuss the case f ≡ 0 , and present the finite-time blow-up results and lifespan estimates of solutions for the subcritical and critical cases. The lifespan estimates of solutions are obtained by employing the method proposed by Ikeda and Sobajama (2019) [13] .},
  archive      = {J_JDE},
  author       = {Nurdaulet N. Tobakhanov and Berikbol T. Torebek},
  doi          = {10.1016/j.jde.2025.113758},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113758},
  shortjournal = {J. Diff. Equ.},
  title        = {On the critical behavior for the semilinear biharmonic heat equation with forcing term in exterior domain},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ABP estimate on metric measure spaces via optimal transport. <em>JDE</em>, <em>451</em>, 113757. (<a href='https://doi.org/10.1016/j.jde.2025.113757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By using optimal transport theory, we establish a sharp Alexandroff–Bakelman–Pucci (ABP) type estimate on metric measure spaces with synthetic Riemannian Ricci curvature lower bounds, and prove some geometric and functional inequalities including a functional ABP estimate. Our result not only extends the border of ABP estimate, but also provides an effective substitution of Jacobi fields computation in the non-smooth framework, which has potential applications to many problems in non-smooth geometric analysis.},
  archive      = {J_JDE},
  author       = {Bang-Xian Han},
  doi          = {10.1016/j.jde.2025.113757},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113757},
  shortjournal = {J. Diff. Equ.},
  title        = {ABP estimate on metric measure spaces via optimal transport},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Global existence for systems of 2-D wave equations with nonlinearity of the wave maps type in exterior domains. <em>JDE</em>, <em>451</em>, 113756. (<a href='https://doi.org/10.1016/j.jde.2025.113756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we solve the global Dirichelt boundary value problem for the system of 2-D wave maps type equations with the form □ u I = ∑ J , K , L = 1 M C I J K L u J Q 0 ( u K , u L ) ( 1 ≤ I ≤ M ) and Q 0 ( f , g ) = ∂ t f ∂ t g − ∑ j = 1 2 ∂ j f ∂ j g in exterior domain. By establishing some crucial classes of pointwise spacetime decay estimates for the small data solution u = ( u 1 , ⋅ ⋅ ⋅ , u M ) and its derivatives, the global existence of u is shown.},
  archive      = {J_JDE},
  author       = {Hou Fei and Yin Huicheng and Yuan Meng},
  doi          = {10.1016/j.jde.2025.113756},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113756},
  shortjournal = {J. Diff. Equ.},
  title        = {Global existence for systems of 2-D wave equations with nonlinearity of the wave maps type in exterior domains},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The asymptotic of the mullins-sekerka and the area-preserving curvature flow in the planar flat torus. <em>JDE</em>, <em>451</em>, 113755. (<a href='https://doi.org/10.1016/j.jde.2025.113755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the asymptotic behavior of flat flow solutions to the periodic and planar two-phase Mullins-Sekerka flow and area-preserving curvature flow. We show that flat flows converge to either a finite union of equally sized disjoint disks or to a finite union of disjoint strips or to the complement of these configurations exponentially fast. A key ingredient in our approach is the derivation of a sharp quantitative Alexandrov inequality for periodic smooth sets.},
  archive      = {J_JDE},
  author       = {Vedansh Arya and Daniele De Gennaro and Anna Kubin},
  doi          = {10.1016/j.jde.2025.113755},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113755},
  shortjournal = {J. Diff. Equ.},
  title        = {The asymptotic of the mullins-sekerka and the area-preserving curvature flow in the planar flat torus},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Heat equation in a periodic domain with special initial data. <em>JDE</em>, <em>451</em>, 113754. (<a href='https://doi.org/10.1016/j.jde.2025.113754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the initial-boundary value problem with the Neumann boundary condition for the classical linear heat equation in unbounded domains Ω ⊊ R d which are periodic in all directions of the Cartesian coordinate system. Generalizing the results of a previous paper by the authors, we apply Floquet transform methods to obtain results on the large time decay rates of the solution in the sup-norm. We observe that for a general, integrable initial data, the solution decays at the same rate t − d / 2 as in the case of the Cauchy problem in the entire Euclidean space. We also consider special initial data with vanishing x -integral and obtain a faster decay rate. In the main results of the paper we pose for the initial data certain more detailed conditions, which are related to the lowest eigenvalue and eigenfunction of the model problem coming from the Floquet transform. Faster decay rates are obtained for such initial data.},
  archive      = {J_JDE},
  author       = {Marcus Rosenberg and Jari Taskinen},
  doi          = {10.1016/j.jde.2025.113754},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113754},
  shortjournal = {J. Diff. Equ.},
  title        = {Heat equation in a periodic domain with special initial data},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bifurcation of gravity-capillary stokes waves with constant vorticity. <em>JDE</em>, <em>451</em>, 113753. (<a href='https://doi.org/10.1016/j.jde.2025.113753'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the gravity-capillary water waves equations of a 2D fluid with constant vorticity. By employing variational methods we prove the bifurcation of periodic traveling water waves –which are steady in a moving frame– for all the values of gravity, surface tension, constant vorticity, depth and wavelenght, extending previous results valid for restricted values of the parameters. We parametrize the bifurcating Stokes waves either with their speed or their momentum.},
  archive      = {J_JDE},
  author       = {T. Barbieri and M. Berti and A. Maspero and M. Mazzucchelli},
  doi          = {10.1016/j.jde.2025.113753},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113753},
  shortjournal = {J. Diff. Equ.},
  title        = {Bifurcation of gravity-capillary stokes waves with constant vorticity},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stability of rarefaction wave for steady supersonic relativistic euler flows past lipschitz wedges. <em>JDE</em>, <em>451</em>, 113752. (<a href='https://doi.org/10.1016/j.jde.2025.113752'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to studying two-dimensional steady supersonic relativistic Euler flows past a sharp corner or a bending wedge. When the vertex angle is larger than π and the wedge is a small perturbation of a convex rigid wall, we prove the global existence and stability of entropy solution including a large rarefaction wave under some small perturbations of the initial data and the slope of the boundary. Moreover, we obtain global non-relativistic limits of entropy solution as well as the asymptotic behavior of the solution as x → + ∞ .},
  archive      = {J_JDE},
  author       = {Min Ding and Yachun Li},
  doi          = {10.1016/j.jde.2025.113752},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113752},
  shortjournal = {J. Diff. Equ.},
  title        = {Stability of rarefaction wave for steady supersonic relativistic euler flows past lipschitz wedges},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Morse index and non-degeneracy of double-tower solutions for prescribed scalar curvature problem. <em>JDE</em>, <em>451</em>, 113751. (<a href='https://doi.org/10.1016/j.jde.2025.113751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the following prescribed scalar curvature equations in R N : (0.1) − Δ u = K ( | y | ) u 2 ⁎ − 1 , u > 0 in R N , u ∈ D 1 , 2 ( R N ) , where K ( r ) is a positive function, N ≥ 5 and 2 ⁎ = 2 N N − 2 . We are concerned with the solutions which are invariant under some non-trivial sub-group of O ( 3 ) to the above problem (we call them double-tower solutions). We first prove a non-degeneracy result for the positive double-tower solutions. As an application, we consider an eigenvalue problem related to prescribed scalar curvature equations and investigate the properties of the eigenvalues. And we compute the Morse index of the double-tower solutions. Our proof is based on the local Pohozaev identities, blow-up analysis, and the properties of the Green function.},
  archive      = {J_JDE},
  author       = {Yuxia Guo and Yichen Hu and Shaolong Peng},
  doi          = {10.1016/j.jde.2025.113751},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113751},
  shortjournal = {J. Diff. Equ.},
  title        = {Morse index and non-degeneracy of double-tower solutions for prescribed scalar curvature problem},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Vanishing viscosity limit of compressible non-resistive magnetohydrodynamic equations with the no-slip boundary condition. <em>JDE</em>, <em>451</em>, 113749. (<a href='https://doi.org/10.1016/j.jde.2025.113749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the vanishing viscosity limit of the three dimensional compressible non-resistive magnetohydrodynamic equations with the no-slip boundary condition in the half-space. Assuming that the initial normal magnetic field is non-degenerate, by identifying a new cancellation structure in the momentum equation, we can use the tangential derivatives of solutions to control the normal derivatives of the magnetic field and pressure. Furthermore, we establish uniform regularity estimates of solutions to the initial-boundary value problem of the compressible non-resistive magnetohydrodynamic equations in conormal Sobolev spaces. Then, based on these uniform regularity estimates and the compactness arguments, the vanishing viscosity limit of solutions to the compressible non-resistive magnetohydrodynamic equations is rigorously verified in L ∞ sense.},
  archive      = {J_JDE},
  author       = {Qiangchang Ju and Jiawei Wang and Feng Xie},
  doi          = {10.1016/j.jde.2025.113749},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113749},
  shortjournal = {J. Diff. Equ.},
  title        = {Vanishing viscosity limit of compressible non-resistive magnetohydrodynamic equations with the no-slip boundary condition},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Global-in-time maximal regularity for the cauchy problem of the heat equation in BMO and applications. <em>JDE</em>, <em>451</em>, 113748. (<a href='https://doi.org/10.1016/j.jde.2025.113748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we establish global-in-time maximal regularity for the Cauchy problem of the classical heat equation ∂ t u ( x , t ) − Δ u ( x , t ) = f ( x , t ) with u ( x , 0 ) = 0 in a certain BMO setting, which improves the local-in-time result initially proposed by Ogawa and Shimizu in [26] , [27] . In further developing our method originally formulated for the heat equation, we obtain analogous global BMO-maximal regularity associated to the Schrödinger operator L = − Δ + V , where the nonnegative potential V belongs to the reverse Hölder class RH q for some q > n / 2 . This extension includes several inhomogeneous estimates as ingredients, such as Carleson-type estimates for the external forces. Our new methodology is to exploit elaborate heat kernel estimates, along with matched space-time decomposition on the involving integral-type structure of maximal operators, as well as some global techniques such as those from de Simon's work and Schur's lemma. One crucial trick is to utilize the mean oscillation therein to contribute a higher and necessary decay order for global-in-time estimates.},
  archive      = {J_JDE},
  author       = {Xuan Thinh Duong and Ji Li and Liangchuan Wu and Lixin Yan},
  doi          = {10.1016/j.jde.2025.113748},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113748},
  shortjournal = {J. Diff. Equ.},
  title        = {Global-in-time maximal regularity for the cauchy problem of the heat equation in BMO and applications},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reconstruction of schrödinger operators by half of the dirichlet eigenvalues. <em>JDE</em>, <em>451</em>, 113747. (<a href='https://doi.org/10.1016/j.jde.2025.113747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method for reconstructing the potential of a one-dimensional Schrödinger operator in L 2 ( 0 , 1 ) using half of the Dirichlet-Dirichlet spectrum, combined with the potential known a priori on [ 1 4 , 1 ] . This problem relates to the uniqueness theorem due to Gesztesy and Simon [2] concerning inverse eigenvalue problems with mixed given data. The basic idea is to establish an appropriate functional equation, which enables us to propose a method for recovering the potential in this type of inverse problem. Additionally, we provide a necessary and sufficient condition for the existence of a solution to this problem.},
  archive      = {J_JDE},
  author       = {Xinya Yang and Guangsheng Wei},
  doi          = {10.1016/j.jde.2025.113747},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113747},
  shortjournal = {J. Diff. Equ.},
  title        = {Reconstruction of schrödinger operators by half of the dirichlet eigenvalues},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explicitly solvable NLS model with discontinuous standing waves. <em>JDE</em>, <em>451</em>, 113746. (<a href='https://doi.org/10.1016/j.jde.2025.113746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the NLS Equation on the line with a point interaction given by the superposition of an attractive delta potential with a dipole interaction, in the cases of L 2 -subcritical and L 2 -critical nonlinearity. For a subcritical nonlinearity we prove the existence and the uniqueness of Ground States at any mass. If the mass exceeds an explicit threshold, then there exists a positive excited state too. For the critical nonlinearity we prove that Ground States exist only in a specific interval of masses, while in a different interval excited states exist. We provide the value of the optimal constant in the Gagliardo-Nirenberg estimate and describe in the dipole case the branches of the stationary states as the strength of the interaction varies. Since all stationary states are explicitly computed, ours is a solvable model involving a non-standard interplay of a nonlinearity with a point interaction.},
  archive      = {J_JDE},
  author       = {Riccardo Adami and Filippo Boni and Takaaki Nakamura and Alice Ruighi},
  doi          = {10.1016/j.jde.2025.113746},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113746},
  shortjournal = {J. Diff. Equ.},
  title        = {An explicitly solvable NLS model with discontinuous standing waves},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the stationary magneto-convective motion of compressible full MHD equations in an infinite horizontal layer. <em>JDE</em>, <em>451</em>, 113744. (<a href='https://doi.org/10.1016/j.jde.2025.113744'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an infinite horizontal layer, we consider the equations of the viscous, compressible, and heat conducting magnetohydrodynamic steady flows subject to the gravitational force and to a large gradient of the temperature across the layer. As boundary conditions, we assume in the vertical directions, slip-boundary for the velocity and vertical conditions for magnetic field. The existence of a stationary solution in a small neighborhood of a steady profile close to the rest state is obtained in the Sobolev spaces as limit of a sequence of fixed points of some operators constructed from a suitable linearization of the full magnetohydrodynamic system of equations.},
  archive      = {J_JDE},
  author       = {Rachid Benabidallah and François Ebobisse and Mohamed Azouz},
  doi          = {10.1016/j.jde.2025.113744},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113744},
  shortjournal = {J. Diff. Equ.},
  title        = {On the stationary magneto-convective motion of compressible full MHD equations in an infinite horizontal layer},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Elliptic equations in divergence form with zero mass and critical exponential growth. <em>JDE</em>, <em>451</em>, 113743. (<a href='https://doi.org/10.1016/j.jde.2025.113743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider a class of elliptic equations in divergence form with zero mass, involving weight functions that are not necessarily symmetric and nonlinearities satisfying critical exponential growth. For this purpose, we introduce a weighted Trudinger-Moser type inequality. We prove the existence of nonnegative least energy solutions and investigate their qualitative properties, including asymptotic behavior, growth estimates, regularity results, and the existence of strictly positive solutions.},
  archive      = {J_JDE},
  author       = {J.C. de Albuquerque and J. Carvalho and E.D. Silva},
  doi          = {10.1016/j.jde.2025.113743},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113743},
  shortjournal = {J. Diff. Equ.},
  title        = {Elliptic equations in divergence form with zero mass and critical exponential growth},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). H2-regularity for stationary and non-stationary bingham problems with perfect slip boundary condition. <em>JDE</em>, <em>451</em>, 113739. (<a href='https://doi.org/10.1016/j.jde.2025.113739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {H 2 -spatial regularity of stationary and non-stationary problems for Bingham fluids formulated with the pseudo-stress tensor is discussed. The problem is mathematically described by an elliptic or parabolic variational inequality of the second kind, to which weak solvability in the Sobolev space H 1 is well known. However, higher regularity up to the boundary in a bounded smooth domain seems to remain open. This paper indeed shows such H 2 -regularity if the problems are supplemented with the so-called perfect slip boundary condition and if the yield stress vanishes on the boundary. For the stationary Bingham–Stokes problem, the key of the proof lies in a priori estimates for a regularized problem avoiding investigation of higher pressure regularity, which seems difficult to get in the presence of a singular diffusion term. The H 2 -regularity for the stationary case is then directly applied to establish strong solvability of the non-stationary Bingham–Navier–Stokes problem, based on discretization in time and on the truncation of the nonlinear convection term.},
  archive      = {J_JDE},
  author       = {Takeshi Fukao and Takahito Kashiwabara},
  doi          = {10.1016/j.jde.2025.113739},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113739},
  shortjournal = {J. Diff. Equ.},
  title        = {H2-regularity for stationary and non-stationary bingham problems with perfect slip boundary condition},
  volume       = {451},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Global strong solutions of the 3D compressible viscoelastic equations without structure assumptions. <em>JDE</em>, <em>450</em>, 113767. (<a href='https://doi.org/10.1016/j.jde.2025.113767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop Zhu Yi's method (Y. Zhu (2022) [29] ) to prove the global strong solutions of the 3D compressible viscoelastic equations without any additional structure assumptions on the deformation tensor. To obtain the uniform bounds of the density and deformation tensor, the spectral method is used.},
  archive      = {J_JDE},
  author       = {Yifeng Huang and Qingqing Liu and Changjiang Zhu},
  doi          = {10.1016/j.jde.2025.113767},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113767},
  shortjournal = {J. Diff. Equ.},
  title        = {Global strong solutions of the 3D compressible viscoelastic equations without structure assumptions},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Existence of axis-symmetric blow-up solution with multiple peak aggregations for the 2-D keller-segel systems coupled bipolar source and sink flow. <em>JDE</em>, <em>450</em>, 113745. (<a href='https://doi.org/10.1016/j.jde.2025.113745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the Keller-Segel systems in R d , coupled with a bipolar source and sink flow. Focusing on the two-dimensional case ( d = 2 ), we establish finite-time blow-up of solutions under an axis-symmetric setting, without requiring the solutions to be radial. In particular, we prove that multiple blow-up points appear in pairs (i.e., in even numbers) away from the origin, lying on the x 1 -axis and exhibiting axis-symmetry about the x 2 -axis. This result holds for initial data with total mass strictly greater than 16 π , and stands in contrast to the classical radial setting, where blow-up is confined to the origin. A crucial part of our analysis is a sharp ε -regularity theorem, originally developed for the classical Keller-Segel systems and first established by Luckhaus–Sugiyama–Velázquez [12] . This theorem states that if the local mass around x 1 is sufficiently small at some time t 1 , then the solution remains locally bounded in a suitable parabolic cylinder in space–time centered at ( x 1 , t 1 ) . Compared to the classical ε -regularity theorem, it requires weaker assumptions and yields weaker conclusions, making it a form of partial regularity that is particularly essential for analyzing blow-up singularities. Based on this sharp ε -regularity theorem, we further prove that only finitely many blow-up points appear as singular sets, and the asymptotic profile is characterized as the sum of a finite number of δ -functions and a regular part in L 1 ( R 2 ) . Moreover, our results reveal that multi-peak blow-up phenomena can occur with or without the presence of non-trivial flow, highlighting the intricate interplay between diffusion, chemotaxis, and persistent advection. By accounting for non-decaying flow and employing precise blow-up criteria, we establish that the blow-up time can be bounded above by any prescribed threshold. These findings are justified through the construction of a time-local existence and extension theory for strong solutions, which incorporates both advection and mass conservation.},
  archive      = {J_JDE},
  author       = {Yukihiro Seki and Kosuke Shibata and Yoshie Sugiyama},
  doi          = {10.1016/j.jde.2025.113745},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113745},
  shortjournal = {J. Diff. Equ.},
  title        = {Existence of axis-symmetric blow-up solution with multiple peak aggregations for the 2-D keller-segel systems coupled bipolar source and sink flow},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The stability on the caffarelli-kohn-nirenberg and hardy-type inequalities and beyond. <em>JDE</em>, <em>450</em>, 113738. (<a href='https://doi.org/10.1016/j.jde.2025.113738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we establish several improved Caffarelli-Kohn-Nirenberg and Hardy-type inequalities. Our main results are divided into two parts. In the first part, we consider the following Caffarelli-Kohn-Nirenberg inequality: ( ∫ R n | x | − p a | ∇ u | p d x ) 1 p ≥ S ( p , a , b ) ( ∫ R n | x | − q b | u | q d x ) 1 q , ∀ u ∈ D a p ( R n ) , where S ( p , a , b ) is the sharp constant and a , b , p , q satisfy the relations: 1 < p < n , 0 ≤ a < n − p p , a ≤ b < a + 1 , q = n p n − p ( 1 + a − b ) . We establish gradient stability of this inequality in both functional and critical settings, and we derive some functional properties of the stability constant. Building on the gradient stability, we also obtain several refined Sobolev-type embeddings involving weak Lebesgue norms for functions supported in general domains. In the second part, we focus on various classical Hardy-type inequalities, including the standard Hardy inequality, the L p -logarithmic Sobolev inequality with weights, the logarithmic Hardy inequality, the Hardy-Morrey inequality, the Hardy-Sobolev interpolation inequality, and the interpolated Caffarelli-Kohn-Nirenberg inequality. We investigate their weighted versions and derive corresponding extremal functions, refinements, new remaining terms and stability constants. An important tool in our arguments is a class of simple yet super useful transformations. These transformations enable us to reduce inequalities with complicated weights to simpler forms and to establish explicit relations between stability constants.},
  archive      = {J_JDE},
  author       = {Yuxuan Zhou and Wenming Zou},
  doi          = {10.1016/j.jde.2025.113738},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113738},
  shortjournal = {J. Diff. Equ.},
  title        = {The stability on the caffarelli-kohn-nirenberg and hardy-type inequalities and beyond},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cancellation properties and unconditional well-posedness for fifth order modified KdV type equations with periodic boundary conditions. <em>JDE</em>, <em>450</em>, 113736. (<a href='https://doi.org/10.1016/j.jde.2025.113736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove the unconditional well-posedness result for fifth order modified KdV type equations in H s ( T ) when s ≥ 3 / 2 , which includes non-integrable cases. By the conservation laws, we also obtain the global well-posedness result when s = 2 , which also includes non-integrable cases. The main idea is to employ the normal form reduction and a kind of cancellation properties to deal with the derivative losses.},
  archive      = {J_JDE},
  author       = {Takamori Kato and Kotaro Tsugawa},
  doi          = {10.1016/j.jde.2025.113736},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113736},
  shortjournal = {J. Diff. Equ.},
  title        = {Cancellation properties and unconditional well-posedness for fifth order modified KdV type equations with periodic boundary conditions},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Solvability and convergence results for the temperature and concentration field in incompressible navier-stokes equations with boundary conditions. <em>JDE</em>, <em>450</em>, 113735. (<a href='https://doi.org/10.1016/j.jde.2025.113735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider a new and complicated coupled system consisting of the incompressible Navier-Stokes equations (NSEs) subject to boundary conditions, a fractional diffusion equation governing the concentration field, and an evolution equation describing the temperature field. Under mild assumptions, the existence of a mild solution to the coupled system is proved using a surjectivity result for weakly-weakly upper semicontinuous multivalued mappings, combined with a feedback iterative method and a temporally semi-discrete strategy. Additionally, we examine the asymptotic behavior of the solution sequence as the small parameter in the inertial term approaches zero, offering deeper insights into the limiting behavior and dynamic properties of the system.},
  archive      = {J_JDE},
  author       = {Jianwei Hao and Tomás Caraballo},
  doi          = {10.1016/j.jde.2025.113735},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113735},
  shortjournal = {J. Diff. Equ.},
  title        = {Solvability and convergence results for the temperature and concentration field in incompressible navier-stokes equations with boundary conditions},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Center problem of generalized kukles systems with z2-symmetry or weak z2-symmetry. <em>JDE</em>, <em>450</em>, 113734. (<a href='https://doi.org/10.1016/j.jde.2025.113734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we research the center problem for generalized Kukles systems with Z 2 -symmetry or weak Z 2 -symmetry as follows x ˙ = y , y ˙ = f 0 ( x ) + f 1 ( x ) y + f 2 ( x ) y 2 + f 3 ( x ) y 3 , which have a non-degenerate or nilpotent singular point at the origin and functions f i ( x ) are analytic at x = 0 for i = 0 , 1 , 2 , 3 . Sufficient and necessary conditions are obtained for the origin to be a center, which can be directly determined by the expressions of f i ( x ) and can be verified easily. In order to prove the main results, we use the comparison theorem to get the center condition for a class of systems with weak symmetry, and we present a necessary condition for the existence of a center in analytic Z 2 -symmetric generalized Liénard systems. At last, we provide two examples to present the center conditions by applying our theoretical results and give a negative answer to a conjecture proposed in the literature.},
  archive      = {J_JDE},
  author       = {Xinhao Hu and Yilei Tang},
  doi          = {10.1016/j.jde.2025.113734},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113734},
  shortjournal = {J. Diff. Equ.},
  title        = {Center problem of generalized kukles systems with z2-symmetry or weak z2-symmetry},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the local well-posedness of fractionally dissipated primitive equations with transport noise. <em>JDE</em>, <em>450</em>, 113729. (<a href='https://doi.org/10.1016/j.jde.2025.113729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the three-dimensional fractionally dissipated primitive equations with transport noise, focusing on subcritical and critical dissipation regimes characterized by ( − Δ ) s / 2 with s ∈ ( 1 , 2 ) and s = 1 , respectively. For σ > 3 , we establish the local existence of unique pathwise solutions in Sobolev space H σ . This result applies to arbitrary initial data in the subcritical case ( s ∈ ( 1 , 2 ) ), and to small initial data in the critical case ( s = 1 ). The analysis is particularly challenging due to the loss of horizontal derivatives in the nonlinear terms and the lack of full dissipation. To address these challenges, we develop novel commutator estimates involving the hydrostatic Leray projection.},
  archive      = {J_JDE},
  author       = {Ruimeng Hu and Quyuan Lin and Rongchang Liu},
  doi          = {10.1016/j.jde.2025.113729},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113729},
  shortjournal = {J. Diff. Equ.},
  title        = {On the local well-posedness of fractionally dissipated primitive equations with transport noise},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stokes-brinkman equations with diffusion and convection in thin tube structures. <em>JDE</em>, <em>450</em>, 113728. (<a href='https://doi.org/10.1016/j.jde.2025.113728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The steady state Stokes-Brinkman equations coupled with a system of diffusion-convection equations in a thin tube structure is considered. The Brinkman term differs from zero only in small balls near the ends of the tubes. The boundary conditions are: given pressure and concentrations at the inflow and outflow of the tube structure, the no slip boundary condition on the lateral boundary for the fluid, and Neumann type condition on the lateral boundary for the diffusion-convection equations. In this paper, the existence, uniqueness, and stability of the solution to such a problem are proved. Moreover, some a priori norm-estimates depending on the small thickness of the tubes are also provided. This model is well suited to describing thrombosis in blood vessels.},
  archive      = {J_JDE},
  author       = {Antonio Gaudiello and Grigory Panasenko},
  doi          = {10.1016/j.jde.2025.113728},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113728},
  shortjournal = {J. Diff. Equ.},
  title        = {Stokes-brinkman equations with diffusion and convection in thin tube structures},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multiplicity and profile of solutions for singularly perturbed kirchhoff-type problems on closed manifolds. <em>JDE</em>, <em>450</em>, 113727. (<a href='https://doi.org/10.1016/j.jde.2025.113727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the existence of solutions for singularly perturbed Kirchhoff-type problems on a closed 3-dimensional Riemannian manifold, focusing on the relation between the number of solutions and the topological properties of the manifold. Our approach is based on the Lusternik–Schnirelmann category. We also provide a profile description of low energy solutions.},
  archive      = {J_JDE},
  author       = {Xiaojin Bai and Hua Chen and Xiaochun Liu},
  doi          = {10.1016/j.jde.2025.113727},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113727},
  shortjournal = {J. Diff. Equ.},
  title        = {Multiplicity and profile of solutions for singularly perturbed kirchhoff-type problems on closed manifolds},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Abelian integrals for polynomials with trivial global monodromy on c2. <em>JDE</em>, <em>450</em>, 113726. (<a href='https://doi.org/10.1016/j.jde.2025.113726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider infinitesimal perturbations of Hamiltonian differential equations d H + ε ω = 0 on the complex plane C 2 , where H is a polynomial of degree m + 1 and ω is a non-exact polynomial 1-form of degree n . In order to study these perturbed differential equations, the associated Abelian integrals I ( c ) = ∫ γ ( c ) ω are valuable tools. We assume that the polynomials H are primitive with trivial global monodromy. For these polynomials, W.D. Neumann and P. Norbury provided a classification in three large families, up to algebraic equivalence. The knowledge of these families allows us to prove as first main result, that the respective Abelian integrals I ( c ) are polynomial functions of the variable c , and to find sharp explicit upper bounds for the number of their zeros. These upper bounds depend on m , n and the number of the generators of the fundamental group of the generic fibers of H , and they work for several new families of infinitesimal perturbations of Hamiltonian differential equations. Under trivial global monodromy, there exist canonical global generators B C ( H ) = { γ i ( c ) } of the fundamental groups for all the generic fibers of H , which are complex cycles of d H = 0 . As second main result; we compute the number of complex limit cycles of d H + ε ω = 0 which originate from complex cycles in B C ( H ) . Several accurate examples are provided.},
  archive      = {J_JDE},
  author       = {Jesús Muciño-Raymundo and Salomón Rebollo-Perdomo},
  doi          = {10.1016/j.jde.2025.113726},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113726},
  shortjournal = {J. Diff. Equ.},
  title        = {Abelian integrals for polynomials with trivial global monodromy on c2},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Local well-posedness in gevrey function spaces for 3D boussinesq boundary layer system. <em>JDE</em>, <em>450</em>, 113725. (<a href='https://doi.org/10.1016/j.jde.2025.113725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the 3D Boussinesq boundary layer system in R + × R 2 , which is a coupling of the Prandtl type equations and a thermal layer equation due to the coupling of velocity and temperature in Boussinesq equations. We observe that there is also a cancellation mechanism in the temperature equation, which has been applied to the Prandtl equations in Li et al. (2022) [14] . Utilizing these cancellation mechanisms and constructing good unknowns, we overcome the loss of derivative arising in not only the velocity equations but also the temperature equation, then we show the local well-posedness of the Boussinesq boundary layer system in Gevrey function spaces. Furthermore, we obtain the optimal Gevrey index 2.},
  archive      = {J_JDE},
  author       = {Qian Li and Peixin Wang and Xiaojing Xu},
  doi          = {10.1016/j.jde.2025.113725},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113725},
  shortjournal = {J. Diff. Equ.},
  title        = {Local well-posedness in gevrey function spaces for 3D boussinesq boundary layer system},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stability for inverse random source problems in electromagnetic and biharmonic waves. <em>JDE</em>, <em>450</em>, 113723. (<a href='https://doi.org/10.1016/j.jde.2025.113723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with inverse random source problems for electromagnetic and biharmonic wave equations. The driven sources are assumed to be generalized microlocally isotropic Gaussian random fields such that the covariances are classical pseudo-differential operators. Uniqueness and stability are established for both inverse random source problems. The stability estimates consist of a Lipschitz type data discrepancy and a logarithmic stability, which decreases as the upper bound of wavenumbers increases. These increasing stability results reveal that ill-posedness can be overcome by using multi-wavenumber data. The analysis is based on integral equations and analytical continuation, which only requires multi-frequency Dirichlet data on the boundary in a finite interval and removes the limitation of data to be collected at all high wavenumbers. For the first time, the stability is established on the inverse source problems for both the Maxwell and biharmonic equations by Dirichlet boundary measurements.},
  archive      = {J_JDE},
  author       = {Tianjiao Wang and Xiang Xu and Yue Zhao},
  doi          = {10.1016/j.jde.2025.113723},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113723},
  shortjournal = {J. Diff. Equ.},
  title        = {Stability for inverse random source problems in electromagnetic and biharmonic waves},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Global dynamics of a generalized van der pol-duffing system with arbitrary degree. <em>JDE</em>, <em>450</em>, 113722. (<a href='https://doi.org/10.1016/j.jde.2025.113722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the global dynamics of a generalized van der Pol-Duffing system in this paper, which has four nonlinear terms with arbitrary degree. This generalized nonlinear system possesses complicated dynamics, including at most three limit cycles, a figure-eight loop, infinitely many heteroclinic bifurcations, Hopf bifurcation, double large limit cycle bifurcation, generalized pitchfork bifurcation and generalized Hopf bifurcation. In addition, these theoretical results are exhibited via numerical simulations.},
  archive      = {J_JDE},
  author       = {Zhaoxia Wang and Jueliang Zhou and Lan Zou},
  doi          = {10.1016/j.jde.2025.113722},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113722},
  shortjournal = {J. Diff. Equ.},
  title        = {Global dynamics of a generalized van der pol-duffing system with arbitrary degree},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Normalized solutions for a class of sobolev critical schrödinger systems. <em>JDE</em>, <em>450</em>, 113719. (<a href='https://doi.org/10.1016/j.jde.2025.113719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the existence and multiplicity of normalized solutions for the following coupled Schrödinger system with Sobolev critical coupling term: { − Δ u + λ 1 u = ω 1 | u | p − 2 u + α ν 2 ⁎ | u | α − 2 | v | β u , in R N , − Δ v + λ 2 v = ω 2 | v | p − 2 v + β ν 2 ⁎ | u | α | v | β − 2 v , in R N , ∫ R N u 2 d x = a 2 , ∫ R N v 2 d x = b 2 , where N ≥ 3 , a , b > 0 , ω 1 , ω 2 , ν ∈ R ∖ { 0 } , and the exponents p , α , β satisfy α > 1 , β > 1 , α + β = 2 ⁎ , 2 < p ≤ 2 ⁎ = 2 N / ( N − 2 ) . The parameters λ 1 , λ 2 ∈ R will arise as Lagrange multipliers that are not prior given. This paper mainly presents several existence and multiplicity results under explicit conditions on a , b for the focusing case ω 1 , ω 2 > 0 and attractive case ν > 0 : (1) When 2 < p < 2 + 4 / N , we prove that there exist two solutions: one is a local minimizer, which serves as a normalized ground state, and the other is of mountain-pass type, which is a normalized excited state. (2) When 2 + 4 / N ≤ p < 2 ⁎ , we prove that there exists a mountain-pass type solution, which serves as a normalized ground state. (3) When p = 2 ⁎ , the existence and classification of normalized ground states are provided for and N ≥ 5 , alongside a non-existence result for N = 3 , 4 . These results reflect the properties of the Aubin-Talenti bubble, which attains the best Sobolev embedding constant. Furthermore, we present a non-existence result for the defocusing case ω 1 , ω 2 < 0 . We believe our methods can also address the open problem of the multiplicity of normalized solutions for Schrödinger systems with Sobolev critical growth, with potential for future development and broader applicability.}},
  archive      = {J_JDE},
  author       = {Houwang Li and Tianhao Liu and Wenming Zou},
  doi          = {10.1016/j.jde.2025.113719},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113719},
  shortjournal = {J. Diff. Equ.},
  title        = {Normalized solutions for a class of sobolev critical schrödinger systems},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Entire solutions to a quasilinear purely critical competitive system. <em>JDE</em>, <em>450</em>, 113717. (<a href='https://doi.org/10.1016/j.jde.2025.113717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish the existence of a fully nontrivial solution with nonnegative components for a weakly coupled competitive system for the p -Laplacian in R N whose nonlinear terms are purely critical. We also show that the purely critical equation for the p -Laplacian in R N has infinitely many nodal solutions.},
  archive      = {J_JDE},
  author       = {Mónica Clapp and Víctor A. Vicente-Benítez},
  doi          = {10.1016/j.jde.2025.113717},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113717},
  shortjournal = {J. Diff. Equ.},
  title        = {Entire solutions to a quasilinear purely critical competitive system},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hölder regularity for nonlocal in time subdiffusion equations with general kernel. <em>JDE</em>, <em>450</em>, 113716. (<a href='https://doi.org/10.1016/j.jde.2025.113716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the regularity of weak solutions to nonlocal in time subdiffusion equations for a wide class of weakly singular kernels appearing in the generalised fractional derivative operator. We prove a weak Harnack inequality for nonnegative weak supersolutions and Hölder continuity of weak solutions to such problems. Our results substantially extend the results from our previous work [11] by leaving the framework of distributed order fractional time derivatives and considering a general PC kernel and by also allowing for an inhomogeneity in the PDE from a Lebesgue space of mixed type.},
  archive      = {J_JDE},
  author       = {Adam Kubica and Katarzyna Ryszewska and Rico Zacher},
  doi          = {10.1016/j.jde.2025.113716},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113716},
  shortjournal = {J. Diff. Equ.},
  title        = {Hölder regularity for nonlocal in time subdiffusion equations with general kernel},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Construction of hunt processes by the lyapunov method and applications to generalized mehler semigroups. <em>JDE</em>, <em>450</em>, 113715. (<a href='https://doi.org/10.1016/j.jde.2025.113715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that in general, generalized Mehler semigroups defined on a Hilber space H may not correspond to càdlàg (or even càd) Markov processes with values in H endowed with the norm topology. In this paper we deal with the problem of characterizing those generalized Mehler semigroups that do correspond to càdlàg Markov processes, which is highly non-trivial and has remained open for more than a decade. Our approach is to reconsider the càdlàg problem for generalized Mehler semigroups as a particular case of the much broader problem of constructing Hunt (hence càdlàg and quasi-left continuous) processes from a given Markov semigroup. Following this strategy, a consistent part of this work is devoted to prove that starting from a Markov semigroup on a general (possibly non-metrizable) state space, the existence of a suitable Lyapunov function with relatively compact sub/sup-sets in conjunction with a local Feller-type regularity of the resolvent are sufficient to ensure the existence of an associated càdlàg Markov process; if in addition the topology is locally generated by potentials, then the process is in fact Hunt. Other results of fine potential theoretic nature are also pointed out, an important one being the fact that the Hunt property of a process is stable under the change of the topology, as long as it is locally generated by potentials. Based on such general existence results, we derive checkable sufficient conditions for a large class of generalized Mehler semigroups in order to possess an associated Hunt process with values in the original space, in contrast to previous results where an extension of the state space was required; to this end, we first construct explicit Lyapunov functions whose sub-level sets are relatively compact with respect to the (non-metrizable) weak topology, and then we use the above mentioned stability to deduce the Hunt property with respect to the stronger norm topology. As a particular example, we test these conditions on a stochastic heat equation on L 2 ( D ) whose drift is given by the Dirichlet Laplacian on a bounded domain D ⊂ R d , driven by a (non-diagonal) Lévy noise whose characteristic exponent is not necessarily Sazonov continuous; in this case, we construct the corresponding Mehler semigroup and we show that it is the transition function of a Hunt process that lives on the original space L 2 ( D ) endowed with the norm topology.},
  archive      = {J_JDE},
  author       = {Lucian Beznea and Iulian Cîmpean and Michael Röckner},
  doi          = {10.1016/j.jde.2025.113715},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113715},
  shortjournal = {J. Diff. Equ.},
  title        = {Construction of hunt processes by the lyapunov method and applications to generalized mehler semigroups},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Two-dimensional signal-dependent parabolic-elliptic keller-segel system and its mean-field derivation. <em>JDE</em>, <em>450</em>, 113712. (<a href='https://doi.org/10.1016/j.jde.2025.113712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the well-posedness of two-dimensional signal-dependent Keller-Segel system and its mean-field derivation from a interacting particle system on the whole space are investigated. The signal dependence effect is reflected by the fact that the diffusion coefficient in the particle system depends nonlinearly on the interactions between the individuals. Therefore, the mathematical challenge in studying the well-posedness of this system lies in the possible degeneracy and the aggregation effect when the concentration of signal becomes unbounded. The well-established method on bounded domains, to obtain the appropriate estimates for the signal concentration, is invalid for the whole space case. Motivated by the entropy minimization method and Onofri's inequality, which has been successfully applied for the parabolic-parabolic Keller-Segel system, we establish a complete entropy estimate benefited from the linear diffusion term, which plays an important role in obtaining the L p estimates for the solution. Furthermore, the upper bound for the concentration of signal is obtained. Based on the estimates we obtained for the density of bacteria, the rigorous mean-field derivation is proved by introducing an intermediate particle system with a mollified interaction potential with logarithmic scaling. By using this mollification, we obtain the convergence of the particle trajectories in expectation, which implies the weak propagation of chaos. Additionally, under a regularity assumption of the initial data, we infer higher regularity for the solutions, which allows us to use the relative entropy method to derive the strong L 1 convergence for the propagation of chaos.},
  archive      = {J_JDE},
  author       = {Lukas Bol and Li Chen and Yue Li},
  doi          = {10.1016/j.jde.2025.113712},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113712},
  shortjournal = {J. Diff. Equ.},
  title        = {Two-dimensional signal-dependent parabolic-elliptic keller-segel system and its mean-field derivation},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Conformally weighted einstein manifolds: The uniqueness problem. <em>JDE</em>, <em>450</em>, 113711. (<a href='https://doi.org/10.1016/j.jde.2025.113711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss smooth metric measure spaces admitting two weighted Einstein representatives of the same weighted conformal class. First, we describe the local geometries of such manifolds in terms of certain Einstein and quasi-Einstein warped products. Secondly, a global classification result is obtained when one of the underlying metrics is complete, showing that either it is a weighted space form, a special Einstein warped product, or a specific family of quasi-Einstein warped products. As a consequence, it must be a weighted sphere in the compact case.},
  archive      = {J_JDE},
  author       = {M. Brozos-Vázquez and E. García-Río and D. Mojón-Álvarez},
  doi          = {10.1016/j.jde.2025.113711},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113711},
  shortjournal = {J. Diff. Equ.},
  title        = {Conformally weighted einstein manifolds: The uniqueness problem},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Metastability in parabolic equations and diffusion processes with a small parameter. <em>JDE</em>, <em>450</em>, 113705. (<a href='https://doi.org/10.1016/j.jde.2025.113705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study diffusion processes in R d that leave invariant a finite collection of manifolds (surfaces or points) in R d and small perturbations of such processes. Assuming certain ergodic properties at and near the invariant surfaces, we describe the rate at which the process gets attracted to or repelled from the surface, based on the local behavior of the coefficients. For processes that include, additionally, a small non-degenerate perturbation, we describe the metastable behavior. Namely, by allowing the time scale to depend on the size of the perturbation, we observe different asymptotic distributions of the process at different time scales. Stated in PDE terms, the results provide the asymptotics, at different time scales, for the solution of the parabolic Cauchy problem when the operator that degenerates on a collection of surfaces is perturbed by a small non-degenerate term. This asymptotic behavior switches at a finite number of time scales that are calculated and does not depend on the perturbation.},
  archive      = {J_JDE},
  author       = {M. Freidlin and L. Koralov},
  doi          = {10.1016/j.jde.2025.113705},
  journal      = {Journal of Differential Equations},
  month        = {1},
  pages        = {113705},
  shortjournal = {J. Diff. Equ.},
  title        = {Metastability in parabolic equations and diffusion processes with a small parameter},
  volume       = {450},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jmaa">JMAA - 41</h2>
<ul>
<li><details>
<summary>
(2026). An application of a discrete sobolev inequality to discretised kirchhoff equations. <em>JMAA</em>, <em>555</em>(2), 130066. (<a href='https://doi.org/10.1016/j.jmaa.2025.130066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a discrete Sobolev inequality, and we use this inequality to analyse the nonlocal discretised Kirchhoff equation − A ( ( a ⁎ ( g ∘ | Δ u | ) ) ( b + 1 ) ) ( Δ 2 u ) ( n ) = λ f ( n , u ( n + 1 ) ) , n ∈ { 0 , 1 , 2 , … , b } , where ⁎ represents a finite convolution. The equation is a discrete analogue of the classical steady-state Kirchhoff equation in one space dimension. Existence of at least one positive solution is investigated under the assumption that the equation is subject to two-point boundary data such that u ( 0 ) = 0 . Thus, both Dirichlet and right-focal data are captured by our results. An interesting aspect of our theory is that the coefficient function A may be both vanishing and sign-changing.},
  archive      = {J_JMAA},
  author       = {Christopher S. Goodrich},
  doi          = {10.1016/j.jmaa.2025.130066},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {2},
  pages        = {130066},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {An application of a discrete sobolev inequality to discretised kirchhoff equations},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Traveling wave solutions for a density-suppressed motility model with strong allee effect. <em>JMAA</em>, <em>555</em>(2), 130063. (<a href='https://doi.org/10.1016/j.jmaa.2025.130063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate a density-suppressed motility model with strong Allee effect. By leveraging existing results on asymptotic autonomous systems, along with Fredholm theory and the Banach fixed-point theorem, we establish the existence of bistable traveling wave solutions using a perturbation argument. This result holds when the density-suppressed sensitivity is relatively small. Finally, we validate our main results through numerical simulations and further discuss wave patterns and the sign of the wave speed as the density-suppressed sensitivity varies.},
  archive      = {J_JMAA},
  author       = {Cui Song and Zhi-Cheng Wang},
  doi          = {10.1016/j.jmaa.2025.130063},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {2},
  pages        = {130063},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Traveling wave solutions for a density-suppressed motility model with strong allee effect},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Numerical dynamics of infection-age models with logistic growth and general nonlinear incidence. <em>JMAA</em>, <em>555</em>(2), 130062. (<a href='https://doi.org/10.1016/j.jmaa.2025.130062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an age-structured viral dynamics model with Logistic growth and a general nonlinear incidence rate. We present the basic reproduction number of the continuous model and conduct a theoretical analysis of the model. For such a hybrid infinite-dimensional system with abstract nonlinear terms, the comprehensive numerical analysis is still pending. We address this problem by establishing a fully discrete linearly implicit scheme, and the non-negativity of the numerical scheme is confirmed by utilizing the theory of M -matrix. With a solvability analysis, the finite time convergence is proved for strong solutions. For long-time dynamics, by utilizing the exponential decay characteristic of the fundamental solution matrix, we established a 1-order convergence analysis for the numerical reproduction number R 0 Δ t , and further proved the 1-order convergence property of numerical equilibria. By applying linearization techniques and comparison principles, we demonstrate that the disease-free equilibrium is globally asymptotically stable when R 0 Δ t < 1 , and the endemic equilibrium is locally asymptotically stable when R 0 Δ t > 1 . Hence, numerical processes almost completely replicate the dynamic properties of continuous system. At last, some numerical experiments demonstrate the obtained results.},
  archive      = {J_JMAA},
  author       = {Zhuzan Wang and Zhanwen Yang and Huiqing Xie and Zhijie Chen},
  doi          = {10.1016/j.jmaa.2025.130062},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {2},
  pages        = {130062},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Numerical dynamics of infection-age models with logistic growth and general nonlinear incidence},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hopf bifurcation in a time-delayed multi-group SIR epidemic model for population behavior change. <em>JMAA</em>, <em>555</em>(2), 130061. (<a href='https://doi.org/10.1016/j.jmaa.2025.130061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we construct a time-delayed multi-group SIR epidemic model to discuss the impact of population behavior change on the occurrence of recurrent epidemic waves. We obtain the basic reproduction number R 0 and show that if R 0 ≤ 1 , then the disease-free equilibrium is globally asymptotically stable, whereas if R 0 > 1 , then the disease-free equilibrium is unstable and an endemic equilibrium exists. In a special two-group case, we show sufficient conditions for Hopf bifurcation and obtain index values that determine the direction, stability and period of bifurcated periodic solutions. By numerical simulation, we investigate the occurrence of periodic solutions in two groups representing an urban area and a non-urban area. We conclude that the epidemic size, response intensity of population behavior change and heterogeneity in two different groups can be the key factors of the occurrence of recurrent epidemic waves.},
  archive      = {J_JMAA},
  author       = {Toshikazu Kuniya},
  doi          = {10.1016/j.jmaa.2025.130061},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {2},
  pages        = {130061},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Hopf bifurcation in a time-delayed multi-group SIR epidemic model for population behavior change},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integral operators in the schatten class on dirichlet spaces. <em>JMAA</em>, <em>555</em>(2), 130060. (<a href='https://doi.org/10.1016/j.jmaa.2025.130060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We characterize three integral operators in Schatten p -classes on Dirichlet spaces D α in the unit disk D for α > 0 and 0 < p < ∞ . The main results are threefold: (1) If 0 < α < 1 < p < ∞ and g is a holomorphic function in D , then the Volterra operator T g , defined by T g f ( z ) = ∫ 0 z f ( ζ ) g ′ ( ζ ) d ζ , is in the Schatten p -class on D α if and only if ∫ D ( ( 1 − | w | 2 ) α ∫ D | g ′ ( z ) | 2 d A α ( z ) | 1 − w ¯ z | 2 + 2 α ) p 2 ( 1 − | w | 2 ) p − 2 d A ( w ) < ∞ . (2) If α > 0 and 0 < p < ∞ , μ is a finite Borel measure on D , then the Toeplitz operator Q μ α acting on D α is in the Schatten p -class if and only if ∫ D ( ( 1 − | w | 2 ) α + 2 t ∫ D d μ ( z ) | 1 − w ¯ z | 2 α + 2 t ) p ( 1 − | w | 2 ) − 2 d A ( w ) < ∞ , where t is any (or some) nonnegative number such that α + 2 t > max ⁡ { 1 , 1 p } . (3) If g is a holomorphic function in D , α > 0 and 0 < p ≤ 1 , then the small Hankel operator h g α acting from D α to the Sobolev space L α 2 is in the Schatten p -class if and only if g belongs to the Besov space B p . These results answer the corresponding open problems left by Pau-Peláez [12] (J. Anal. Math. 120 (2013), 255-289).},
  archive      = {J_JMAA},
  author       = {Xin-Qi Wen and Cheng Yuan},
  doi          = {10.1016/j.jmaa.2025.130060},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {2},
  pages        = {130060},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Integral operators in the schatten class on dirichlet spaces},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Kernels for composition of positive linear operators. <em>JMAA</em>, <em>555</em>(2), 130052. (<a href='https://doi.org/10.1016/j.jmaa.2025.130052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the composition of Bernstein–Durrmeyer operators and Szász–Mirakjan–Durrmeyer operators, focusing on the structure and properties of the associated kernel functions. In the case of the Bernstein–Durrmeyer operators, we establish new identities for the kernel arising from the composition of two and three operators. Like the well-known representation in terms of Legendre polynomials, they show the commutativity of these operators naturally. While this Legendre representation contains all possible products p k , i ( x ) p k , j ( y ) , 0 ≤ i , j ≤ k ≤ n , of Bernstein basis polynomials, the new representation has the beautiful property to contain only products p k , ℓ ( x ) p k , ℓ ( y ) , 0 ≤ ℓ ≤ k ≤ n , where n is the smallest degree of the Bernstein–Durrmeyer polynomials involved. This fact immediately implies that the composition can be written as a linear combination of the operators themselves. Building on the eigenstructure of the Bernstein–Durrmeyer operator M n , we obtain a representation of its r -th iterate as a linear combination of the operators M k , for k = 0 , 1 , … , n . We also address the composition of Szász–Mirakjan–Durrmeyer operators and revisit a known result giving an elementary proof.},
  archive      = {J_JMAA},
  author       = {Ulrich Abel and Ana Maria Acu and Margareta Heilmann and Ioan Raşa},
  doi          = {10.1016/j.jmaa.2025.130052},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {2},
  pages        = {130052},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Kernels for composition of positive linear operators},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Some properties of a new mean measure. <em>JMAA</em>, <em>555</em>(1), 130051. (<a href='https://doi.org/10.1016/j.jmaa.2025.130051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to introduce the concept of the mean multifractal measure, which is a multifractal-measure-like quantity on an infinite dimensional space R N , and also a dynamical-like quantity with respect to the natural shift. We first focus on the existence of sets with finite mean multifractal measure. Then properties concerning the density of the mean multifractal measure are explored.},
  archive      = {J_JMAA},
  author       = {Yu Liu and Bilel Selmi and Zhiming Li},
  doi          = {10.1016/j.jmaa.2025.130051},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130051},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Some properties of a new mean measure},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Global solvability for the heat equations in two half spaces and an interface. <em>JMAA</em>, <em>555</em>(1), 130050. (<a href='https://doi.org/10.1016/j.jmaa.2025.130050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the existence of a global-in-time strong solution to the heat equations in the two half spaces R + 3 ( = R 2 × ( 0 , ∞ ) ) , R − 3 ( = R 2 × ( − ∞ , 0 ) ) , and the interface R 2 × { 0 } ( ≅ R 2 ) . We introduce and study some function spaces in the two half spaces and the interface. We apply our function spaces and the maximal L p -regularity for Hilbert space-valued functions to show the existence of a local-in-time strong solution to our heat equations. By using an energy equality of our heat system, we prove the existence of a unique global-in-time strong solution to the system with large initial data. The key idea of constructing strong solutions to our system is to make use of nice properties of the heat semigroups and kernels for R + 3 , R − 3 , and R 2 . In Appendix, we derive our heat equations in the two half spaces and the interface from an energetic point of view.},
  archive      = {J_JMAA},
  author       = {Hajime Koba},
  doi          = {10.1016/j.jmaa.2025.130050},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130050},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Global solvability for the heat equations in two half spaces and an interface},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Perspectives on the ρ-operator radius. <em>JMAA</em>, <em>555</em>(1), 130049. (<a href='https://doi.org/10.1016/j.jmaa.2025.130049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let ρ ∈ ( 0 , 2 ] and let w ρ ( X ) be the ρ -operator radius of a Hilbert space operator X . Using techniques involving the Kronecker product, it is shown that 1 + | 1 − ρ | ρ w ( X ) ≤ w ρ ( X ) ≤ 2 ρ w ( X ) , where w ( X ) is the numerical radius of X . These bounds for w ρ ( X ) are sharper than those presented by J. A. R. Holbrook. Furthermore, the cases of equality are investigated. We prove that the ρ -operator radius exposes certain operators as projections. We establish new inequalities for the ρ -operator radius, focusing on the sum and product of operators. For the generalized Aluthge transform X ˜ t of an operator X , we prove the inequality: w ρ ( X ) ≤ 1 2 w ρ ( X ˜ t ) + 1 ρ ‖ X ‖ , for all t ∈ [ 0 , 1 ] . The derived inequalities extend and generalize several well-known results for the classical operator norm and numerical radius.},
  archive      = {J_JMAA},
  author       = {Pintu Bhunia and Mohammad Sal Moslehian and Ali Zamani},
  doi          = {10.1016/j.jmaa.2025.130049},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130049},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Perspectives on the ρ-operator radius},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust and minimum norm partial eigenvalue assignment in singular vibration systems. <em>JMAA</em>, <em>555</em>(1), 130048. (<a href='https://doi.org/10.1016/j.jmaa.2025.130048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the partial quadratic eigenvalue assignment problem (PQEAP) for the singular second-order system by the acceleration-velocity-displacement active controller was considered. Based on the spectral decomposition of quadratic symmetric pencil, a sufficient and necessary condition of the closed-loop to preserve no spill-over is provided. Using the receptances and system matrices, the parametric solutions of the PQEAP are characterized. Finally, a gradient-based optimization algorithm for the robust and minimum norm solution of the PQEAP is proposed. Numerical examples show the robustness and effectiveness of the proposed method.},
  archive      = {J_JMAA},
  author       = {Kang Zhao and Jiantian Wang and Fangting Deng},
  doi          = {10.1016/j.jmaa.2025.130048},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130048},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Robust and minimum norm partial eigenvalue assignment in singular vibration systems},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On critical logarithmic double phase problems with locally defined perturbation. <em>JMAA</em>, <em>555</em>(1), 130047. (<a href='https://doi.org/10.1016/j.jmaa.2025.130047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with critical logarithmic double phase problems of the form − div K ( u ) = g ( x , u ) + | u | p ⁎ − 2 u in Ω , u = 0 on ∂ Ω , where div K is the logarithmic double phase operator defined by div ( | ∇ u | p − 2 ∇ u + μ ( x ) ( log ⁡ ( e + | ∇ u | ) + | ∇ u | q ( e + | ∇ u | ) ) | ∇ u | q − 2 ∇ u ) , e is Euler's number, Ω ⊂ R N , N ≥ 2 , is a bounded domain with Lipschitz boundary ∂Ω, 1 < p < N , p < q < p ⁎ = N p N − p , 0 ≤ μ ( ⋅ ) ∈ L ∞ ( Ω ) and g : Ω × [ − ξ , ξ ] → R for ξ > 0 is a locally defined Carathéodory function satisfying a certain behavior near the origin. Based on appropriate truncation techniques and a suitable auxiliary problem, we prove the existence of a whole sequence of sign-changing solutions of the problem above which converges to 0 in the logarithmic Musielak-Orlicz Sobolev space W 0 1 , H log ( Ω ) and in L ∞ ( Ω ) .},
  archive      = {J_JMAA},
  author       = {Yino B. Cueva Carranza and Marcos T.O. Pimenta and Francesca Vetro and Patrick Winkert},
  doi          = {10.1016/j.jmaa.2025.130047},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130047},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On critical logarithmic double phase problems with locally defined perturbation},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the hausdorff measure of self-similar sets in qpd. <em>JMAA</em>, <em>555</em>(1), 130046. (<a href='https://doi.org/10.1016/j.jmaa.2025.130046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of self-similar sets and their fractal dimensions has been a central topic in geometric measure theory and fractal geometry. In this paper, we extend classical results on self-similar sets to the p -adic settings. Specifically, we investigate the Hausdorff measure and dimension of self-similar sets in Q p d , the d -dimensional vector space over the p -adic numbers. Our main results provide necessary and sufficient conditions for the open set condition (OSC) and strong open set condition (SOSC) in Q p d and establish the relationship between these conditions and the Hausdorff measure of the attractor.},
  archive      = {J_JMAA},
  author       = {Mamateli Kadir},
  doi          = {10.1016/j.jmaa.2025.130046},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130046},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On the hausdorff measure of self-similar sets in qpd},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On new approximations of a functional equation having monomials. <em>JMAA</em>, <em>555</em>(1), 130045. (<a href='https://doi.org/10.1016/j.jmaa.2025.130045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using a different direct method from the previous studies and the Banach fixed point theorem, we investigate the stability problem of a functional equation having monomials. The results of this paper improve the main results of [3] , [12] , [18] , [23] , [24] . Some examples are included for comparison with previous studies.},
  archive      = {J_JMAA},
  author       = {Hamid Khodaei},
  doi          = {10.1016/j.jmaa.2025.130045},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130045},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On new approximations of a functional equation having monomials},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weak fixed point property of order p with respect to orbits. <em>JMAA</em>, <em>555</em>(1), 130044. (<a href='https://doi.org/10.1016/j.jmaa.2025.130044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this note, weakly p -summable (resp. weakly p -summable and Dunford-Pettis) sequences in a Banach space are used to obtain a characterization of weak normal structure of order p (resp. Right normal structure of order p ). It is proved that a Banach space has weak normal structure of order p (resp. Right normal structure of order p ) if and only if it has the weak fixed point property of order p (resp. Right fixed point property of order p ) for non-expansive mappings with respect to orbits.},
  archive      = {J_JMAA},
  author       = {Halimeh Ardakani and Kamal Fallahi},
  doi          = {10.1016/j.jmaa.2025.130044},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130044},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Weak fixed point property of order p with respect to orbits},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Upper and lower bounds of the value function for optimal control in the wasserstein space. <em>JMAA</em>, <em>555</em>(1), 130043. (<a href='https://doi.org/10.1016/j.jmaa.2025.130043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the application of nonsmooth analysis in the Wasserstein space to finite-horizon optimal control problems for nonlocal continuity equations. We characterize the value function as a strict viscosity solution of the corresponding Bellman equation using the notions of ε -subdifferentials and ε -superdifferentials. The main paper's result is the fact that continuous subsolutions and supersolutions of this Bellman equation yield lower and upper bounds for the value function. These estimates rely on proximal calculus in the space of probability measures and the Moreau–Yosida regularization. Furthermore, the upper estimates provide a family of approximately optimal feedback strategies that realize the concept of proximal aiming.},
  archive      = {J_JMAA},
  author       = {Yurii Averboukh and Aleksei Volkov},
  doi          = {10.1016/j.jmaa.2025.130043},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130043},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Upper and lower bounds of the value function for optimal control in the wasserstein space},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Almost sure existence of global weak solutions for incompressible generalized navier-stokes equations. <em>JMAA</em>, <em>555</em>(1), 130042. (<a href='https://doi.org/10.1016/j.jmaa.2025.130042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the initial value problem of the incompressible generalized Navier-Stokes equations in torus T d with d ≥ 2 . The generalized Navier-Stokes equations are obtained by replacing the standard Laplacian in the classical Navier-Stokes equations by the fractional order Laplacian − ( − Δ ) α with α ∈ ( 2 3 , 1 ] . After an appropriate randomization on the initial data, we obtain the almost sure existence of global weak solutions for initial data being in H ˙ s ( T d ) with s ∈ ( 1 − 2 α , 0 ) .},
  archive      = {J_JMAA},
  author       = {Y.-X. Lin and Y.-G. Wang},
  doi          = {10.1016/j.jmaa.2025.130042},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130042},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Almost sure existence of global weak solutions for incompressible generalized navier-stokes equations},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Regularity for solutions of parabolic equations with anisotropic growth. <em>JMAA</em>, <em>555</em>(1), 130041. (<a href='https://doi.org/10.1016/j.jmaa.2025.130041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove the integrability for solutions of the nonlinear parabolic problem with anisotropic growth { u t − ∑ i = 1 n D i ( a i ( x , t , D u ) ) = f ( x , t ) in Q T = Ω × ( 0 , T ) , u ( x , 0 ) = 0 in Ω , u ( x , t ) = 0 on Γ = ∂ Ω × ( 0 , T ) for the model case of a i ( x , t , ξ ) ≈ | ξ i | p i − 2 ξ i , p i > 1 for i = 1 , ⋯ , n .}},
  archive      = {J_JMAA},
  author       = {Shuang Liang and Xuedan Zhao and Xinyue Zhai},
  doi          = {10.1016/j.jmaa.2025.130041},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130041},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Regularity for solutions of parabolic equations with anisotropic growth},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An approximate solution of a perturbed fokker-planck equation. <em>JMAA</em>, <em>555</em>(1), 130040. (<a href='https://doi.org/10.1016/j.jmaa.2025.130040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on finding an approximate solution of a kind of Fokker-Planck equation with time-dependent perturbations. A formulation of the approximate solution of the equation is constructed, and then the existence of the formulation is proved. The related Hamiltonian dynamical system explains the estimations. Examples of the Ornstein-Uhlenbeck process model and the nonlinear Langevin equation are used to validate the proposed results. Our work provides a more comprehensive understanding of the long-time behaviour of systems described by this Fokker-Planck equation and the corresponding stochastic differential equation.},
  archive      = {J_JMAA},
  author       = {Yan Luo and Kaicheng Sheng},
  doi          = {10.1016/j.jmaa.2025.130040},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130040},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {An approximate solution of a perturbed fokker-planck equation},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intermediate dimensions of measures: Interpolating between hausdorff and minkowski dimensions. <em>JMAA</em>, <em>555</em>(1), 130039. (<a href='https://doi.org/10.1016/j.jmaa.2025.130039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we define a family of dimensions for Borel measures that lie between the Hausdorff and Minkowski dimensions for measures, analogous to the intermediate dimensions of sets. Previously, Hare et al. in [11] defined families of dimensions that interpolate between the Minkowski and Assouad dimensions for measures. Additionally, Fraser, in [8] introduced an additional family of dimensions that interpolate between the Fourier and Sobolev dimensions of measures. Our results address a “gap” in the study of dimension interpolation for measures, almost completing the spectrum of intermediate dimensions for measures: from Hausdorff to Assouad dimensions. Furthermore, Theorem 3.13 can be interpreted as a “reverse Frostman” lemma for intermediate dimensions. We also obtain a capacity-theoretic definition that enables us to estimate the intermediate dimensions of pushforward measures by projections.},
  archive      = {J_JMAA},
  author       = {Nicolas E. Angelini and Ursula M. Molter and Jose M. Tejada},
  doi          = {10.1016/j.jmaa.2025.130039},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130039},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Intermediate dimensions of measures: Interpolating between hausdorff and minkowski dimensions},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Non-invertible mappings of linear PDEs to nonlinear PDEs through the symmetry-based method. <em>JMAA</em>, <em>555</em>(1), 130038. (<a href='https://doi.org/10.1016/j.jmaa.2025.130038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that the well-known Hopf–Cole transformation mapping the linear heat equation to the nonlinear Burgers' equation naturally extends to the mapping of any linear PDE to a non-invertibly equivalent nonlinear PDE. This mapping is obtained through the symmetry-based method by using the admitted obvious scaling symmetry in the dependent variable of any linear homogeneous PDE. Furthermore, each nontrivial point symmetry of any linear PDE yields a corresponding nonlocally related nonlinear PDE. The mapping relating the linear PDE and the corresponding nonlinear PDE is not one-to-one. As examples we consider the linear heat equation, the linear wave equation, Laplace's equation and the Helmholtz equation in two or more independent variables. We exhibit some exact solutions of the corresponding nonlinear system of PDEs from a known solution of the associated linear PDE. Moreover, we find nonlocal symmetries for the corresponding nonlocally related nonlinear systems of PDEs through the commutator relationship between point symmetries of the associated linear PDE.},
  archive      = {J_JMAA},
  author       = {Subhankar Sil and George Bluman},
  doi          = {10.1016/j.jmaa.2025.130038},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130038},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Non-invertible mappings of linear PDEs to nonlinear PDEs through the symmetry-based method},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The compactness of trudinger-moser type functionals with variable exponents for domains in RN. <em>JMAA</em>, <em>555</em>(1), 130037. (<a href='https://doi.org/10.1016/j.jmaa.2025.130037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the compactness property of several Trudinger-Moser type functionals with variable exponents. We establish various nearly optimal conditions on the variable exponents which assure the compactness or the noncompactness of functionals. We treat this problem both on bounded domains and the entire domain. The entire domain case needs the condition which excludes the so-called vanishing phenomena which has not been well treated so far together with the consideration of the concentration phenomena.},
  archive      = {J_JMAA},
  author       = {Masato Hashizume and Michinori Ishiwata and Xu Yan},
  doi          = {10.1016/j.jmaa.2025.130037},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130037},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {The compactness of trudinger-moser type functionals with variable exponents for domains in RN},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hamilton inequality for the p-laplacian on weighted graphs with the CDp⋅(m,K) curvature. <em>JMAA</em>, <em>555</em>(1), 130036. (<a href='https://doi.org/10.1016/j.jmaa.2025.130036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study Hamilton type gradient estimates for the p -Laplacian on weighted graphs. For p > 5 and some additional assumptions, we derive a more general gradient estimate of Hamilton type for positive solutions to the p -Laplacian heat equation on finite graphs satisfying the C D p ⋅ ( m , K ) curvature. The analogous result is also proved for locally finite graphs with bounded weighted vertex degree. As an application of our main results, we show that the corresponding Harnack inequality.},
  archive      = {J_JMAA},
  author       = {Yongtao Liu},
  doi          = {10.1016/j.jmaa.2025.130036},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130036},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Hamilton inequality for the p-laplacian on weighted graphs with the CDp⋅(m,K) curvature},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The complex structure of the teichmüller space of circle diffeomorphisms in the zygmund smooth class II. <em>JMAA</em>, <em>555</em>(1), 130035. (<a href='https://doi.org/10.1016/j.jmaa.2025.130035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our previous paper with the same title, we established the complex Banach manifold structure for the Teichmüller space of circle diffeomorphisms whose derivatives belong to the Zygmund class. This was achieved by demonstrating that the Schwarzian derivative map is a holomorphic split submersion. We also obtained analogous results for the pre-Schwarzian derivative map. In this second part of the study, we investigate the structure of the image of the pre-Schwarzian derivative map, viewing it as a fiber space over the Bers embedding of the Teichmüller space, and prove that it forms a real-analytic disk-bundle. Furthermore, we consider the little Zygmund class and establish corresponding results for the closed Teichmüller subspace consisting of mappings in this class. Finally, we construct the quotient space of this subspace in analogy with the asymptotic Teichmüller space and prove that the quotient Bers embedding and pre-Bers embedding are well-defined and injective, thereby endowing it with a complex structure modeled on a quotient Banach space.},
  archive      = {J_JMAA},
  author       = {Katsuhiko Matsuzaki},
  doi          = {10.1016/j.jmaa.2025.130035},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130035},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {The complex structure of the teichmüller space of circle diffeomorphisms in the zygmund smooth class II},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Wolff potential estimates for elliptic double obstacle problems with orlicz growth. <em>JMAA</em>, <em>555</em>(1), 130034. (<a href='https://doi.org/10.1016/j.jmaa.2025.130034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the solutions of the elliptic double obstacle problems with Orlicz growth involving measure data. Some pointwise estimates for the approximable solutions to these problems are obtained in terms of fractional maximal operators. Furthermore, we establish pointwise and oscillation estimates for the gradients of solutions via the nonlinear Wolff potentials, which in turn yield C 1 , α -regularity of solutions.},
  archive      = {J_JMAA},
  author       = {Qi Xiong and Zhenqiu Zhang and Lingwei Ma},
  doi          = {10.1016/j.jmaa.2025.130034},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130034},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Wolff potential estimates for elliptic double obstacle problems with orlicz growth},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Positive singular solutions of a certain elliptic PDE. <em>JMAA</em>, <em>555</em>(1), 130033. (<a href='https://doi.org/10.1016/j.jmaa.2025.130033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the existence of positive singular solutions for a system of partial differential equations on a bounded domain (1) { − Δ u = ( 1 + κ 1 ( x ) ) | ∇ v | p in B 1 ﹨ { 0 } , − Δ v = ( 1 + κ 2 ( x ) ) | ∇ u | p in B 1 ﹨ { 0 } , u = v = 0 on ∂ B 1 . We investigate the existence of positive singular solutions within B 1 , the unit ball centered at the origin in R N , under the conditions N ≥ 3 and N N − 1 < p < 2 . Additionally, we assume that κ 1 and κ 2 are non-negative, continuous functions satisfying κ 1 ( 0 ) = κ 2 ( 0 ) = 0 . Our system is an extension of the PDE studied by Aghajani et al. [1] under similar assumptions.}},
  archive      = {J_JMAA},
  author       = {Negar Mohammadnejad},
  doi          = {10.1016/j.jmaa.2025.130033},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130033},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Positive singular solutions of a certain elliptic PDE},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multiple zeta values and coefficients of laurent series expansion of beta function. <em>JMAA</em>, <em>555</em>(1), 130031. (<a href='https://doi.org/10.1016/j.jmaa.2025.130031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In [12] , we proved a translation formula for multiple zeta functions, which is analogous to that of Riemann zeta function proved by V. Ramaswami [11] . In this article we present a nice application of this formula. Particularly we express the coefficients of Laurent series expansion of one variable Beta function B ( s , 1 2 ) in terms of certain series involving multiple zeta values. As a consequence, we are able to calculate the values of these series recursively.},
  archive      = {J_JMAA},
  author       = {Dilip K. Sahoo},
  doi          = {10.1016/j.jmaa.2025.130031},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130031},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Multiple zeta values and coefficients of laurent series expansion of beta function},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Self-similar singularities for electron MHD. <em>JMAA</em>, <em>555</em>(1), 130029. (<a href='https://doi.org/10.1016/j.jmaa.2025.130029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study several types of self-similar solutions for the electron magnetohydrodynamics (MHD) without resistivity, including locally self-similar solutions and pseudo-self-similar solutions. We show that under certain conditions, these types of self-similar blowup solutions can be excluded.},
  archive      = {J_JMAA},
  author       = {Mimi Dai and Hannah Guerra and Chao Wu},
  doi          = {10.1016/j.jmaa.2025.130029},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130029},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Self-similar singularities for electron MHD},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generalised Hajłasz–Besov spaces on RD-spaces. <em>JMAA</em>, <em>555</em>(1), 130028. (<a href='https://doi.org/10.1016/j.jmaa.2025.130028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An RD space is a doubling measure metric space Ω with the additional property that it has a reverse doubling property. In this paper we introduce a new class of Hajłasz–Besov spaces on Ω and extend several results from classical theory, such as embeddings and Sobolev-type embeddings.},
  archive      = {J_JMAA},
  author       = {Joaquim Martín and Walter A. Ortiz},
  doi          = {10.1016/j.jmaa.2025.130028},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130028},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Generalised Hajłasz–Besov spaces on RD-spaces},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Traveling wave solutions in a discrete diffusive epidemic model with stage structure and nonlinear incidence rate. <em>JMAA</em>, <em>555</em>(1), 130027. (<a href='https://doi.org/10.1016/j.jmaa.2025.130027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to understand the geographical spread of infectious diseases, classical epidemic models should consider spatial effects. Compared to the continuous diffusion version, the discrete diffusive version will be more realistic and meaningful. To our knowledge, there are not many studies on discrete diffusive epidemic models, therefore, this article investigates the existence, nonexistence, and asymptotic behavior of traveling wave solutions for a discrete diffusive epidemic model incorporating stage structure and a nonlinear incidence rate. Concretely, to begin with, we obtain the basic reproduction number. And then, we get that the critical wave speed determines the existence and nonexistence of traveling wave solutions. Meanwhile, by establishing an appropriate Lyapunov functional and applying Lebesgue dominated convergence theorem, we derive the boundary asymptotic behavior of traveling wave solutions. Ultimately, we employ these results to two examples (i.e. discrete diffusion stage epidemic models).},
  archive      = {J_JMAA},
  author       = {Peng Yang},
  doi          = {10.1016/j.jmaa.2025.130027},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130027},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Traveling wave solutions in a discrete diffusive epidemic model with stage structure and nonlinear incidence rate},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage sheep brucellosis transmission dynamic model in a patchy environment: Stability analysis and optimization of transportation scheme. <em>JMAA</em>, <em>555</em>(1), 130026. (<a href='https://doi.org/10.1016/j.jmaa.2025.130026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cross-regional transport of sheep breaks geographical restrictions and expands the range of sheep, leading to the spread of brucellosis, one of the most widely spread zoonotic diseases transmitted by animals, and exposing more sheep and people to the threat of infection. To this end, a two-stage sheep brucellosis transmission dynamic model in a patchy environment is formulated based on the transmission characteristics of brucellosis. Firstly, the basic reproduction number is determined, and the global stabilities of disease-free, nontrivial boundary, and endemic equilibria are established, respectively. Subsequently, numerical simulations are applied to verify the correctness of the theoretical results. Finally, based on the recruitment rates of lambs and the basic reproduction number of two patches, the optimal transportation scheme for lambs and adult sheep is provided to reduce the risk of transmission of brucellosis.},
  archive      = {J_JMAA},
  author       = {Shuangjie Bai and Boqiang Cao and Ting Kang and Qingyun Wang},
  doi          = {10.1016/j.jmaa.2025.130026},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130026},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {A two-stage sheep brucellosis transmission dynamic model in a patchy environment: Stability analysis and optimization of transportation scheme},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Continuity of multi-parameter adjoint paraproduct operators. <em>JMAA</em>, <em>555</em>(1), 130025. (<a href='https://doi.org/10.1016/j.jmaa.2025.130025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the boundedness of inhomogeneous Journé's operators on multi-parameter local Hardy spaces. Recently, a class of local multi-parameter paraproducts was shown to obstruct particular T1-type theorems in this context. In this paper, we study the boundedness of the adjoints of these local multi-parameter paraproducts. The theory is more challenging due to the lack of vanishing moments.},
  archive      = {J_JMAA},
  author       = {Wei Ding and Yongjia Xue and Tianyu Zhang and Yueping Zhu},
  doi          = {10.1016/j.jmaa.2025.130025},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130025},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Continuity of multi-parameter adjoint paraproduct operators},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stability and averaging principle for distribution dependent SDEs driven by G-brownian motion. <em>JMAA</em>, <em>555</em>(1), 130024. (<a href='https://doi.org/10.1016/j.jmaa.2025.130024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the asymptotic behavior for distribution dependent stochastic differential equations driven by G -Brownian motion ( G -SDEs). Under Lipschitz condition, we study exponentially second-moment ultimate boundedness, stability and averaging principle. Under non-Lipschitz condition, we first prove the existence and uniqueness for distribution dependent G -SDEs by adopting Carathéodory approximation approach. In particular, the fast time oscillating distribution dependent G -SDEs is treated and its solution can be approximated by the averaged distribution dependent G -SDEs under averaging condition. Additionally, two illustrative examples are provided to validate the averaged-distribution-dependent G -SDEs.},
  archive      = {J_JMAA},
  author       = {Wensheng Yin and Yong Ren and Kaile Cao},
  doi          = {10.1016/j.jmaa.2025.130024},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130024},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Stability and averaging principle for distribution dependent SDEs driven by G-brownian motion},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stochastic very weak solutions to parabolic equations with singular coefficients. <em>JMAA</em>, <em>555</em>(1), 130023. (<a href='https://doi.org/10.1016/j.jmaa.2025.130023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A class of stochastic parabolic equations with singular potentials is analyzed within the chaos expansion framework, utilizing the Wick product to handle the multiplication of generalized stochastic processes. The analysis combines the chaos expansion method from white noise analysis with the concept of very weak solutions from partial differential equation theory. The stochastic very weak solution to the parabolic evolution problem is defined, and its existence and uniqueness are established. For sufficiently regular potentials and data, we demonstrate the consistency of the stochastic very weak solution with a stochastic weak solution. An illustrative example is provided, potential applications are reviewed, and future challenges are outlined.},
  archive      = {J_JMAA},
  author       = {Snežana Gordić and Tijana Levajković and Ljubica Oparnica},
  doi          = {10.1016/j.jmaa.2025.130023},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130023},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Stochastic very weak solutions to parabolic equations with singular coefficients},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the weak sard property. <em>JMAA</em>, <em>555</em>(1), 130022. (<a href='https://doi.org/10.1016/j.jmaa.2025.130022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {If f : [ 0 , 1 ] 2 → R is of class C 2 then Sard's theorem implies that f has the following relaxed Sard property : the image under f of the Lebesgue measure restricted to the critical set of f is a singular measure. We show that for C 1 , α functions with α < 1 this property is strictly stronger than the weak Sard property introduced by Alberti, Bianchini and Crippa, while for any monotone continuous function these two properties are equivalent. We also show that even in the one-dimensional setting Hölder regularity is not sufficient for the relaxed Sard property.},
  archive      = {J_JMAA},
  author       = {Roman V. Dribas and Andrew S. Golovnev and Nikolay A. Gusev},
  doi          = {10.1016/j.jmaa.2025.130022},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130022},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On the weak sard property},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Orbit counting for sofic shift-flip systems. <em>JMAA</em>, <em>555</em>(1), 130021. (<a href='https://doi.org/10.1016/j.jmaa.2025.130021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sofic shift is a discrete dynamical system which consists of bi-infinite sequences of labels corresponding to paths in a labeled graph. If it is subjected to a certain automorphism called a flip, then it forms a sofic shift-flip system. The flip system is regarded as an action of infinite dihedral group on the sofic shift. The distribution of finite orbits under this action may indicate the complexity of the flip system. For this purpose, the prime orbit counting function is used to describe the growth of the finite orbits. In the literature, the asymptotic behavior of the counting function has been obtained for shift-flip systems of finite type (SFT-flip systems), which are a subclass of the sofic shift-flip systems. In this paper, we will prove a similar asymptotic result for a sofic shift-flip system. The proof relies on the construction of an underlying SFT-flip system to serve as a presentation of the sofic shift-flip system. The number of finite orbits in the said system is then estimated from the SFT-flip system via combinatorial calculations. Our finding here is complete since it is applicable to both irreducible and reducible sofic shifts.},
  archive      = {J_JMAA},
  author       = {Azmeer Nordin and Mohd Salmi Md Noorani and Mohd Hafiz Mohd},
  doi          = {10.1016/j.jmaa.2025.130021},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130021},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Orbit counting for sofic shift-flip systems},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inhomogeneous generalized fractional bessel differential equations in complex domain. <em>JMAA</em>, <em>555</em>(1), 130020. (<a href='https://doi.org/10.1016/j.jmaa.2025.130020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores inhomogeneous generalized fractional-order Bessel differential equations in the complex domain with arbitrary-order δ ( δ = τ + ι a ; 1 < τ ≤ 2 , a ∈ R + ) using Riemann-Liouville (R-L) fractional operators. The study establishes the existence of holomorphic solutions through the power series method, considering the concept of radius of convergence. Conditions for the unique existence of holomorphic solutions in the complex domain are identified using fixed point theory and the Rouche theorem. Additionally, the paper demonstrates that the solution, particularly for infinite series of fractional power, satisfies the generalized Ulam-Hyers stability. Furthermore, when δ = 2 , the solution to the inhomogeneous Bessel differential equation takes the form of Bessel functions of the first kind, denoted as J 0 ( w ) .},
  archive      = {J_JMAA},
  author       = {Babli Yadav and Trilok Mathur and Shivi Agarwal},
  doi          = {10.1016/j.jmaa.2025.130020},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130020},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Inhomogeneous generalized fractional bessel differential equations in complex domain},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Limit theorems and fractal properties of digit gaps in pierce expansions. <em>JMAA</em>, <em>555</em>(1), 130019. (<a href='https://doi.org/10.1016/j.jmaa.2025.130019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we revisit Shallit's results on the law of large numbers, the central limit theorem, and the law of the iterated logarithm for the digits of Pierce expansions. We extend these limit theorems to the setting of digit gaps in Pierce expansions, showing that digit gaps exhibit the same limit behavior as the digits themselves. However, the fractal properties of digit gaps differ significantly from those of the digits. To capture this difference, we compute the Hausdorff dimension of the exceptional sets associated with the law of large numbers for digit gaps and obtain explicit formulas for these dimensions.},
  archive      = {J_JMAA},
  author       = {Liuhui Lu and Cai Long and Lei Shang},
  doi          = {10.1016/j.jmaa.2025.130019},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130019},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Limit theorems and fractal properties of digit gaps in pierce expansions},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Asymptotic behaviors of solutions for timoshenko systems with memory damping. <em>JMAA</em>, <em>555</em>(1), 130017. (<a href='https://doi.org/10.1016/j.jmaa.2025.130017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the asymptotic behaviors of solutions for Timoshenko systems with interior memory damping, subject to the feedback-type boundary conditions. The memory kernel function possesses a positive definite primitive, allowing it to vary in sign and oscillate. By employing multiplier methods and constructing auxiliary systems, we establish asymptotic stability and exponential stability of the system. The existing work studied systems corresponding to positive definite operators. The present paper extends the current theory to systems corresponding to non-positive definite operators.},
  archive      = {J_JMAA},
  author       = {Chan Li and Jia-Yi Li and Li-Jun Wu},
  doi          = {10.1016/j.jmaa.2025.130017},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130017},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Asymptotic behaviors of solutions for timoshenko systems with memory damping},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the robin problems of degenerate elliptic equations. <em>JMAA</em>, <em>555</em>(1), 130011. (<a href='https://doi.org/10.1016/j.jmaa.2025.130011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let Ω be a bounded smooth domain in R N ( N ≥ 3 ) with 0 ∈ Ω . Positive weak solutions of the Robin problems of a class of degenerate elliptic equations are obtained via variational methods and new embeddings related to new Caffarelli-Kohn-Nirenberg inequalities. Meanwhile, the further regularities of the weak solutions are studied, especially, the regularities at the singular point x = 0 of the solutions are obtained.},
  archive      = {J_JMAA},
  author       = {Xiaohong Guan and Zongming Guo and Fangshu Wan},
  doi          = {10.1016/j.jmaa.2025.130011},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130011},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On the robin problems of degenerate elliptic equations},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generalized m-quasi-einstein metrics with certain conditions on the potential vector field. <em>JMAA</em>, <em>555</em>(1), 130004. (<a href='https://doi.org/10.1016/j.jmaa.2025.130004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we have studied generalized m -quasi-Einstein and m -quasi-Einstein manifold ( M n , g , X , λ ) satisfying certain conditions on the potential vector field. First, we classify a compact m -quasi-Einstein metric with geodesic potential and non-positive Ricci tensor. Then, we establish that the potential vector field X of an m -quasi-Einstein metric is Killing if X is an infinitesimal harmonic transformation and geodesic. Further, we classify complete non-compact m -quasi-Einstein metric with Ricci tensor S ( X , X ) ≤ 0 when the potential vector field X is an infinitesimal harmonic transformation, or its energy is finite. Furthermore, we establish that the potential vector field X of a compact generalized m -quasi-Einstein manifold is Killing when it satisfies d i v X = 0 . Finally, we prove that a generalized m -quasi-Einstein manifold is a warped product when its potential vector field is a non-homothetic conformal Killing.},
  archive      = {J_JMAA},
  author       = {Amalendu Ghosh},
  doi          = {10.1016/j.jmaa.2025.130004},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {130004},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Generalized m-quasi-einstein metrics with certain conditions on the potential vector field},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). System tautochrone motion path for centrifugal pendulum vibration absorbers. <em>JMAA</em>, <em>555</em>(1), 129994. (<a href='https://doi.org/10.1016/j.jmaa.2025.129994'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Centrifugal Pendulum Vibration Absorbers (CPVAs) have been in use for over a century and have become integral in addressing torsional vibrations in rotating machinery across a wide range of applications in both the aerospace and automotive industries. Proper tuning of the pendulum, such that it counteracts the engine-order fluctuating torques acting on the rotor during operation, enables the device to effectively attenuate vibrations across the full range of engine operating speeds. However, as operating amplitudes increase, the dynamic stability and performance of these passive torsional smoothing devices are highly dependent upon the motion path defined for their pendulous masses. In fact, the pendulum natural frequency commonly shifts as a function of their swing amplitude. Tautochronic motion paths can eliminate this resonant frequency shift as excitation levels increase and can thus overcome the common detuning issues associated with existing paths within the epicycloid family. At present, approximate tautochrone motion paths for CPVAs are derived using simplifying assumptions, which uncouples the pendulum and rotor dynamics. In this paper, using variational calculus, a system tautochrone motion path that accounts for the pendulum to rotor inertial coupling is derived. Its use results in tautochronic motion of the entire oscillatory system including both pendulum and rotor. Numerical simulations of the system forced response show that a system tautochrone motion path has distinct vibration control advantages, including enhanced stability and vibration correction performance. Most fundamentally, a new concept of order-tuning in these systems is for the first time identified, where a pendulum following a system tautochrone motion path retains a fixed order tuning for all feasible system energy levels. That is, the paper presents a more exact order tuning concept, expressed in terms of the square root of system energy, thereby accounting for pendulum motion in addition to rotor speed effects on tuning order.},
  archive      = {J_JMAA},
  author       = {Ryan Monroe and Bruce Geist},
  doi          = {10.1016/j.jmaa.2025.129994},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {129994},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {System tautochrone motion path for centrifugal pendulum vibration absorbers},
  volume       = {555},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jocs">JOCS - 16</h2>
<ul>
<li><details>
<summary>
(2025). Approach to global path planning and optimization for mobile robots based on multi-local gravitational potential fields bias-P-RRT*. <em>JOCS</em>, <em>92</em>, 102718. (<a href='https://doi.org/10.1016/j.jocs.2025.102718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sampling-based method has strong environmental adaptability and probability completeness, providing an effective solution for mobile robot path planning. However, the conventional rapidly-exploring random trees (RRT) algorithm often presents slow convergence and inefficient search paths. In this sense, this paper proposes a mobile robot path planning and optimization algorithm based on P-RRT* that incorporates multi-local gravitational potential fields and bias sampling, i.e., multi-local gravitational potential fields Bias-P-RRT* (MLGPFB-P-RRT*). The algorithm adds a local gravitational field between the starting point and the target point to better guide the direction of random tree growth, and directly connects the center of the last local gravitational field to the target point to accelerate the convergence of the random tree at the target point. Meanwhile, the introduction of bias sampling based on local potential fields to optimize the generation quality of random points, thereby improving the generation position of new nodes and reducing the randomness of sampling for mobile robots in the workspace. Then, a collision detection method between sampling nodes and obstacles was developed, which can quickly determine the feasibility of the sampling path. Finally, the generated path is optimized and smoothed through pruning optimization and quadratic B-spline function. A series of simulation studies and mobile robot experiments demonstrate the superior performance of the proposed algorithm.},
  archive      = {J_JOCS},
  author       = {Leiwen Yuan and Jingwen Luo},
  doi          = {10.1016/j.jocs.2025.102718},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102718},
  shortjournal = {J. Comput. Sci.},
  title        = {Approach to global path planning and optimization for mobile robots based on multi-local gravitational potential fields bias-P-RRT*},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid nutcracker optimization algorithm for multi-objective energy scheduling in grid-connected microgrid systems. <em>JOCS</em>, <em>92</em>, 102716. (<a href='https://doi.org/10.1016/j.jocs.2025.102716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing demand for clean and sustainable energy has driven rapid advancements in hybrid microgrid systems to mitigate climate change and environmental degradation. This paper proposes a novel multi-objective scheduling framework for hybrid microgrids aimed at minimizing operational costs while maximizing environmental benefits. To efficiently solve this complex optimization problem, we introduce a Hybrid Nutcracker Optimization Algorithm (HNOA), which combines the recently developed Nutcracker Optimization Algorithm (NOA) with the Bat Algorithm (BAT). This hybridization enhances NOA’s exploration–exploitation balance and search capability, as demonstrated by rigorous validation on 12 benchmark functions. HNOA achieves superior accuracy and computational efficiency compared to several state-of-the-art metaheuristics. The proposed HNOA is then applied to solve the scheduling of a grid-connected hybrid microgrid under various scenarios to evaluate its performance. Simulation results indicate that the optimal microgrid configuration, consisting of PV/WT/turbine/diesel/battery, achieves an investment cost of 80,789.02 yuan. The findings of this study offer valuable insights for advancing renewable energy integration and promoting environmental sustainability.},
  archive      = {J_JOCS},
  author       = {Yiwei Liu and Yinggan Tang and Changchun Hua},
  doi          = {10.1016/j.jocs.2025.102716},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102716},
  shortjournal = {J. Comput. Sci.},
  title        = {Hybrid nutcracker optimization algorithm for multi-objective energy scheduling in grid-connected microgrid systems},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Darcy-scale digital core models for rock properties upscaling and computational domain reduction. <em>JOCS</em>, <em>92</em>, 102715. (<a href='https://doi.org/10.1016/j.jocs.2025.102715'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of Digital Rock Physics (DRP) requires the elaboration of robust techniques for closing the gaps between different scales of rock studies (upscaling). The upscaling workflows are especially needed to support the applicability of DRP for heterogeneous rocks. Basically, DRP involves two primary stages: model construction and simulation of physical processes on the models created. For heterogeneous rocks, there is an inherent trade-off between the spatial resolution of the data and the representativeness of the model size. The primary objective of this study was to implement and test a technique for upscaling digital core models from microscale to macroscale, enabling the computation of rock properties while accounting for heterogeneity of various scales. The upscaling is based on establishing correlations between tomography data of different resolutions and transforming low-resolution tomography into a multi-class model according to the defined correlation. The convolutional neural network for high-resolution tomography data was considered as the optimal algorithm for transforming low-resolution tomography into a multi-class model. The output of the neural network was an upscaled model of lower resolution than the original tomography image. Each cell in the upscaled model belonged to one of several types of formation, whose generalized characteristics were determined on the basis of the analysis of high-resolution tomography data. To validate the upscaling technique, we constructed a digital model of a complex carbonate reservoir based on data from multi-scale microtomography ( μ CT). A Darcy-scale model has been used and validated as a multi-class model, enabling the computation of flows in pore samples of various scales. By incorporating diverse pore space structures as different classes in the Darcy-scale model, it is possible to preserve the substantial physical size of the model while enhancing its level of complexity.},
  archive      = {J_JOCS},
  author       = {Denis Orlov and Batyrkhan Gainitdinov and Dmitry Koroteev},
  doi          = {10.1016/j.jocs.2025.102715},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102715},
  shortjournal = {J. Comput. Sci.},
  title        = {Darcy-scale digital core models for rock properties upscaling and computational domain reduction},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical study of two-dimensional sediment transport using momentum-conserving staggered grid scheme. <em>JOCS</em>, <em>92</em>, 102714. (<a href='https://doi.org/10.1016/j.jocs.2025.102714'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sediment transport plays a crucial role in the evolution of bed morphology through deposition and erosion. This study presents numerical simulations of two-dimensional sediment transport induced by fluid flow. The fluid-sediment interaction is governed by a capacity model, i.e., the coupled system of shallow water and Exner equations, a simplification of more physically advanced non-capacity models. The system is solved using a momentum-conserving staggered grid (MCS) scheme. Model validation is performed using the Meyer-Peter and Müller (MPM) bedload transport formula, applied to experimental data from dam-break flows in various channel configurations. The proposed method successfully reproduces trends in the evolution of the water surface and quasi-steady sediment profiles. In general, the MCS scheme provides more accurate water level predictions than the numerical benchmark schemes. Although the predictions of maximum depths of deposition and erosion are less accurate, the overall results are consistent with those obtained from non-capacity models. Furthermore, the model is applied to the Kampar River estuary to simulate sediment transport due to the tidal bore.},
  archive      = {J_JOCS},
  author       = {Riski Kurniawan and Sri Redjeki Pudjaprasetya and Rani Sulvianuri},
  doi          = {10.1016/j.jocs.2025.102714},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102714},
  shortjournal = {J. Comput. Sci.},
  title        = {Numerical study of two-dimensional sediment transport using momentum-conserving staggered grid scheme},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cellular automaton towards structural balance—Long cycles of link dynamics. <em>JOCS</em>, <em>92</em>, 102712. (<a href='https://doi.org/10.1016/j.jocs.2025.102712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A cellular automaton is defined on a line graph of a fully connected network. The automaton rule drives the system to a structural balance in most cases. Here, we investigate cycles with special symmetries, the so-called ’perfect cycles’ Burda et al. (2022). Two new characteristics of the cycles are investigated, as potential markers of perfect cycles: an equivalence of sets of states attained after external damage of links, and the homogeneity of the distribution of phase shifts between local trajectories. Only the second characteristic works as a criterion of the perfectness of the cycles. The results can be useful for generating pseudorandom numbers.},
  archive      = {J_JOCS},
  author       = {Malgorzata J. Krawczyk and Krzysztof Kułakowski},
  doi          = {10.1016/j.jocs.2025.102712},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102712},
  shortjournal = {J. Comput. Sci.},
  title        = {A cellular automaton towards structural balance—Long cycles of link dynamics},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive hamiltonian circuit of virtual sample generation for a small dataset. <em>JOCS</em>, <em>92</em>, 102711. (<a href='https://doi.org/10.1016/j.jocs.2025.102711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small datasets often lead to poor performance of data-driven prediction models due to uneven data distribution and large data spacing. One popular approach to address this issue is to use virtual samples during machine learning (ML) model training. This study proposes a Hamiltonian Circuit Virtual Sample Generation (HCVSG) method to distribute virtual samples generated using interpolation techniques while integrating the K-Nearest Neighbors (KNN) algorithm in model development. The Hamiltonian circuit is chosen because it doesn’t depend on the distribution assumption and provides multiple circuits that allow adaptive sample distribution, allowing the selection of circuits that produce minimum errors. This method supports improving feature-target correlation, reducing the risk of overfitting, and stabilizing error values as model complexity increases. Applying this method to three datasets in material research (MLCC, PSH, and EFD) shows that HCVSG significantly improves prediction accuracy compared to conventional KNN and eight MTD-based methods. The distribution of virtual samples along the Hamiltonian circuit helps fill the information gap and makes the data distribution more even, ultimately improving the predictive model's performance.},
  archive      = {J_JOCS},
  author       = {Totok Sutojo and Supriadi Rustad and Muhamad Akrom and Wahyu Aji Eko Prabowo and De Rosal Ignatius Moses Setiadi and Hermawan Kresno Dipojono and Yoshitada Morikawa},
  doi          = {10.1016/j.jocs.2025.102711},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102711},
  shortjournal = {J. Comput. Sci.},
  title        = {An adaptive hamiltonian circuit of virtual sample generation for a small dataset},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tuning sensitivity of black phosphorene surface doped SnS, SnSe, GeS, and GeSe quantum dots toward water molecule and other small toxic molecules. <em>JOCS</em>, <em>92</em>, 102707. (<a href='https://doi.org/10.1016/j.jocs.2025.102707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, Density Functional Theory (DFT) was employed to investigate the impact of SnS, GeS, SnSe, and GeSe quantum dots doped black phosphorene on the sensitivity of black phosphorene toward various adsorbed gas molecules namely NO 2 and H 2 S. The interaction of H 2 O molecule with doped black phosphorene surface is also investigated to evaluate the impact of humidity on the sensing response. The results revealed the large electronic changes in bands distribution upon exposure to the selected gas molecules, giving rise to a variation in the electronic band nature from hole to electron doping which can promote the electrical conductivity and the sensing properties of the doped phosphorene structures.},
  archive      = {J_JOCS},
  author       = {Mamori Habiba and Moatassim Hajar and El Kenz Abdallah and Benyoussef Abdelilah and Taleb Abdelhafed and Abdel Ghafour El Hachimi and Zaari Halima},
  doi          = {10.1016/j.jocs.2025.102707},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102707},
  shortjournal = {J. Comput. Sci.},
  title        = {Tuning sensitivity of black phosphorene surface doped SnS, SnSe, GeS, and GeSe quantum dots toward water molecule and other small toxic molecules},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CKDTA: A chemical knowledge-enhanced framework for drug–target affinity prediction. <em>JOCS</em>, <em>92</em>, 102706. (<a href='https://doi.org/10.1016/j.jocs.2025.102706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate drug–target affinity (DTA) prediction is a cornerstone of efficient drug discovery, as it directly accelerates the screening of potential therapeutic candidates, reduces the cost of preclinical experiments, and shortens the development cycle of new drugs. However, existing deep learning-based methods face two main challenges: (I) Purely data-driven approaches struggle to capture the functional semantics of molecules, such as the role of specific functional regions and chemical element properties in binding interactions, due to the lack of integration with chemical prior knowledge, leading to unreliable predictions; (II) the integration of topological structure from graphs and long-range dependencies from sequences is insufficient, often failing to capture complementary features, limiting the model’s generalization ability, especially for novel drugs or targets commonly encountered in early drug discovery . To address these issues, we propose CKDTA , a C hemical K nowledge Enhanced framework for D rug- T arget A ffinity prediction. Our framework introduces two key innovations: (1) a chemical knowledge-enhanced molecular modeling approach, which constructs a multi-layer molecular graph incorporating atom-level features, chemical element information, and functional regions, enabling the capture of functional semantics through a hierarchical attention mechanism, while leveraging chemical prior knowledge; (2) a co-attention module designed to optimize sequence interaction information by leveraging graph-based interaction data, compensating for the lack of spatial structural information in sequence data. This module fully exploits the topological structure of graphs and the long-range dependencies in sequences, capturing complementary features. Extensive experiments on benchmark datasets demonstrate that CKDTA outperforms state-of-the-art methods. Furthermore, cold-start experiments validate its generalizability, highlighting its potential for drug discovery applications.},
  archive      = {J_JOCS},
  author       = {Xingran Zhao and Yanbu Guo and Bingyi Wang and Weihua Li},
  doi          = {10.1016/j.jocs.2025.102706},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102706},
  shortjournal = {J. Comput. Sci.},
  title        = {CKDTA: A chemical knowledge-enhanced framework for drug–target affinity prediction},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient numerical simulation of variable-order fractional diffusion processes with a memory kernel. <em>JOCS</em>, <em>92</em>, 102705. (<a href='https://doi.org/10.1016/j.jocs.2025.102705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion equations are fundamental in modeling the transport of heat, mass, or contaminants in porous media. However, classical models often fail to capture the anomalous diffusion behavior inherent in heterogeneous and memory-dependent materials. To address this, we investigate a fractional diffusion integro-differential equation involving variable-order derivatives in both time and space, subject to suitable conditions. The solutions are shown to exist and be unique through the rigorous application of fixed-point theorems. A finite difference-based numerical scheme is formulated to handle the variable-order fractional operators and convolution-type integral terms efficiently. Stability analysis confirms the accuracy and robustness of the method. In addition, approximate solutions are computed for three representative cases:(i) constant-order fractional diffusion ( α = constant ), (ii) time-dependent order α ( t ) , and (iii) fully variable-order α ( x , t ) . By incorporating variable order dynamics and integro-differential structures, this work extends conventional models and provides a unified framework for simulating complex transport processes in porous media.},
  archive      = {J_JOCS},
  author       = {Sabita Bera and Mausumi Sen and Sujit Nath},
  doi          = {10.1016/j.jocs.2025.102705},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102705},
  shortjournal = {J. Comput. Sci.},
  title        = {Efficient numerical simulation of variable-order fractional diffusion processes with a memory kernel},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical solution of the biological SIR model for COVID-19 with convergence analysis. <em>JOCS</em>, <em>92</em>, 102704. (<a href='https://doi.org/10.1016/j.jocs.2025.102704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the numerical solution of the biological Susceptible–Infectious–Recovered model for COVID-19 over extended time intervals using the shifted Chebyshev polynomial collocation method. Initially, the original problem is reformulated into a nonlinear Volterra integral equation for the susceptible population. The shifted Chebyshev polynomials are then employed to derive the numerical solution. A comprehensive convergence analysis of the collocation method is conducted to ensure the reliability and accuracy of the proposed approach. Finally, numerical simulations are performed for various parameter configurations that influence the system’s coefficients. Our method is compared with existing approaches, providing insights into the model’s dynamics under different conditions.},
  archive      = {J_JOCS},
  author       = {Walid Remili and Wen-Xiu Ma},
  doi          = {10.1016/j.jocs.2025.102704},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102704},
  shortjournal = {J. Comput. Sci.},
  title        = {Numerical solution of the biological SIR model for COVID-19 with convergence analysis},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decomposition based imputation algorithm for long consecutive missing atmospheric pollution data and its application. <em>JOCS</em>, <em>92</em>, 102697. (<a href='https://doi.org/10.1016/j.jocs.2025.102697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the intensification of environmental air pollution, the impact of air pollutants on both the ecological environment and human health has attracted widespread attention. However, due to the relatively late introduction of environmental monitoring systems, there were long consecutive missing values in early pollutant data. In this paper, we propose a decomposition-based imputation method for long consecutive missing pollution data. Firstly, wavelet coherence analysis is employed to investigate the periodic relationship between the pollution data and the relevant air data, decomposing them into periodic and non-periodic components. Then, machine learning and transfer learning are used to impute the periodic and non-periodic components, respectively. Furthermore, the effectiveness of the method is validated on artificially missing NO 2 and SO 2 concentration data from five regions of China. Comparison results show that the proposed method significantly outperforms some other imputation methods in the literature in terms of both mean absolute error and mean absolute percentage error. Finally, the proposed imputation method is applied in the study of accelerated aging of polycarbonate materials. Experimental results show that the predictive accuracy of the aging model is improved when using the imputed pollutant data.},
  archive      = {J_JOCS},
  author       = {Xinyi Wei and Hao Meng and Lizhen Shao and Dongmei Fu and Lingwei Ma and Dawei Zhang},
  doi          = {10.1016/j.jocs.2025.102697},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102697},
  shortjournal = {J. Comput. Sci.},
  title        = {A decomposition based imputation algorithm for long consecutive missing atmospheric pollution data and its application},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Helium focused ion beam damage in silicon: Physics-informed neural network modeling of helium bubble nucleation and early growth. <em>JOCS</em>, <em>92</em>, 102696. (<a href='https://doi.org/10.1016/j.jocs.2025.102696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the time and cost required to obtain large datasets limit the application of data-driven machine learning in nanoscale manufacturing. Here, we focus on predicting the nanoscale damage induced by helium focused ion beams (He-FIBs) on silicon substrates. We briefly review the most relevant atomistic defects and the partial differential equations (PDEs), or rate equations, that describe the mutual creation and annihilation of the defects, eventually leading to the amorphization of the substrate and, the nucleation and early growth of helium bubbles. The novelty comes from the use of a physics-informed neural network (PINN) to simulate quantitatively the evolution of the bubbles, thus bypassing the dataset availability problem. As usual, the proposed PINN learns the underlying physics through the incorporation of the residuals of the PDEs and corresponding Initial Conditions (ICs) and Boundary Conditions (BCs) in the network’s loss function. Meanwhile, the system of PDEs poses some challenges to the PINN modeling strategy. We find that (i) hard constraints need to be imposed on the network output in order to satisfy both BCs and ICs, (ii) all the inputs and outputs of the PINN need to be cautiously normalized to ensure convergence during training, and (iii) customized weights need to be carefully applied to all the PDE loss terms in order to balance their contributions, thus improving the accuracy of the PINN predictions. Once trained, the network achieves good prediction accuracy over the entire space-time domain for various ion beam energies and doses. Comparisons are provided against previous experiments and traditional numerical simulations, which are also implemented in this study using the Finite Difference Method (FDM). While the L2 relative errors for all collocated points remain below 10%, the accuracy of the PINN decreases at lower beam energies and larger ion doses, due to the presence of higher numerical gradients.},
  archive      = {J_JOCS},
  author       = {Shupeng Gao and Qi Li and M.A. Gosalvez and Xi Lin and Yan Xing and Zaifa Zhou and Qianhuang Chen},
  doi          = {10.1016/j.jocs.2025.102696},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102696},
  shortjournal = {J. Comput. Sci.},
  title        = {Helium focused ion beam damage in silicon: Physics-informed neural network modeling of helium bubble nucleation and early growth},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving the dopant diffusion dynamics with physics-informed neural networks. <em>JOCS</em>, <em>92</em>, 102695. (<a href='https://doi.org/10.1016/j.jocs.2025.102695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulation plays a crucial role in the semiconductor chip manufacturing. In particular, process simulation is primarily used to solve the dopant diffusion dynamics, which describes the temporal evolution of doping profiles during the thermal annealing process. The diffusion dynamics constitutes a multiscale problem, formulated as a set of coupled partial differential equations (PDEs) with respect to the concentration of dopants and point defects. In this paper, we demonstrate that Physics-Informed Neural Networks (PINNs) can accurately predict not only the evolution of the doping profile, but also the unknown physical parameters, specifically the diffusivities appearing as PDE coefficients. Furthermore, we propose a physics-informed calibration method, which performs PDE-constrained optimization by leveraging a pre-trained PINN model. We experimentally verify that this post-processing significantly improves the accuracy of coefficients fine-tuning. To the best of our knowledge, this is the first demonstration of an annealing simulation for the semiconductor diffusion process using a physics-informed machine learning approach. This framework is expected to enable more efficient calibration of simulation parameters based on measurement data.},
  archive      = {J_JOCS},
  author       = {Sungyeop Lee and Jisu Ryu and Young-Gu Kim and Dae Sin Kim and Hiroo Koshimoto and Jaeshin Park},
  doi          = {10.1016/j.jocs.2025.102695},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102695},
  shortjournal = {J. Comput. Sci.},
  title        = {Solving the dopant diffusion dynamics with physics-informed neural networks},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on pest control models based on nonlinear threshold control. <em>JOCS</em>, <em>92</em>, 102694. (<a href='https://doi.org/10.1016/j.jocs.2025.102694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pest number trigger threshold strategy has been widely used in the control of pests in agricultural production. In this study, pest populations are managed by using an integrated nonlinear threshold function and a saturation function. The existence conditions of various equilibrium points and sliding sections in the system are derived. Theoretical analysis and numerical simulation results show the existence of boundary equilibrium bifurcations, tangency bifurcations and limit cycle bifurcations caused by discontinuous boundary. It is worth noting that persistence and non-smooth folding can be observed in the boundary equilibrium bifurcations. At the same time, because the nonlinear threshold control strategy is adopted in this study, the change of the sliding section of the model is more complicated. The numerical simulation results show that if there is an unstable focus in the model, a sliding homoclinic cycle will appear with the occurrence of boundary saddle point bifurcation, and then form a crossing limit cycle. The sensitivity analysis results of the system show that if the threshold level is too low, the control measures do not achieve the desired results. Too high threshold selection will cause unnecessary economic losses. Therefore, our results show that an appropriate threshold should be set to reduce economic losses while ensuring that the number of pests is in a lower stable state.},
  archive      = {J_JOCS},
  author       = {Yongfeng Li and Leyan Liang and Zhong Zhao},
  doi          = {10.1016/j.jocs.2025.102694},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102694},
  shortjournal = {J. Comput. Sci.},
  title        = {A study on pest control models based on nonlinear threshold control},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Private linear equation solving: An application to federated learning and extreme learning machines. <em>JOCS</em>, <em>92</em>, 102693. (<a href='https://doi.org/10.1016/j.jocs.2025.102693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In federated learning, multiple devices compute each a part of a common machine learning model using their own private data. These partial models (or their parameters) are then exchanged in a central server that builds an aggregated model. This sharing process may leak information about the data used to train them. This problem intensifies as the machine learning model becomes simpler, indicating a higher risk for single-hidden-layer feedforward neural networks, such as extreme learning machines. In this paper, we establish a mechanism to disguise the input data to a system of linear equations while guaranteeing that the modifications do not alter the solutions, and propose two possible approaches to apply these techniques to federated learning. Our findings show that extreme learning machines can be used in federated learning with an extra security layer, making them attractive in learning schemes with limited computational resources.},
  archive      = {J_JOCS},
  author       = {Daniel Heinlein and Anton Akusok and Kaj-Mikael Björk and Leonardo Espinosa-Leal},
  doi          = {10.1016/j.jocs.2025.102693},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102693},
  shortjournal = {J. Comput. Sci.},
  title        = {Private linear equation solving: An application to federated learning and extreme learning machines},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BAHA: Binary artificial hummingbird algorithm for feature selection. <em>JOCS</em>, <em>92</em>, 102686. (<a href='https://doi.org/10.1016/j.jocs.2025.102686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Datasets classification accuracy depends on their features. The presence of irrelevant and redundant features in the dataset leads to the reduction of classification accuracy. Identifying and removing such features is the main purpose in feature selection, which is an important step in the data science lifecycle. The objective of the Wrapper feature selection method is to reduce the number of selected feature (NSF) while improving the classification accuracy by working on a set of features. The feature selection is a challenging and computationally expensive problem that falls under the NP-complete category, so it requires computationally cheap and efficient algorithm to solve it. The artificial hummingbird algorithm (AHA) is a biological inspired optimization technique that mimics the unique flight capabilities and intelligent foraging tactics of hummingbirds in nature. Since feature selection is inherently a binary problem. In this paper, the binary form of the AHA meta-heuristic algorithm is proposed to show that binarizing the AHA meta-heuristic algorithm improves its performance for solving feature selection problems. The proposed method is tested on a standard benchmark dataset and compared with four state-of-the-art feature selection algorithms: Automata-based improved equilibrium optimizer with U-shaped transfer function (AIEOU), Whale optimization approaches for wrapper feature selection (WOA-CM), Ring theory-based harmony search (RTHS), and Adaptive switching gray-whale optimizer (ASGW). The results show the effectiveness of the proposed algorithm in searching for optimal features subset. The source code for the algorithm being proposed is accessible to the public on https://github.com/alihamdipour/baha .},
  archive      = {J_JOCS},
  author       = {Ali Hamdipour and Abdolali Basiri and Mostafa Zaare and Seyedali Mirjalili},
  doi          = {10.1016/j.jocs.2025.102686},
  journal      = {Journal of Computational Science},
  month        = {12},
  pages        = {102686},
  shortjournal = {J. Comput. Sci.},
  title        = {BAHA: Binary artificial hummingbird algorithm for feature selection},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="joe">JOE - 4</h2>
<ul>
<li><details>
<summary>
(2025). Structural periodic vector autoregressions. <em>JOE</em>, <em>252</em>, 106099. (<a href='https://doi.org/10.1016/j.jeconom.2025.106099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While seasonality inherent to raw macroeconomic data is commonly removed by seasonal adjustment techniques before it is used for structural inference, this may distort valuable information in the data. As an alternative method to commonly used structural vector autoregressions (SVARs) for seasonally adjusted data, we propose to model potential periodicity in seasonally unadjusted (raw) data directly by structural periodic vector autoregressions (SPVARs). This approach does not only allow for periodically time-varying intercepts, but also for periodic autoregressive parameters and innovations variances. As this larger flexibility leads to an increased number of parameters, we propose linearly constrained estimation techniques. Moreover, based on SPVARs, we provide two novel identification schemes and propose a general framework for impulse response analyses that allows for direct consideration of seasonal patterns. We provide asymptotic theory for SPVAR estimators and impulse responses under flexible linear restrictions and introduce a test for seasonality in impulse responses. For the construction of confidence intervals, we discuss several residual-based (seasonal) bootstrap methods and prove their bootstrap consistency under different assumptions. A real data application shows that useful information about the periodic structure in the data may be lost when relying on common seasonal adjustment methods.},
  archive      = {J_JOE},
  author       = {Daniel Dzikowski and Carsten Jentsch},
  doi          = {10.1016/j.jeconom.2025.106099},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106099},
  shortjournal = {J. Econ.},
  title        = {Structural periodic vector autoregressions},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Misspecification-robust bootstrap t-test for irrelevant factor in linear stochastic discount factor models. <em>JOE</em>, <em>252</em>, 106097. (<a href='https://doi.org/10.1016/j.jeconom.2025.106097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the applicability of the bootstrap approach to test for irrelevant risk factors that are potentially useless in misspecified linear stochastic discount factor (SDF) models. In the literature, the misspecification-robust inference with useless factors is known to give rise to nonstandard limiting distributions bounded stochastically to compute critical values. We show how and to what extent the wild bootstrap yields a more accurate approximation of the distribution of t -statistics when testing for an unpriced factor in the context of linear SDF models. Simulation experiments and empirical tests are also used to document the relevance of the bootstrap method.},
  archive      = {J_JOE},
  author       = {Antoine A. Djogbenou and Ulrich Hounyo},
  doi          = {10.1016/j.jeconom.2025.106097},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106097},
  shortjournal = {J. Econ.},
  title        = {Misspecification-robust bootstrap t-test for irrelevant factor in linear stochastic discount factor models},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On-line detection of changes in the shape of intraday volatility curves. <em>JOE</em>, <em>252</em>, 106089. (<a href='https://doi.org/10.1016/j.jeconom.2025.106089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We devise an on-line detector for temporal instability in the shape of average intraday volatility curves under a general semimartingale setup for the price-volatility dynamics. We adopt a block-based strategy to estimate volatility nonparametrically from the intraday observations over local time windows with asymptotically shrinking size. Our detector then tracks sequential changes in running means of the intraday volatility curve estimates. Asymptotic size and power properties of the detector follow from a weak form invariance principle, which is established under the strong mixing condition aligned with our semimartingale setup. Simulation and empirical results demonstrate good finite-sample performance of the proposed detection method.},
  archive      = {J_JOE},
  author       = {Torben G. Andersen and Yingwen Tan and Viktor Todorov and Zhiyuan Zhang},
  doi          = {10.1016/j.jeconom.2025.106089},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106089},
  shortjournal = {J. Econ.},
  title        = {On-line detection of changes in the shape of intraday volatility curves},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High dimensional factor analysis with weak factors. <em>JOE</em>, <em>252</em>, 106086. (<a href='https://doi.org/10.1016/j.jeconom.2025.106086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the principal components (PC) estimator for high dimensional approximate factor models with weak factors in that the factor loading ( Λ 0 ) scales sublinearly in the number N of cross-section units, i.e., Λ 0 ⊤ Λ 0 / N α is positive definite in the limit for some α ∈ ( 0 , 1 ) . While the consistency and asymptotic normality of these estimates are by now well known when the factors are strong, i.e., α = 1 , the statistical properties for weak factors remain less explored. Here, we show that the PC estimator maintains consistency and asymptotic normality for any α ∈ ( 0 , 1 ) , provided suitable conditions regarding the dependence structure in the noise are met. This complements earlier result by Onatski (2012) that the PC estimator is inconsistent when α = 0 , and the more recent work by Bai and Ng (2023) who established the asymptotic normality of the PC estimator when α ∈ ( 1 / 2 , 1 ) . Our proof strategy integrates the traditional eigendecomposition-based approach for factor models with leave-one-out analysis similar in spirit to those used in matrix completion and other settings. This combination allows us to deal with factors weaker than the former and at the same time relax the incoherence and independence assumptions often associated with the later.},
  archive      = {J_JOE},
  author       = {Jungjun Choi and Ming Yuan},
  doi          = {10.1016/j.jeconom.2025.106086},
  journal      = {Journal of Econometrics},
  month        = {11},
  pages        = {106086},
  shortjournal = {J. Econ.},
  title        = {High dimensional factor analysis with weak factors},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="joma">JOMA - 7</h2>
<ul>
<li><details>
<summary>
(2026). A novel martingale difference correlation via data splitting with applications in feature screening. <em>JOMA</em>, <em>211</em>, 105508. (<a href='https://doi.org/10.1016/j.jmva.2025.105508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel sample martingale difference correlation via data splitting to measure the departure of conditional mean independence between a response variable Y and a vector predictor X . The proposed correlation converges to zero and has an asymptotically symmetric sampling distribution around zero when Y and X are conditionally mean independent. In contrast, it converges to a positive value when Y and X are conditionally mean dependent. Leveraging these properties, we develop a new model-free feature screening method with false discovery rate (FDR) control for ultrahigh-dimensional data. We demonstrate that this screening method achieves FDR control and the sure screening property simultaneously. We also extend our approach to conditional quantile screening with FDR control. To further enhance the stability of the screening results, we implement multiple splitting techniques. We evaluate the finite sample performance of our proposed methods through simulations and real data analyses, and compare them with existing methods.},
  archive      = {J_JOMA},
  author       = {Zhengyu Zhu and Jicai Liu and Riquan Zhang},
  doi          = {10.1016/j.jmva.2025.105508},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105508},
  shortjournal = {J. Multi. Anal.},
  title        = {A novel martingale difference correlation via data splitting with applications in feature screening},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tree pólya splitting distributions for multivariate count data. <em>JOMA</em>, <em>211</em>, 105507. (<a href='https://doi.org/10.1016/j.jmva.2025.105507'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we develop a new class of multivariate distributions adapted for count data, called Tree Pólya Splitting. This class results from the combination of a univariate distribution and singular multivariate distributions along a fixed partition tree. Known distributions, including the Dirichlet-multinomial, the generalized Dirichlet-multinomial and the Dirichlet-tree multinomial, are particular cases within this class. As we will demonstrate, these distributions offer some flexibility, allowing for the modeling of complex dependence structures (positive, negative, or null) at the observation level. Specifically, we present theoretical properties of Tree Pólya Splitting distributions by focusing primarily on marginal distributions, factorial moments, and dependence structures (covariance and correlations). A dataset of abundance of Trichoptera is used, on one hand, as a benchmark to illustrate the theoretical properties developed in this article, and on the other hand, to demonstrate the interest of these types of models, notably by comparing them to other approaches for fitting multivariate data, such as the Poisson-lognormal model in ecology or singular multivariate distributions used in microbial analysis.},
  archive      = {J_JOMA},
  author       = {Samuel Valiquette and Jean Peyhardi and Éric Marchand and Gwladys Toulemonde and Frédéric Mortier},
  doi          = {10.1016/j.jmva.2025.105507},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105507},
  shortjournal = {J. Multi. Anal.},
  title        = {Tree pólya splitting distributions for multivariate count data},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficiency of markov chains for bayesian linear regression models with heavy-tailed errors. <em>JOMA</em>, <em>211</em>, 105506. (<a href='https://doi.org/10.1016/j.jmva.2025.105506'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider posterior simulation for a linear regression model when the error distribution is given by a scale mixture of multivariate normals. We first show that a sampler given in the literature for the case of the conditionally conjugate normal-inverse Wishart prior continues to be geometrically ergodic even when the error density is heavier-tailed. Moreover, we prove that the ergodicity is uniform by verifying the minorization condition. In the second half of this note, we treat an improper case and, using a simple energy function, show that a data augmentation algorithm in the literature is geometrically ergodic under a significantly different condition.},
  archive      = {J_JOMA},
  author       = {Yasuyuki Hamura},
  doi          = {10.1016/j.jmva.2025.105506},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105506},
  shortjournal = {J. Multi. Anal.},
  title        = {Efficiency of markov chains for bayesian linear regression models with heavy-tailed errors},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified selection consistency theorem for information criterion-based rank estimators in factor analysis. <em>JOMA</em>, <em>211</em>, 105498. (<a href='https://doi.org/10.1016/j.jmva.2025.105498'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years, numerous rank estimators for factor models have been proposed in the literature. This article focuses on information criterion-based rank estimators and investigates their consistency in rank selection. The gap conditions serve as necessary and sufficient conditions for rank estimators to achieve selection consistency under the general assumptions of random matrix theory. We establish a unified theorem on selection consistency, presenting the gap conditions for information criterion-based rank estimators with a unified formulation. To validate the theorem’s assertion that rank selection consistency is solely determined by the gap conditions, we conduct extensive numerical simulations across various settings. Additionally, we undertake supplementary simulations to explore the strengths and limitations of information criterion-based estimators by comparing them with other types of rank estimators.},
  archive      = {J_JOMA},
  author       = {Toshinari Morimoto and Hung Hung and Su-Yun Huang},
  doi          = {10.1016/j.jmva.2025.105498},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105498},
  shortjournal = {J. Multi. Anal.},
  title        = {A unified selection consistency theorem for information criterion-based rank estimators in factor analysis},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On nonparametric functional data regression with incomplete observations. <em>JOMA</em>, <em>211</em>, 105497. (<a href='https://doi.org/10.1016/j.jmva.2025.105497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we consider the problem of nonparametric estimation of a regression function m ( χ ) = E ( Y | χ = χ ) with the functional covariate χ when the response Y may be missing according to a missing-not-at-random (MNAR) setup, i.e., when the underlying missing probability mechanism can depend on both χ and Y . Our proposed estimator is based on a particular representation of the regression function m ( χ ) in terms of four associated conditional expectations that can be estimated nonparametrically. To assess the theoretical performance of our estimators, we study their convergence properties in general L p norms where we also look into their rates of convergence. Our numerical results show that the proposed estimators have good finite-sample performance. We also explore the applications of our results to the problem of statistical classification with missing labels and establish a number of convergence results for new kernel-type classification rules.},
  archive      = {J_JOMA},
  author       = {Majid Mojirsheibani},
  doi          = {10.1016/j.jmva.2025.105497},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105497},
  shortjournal = {J. Multi. Anal.},
  title        = {On nonparametric functional data regression with incomplete observations},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Matérn and generalized wendland correlation models that parameterize hole effect, smoothness, and support. <em>JOMA</em>, <em>211</em>, 105496. (<a href='https://doi.org/10.1016/j.jmva.2025.105496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A huge literature in statistics and machine learning is devoted to parametric families of correlation functions, where the correlation parameters are used to understand the properties of an associated spatial random process in terms of smoothness and global or compact support. However, most of current parametric correlation functions attain only non-negative values. This work provides two new families of correlation functions that can have some negative values (aka hole effects), along with smoothness, and global or compact support. They generalize the celebrated Matérn and Generalized Wendland models, respectively, which are obtained as special cases. A link between the two new families is also established, showing that a specific reparameterization of the latter includes the former as a special limit case. Their performance in terms of estimation accuracy and goodness of best linear unbiased prediction is illustrated through synthetic and real data.},
  archive      = {J_JOMA},
  author       = {Xavier Emery and Moreno Bevilacqua and Emilio Porcu},
  doi          = {10.1016/j.jmva.2025.105496},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105496},
  shortjournal = {J. Multi. Anal.},
  title        = {Matérn and generalized wendland correlation models that parameterize hole effect, smoothness, and support},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust semi-functional censored regression. <em>JOMA</em>, <em>211</em>, 105491. (<a href='https://doi.org/10.1016/j.jmva.2025.105491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a robust methodological framework for analyzing randomly censored responses within the semi-functional partial linear regression models, utilizing the exponential squared loss criterion. The proposed methodology capitalizes on the robustness of the exponential squared loss function against outliers and heavy-tailed error distributions, while preserving the flexibility and interpretability of semi-functional regression, which accommodates scalar and functional predictors in a unified framework. To account for the divergent convergence rates of the parametric and nonparametric components, we introduce a novel three-step estimation procedure designed to enhance computational efficiency, ensure model robustness, and achieve asymptotically optimal estimation performance. The parametric component is estimated through a quasi-Newton algorithm, for which we establish global convergence under standard regularity conditions using a Wolfe-type line search strategy. Additionally, we suggest a cross-validation criterion based on the exponential squared loss function to guide the data-driven selection of tuning parameters. The theoretical properties, including consistency and asymptotic normality of the proposed estimators, are established under mild conditions. The efficacy and robustness of the method are demonstrated through a series of simulation studies and an empirical application to Alzheimer’s disease progression, highlighting its practical applicability in addressing complex and censored data structures.},
  archive      = {J_JOMA},
  author       = {Tao Wang},
  doi          = {10.1016/j.jmva.2025.105491},
  journal      = {Journal of Multivariate Analysis},
  month        = {1},
  pages        = {105491},
  shortjournal = {J. Multi. Anal.},
  title        = {Robust semi-functional censored regression},
  volume       = {211},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jomp">JOMP - 3</h2>
<ul>
<li><details>
<summary>
(2025). Experiment-based calibration in psychology: Foundational and data-generating model. <em>JOMP</em>, <em>127</em>, 102950. (<a href='https://doi.org/10.1016/j.jmp.2025.102950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experiment-based calibration is a novel method for measurement validation, which – unlike classical validity metrics – does not require stable between-person variance. In this approach, the latent variable to be measured is manipulated by an experiment, and its predicted scores – termed standard scores – are compared against the measured scores. Previous work has shown that under plausible boundary conditions, the correlation between standard and measured scores – termed retrodictive validity – is informative about measurement accuracy, i.e. combined trueness and precision. Here, I expand these findings in several directions. First, I formalise the approach in a probability-theoretic framework with the concept of a standardised calibration space. Second, I relate this framework to classical validity theory and show that the boundary conditions in fact apply to any form of criterion validity, including classical convergent validity. Thus, I state precise and empirically quantifiable boundary conditions under which criterion validity metrics are informative on validity. Third, I relate these boundary conditions to confounding variables, i.e. correlated latent variables. I show that in the limit, calibration will converge on the latent variable that is most closely related to the standard. Finally, I provide a framework for modelling the data-generating process with Markov kernels, and identify sufficient conditions under which the data generation model results in a calibration space. In sum, this article provides a formal probability-theoretic framework for experiment-based calibration and facilitates modelling and empirical assessment of the data generating processes.},
  archive      = {J_JOMP},
  author       = {Dominik R. Bach},
  doi          = {10.1016/j.jmp.2025.102950},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102950},
  shortjournal = {J. Math. Psychol.},
  title        = {Experiment-based calibration in psychology: Foundational and data-generating model},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On iverson’s law of similarity. <em>JOMP</em>, <em>127</em>, 102943. (<a href='https://doi.org/10.1016/j.jmp.2025.102943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Iverson (2006b) proposed the law of similarity ξ s ( λ x ) = γ ( λ , s ) ξ η ( λ , s ) ( x ) for the sensitivity functions ξ s ( s ∈ S ) . Compared to the former models, the generality of this one lies in that here γ and η can also depend on the variables λ and s . In the literature, this model (or its special cases) is usually considered together with a given psychophysical representation (e.g. Fechnerian, subtractive, or affine). Our goal, however, is to study at first Iverson’s law of similarity on its own. We show that if certain mild assumptions are fulfilled, then ξ can be written in a rather simple form containing only one-variable functions. The obtained form proves to be very useful when we assume some kind of representation. Motivated by Hsu and Iverson (2016) , we then study the above model assuming that the mapping η is multiplicatively translational. First, we show how these mappings can be characterized. Later we turn to the examination of Falmagne’s power law. According to our results, the corresponding function ξ can have a Fechnerian representation, and also it can have a subtractive representation. We close the paper with the study of the shift invariance property.},
  archive      = {J_JOMP},
  author       = {Eszter Gselmann and Christopher W. Doble and Yung-Fong Hsu},
  doi          = {10.1016/j.jmp.2025.102943},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102943},
  shortjournal = {J. Math. Psychol.},
  title        = {On iverson’s law of similarity},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal analysis of absolute and relative risk reductions. <em>JOMP</em>, <em>127</em>, 102942. (<a href='https://doi.org/10.1016/j.jmp.2025.102942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any medical innovation must first prove its benefits with reliable evidence from clinical trials. Evidence is commonly expressed using two metrics, summarizing treatment benefits based on either absolute risk reductions (ARRs) or relative risk reductions (RRRs). Both metrics are derived from the same data, but they implement conceptually distinct ideas. Here, we analyze these risk reductions measures from a causal modeling perspective. First, we show that ARR is equivalent to Δ P , while RRR is equivalent to causal power, thus clarifying the implicit causal assumptions. Second, we show how this formal equivalence establishes a relationship with causal Bayes nets theory, offering a basis for incorporating risk reduction metrics into a computational modeling framework. Leveraging these analyses, we demonstrate that under dynamically varying baseline risks, ARRs and RRRs lead to strongly diverging predictions. Specifically, the inherent assumption of a linear parameterization of the underlying causal graph can lead to incorrect conclusions when generalizing treatment benefits (e.g, predicting the effect of a vaccine in new populations with different baseline risks). Our analyses highlight the shared principles underlying risk reduction metrics and measures of causal strength, emphasizing the potential for explicating causal structure and inference in medical research.},
  archive      = {J_JOMP},
  author       = {Björn Meder and Charley M. Wu and Felix G. Rebitschek},
  doi          = {10.1016/j.jmp.2025.102942},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102942},
  shortjournal = {J. Math. Psychol.},
  title        = {Causal analysis of absolute and relative risk reductions},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="jpdc">JPDC - 1</h2>
<ul>
<li><details>
<summary>
(2026). A scalable tensor-based MDTW approach for multi-modal time series patterns clustering. <em>JPDC</em>, <em>207</em>, 105173. (<a href='https://doi.org/10.1016/j.jpdc.2025.105173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal Time Series (MTS) is a vital ingredient to Predictive Multi-modal Artificial Intelligence (PMAI). MTS systems capture varying temporal modalities and their inherent dependencies for their accurate analytics. However, efficiently exploring these cross-modalities relationships is a challenging research due to their complexity facets and information redundancies. MTS patterns' pairwise similarity measures precede PMAI. Multi-modal Dynamic Time Warping (MDTW) is frequently explored to quantify similar MTS. Yet, it's reliant on the orthogonal conditioned local similarity measures that ignore the contributions of MTS' underlying structural relationships in the warping process and, hence, susceptible to unrealistic matching. This paper addresses the setbacks by recommending a scalable MTS recognition model, named Tensor-Slices Distance (TSD)-based MDTW (TSD-MDTW), that's subsequently advanced to two more distinct models termed Weighted modality and TSD (WmTSD-MDTW) and TSD-Mahalanobis (TSDMaha-MDTW). To quantify an alignment's cost, TSD-MDTW incorporates intrinsic spatial dependencies between modalities' coordinates, while WmTSD-MDTW relaxes information redundancies through weighing modalities based on information richness, whereas TSDMaha-MDTW embodies modalities dependencies and their coordinates' innate spatial dependencies. Besides, it proposes a scalable Tensor-based DTW (TDTW) model that re-formulates MDTW into multiple dimensions that are found paralleling warping processes. Theoretical and empirical experimental results on MTS multi-modal datasets encompassing load patterns and meteorological modalities reveal TDTW's efficiency and proposals' superior performances in terms of cluster compactness and separation over MDTW employing the state-of-the-art local similarity measures.},
  archive      = {J_JPDC},
  author       = {Bahati Alam Sanga and Laurence T. Yang and Shunli Zhang and Zecan Yang and Nicholaus Gati},
  doi          = {10.1016/j.jpdc.2025.105173},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {1},
  pages        = {105173},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {A scalable tensor-based MDTW approach for multi-modal time series patterns clustering},
  volume       = {207},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="jtb">JTB - 6</h2>
<ul>
<li><details>
<summary>
(2026). A kinetic study of multi-substrate uniporters. <em>JTB</em>, <em>616</em>, 112267. (<a href='https://doi.org/10.1016/j.jtbi.2025.112267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transporters play key roles in regulating the movement of molecules into and out of cells. Uniporters, the simplest class of transporters, use facilitated diffusion to translocate molecules across membranes down their concentration gradient. This process can be affected by the presence of additional substrates in the intra- and extracellular environment, which can either increase the net transport rate of a molecule via trans acceleration or decrease it via competitive inhibition. In this study, we derived mathematical models to describe the net transport rate of uniporters in the presence of multiple extracellular substrates or inhibitors. Analyses of these models identified four possible states for the system when two substrates are present, with two states leading to trans acceleration and the other two states resulting in inhibition. Finally, we found that the relation between kinetic constants that controls the fraction of transporters in the inward-facing open state is responsible for these behaviors. Our theoretical results provide a mathematical framework for understanding the dynamic response of uniporters in the presence of multiple substrates and inhibitors, which could have implications for various processes, from nutrient utilization to metabolic engineering.},
  archive      = {J_JTB},
  author       = {Ana S. de Pereda and Jihyun Park and Lily S. Cheung},
  doi          = {10.1016/j.jtbi.2025.112267},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112267},
  shortjournal = {J. Theor. Biol},
  title        = {A kinetic study of multi-substrate uniporters},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Phenomenological modeling of gene transcription by approximating cooperativity of transcription factors improves prediction and reduces complexity in gene regulatory network models. <em>JTB</em>, <em>616</em>, 112264. (<a href='https://doi.org/10.1016/j.jtbi.2025.112264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several computational models are available for representing the gene expression process, with each having their advantages and disadvantages. Phenomenological models are widely used as they make appropriate simplifications that aim to find a middle ground between accuracy and complexity. The existing phenomenological models compete in terms of how the transcription initiation process is approximated, to achieve high accuracy while having the lowest complexity possible. However, most current models still suffer from high parameter complexity in the case of complex promoters. Herein, we formally derive a phenomenological approach to model RNA polymerase recruitment, stating approximations on cooperativity between transcription factors that are applicable to promoters requiring multifactorial input, which reduces parameter complexity. We then apply this method to biologically relevant networks of varying complexities to show that the approximations improved predictive ability compared to existing models. In summary, our reduced parameter model (RPM) had lower complexity while maintaining high accuracy, which leads to better scalability for complex networks.},
  archive      = {J_JTB},
  author       = {Thiruvickraman Jothiprakasam and Siddharth Jhunjhunwala},
  doi          = {10.1016/j.jtbi.2025.112264},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112264},
  shortjournal = {J. Theor. Biol},
  title        = {Phenomenological modeling of gene transcription by approximating cooperativity of transcription factors improves prediction and reduces complexity in gene regulatory network models},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mathematical model suggests current CAR-macrophage dosage is efficient to low pre-infusion tumour burden but refractory to high tumour burden. <em>JTB</em>, <em>616</em>, 112263. (<a href='https://doi.org/10.1016/j.jtbi.2025.112263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chimeric antigen receptor (CAR)-macrophage therapy is a promising approach for tumour treatment due to antigen-specific phagocytosis and tumour clearance. However, the precise impact of tumour burden, dose and dosing regimens on therapeutic outcomes remains poorly understood. We developed ordinary differential equation (ODE) mathematical modelling and utilised parameter inference to analyse in vitro FACS-based phagocytosis assay data testing CD19-positive Raji tumour cell against CAR-macrophage, and revealed that phagocytosing efficiency of CAR-macrophage increases but saturates as both Raji cell and CAR-macrophage concentrations increase. This interaction resulted in bistable Raji cell kinetics; specifically, within a particular range of CAR-macrophage concentration, low tumour burdens are effectively inhibited, while high tumour burdens remain refractory. Furthermore, our model predicted that CAR-macrophage dosages typically suggested by current clinical trials yield favourable therapeutic outcomes only when tumour burden is low. For split CAR-macrophage infusion with fixed total dosage, the first infusion with high CAR-macrophage dose delivers superior treatment outcomes. Finally, we identified alternative infusion regimens: five billion cells administered monthly for three months, or seven billion cells every two months for six months, can efficiently suppress Raji cell replication irrespective of tumour burden. Our findings highlight CAR-macrophage therapeutic outcomes are strongly influenced by both tumour burden and different dosing regimens. This work underscores that reducing tumour burden, increasing CAR-macrophage dose in the first infusion and prolonging CAR-macrophage persistence are key strategies for achieving durable responses.},
  archive      = {J_JTB},
  author       = {Shilian Xu and Maoxuan Liu},
  doi          = {10.1016/j.jtbi.2025.112263},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112263},
  shortjournal = {J. Theor. Biol},
  title        = {Mathematical model suggests current CAR-macrophage dosage is efficient to low pre-infusion tumour burden but refractory to high tumour burden},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Emergent microtubule properties in a model of filament turnover and nucleation. <em>JTB</em>, <em>616</em>, 112254. (<a href='https://doi.org/10.1016/j.jtbi.2025.112254'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microtubules (MTs) are dynamic protein filaments essential for intracellular organization and transport, particularly in long-lived cells such as neurons. The plus and minus ends of neuronal MTs switch between growth and shrinking phases, and the nucleation of new filaments is believed to be regulated in both healthy and injury conditions. We propose stochastic and deterministic mathematical models to investigate the impact of filament nucleation and length-regulation mechanisms on emergent properties such as MT lengths and numbers in living cells. We expand our stochastic continuous-time Markov chain model of filament dynamics to incorporate MT nucleation and capture realistic stochastic fluctuations in MT numbers and tubulin availability. We also propose a simplified partial differential equation (PDE) model, which allows for tractable analytical investigation into steady-state MT distributions under different nucleation and length-regulating mechanisms. We find that the stochastic and PDE modeling approaches show good agreement in MT length distributions, and that both MT nucleation and the catastrophe rate of large-length MTs regulate MT length distributions. In both frameworks, multiple mechanistic combinations achieve the same average MT length. The models proposed can predict parameter regimes where the system is scarce in tubulin, the building block of MTs, and suggest that low filament nucleation regimes are characterized by high variation in MT lengths, while high nucleation regimes drive high variation in MT numbers. These mathematical frameworks have the potential to improve our understanding of MT regulation in both healthy and injured neurons.},
  archive      = {J_JTB},
  author       = {Anna C. Nelson and Scott A. McKinley and Melissa M. Rolls and Maria-Veronica Ciocanel},
  doi          = {10.1016/j.jtbi.2025.112254},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112254},
  shortjournal = {J. Theor. Biol},
  title        = {Emergent microtubule properties in a model of filament turnover and nucleation},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Modelling phylogeny in 16S rRNA gene sequencing datasets using string-based kernels. <em>JTB</em>, <em>616</em>, 112249. (<a href='https://doi.org/10.1016/j.jtbi.2025.112249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bacterial microbiome is increasingly being recognised as a key factor in human health, driven in large part by datasets collected using 16S rRNA (ribosomal ribonucleic acid) gene sequencing, which enable cost-effective quantification of the composition of an individual’s bacterial community. One of the defining characteristics of 16S rRNA datasets is the evolutionary relationships that exist between taxa (phylogeny). Here, we demonstrate the utility of modelling these phylogenetic relationships in two statistical tasks (the two sample test and host trait prediction) and propose a novel family of kernels for analysing microbiome datasets by leveraging string kernels from the natural language processing literature. We show via simulation studies that a kernel two-sample test using the proposed kernel is sensitive to the phylogenetic scale of the difference between the two populations. In a second set of simulations we also show how Gaussian process modelling with string kernels can infer the distribution of bacterial-host effects across the phylogenetic tree and apply this approach to a real host-trait prediction task. The results in the paper can be reproduced by running the code at https://github.com/jonathanishhorowicz/modelling_phylogeny_in_16srrna_using_string_kernels .},
  archive      = {J_JTB},
  author       = {Jonathan Ish-Horowicz and Sarah Filippi},
  doi          = {10.1016/j.jtbi.2025.112249},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112249},
  shortjournal = {J. Theor. Biol},
  title        = {Modelling phylogeny in 16S rRNA gene sequencing datasets using string-based kernels},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Approximate bayesian computation for markovian binary trees in phylogenetics. <em>JTB</em>, <em>616</em>, 112246. (<a href='https://doi.org/10.1016/j.jtbi.2025.112246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phylogenetic trees describe the relationships between species in the evolutionary process, and provide information about the rates of diversification. To understand the mechanisms behind macroevolution, we consider a class of multitype branching processes called Markovian binary trees (MBTs). MBTs allow for trait-based variation in diversification rates, and provide a flexible and realistic probabilistic model for phylogenetic trees. We develop an approximate Bayesian computation (ABC) scheme to infer the rates of MBT parameters by exploiting the information in the shapes of phylogenetic trees. We evaluate the accuracy of this inference method using simulation studies, and find that our method is able to detect variation in the diversification rates, with accuracy comparable to, and generally better than, likelihood-based methods. In an application to a real-life phylogeny of squamata, we reinforce conclusions drawn from earlier studies, in particular supporting the existence of ovi-/viviparity transitions in both directions. Our method demonstrates the potential for more complex models of evolution to be employed in phylogenetic inference, in conjunction with likelihood-free schemes.},
  archive      = {J_JTB},
  author       = {Mingqi He and Sophie Hautphenne and Yao-ban Chan},
  doi          = {10.1016/j.jtbi.2025.112246},
  journal      = {Journal of Theoretical Biology},
  month        = {1},
  pages        = {112246},
  shortjournal = {J. Theor. Biol},
  title        = {Approximate bayesian computation for markovian binary trees in phylogenetics},
  volume       = {616},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="kbs">KBS - 195</h2>
<ul>
<li><details>
<summary>
(2025). Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning. <em>KBS</em>, <em>330</em>, 114483. (<a href='https://doi.org/10.1016/j.knosys.2025.114483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop knowledge graph reasoning aims to leverage the relations between multiple nodes in a knowledge graph to reason information about an event or entity. This reasoning process requires traversing multiple interconnected facts or knowledge points, which aids in understanding the model’s decision-making process. Multi-hop knowledge graph reasoning has driven the development of knowledge-based technologies, such as question-answering systems and recommendation systems. However, multi-hop reasoning relies on the connectivity between different entities in the knowledge graph. This characteristic makes multi-hop reasoning lack robustness when dealing with sparse data. To address the challenges of sparsity, recent studies pre-train knowledge graph embedding models to complete potential triples. The completion methods introduce noisy triples, which increases the risk of model selection errors and spurious paths. In this work, we propose a framework based on potential subgraph rule and reasoning context enhancement to mitigate the challenges of sparsity. On one hand, we leverage reasoning context to enhance state information and the reasoning process; on the other hand, we design an action perceptron based on the importance of reasoning context to reduce the introduction of noisy triples. Additionally, we analyze the phenomenon of data augmentation introducing spurious paths, and further utilize data augmentation-based potential subgraph rules to guide the reasoning process. This dual mechanism demonstrates stronger robustness in addressing sparsity challenges and spurious paths. Diverse experiments demonstrate that our model outperforms the existing multi-hop reasoning models across five datasets. Our implementations will be publicly available at: https://github.com/jianruichen/PreKGR .},
  archive      = {J_KBS},
  author       = {Congcong Sun and Jianrui Chen and Deguang Chen and Junjie Huang},
  doi          = {10.1016/j.knosys.2025.114483},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114483},
  shortjournal = {Knowl. Based Syst.},
  title        = {Potential subgraph rule and reasoning context enhancement for sparse multi-hop knowledge graph reasoning},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. <em>KBS</em>, <em>330</em>, 114482. (<a href='https://doi.org/10.1016/j.knosys.2025.114482'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has emerged as a powerful self-supervised approach for learning generalized graph representations, achieving remarkable advancements in recent years. However, most existing GCL methods ignore the noise of the augmented global structure and the dynamic change in training, and lack detailed consideration in calculating local structural homogeneity. These limitations may lead to the model’s insufficient performance in capturing fine-grained semantic features at the node level, making it difficult to fully explore the potential semantic associations between adjacent nodes. Meanwhile, on a global scale, there is also a lack of the ability to model complex topological structures. To this end, we propose a new multi-scale graph contrastive learning with dynamic adjustment and mutual rectification. This method dynamically adjusts the global structure via graph reconstruction and adaptively learns node representations; Meanwhile, a mutual rectification module is designed to predict the support scores of neighbors relative to anchors and quantify each neighbor’s contribution to view agreement. Both reconstruction and rectification are integrated into the training objective and effectively capture the graph structure information from both global and local scales, improving the quality and robustness of graph representations. We conduct extensive experiments on three downstream tasks: node classification, node clustering, and link prediction. The experimental results demonstrate that our method outperforms existing GCL methods across multiple tasks and datasets, validating the effectiveness and generalizability of the proposed model.},
  archive      = {J_KBS},
  author       = {Dengdi Sun and Zhixiang Wu and Mingwei Cao and Zhifu Tao and Zhuanlian Ding},
  doi          = {10.1016/j.knosys.2025.114482},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114482},
  shortjournal = {Knowl. Based Syst.},
  title        = {DAMR: Multi-scale graph contrastive learning with dynamic adjustment and mutual rectification},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer. <em>KBS</em>, <em>330</em>, 114471. (<a href='https://doi.org/10.1016/j.knosys.2025.114471'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are widely applied in optimization because of their flexibility and ability to address complex and high-dimensional problems. Nevertheless, they face persistent challenges, including susceptibility to local optima, limited parameter adaptability, and premature convergence. Leadership-based metaheuristics, in which leaders guide the search process, encounter additional difficulties such as limited exploration capacity, leader stagnation, and reduced diversity, often stemming from underutilization of data generated during the search. To overcome these limitations, this study proposes a reinforcement learning–based approach, RL-LGWO, which enhances the Grey Wolf Optimizer (GWO) by integrating multi-agent reinforcement learning. In RL-LGWO, agents share experiences to improve decision-making, and reinforcement learning is employed to decouple and adapt the leader update mechanism, thereby improving the exploration–exploitation balance and enabling leaders to dynamically escape local optima. The proposed method was evaluated against two GWO-enhancing algorithms, three RL-based GWO variants, PSO, WOA, and the original GWO across 23 well-known benchmark functions, in addition to the recent CEC2022 benchmark suite. Experimental results show that RL-LGWO achieved the best solutions on 17 of the 23 benchmark functions, with superior convergence speed and improved stability, while incurring only a minor runtime increase compared with the original GWO. Furthermore, on the CEC2022 suite, RL-LGWO outperformed competing algorithms on 10 of 12 test functions, underscoring its robustness and adaptability to recent and challenging benchmarks. Overall, the findings indicate that RL-LGWO delivers a substantive improvement over state-of-the-art alternatives and holds strong potential to advance leadership-based metaheuristics for a wide range of optimization problems.},
  archive      = {J_KBS},
  author       = {Afifeh Maleki and Mehdy Roayaei and Seyedali Mirjalili},
  doi          = {10.1016/j.knosys.2025.114471},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114471},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing leadership-based metaheuristics using reinforcement learning: A case study in grey wolf optimizer},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling. <em>KBS</em>, <em>330</em>, 114454. (<a href='https://doi.org/10.1016/j.knosys.2025.114454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable performance of supervised medical image segmentation models, relying on a large amount of labeled data is impractical in real-world situations. Semi-supervised learning approaches aim to alleviate this challenge using unlabeled data through pseudo-label generation. Yet, existing semi-supervised segmentation methods still suffer from noisy pseudo-labels and insufficient supervision within the feature space. To solve these challenges, this paper proposes a novel semi-supervised 3D medical image segmentation framework based on a dual-network architecture. Specifically, we investigate a Cross Consistency Enhancement module using both cross pseudo and entropy-filtered supervision to reduce the noisy pseudo-labels, while we design a dynamic weighting strategy to adjust the contributions of pseudo-labels using an uncertainty-aware mechanism (i.e., Kullback–Leibler divergence). In addition, we use a self-supervised contrastive learning mechanism to align uncertain voxel features with reliable class prototypes by effectively differentiating between trustworthy and uncertain predictions, thus reducing prediction uncertainty. Extensive experiments are conducted on three 3D segmentation datasets, Left Atrial, NIH Pancreas and BraTS-2019. The proposed approach consistently exhibits superior performance across various settings (e.g., 89.95 % Dice score on left Atrial with 10 % labeled data) compared to the state-of-the-art methods. Furthermore, the usefulness of the proposed modules is further validated via ablation experiments. The code repository is available at https://github.com/AIPMLab/Semi-supervised-Segmentation .},
  archive      = {J_KBS},
  author       = {Yunyao Lu and Yihang Wu and Ahmad Chaddad and Tareef Daqqaq and Reem Kateb},
  doi          = {10.1016/j.knosys.2025.114454},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114454},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing dual network based semi-supervised medical image segmentation with uncertainty-guided pseudo-labeling},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. <em>KBS</em>, <em>330</em>, 114452. (<a href='https://doi.org/10.1016/j.knosys.2025.114452'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of transfer learning strategies to solve cross-domain fault diagnosis problems has achieved significant results. However, most existing multi-source domain generalization fault diagnosis methods use a single classifier or introduce auxiliary classifiers, focusing on learning domain-invariant features or global feature distribution matching. Furthermore, since the data distributions of different source domains may be significantly different, this may lose the data distribution information specific to each source domain. In addition, how to reduce the variation in risk between samples within the same domain training is also a challenging issue. Finally, it is also crucial to balance the predictive outputs of multiple classifiers to adapt them to the data distribution of the target domain. Based on the above challenges, this paper proposes a multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions. Feature weakly decoupled mechanism is achieved by employing multiple classifiers and incorporating the variance of samples within the same sample domain as a penalty term. This reduces the model’s sensitivity to changes in the extreme distribution of samples within the domain. Classifier weakly decoupled mechanism, on the other hand, reduces the inter-domain risk variance by minimizing the loss of variance in the predicted output of the source domain classifiers. This improves the robustness of the model to inter-domain distributional changes and covariate changes. Experimental results on three datasets validate the effectiveness and general applicability of the proposed approach.},
  archive      = {J_KBS},
  author       = {Yawei Sun and Hongfeng Tao and Vladimir Stojanovic},
  doi          = {10.1016/j.knosys.2025.114452},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114452},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-domain weakly decoupled domain generalization network for fault diagnosis under unknown operating conditions},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing large language models for bitcoin time series forecasting. <em>KBS</em>, <em>330</em>, 114449. (<a href='https://doi.org/10.1016/j.knosys.2025.114449'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent advancements in application of deep learning to time series forecasting, focus has shifted from training transformers end-to-end to efficiently leveraging the predictive capabilities of Large Language Models (LLMs). Models that encode the time series data to interact with a frozen LLM backbone have been shown to outperform transformers on all benchmark datasets. However, their efficiency on complex datasets, which do not show clear seasonality or trend, remains an open question. In this work, we seek to evaluate the performance of reprogrammed LLMs on the Bitcoin price chart, a financial time series known for its complexity and high volatility. We propose effective methods to improve the performance of Time-LLM, a State-of-the-art (SOTA) method, on such a time series. First, we propose structural improvements to Time-LLM. Second, we suggest an efficient way to handle the non-stationarity of the dataset. Finally, we propose an efficient method for passing additional financial information to the LLM. Our results demonstrate a 50 % improvement on the average percentage loss and a 5 % increase on accuracy of our adapted Time-LLM architecture on Bitcoin data when compared to SOTA models, including the original Time-LLM model. This highlights the impact on forecast accuracy of domain-specific decision making in data processing and feature selection.},
  archive      = {J_KBS},
  author       = {Owen Chaffard and Pablo Mollá and Marc Cavazza and Helmut Prendinger},
  doi          = {10.1016/j.knosys.2025.114449},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114449},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing large language models for bitcoin time series forecasting},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCAT: Federated causal adversarial training. <em>KBS</em>, <em>330</em>, 114440. (<a href='https://doi.org/10.1016/j.knosys.2025.114440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal inference has been proven to be a crucial technique for improving the efficacy and explainability of adversarial training (AT). However, its applicability in the decentralized adversarial training paradigm has not been fully explored. Where one potential challenge is to apply the causal inference in the settings of non-independent and identically distributed (Non-IID) federated learning. In particular, the imbalanced data distributions among various clients will unavoidably hinder the efficacy and adaptability of causal inference. To address this issue, this paper proposes a novel yet practical method dubbed Federated Causal Adversarial Training (FCAT), which seeks to improve causal models via calibrated correction information. Additionally, we introduce a lightweight slack aggregation method aimed at addressing client model disparities and minimizing the communication overhead in each iteration. Extensive experimental results demonstrate that FCAT significantly improves the efficacy of causal models in federated adversarial training, and remarkably outperforms the current state-of-the-art (SOTA) competitors on multiple widely-adopted benchmarks.},
  archive      = {J_KBS},
  author       = {Yunhao Feng and Yanming Guo and Mingrui Lao and Yulun Wu and Yishan Li and Yuxiang Xie},
  doi          = {10.1016/j.knosys.2025.114440},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114440},
  shortjournal = {Knowl. Based Syst.},
  title        = {FCAT: Federated causal adversarial training},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem. <em>KBS</em>, <em>330</em>, 114439. (<a href='https://doi.org/10.1016/j.knosys.2025.114439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The polynomial robust knapsack problem (PRKP) is a variant of the classic knapsack problem by incorporating uncertain costs and benefits from item combinations, leading to a nonlinear objective function and exponential solution space. These complexities make the PRKP suitable for real-world scenarios where interactions between items unpredictably impact outcomes. However, existing algorithms struggle to efficiently solve large instances of the PRKP due to its computational complexity. Therefore, this paper presents an iterative heuristic algorithm leveraging a neural network (NN) to address the PRKP, reducing the solution space and enabling efficient resolution of subproblems. The framework integrates an NN trained in two steps: general training and fine-tuning. The trained model is then embedded in the iterative heuristic algorithm to tackle the PRKP. A synthetic dataset comprising 2500 instances, ranging from 100 to 1500 items, is created to train the NN. Comparative evaluations are conducted using 1600 benchmark instances from the literature and 140 larger instances containing between 2000 and 15,000 items. We compare our approach against two state-of-the-art algorithms for the PRKP: a genetic algorithm and a random forest-based heuristic. Computational results demonstrate that the proposed algorithm outperforms the genetic algorithm, providing superior solution quality with significantly reduced computing times. Meanwhile, against random forest-based heuristic, it delivers better solution quality with only a moderate increase in computing time. For larger instances, it maintains its advantage in solution quality while remaining computationally efficient. These results highlight the algorithm’s scalability, effectiveness, and potential to address the PRKP.},
  archive      = {J_KBS},
  author       = {José González-Cortés and Carlos Contreras-Bolton},
  doi          = {10.1016/j.knosys.2025.114439},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114439},
  shortjournal = {Knowl. Based Syst.},
  title        = {A neural network-based iterative heuristic algorithm for the polynomial robust knapsack problem},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TWDT: Training-free word-level controllable diffusion model for text generation. <em>KBS</em>, <em>330</em>, 114437. (<a href='https://doi.org/10.1016/j.knosys.2025.114437'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing controlled text generation (CTG) methods typically require the training of additional components, whereas diffusion models have already achieved fine control in image generation by adjusting latent feature information during the inference process. However, existing diffusion models still face issues such as “attribute leakage” and “overgeneration” when applied to text generation, leading to generated texts lacking precise control. To address these problems, we propose a training-free word-level controllable diffusion language network (TWDT). This network achieves fine-grained control of text generation by adjusting latent space features during the inference process. Specifically, TWDT introduces an Alignment and Word Evaluation (AWE) module, which ensures accurate mapping of the text to a predefined set of feature words through syntactic segmentation and multi-level semantic alignment. At the same time, a similarity threshold filtering mechanism is applied to inject Gaussian noise into low-consistency nodes, ensuring semantic consistency and stability during generation. To evaluate the rigor and accuracy of the model, we have developed a high-quality multi-disease dental diagnostic dataset, all of which are annotated by experienced dental experts, serving as the benchmark for model evaluation. Experimental results show that TWDT outperforms existing diffusion models in terms of generation accuracy and rigor.},
  archive      = {J_KBS},
  author       = {Nan Gao and Yangjie Lu and Peng Chen and Guodao Sun and Ronghua Liang and Yilong Zhang},
  doi          = {10.1016/j.knosys.2025.114437},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114437},
  shortjournal = {Knowl. Based Syst.},
  title        = {TWDT: Training-free word-level controllable diffusion model for text generation},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network. <em>KBS</em>, <em>330</em>, 114436. (<a href='https://doi.org/10.1016/j.knosys.2025.114436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern vehicles depend on the Controller Area Network (CAN) for electronic control unit (ECU) communication, but its inherent vulnerabilities necessitate robust intrusion detection systems (IDS). Current machine learning and deep learning IDS solutions struggle with limited labeled data, class imbalances, and costly data collection processes. Few-shot learning, effective with few labeled samples, remains underexplored for in-vehicle networks (IVNs) despite its potential in data-scarce automotive cybersecurity scenarios. To bridge this gap, we introduce the first few-shot learning approach for multi-class intrusion detection in IVNs, leveraging a novel, lightweight Convolutional Anomaly Transformer. By integrating a 1D convolutional layer with an Anomaly Transformer, our model effectively classifies diverse attack types with minimal training data, mitigating class imbalance. Experiments on the widely-used real-world Car Hacking dataset, the complex ROAD dataset, and the distinct CAN-ML dataset validate its efficacy. On the Car Hacking dataset, we achieve an exceptional F1 score of 0.9994 with only 2 % of training data, improving to 0.9999 with 10 %. On the challenging ROAD dataset, characterized by diverse attacks and high variability, the model achieves an F1 score of up to 0.9980 using just 10 % of training data. Demonstrating strong generalization capabilities, the model also attains an impressive F1 score of 0.9918 on the CAN-ML dataset, which features entirely different vehicles and attack distributions. Furthermore, the lightweight architecture of our proposed IDS enables practical deployment in resource-constrained automotive environments.},
  archive      = {J_KBS},
  author       = {Nguyen Thanh Minh Duy and Truong Hoang Bao Huy and Pham Van Phu and Tien-Dat Le and Daehee Kim},
  doi          = {10.1016/j.knosys.2025.114436},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114436},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-class intrusion detection system for in-vehicle networks using few-shot learning and convolutional anomaly transformer network},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining. <em>KBS</em>, <em>330</em>, 114434. (<a href='https://doi.org/10.1016/j.knosys.2025.114434'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) algorithms have displayed their effectiveness in predicting sequence modelling compared to various systems. Nevertheless, some limitations of existing methods are the demand for enormous databases, computational expense, and the risk of overfitting. To address these problems, this study proposes a novel DL technique using knowledge distillation and sequence illness pattern recognition from medical databases. Firstly, the input data is pre-processed using the data cleaning method. The size of the sequence dataset and the duration of the sequential patterns are both considered during the process of using PREFIXSPAN to manage long sequential patterns. In the proposed strategy, a lightweight student network is employed to train a strong teacher network, which is produced by a Knowledge Distillation framework. A teacher network is assessed by the Attention Based Densely Connected Capsule Model (Attention-DC). An efficient, low-weight Depthwise Separable Convolutional Neural Network (DSCNN) model is then chosen as the student network. This study uses three datasets to solve enormous database issues. The KD helps prevent the student model from overfitting to noise or specific patterns in the training data. The Improved Coot Optimization Algorithm (ICOA) is applied to adjust the parameter. The hyperparameters used to optimize the performance of the proposed model are Epochs (300), learning rate (0.001), and batch size (32), respectively. The experiments use the resources of three different datasets, and Python is employed to analyze the results. The proposed technique achieves accuracy of 99.512 %, 99.329 % and 99.351 % for the heart disease, cardiovascular disease, and Diabetes dataset.},
  archive      = {J_KBS},
  author       = {Dinesh Kumar Bhawnani and Sunita Soni and Arpana Rawal},
  doi          = {10.1016/j.knosys.2025.114434},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114434},
  shortjournal = {Knowl. Based Syst.},
  title        = {Development of an enhanced heart attack diagnosis model using knowledge distillation and frequent sequence pattern mining},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural chain of thoughts for radiology education. <em>KBS</em>, <em>330</em>, 114433. (<a href='https://doi.org/10.1016/j.knosys.2025.114433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology education requires trainees to develop both perceptual and interpretive expertise. However, refinement of these skills is often impeded by the limited availability of mentorship, a consequence of the demanding schedules of experienced radiologists. This lack of personalized guidance makes it difficult for learners to recognize the mistakes they make, understand why those errors occurred and how to refine their perceptual processes. Many of these errors arise from subtle differences in visual attention, such as failing to fixate on an abnormality, allocating an insufficient fixation time, or overlooking an abnormality despite scanning the correct region. Although Large Language Models (LLMs) and Large Multimodal Models (LMMs) have been explored for radiology tasks, they often struggle to detect such fine-grained multimodal variations, particularly when comparing gaze behavior between experts and trainees. To address these limitations, we introduce Structural Chain of Thoughts (SCoT), a novel framework that enhances LLMs and LMMs sensitivity to nuanced multimodal differences by structuring gaze data and radiology report into a thought graph. By leveraging a structural prior, SCoT systematically identifies key perceptual and interpretive discrepancies, allowing models to provide targeted, context-aware feedback. This structured approach not only highlights missed findings but also explains the reasoning behind perceptual errors, turning them into learning opportunities. Applied within radiology education, SCoT bridges the gap between expert and novice performance, offering a scalable solution for AI-driven diagnostic training. We further contribute a simulated dataset of perceptual errors in chest X-ray (CXR) interpretation, facilitating future research into multimodal reasoning and AI-driven medical education. Unlike conventional Chain-of-Thought approaches, SCoT explicitly integrates gaze and textual information into a structured reasoning process, yielding interpretable, fine-grained, and personalized feedback tailored to the unique needs of radiology training. The code and data will be available here: GitHub Repository .},
  archive      = {J_KBS},
  author       = {Akash Awasthi and Brandon Chung and Anh Mai Vu and Saba Khan and Ngan Le and Zhigang Deng and Rishi Agrawal and Carol C. Wu and Hien Van Nguyen},
  doi          = {10.1016/j.knosys.2025.114433},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114433},
  shortjournal = {Knowl. Based Syst.},
  title        = {Structural chain of thoughts for radiology education},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing. <em>KBS</em>, <em>330</em>, 114431. (<a href='https://doi.org/10.1016/j.knosys.2025.114431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing enables the efficient execution of compute-intensive tasks by offloading them to edge servers. However, frequent user mobility in 5 G urban networks leads to increased latency, energy consumption, and resource wastage due to continuous handovers. To address these challenges, Energy Efficient Communication and Optimal Offloading Network, a framework is proposed that combines user mobility prediction and hybrid optimization for task offloading. Energy Efficient Communication and Optimal Offloading Network utilizes a modified Long Short-Term Memory model to predict user movement with high accuracy, achieving an accuracy improvement from 65 % to 95 % over ten iterations. Additionally, a Hybrid Grey Wolf Optimization Algorithm optimizes task allocation, resulting in a 30 % reduction in energy consumption and a 25 % improvement in server utilization compared to baseline methods. The framework achieves latency as low as 5 milliseconds for augmented reality tasks while maintaining scalability in high-traffic 5 G environments. The proposed model also outperforms baseline approaches in terms of task completion time, throughput, and communication efficiency, and it achieves a 94.5 % offloading success rate and 98 % augmented reality delay compliance. The proposed model provides a scalable and useful solution for real-time Augmented Reality by combining energy-constrained task allocation with mobility-aware predictions.},
  archive      = {J_KBS},
  author       = {Anitha Jebamani Soundararaj and Godfrey Winster Sathianesan},
  doi          = {10.1016/j.knosys.2025.114431},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114431},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimized task offloading with energy efficient communication and optimal offloading network: A mobility and energy-efficient approach for augmented reality in mobile edge computing},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified multi-subgraph pre-training framework for spatio-temporal graph. <em>KBS</em>, <em>330</em>, 114428. (<a href='https://doi.org/10.1016/j.knosys.2025.114428'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graph (STG) learning has shown great potential in capturing complex spatio-temporal dependencies and has achieved significant success in various fields such as traffic flow prediction, climate forecasting, and epidemiological spread research. By learning general features from spatio-temporal graphs, pre-trained graph models can capture hidden semantic information in the data, thereby enhancing the learning effect of downstream tasks and improving overall model performance. However, most existing spatio-temporal graph learning methods use the entire graph for training, which may not fully capture local structure and feature information. In addition, existing methods usually adopt sequence modeling techniques without fully considering the time decay effect, i.e., the need to apply decaying attention to distant time steps. To address these issues, this paper proposes a u nified dual-phase m ulti- s ubgraph pre-training s patio- t emporal graph framework (UMSST). Specifically, in the first phase, the framework learns the global representation of the spatio-temporal graph and locates key graph nodes, while learning the “unit representations” of these key nodes. In the second phase, multiple spatio-temporal subgraphs are constructed based on these “unit representations” to further capture the implicit encoding information of more general features around the corresponding subgraphs, thereby helping the model make full use of general features. Experimental results on real datasets show that the proposed pre-trained spatio-temporal graph framework significantly improves the performance of downstream tasks and demonstrates its effectiveness in comparison with recent strong baseline models.},
  archive      = {J_KBS},
  author       = {Mingze Zhong and Zexuan Long and Xinglei Wang and Tao Cheng and Meng Fang and Ling Chen},
  doi          = {10.1016/j.knosys.2025.114428},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114428},
  shortjournal = {Knowl. Based Syst.},
  title        = {A unified multi-subgraph pre-training framework for spatio-temporal graph},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provide explainable clues: A generative traceable method for knowledge graph completion. <em>KBS</em>, <em>330</em>, 114426. (<a href='https://doi.org/10.1016/j.knosys.2025.114426'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the quality of Knowledge Graph Completion (KGC) results is an essential topic in the field of knowledge graphs. Recently, generative models (GMs) have gained widespread attention for addressing the generalization issues of traditional approaches. However, the black-box nature of generative models often leads to hallucinations, which reduce the model’s performance. Most methods attempt to mitigate this issue through retrieval enhancement and decoding constraints. However, they overlook one major cause of hallucinations–poor explainability. Based on this concept, we propose a G enerative T raceable M ethod, namely GTM, which aims to improve the KGC capability of GMs by exploring the inhibitory effect of explainability on hallucinations. In GTM, a clue tracker is used to find contextual evidence for explainability. In addition, to measure explainability clues, we propose a context-aware analyzer, which enhances the understanding of context through group analogy. In the reasoning phase, we ensure the validity of the generated results by integrating the interpretive capability of clues. Extensive experiments have demonstrated that GTM can adapt to various KGC tasks and significantly enhance the performance of KGC models.},
  archive      = {J_KBS},
  author       = {Ziqi Ma and Jinpeng Li and Hang Yu},
  doi          = {10.1016/j.knosys.2025.114426},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114426},
  shortjournal = {Knowl. Based Syst.},
  title        = {Provide explainable clues: A generative traceable method for knowledge graph completion},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IRTF: A new tensor factorization for irregular multidimensional data recovery. <em>KBS</em>, <em>330</em>, 114372. (<a href='https://doi.org/10.1016/j.knosys.2025.114372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor factorizations, although serving as paramount tools for exploiting prior knowledge of multidimensional data, are unsuitable for emerging irregular multidimensional data with the arbitrary shape spatial domain (i.e., spatial-irregular tensor), such as superpixels and spatial transcriptomics. Developing new tensor factorizations suitable for spatial-irregular tensors poses a compelling challenge. To meet this challenge, we introduce a novel Irregular Tensor Factorization (IRTF), which can fully capture the intrinsic spatial and channel information behind the spatial-irregular tensor. Concretely, a spatial-irregular tensor can be decomposed into the product of an intrinsic regular tensor, learnable channel transform matrices, and a learnable spatial transform matrix. Accompanying IRTF, we suggest the Total Variation on Channel and Spatial Transforms (TV-CST) to exploit the local information of spatial-irregular tensors, which is hardly excavated by traditional total variation methods. Combining the proposed IRTF and TV-CST, we built a spatial-irregular tensor recovery model. Extensive experiments on real-world spatial-irregular tensors demonstrate the promising performance of our IRTF and its significant advantages on downstream tasks.},
  archive      = {J_KBS},
  author       = {Jin-Yu Xie and Hao Zhang and Xi-Le Zhao and Yi-Si Luo},
  doi          = {10.1016/j.knosys.2025.114372},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114372},
  shortjournal = {Knowl. Based Syst.},
  title        = {IRTF: A new tensor factorization for irregular multidimensional data recovery},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-driven deep learning network for image splicing forgery detection. <em>KBS</em>, <em>330</em>, 114365. (<a href='https://doi.org/10.1016/j.knosys.2025.114365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image splicing is a widely used technique for manipulating images in various social activities. Detecting splicing forgery is crucial in digital forensics to identify malicious image manipulation and protect information security. However, existing methods for detecting splicing forgery typically learn features in the spatial domain and struggle to effectively capture subtle features indicative of forgery, resulting in insufficient image splicing forgery detection accuracy. To address this challenge, we propose a novel deep-learning network named the frequency-driven deep-learning network (FreNet). Specifically, FreNet comprises three innovative modules: the frequency learnable module (FLM), the spatial-aware frequency learning module (SFLM), and the high-level feature-enhancement module (HFEM). The FLM effectively extracts high- and low-frequency features, thus enhancing frequency-domain representation and capturing subtle tampered features in splicing forgery images. The SFLM utilizes spatial information to guide frequency feature learning, thus enabling spatial-aware frequency feature learning. The HFEM enhances rich contextual and high-level semantic information through multilevel and multipath extraction and fusion. Extensive experiments on five benchmark datasets indicate that FreNet can achieve superior performance. Additionally, robustness experiments demonstrate the superior robustness of FreNet against various common attacks.},
  archive      = {J_KBS},
  author       = {Enji Liang and Kuiyuan Zhang and Zhongyun Hua and Xiaohua Jia},
  doi          = {10.1016/j.knosys.2025.114365},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114365},
  shortjournal = {Knowl. Based Syst.},
  title        = {Frequency-driven deep learning network for image splicing forgery detection},
  volume       = {330},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MLDCGAN: A multimodal latent diffusion conditioned GAN model for accelerated and high-fidelity MRI-CT synthesis in radiotherapy planning. <em>KBS</em>, <em>329</em>, 114491. (<a href='https://doi.org/10.1016/j.knosys.2025.114491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) offers significant advantages in soft tissue contrast. However, it cannot directly provide electron density information for radiotherapy, relying instead on time-consuming and error-prone MRI-CT image registration. Synthetic CT (sCT) technology, which directly generates CT images from MRI, is pivotal for achieving only MRI-based radiotherapy. However, existing synthesis methods based on generative adversarial network (GAN) and diffusion models face challenges such as prolonged inference times and insufficient utilization of multimodal information, which severely hinder the clinical application of synthetic images. In this study, we propose a novel Multimodal Latent Diffusion Conditioned GAN (MLDCGAN) Model. First, we design a non-parametric non-Gaussian complex denoising distribution based on a conditional GAN, employing a multimodal distribution to achieve large-step denoising. This is combined with a pre-trained autoencoder to compress the image into a low-dimensional latent space, significantly reducing inference time. Second, we fully leverage multimodal MRI information by constructing a local refinement conditional generator with multimodal inputs, including T1-Weighted (T1W), T2-Weighted (T2W), and Mask images. The generator is enhanced by an adaptive weighted multi-sequence fusion module and an enhanced cross-attention module, significantly improving the structural consistency and detail fidelity of the generated sCT images. Finally, by jointly optimizing the style loss and content loss, we ensure the perceptual quality and clinical accuracy of the synthetic images. Experimental results demonstrate that MLDCGAN outperforms existing state-of-the-art methods on both public and private datasets, showing significant improvements in both image quality and inference speed. Subjective evaluations from multiple experienced clinicians indicate that the generated sCT images exhibit no significant difference from real CT in terms of key anatomical structure clarity and overall quality ( P > 0.05). Further assessments of clinical target delineation and dose distribution confirm that sCT retains anatomical features well and provides dose distributions consistent with real CT, ensuring the reliability of dose calculations in radiotherapy planning. This study provides a more reliable and efficient technical foundation for achieving only MRI-based radiotherapy. It is expected to assist clinicians in developing more precise radiotherapy plans, ultimately improving treatment outcomes in future clinical practice.},
  archive      = {J_KBS},
  author       = {Can Hu and Chunchao Xia and Chuanbing Wang and Xiayu Hang and Xiuhan Li and Han Zhou and Ning Cao},
  doi          = {10.1016/j.knosys.2025.114491},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114491},
  shortjournal = {Knowl. Based Syst.},
  title        = {MLDCGAN: A multimodal latent diffusion conditioned GAN model for accelerated and high-fidelity MRI-CT synthesis in radiotherapy planning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal knowledge graph forecasting query based on global-local historical information. <em>KBS</em>, <em>329</em>, 114476. (<a href='https://doi.org/10.1016/j.knosys.2025.114476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graph (TKG) queries aim to retrieve relevant facts that conform to time constraints to answer a given query by reasoning known TKG facts. The continuous development of TKG query research has extended TKG queries to the TKG forecasting domain, enabling the forecasting of answers to unknown queries by leveraging historical information from query questions. However, TKG forecasting query research is currently facing two considerable challenges. Firstly, existing TKG forecasting query methods cannot adequately capture the global historical information of query questions, which makes it difficult to effectively mine periodic features, repetitive patterns, and dynamic evolution characteristics of new events. Secondly, when modeling local historical information, existing methods fail to focus on the historical correlation of facts between adjacent timestamps, ignoring the crucial role of local information in the temporal evolution process. In this paper, a TKG forecasting query framework based on global-local historical information is proposed to solve the above challenges. Specifically, for the global historical information of the query question, the periodic and repetitive patterns of historical facts and the potential changing laws of non-historical facts are learned by modeling global historical facts and non-historical facts. Concerning the local historical information, entities and relations are aggregated in knowledge graph (KG) snapshots and their changes and evolution are simulated at adjacent timestamps to enhance the ability of the model to capture temporal dependencies. At the same time, the impact of local snapshots on query questions is quantified to capture the evolution process of local information more accurately. Finally, we design dedicated scoring functions for different types of query tasks to achieve effective query forecasting. Extensive experiments on four datasets demonstrate that the proposed model has better performances in forecasting unknown queries than other baseline models.},
  archive      = {J_KBS},
  author       = {Luyi Bai and Tongyue Zhang and Lin Zhu},
  doi          = {10.1016/j.knosys.2025.114476},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114476},
  shortjournal = {Knowl. Based Syst.},
  title        = {Temporal knowledge graph forecasting query based on global-local historical information},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proposed quaternion fractional dual-hahn moments for color image reconstruction and encryption. <em>KBS</em>, <em>329</em>, 114467. (<a href='https://doi.org/10.1016/j.knosys.2025.114467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moments are essential descriptors for capturing fundamental characteristics of a signal, such as its shape and texture, thereby enabling a compact and easily analyzable representation. This article introduces a new family of discrete fractional moments, the quaternion Cartesian fractional dual-Hahn moments (QCFrDHOMs). These moments are derived from the fractional dual-Hahn moments (FrDHOMs), which are constructed from the matrix of fractional dual-Hahn orthogonal polynomials (FrDHOPs), obtained through the spectral decomposition of the classical dual-Hahn orthogonal polynomials (DHOPs). To ensure the stability of the computations, particularly for high-degree polynomials, a recursive method is proposed to calculate the initial terms of the DHOPs, thereby reducing the risk of numerical instability. The FrDHOMs are then generalized into QCFrDHOMs for efficient analysis of color images using quaternion algebra. Experimental results demonstrate that the QCFrDHOMs outperform classical DHOMs in terms of robustness and reconstruction capability. Additionally, an encryption and decryption scheme using QCFrDHOMs and chaotic systems is presented. Tests show that this scheme provides significant resistance to various attacks while maintaining nearly intact quality in the decrypted images. This not only highlights the effectiveness of the encryption scheme but also the enhanced security and robustness of the approach. Compared to other existing methods, our scheme stands out for its exceptional reliability and robustness, making a significant contribution to the secure protection of color images.},
  archive      = {J_KBS},
  author       = {Karim El-khanchouli and Hanaa Mansouri and Ahmed Bencherqui and Hicham Karmouni and Nour-Eddine Joudar and Mhamed Sayyouri},
  doi          = {10.1016/j.knosys.2025.114467},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114467},
  shortjournal = {Knowl. Based Syst.},
  title        = {Proposed quaternion fractional dual-hahn moments for color image reconstruction and encryption},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transformer-based approach for traffic prediction with fusion spatiotemporal attention. <em>KBS</em>, <em>329</em>, 114466. (<a href='https://doi.org/10.1016/j.knosys.2025.114466'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic data prediction is a crucial technology for data-driven intelligent transportation systems. This has an important impact on optimizing urban traffic management, travel efficiency, traffic experience, etc. Traffic flow prediction tasks primarily focus on mining dynamic spatiotemporal dependencies. Most existing Transformer-based methods and GNN-based methods have limitations in mining local-global spatiotemporal dependencies. To address this issue, we propose a novel traffic data prediction model called LGSTformer that can perceive local-global spatiotemporal dependencies. First, we construct an embedding layer that provides multiple types of embedding representations for the model by projecting spatiotemporal data and temporal and spatial information into different embeddings. Next, we design two modules to capture local-global temporal and spatial dependencies based on the naive spatiotemporal self-attention mechanism: the local-global temporal module and the local-global spatial module. The former incorporates multi-scale temporal convolutions to capture short-term temporal dependencies, and the latter incorporates dynamic-static graph convolutions to capture local spatial dependencies. Finally, to achieve effective fusion of local-global dependency information, a dual-path adaptive gated fusion layer based on a gating mechanism is introduced to attain adaptive fusion of information at different levels. Experimental results on four public real-world traffic datasets show that LGSTformer outperforms existing methods and has potential as an advanced solution for traffic flow prediction.},
  archive      = {J_KBS},
  author       = {Wenfeng Zhou and Guojiang Shen and Zhenzhen Zhao and Zhaolin Deng and Tao Tang and Xiangjie Kong and Amr Tolba and Osama Alfarraj},
  doi          = {10.1016/j.knosys.2025.114466},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114466},
  shortjournal = {Knowl. Based Syst.},
  title        = {A transformer-based approach for traffic prediction with fusion spatiotemporal attention},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SEER: Knowledge-driven semantic image restoration with vision-language diffusion alignment. <em>KBS</em>, <em>329</em>, 114464. (<a href='https://doi.org/10.1016/j.knosys.2025.114464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic communication is an emerging paradigm to enhance network efficiency and perceptual quality, particularly demonstrating strong potential in image generation tasks. However, existing deep learning (DL)-based single-modal reconstruction approaches often suffer from semantic distortion and image blurring under bandwidth-limited and highly noisy channel conditions, limiting their suitability in task-oriented perception scenarios. Although generative AI-based semantic communication can significantly reduce data transmission volume, its high sensitivity to channel noise and lack of dynamic adaptation mechanisms limit the stability of reconstruction. To address these challenges, this paper proposes a multi-modal semantic communication framework named SEER , designed for resource-constrained intelligent sensing terminals. Built upon a pretrained language model, SEER incorporates a channel-aware prompt control strategy, a dual-modal integrative semantic restoration mechanism (DISR), and a single-pass sequential cross-modal reconstruction pathway to achieve collaborative semantic representation and robust structural recovery between images and text. Experimental results demonstrate that SEER achieves approximately 2.08 % bandwidth compression, while outperforming existing methods under extreme channel conditions by 33.92 % in structural fidelity and 12.64 % in perceptual consistency, highlighting its strong engineering deployability.},
  archive      = {J_KBS},
  author       = {Shengliang Wu and Jun Jiang and Xin He and Yong Xu and Yujun Zhu and Weiwei Jiang and Heju Li},
  doi          = {10.1016/j.knosys.2025.114464},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114464},
  shortjournal = {Knowl. Based Syst.},
  title        = {SEER: Knowledge-driven semantic image restoration with vision-language diffusion alignment},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating structural and operational knowledge into multi-state system modeling: Application in urban infrastructures. <em>KBS</em>, <em>329</em>, 114457. (<a href='https://doi.org/10.1016/j.knosys.2025.114457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern engineering systems, with their increasing complexity driven by technological advancements and growing interdependencies among components, present a challenge to traditional binary-state models. These models, which classify components as either fully operational or failed, are insufficient for capturing the progressive degradation, redundancy mechanisms, and cascading effects observed in real-world systems. Multi-State System (MSS) modeling, which represents intermediate operability states, is a step forward. However, the current literature overlooks a crucial information source: the system’s internal dynamics. These dynamics, which play a crucial role in shaping the system’s behavior, can be leveraged to enhance the learning process in MSS modeling. This study introduces a novel hybrid MSS modeling methodology that incorporates a system’s internal dynamic - such as network topology, redundancy mechanisms, and operational constraints - within an MSS. The methodology is first applied to a Brazilian power system, demonstrating how internal system characteristics influence the state evolution of individual components over time. This evaluation highlights the ability of the model to capture nuanced operational behavior driven by system-level constraints. The methodology is tested on multiple European transmission systems in a second stage to assess its predictive performance in estimating key reliability metrics. The proposed approach consistently outperforms existing models, achieving significantly lower prediction errors by accounting for internal constraints and the system’s dynamics. This work offers a generalizable solution for critical infrastructure planning across domains, enhancing MSS reliability modeling in various engineering systems.},
  archive      = {J_KBS},
  author       = {Henrique O. Caetano and Luiz Desuó N and Marco Aiello and Carlos D. Maciel},
  doi          = {10.1016/j.knosys.2025.114457},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114457},
  shortjournal = {Knowl. Based Syst.},
  title        = {Integrating structural and operational knowledge into multi-state system modeling: Application in urban infrastructures},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stock conditional drawdown at risk portfolio optimization based on gated bidirectional temporal convolution and discrete cosine graph neural networks on hypervariable graphs. <em>KBS</em>, <em>329</em>, 114456. (<a href='https://doi.org/10.1016/j.knosys.2025.114456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of machine learning technology, the application of stock prediction in financial portfolio optimization has become increasingly important. This study proposes an intelligent portfolio optimization method that combines gated bidirectional temporal convolution-discrete cosine graph neural network (TDGNN) with the mean-conditional drawdown at risk (Mean-CDaR) model, aiming to improve the risk-return performance of the portfolio. The method consists of two main stages: first, the data is converted into a hypervariable graph through the TDGNN model, the gated bidirectional temporal convolution layer is used to capture the temporal dynamic characteristics, and the discrete cosine graph neural network is combined to effectively model the complex spatiotemporal relationship in the stock market; second, the Mean-CDaR model is used for portfolio optimization, and the maximum drawdown is used as a measurement indicator to achieve precise risk control. Experimental results show that on the CSI 300, S&P500, and Nikkei 225 data sets, TDGNN and Mean-CDaR models perform significantly better than traditional methods, with R 2 of 0.9991, 0.9991, and 0.9983, respectively. Under the assumption of no transaction costs, the cumulative returns are 0.42, 0.62, and 0.93, respectively; considering 0.05 % transaction costs, the cumulative returns are 0.1, 0.25, and 0.49, respectively. The study shows that this method not only effectively captures the spatiotemporal dependency of stock data but also effectively controls risks while improving returns, providing investors with a robust and efficient decision support system.},
  archive      = {J_KBS},
  author       = {Chia-Hung Wang and Chiwang Lin},
  doi          = {10.1016/j.knosys.2025.114456},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114456},
  shortjournal = {Knowl. Based Syst.},
  title        = {Stock conditional drawdown at risk portfolio optimization based on gated bidirectional temporal convolution and discrete cosine graph neural networks on hypervariable graphs},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Utility and occupancy driven pattern analysis for processing dynamic data streams in damped window control. <em>KBS</em>, <em>329</em>, 114453. (<a href='https://doi.org/10.1016/j.knosys.2025.114453'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data analysis is suitable for data control systems by discovering hidden knowledge that is difficult for humans to perceive from huge and complex data. In various data analysis methods, high utility occupancy pattern analysis considers the utility occupancy of each pattern in the corresponding transaction in addition to the profit and quantity of patterns, which is effective for data control systems, including data science fields. However, recent data holds more insightful knowledge when processing real-time generated data. Previous occupancy-based approaches do not handle the relative significance of the latest data. To overcome the limitation, we introduce a new method for discovering high utility occupancy patterns from dynamic data streams where time-sensitive data consistently occurs. The proposed method assigns relative importance to each pattern by considering the temporal aspect of each transaction. Advanced constructing and restructuring processes are utilized in the proposed method for efficiently controlling data according to the time flow of each pattern in dynamic environments. In the pattern expansion process, a new upper bound adopting the decaying factor is suggested to efficiently reduce unnecessary searches for unpromising patterns. Experimental results demonstrate that the proposed method has superior runtime and scalability performance compared to state-of-the-art methods with comparable memory usage. The ablation study underscores how the proposed components contribute to the overall effectiveness of the proposed method. Additional evaluations indicate that the proposed method analyzes insightful result patterns compared to state-of-the-art methods, and a case study demonstrates its applicability to real-time dynamic data control systems.},
  archive      = {J_KBS},
  author       = {Taewoong Ryu and Doyoung Kim and Seungwan Park and Seongbin Park and Myungha Cho and Hanju Kim and Junyoung Park and Hyeonmo Kim and Unil Yun},
  doi          = {10.1016/j.knosys.2025.114453},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114453},
  shortjournal = {Knowl. Based Syst.},
  title        = {Utility and occupancy driven pattern analysis for processing dynamic data streams in damped window control},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel TriCore scheme for multiple RGB images in telemedicine environments. <em>KBS</em>, <em>329</em>, 114451. (<a href='https://doi.org/10.1016/j.knosys.2025.114451'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scientific community is paying high attention to propose efficient solution to the open problem related to security and privacy of still visual communications. Telemedicine is one of the real world applications, experiencing such security concerns related to virtual consultation. Among the presence of already defined encryption schemes, this paper is dedicated to define TriCore, an efficient encryption scheme for multiple RGB images, inspired by three core components: σ ∃ -permutation, Laplacian matrix and 4D hyper chaotic system. The use of Secure Hash Algorithm-256 (SHA-256) in key generation assures the randomness and make it highly sensitive. Also, this paper presents a novel σ ∃ -permutation, to enhance the randomness effect in the corresponding cipher image. The scheme mainly deals with the matrices corresponding to the three channels of the merged image, undergoing σ ∃ -permutation and XOR operations with pair of channel matrices and key matrices, a single cipher image is produced corresponding to multiple RGB images. It prevents the revelation of actual number of shared images and make the scheme more strong. Obtaining the ideal values, experimental results witness the efficiency of TriCore scheme. The entropy is measured as 7.9998. The high resistance against the differential attacks is measured through the Number of Pixel Change rate (99.6158 % ) and Unified Average Changing Intensity (33.4621 % ). The execution time for 4 images each of size 256 × 256 is just 0.173470 s. The experimental results show that this paper efficiently facilitates secure communications in telemedicine providing higher security at lowest computational costs.},
  archive      = {J_KBS},
  author       = {Muhammad Tanveer Hussain and Imrana Shafique and Shamsher Ullah},
  doi          = {10.1016/j.knosys.2025.114451},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114451},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel TriCore scheme for multiple RGB images in telemedicine environments},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). G-GTNet: Gestalt-inspired graph transformer network for robust point cloud registration. <em>KBS</em>, <em>329</em>, 114450. (<a href='https://doi.org/10.1016/j.knosys.2025.114450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Removing outliers is of paramount importance in the process of feature-based point cloud registration. However, it is still extremely challenging due to the high proportion of outliers, and the estimation of the accurate transmission matrix depends on the distribution of the inliers. The effective extraction of contextual information (local view) and the acquisition of full structural information (global view) influence the identification of inliers. Inspired by Gestalt principles in handling local and global relationships, we propose a Gestalt-inspired Graph Transformer Network (G-GTNet) for robust point cloud registration. G-GTNet extracts broader and more reliable contextual information while effectively aggregating both local and global features. Specifically, adhering to Gestalt principles, we design a multi-granularity aggregation (MGA) block that refines feature maps through a cascaded expanding path to acquire contextual details and promote information exchange among correspondences. In addition, to establish a consensus mechanism between local and global information, we introduce a global consensus attention (GCA) block. Similarly, the GCA follows Gestalt principles to optimally integrate local details and information about global structure, which allows it to gather information on a larger scale. Furthermore, a dependable seed selection (DSS) block is designed to filter out reliable and evenly distributed correspondences by distinguishing outliers and inliers more efficiently. Extensive experiments demonstrate that G-GTNet achieves better performance than state-of-the-art methods. It exhibits competitive performance and robustness in both outlier removal and pose estimation tasks across various public datasets with diverse feature descriptors. Notably, our proposed G-GTNet achieves an RR of 84.36 % on the 3DMatch using FPFH descriptor, surpassing S C 2 -PCR by 1.33 %. Our code will be released at https://github.com/gwk429/G-GTNet .},
  archive      = {J_KBS},
  author       = {Weikang Gu and Mingyue Han and Li Xue and Jiaming Yu and Heng Dong and Changcai Yang and Riqing Chen and Lifang Wei},
  doi          = {10.1016/j.knosys.2025.114450},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114450},
  shortjournal = {Knowl. Based Syst.},
  title        = {G-GTNet: Gestalt-inspired graph transformer network for robust point cloud registration},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precision through progression: Empowering temporal knowledge graph reasoning with knowledge-guided chain of thought. <em>KBS</em>, <em>329</em>, 114448. (<a href='https://doi.org/10.1016/j.knosys.2025.114448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Knowledge Graphs (TKGs) have emerged as a powerful paradigm for event forecasting, owing to their ability to dynamically represent the evolving relationships between entities over time. By effectively reasoning along the temporal dimension, TKGs help address real-world data incompleteness through inference of missing facts. Recent advances in large language models (LLMs) have led to their integration with TKG reasoning tasks. However, current LLM-based approaches face three critical challenges: (1) insufficient utilization of background knowledge, (2) inadequate modeling of the evolving temporal dynamics intrinsic to TKGs, and (3) difficulty in bridging the structural mismatch between the graph structure and the sequential operation mode of LLMs. To address these challenges, we propose EV-COT, a novel EVent-aware Chain-Of-Thought reasoning framework designed to explicitly model event evolution through structured, interpretable reasoning chains. EV-COT comprises three modular, plug-and-play components – knowledge module, perception module, and thinking module – that work collaboratively to extract essential event-related cues for enhanced reasoning. Specifically, the knowledge module generates high-quality contextual knowledge to enrich entity representation, and the perception module captures intricate structural and temporal patterns inherent in TKGs. Moreover, the thinking module extracts temporal logical rules, facilitating interpretable step-by-step reasoning. By effectively integrating these diverse contextual knowledge, EV-COT delivers more accurate predictions. Extensive evaluations on three datasets demonstrate that EV-COT consistently outperforms state-of-the-art methods, highlighting its effectiveness for precise event forecasting in TKGs.},
  archive      = {J_KBS},
  author       = {Zhangtao Cheng and Shichong Li and Yichen Xin and Bin Chen and Ting Zhong and Fan Zhou},
  doi          = {10.1016/j.knosys.2025.114448},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114448},
  shortjournal = {Knowl. Based Syst.},
  title        = {Precision through progression: Empowering temporal knowledge graph reasoning with knowledge-guided chain of thought},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Taxonomy-guided routing in capsule network for hierarchical image classification. <em>KBS</em>, <em>329</em>, 114444. (<a href='https://doi.org/10.1016/j.knosys.2025.114444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical multi-label classification in computer vision presents significant challenges in maintaining consistency across different levels of class granularity while capturing fine-grained visual details. This paper presents Taxonomy-aware Capsule Network (HT-CapsNet), a novel capsule network architecture that explicitly incorporates taxonomic relationships into its routing mechanism to address these challenges. Our key innovation lies in a taxonomy-aware routing algorithm that dynamically adjusts capsule connections based on known hierarchical relationships, enabling more effective learning of hierarchical features while enforcing taxonomic consistency. Extensive experiments on six benchmark datasets, including Fashion-MNIST, Marine-Tree, CIFAR-10, CIFAR-100, CUB-200-2011, and Stanford Cars, demonstrate that HT-CapsNet significantly outperforms existing methods across various hierarchical classification metrics. Notably, on CUB-200-2011, HT-CapsNet achieves absolute improvements of 10.32 % , 10.2 % , 10.3 % , and 8.55 % in hierarchical accuracy, F1-score, consistency, and exact match, respectively, compared to the best-performing baseline. On the Stanford Cars dataset, the model improves upon the best baseline by 21.69 % , 18.29 % , 37.34 % , and 19.95 % in the same metrics, demonstrating the robustness and effectiveness of our approach for complex hierarchical classification tasks.},
  archive      = {J_KBS},
  author       = {Khondaker Tasrif Noor and Wei Luo and Antonio Robles-Kelly and Leo Yu Zhang and Mohamed Reda Bouadjenek},
  doi          = {10.1016/j.knosys.2025.114444},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114444},
  shortjournal = {Knowl. Based Syst.},
  title        = {Taxonomy-guided routing in capsule network for hierarchical image classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning with gradient norm arbitration for sample-aware few-shot learning. <em>KBS</em>, <em>329</em>, 114443. (<a href='https://doi.org/10.1016/j.knosys.2025.114443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to rapidly adapt to unseen tasks is a fundamental objective in few-shot learning. Recent advances in optimization-based meta-learning have enhanced adaptability by learning sharable prior knowledge across tasks with just a few gradient descent steps. However, we argue that this shared prior knowledge can exert an imbalanced influence on individual samples within tasks, potentially resulting in a broad loss distribution where samples closely aligned with the prior knowledge exhibit low loss values, while others display high loss values. Furthermore, our experiments show that gradients computed as the average from a broad loss distribution tend to be non-representative and low, leading to poor generalization performance since the contribution of high-loss samples is diminished by low-loss samples. To address this, we propose a novel meta-learning method that arbitrates gradient norms based on sample-aware information during task adaptation. Specifically, we first normalize the gradient vector to reduce the imbalanced influence of prior knowledge on individual samples. Subsequently, the Arbiter, a learnable network, dynamically scales the current gradient norm by analyzing the relationship between original gradient norms and weight norms, which indicates the model’s sensitivity and complexity to each sample. In this way, the proposed method, Meta-learning with Gradient Norm Arbitration (Meta-GNA), improves generalization performance by preserving more representative and higher gradients that adequately reflect high-loss samples, which are distantly aligned with prior knowledge. Experimental results show that Meta-GNA improves performance in few-shot classification, particularly in cross-domain scenarios where the imbalance in prior knowledge across samples is more pronounced.},
  archive      = {J_KBS},
  author       = {Jongmin Lim and Soobin Cha and Heesan Kong and Sungkuk Shyn and Kwangsu Kim},
  doi          = {10.1016/j.knosys.2025.114443},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114443},
  shortjournal = {Knowl. Based Syst.},
  title        = {Meta-learning with gradient norm arbitration for sample-aware few-shot learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward efficient digital twin simulation: A causal representation learning approach. <em>KBS</em>, <em>329</em>, 114442. (<a href='https://doi.org/10.1016/j.knosys.2025.114442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, digital twin (DT) technology has emerged as a focal point in the field of shaft system prognostics and health management. To reduce simulation time cost and computational overhead, data-driven intelligent data generation algorithms have been employed as surrogates for traditional finite element simulations. However, such algorithms are typically constrained to generating in-distribution data within known operational domains and fail to generalize to out-of-distribution data under unseen conditions, which significantly hindering the development of DT model under variable operating scenarios. To address this limitation, this paper proposes a novel causal factorization–recombination network (CFRN) for generating shaft vibration responses under previously unseen operating conditions. Firstly, the structural causal model (SCM) for shaft vibration response is constructed to encode the causal mechanisms linking two critical operational parameters with vibration responses. Based on the SCM, a dual-encoder architecture is developed. By optimizing causal consistency loss, causal independence loss, and reconstruction loss, the model identifies latent mediators associated with the two causal factors. Additionally, a novel bidirectional cross-attention mechanism is introduced to equitably integrate mediators corresponding to different combinations of causal factors, enabling robust feature representation under unseen operational conditions. Finally, the recombined features are utilized to synthesize vibration response data. The proposed CFRN is validated using a shaft system simulation dataset. Extensive comparative experiments demonstrate that the generated data under unseen conditions by CFRN achieves 98.06% accuracy on crucial frequency. The proposed approach offers a novel paradigm for accelerating simulation response in DT frameworks.},
  archive      = {J_KBS},
  author       = {Shuyang Luo and Jiachang Qian and Yunhan Geng and Qi Zhou and Quan Lin},
  doi          = {10.1016/j.knosys.2025.114442},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114442},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward efficient digital twin simulation: A causal representation learning approach},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning methods for chaotic time series prediction. <em>KBS</em>, <em>329</em>, 114441. (<a href='https://doi.org/10.1016/j.knosys.2025.114441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chaos is a fundamental property of nonlinear dynamical systems, characterized by sensitivity to initial conditions, aperiodicity, and long-term unpredictability. It arises in numerous real-world processes-especially in energy systems, atmospheric dynamics, financial markets, and biomedical signals-where small perturbations may lead to drastic changes. Owing to its practical importance and modeling complexity, chaotic system prediction has received increasing attention in recent years. Regarding chaotic time series forecasting, deep learning offers strong capability in capturing nonlinear dependencies and long-horizon patterns. This review provides a comprehensive summary of deep learning techniques in this area, covering five core model classes: recurrent networks, convolutional structures, attention-based models, graph neural networks, and generative architectures. It also discusses hybrid modeling schemes, input-output paradigms, evaluation strategies, and complexity analysis. In addition, challenges-such as noise, missing data, and non-stationarity-are examined, along with recent efforts to mitigate them through signal decomposition, data completion, lightweight design, and loss adaptation. Real-world applications across diverse fields are surveyed to validate model effectiveness under complex conditions. This review offers new insight into the development of reliable, efficient, and generalizable deep learning frameworks for chaotic sequence prediction-highlighting directions such as physics-informed learning, lightweight architectures, and advanced hardware architectures.},
  archive      = {J_KBS},
  author       = {Yangyang Kui and Qiang Lai},
  doi          = {10.1016/j.knosys.2025.114441},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114441},
  shortjournal = {Knowl. Based Syst.},
  title        = {Deep learning methods for chaotic time series prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust label propagation based on prior-guided cross domain data augmentation for few-shot unsupervised domain adaptation. <em>KBS</em>, <em>329</em>, 114432. (<a href='https://doi.org/10.1016/j.knosys.2025.114432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot unsupervised domain adaptation (FS-UDA) aims to leverage knowledge from an imbalanced, labeled source domain and apply it to an unlabeled target domain. The primary difficulties of FS-UDA stem from the disparity in data distributions across source and target domains, coupled with uneven class representation in the source data. Label propagation (LP) is commonly used in domain adaptation scenarios. However, in FS-UDA tasks, LP disproportionately favors the normal classes because the source domain suffers from imbalanced class distribution, which results in insufficient feature representation and a large domain gap for the few-shot classes. To tackle these problems, we introduce a new robust LP approach that leverages prior-guided cross-domain data augmentation for FS-UDA. Unlike conventional approaches that solely utilize source domain visual data for few-shot class augmentation, our proposed method employs contrastive language image pretraining-derived semantic priors to supervise visual feature extractor training and optimize few-shot prototypes. It enhances domain-invariant feature learning while mitigating cross-domain distribution mismatches. We introduce the visual information from the target domain to perform data augmentation via style transfer, obtaining more diverse class-specific information. Subsequently, we capture intradomain and interdomain relationships more accurately by constructing intradomain and interdomain graphs independently for all samples (original and augmented) from both domains, which facilitates more effective LP and makes LP robust to few-shot classes. Furthermore, we introduce an adaptive graph regularization loss to dynamically adjust class weights, enhance intraclass compactness within domains, and reduce intraclass distribution discrepancies between different domains. Comprehensive experiments validate that the proposed method achieves superior performance compared to existing state-of-the-art methods across various FS-UDA tasks. The proposed method achieves 77.3 % and 61.7 % average accuracies for few-shot classes on the Office-31 and Office-Home datasets, respectively.},
  archive      = {J_KBS},
  author       = {Peng Zhao and Jiakun Shi and Ping Ye and Huiting Liu and Xia Ji},
  doi          = {10.1016/j.knosys.2025.114432},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114432},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust label propagation based on prior-guided cross domain data augmentation for few-shot unsupervised domain adaptation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced binary particle swarm optimization for mitigating pandemic spread through passenger air traffic management. <em>KBS</em>, <em>329</em>, 114430. (<a href='https://doi.org/10.1016/j.knosys.2025.114430'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study tackles a complex binary multi-objective optimization problem focused on minimizing the risk of pandemic importation through strategic passenger air traffic management. The approach involves determining whether international connections to destination airports within a specified country should be activated or deactivated over a defined time frame, considering epidemiological, economic, and socio-political impacts. We introduce a preliminary decision support system designed to assist decision-makers in the parametrization of the problem and quantify their preferences, thereby facilitating the derivation of a compromise solution via a binary particle swarm optimization (BPSO) metaheuristic. The standard BPSO is prone to particles getting trapped in local optima instead of searching for new solution and does not handle infeasible solutions properly. To overcome these inherent limitations, we propose an enhanced version of the BPSO metaheuristic. This enhanced algorithm incorporates novel mechanisms to promote solution space exploration and a robust strategy for managing infeasible solutions. A rigorous comparative analysis is conducted to evaluate the performance of the enhanced BPSO against both the original BPSO and several established state-of-the-art metaheuristics utilizing three benchmark datasets of a constrained problem. Finally, the effectiveness of the proposed enhanced metaheuristic is demonstrated in the context of the pandemic importation risk reduction problem, where it outperforms the original BPSO.},
  archive      = {J_KBS},
  author       = {Gabriel A. Peña and Antonio Jiménez-Martín and Alfonso Mateos},
  doi          = {10.1016/j.knosys.2025.114430},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114430},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced binary particle swarm optimization for mitigating pandemic spread through passenger air traffic management},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid domain based data embedding using quantization index modulation and metaheuristic optimization. <em>KBS</em>, <em>329</em>, 114429. (<a href='https://doi.org/10.1016/j.knosys.2025.114429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding additional information into digital images is an effective method of data privacy protection. A data hiding scheme needs to have a high level of imperceptibility to provide a high level of security. At the same time, it is necessary to maintain good capacity and ability to extract information in its original form. In this study, we propose an adaptive scheme for embedding data into the hybrid spatial-frequency domain of images based on the quantization index modulation (QIM) method. Information embedding is performed by small changes in pixels in the spatial domain using a change matrix. A genetic algorithm finds the optimal change matrix for each image block. The objective function combines visual invisibility, statistical invisibility, and extraction stability metrics. Information extraction is performed in the Discrete Cosine Transform (DCT) domain. Using the hybrid spatial-frequency domain reduces the number of DCTs and inverse DCTs when calculating objective function values during optimization. Additionally, we adaptively select quantization step values. Experimental results show that the proposed scheme is efficient in terms of embedding quality indicators. Moreover, the influence of additional information embedding on image histogram in the frequency domain is minimized. In terms of imperceptibility, our scheme achieves an average PSNR of 44.0920 dB, SSIM of 0.9995, and NCC of 0.9998 with an average capacity of 0.4640 bpp. The embedded information is extracted without errors in all cases and no additional information or re-optimization is required during extraction.},
  archive      = {J_KBS},
  author       = {Anna Melman and Oleg Evsutin},
  doi          = {10.1016/j.knosys.2025.114429},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114429},
  shortjournal = {Knowl. Based Syst.},
  title        = {Hybrid domain based data embedding using quantization index modulation and metaheuristic optimization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-coordinate graph representation with temporal edge encoding for multi-agent trajectory prediction. <em>KBS</em>, <em>329</em>, 114427. (<a href='https://doi.org/10.1016/j.knosys.2025.114427'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory prediction is critical in multi-agent systems, with applications in autonomous driving, surveillance, and robotic collaboration. It aims to anticipate future agent behaviors to support proactive decision-making. However, modeling the temporal evolution of agent interactions in complex environments remains challenging. This paper introduces a dual-perspective trajectory prediction framework that integrates a dual-coordinate graph representation with temporally-aware edge modeling. Agent-centric interactions are captured using graph attention networks, while global scene-level dependencies are modeled via a Transformer. A cross-perspective fusion module merges these complementary features into expressive node embeddings. To better capture dynamic interaction patterns, a temporal edge encoding module combines relative positional features with sequential information. This design improves the model’s temporal sensitivity and robustness. Experiments on Argoverse 1 and Argoverse 2 benchmarks show that the proposed method achieves strong single-modal prediction accuracy while maintaining competitive multi-modal performance. Ablation studies validate the contributions of each module, highlighting the framework’s effectiveness, generalization capability, and potential for real-world deployment in complex multi-agent scenarios.},
  archive      = {J_KBS},
  author       = {Xudong Zhang and Yingqun Liu and Jie Fan and Guodong Du and Yuan Zou and Xuan Liu},
  doi          = {10.1016/j.knosys.2025.114427},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114427},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-coordinate graph representation with temporal edge encoding for multi-agent trajectory prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DGPR: Towards privacy-preserving recommendation via bayesian data generation. <em>KBS</em>, <em>329</em>, 114425. (<a href='https://doi.org/10.1016/j.knosys.2025.114425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recommender system achieves more accurate user profile mining, the risk of user privacy disclosure increases. To address this, existing privacy protection-aware works model user interests and sensitive attributes and maintain independence between them. However, these efforts ignore the extraction of potentially interesting and similar items when modeling interest and sensitive properties. In this paper, a data generation-based privacy-aware recommendation (DGPR) is proposed to improve the modeling of interest and sensitive attributes to protect privacy. Specifically, a Bayesian data generation module is designed to construct the interaction behavior of potential interest items and potential attributes-similar items. Based on the generated data, DGPR learns representations of users/items with mutual information constraint to contain less sensitive attributes. In addition, DGPR focuses on the leakage of privacy from the recommendation list by using adversarial learning to remove sensitive attributes that were leakaged from the representation of the recommendation list of each user. A new metric RLP is designed to measure privacy leakage at the recommendation list level. Experiments are conducted on two publicly available datasets to verify the effectiveness of our proposed model in improving recommendation accuracy and privacy protection.},
  archive      = {J_KBS},
  author       = {Shenghao Liu and Guoyang Wu and Xianjun Deng and Hongwei Lu and Yuanyuan He and Minmin Cheng and Laurence Yang},
  doi          = {10.1016/j.knosys.2025.114425},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114425},
  shortjournal = {Knowl. Based Syst.},
  title        = {DGPR: Towards privacy-preserving recommendation via bayesian data generation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective optimization of sampling locations for source detection of antibiotic-resistant genes in hydrosystems. <em>KBS</em>, <em>329</em>, 114424. (<a href='https://doi.org/10.1016/j.knosys.2025.114424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Antimicrobial resistance is a growing global challenge with significant implications for public health. Wastewater surveillance offers a promising approach to monitoring and predicting the dissemination of antibiotic-resistant bacteria and genes (ARGs) in systems like sewer systems. However, current studies often lack integration between the optimization of sampling locations and the dynamic updating of predicted source locations based on continuous measurements. This paper proposes a novel data-driven framework that bridges this gap by combining multi-objective optimization for selecting optimal sampling locations with Bayesian updating for probabilistic source detection. The framework accounts for DNA degradation, sewage dilution and measurement variability to realistically simulate ARG concentrations in hydrosystems. Through iterative updates guided by detected signals at selected sampling locations, the model refines the likelihood of each sub-catchment being the main source of multiple ARGs, enabling accurate source localization. Validation was conducted using two real-world sewer systems under varying structural and sampling constraints. Across 1,000 simulated ARG scenarios and different sampler limits, results show that using only 3 and 5 samplers, the framework can achieve over 80% detection accuracy within four iterations; using 7 and 12 samplers raises accuracy to above 90%, depending on the complexity of the networks. These findings demonstrate the scalability, robustness, and practical applicability of the framework for ARG monitoring and decision support in diverse wastewater systems.},
  archive      = {J_KBS},
  author       = {Yao Yao and Regina Nogueira and Frank Klawonn and Markus Wallner},
  doi          = {10.1016/j.knosys.2025.114424},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114424},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-objective optimization of sampling locations for source detection of antibiotic-resistant genes in hydrosystems},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLAV: Clustering latent vector aggregation for whole slide image retrieval leveraging foundation models. <em>KBS</em>, <em>329</em>, 114423. (<a href='https://doi.org/10.1016/j.knosys.2025.114423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-Based Image Retrieval (CBIR) is crucial in cancer diagnosis, assisting pathologists by providing similar image data from previous records for analysis, especially when there is uncertainty in diagnosing a case. This process supports decision-making by providing valuable reference points to guide the diagnostic process. Foundation models have become increasingly important in the medical field due to their ability to generalize across various tasks and datasets, offering valuable support to pathologists by enhancing the accuracy and efficiency of diagnostic processes. In this article, a foundation model pre-trained on histopathology data is leveraged as a feature extractor without the need for task-specific training, in contrast to existing models that require extensive training to learn significant data representations. The proposed method, Clustering Latent Vector Aggregation (CLAV), condenses the significant feature vectors into a unique representative vector for the Whole Slide Image (WSI). Using a unique feature vector offers the advantage of reducing the size of the memory bank, thereby making the process of querying and retrieving similar WSIs more efficient. The experimental results presented in this study demonstrate that the proposed method enhances performance in CBIR tasks. This article highlights the potential of foundation models to achieve superior retrieval metrics compared to state-of-the-art methods specifically trained for CBIR.},
  archive      = {J_KBS},
  author       = {Alejandro Golfe and Pablo Meseguer and Valery Naranjo and Adrián Colomer},
  doi          = {10.1016/j.knosys.2025.114423},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114423},
  shortjournal = {Knowl. Based Syst.},
  title        = {CLAV: Clustering latent vector aggregation for whole slide image retrieval leveraging foundation models},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributor-centric model watermarking for image generative models. <em>KBS</em>, <em>329</em>, 114422. (<a href='https://doi.org/10.1016/j.knosys.2025.114422'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an efficient watermarking method for generative models that allows the developer (distributor) to create model instances with unique watermarks that are naturally embedded in their generated images. To achieve this, we replace the convolution layers of the generator with Watermark-Informed Convolution (WIC) in the pre-trained model. WIC consists of N parallel standard convolution kernels, and a watermark encoder transforms watermarks into coefficients that modulate these parallel kernels. Once fine-tuned with WIC, the distributor only needs to generate the coefficients and use them to combine the parallel kernels in WIC to create a generator with the desired watermark. Importantly, the combined kernel is identical to a standard convolution kernel, ensuring no additional inference overhead. Our method is highly scalable and efficient, making it practical for forensic capabilities by embedding watermarks directly into model parameters, remaining robust against common attacks such as model pruning or image compression. Furthermore, we evaluate our method on scenarios with highly aggressive compression or advanced adversarial attacks, and the trade-offs between watermark capacity, robustness, and computational efficiency. Experiments on multiple generative models demonstrate that the proposed method is architecture-agnostic, achieves high fidelity, and provides superior robustness compared to the existing methods.},
  archive      = {J_KBS},
  author       = {Jianwei Fei and Yunshu Dai and Wenyuan Yang and Zhihua Xia},
  doi          = {10.1016/j.knosys.2025.114422},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114422},
  shortjournal = {Knowl. Based Syst.},
  title        = {Distributor-centric model watermarking for image generative models},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QuadAt-GAN: Quad attention enabled generative adversarial network for photorealistic image generation. <em>KBS</em>, <em>329</em>, 114421. (<a href='https://doi.org/10.1016/j.knosys.2025.114421'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, photorealistic image generation has been a significant task in computer vision applications. Artificial intelligence-based generative models have attracted significant attention because they can generate samples that nearly resemble the properties of the training data. However, traditional methods leveraged for image generation tasks pose certain limitations such as model collapse, overfitting, and lack of diversity. As a result, this research aims to generate photorealistic images in the presence of adversarial attacks using the Quad Attention-enabled Generative Adversarial Networks (QuadAt-GAN) framework. The proposed QuadAt-GAN model can create photorealistic images from both text and image inputs. In addition, the incorporation of four different adversarial attacks in this research aids the system in fortifying itself against potential manipulations, thereby enhancing the robustness of the generated images. Moreover, the Quad attention (QuadAt) in the discriminator section refines the image generation process and equips the framework with a much better comprehension of the global information thus reducing the computational complexity of the model. The experimental results indicate the superiority of the proposed model for the photorealistic image generation task. When compared with the existing techniques the QuadAt-GAN model achieves a superior Structural similarity index measure (SSIM) of 0.95 for the Flickr 8k dataset with a training percentage of 80.},
  archive      = {J_KBS},
  author       = {Mohd Miskeen Ali and Mujahedullah H. Syed (S M) and Zeeshan Ahmed Mohammed and Ahmed Shahebaaz},
  doi          = {10.1016/j.knosys.2025.114421},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114421},
  shortjournal = {Knowl. Based Syst.},
  title        = {QuadAt-GAN: Quad attention enabled generative adversarial network for photorealistic image generation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-light image enhancement with luminance duality. <em>KBS</em>, <em>329</em>, 114420. (<a href='https://doi.org/10.1016/j.knosys.2025.114420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured under low-light conditions often suffer from high noise levels and a loss of details. Existing Low-light enhancement approaches often assume illumination as a global factor under Retinex theory, which may need to be more balanced with the complexities of real-world scenes with diverse lighting conditions. We propose a novel enhancement approach rooted in the Direct Perception (DP) theory. Through empirical evidence from real-world scenes, we illustrate the phenomenon of the duality of luminance in DP model, highlighting that luminance can exhibit both global and regional variations. Motivated by the above, we propose a novel low-light image enhancement framework, namely DPNet, that considers global and local luminance differences. Central to our approach is the introduction of two key modules: the Lumimator , a luminance estimator that leverages both local and global attention mechanisms, and the NLRestorer , a normal-light restoration network that effectively fuses color and luminance information for image restoration. Extensive experiments validate the efficacy of our framework, demonstrating significant enhancements in image quality metrics over state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Xingguo Lv and Xingbo Dong and Jiewen Yang and Lei Zhao and Bin Pu and Zhe Jin and Yudong Zhang},
  doi          = {10.1016/j.knosys.2025.114420},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114420},
  shortjournal = {Knowl. Based Syst.},
  title        = {Low-light image enhancement with luminance duality},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HBOFFS: Hybrid breeding optimization algorithm inspired federated feature selection for intrusion detection in IIoT. <em>KBS</em>, <em>329</em>, 114419. (<a href='https://doi.org/10.1016/j.knosys.2025.114419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection systems in the Industrial Internet of Things (IIoT) face challenges from high-dimensional, redundant data, making feature selection (FS) critical. Moreover, IIoT data is distributed across devices, creating data silos as for privacy concerns. Although federated learning (FL) has been extensively applied, existing federated FS methods based on swarm intelligence have limitations in both solution quality and convergence. To overcome these issues, we propose a hybrid breeding optimization algorithm inspired federated FS (HBOFFS) for intrusion detection in IIoT. Specifically, HBOFFS operates within a horizontal FL framework, where each client first employs a hybrid breeding optimization algorithm that integrates immune evolutionary mechanisms with cauchy distribution-based sampling (IC-HBO) to select a private optimal feature subset. IC-HBO improves both the global search capability and convergence efficiency of FS. Furthermore, a multi-client cooperative ensemble strategy (MCCES) is utilized, leveraging homomorphic encryption and secure multi-party computation to ensure the transmission of the feature weight matrix and corresponding indices of the selected feature subsets between clients and the server. The performance of HBOFFS is evaluated on several benchmark datasets, including CEC2022, UCI, NSL-KDD, HAI, and WUSTL-IIOT, using classifiers such as KNN, SVM, and XGBoost. The experimental results demonstrate that HBOFFS consistently outperforms state-of-the-art federated FS methods in terms of classification accuracy, recall, F1-score, runtime, and convergence speed, while effectively preserving data privacy.},
  archive      = {J_KBS},
  author       = {Zhiwei Ỹe and Songsong Zhang and Wen Zhou and Libing Wu and Ting Cai and Mingwu Zhang and Mingwei Wang and Jixin Zhang and Mengya Lei},
  doi          = {10.1016/j.knosys.2025.114419},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114419},
  shortjournal = {Knowl. Based Syst.},
  title        = {HBOFFS: Hybrid breeding optimization algorithm inspired federated feature selection for intrusion detection in IIoT},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge-driven deep reinforcement learning approach for dynamic scheduling of re-entrant hybrid flow shop with in-line product quality inspection. <em>KBS</em>, <em>329</em>, 114418. (<a href='https://doi.org/10.1016/j.knosys.2025.114418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time product quality inspection (QI) of products during manufacturing enables early defect detection and reduces resource waste. However, dynamic disturbances arising from QI, such as machine maintenance and rework operations, impose significant challenges to real-time production scheduling. In this study, a dynamic re-entrant hybrid flow shop scheduling problem considering in-line product quality inspection (DHFSP-QI) is investigated, where product quality variations dynamically impact production scheduling. To address this challenge, a multi-agent system (MAS) is developed to model dynamic shop-floor interactions among machines, quality detectors, products, and scheduling units. A knowledge-driven deep reinforcement learning (DRL) framework integrated with variable neighborhood search (KDRL-VNS) is proposed. The VNS-enhanced reward feedback mechanism guides agents to acquire efficient strategies. The DRL-enhanced scheduling agents use graph attention networks (GATs) to extract graph-based state representations of the workshop in real time, thereby enabling dynamic-scheduling decisions aimed at the minimizing total weighted tardiness. Experimental evaluations across multiple scenarios demonstrate that the proposed method, by incorporating VNS-based expert knowledge, outperforms various heuristic algorithms, genetic programming algorithms and DRL algorithms. It achieves accelerated convergence and delivers an average 4.6% relative improvement in performance compared to DRL methods.},
  archive      = {J_KBS},
  author       = {Youshan Liu and Jiaxin Fan and Chunjiang Zhang and Weiming Shen},
  doi          = {10.1016/j.knosys.2025.114418},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114418},
  shortjournal = {Knowl. Based Syst.},
  title        = {A knowledge-driven deep reinforcement learning approach for dynamic scheduling of re-entrant hybrid flow shop with in-line product quality inspection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WinGraphUNet: Advanced windowed graph modeling with remixed contextual learning for efficient medical image segmentation. <em>KBS</em>, <em>329</em>, 114417. (<a href='https://doi.org/10.1016/j.knosys.2025.114417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has achieved remarkable success in medical image segmentation. However, most existing methods treat images as regular grids (e.g., CNNs) or sequential structures (e.g., Transformers), which are not well-suited for the flexible extraction of irregular anatomical features in medical images. In this paper, we propose an efficient graph-based method, WinGraphUNet (Windowed Graph U-Net), for medical image segmentation. Our model innovatively integrates graph learning both within and between windows to capture local and global correlations efficiently. To merge local and global correlations across multi-scale feature maps effectively, we introduce a ReMixed Context Graph Bridge Block, which remixes multi-scale feature maps. Specifically, we use self-attention mechanisms to extract local features from non-overlapping windows, which can be treated as learning on fully connected graphs, and apply dynamic graph learning to capture long-range dependencies between windows, where inter-window connections are recomputed at each layer based on feature similarity. Our model fully leverages the flexibility of graphs to capture complex anatomical structures. Extensive experimental results on three medical image datasets ( i.e. , Synapse, Polyp, and ISIC2018 datasets) show that our approach outperforms state-of-the-art methods in segmentation accuracy. Notably, by reducing model parameters by 18 % and computational cost by 68 % compared to representative graph-based methods ( e.g. , AHGNN), our design significantly enhances the applicability of graph modeling in resource-constrained clinical scenarios, where model compactness and inference efficiency are critical. The code is publicly available at https://github.com/zndxyhn/WinGraphUNet .},
  archive      = {J_KBS},
  author       = {Xiaoyan Kui and Haonan Yan and Qinsong Li and Lingxiao Liu and Weixin Si and Wei Liang and Beiji Zou},
  doi          = {10.1016/j.knosys.2025.114417},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114417},
  shortjournal = {Knowl. Based Syst.},
  title        = {WinGraphUNet: Advanced windowed graph modeling with remixed contextual learning for efficient medical image segmentation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ScExGraph: Explainable graph neural network for predicting tumor environment components with single-cell sequencing data. <em>KBS</em>, <em>329</em>, 114416. (<a href='https://doi.org/10.1016/j.knosys.2025.114416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell RNA sequencing (scRNA-seq) enables high-resolution analysis of the tumor microenvironment (TME), yet it faces key challenges in cross-patient cell type annotation and interpretable cell interaction analysis. This study introduces scExGraph, a graph neural network framework that combines adversarial graph domain adaptation and dynamic subgraph learning. Initially, a cell-cell graph is constructed via KNN, and a dual-branch graph convolutional encoder (GCN) is used to disentangle domain-specific and shared features, with adversarial training and adjacency matrix reconstruction ensuring topological consistency. Subsequently, a random attention mechanism dynamically adjusts edge weights, and KL divergence constraints generate interpretable subgraphs to identify key cell nodes. Finally, based on experimentally validated tumor-immune interaction genes, t -tests analyze these key cell nodes to identify critical cell signaling pathways affecting immune responses. Experiments across colorectal, non-small cell lung, and breast cancer datasets (88,507 cells) show scExGraph achieves an average accuracy of 0.918 in cross-patient annotation, significantly better than the benchmark GCN, and identifies immune regulatory genes like CEACAM1 and USP15. This research offers an explainable graph learning framework for decoding TME heterogeneity, balancing computational efficiency and biological significance. The source code are available at: https://github.com/an-xing456/scExGraph .},
  archive      = {J_KBS},
  author       = {Zhihua Du and Jiale Yi and Jianqiang Li and Hai-Ru You and Zhu-Hong You and Zhi-An Huang and Yu-An Huang},
  doi          = {10.1016/j.knosys.2025.114416},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114416},
  shortjournal = {Knowl. Based Syst.},
  title        = {ScExGraph: Explainable graph neural network for predicting tumor environment components with single-cell sequencing data},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing polyp characterization in colon capsule endoscopy using ResNet9-KAN. <em>KBS</em>, <em>329</em>, 114415. (<a href='https://doi.org/10.1016/j.knosys.2025.114415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Aim: Colon capsule endoscopy (CCE) offers a minimally invasive method for imaging gastrointestinal lesions, including colorectal polyps, which may be precursors to colorectal cancer. However, its low image quality poses challenges for tasks such as polyp characterization. This work develops a low-complexity AI model, ResNet9-KAN, by integrating the Kolmogorov-Arnold network (KAN) into 9-layer residual network (ResNet9) architecture. This model efficiently characterizes polyps as neoplastic or non-neoplastic in CCE images, facilitating real-time patient management. Methods: This work utilized a CCE dataset generated from the PillCam Colon 2 system at four hospitals in the Region of Southern Denmark. It comprises 2089 CCE images of 479 polyps (317 neoplastic, 162 non-neoplastic) from a bowel cancer screening population aged 50 to 74. The proposed ResNet9-KAN and several existing AI models were trained on 1672 CCE images (221 neoplastic, 113 non-neoplastic polyps) and evaluated on 569 test images (48 neoplastic, 25 non-neoplastic polyps). Results: The evaluation revealed that our proposed ResNet9-KAN surpassed existing AI models with per-image characterization accuracy of 97.71 %, demonstrating an excellent balance between sensitivity (97.10 %) and specificity (98.17 %). It also achieved the highest F1 score of 0.9730 and a competitive area under the curve (AUC) of 0.9895. Additionally, ResNet9-KAN exhibited per-polyp characterization accuracy of 99.23 %, with a sensitivity of 99.85 %, specificity of 98.65 %, and an F1 score of 0.9912. Conclusions: This work highlights the efficacy of ResNet9-KAN in accurately characterizing polyps in low-quality CCE images, showing substantial potential for in situ characterization where histological verification currently requires a follow-up colonoscopy.},
  archive      = {J_KBS},
  author       = {Vinay Chakravarthi Gogineni and Jan-Matthias Braun and Benedicte Schelde-Olesen and Gunnar Baatrup and Esmaeil S. Nadimi},
  doi          = {10.1016/j.knosys.2025.114415},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114415},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing polyp characterization in colon capsule endoscopy using ResNet9-KAN},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential contrastive learning for progressive knowledge tracing. <em>KBS</em>, <em>329</em>, 114413. (<a href='https://doi.org/10.1016/j.knosys.2025.114413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, knowledge tracing has received significant attention in personalized education. It dynamically assesses users’ knowledge states based on their historical response sequence. User response sequences are central to knowledge tracing. While most studies focus on modeling short-term and long-term dependencies, few consider the order in which interactions occur. A recent study argues that the interaction order has little impact on users’ knowledge states (Lee et al. , The Web Conference, 2022), which contradicts both our intuition and constructivist learning theory. To address this contradiction, we propose a S equential Contrastive Learning algorithm for P rogressive K nowledge T racing, termed SPKT , to test the effectiveness of order information within the response sequences for assessing users’ knowledge states. SPKT embeds order information into the response sequence representation through a carefully designed contrastive learning module, and captures users’ monotonic memory decay patterns using a carefully designed non-symmetrical augmented view construction method. The enhanced sequence representation is subsequently utilized to decode user behavior with a progressive learning process module. Extensive experiments demonstrate that, on average, SPKT outperforms 10 baselines by up to 14 % in AUC and 8 % in ACC across 6 real-world datasets. Furthermore, the results highlight that the order information in response sequences significantly improves algorithmic performance-sometimes even more than the correctness of the responses themselves. Moreover, SPKT more accurately evaluates users with better academic performance and shorter learning sequences. For the same user, longer response sequences are more helpful in assessing a user’s knowledge state.},
  archive      = {J_KBS},
  author       = {Yi-Fei Wen and Hang Liang and Carl Yang and Tao Zhou and Jia Liu and Yajun Du and Yan-Li Lee},
  doi          = {10.1016/j.knosys.2025.114413},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114413},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sequential contrastive learning for progressive knowledge tracing},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel stochastic neural network framework for modeling and simulation of within-host chikungunya virus transmission with latency. <em>KBS</em>, <em>329</em>, 114412. (<a href='https://doi.org/10.1016/j.knosys.2025.114412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present an innovative stochastic computing framework for modeling and simulation of within-host transmission dynamics of Chikungunya virus infection, incorporating latency and randomness. We integrate a feedforward neural network with the Legendre spectral collocation method to provide accurate results for the complex nonlinear model. The stochastic model captures intrinsic randomness associated with disease progression. A rigorous theoretical analysis is conducted, establishing the stability of the disease-free equilibrium when the control reproduction number R ˜ 0 < 1 . To explore the model’s behavior under stochastic influences, we implement the spectral collocation scheme for numerical simulations and analyze the impact of key epidemiological parameters. Extensive computational experiments are performed to support the theoretical results. The effectiveness and reliability of the present neural network-enhanced scheme are assessed through multiple evaluation criteria, including regression performance, mean squared error (MSE), error distribution, and phase portrait analysis. Additionally, the developed approach is benchmarked against the standard spectral collocation method to demonstrate its improved accuracy and predictive capabilities. The present scheme can be effectively extended to simulate complex real-world systems beyond epidemic models.},
  archive      = {J_KBS},
  author       = {Shuo Li and Misbah Ullah and Saif Ullah and Taseer Muhammad and Qaiser Iqbal},
  doi          = {10.1016/j.knosys.2025.114412},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114412},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel stochastic neural network framework for modeling and simulation of within-host chikungunya virus transmission with latency},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing sentiment analysis with local and global memory in heterogeneous graph neural networks. <em>KBS</em>, <em>329</em>, 114411. (<a href='https://doi.org/10.1016/j.knosys.2025.114411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is an essential task in natural language processing (NLP) and is applicable in various areas, such as social media monitoring and consumer feedback assessment. Existing approaches, which are primarily based on transformer architectures, perform well in capturing contextual semantics; however, they often fail to model the structured relationships and long-range dependencies inherent in complex text, especially when multiple granularities (e.g., words, aspects, sentences) interact. To address this, we propose LGM-HGNN , a unique hybrid model that utilizes heterogeneous graph neural networks enhanced with hierarchical memory tracking through dynamic GRU gating. The proposed model uses rich graph representations to capture inter-word and inter-aspect relationships. Additionally, it incorporates a dual-level memory module, with local memory for instance-level detail and global memory for corpus-level sentiment trends, which are dynamically updated and fused for better sentiment tracking. Experiments using Twitter airline reviews and financial sentiment analysis datasets demonstrate that LGM-HGNN consistently outperforms transformer-based models, highlighting its effectiveness in aspect-based sentiment analysis (ABSA). Furthermore, LGM-HGNN combines structured graph representations with dynamic memory updates to improve sentiment tracking skills in many real-world applications.},
  archive      = {J_KBS},
  author       = {Md. Mithun Hossain and Sanjara and Md. Shakil Hossain and Sudipto Chaki and Md. Saifur Rahman and A B M Shawkat Ali},
  doi          = {10.1016/j.knosys.2025.114411},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114411},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing sentiment analysis with local and global memory in heterogeneous graph neural networks},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking interactive image matting as incremental gaussian process regression problems. <em>KBS</em>, <em>329</em>, 114410. (<a href='https://doi.org/10.1016/j.knosys.2025.114410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive Image Matting (IIM) aims to predict alpha mattes through user interaction. Traditional methods often depend on user experience to interact at the regions where the alpha matte are inaccurate. However, regions with inaccurate model predictions do not necessarily correspond to areas of high model uncertainty, so these methods are unable to effectively reduce model uncertainty, resulting in low interaction efficiency. To address this issue, we observe a commonality between IIM tasks and Gaussian Process (GP) regression: the former predicts alpha values of unlabeled pixels based on user-labeled information, while the latter predicts observations of unknown data based on known data and provides uncertainty estimation for predictions. Based on this observation, we model IIM as an incremental GP regression problem and propose a novel IIM paradigm, IIM-GP. First, IIM-GP is the first model to incrementally utilize model-predicted uncertainty to guide user interaction and update matting results, significantly enhancing interaction efficiency and prediction reliability. Second, an incremental update strategy is implemented within the GP framework, overcoming traditional GP models’ inefficiency in updating results for IIM tasks. Additionally, IIM-GP employs a strategy of selecting p inducing points from n labeled pixels to perform variational inference on GP, reducing computational complexity from O ( n 3 ) to O ( n p 2 ) ( p ≪ n ). Comprehensive experiments on five widely-used datasets (Composition-1k, AIM-500, Distinctions-646, HIM2K and AM-2K) demonstrate that IIM-GP achieves competitive performance.},
  archive      = {J_KBS},
  author       = {Bingjie Guo and Wenhui Huang},
  doi          = {10.1016/j.knosys.2025.114410},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114410},
  shortjournal = {Knowl. Based Syst.},
  title        = {Rethinking interactive image matting as incremental gaussian process regression problems},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physical imaging model-guided deep variational despeckling framework for ultrasound images. <em>KBS</em>, <em>329</em>, 114409. (<a href='https://doi.org/10.1016/j.knosys.2025.114409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despeckling is essential for enhancing the clinical interpretability of ultrasound (US) images, as speckle noise can obscure tissue details and complicate diagnoses. Traditional despeckling methods, which rely on physical models of US imaging, have proven effective but often suffer from parameter sensitivity, low computational efficiency, and a tendency to over-smooth images. In contrast, deep learning (DL) approaches excel at learning from large datasets and can significantly reduce speckle noise with high efficiency and flexibility. However, DL methods face two key challenges: the scarcity of ground-truth clean US images, which requires the use of simulated clean images that might not accurately reflect real-world conditions, and the lack of integration with prior knowledge, leading to reduced interpretability and generalizability. In this paper, we propose a novel deep Variational US Image Despeckling (VUID) framework that addresses these limitations. VUID integrates the strengths of model-based methods by incorporating prior knowledge of US imaging physics and statistical distributions of relevant parameters into a variational DL architecture. Unlike previous methods, VUID treats simulated clean US images as the mode of the distribution of ground-truth clean images, serving as a guide rather than as absolute ground truth for training, which thereby enables a more accurate representation. The framework employs two distinct deep convolutional networks to predict the parameters of variational posterior distributions for speckle noise variance and ground-truth clean images. These networks are jointly optimized using a hybrid loss function that combines an Evidence Lower Bound (ELBO) loss with an image reconstruction loss guided by the US imaging model. We conducted extensive experiments comparing VUID with state-of-the-art traditional and DL despeckling methods. Our tests included assessing overall despeckling performance on three synthetic and two real US datasets, evaluating robustness and generalizability on two unseen real US datasets, and demonstrating clinical value through diagnostic quality assessments by medical experts. The results demonstrate that VUID surpasses existing methods across multiple metrics, highlighting its potential to improve the diagnostic accuracy and clinical utility of ultrasonic imaging. The code is available at https://github.com/blackpearl2021/VUID .},
  archive      = {J_KBS},
  author       = {Wenchao Cui and Zhihong Pan and Xiaolong Li and Yongheng Tang and Shuifa Sun},
  doi          = {10.1016/j.knosys.2025.114409},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114409},
  shortjournal = {Knowl. Based Syst.},
  title        = {Physical imaging model-guided deep variational despeckling framework for ultrasound images},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust contrastive knowledge distillation for long-tailed noisy class labels. <em>KBS</em>, <em>329</em>, 114408. (<a href='https://doi.org/10.1016/j.knosys.2025.114408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training robust models on datasets with both long-tailed class imbalance and label noise is critical for real-world applications. Existing methods often fail to holistically address feature-space disentanglement and the synergy between noise robustness and imbalance mitigation. We propose Robust Contrastive Knowledge Distillation (RCKD) to bridge this gap. RCKD innovates in two aspects: (1) Diverse Multi-Expert Distillation: Peer networks with self-attention-driven weight diversification yield complementary feature/logit insights, coupled with synchronized logit calibration and feature disentanglement; (2) Dual-Mode Contrastive Learning: Unsupervised contrastive learning captures intrinsic geometry for pseudo-clean samples, while reweighted supervised contrastive learning enforces discriminative features for pseudo-noise samples using class-balanced queues. Extensive experiments show RCKD achieves state-of-the-art performance, e.g., +6.66 % over the best baseline on CIFAR-100-NLT (100:1 imbalance, 50 % noise).},
  archive      = {J_KBS},
  author       = {Shao-Yuan Li and Jinpeng Zheng and Mingguang Zhang and Dong Liang and Shaofang Li and Kangkan Wang},
  doi          = {10.1016/j.knosys.2025.114408},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114408},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust contrastive knowledge distillation for long-tailed noisy class labels},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density clustering hypersphere-based self-adaptively oversampling algorithm for imbalanced datasets. <em>KBS</em>, <em>329</em>, 114407. (<a href='https://doi.org/10.1016/j.knosys.2025.114407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalances are a common issue in machine learning. Oversampling, one of the most prevalently adopted strategies, is utilized to address this issue. However, the currently available oversampling techniques suffer from certain limitations when handling complex imbalanced datasets, such as introducing noisy samples that result in class overlap and failing to effectively tackle within-class imbalances caused by low-density and small disjuncts etc. To address these limitations, a Density Clustering Hypersphere-based Self-Adaptively Oversampling Algorithm (DCHO) is introduced in this paper. The approach first dynamically determines the clustering centers through calculating the density of minority class instances, constructs hyperspheres for clustering on each determined center and then adaptively adjusts the radius of the hypersphere according to the imbalance ratio. Finally, oversampling is performed within the hyperspheres to avoid class overlap. Additionally, it adaptively assigns oversampling weights based on local densities and the radius of the hyperspheres, thereby addressing within-class imbalances. To further enhance the boundary distribution of the minority class and explore the unknown minority class area, a new boundary-biased random oversampling technique is developed to conduct oversampling inside each hypersphere. Evaluation results show that DCHO significantly outperforms other popular oversampling algorithms in handling classification problems in imbalanced datasets.},
  archive      = {J_KBS},
  author       = {Tao Xinmin and Xu Annan and Shi Lihang and Li Junxuan and Guo Xinyue and Tao Sirui},
  doi          = {10.1016/j.knosys.2025.114407},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114407},
  shortjournal = {Knowl. Based Syst.},
  title        = {Density clustering hypersphere-based self-adaptively oversampling algorithm for imbalanced datasets},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated vulnerability score prediction through lightweight generative AI. <em>KBS</em>, <em>329</em>, 114406. (<a href='https://doi.org/10.1016/j.knosys.2025.114406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the constantly increasing number of newly published vulnerabilities, manually assessing their scores (e.g., under the Common Vulnerability Scoring System) has become unfeasible. Recently, learning-based systems have been proposed to automatically predict vulnerability scores. Such systems use vulnerability indexing databases to train deep learning algorithms. However, their practical applicability has important limitations, including a high dependency on the quality and diversity of training data, and high computational requirements. In addition, vulnerability descriptions often do not follow the standard templates and are not rich enough with respect to the expected features. In this paper, we propose a novel architecture that takes advantage of both generative artificial intelligence and lightweight deep learning techniques to provide an efficient and effective solution for automated vulnerability scoring. Data extracted from the National Vulnerability Dataset is fed into a large language model layer, whose output (i.e., an augmented dataset) is then used in a lightweight fine-tuned BERTsmall layer. We provide the results of an extensive experimental assessment of the effect of both each layer of the architecture and end-to-end performances. The results suggest that the combination of GPT3.5-Turbo and BERTsmall provides the most effective accuracy-time trade-off. We also compare the performance of the proposed architecture with other LLMs, BERT models, and cutting-edge approaches. The results show good improvements in prediction quality also when compared to a recent technique that incorporates data from 66 different sources, including the NVD.},
  archive      = {J_KBS},
  author       = {Seyedeh Leili Mirtaheri and Andrea Pugliese and Valerio Pascucci},
  doi          = {10.1016/j.knosys.2025.114406},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114406},
  shortjournal = {Knowl. Based Syst.},
  title        = {Automated vulnerability score prediction through lightweight generative AI},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Query-efficient and dataset-independent red teaming for LLMs content safety evaluation. <em>KBS</em>, <em>329</em>, 114404. (<a href='https://doi.org/10.1016/j.knosys.2025.114404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) are widely used for their remarkable ability to understand and generate natural language. Nevertheless, LLMs can also produce unintended outputs that pose significant social risks. Red teaming can identify potential security vulnerabilities in LLMs and support mitigating such risks. However, existing red teaming approaches struggle to balance query efficiency and generalizability due to their complex search processes or reliance on pre-existing datasets. To address these issues, we present RAPT, a query-efficient and dataset-independent red teaming approach. RAPT employs an adaptive generate-select framework that consists of four cyclic steps: generating test cases by an LLM-based generator, selecting test cases by an reinforcement learning (RL)-based selector, testing the target model, and refining the generator and the selector. In this framework, the generator is used to generate test cases, and the selector is used to select test cases. We introduce a contrast prompt template and diversity demonstration extraction method to guide the generator, incorporating previous test feedback as demonstrations to generate more effective and diverse test cases. For the selector, we formalize the test case selection process as a Markov decision process (MDP), allowing us to design a reinforcement learning-based agent to continuously optimize the selection policy, which is able to balance the effectiveness and diversity of test cases according to a compound reward function. Experimental results show that RAPT can effectively discover more successful and diverse test cases than existing methods within a limited number of queries without relying on any pre-existing dataset.},
  archive      = {J_KBS},
  author       = {Shuo Liu and Xiang Cheng and Sen Su},
  doi          = {10.1016/j.knosys.2025.114404},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114404},
  shortjournal = {Knowl. Based Syst.},
  title        = {Query-efficient and dataset-independent red teaming for LLMs content safety evaluation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-assisted explainable decision traces (BAXDT): An approach for transparency and accountability in artificial intelligence systems. <em>KBS</em>, <em>329</em>, 114402. (<a href='https://doi.org/10.1016/j.knosys.2025.114402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing opacity and lack of verifiable audit trails in AI decision-making systems pose significant challenges to establishing trust and accountability, particularly in high-impact domains. This paper introduces Blockchain-Assisted Explainable Decision Traces (BAXDT), a novel architecture designed to enhance the transparency and auditability of AI systems. BAXDT creates comprehensive, immutable records for each AI decision by integrating model outputs, SHAP-based XAI summaries, a novel Explanation Density Metric, and detailed model/data context into a unified JSON trace. The 0.80 threshold for the Explanation Density Metric was empirically supported by Kneedle-based automatic threshold detection. The BAXDT architecture leverages blockchain by recording a cryptographic hash of each decision trace on-chain, while the full trace is stored off-chain. The system's effectiveness was demonstrated through a multi-faceted evaluation: simulations across three diverse public datasets (medical, financial, educational) confirmed its domain-agnostic applicability; a scalability analysis of up to 20,000 traces demonstrated its efficient and linear performance; and a successful deployment on the Ethereum Sepolia public testnet verified its real-world viability. A case study on text data further underscored the framework's flexibility. BAXDT provides a robust framework for documenting AI decisions - what, why, based on what, and when - thereby fostering trustworthy AI and supporting regulatory compliance.},
  archive      = {J_KBS},
  author       = {İsmail Enes Parlak},
  doi          = {10.1016/j.knosys.2025.114402},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114402},
  shortjournal = {Knowl. Based Syst.},
  title        = {Blockchain-assisted explainable decision traces (BAXDT): An approach for transparency and accountability in artificial intelligence systems},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDGC: Fuzzy deep clustering with dual-granularity contrastive learning. <em>KBS</em>, <em>329</em>, 114401. (<a href='https://doi.org/10.1016/j.knosys.2025.114401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep clustering has garnered considerable attention in data mining and computer vision due to its effectiveness in handling high-dimensional data. However, traditional deep clustering methods face notable limitations. Real-world data often exhibit complex feature distributions and ambiguous boundaries. Fixed network architectures struggle to capture both global and local dependencies among data samples and are inadequate for managing fuzzy boundaries. Additionally, contrastive learning methods commonly used in deep clustering suffer from inefficient negative sample selection, where many positive samples are mistakenly treated as negative, thereby hindering training. To address these challenges, this paper proposes a fuzzy deep clustering method with dual-granularity contrastive learning (FDGC). The method extracts features and clusters them to generate pseudo-labels, retaining only the reliable ones through a confidence screening mechanism for use as supervision signals. By integrating data augmentation strategies with a self-attention fuzzy network, FDGC effectively captures both context and local details while dynamically adapting to feature fuzziness. Furthermore, a dual-granularity contrastive loss function is introduced to enhance feature representation. This loss improves sample discriminability at both the cluster and instance levels, significantly mitigating the issue of inaccurate negative sampling in traditional contrastive learning. Experimental results across multiple benchmark datasets demonstrate that FDGC outperforms existing method, validating the effectiveness of the proposed approach.},
  archive      = {J_KBS},
  author       = {Hengrong Ju and Jing Guo and Weiping Ding and Witold Pedrycz and Xiaotian Cheng and Xibei Yang},
  doi          = {10.1016/j.knosys.2025.114401},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114401},
  shortjournal = {Knowl. Based Syst.},
  title        = {FDGC: Fuzzy deep clustering with dual-granularity contrastive learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmented decoding method using semantic diverse beam search for language generation model. <em>KBS</em>, <em>329</em>, 114400. (<a href='https://doi.org/10.1016/j.knosys.2025.114400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning, the task of automatically generating natural language descriptions from visual content, has achieved remarkable accuracy in recent years. However, current approaches face a critical limitation in semantic diversity. Most diversity-oriented methods evaluate similarity at the surface lexical level, incorrectly treating lexically different but semantically equivalent phrases (e.g., 'dog runs' vs 'canine sprints') as meaningfully diverse outputs. This superficial approach fails to capture true semantic variation. Consequently, generated captions appear different but convey essentially identical meanings. To address this fundamental limitation, we propose Semantic Diverse Beam Search (SDBS), an augmented decoding algorithm that operates in semantic space rather than surface lexical space. SDBS integrates four key innovations: knowledge graph-based semantic similarity scoring, adaptive thresholding for important word focus, statistics-based stratified top-k sampling, and beam size normalization. Additionally, we introduce an early-stop strategy that significantly reduces computational complexity while maintaining generation quality, making SDBS practically viable for real-world applications. Comprehensive experiments demonstrate that SDBS achieves superior performance on both traditional metrics and modern evaluation approaches (BARTScore++, LLM-based assessment), generating captions with genuine semantic diversity while maintaining high accuracy and computational efficiency.},
  archive      = {J_KBS},
  author       = {HyungSun Na and Hee-Gook Jun and Jinhyun Ahn and Dong-Hyuk Im},
  doi          = {10.1016/j.knosys.2025.114400},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114400},
  shortjournal = {Knowl. Based Syst.},
  title        = {Augmented decoding method using semantic diverse beam search for language generation model},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent space refinement for unsupervised cyber threat text classification. <em>KBS</em>, <em>329</em>, 114399. (<a href='https://doi.org/10.1016/j.knosys.2025.114399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification plays a critical role in Cyber Threat Intelligence (CTI) applications, where open-source text data is mined to identify patterns such as Indicators of Compromise (IoC), Tactics, Techniques and Procedures (TTPs), Named Entities and more. However, the dynamic nature of CTI makes traditional supervised machine learning classifiers impractical due to their reliance on large number of labelled training datasets. To address this, we propose Latent Space Refinement (LSR), an unsupervised method designed for CTI text classification. LSR introduces a posterior regularisation strategy where an auxiliary distribution derived from a TF-IDF feature space serves as signals to refine latent representations derrived from Pretrained Language Models (PLMs). By iteratively refining this latent space with clustering signals, LSR enables efficient similarity-based classification using only a few user-provided seed keywords. Extensive experiments on diverse CTI tasks, including both binary and multi-class classification, demonstrate that LSR consistently outperforms state-of-the-art unsupervised and zero-shot/few-shot methods in Accuracy and Weighted F1 score, all without tuning internal PLM parameters. This makes LSR a lightweight and PLM-agnostic solution for real-world CTI applications.},
  archive      = {J_KBS},
  author       = {Yue Wang and Richi Nayak and Md Abul Bashar and Mahinthan Chandramohan},
  doi          = {10.1016/j.knosys.2025.114399},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114399},
  shortjournal = {Knowl. Based Syst.},
  title        = {Latent space refinement for unsupervised cyber threat text classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-gate self-distillation network for efficient image super-resolution. <em>KBS</em>, <em>329</em>, 114398. (<a href='https://doi.org/10.1016/j.knosys.2025.114398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The balanced extraction of both non-local and local features represents a critical requirement for effective image super-resolution (SR). While transformer-based self-attention (SA) mechanisms demonstrate superior non-local modeling capabilities, their substantial computational demands limit practical deployment. To address this efficiency-performance trade-off, the Spatial-Gate Self-Distillation Network (SGSDN) implements a dual-capacity architecture combining: an SA-like (SAL) module employing strategically dilated 1D depthwise convolutions in horizontal and vertical orientations for efficient non-local feature extraction, and a lightweight local spatial-gate (LKG) block optimized for local detail preservation. Moreover, the proposed spatial-gate self-distillation block (SGSDB) further enhances performance through an optimized distillation structure that simultaneously processes both feature types while minimizing memory overhead. Experimental results demonstrate SGSDN’s superior performance-complexity balance, with benchmark evaluations showing comparable accuracy to SwinIR-light while requiring only 25% of the computational resources (FLOPs) and 25% of parameters, attributable to its avoidance of computationally intensive matrix operations.},
  archive      = {J_KBS},
  author       = {Yinggan Tang and Mengjie Su and Quansheng Xu},
  doi          = {10.1016/j.knosys.2025.114398},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114398},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatial-gate self-distillation network for efficient image super-resolution},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Like or dislike? capturing heterogeneity in social recommendation via motif-induced capsules. <em>KBS</em>, <em>329</em>, 114397. (<a href='https://doi.org/10.1016/j.knosys.2025.114397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many trust-based social recommender systems have focused on heterogeneity in trust relations, but this heterogeneity is considered only for explicit neighbors. Most of the existing works overlook heterogeneity in the high-order network structure of user-user social networks. Most of them assume that the power of trust relationship of a neighbor on a target user is constant and applies the same value when considering different categories of recommendations. To overcome the above challenges, we propose a model architecture named Motif-induced attention-based Capsule Graph Convolutional Networks ( mCGCNs ). To the best of our knowledge, this is the first study in which the capsule network extracts multiple latent social-aware user vectors and latent preference-based user vectors of a target user, which vary from item to item based on the recommendation. To extract multiple latent social-aware user vectors, we not only consider explicit neighbors but also consider implicit neighbors, and regarding this the motif networks capture the complex higher-level pattern of interactivities among users. The investigations and empirical analyses on publicly available real-world datasets (Ciao, Epinions, and Library Thing) illustrate the effectiveness of our model compared to 13 popular baselines. It outperforms the best baseline model by margins ranging from 9.86 % to 12.78 % in HR@10, 13.07 % to 13.55 % in NDCG@10, 7.63 % to 8.97 % in MAE, 6.05 % to 7.24 % in RMSE for three datasets of product recommendations. Through ablation study, key components in mCGCNs are validated to benefit the recommendation performance improvement.},
  archive      = {J_KBS},
  author       = {Supriyo Mandal and Ralf Krestel},
  doi          = {10.1016/j.knosys.2025.114397},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114397},
  shortjournal = {Knowl. Based Syst.},
  title        = {Like or dislike? capturing heterogeneity in social recommendation via motif-induced capsules},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCWANet: A hyperspectral anomaly detection network with multi-stage collaborative optimization of wavelet convolution and attention mask. <em>KBS</em>, <em>329</em>, 114396. (<a href='https://doi.org/10.1016/j.knosys.2025.114396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral anomaly detection (HAD), a key research area in remote sensing, aims to efficiently identify and localize anomalous targets. However, challenges such as the high dimensionality of hyperspectral data, the sparse and complex distribution of anomalous targets, and the strong diversity of backgrounds make it difficult to distinguish anomalies from the background, thereby affecting detection accuracy. Existing methods often rely on background reconstruction for anomaly detection, but this approach tends to weaken the expression of the anomalous targets themselves, neglecting the core task of detection–accurate identification and localization of anomalous regions. To address this issue, this paper proposes a Multi-stage Cooperative Wavelet Convolution and Attention Mask Network (MCWANet), which aims to simultaneously enhance anomaly enhancement and background reconstruction capabilities, thereby effectively amplifying the differences between anomalies and the background. MCWANet employs a wavelet-based multi-spectral feature extractor, using low-frequency information for background modeling and high-frequency information for anomaly enhancement and boundary refinement. Meanwhile, a progressive attention refinement module, based on a spatial attention mechanism, dynamically generates adaptive masks to highlight potential anomalous regions and suppress background interference. Finally, a spectral-spatial residual fusion module integrates multi-source information, balancing anomaly enhancement and background modeling. Extensive experimental results on six public datasets show that, compared to ten state-of-the-art methods, MCWANet demonstrates superior anomaly detection performance and stronger generalization ability in complex backgrounds.},
  archive      = {J_KBS},
  author       = {Yuquan Gan and Xingyu Li and Siyu Wu and Ji Zhang and Ying Liu},
  doi          = {10.1016/j.knosys.2025.114396},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114396},
  shortjournal = {Knowl. Based Syst.},
  title        = {MCWANet: A hyperspectral anomaly detection network with multi-stage collaborative optimization of wavelet convolution and attention mask},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PADetBench: Towards benchmarking texture- and patch-based physical attacks against object detection. <em>KBS</em>, <em>329</em>, 114395. (<a href='https://doi.org/10.1016/j.knosys.2025.114395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical attacks against object detection have gained significant attention due to their practical implications. However, conducting physical experiments is time-consuming and labor-intensive, and controlling physical dynamics and cross-domain transformations in the real world is challenging, leading to inconsistent evaluations and hindering the development of robust models. To address these issues, we rigorously explore realistic simulations to benchmark physical attacks under controlled conditions. This approach ensures fairness and resolves the problem of capturing strictly aligned adversarial images, which is challenging in the real world. Our benchmark includes 23 physical attacks, 48 object detectors, comprehensive physical dynamics, and evaluation metrics. We provide end-to-end pipelines for dataset generation, detection, evaluation, and analysis. The benchmark is flexible and scalable, allowing easy integration of new objects, attacks, models, and vision tasks. Based on this benchmark, we generate comprehensive datasets and perform over 8000 evaluations, including overall assessments and detailed ablation studies. These experiments provide detailed analyses from detection and attack perspectives, highlight limitations of existing algorithms, and offer revealing insights. The code and datasets are publicly available at https://github.com/JiaweiLian/PADetBench .},
  archive      = {J_KBS},
  author       = {Jiawei Lian and Jianhong Pan and Lefan Wang and Yi Wang and Shaohui Mei and Lap-Pui Chau},
  doi          = {10.1016/j.knosys.2025.114395},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114395},
  shortjournal = {Knowl. Based Syst.},
  title        = {PADetBench: Towards benchmarking texture- and patch-based physical attacks against object detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot temporal knowledge graph completion based on query-adaptive mamba-enhanced temporal relation learning. <em>KBS</em>, <em>329</em>, 114394. (<a href='https://doi.org/10.1016/j.knosys.2025.114394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot Temporal Knowledge Graph Completion (FTKGC) aims to predict missing facts when only a few instances are available for each relation. The shared relation between known few-shot instances and the query quadruple is highly time-dependent, while existing approaches model it as static. Static relation modeling faces two key challenges: First, neighbor aggregation relies on fully connected attention mechanisms, ignoring the sequential nature of neighbor quadruples. Second, relation learning treats support set knowledge as static, overlooking its dynamic temporal relations with the query. In this paper, we propose a novel F TKGC framework based on query- A daptive M amba- E nhanced temporal relation learning ( FAME ) to address above challenges. Specifically, our approach presents a three-stage relation representation learning strategy. It integrates neighbor-aware modeling for sequential neighbor aggregation, instance-aggregated modeling for relation learning across instances, and time-sensitive modeling to capture query-adaptive temporal dynamics. Experiments demonstrate the effectiveness of FAME on three benchmark datasets and validate the contribution of the proposed strategies.},
  archive      = {J_KBS},
  author       = {Xingyue Guo and Ying Zhang and Yu Zhao and Baohang Zhou and Xuhui Sui and Xinying Qian and Xiaojie Yuan},
  doi          = {10.1016/j.knosys.2025.114394},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114394},
  shortjournal = {Knowl. Based Syst.},
  title        = {Few-shot temporal knowledge graph completion based on query-adaptive mamba-enhanced temporal relation learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting online order satisfaction with lagged data using WGAIN-GP. <em>KBS</em>, <em>329</em>, 114393. (<a href='https://doi.org/10.1016/j.knosys.2025.114393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce has grown a lot in recent years and so has the research performed in this field. In this paper we estimate order satisfaction by predicting outcomes of relevant variables at the moment an order is made, such that companies can act on this signal. In order to deal with data that is not known at the order date (i.e., lagged missing data), we propose an extension of an existing generative imputation method. The Generative Adversarial Imputation Network (GAIN) is suitable for data imputation on tabular datasets. A more stable method is the Wasserstein GAIN (WGAIN). In this paper, we propose to improve this method by adding the Gradient Penalty to WGAIN resulting in WGAIN-GP. We perform experiments on a large dataset from a Dutch online retailer. Using WGAIN-GP we obtain a better accuracy of 61 % at the order date compared to 54 % and 53 % obtained by GAIN and WGAIN, respectively.},
  archive      = {J_KBS},
  author       = {Bette Donker and Evita Hoogeveen and Lars Hurkmans and Daan Schopmeijer and Flavius Frasincar and Enzo Ido and Jasmijn Klinkhamer},
  doi          = {10.1016/j.knosys.2025.114393},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114393},
  shortjournal = {Knowl. Based Syst.},
  title        = {Predicting online order satisfaction with lagged data using WGAIN-GP},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Virtual regularized bipartite graph learning for multi-view subspace clustering. <em>KBS</em>, <em>329</em>, 114392. (<a href='https://doi.org/10.1016/j.knosys.2025.114392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MVSC) has been widely studied for its ability to effectively capture the underlying structural information of multi-view data and achieve impressive clustering performance. As the volume of real-world data continues to grow, existing multi-view subspace clustering algorithms are unable to effectively tackle large-scale datasets. Therefore, multi-view subspace clustering methods based on bipartite graphs have been proposed to effectively solve the time complexity problem. Moreover, existing bipartite graph methods inevitably cause information loss due to the use of anchor points instead of the original data, leading to degradation of clustering performance. To address the above problems, we propose a virtual regularized bipartite graph learning for multi-view subspace clustering (VRBGL-MVSC) method, which utilizes anchors and bipartite graph learning to deal with the complexity associated with large-scale datasets. Specifically, we incorporate projection learning to generate discriminative anchor graphs in potentially low-dimensional spaces. Additionally, we propose a novel virtual regularization (VR) technique to guide bipartite graph learning, which explores multi-view data information faster and more efficiently. Furthermore, we develop an algorithm with good convergence to optimize VRBGL-MVSC. Experimental data show that in tests on four large-scale datasets, the VRBGL-MVSC algorithm outperformed all comparison algorithms, with improvements in the NMI metric of 0.17 %, 1.79 %, 1.13 %, and 3.24 % compared to the next-best results. This result clearly demonstrates that the VRBGL-MVSC algorithm excels in handling large-scale multi-view subspace clustering tasks and possesses a significant performance advantage.},
  archive      = {J_KBS},
  author       = {Linlin Ma and Wenke Zang and Xincheng Liu and Yuzhen Zhao and Xiyu Liu and Zhenni Jiang and Baoqiang Yan and Yawen Chen},
  doi          = {10.1016/j.knosys.2025.114392},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114392},
  shortjournal = {Knowl. Based Syst.},
  title        = {Virtual regularized bipartite graph learning for multi-view subspace clustering},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Target-guided dialog generation with dynamic knowledge path by commonsense knowledge graph and relation prediction. <em>KBS</em>, <em>329</em>, 114390. (<a href='https://doi.org/10.1016/j.knosys.2025.114390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational AI has been rapidly advancing with the development of large language models and has shown excellent performance. However, one of its limitations is a passive system that cannot ask or guide users back to ambiguous questions. To overcome this, we have implemented an active dialog system that can smoothly transition from previous conversations. Our system is a target-guided system, which means it can guide the conversation by asking the user to provide a desired response or target. This approach is knowledge-rich and challenging, as it requires achieving the target while maintaining contextual consistency. To generate responses, we dynamically construct knowledge paths through knowledge graphs and relation predictors. These play an essential role in generating diverse and logically connected responses. To achieve this, we follow a global planning method that systematically conducts conversations with a target, and constructs knowledge paths based on common sense. We perform multi-hop reasoning and bi-directional search simultaneously to increase diversity and logical connectivity. We have overcome the limitations of existing works that rely solely on knowledge graphs by reflecting the results of relation predictors along with each object’s WIKI data in the path. Therefore, the consideration of the knowledge graph and the performance of the relation predictor, compared to the existing system, in completing the dynamic knowledge path and generating transition responses allowed conversations to transition more naturally. We have verified the proposed model through experiments.},
  archive      = {J_KBS},
  author       = {Hayoung Lee and Soyeop Yoo and Woong-Kee Loh and Ok-Ran Jeong},
  doi          = {10.1016/j.knosys.2025.114390},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114390},
  shortjournal = {Knowl. Based Syst.},
  title        = {Target-guided dialog generation with dynamic knowledge path by commonsense knowledge graph and relation prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward transformer-compatible multivariate time series learning via visibility graph-based structural encoding. <em>KBS</em>, <em>329</em>, 114389. (<a href='https://doi.org/10.1016/j.knosys.2025.114389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series (MTS) modeling plays a crucial role in understanding complex systems. However, existing Transformer-based approaches often struggle to capture essential temporal structures, leading to information loss and even attention dispersion. To address these challenges, we propose MVGFormer , a novel Trans former -compatible M ultivariate Time Series framework guided by V isibility G raph principles. By explicitly establishing connections between time points based on visibility criteria, we introduce a graph-based sparse Attention (VG-Attention) mechanism, which selectively focuses on crucial temporal dependencies while filtering out irrelevant noise. This sparse Attention significantly mitigates the impact of quadratic complexity, improving scalability for larger time series data. Moreover, considering existing models often overlook the global dependencies within MTS, we extract consensus information across channels and aggregate the multiplex visibility graph into a consensus graph, revealing potential cross-layer patterns. Compared to single-channel models, MSE decreases by 2.82 %, classification accuracy increases by 9.73 %, and training speed improves by 67.48 %. Experimental results across 25 real-world datasets demonstrate that MVGFormer outperforms most existing models in four main tasks, including forecasting, classification, imputation, and anomaly detection. Overall, our approach provides a fresh perspective on adapting Transformers to better understanding temporal dependencies within time series data.},
  archive      = {J_KBS},
  author       = {Ting Chen and Xinyue Ren and Jinzhou Lai and Hongming Tan and Fangming Liu and Wai Kin Victor Chan},
  doi          = {10.1016/j.knosys.2025.114389},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114389},
  shortjournal = {Knowl. Based Syst.},
  title        = {Toward transformer-compatible multivariate time series learning via visibility graph-based structural encoding},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic partial person embedding for visible-infrared person re-identification with twin noise labels. <em>KBS</em>, <em>329</em>, 114388. (<a href='https://doi.org/10.1016/j.knosys.2025.114388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twin Noise Labels (TNL) in Visible-Infrared Person Re-identification (VI-ReID) introduce annotation errors, severely impacting identity consistency. Besides, these misannotations contaminate identity correspondences and increase feature uncertainty, leading to degraded retrieval performance. Existing methods predominantly rely on point-based feature representations, which extract isolated identity features but struggle to capture the distributional variations caused by noise. To address these issues, we propose Probabilistic Partial Person Embedding ( P 3 E ), which introduces a multi-probabilistic embedding strategy that models local body regions as Gaussian distributions, capturing regional uncertainty. Additionally, we propose a probabilistic embedding fusion for Re-ID, which adaptively integrates local probabilistic embeddings to form a more robust identity representation. Furthermore, a Probabilistic Embedding Triplet loss is introduced to ensure distributional consistency and enhance cross-modal identity discrimination. Extensive experiments on SYSU-MM01 and RegDB demonstrate that P 3 E significantly outperforms state-of-the-art methods. Particularly in noisy-label scenarios, it achieves superior robustness and Re-ID accuracy, effectively mitigating the impact of TNL.},
  archive      = {J_KBS},
  author       = {Wen Guo and Manyu Wei and Jing Sun and Tuo Zhou and Junling Gao},
  doi          = {10.1016/j.knosys.2025.114388},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114388},
  shortjournal = {Knowl. Based Syst.},
  title        = {Probabilistic partial person embedding for visible-infrared person re-identification with twin noise labels},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing sparse triplet overlapping relation extraction using triaxial syntactic fusion approach. <em>KBS</em>, <em>329</em>, 114387. (<a href='https://doi.org/10.1016/j.knosys.2025.114387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation Extraction (RE) is a crucial component of information extraction, with the challenge of overlapping RE presenting considerable complexity. In this overlapping scenario, text often contains multiple relation triplets involving shared entities, requiring advanced methods to disentangle the complex semantics. Some existing works or large language models cannot address the nuances of overlapping semantics in special low information density cases with longer text but sparse triplets. To address this, we introduce the Triaxial Syntactic Fusion Approach (TSFA), which leverages shortest dependency paths (SDP) to fuse semantics and capture their nuance. By identifying candidate SDPs for overlapping entity pairs and transforming these into a comprehensive fusion SDP token set, TSFA grasps contextual clues to resolve overlapping RE more effectively. Subsequently, the TSFA integrates two attention mechanisms in three dimensions to direct the attention weights toward semantically significant tokens. This method facilitates the efficient interaction of all entities in a single step, thereby enhancing the model to capture nuance semantics in sparse triplet scenarios. Our extensive experiments on the widely recognized overlapping datasets demonstrate TSFA’s superior performance, achieving an excellent improvement in the F1-score over most of the leading baselines. 1},
  archive      = {J_KBS},
  author       = {Hailin Wang and Ran Tao and Xiufen Fang and Guisong Liu and Ke Qin},
  doi          = {10.1016/j.knosys.2025.114387},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114387},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing sparse triplet overlapping relation extraction using triaxial syntactic fusion approach},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel data-driven input shaping method using residual impulse vector via unscented kalman filter. <em>KBS</em>, <em>329</em>, 114385. (<a href='https://doi.org/10.1016/j.knosys.2025.114385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by escalating demands for precision and speed in modern industrial applications, residual vibrations in flexible structures and underactuated systems have emerged as a critical technical challenge, particularly during high-speed emergency braking scenarios. Input shaping has proven to be an effective technique for vibration control. However, existing input shapers commonly encounter challenges with time delay and inaccurate parameters, leading to suboptimal control performance. To address these critical issues, this paper proposes an Unscented Kalman filter-based Residual negative equal-magnitude Shaping (URS) model with two-fold ideas: a) reducing the time delay and compensating the modeling error via the consideration of negative and residual impulse vector; and b) identifying system parameters using a data-driven unscented Kalman filter to enhance control effectiveness. To validate its performance, four experimental datasets from laboratory systems have been established and publicly released. Empirical studies demonstrate that the proposed URS model has achieved a significant vibration suppression effect over several state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Weiyi Yang and Yuqi Li and Mingsheng Shang and Shuai Li and Shiping Wen},
  doi          = {10.1016/j.knosys.2025.114385},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114385},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel data-driven input shaping method using residual impulse vector via unscented kalman filter},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An explainable multi-task similarity measure: Integrating accumulated local effects and weighted fréchet distance. <em>KBS</em>, <em>329</em>, 114384. (<a href='https://doi.org/10.1016/j.knosys.2025.114384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many machine learning contexts, tasks are often treated as interconnected components with the goal of leveraging knowledge transfer between them, which is the central aim of Multi-Task Learning (MTL). Consequently, this multi-task scenario requires addressing critical questions: which tasks are similar, and how and why do they exhibit similarity? In this work, we propose a multi-task similarity measure based on Explainable Artificial Intelligence (XAI) techniques, specifically Accumulated Local Effects (ALE) curves. ALE curves are compared using the Fréchet distance, weighted by the data distribution, and the resulting similarity measure incorporates the importance of each feature. The measure is applicable in both single-task learning scenarios, where each task is trained separately, and multi-task learning scenarios, where all tasks are learned simultaneously. The measure is model-agnostic, allowing the use of different machine learning models across tasks. A scaling factor is introduced to account for differences in predictive performance across tasks, and several recommendations are provided for applying the measure in complex scenarios. We validate this measure using four datasets, one synthetic dataset and three real-world datasets. The real-world datasets include a well-known Parkinson’s dataset and a bike-sharing usage dataset — both structured in tabular format — as well as the CelebA dataset, which is used to evaluate the application of concept bottleneck encoders in a multitask learning setting. The results demonstrate that the measure aligns with intuitive expectations of task similarity across both tabular and non-tabular data, making it a valuable tool for exploring relationships between tasks and supporting informed decision-making.},
  archive      = {J_KBS},
  author       = {Pablo Hidalgo and Daniel Rodriguez},
  doi          = {10.1016/j.knosys.2025.114384},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114384},
  shortjournal = {Knowl. Based Syst.},
  title        = {An explainable multi-task similarity measure: Integrating accumulated local effects and weighted fréchet distance},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prostate cancer forecasting in small samples based on lightweight neural networks using ensemble learning. <em>KBS</em>, <em>329</em>, 114383. (<a href='https://doi.org/10.1016/j.knosys.2025.114383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prostate cancer is the most common malignancy among Australian men, with over 20 000 new diagnoses each year. Accurate forecasts of its incidence and mortality inform stakeholder decision-making and help mitigate its public health impact. In this context, we introduce cutting-edge lightweight neural networks into the domain of prostate cancer data forecasting with edge intelligence for the first time. To address the issue of overfitting in coarse-grained and small-scale prostate cancer datasets, we employ structurally streamlined models: the Gated Recurrent Unit (GRU) and Temporal Convolutional Network (TCN), representing two predominant branches of neural networks. The GRU’s simplified gating mechanism maintains excellent long-term dependencies capturing capability while drastically reducing parameter count, and the TCN combines sparse connections, parameter sharing, and causal dilated convolutions for efficient temporal modeling. To further bolster generalization, we integrate multiple regularization strategies, including the snapshot ensemble method. Comparative experiments on three real-world prostate cancer datasets demonstrate that our improved lightweight, high-performance neural networks achieve over 40 % higher accuracy than linear time series forecasting suitable for small-scale datasets.},
  archive      = {J_KBS},
  author       = {Yuting Cao and Ziyu Sheng and Haibin Zhu and Tingwen Huang and Shiping Wen},
  doi          = {10.1016/j.knosys.2025.114383},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114383},
  shortjournal = {Knowl. Based Syst.},
  title        = {Prostate cancer forecasting in small samples based on lightweight neural networks using ensemble learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating the validity of structure learning algorithms in identifying risk factors for intervention in patients with diabetes. <em>KBS</em>, <em>329</em>, 114382. (<a href='https://doi.org/10.1016/j.knosys.2025.114382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes, a pervasive and enduring health challenge, imposes significant global implications on health, financial healthcare systems, and societal well-being. This study undertakes a comprehensive exploration of various structural learning algorithms to discern causal pathways amongst potential risk factors influencing diabetes progression. This study evaluates a diverse set of structure learning algorithms to discern causal pathways amongst potential risk factors influencing diabetes progression. The methodology involves the application of these algorithms to relevant diabetes data, followed by the conversion of their output graphs into Causal Bayesian Networks (CBNs), enabling predictive analysis and the evaluation of discrepancies in the effect of hypothetical interventions within our context-specific case study. This study highlights the substantial impact of algorithm selection on intervention outcomes. To consolidate insights from diverse algorithms, we employ a model-averaging technique that helps us obtain a unique causal model for diabetes derived from a varied set of structural learning algorithms.We also investigate how each of those individual graphs, as well as the average graph, compare to the structures elicited by a domain expert who categorised graph edges into high confidence, moderate, and low confidence types, leading into three individual graphs corresponding to the three levels of confidence. The resulting causal model and data are made available online, and serve as a valuable resource and a guide for informed decision-making by healthcare practitioners. Our applied work integrates and evaluates existing causal structure learning methods for decision support in patients with diabetes. It offers a comprehensive understanding of the interactions between relevant risk factors for intervention, and enables us to simulate the effect of hypothetical interventions before implementation. Therefore, this research not only contributes to the academic discussion on diabetes, but also provides practical guidance for healthcare professionals in developing efficient intervention and risk management strategies.},
  archive      = {J_KBS},
  author       = {Sheresh Zahoor and Anthony C. Constantinou and Tim M. Curtis and Mohammed Hasanuzzaman},
  doi          = {10.1016/j.knosys.2025.114382},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114382},
  shortjournal = {Knowl. Based Syst.},
  title        = {Investigating the validity of structure learning algorithms in identifying risk factors for intervention in patients with diabetes},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained multimodal molecular pretraining via prompt learning. <em>KBS</em>, <em>329</em>, 114381. (<a href='https://doi.org/10.1016/j.knosys.2025.114381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the advancement of pretraining models has revolutionized artificial intelligence, driving significant progress across various domains. In drug discovery, these models have shown remarkable potential by leveraging large-scale data to learn generalizable molecular representations, accelerating the identification of promising drug candidates. However, existing models often rely on atom-based reconstruction techniques to handle molecular structures, yet they frequently overlook substructural details such as functional groups and rings—elements that are critical for drug design and discovery. Furthermore, these models exhibit limitations in task adaptability, which impedes their precision in interpreting and predicting complex chemical environments. To address these challenges, we introduce MolFinePrompt, a fine-grained multimodal molecular pretraining model designed to enhance the representational capacity of molecular structures by integrating functional group data into their topological framework. Employing a contrastive learning approach, MolFinePrompt is pre-trained on a dataset of 316K molecular structure-text pairs and features bespoke task prompt texts for optimized fine-tuning, thereby improving its task-specific comprehension. The effectiveness of MolFinePrompt is validated through exemplary experimental results on cross-modal retrieval, molecular property prediction, and drug interaction prediction tasks.},
  archive      = {J_KBS},
  author       = {Yang Li and Zhengxin Wei and Chang Liu and Guohua Wang},
  doi          = {10.1016/j.knosys.2025.114381},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114381},
  shortjournal = {Knowl. Based Syst.},
  title        = {Fine-grained multimodal molecular pretraining via prompt learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PK-net: A prior knowledge-driven dual-path network for enhanced glaucoma screening. <em>KBS</em>, <em>329</em>, 114374. (<a href='https://doi.org/10.1016/j.knosys.2025.114374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma is a chronic ocular disease that often remains undiagnosed until advanced stages, highlighting the need for early detection. Current state-of-the-art methods mainly adapt attention mechanisms into classification networks designed for natural images via transfer learning, but they fail to capture domain-specific features and show weak cross-dataset generalization. In this paper, we propose a prior knowledge-driven dual-path network (PK-Net) that integrates medical knowledge into model architecture for glaucoma screening. First, based on the diagnostic importance of the optic disc, we introduce the Global and Local Fusion Network (GloLocNet), which combines high-resolution local optic disc images with global fundus images and applies a triple-loss strategy to improve feature extraction. Second, to leverage the strong inter-eye correlation of glaucoma, we propose the Binocular Fusion Network (BFNet), where paired eye images are processed through parallel GloLocNet encoders and fused to yield joint screening results. PK-Net was validated on multiple datasets, achieving superior intra- and cross-dataset results. For PAPILA, AUC, BAcc, Sen, and Spe were 95.67 %, 91.18 %, 88.72 %, and 93.63 %; for OIA-ODIR, 92.43 %, 85.64 %, 84.62 %, and 86.67 %. Trained on ORIGA and tested on REFUGE, the values were 90.00 %, 82.29 %, 81.25 %, and 83.33 %, demonstrating strong generalization. On GAMMA, results were 95.16 %, 83.37 %, 75.49 %, and 91.29 %. These findings indicate that PK-Net effectively enhances glaucoma screening by embedding prior medical knowledge into network design.},
  archive      = {J_KBS},
  author       = {Xiaoyan Kui and Zeru Hai and Beiji Zou and Yang Li and Wei Liang and Zuheng Ming and Liming Chen},
  doi          = {10.1016/j.knosys.2025.114374},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114374},
  shortjournal = {Knowl. Based Syst.},
  title        = {PK-net: A prior knowledge-driven dual-path network for enhanced glaucoma screening},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label feature selection based on positive sample information weighting. <em>KBS</em>, <em>329</em>, 114373. (<a href='https://doi.org/10.1016/j.knosys.2025.114373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection has garnered significant attention due to its capacity to reduce data dimensionality while effectively eliminating noise and irrelevant features. Information-theoretic methods are predominant in this domain, as they aim to quantify the relevance and redundancy among features, as well as between features and labels. However, existing information-theoretic methods frequently disregard the inherent distributional differences between positive and negative samples when assessing relevance and redundancy among variables. In multi-label data sets, positive samples associated with the same label tend to be more concentrated in the feature space, whereas negative samples exhibit a more dispersed distribution. This disparity is particularly evident in datasets characterized by label sparsity. The dispersed distribution of feature values for negative samples often results in reduced discriminative power and increased susceptibility to noise. To mitigate this limitation, we propose a novel feature selection method termed Multi-label Feature Selection based on Positive Sample Information Weighting (PSIWFS). PSIWFS assigns higher weights to features that demonstrate strong correlations with positive samples during the feature selection process, thereby enhancing the identification and prioritization of the less frequent positive samples. Experimental evaluations conducted on 14 datasets with 7 comparison methods underscore the superior classification performance of the proposed method.},
  archive      = {J_KBS},
  author       = {Qingqi Han and Ruikai Shi and Liang Hu and Wanfu Gao},
  doi          = {10.1016/j.knosys.2025.114373},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114373},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-label feature selection based on positive sample information weighting},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing pre-training via target-aware source data selection. <em>KBS</em>, <em>329</em>, 114371. (<a href='https://doi.org/10.1016/j.knosys.2025.114371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, due to the explosive popularity of large-scale pre-trained models such as large language models, pre-training approaches that use a massive amount of source data and can be applied to various target tasks are becoming more popular. Pre-trained models allow us to learn highly accurate target models by fine-tuning them with target data, even when their volume is insufficient. However, the source data used to train a pre-training model is generally a large and miscellaneous data set obtained in the wild without being aware of the target task, and it highly possibly contains much data that does not contribute to relearning the target task. This study defines a novel paradigm as “target-aware source data selection,” which uses the source data itself instead of a pre-training model and selects source data for pre-training and aims to increase its quality, effectiveness, and robustness. Our proposal fundamentally differs from the current studies addressing the lack of target data and conventional transfer learning approaches, improving source data quality using the novel Domain Adaptation Information Gain criteria. Specifically, the target model is pre-trained while actively selecting only informative data from the source data using the “rough-prior knowledge” obtained from the target data training before the pre-training. Finally, fine-tuning the model with the target data results in a highly accurate model for the target (downstream) task. The effectiveness of our proposed paradigm has been demonstrated through multifaceted experiments using multiple pairs of target data and source data with different strengths of their relevance.},
  archive      = {J_KBS},
  author       = {Kanyu Miyoshi and Ryotaro Shimizu and Linxin Song and Masayuki Goto},
  doi          = {10.1016/j.knosys.2025.114371},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114371},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimizing pre-training via target-aware source data selection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TSH-FCNet: Triple-source heterogeneous remote sensing images fusion classification network based on feature propagation and perception. <em>KBS</em>, <em>329</em>, 114370. (<a href='https://doi.org/10.1016/j.knosys.2025.114370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the diversification of remote sensing (RS) sensor types, the accessibility and availability of various RS data types are continuously improving. The collaborative use of multi-source RS data can comprehensively and effectively improve the accuracy of RS for earth observation. However, current research on multi-source RS image fusion classification primarily focuses on only two types of RS data. The heterogeneous characteristics of three or more types of RS data significantly complicate the data fusion process. In particular, how to effectively explore the correlations among the inherent characteristics of three or more heterogeneous RS data remains a critical challenge that has not been effectively addressed. This greatly affects the accuracy of RS land classification and other earth observation tasks. To address this issue, a TSH-FCNet based on feature propagation and perception for collaborative classification of hyperspectral (HS), multispectral (MS), and radar images is proposed. This network thoroughly explores the intrinsic correlations among the three heterogeneous data sources and employs an innovative feature interaction mechanism to leverage their complementary advantages. It overcomes the interference of heterogeneous characteristics between different data sources on fusion, effectively enhancing the final classification accuracy. Specifically, a distance similarity attention guides the mutual perception and fusion of triple-source RS information, promoting the flow of complementary features among the triple-source and improving the final classification accuracy. Additionally, the shared information from the triple-source RS data is injected into the features to be fused through a domain alignment mechanism, enhancing the spatial and semantic consistency of the features, thereby strengthening the classification model’s ability to recognize complex surface features. We tested the algorithm on three triple-source RS datasets. The experimental results indicate that the proposed algorithm achieves significant improvements over existing mainstream methods, exhibiting greater stability and reliability when handling highly heterogeneous and diverse data sources. The implementation code of this algorithm will be available from https://github.com/cwlnnu/TSH-FCNet .},
  archive      = {J_KBS},
  author       = {Wei Cheng and Yining Feng and Yuting Zhao and Xianghai Wang},
  doi          = {10.1016/j.knosys.2025.114370},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114370},
  shortjournal = {Knowl. Based Syst.},
  title        = {TSH-FCNet: Triple-source heterogeneous remote sensing images fusion classification network based on feature propagation and perception},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced prototype network with gated point recyclable feature mining for few-shot 3D point cloud classification. <em>KBS</em>, <em>329</em>, 114369. (<a href='https://doi.org/10.1016/j.knosys.2025.114369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the high annotation cost of 3D point cloud and the natural long-tail distribution across categories, 3D Point Cloud Few-shot Learning (3DPC-FSL) has arisen and attracted wide attention. However, as a core step of representation, max-pooling results in a substantial loss of point information and, thereby, leads to unsatisfactory performance, particularly with limited training data. The current solution for addressing this issue is to project 3D data into a series of 2D views and then aggregate the resulting 2D features for sufficient mining of point information. However, such a solution unavoidably neglects the internal 3D structure of point clouds. Herein, we propose a pure 3D approach named Enhanced Prototype Network with Gated Point Recyclable Feature Mining (EPN-GPRFM) for 3DPC-FSL. EPN-GPRFM follows the prototype-based FSL paradigm and enhances this paradigm from the perspectives of feature learning and prototype representation. In terms of feature learning, EPN-GPRFM enhances the 3DPC features by cyclically and adaptively mining the beneficial information from discarded points via a gating mechanism in each stage. In terms of prototype representation, EPN-GPRFM sufficiently exploits query samples to compensate the prototypes via a query-guided prototype enhancement strategy. Experiments on three well-known 3DPC benchmarks validate the effectiveness of our method and its prominent performance advantages over baselines.},
  archive      = {J_KBS},
  author       = {Hailin Wang and Sheng Huang and Luwen Huangfu and Ma Rui and Bo Liu},
  doi          = {10.1016/j.knosys.2025.114369},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114369},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced prototype network with gated point recyclable feature mining for few-shot 3D point cloud classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal prompting and masking strategy for video-grounded dialogue. <em>KBS</em>, <em>329</em>, 114367. (<a href='https://doi.org/10.1016/j.knosys.2025.114367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-Grounded Dialogue (VGD) is a challenging vision-language task aimed at engaging in multi-turn dialogues with humans based on video and audio content. Despite significant progress in improving AI-generated responses has been made, several challenges remain: 1) A significant amount of computing resources and time are required during training; 2) Current dominant approaches, utilizing T5 or GPT2 as base models, exhibit limited ability to understand video and audio features due to their text-based pre-training paradigms; 3) Existing studies have not addressed the robustness of models in real-world scenarios where dialog history is often missing. To address these issues, we propose VPM, a Video-Grounded Dialogue framework employing prompt-based tuning and a masking strategy. Firstly, to reduce computation resources, inspired by prompt learning, we are the first to employ prompt-based tuning in Video-Grounded Dialogue task by using only 20 % of the training set while maintaining proximal accuracy. Secondly, to enhance the model’s understanding of video and audio, we propose a slicing-based visual mapping network, integrating learnable visual prompts and video-audio slice features sequentially through a series of operations. Finally, we put forward an exponentially masking strategy for dialogue history to improve cross-modal understanding and robustness. Extensive experiments validate the effectiveness of our proposed framework, achieving state-of-the-art performance on the AVSD@DSTC7 and AVSD@DSTC8 datasets.},
  archive      = {J_KBS},
  author       = {Feifei Xu and Wang Zhou and Fumiaoyue Jia},
  doi          = {10.1016/j.knosys.2025.114367},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114367},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multimodal prompting and masking strategy for video-grounded dialogue},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data preprocessing using banded structure and image morphology enhancing boolean matrix factorization. <em>KBS</em>, <em>329</em>, 114366. (<a href='https://doi.org/10.1016/j.knosys.2025.114366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boolean Matrix Factorization (BMF) is a widely used method for revealing underlying patterns, called factors, in data. In the paper, we propose a novel data preprocessing method that makes patterns more visible, thus simplifying the overall BMF process. The method first reorders the data to reveal a banded structure. Then, it applies image morphology to enhance this structure by emphasizing important information and suppressing less relevant information. We demonstrate the efficacy of our approach through various experimental evaluations, showing that it effectively modifies the data, resulting in fewer, more interpretable factors. The proposed method also allows using more straightforward and faster BMF algorithms while maintaining high-quality results.},
  archive      = {J_KBS},
  author       = {Klara Brazdilova and Martin Trnecka and Marketa Trneckova},
  doi          = {10.1016/j.knosys.2025.114366},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114366},
  shortjournal = {Knowl. Based Syst.},
  title        = {Data preprocessing using banded structure and image morphology enhancing boolean matrix factorization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MTSL-TimesNet: A multi-task self-supervised learning model based on TimesNet for EEG emotion recognition. <em>KBS</em>, <em>329</em>, 114364. (<a href='https://doi.org/10.1016/j.knosys.2025.114364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, electroencephalogram (EEG)-based emotion recognition tasks have attracted considerable interest. Current approaches predominantly rely on single-task learning to extract latent features and construct general models, which can result in overfitting and weak generalization of the model. To resolve this issue, we propose a Multi-Task Self-Supervised Emotion Recognition Method (MTSL-ERM). This method first eliminates the baseline signal from the raw EEG data and maps the processed signals onto a brain electrode map. The processed data is input into MTSL-TimesNet, a novel deep learning model based on TimesNet architecture. The model enables cross-task knowledge sharing and multi-task optimization through spatial jigsaw and contrastive learning tasks. Specifically, the spatial jigsaw task aims to capture spatial patterns across different brain regions, while the contrastive learning task introduces a time-frequency enhancement method and generates instance-level hard negative samples to preserve key temporal relationships in the time series, thereby enhancing the model’s discriminative capability. Through enhancing the resemblance of similar samples and reconstructing time sequences, the model better regularizes feature learning and improves its ability to learn the data’s inherent patterns. Results on the DEAP and DREAMER datasets show MTSL-ERM’s superiority over current approaches. The classification accuracy for arousal and valence in subject-dependent experiments on the DEAP dataset are 96.30 % and 95.92 % , respectively. Meanwhile, on the DREAMER dataset, the accuracies are 90.76 % and 90.66 % , respectively.},
  archive      = {J_KBS},
  author       = {Yongqi Li and Qiuhong Hong and Jibin Yin and Luyao Han and Shoulin Wei and Xiangliang Zhang},
  doi          = {10.1016/j.knosys.2025.114364},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114364},
  shortjournal = {Knowl. Based Syst.},
  title        = {MTSL-TimesNet: A multi-task self-supervised learning model based on TimesNet for EEG emotion recognition},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiplane depth image for view-consistent light field depth estimation. <em>KBS</em>, <em>329</em>, 114363. (<a href='https://doi.org/10.1016/j.knosys.2025.114363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light field cameras capture both spatial and angular information of light rays, offering rich data that has made center-view depth estimation a topic of significant interest in recent years. However, the limited flexibility of center-view depth estimation presents substantial challenges for real-world applications, underscoring the need for full-view depth estimation. A primary challenge in this domain is ensuring view consistency. Multiplane Image is a widely used technique for view synthesis, which represents a 3D scene as a series of parallel 2D image planes. Inspired by this structure, we propose a novel approach called Multiplane Depth Image (MDI), which leverages the consistency of density features across multiple views to represent depth information more effectively. To accurately capture the spatial relationships of occluded objects, we introduce a scene-wide hierarchical density update mechanism, which renders depth from the foreground to background, facilitating a more coherent depth representation. Additionally, it corrects visible holes during propagation by focusing on the evident missing regions in the updated density. Finally, we develop an LF full-view depth estimation framework based on these techniques, which enables simultaneous depth prediction across all views. This framework incorporates a comprehensive loss function to supervise depth errors, view consistency, and edge blurring. Experimental results demonstrate that our method predicts high-quality depth maps across all views and achieves state-of-the-art performance compared to center-view methods.},
  archive      = {J_KBS},
  author       = {Tun Wang and Hao Sheng and Rongshan Chen and Ruixuan Cong and Mingyuan Zhao and Da Yang},
  doi          = {10.1016/j.knosys.2025.114363},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114363},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multiplane depth image for view-consistent light field depth estimation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing text adversarial example generation using large language models. <em>KBS</em>, <em>329</em>, 114361. (<a href='https://doi.org/10.1016/j.knosys.2025.114361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in Natural Language Processing (NLP) are highly based on black-box score-based models that provide only final predictions along with their score. This opacity impedes the comprehension of their internal decision-making processes, complicating the identification of potential weaknesses. A powerful strategy for analyzing model vulnerabilities is the generation of text adversarial examples. These attacks introduce subtle text perturbations that cause victim models to make incorrect predictions while preserving the original semantic meaning. This paper presents a novel method for generating text adversarial examples through Large Language Models (LLMs). The proposed method uses the outstanding text generation capabilities of LLMs to modify the original input text at multiple granularities: character-, word-, and sentence-level. First, sentence-level perturbations are introduced by generating paraphrases with an LLM instruction prompt. Next, further character- and word-level perturbations are introduced to words that most affect predictions using another set of LLM instruction prompts. In particular, vulnerable words are perturbed by replacing them with their synonyms or misspelled variants, or by inserting additional neutral words adjacent to them. Experiments were conducted to assess the proposal’s viability on two sentiment classification tasks: sentence-level reviews and full-length reviews. The proposal demonstrates an advantage over many well-known approaches based on LLMs. It preserves the original semantics to a similar extent, while increasing the deception of victim models by 29–85 % over the best-analyzed state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Natalia Madrueño and Alberto Fernández-Isabel and Rubén R. Fernández and Isaac Martín de Diego},
  doi          = {10.1016/j.knosys.2025.114361},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114361},
  shortjournal = {Knowl. Based Syst.},
  title        = {Advancing text adversarial example generation using large language models},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect-level sentiment-aware mining of inter-review relations for detecting fake reviews. <em>KBS</em>, <em>329</em>, 114360. (<a href='https://doi.org/10.1016/j.knosys.2025.114360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of fake reviews poses a significant challenge in e-commerce, undermining consumer trust and market integrity. Recently, graph-based approaches have emerged as promising solutions. However, most existing approaches focus primarily on modeling the strong relationships among reviewers, reviews, and products. They often neglect inter-review relationships that are critical for accurate fake review detection. Additionally, their reliance on coarse-grained features limits the detection of subtle, context-aware signals in fake reviews. To address these limitations, we propose a novel method called A spect- L evel S entiment- A ware M ining of I nter- R eview relations ( ALSAMIR ) for effective fake review detection. The method comprises four key components: (1) Aspect-level sentiment-aware graph to aggregate reviews sharing similar aspect-specific sentiments based on uniformity and similarity in aspect-level sentiments. This component helps reveal abnormal spammer behavior patterns; (2) A graph-based oversampling technique to mitigate imbalanced class distribution; (3) A Graph Convolutional Network (GCN) to aggregate semantics of inter-review relation embeddings with strong relations; and (4) An attention mechanism to capture non-linear, higher-order dependencies among latent features. Extensive experiments on publicly available datasets demonstrate that ALSAMIR outperforms state-of-the-art baseline methods.},
  archive      = {J_KBS},
  author       = {Ramadhani A. Duma and Zhendong Niu and Ally S. Nyamawe and Ali Asghar Manjotho and Augustino Deve},
  doi          = {10.1016/j.knosys.2025.114360},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114360},
  shortjournal = {Knowl. Based Syst.},
  title        = {Aspect-level sentiment-aware mining of inter-review relations for detecting fake reviews},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSFormer: Dynamic size attention with enhanced long-range dependency modeling for artery/vein classification. <em>KBS</em>, <em>329</em>, 114359. (<a href='https://doi.org/10.1016/j.knosys.2025.114359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal artery/vein (A/V) classification plays a crucial role in retinal disease screening and diagnosis, serving as a key biomarker for the early detection of various systemic diseases. Despite progress in automatic A/V classification, existing methods often suffer from high computational cost and the impact of irrelevant background information, limiting their practical application. To alleviate these limitations, we propose a hierarchical dynamic size transformer network (DSFormer), which integrates dynamic context-aware (DCA) blocks to improve the ability of the network to capture long-range dependencies while reducing computational complexity. The DCA block, comprising dynamic size self-attention and a dual fusion feed-forward network, is designed to emphasize crucial information in global feature representation, aggregate relevant features, and reduce the quadratic complexity of attention calculations. Additionally, a mixed shallow-deep context bridge integrates shallow and deep features across multiple scales, preserving spatial details at different scales and enhancing feature fusion. Extensive experiments on DRIVE, HRF, and IOSTAR datasets demonstrate that DSFormer outperforms state-of-the-art methods, achieving superior A/V classification performance. Code is available at https://github.com/juzi01-smallju/DSFormer .},
  archive      = {J_KBS},
  author       = {Zeyuan Ju and Chouyu Chen and Zhipeng Liu and Lijun Guo and Zhenyu Lei and Masaaki Omura and Shangce Gao},
  doi          = {10.1016/j.knosys.2025.114359},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114359},
  shortjournal = {Knowl. Based Syst.},
  title        = {DSFormer: Dynamic size attention with enhanced long-range dependency modeling for artery/vein classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond text: Fusing multi-modal legal knowledge for legal judgment prediction. <em>KBS</em>, <em>329</em>, 114358. (<a href='https://doi.org/10.1016/j.knosys.2025.114358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of the Legal Judgment Prediction (LJP) task is to predict judgment outcomes based on the fact description texts within legal cases. Existing LJP methods are confined to leveraging knowledge inherent only within the dataset itself, often failing to achieve satisfactory performance when factual descriptions contain text prone to causing erroneous judgments. Consequently, extracting and utilizing external legal knowledge represents a critical challenge that the LJP task urgently needs to overcome. To address the aforementioned issues, this study proposes a legal judgment framework named MLK-LJP, which pioneers the integration of multi-granularity, multi-modal legal knowledge into the LJP task. MLK-LJP comprises two primary modules: Multimodal Legal Knowledge Extraction (MLKE) and Multi-modal Legal Knowledge Fusion (MLKF). Specifically: 1) In the MLKE module, we devise distinct methods to acquire five types of multi-modal legal knowledge: Legal article knowledge, legal event knowledge, legal relation knowledge, quantitative evidence knowledge, and image evidence knowledge. 2) In the MLKF module, we first design a Legal Knowledge Experts Fusion mechanism. This mechanism leverages a Graph Neural Network to capture collaborative signals among the five legal knowledge expert types. Subsequently, the fused multi-modal legal knowledge is allocated across different layers of a Transformer model. This legal knowledge enhanced Transfomer model, combined with LJP prompts, is used to predict the LJP outcomes. Extensive experiments conducted on the three LJP datasets demonstrate the effectiveness and validity of MLK-LJP in comparison to state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Qihui Zhao and Tianhan Gao and Nan Guo},
  doi          = {10.1016/j.knosys.2025.114358},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114358},
  shortjournal = {Knowl. Based Syst.},
  title        = {Beyond text: Fusing multi-modal legal knowledge for legal judgment prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual constraint based semi-supervised nonnegative matrix factorization for multi-view clustering. <em>KBS</em>, <em>329</em>, 114357. (<a href='https://doi.org/10.1016/j.knosys.2025.114357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised nonnegative matrix factorization (NMF) has attracted considerable attentions in multi-view clustering applications. However, existing semi-supervised methods only adopt either pointwise (i.e., label) or pairwise constraints as supervisory information, without considering taking full advantage of both to further enhance the effectiveness of clustering performance. To this end, a novel dual constraint based semi-supervised nonnegative matrix factorization (DSNMF) method is proposed in this paper for multi-view clustering tasks. Concretely, a new multi-view based dual constraint (MDC) algorithm is developed in DSNMF, which simultaneously utilizes both the pointwise and pairwise supervisory information to promote the performance of multi-view clustering. Specifically, when the limited label information is obtained, the MDC algorithm not only constructs the label regularization to guide the learning of the indicator matrices, but also adopts the hypergraph based pairwise constraint propagation algorithm to construct the graph regularization. Moreover, an alternating multiplicative iterative method is developed for solving the optimization problem of DSNMF, as well as analyzing its convergence, supervisory information effect and computational complexity. Finally, numerous experimental results over five multi-view datasets conclude that DSNMF has better performance than several state-of-the-art semi-supervised multi-view clustering methods.},
  archive      = {J_KBS},
  author       = {Siyuan Peng and Zimeng Huangfu and Wenyun Xie and Zhijing Yang and Feiping Nie},
  doi          = {10.1016/j.knosys.2025.114357},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114357},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual constraint based semi-supervised nonnegative matrix factorization for multi-view clustering},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view clustering with privileged information based on probabilistic tensor factorization. <em>KBS</em>, <em>329</em>, 114356. (<a href='https://doi.org/10.1016/j.knosys.2025.114356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) is a powerful technique for analyzing multi-feature datasets by integrating multiple views to enhance clustering performance. Traditional MVC methods focus mainly on the consensus principle, aiming for consistency across views, but often neglects the complementary information that can be leveraged from different views. In this paper, we propose a novel probabilistic framework for tensor-based MVC that effectively incorporates both the consensus and complementarity principles. Our approach adopts the Learning Using Privileged Information (LUPI) paradigm, where one view is used as the primary learning source while the remaining views serve as privileged information. This enables the views to complement one another, thereby improving clustering results. The proposed framework utilizes probabilistic tensor factorization to capture high-order correlations between views and incorporates a max-margin constraint to enhance robustness. The proposed approach provides an interpretable generative process for tensor factorization within a probabilistic Bayesian context. Notably, our proposed framework is highly flexible and can be naturally integrated with existing anchor graph or deep learning paradigms to construct the view-specific representations. Experimental results on benchmark multi-view datasets demonstrate that our method outperforms existing MVC counterparts.},
  archive      = {J_KBS},
  author       = {Xu Tan and Haidong Gao and Yang Yu},
  doi          = {10.1016/j.knosys.2025.114356},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114356},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-view clustering with privileged information based on probabilistic tensor factorization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedAGHN: Personalized federated learning with attentive graph hypernetworks. <em>KBS</em>, <em>329</em>, 114355. (<a href='https://doi.org/10.1016/j.knosys.2025.114355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized Federated Learning (PFL) aims to address the statistical heterogeneity of data across clients by learning the personalized model for each client. Among various PFL approaches, the personalized aggregation-based approach conducts parameter aggregation in the server-side aggregation phase to generate personalized models, and focuses on learning appropriate collaborative relationships among clients for aggregation. However, the collaborative relationships vary in different scenarios and even at different stages of the FL process. To this end, we propose Personalized Federated Learning with Attentive Graph HyperNetworks (FedAGHN), which employs Attentive Graph HyperNetworks (AGHNs) to dynamically capture fine-grained collaborative relationships and generate client-specific personalized initial models. Specifically, AGHNs empower graphs to explicitly model the client-specific collaborative relationships, construct collaboration graphs, and introduce tunable attentive mechanism to derive the collaboration weights, so that the personalized initial models can be obtained by aggregating parameters over the collaboration graphs. Extensive experiments can demonstrate the superiority of FedAGHN. Moreover, a series of visualizations are presented to explore the effectiveness of learned collaboration graphs.},
  archive      = {J_KBS},
  author       = {Jiarui Song and Yunheng Shen and Chengbin Hou and Pengyu Wang and Jinbao Wang and Ke Tang and Hairong Lv},
  doi          = {10.1016/j.knosys.2025.114355},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114355},
  shortjournal = {Knowl. Based Syst.},
  title        = {FedAGHN: Personalized federated learning with attentive graph hypernetworks},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PromptAL: Sample-aware dynamic soft prompts for few-shot active learning. <em>KBS</em>, <em>329</em>, 114354. (<a href='https://doi.org/10.1016/j.knosys.2025.114354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning (AL) aims to optimize model training and reduce annotation costs by selecting the most informative samples for labeling. Typically, AL methods rely on the empirical distribution of labeled data to define the decision boundary and perform uncertainty or diversity estimation, subsequently identifying potential high-quality samples. In few-shot scenarios, the empirical distribution often diverges significantly from the target distribution, causing the decision boundary to shift away from its optimal position. However, existing methods overlook the role of unlabeled samples in enhancing the empirical distribution to better align with the target distribution, resulting in a suboptimal decision boundary and the selection of samples that inadequately represent the target distribution. To address this, we propose a hybrid AL framework, termed PromptAL (Sample-Aware Dynamic Soft Prompts for Few-Shot A ctive L earning). This framework accounts for the contribution of each unlabeled data point in aligning the current empirical distribution with the target distribution, thereby optimizing the decision boundary. Specifically, PromptAL first leverages unlabeled data to construct sample-aware dynamic soft prompts that adjust the model’s predictive distribution and decision boundary. Subsequently, based on the adjusted decision boundary, it integrates uncertainty estimation with both global and local diversity to select high-quality samples that more accurately represent the target distribution. Experimental results on six in-domain and three out-of-domain datasets show that PromptAL achieves superior performance over nine baselines. Our codebase is openly accessible.},
  archive      = {J_KBS},
  author       = {Hui Xiang and Jinqiao Shi and Ting Zhang and Xiaojie Zhao and Yong Liu and Yong Ma},
  doi          = {10.1016/j.knosys.2025.114354},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114354},
  shortjournal = {Knowl. Based Syst.},
  title        = {PromptAL: Sample-aware dynamic soft prompts for few-shot active learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EFNet-CSM: EfficientNet with a modified attention mechanism for effective fire detection. <em>KBS</em>, <em>329</em>, 114353. (<a href='https://doi.org/10.1016/j.knosys.2025.114353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire is considered one of the major threats to life, property, ecosystems, global warming, and the economy. Recent advancements in convolution neural networks have shown potential for vision-based fire detection; however, several challenges are associated with these techniques, such as limited model performance and high computational complexity. To address these issues, we present an efficient CNN-based model in which EfficientNetV2B0 is employed as a backbone feature extractor and is integrated with a channel and modified spatial attention mechanism to extract deeper spatial details, thereby weighting important features appropriately. The spatial attention is modified by introducing two depth-separable convolution layers to control computational complexity without affecting the performance. The proposed model is assessed on four benchmark datasets in the domain of remote sensing and CCTV-based systems for effective fire detection. Experimental analysis reveals that our model outperforms existing methods in terms of higher accuracy and inference speed, with lower model size and computational burden, indicating its suitability for deployment on resource-constrained devices in real time. To explain the predictions made by the proposed model, we use explainable artificial intelligence methods called Grad-CAM, guided backpropagation, and guided Grad-CAM to provide visualizations by localizing the most salient regions in the image, as emphasized by the attention mechanism.},
  archive      = {J_KBS},
  author       = {Hikmat Yar and Fath U Min Ullah and Zulfiqar Ahmad Khan and Min Je Kim and Sung Wook Baik},
  doi          = {10.1016/j.knosys.2025.114353},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114353},
  shortjournal = {Knowl. Based Syst.},
  title        = {EFNet-CSM: EfficientNet with a modified attention mechanism for effective fire detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cross-city spatio-temporal prediction via dynamic multi-scale hypergraph learning with domain adversarial training. <em>KBS</em>, <em>329</em>, 114352. (<a href='https://doi.org/10.1016/j.knosys.2025.114352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal prediction is vital for enabling intelligent urban services. However, due to newly deployed infrastructure, developing cities often suffer from data scarcity, which significantly limits the applicability of deep learning models that rely on large volumes of historical data. Moreover, most existing methods focus solely on pairwise spatial interactions, overlooking complex high-order spatial dependencies that are crucial for accurate prediction. To address these challenges, we propose D2MHyper, a cross-city spatio-temporal prediction framework that integrates high-order spatial information through a D ynamic M ulti-scale Hyper graph neural network enhanced by D omain adversarial training. Specifically, we design a shared-private representation learning strategy that captures both city-invariant and city-specific spatial features through inter-city shared and intra-city private hypergraphs. To effectively model complex dependencies, we develop a dynamic multi-scale hypergraph generation module based on learnable incidence matrices, which captures implicit time-varying high-order interactions at multiple granularities. To enhance generalization to data-scarce target cities, a cross-city knowledge transfer module is introduced to transfer global information from source cities. Furthermore, a domain adversarial training strategy is incorporated to enforce the disentanglement of shared and private representations. Extensive experiments on four real-world benchmark datasets consistently validate the effectiveness of D2MHyper, which outperforms state-of-the-art methods in cross-city prediction under data scarcity scenarios.},
  archive      = {J_KBS},
  author       = {Xiaocao Ouyang and Yanhua Li and Jie Zhang and Xin Yang and Yan Yang and Junbo Zhang and Wei Huang and Tianrui Li and Zhiquan Liu},
  doi          = {10.1016/j.knosys.2025.114352},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114352},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing cross-city spatio-temporal prediction via dynamic multi-scale hypergraph learning with domain adversarial training},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unleashing powerful generalization for point cloud registration. <em>KBS</em>, <em>329</em>, 114351. (<a href='https://doi.org/10.1016/j.knosys.2025.114351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep learning-based point cloud registration have significantly enhanced performance on in-domain data. However, an ideal point cloud registration method should not only excel in same-domain scenarios but also demonstrate robust generalization to achieve the goal of ”train once, apply anywhere.” To this end, existing patch-based methods employ keypoint sampling to identify matchable local 3D patches, thereby improving generalization. Nevertheless, viewpoint variations due to changes in sensor pose, coupled with uneven density and scale issues in point clouds acquired by different sensors, hinder reliable keypoint detection, consequently complicating the identification of matching local 3D patches. To address these challenges, we propose UPG, a point cloud registration method with powerful generalization performance. First, we design an equivariant network architecture based on PPF features to detect keypoints that are rotation-equivariant. Additionally, we present a multi-level patch-wise embedding technique and a joint-level inliers generator to mitigate density and scale variations and improve both registration performance and generalization. Extensive experiments on multiple datasets demonstrate that the proposed UPG achieves state-of-the-art generalization performance.},
  archive      = {J_KBS},
  author       = {Yejun Shou and Haocheng Wang and Lingfeng Shen and Shuai Li and Yanlong Cao},
  doi          = {10.1016/j.knosys.2025.114351},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114351},
  shortjournal = {Knowl. Based Syst.},
  title        = {Unleashing powerful generalization for point cloud registration},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LFE-PointMamba: Point cloud learning via local feature enhancement and state space model. <em>KBS</em>, <em>329</em>, 114350. (<a href='https://doi.org/10.1016/j.knosys.2025.114350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud learning has important application value in autonomous driving and robot navigation. To address the limitations of existing approaches-Transformer’s high quadratic complexity and Mamba’s insufficient local geometric capture, as well as its unidirectional modeling bias conflicting with the non-causal nature of point clouds-this paper proposes LFE-PointMamba. This framework co-optimizes a local feature enhancement module and an improved Mamba architecture, enabling fine-grained geometric perception and efficient global modeling. First, it employs a composite representation that integrates explicit geometric structures and implicit semantic features, alongside a three-level cascading graph convolution for multi-scale context fusion, which enhances local feature capture and provides a more robust semantic basis for global modeling. Second, it replaces causal convolution with non-causal grouping convolution, thereby resolving the conflict between Mamba’s one-way modeling and the non-causal relations inherent in point clouds. At the same time, local and global features are dynamically aggregated through dual-path feature fusion, allowing the model to better balance the capture of local details and modeling of long-range dependencies. Third, utilizing the Hilbert curve’s spatial proximity property and multi-variant dynamic rearrangement, it enables efficient global modeling and spatial topology adaptation without significantly increasing computation. Experiments show that LFE-PointMamba performs well in various downstream tasks. On ModelNet40 and the most challenging PB-T50-RS variant of ScanObjectNN, the classification accuracy achieved 93.0 % and 89.3 %, respectively. In the ShapeNetPart segmentation task, the mean IoU for all instances is 86.1 %. Additionally, the model significantly reduces the number of parameters and computational complexity, offering an efficient solution for point cloud learning.},
  archive      = {J_KBS},
  author       = {Bowen Zhou and Lixin Zhan and Jie Jiang},
  doi          = {10.1016/j.knosys.2025.114350},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114350},
  shortjournal = {Knowl. Based Syst.},
  title        = {LFE-PointMamba: Point cloud learning via local feature enhancement and state space model},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parsilo-CDR: Privacy-aware cross-domain recommendation for data silo. <em>KBS</em>, <em>329</em>, 114349. (<a href='https://doi.org/10.1016/j.knosys.2025.114349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain recommendation is a significant topic to alleviate the data sparsity issue in the target domain by leveraging source domain information. However, cross-domain recommendation usually falls into the effect of data silo, since data of the source domain and target domain are generally isolated in different platforms. Intuitively, there are two limits on cross-domain recommendation for data silo. Firstly, data sharing across different domains is difficult, due to the concern of privacy breaching. Secondly, the noise of shared information during cross-platform interactions negatively impacts recommendation in target domain with limited cross-domain knowledge exchange, especially domain-specific noise (the domain information of source domain which is harmful to target domain) on cross-domain recommendation. To tackle these issues, this paper proposes a privacy-aware cross-domain recommendation framework for data silo, known as Parsilo-CDR. Parsilo-CDR introduces the pre-training module and the decoupling regularizers into cross-domain recommendation. The pre-training module is designed to convert raw data into synthetic privacy-preserving data, dynamically balancing privacy and usability based on user privacy preferences. The regularizers further enhance recommendation accuracy by separating user information into domain-common knowledge and domain-specific features, preserving common information while filtering out the domain-specific noise of the shared knowledge. Experimental results validate Parsilo-CDR’s effectiveness in improving recommendation accuracy while overcoming the privacy concern posed by data silo.},
  archive      = {J_KBS},
  author       = {Shanpeng Liu and Buqing Cao and Sheng Lin and Wenyu Zhao and Jianxun Liu and Xiong Li},
  doi          = {10.1016/j.knosys.2025.114349},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114349},
  shortjournal = {Knowl. Based Syst.},
  title        = {Parsilo-CDR: Privacy-aware cross-domain recommendation for data silo},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-matching framework for visual entity linking enhanced by large language models. <em>KBS</em>, <em>329</em>, 114348. (<a href='https://doi.org/10.1016/j.knosys.2025.114348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal entity linking (MEL) accurately links ambiguous textual mentions in a multimodal context to unambiguous entities within a knowledge graph (KG) or knowledge base (KB). It plays a substantial role in various application domains, such as KG construction and semantic retrieval. However, currently, this task primarily aims to enhance the textual semantic level and fails to fully leverage multimodal context to enrich the semantic depth of a KG. We address this limitation by proposing a new task called visual entity linking (VEL), which is similar to traditional MEL. The key difference is that VEL aims to jointly map ambiguous textual mentions and their corresponding visual objects to entities in the KG. To this end, we introduce DMVEL, a dual-matching framework for VEL. (1) The optimal visual object can be obtained by utilizing a multi-instance feature alignment and classification mechanism that fully leverages both coarse-grained (textual and image) and fine-grained (textual and visual object) information. (2) Pre-designed prompt templates are employed to guide large language models (LLMs) in generating entity-focused descriptions for all entities in the KG, minimizing noise from irrelevant information. (3) A dual matching strategy comprising two key components is proposed. The first component entails applying an innovative filter to align ambiguous mentions with entities at the macro level of the overall semantics. The second component is the re-ranker, which performs fine-grained matching between local features and enhanced entity feature representations at the granular level, ensuring global semantic alignment while emphasizing local semantics. Extensive experiments on three public benchmarks demonstrate that the proposed method achieves state-of-the-art performance, paving the way toward an efficient and general solution to utilize LLMs to perform VEL.},
  archive      = {J_KBS},
  author       = {Dijing Pan and Runhe Qiu and Xueqin Jiang and Shaohua Tao},
  doi          = {10.1016/j.knosys.2025.114348},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114348},
  shortjournal = {Knowl. Based Syst.},
  title        = {A dual-matching framework for visual entity linking enhanced by large language models},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information bottleneck-guided KNN contrastive hashing for unsupervised cross-modal retrieval. <em>KBS</em>, <em>329</em>, 114347. (<a href='https://doi.org/10.1016/j.knosys.2025.114347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised cross-modal hashing (UCMH) has emerged as a promising solution for scalable multi-modal retrieval without costly annotations. However, existing methods often rely on rigid pairwise contrastive learning and fixed-size neighborhood selection, which suffer from false negatives and semantic noise, respectively—limiting their ability to model complex semantic structures in open-world scenarios. In this paper, we propose a novel framework, I nformation B ottleneck-guided K NN C ontrastive H ashing ( IBKCH ), which introduces a flexible and semantically adaptive contrastive paradigm for UCMH. Specifically, we design an information-aware neighbor sampling strategy that integrates: (1) a Hard-negative and Soft-positive (HN-SP) mechanism to adaptively distinguish informative negatives and softly aggregate latent positives; (2) an information bottleneck loss to retain task-relevant semantics while suppressing redundancy; and (3) an entropy sparsity regularizer to mitigate noisy neighbor interference. Furthermore, we develop an adaptive KNN contrastive learning scheme that unifies intra-modal and inter-modal alignment, enabling robust and discriminative hash code learning. Extensive experiments on three benchmark datasets demonstrate that IBKCH consistently outperforms state-of-the-art methods, especially under noisy or semantically diverse conditions—highlighting its effectiveness and generalizability in real-world UCMH applications.},
  archive      = {J_KBS},
  author       = {Lei Zhu and Zhengchang Yuan and Zeqian Yi and Chengyuan Zhang and Lin Wu and Ying Zhang and Farid Boussaid and Mohammed Bennamoun and Shichao Zhang},
  doi          = {10.1016/j.knosys.2025.114347},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114347},
  shortjournal = {Knowl. Based Syst.},
  title        = {Information bottleneck-guided KNN contrastive hashing for unsupervised cross-modal retrieval},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TIJERE: A novel threat intelligence joint extraction model based on analyst expert knowledge. <em>KBS</em>, <em>329</em>, 114346. (<a href='https://doi.org/10.1016/j.knosys.2025.114346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraction of entities and relationships from threat intelligence reports into structured formats, such as cybersecurity knowledge graphs, is essential for automated threat analysis, detection, and mitigation. However, existing joint extraction methods struggle with feature confusion, language ambiguity, noise propagation, and overlapping relations, resulting in low accuracy and poor model performance. This paper presents TIJERE, an innovative joint entity and relation extraction framework that formulates joint extraction as a multisequence labeling representation (MSLR) problem. Specifically, separate sequences are generated for each entity pair. Unlike prior tagging schemes, MSLR integrates expert domain features to enrich positional, contextual, and semantic representations of entities, thereby enhancing feature distinction and classification accuracy. Additionally, TIJERE reduces language ambiguity and enhances domain-specific generalization by leveraging SecureBERT+, a contextual language model fine-tuned on cybersecurity text. This improves both named entity recognition (NER) and relation extraction (RE). This paper also introduces DNRTI-JE, the first publicly available jointly labeled dataset for cybersecurity entity and RE, filling a crucial gap in cyber threat intelligence automation. Empirical evaluations on the curated DNRTI-JE dataset demonstrate that TIJERE achieves state-of-the-art performance, with F1-scores exceeding 0.93 for NER and 0.98 for RE, outperforming existing methods. Together, TIJERE and the standardized benchmarking DNRTI-JE dataset enable high-performance cybersecurity intelligence extraction, with transferable applications in healthcare, finance, and bioinformatics.},
  archive      = {J_KBS},
  author       = {Inoussa Mouiche and Sherif Saad},
  doi          = {10.1016/j.knosys.2025.114346},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114346},
  shortjournal = {Knowl. Based Syst.},
  title        = {TIJERE: A novel threat intelligence joint extraction model based on analyst expert knowledge},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-cause deconfounding for recommender systems with latent confounders. <em>KBS</em>, <em>329</em>, 114345. (<a href='https://doi.org/10.1016/j.knosys.2025.114345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effectiveness of modern recommender systems is often undermined by various biases, such as popularity bias, that stem from multi-causal latent confounders inherent in user-item interaction data. However, existing approaches to mitigate these confounding effects often fail to distinguish between user-side and item-side latent confounders, treating them indiscriminately and thereby limiting their effectiveness. To address this issue, a m ulti- c ause d e c on f ounding method for recommender systems with latent confounders (MCDCF) is proposed. MCDCF leverages multi-cause causal effect estimation to learn substitutes for latent confounders at the user and item sides, respectively, using user behaviour data. Specifically, MCDCF treats the multiple items that users interact with and the multiple users that interact with items as treatment variables, and then uses a variational inference model to learn substitutes for latent confounders that influence the estimation of causality between users and user feedback, as well as between items and user feedback. Additionally, this research theoretically demonstrate the soundness of the MCDCF method. Extensive experiments on four real-world datasets demonstrate that the MCDCF method effectively recovers latent confounders related to users and items, reducing bias and thereby improving recommendation accuracy. Compared with the best-performing baselines, MCDCF achieves up to a 38.61 % improvement in recommendation metrics.},
  archive      = {J_KBS},
  author       = {Zhirong Huang and Yuxuan Hu and Debo Cheng and Jiuyong Li and Lin Liu and Guixian Zhang and Shichao Zhang},
  doi          = {10.1016/j.knosys.2025.114345},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114345},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-cause deconfounding for recommender systems with latent confounders},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topological insights into heterogeneous information networks: A systematic review on biological data association. <em>KBS</em>, <em>329</em>, 114344. (<a href='https://doi.org/10.1016/j.knosys.2025.114344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interactions and associations among biomolecules, such as proteins, RNA, metabolites, and genes, form the foundation of the biological process. Systematic analysis of these associations is crucial for uncovering biological mechanisms and enabling more precise bioengineering applications. Given the complexity and diversity of biological entities and their interrelationships, biological networks are inherently heterogeneous, comprising multiple types of nodes and edges. This complexity has driven the growing adoption of heterogeneous information networks (HINs) for biological data association analysis. To the best of our knowledge, the influence of topological properties has been largely disregarded in previous studies, which have focused on the classification and analytical stages of HIN-based biological data association. A search was conducted across five scientific databases, and with the assistance of the guidance for systematic review and PRISMA framework, 53 articles from 2020 to 2024 were selected for analysis. The reviewed articles highlight the crucial roles of topological properties in biological HINs, such as dynamics of random walks, network completion, and path sampling. The miRNA-disease database, HMDDv4.0, is examined as a case study to identify the challenges that result from node degrees imbalances and the ambiguity of meta-paths in biological networks. Two preliminary research frameworks are proposed, one of which on modeling based on HIN and Markov model and the other on the improvement of meta-path induction ability based on this model. These findings can augment the representation capacity of HINs and to assist future research on biological data association analysis based on HINs.},
  archive      = {J_KBS},
  author       = {Di-Wen Kang and Khairunnisa Hasikin and Anis Salwa Mohd Khairuddin and Kai-Qing Zhou},
  doi          = {10.1016/j.knosys.2025.114344},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114344},
  shortjournal = {Knowl. Based Syst.},
  title        = {Topological insights into heterogeneous information networks: A systematic review on biological data association},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCINet: Multimodal context-aware network for RGBT tracking. <em>KBS</em>, <em>329</em>, 114343. (<a href='https://doi.org/10.1016/j.knosys.2025.114343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional RGBT tracking methods rely heavily on visual feature extraction and fusion, but often fail in real-world conditions where visual inputs are degraded by occlusion, illumination changes, or thermal crossover. Additionally, limited dataset scale constrains model generalization. To address these challenges, we propose MCINet, a novel multimodal tracking framework that shifts from vision-centric modeling to a multi-cue collaborative paradigm for enhanced robustness. MCINet integrates historical motion patterns, frequency-domain structure, and language-driven semantics, and employs a staged and decoupled fusion strategy to build a fault-tolerant target representation. Its long-short range attention mechanism captures both temporal dynamics and spatial variations, while a frequency-guided semantic alignment module enhances visual-textual consistency. Crucially, even when visual signals deteriorate, MCINet maintains reliable tracking by leveraging auxiliary cues. This weakly supervised multi-cue design also mitigates the dependence on large-scale labeled data, improving adaptability under modality imbalance or failure. Experimental results on RGBT210, RGBT234, and LasHeR benchmarks demonstrate that MCINet achieves competitive performance in both accuracy and robustness, highlighting its practical potential in challenging real-world environments. The code of the proposed method will be available at https://github.com/ysqidong-dotcon/MCINet .},
  archive      = {J_KBS},
  author       = {Zhao Gao and Dongming Zhou and Zhiyong Wu and Yisong Liu and Qingqing Shan},
  doi          = {10.1016/j.knosys.2025.114343},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114343},
  shortjournal = {Knowl. Based Syst.},
  title        = {MCINet: Multimodal context-aware network for RGBT tracking},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active source-free open-set domain adaptation. <em>KBS</em>, <em>329</em>, 114342. (<a href='https://doi.org/10.1016/j.knosys.2025.114342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-free open-set domain adaptation (SFODA) aims to transfer a source model to an unlabeled target domain without explicit class restrictions. However, the SFODA setting faces a challenge in accurately identifying true labels for novel class samples. In this paper, we introduce a new research problem termed Active SFODA (ASFODA). By labeling a small budget of active samples, ASFODA aims to not only identify common class samples but also detect and identify novel class samples. Our investigations reveal that the targeted active samples should exhibit characteristics of abnormal uncertainty and diversity, which are not captured by existing active learning strategies. To remedy these shortcomings, we propose a method known as Diverse Structure Learning (DSL) comprised of Local Diversity Annotation (LDA) and Local Consistency Learning (LCL). Driven by the observation that both common and novel classes tend to form distinct clusters initially, LDA is designed to exploit this structural property. It annotates reliable samples situated in high-density regions of clusters, thereby facilitating the exploration of targeted active samples. Concurrently, LCL tackles the challenge of novel class clusters that may bear the same label but are located disparately by constructing interconnected samples between these clusters. This effectively learns the uncertain novel samples that reside between these clusters. Extensive experiments have validated the effectiveness of DSL, achieving over 15 % enhancements in the context of ASFODA.},
  archive      = {J_KBS},
  author       = {Fan Wang and Zhongyi Han and Hao Sun and Yilong Yin},
  doi          = {10.1016/j.knosys.2025.114342},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114342},
  shortjournal = {Knowl. Based Syst.},
  title        = {Active source-free open-set domain adaptation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning adaptive frequency-prompt denoising transformer for UAV nighttime tracking. <em>KBS</em>, <em>329</em>, 114341. (<a href='https://doi.org/10.1016/j.knosys.2025.114341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art (SOTA) visual tracking techniques have significantly advanced unmanned aerial vehicle (UAV) autonomy. However, their performance remains hindered by on-board camera hardware limitations and prevalent noise and blurring in complex environments, particularly under low-light conditions. Existing low-light enhancement methods frequently introduce overexposure, detail loss, and inadequate noise suppression, further degrading nighttime tracking performance. To address these challenges, we propose a Frequency Domain Prompt-based Denoising Transformer Network (FPDT). Specifically, we design a lightweight Adaptive Frequency Prompt Learning Module (AFP-LM), comprising a Frequency Learning Block (FLB) and a Prompt Block (PB). FLB leverages frequency domain analysis to achieve adaptive separation and interaction between high- and low-frequency features. PB dynamically generates frequency prompts to guide the model in suppressing high-frequency noise, thereby improving the feature extraction capabilities of the tracker. To further strengthen cross-domain feature representation, we introduce a Bidirectional Cross-Fusion Module (BCFM) that enables bidirectional interaction between frequency-domain and spatial-domain information. Additionally, a novel Multi-Dconv Head Transposed Cross-Attention (MDCA) is integrated into the decoder to facilitate multi-scale feature cross-fusion. Extensive experiments demonstrate that FPDT achieves superior performance on multiple UAV nighttime tracking benchmarks.},
  archive      = {J_KBS},
  author       = {Lihua Qi and Haijun Wang and Haoyu Qu and Zihao Su},
  doi          = {10.1016/j.knosys.2025.114341},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114341},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning adaptive frequency-prompt denoising transformer for UAV nighttime tracking},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised pretraining model for time series classification based on data preprocessing. <em>KBS</em>, <em>329</em>, 114340. (<a href='https://doi.org/10.1016/j.knosys.2025.114340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, time series have been widely applied and made great progress in the industrial field, including pretrained models. By training models with a large amount of data similar to a certain field and fine-tuning them with a small number of samples, high-precision models, which have great value in the industrial field, can be obtained. However, the current models have two main problems. First, they mostly use supervised classification. Although the accuracy is high, it is not practical for various real-world data with a small number of labeled samples. Second, recent research has mainly focused on contrastive learning, which has higher requirements for data form and regularity. To address these two problems, we propose a self-supervised preprocessing classification model for time series. First, based on the inherent characteristics of the data, we determined the data preprocessing method by judging the properties of the time series. Second, we proposed a self-supervised contrastive learning-based sorting similarity method using coarse similarity in the pretraining stage and our sorting loss function in the fine-tuning stage to improve overall performance. Subsequently, we conducted extensive experiments on 8 different real-world datasets from various domains. The experimental results indicated that the proposed model improved over existing methods by at least 1.1 % , 2.7 % , 6.9 % , and 2 % in terms of ACC, Precision, Recall, and AUPRC, respectively.},
  archive      = {J_KBS},
  author       = {Hanlin Zhang},
  doi          = {10.1016/j.knosys.2025.114340},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114340},
  shortjournal = {Knowl. Based Syst.},
  title        = {A self-supervised pretraining model for time series classification based on data preprocessing},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic spatiotemporal graph convolutional network collaborative pre-training learning for traffic flow prediction. <em>KBS</em>, <em>329</em>, 114339. (<a href='https://doi.org/10.1016/j.knosys.2025.114339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction constitutes a fundamental pillar for intelligent transportation systems (ITS) optimization. However, the intricate spatiotemporal correlations within traffic networks pose significant challenges to precise prediction. Existing methods often rely on static relational assumptions, inadequately capturing global temporal correlations and struggling to model the complex trends and periodic patterns present in long-term traffic data. To surmount these limitations, we present a novel d ynamic spatiotemporal g raph c onvolutional n etwork collaborative p re- t raining l earning (DGCN-PTL). Our methodology incorporates a dual stage architecture: initially, a pre-training stage employs masked autoencoder mechanisms coupled with Transformer architectures to effectively extract temporal representations from extensive historical time series data. Subsequently, the prediction stage executes downstream forecasting through several pivotal components. We develop a dynamic graph learning module that adaptively captures evolving spatial interdependencies among network nodes across temporal intervals. Additionally, we integrate gating mechanisms with self-attention operations to augment the model’s capability in characterizing both local and global temporal correlations. A dedicated feature transformation module facilitates channel adaptation and representation refinement. Comprehensive experiments across four real-world datasets substantiate DGCN-PTL’s superior performance against 23 state-of-the-art baselines, achieving remarkable improvements of 5.49 % over the most competitive existing method.},
  archive      = {J_KBS},
  author       = {Haiyang Chi and Yuhuan Lu and Yirong Zhu and Wei Ke and Hanbin Mao},
  doi          = {10.1016/j.knosys.2025.114339},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114339},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic spatiotemporal graph convolutional network collaborative pre-training learning for traffic flow prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new feature selection method using deep learning and graph representation in high-dimensional datasets. <em>KBS</em>, <em>329</em>, 114338. (<a href='https://doi.org/10.1016/j.knosys.2025.114338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, advances in data collection and storage have led to high-dimensional datasets containing numerous, often redundant features, which can negatively affect machine learning algorithms. Feature selection has emerged as a key solution to reduce dataset dimensionality, thereby improving computational efficiency and minimizing overfitting. Traditional feature selection models have limitations in effectively handling high-dimensional data and often overlook intricate relationships between features. Therefore, they may not fully optimize model performance and may be prone to overfitting. To address these challenges, we propose a novel feature selection method based on deep learning that can better capture complex patterns and dependencies among features in high-dimensional data. This method, which uses a deep similarity measure and graph representation, involves three phases. First, the problem is modeled as a graph using the deep similarity measure. Next, primary features are clustered through a community detection model. Finally, the most influential feature within each cluster is selected using node centrality and feature appropriateness measures. Notably, the feature selection step adopts a filter-based approach rather than relying on a learning algorithm, as is common in wrapper models. This design significantly reduces computational complexity and minimizes parameter requirements compared to previous methods. By avoiding reliance on a learning algorithm, the proposed method overcomes challenges such as high computational costs while improving accuracy. Experimental results across multiple datasets demonstrate that the proposed supervised model outperforms state-of-the-art approaches, achieving average improvements of 1.5 % in accuracy and 1.77 %, 1.87 %, and 1.81 % in precision, recall, and F1-score, respectively.},
  archive      = {J_KBS},
  author       = {Matin Chiregi and Mahdi Mazinani and Mitra Mirzarezaee},
  doi          = {10.1016/j.knosys.2025.114338},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114338},
  shortjournal = {Knowl. Based Syst.},
  title        = {A new feature selection method using deep learning and graph representation in high-dimensional datasets},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STCKGE: Continual knowledge graph embedding based on spatial transformation. <em>KBS</em>, <em>329</em>, 114337. (<a href='https://doi.org/10.1016/j.knosys.2025.114337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current Continual Knowledge Graph Embedding (CKGE) methods primarily rely on translation-based embedding approaches, leveraging previously acquired knowledge to initialize new facts. While these methods often integrate fine-tuning or continual learning strategies to enhance efficiency, they compromise prediction accuracy and lack support for complex relational structures (e.g., multi-hop relations). To address these limitations, we propose STCKGE, a novel CKGE framework based on spatial transformation. In this framework, entity positions are jointly determined by base position vectors and offset vectors, enabling the model to represent complex relations more effectively while supporting efficient embedding updates for both new and existing knowledge through simple spatial operations, without relying on traditional continual learning techniques. Furthermore, we introduce a bidirectional collaborative update strategy and a balanced embedding method to guide parameter updates, effectively minimizing training costs while improving model accuracy. We comprehensively evaluate our model on seven public datasets and a newly constructed dataset (MULTI) focusing on multi-hop relationships. Experimental results confirm STCKGE’s strong performance in multi-hop relationship learning and prediction accuracy, with an average MRR improvement of 5.4 %. Our code and dataset are available at https://github.com/Wxy13131313131/STCKGE},
  archive      = {J_KBS},
  author       = {Xinyan Wang and Jinshuo Liu and Kaijian Xie and Meng Wang and Cheng Bi and Juan Deng and Donghong Ji and Jeff Z. Pan},
  doi          = {10.1016/j.knosys.2025.114337},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114337},
  shortjournal = {Knowl. Based Syst.},
  title        = {STCKGE: Continual knowledge graph embedding based on spatial transformation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge attention via radial basis functions for temporal knowledge graphs completion. <em>KBS</em>, <em>329</em>, 114336. (<a href='https://doi.org/10.1016/j.knosys.2025.114336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, leveraging Large Language Models (LLMs) for Temporal Knowledge Graph Completion (TKGC) based on given queries and corresponding knowledge sequences has emerged as a novel architecture. The quality of knowledge sequences plays a decisive role in prediction performance. Previous studies directly generated knowledge sequences through manually defined rules, which we term Original Knowledge Sequences (OKS). However, due to the inherent complexity of Temporal Knowledge Graphs (TKGs), OKS tend to be overly cumbersome. In contrast, a comprehensive yet concise knowledge sequence (CCKS) proves crucial. To address this challenge, we propose a knowledge ranking model. First, we use the target training quadruples, along with the OKS corresponding to the head and tail entities in those quadruples, as the training samples for the model. Then, the model considers the global graph structure and temporal context of the knowledge in the OKS using a Relational Graph Convolutional Network (R-GCN) and a Transformer Encoder. Finally, the model uses Knowledge Attention via Radial Basis Functions (KA-RBF) to calculate the overall weighted similarity of all knowledge pairs in the OKS corresponding to the head and tail entities, and simplifies the OKS into CCKS by sorting the weights. We conducted experimental analysis from four different perspectives on five datasets, and the experimental results demonstrated the feasibility and effectiveness of the model. Code is available at https://github.com/foundation000/KA-RBF .},
  archive      = {J_KBS},
  author       = {Enqiang Wang and Jin Liu and Xiao Liu and Bo Huang and Xu Huang},
  doi          = {10.1016/j.knosys.2025.114336},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114336},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge attention via radial basis functions for temporal knowledge graphs completion},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient feature points detector for full and partial palmprint recognition. <em>KBS</em>, <em>329</em>, 114335. (<a href='https://doi.org/10.1016/j.knosys.2025.114335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decade, biometrics has witnessed significant advancements in various forensic and security applications for human identification and authentication, with growing interest in effective and discriminative traits such as palmprints. However, practical applications still face challenges, especially when palmprints are collected in portions, such as at crime scenes, or partially acquired for authentication in uncontrolled environments. This paper presents a novel method that incorporates the local binary patterns (LBP) operator into the conventional scale-invariant feature transform (SIFT) algorithm to detect and extract robust keypoint features. While SIFT employs a Gaussian filter to detect keypoints on the palmprint, the proposed method leverages the multi-scale LBP operator to detect stable points prior to computing the corresponding descriptors. Furthermore, an efficient method for filtering keypoints, namely the Self-Geometric Relationship (SGR) filter, is introduced to eliminate potential false matches. The proposed palmprint recognition system, LBPSIFT-SGR, demonstrates competitive performance on full palmprints compared to state-of-the-art techniques and exhibits clear superiority on partial palmprint images, where competing systems fail, across different datasets.},
  archive      = {J_KBS},
  author       = {Fouad Khelifi and Jumma Almaghtuf and Ahmed Bouridane},
  doi          = {10.1016/j.knosys.2025.114335},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114335},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient feature points detector for full and partial palmprint recognition},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InDReCT: Intra-domain dual reconstruction for cross-domain transfer in camouflaged object detection. <em>KBS</em>, <em>329</em>, 114334. (<a href='https://doi.org/10.1016/j.knosys.2025.114334'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current Camouflaged Object Detection (COD) methods primarily rely on a direct mapping from image to mask. However, due to the inherent semantic and structural gap between the image and its corresponding mask, the learned feature representations often exhibit poor generalization ability. To address this issue, we propose a novel intra-domain dual reconstruction framework, termed InDReCT, which reformulates the image-to-mask prediction as a cross-domain transfer task by simultaneously reconstructing both the input image and its corresponding mask. Within this framework, semantic knowledge is transferred through two reconstruction processes from different domains: image reconstruction (appearance domain) and mask reconstruction (structure domain), and is eventually integrated back into the image-to-mask prediction task. This dual reconstruction mechanism implicitly guides the network to extract hidden appearance semantics from image-to-image reconstruction and explicit structural information from mask-to-mask reconstruction, thereby enhancing the model’s generalization capability. Extensive experiments on three benchmark COD datasets and four downstream tasks demonstrate that InDReCT consistently outperforms state-of-the-art methods in both detection accuracy and generalization ability. Notably, on the widely-used COD10K dataset, InDReCT achieves a Mean E-measure ( E m ) of 95.6 %, surpassing the latest state-of-the-art model CamoDiffusion by 1.6 %. Code and models will be publicly available at: https://github.com/KungFuProgrammerle/InDReCT .},
  archive      = {J_KBS},
  author       = {Guowen Yue and Ge Jiao and Fangyan Wang},
  doi          = {10.1016/j.knosys.2025.114334},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114334},
  shortjournal = {Knowl. Based Syst.},
  title        = {InDReCT: Intra-domain dual reconstruction for cross-domain transfer in camouflaged object detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An accurate quantitative analysis model for martian-like mineral elements using bi-LSTM coupled with whale optimization algorithm. <em>KBS</em>, <em>329</em>, 114333. (<a href='https://doi.org/10.1016/j.knosys.2025.114333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser-induced breakdown spectroscopy (LIBS) is an analytical method derived from atomic emission spectroscopy that enables the rapid acquisition of chemical composition information from samples. Due to the susceptibility of the LIBS signal to interference from the self-absorption phenomena, sample matrix, and various other factors, the accuracy of both quantitative and qualitative analyses may be compromised without appropriate data mining techniques. In this work, LIBS is integrated with multivariate analysis algorithms to analyze the major element contents of minerals quantitatively. Using a dataset of geological reference samples made available by the ChemCam and SuperCam teams, an innovative modeling approach is introduced that incorporates a bidirectional long short-term memory (Bi-LSTM) network refined through a whale optimization algorithm (WOA). The findings from the dataset indicate that WOA-Bi-LSTM achieves superior accuracy in the quantitative analysis of in-situ and Martian-like LIBS data, surpassing state-of-the-art models. Compared with those of standalone implementations of Bi-LSTM and the partial least squares (PLS) model, the WOA-Bi-LSTM model yielded average reductions in the root mean square error of prediction (RMSEP) by 15.1 %. The method also achieved an average coefficient of determination (R²) of 0.936, reflecting a close alignment between the actual sample measurements and predicted values. The WOA-Bi-LSTM algorithm achieves high accuracy and strong generalizability, its prediction results are better than those of traditional quantitative regression analysis algorithms. The model established in this paper may significantly enhance the quantitative analysis of LIBS spectral data in future Mars exploration missions.},
  archive      = {J_KBS},
  author       = {Junhui Cheng and Meibao Yao and Yan Yu},
  doi          = {10.1016/j.knosys.2025.114333},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114333},
  shortjournal = {Knowl. Based Syst.},
  title        = {An accurate quantitative analysis model for martian-like mineral elements using bi-LSTM coupled with whale optimization algorithm},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantically enhanced community detection in social networks: Integrating BERT with a comprehensive ontology and SWRL rules. <em>KBS</em>, <em>329</em>, 114332. (<a href='https://doi.org/10.1016/j.knosys.2025.114332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection in social networks is crucial for understanding online interactions. Traditional methods often overlook semantic information. This paper introduces a novel framework that significantly enhances community detection accuracy and interpretability by integrating deep semantic representation with formal knowledge and logical reasoning. Our primary contributions are threefold: (1) a synergistic framework combining fine-tuned BERT embeddings, a comprehensive domain-specific ontology, and SWRL rules; (2) an ontology-guided attention mechanism that directs BERT to focus on semantically relevant concepts during fine-tuning; and (3) the application of logical inference via SWRL to refine community boundaries and identify implicit user relationships. We evaluated our framework on diverse datasets from Facebook, Twitter, and Reddit. Experiments demonstrate significant improvements in modularity, NMI, and F1-score over strong baselines, including Louvain, graph attention networks (GAT), and other embedding-based methods. An ablation study confirms the critical contributions of both the ontology-guided attention and the SWRL rules. A case study on Twitter political discussions further illustrates the framework’s ability to uncover semantically coherent communities, influential users, and fine-grained thematic structures. This research establishes a new paradigm for community detection that effectively merges structural analysis with semantic knowledge, delivering more accurate, interpretable, and scalable results.},
  archive      = {J_KBS},
  author       = {Abdelweheb Gueddes and Borhen Louhichi and Mohamed Ali Mahjoub},
  doi          = {10.1016/j.knosys.2025.114332},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114332},
  shortjournal = {Knowl. Based Syst.},
  title        = {Semantically enhanced community detection in social networks: Integrating BERT with a comprehensive ontology and SWRL rules},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-perspective knowledge graph embedding model fusing structural features and textual descriptions of entities. <em>KBS</em>, <em>329</em>, 114331. (<a href='https://doi.org/10.1016/j.knosys.2025.114331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In knowledge graph, both the structural features and the textual descriptions of entities carry rich content, where structural features can be subdivided into local and global features. However, existing methods find it challenging to fully utilize entities’ structural features and textual descriptions,failing to effectively capture the multiscale interaction between entities and relations.To tackle the problems mentioned, this paper proposes a multi-perspective knowledge graph embedding model fusing structural features and textual descriptions of entities (MPST). This paper solves the problem of insufficiently rich structural features of entities by learning local and global features of entities through relational graph neural network and Transformer, respectively. Then, this paper proposes a structure-text interaction module to capture the interaction between structural features and textual descriptions to fill the missing semantic information in different structural features. Finally, this paper proposes a collaborative structural decoder that fully integrates entities’ local and global features, effectively capturing the deep connections between different structural features of entities and their relations. Experimental results show that the MPST model achieves MRR scores of 0.387 and 0.509 on the FB15k-237 and WN18RR datasets for the link prediction task, respectively, both surpassing mainstream baseline models and demonstrating its remarkable performance.},
  archive      = {J_KBS},
  author       = {Song Li and Guantong Chen and Liping Zhang and Haipeng Jin and Guanglu Sun},
  doi          = {10.1016/j.knosys.2025.114331},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114331},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-perspective knowledge graph embedding model fusing structural features and textual descriptions of entities},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-view temporal knowledge graph reasoning. <em>KBS</em>, <em>329</em>, 114330. (<a href='https://doi.org/10.1016/j.knosys.2025.114330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Knowledge Graph (TKG) reasoning has attracted significant attention for completing missing knowledge over time. Recent graph neural network (GNN) -based approaches that explore the temporal evolution of graph topological structures from either continuous-time or discrete-time, which offer distinct perspectives on modeling event associations in TKG. Two GNN-based approaches with different perspectives are supposed to be complementary, but effective integration has not been thoroughly explored in existing research. In addition, capturing the repetitive nature of events during GNN message passing poses a challenge in the continuous-time view, while the complex associations among co-occurring events in KG snapshots cannot be efficiently modeled in the discrete-time view. In this paper, we propose a new D ual- v iew TK G r easoning network, namely DV-TKR, which comprehensively models the temporal semantic information by integrating the strengths of both types of graph structure encoding representation for reasoning. In DV-TKR, we decompose the quadruple neighbors of each entity into triples and times in the continuous-time TKG. A time-aware event recurring modeling (TERM) module incorporating multiple attention mechanisms in the continuous-time view, is proposed to effectively distinguish the importance of the same triple at different times. For the discrete-time view, we propose a relation-aware graph evolving modeling (RGEM) module to learn the temporal evolution of entities among successive KG snapshots. The relation-aware graph attention mechanism in the RGEM module captures significant correlations among co-occurring events within the overall KG snapshot. Extensive experimental results on three public datasets demonstrate the superiority of our proposed model compared to the state-of-the-art baselines.},
  archive      = {J_KBS},
  author       = {Wei Chen and Yuting Wu and Shengnan Guo and Shuhan Wu and Zhishu Jiang and Youfang Lin and Huaiyu Wan},
  doi          = {10.1016/j.knosys.2025.114330},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114330},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dual-view temporal knowledge graph reasoning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective two-dimensional code instance dollmaker masked convolutional network for QR code beautification. <em>KBS</em>, <em>329</em>, 114329. (<a href='https://doi.org/10.1016/j.knosys.2025.114329'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid proliferation of internet applications has made Quick Response (QR) codes indispensable in domains such as electronic ticketing, warehouse management, and online payments. However, enhancing QR code visual quality for advertising and branding purposes remains challenging due to the trade-off between aesthetic appeal and scanning reliability, as well as the inefficiency of existing beautification methods. To solve these issues, this research introduces a 2-Dimensional Code Instance Improved Dollmaker Masked Convolutional Network (2DMCN) that integrates segmentation-based region of interest extraction, an Improved Dollmaker Optimization (IDO) algorithm for visual quality enhancement, and a VGG-19-based style transfer module for customizable designs. Codeword adjustment and discrete cosine transform-based embedding are employed to maintain both data integrity and visual quality. Experimental results demonstrate that 2DMCN attains a PSNR of 55.38 dB, SSIM of 0.60, FSIM of 0.70, GMSD of 0.30, noise tolerance of 87.04%, error correction capability of 91.23%, a decoding rate of 0.87, and an average processing time of 6.2 seconds. These results confirm the proposed framework’s greater efficiency, strength, and aesthetic performance associated to prevailing approaches, making it highly suitable for practical, visually appealing, and reliable QR code applications.},
  archive      = {J_KBS},
  author       = {Jyoti Rathi and Surender Kumar Grewal},
  doi          = {10.1016/j.knosys.2025.114329},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114329},
  shortjournal = {Knowl. Based Syst.},
  title        = {An effective two-dimensional code instance dollmaker masked convolutional network for QR code beautification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DNMDR: Dynamic networks and multi-view drug representations for safe medication recommendation. <em>KBS</em>, <em>329</em>, 114327. (<a href='https://doi.org/10.1016/j.knosys.2025.114327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medication Recommendation (MR) is a promising research topic which booms diverse applications in healthcare and clinical domains. However, existing methods mainly rely on sequential modelling and static graphs for representation learning, which ignore the dynamic correlations in diverse medical events of a patient’s sequential visits, leading to insufficient global structural exploration on nodes. Additionally, mitigating drug-drug interactions (DDIs) is another issue determining the utility of the MR systems. To address the challenges mentioned above, this paper proposes a novel MR method with the integration of dynamic networks and multi-view drug representations (DNMDR). Specifically, weighted snapshot sequences for dynamic heterogeneous networks are constructed based on discrete visits in sequential EHRs, and all the dynamic networks are jointly trained to capture both structural correlations in diverse medical events and sequential dependency in historical health conditions, aiming to achieve comprehensive patient representations with both semantic features and structural relationships. Moreover, by combining the drug co-occurrences and adverse DDIs in the internal view of drug molecule structure and the interactive view of drug pairs, safe drug representations are available to obtain high-quality medication combination recommendations. Finally, extensive experiments on real-world datasets are conducted for performance evaluation, and the experimental results demonstrate that the proposed DNMDR method outperforms the state-of-the-art baseline models with a large margin on various metrics such as PRAUC, Jaccard, DDI rates and so on. The DNMDR model’s code is available at https://github.com/Liuguanlin818/DNMDR .},
  archive      = {J_KBS},
  author       = {Guanlin Liu and Xiaomei Yu and Zihao Liu and Shucheng Liu and Xue Li and Xingxu Fan and Xiangwei Zheng},
  doi          = {10.1016/j.knosys.2025.114327},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114327},
  shortjournal = {Knowl. Based Syst.},
  title        = {DNMDR: Dynamic networks and multi-view drug representations for safe medication recommendation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Operator transfer learning for physics field prediction on complex geometries with limited labelled data. <em>KBS</em>, <em>329</em>, 114326. (<a href='https://doi.org/10.1016/j.knosys.2025.114326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many engineering applications and scientific discoveries involve predicting physics fields, which are usually functions that operate on complex geometries. The recently proposed neural operator, which is a new machine learning paradigm that can directly learn mappings between functions, has succeeded remarkably in solving physics field prediction problems. However, optimal performance of the neural operators relies heavily on a large amount of labelled data. Collecting sufficient labelled data is expensive and time-consuming for most engineering scenarios. However, transfer learning can leverage the knowledge of relevant domains to reduce data requirements. In this study, a novel operator transfer learning framework based on neural operators on Riemannian manifolds (OTL-NORM) is proposed, which can predict physics fields on complex geometries with limited labelled data. OTL-NORM encodes physics fields on complex geometries by the Laplace–Beltrami operator (LBO) eigenfunctions of the geometries. Additionally, a hybrid loss function is constructed using conditional embedding operator discrepancy to solve the conditional distribution adaptation problem. Experiments on multiple physics field prediction problems involving complex 2D and 3D geometries demonstrate that the proposed operator transfer learning method can accurately predict high-dimensional physics fields with only limited labelled data.},
  archive      = {J_KBS},
  author       = {Lin Hu and Lu Chen and Yingguang Li and Xu Liu and Gengxiang Chen and Qinglu Meng and Xiaozhong Hao and Changqing Liu},
  doi          = {10.1016/j.knosys.2025.114326},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114326},
  shortjournal = {Knowl. Based Syst.},
  title        = {Operator transfer learning for physics field prediction on complex geometries with limited labelled data},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge distillation with predicted depth for robust and lightweight face presentation attack detection. <em>KBS</em>, <em>329</em>, 114325. (<a href='https://doi.org/10.1016/j.knosys.2025.114325'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face Presentation Attack Detection (FacePAD) is critical for safeguarding face recognition systems against spoofing attempts, including printed photos, video replays, and 3D masks. However, many existing approaches struggle with generalization across diverse attack types and real-world conditions. In this study, we propose a dual-branch deep learning framework that leverages both RGB images and synthetically predicted depth maps to improve anti-spoofing robustness and accuracy. A monocular depth estimation network is used to generate depth cues from a single RGB image, which are then processed in parallel with the original image through two distinct branches of a convolutional neural network. The extracted features-texture-based from RGB and structure-aware from depth-are fused via concatenation to facilitate more discriminative spoof detection. Extensive experiments on four benchmark datasets demonstrate that our method achieves state-of-the-art performance, reducing HTER to 0 % on Replay-Attack and Replay-Mobile, and 1.023 % on ROSE-Youtu. Similarly, an ACER of 0.56 % is achieved on OULU-NPU, while maintaining computational efficiency. Furthermore, we introduce a knowledge distillation scheme to compress the dual-branch model into a lightweight single-branch variant suitable for real-time deployment in mobile authentication, surveillance, and biometric access control scenarios.},
  archive      = {J_KBS},
  author       = {Muhammad Shahid Jabbar and Taha Hasan Masood Siddique and Kejie Huang and Shujaat Khan},
  doi          = {10.1016/j.knosys.2025.114325},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114325},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge distillation with predicted depth for robust and lightweight face presentation attack detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient pseudo-label screening for entity alignment: Contrastive learning and cross-entropy joint optimization. <em>KBS</em>, <em>329</em>, 114324. (<a href='https://doi.org/10.1016/j.knosys.2025.114324'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For entity alignment in the knowledge graph, pseudo-label iteration is an important way to address the problem of limited prior aligned entities. It is impacted by the speed, quantity, and accuracy of pseudo-label screening. However, existing methods often have some inadequacy in three factors, leading to the “buckets effect”. In this paper, the TSJO (Two Stages Joint Optimization) model is established for obtaining entity embedding representation. DR-T (Dynamic Relative Threshold) and D-Rot (Datasets Rotation) algorithms are proposed for efficiently screening and utilizing pseudo-labels. Specifically, TSJO simultaneously uses cross-entropy loss and contrastive loss to optimize the embedding layer. The joint execution of two stages allows TSJO to learn more precise entity semantics. DR-T algorithm accurately and rapidly screens a large number of pseudo-labels by comparing a ratio to a dynamically relaxed threshold. This ratio is the result of the second nearest neighbor similarity divided by nearest neighbor similarity. D-Rot algorithm generates a new dataset using prior aligned entities augmented with pseudo-labels. Then it selects either the new dataset or the inital one as the input for TSJO to learn better entity embedding representation. Extensive experiments show that, in contrast to other commonly used pseudo-label methods, the TSJO model achieves a comprehensive optimum in the speed, quantity, and accuracy of pseudo-label screening, and delivers the best entity alignment performance, demonstrating competitive performance.},
  archive      = {J_KBS},
  author       = {Haoran Xu and Wei Huang and Wenjing Xie and Le Yin and Yixin Zhao},
  doi          = {10.1016/j.knosys.2025.114324},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114324},
  shortjournal = {Knowl. Based Syst.},
  title        = {Efficient pseudo-label screening for entity alignment: Contrastive learning and cross-entropy joint optimization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFUSegNet: Boundary-aware hierarchical attentive fusion network with adaptive preprocessing for diabetic foot ulcer segmentation. <em>KBS</em>, <em>329</em>, 114323. (<a href='https://doi.org/10.1016/j.knosys.2025.114323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic Foot Ulcers (DFUs) are a severe complication of diabetes, often leading to lower limb amputation and increased patient morbidity. Accurate segmentation of DFUs is essential for effective wound assessment, treatment planning, and healing monitoring. This paper introduces a novel deep learning framework, DFUSegNet, for accurate segmentation of DFUs and other chronic wounds. The proposed architecture seamlessly integrates a learnable image preprocessor (LIP) to enhance input quality and a hierarchical encoder for capturing multiscale and multiresolution wound features. A boundary enhancer (BE) sharpens ulcer edges, while the multiresolution positional attention (MPA) module emphasizes critical spatial details. Extracted features by the encoder are refined through a local-global feature aggregation (LGFA) module before being processed by a dual-mode attention-guided hierarchical decoder, ensuring precise and robust segmentation. Extensive quantitative and qualitative evaluations on the DFUC, FUSeg, and AZH Wound datasets showcase the superior performance of DFUSegNet, achieving state-of-the-art IoU/F1-scores (in %) of 60.06/70.78 on DFUC, 79.06/85.76 on FUSeg, and 81.21/87.28 on AZH. Interpretability analysis further highlights the effectiveness of our MPA, BE modules, and dual-mode attention-guided decoder in progressively extracting intricate ulcer features. Despite encountering some anomalies in the datasets, DFUSegNet demonstrates immense potential for integration into knowledge-based systems within clinical workflows and telemedicine, enabling automated, high-precision DFU segmentation to support early diagnosis and effective wound management. While promising results validate its effectiveness, successful clinical deployment will require large, accurately annotated DFU datasets, laying the foundation for future advancements in automated DFU segmentation. Source code: https://github.com/tushartalukder/DFUSegNet},
  archive      = {J_KBS},
  author       = {Tushar Talukder Showrav and Muhammad Zubair Hasan and Md Kamrul Hasan},
  doi          = {10.1016/j.knosys.2025.114323},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114323},
  shortjournal = {Knowl. Based Syst.},
  title        = {DFUSegNet: Boundary-aware hierarchical attentive fusion network with adaptive preprocessing for diabetic foot ulcer segmentation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced network security through an intelligent deep learning-based intrusion detection system with optimized performance. <em>KBS</em>, <em>329</em>, 114322. (<a href='https://doi.org/10.1016/j.knosys.2025.114322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network security is increasingly critical with the growth of networks and sophisticated cyberattacks. Existing Intrusion Detection Systems (IDS) face slow training, poor scalability with high-dimensional data, and overfitting, especially in IoT and smart infrastructures. This paper presents an Enhanced Network Security approach through an Intelligent Deep Learning-Based IDS with Optimized Performance (ENS-IDS-HGWNN). Data from CICIDS-2017 and WSN-DS datasets undergo cleaning, missing value handling, and redundancy removal using Neural Correlation Integrated Adaptive Point Process Filtering (NCIAPPF). SMOTE balances datasets, while Weighted Leader Search Algorithm (WLSA) selects features. Intrusion detection and classification is done by using Hyperbolic Graph Wavelet Neural Network (HGWNN), and is optimized by Triangulation Topology Aggregation Optimizer (TTAO). ENS-IDS-HGWNN achieves 98.12 % accuracy for Brute Force (CICIDS-2017) and 96.72 % for Blackhole (WSN-DS), outperforming baselines in precision, recall, F-score, ROC-AUC, MCC, and computational efficiency across all attack categories.},
  archive      = {J_KBS},
  author       = {Siva Subramanian R and Nithya T and Sudha K and Dinesh M G},
  doi          = {10.1016/j.knosys.2025.114322},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114322},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced network security through an intelligent deep learning-based intrusion detection system with optimized performance},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ECMRN: Efficient cross-modal reparameterization network for RGB-D tasks via prompt tuning. <em>KBS</em>, <em>329</em>, 114321. (<a href='https://doi.org/10.1016/j.knosys.2025.114321'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D semantic segmentation has shown notable progress by leveraging the complementary characteristics of RGB and depth modalities, substantially enhancing scene understanding. However, existing approaches often depend on dual-encoder architectures, leading to high computational overhead and limited inference efficiency. To overcome these limitations, we propose an Efficient Cross-Modal Reparameterization Network (ECMRN), which integrates prompt tuning with dynamic frequency-domain structural reparameterization for efficient and accurate segmentation. Specifically, we introduce a hybrid RGB-D block that combines a frozen attention branch and a trainable CNN branch, facilitating collaborative modeling of global context and local structures. A Cross-layer Prompt Adapter (CPA) is devised to bridge the modality gap via learnable attention fusion and token interaction, enabling effective semantic alignment across modalities. Moreover, we propose a unified structural reparameterization framework, instantiated in both the stem module and the Dynamic Frequency-domain Reparameterization Module (DFRM), which facilitates expressive multi-branch feature learning during training and is equivalently transformed into a compact single-branch structure at inference for efficient deployment. Additionally, a Multi-scale Feature Optimization Module (MFOM) applies grouped attention at multiple scales to further enhance feature representation. Extensive experiments demonstrate that ECMRN achieves competitive performance in RGB-D semantic segmentation with nearly half the parameters of state-of-the-art methods and also sets new benchmarks on RGB-D salient object detection. The code will be made available at https://github.com/alkaidzc/ECMRN .},
  archive      = {J_KBS},
  author       = {Di Jia and Chen Zhao and Huilun Song and Huaxiu Zhang and Wei Li},
  doi          = {10.1016/j.knosys.2025.114321},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114321},
  shortjournal = {Knowl. Based Syst.},
  title        = {ECMRN: Efficient cross-modal reparameterization network for RGB-D tasks via prompt tuning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HSAE: Hierarchical structure augment embedding for various knowledge graph completion. <em>KBS</em>, <em>329</em>, 114320. (<a href='https://doi.org/10.1016/j.knosys.2025.114320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph Completion (KGC) addresses the task of reasoning over existing facts to predict missing relationships, serving as a fundamental component for downstream applications including question answering systems and personalized recommendation engines. Over the years, the KGC field has evolved into specialized tasks, including static KGC, temporal KGC, hyper KGC, and few-shot KGC, each requiring specialized methodologies. Although previous methods have utilized Generative Language Models (GLMs) to theoretically support multi task compatibility, their performance remains suboptimal compared to task-specific models. This limitation stems from their inability to effectively integrate structural and textual information, leading to a fine-grained structure-text gap. To address this challenge, we propose HSAE, a novel two-stage framework that hierarchically aligns structural and textual modalities, first at the coarse-grained entity level and then at the fine-grained token level. In the first stage, Entity-Level Structure Augment, we transform structural embeddings into tree-shaped entity classifications, enriching entity representations with explicit structural information. This augmentation provides global structural guidance during beam search, ensuring that generated sequences adhere to the underlying knowledge graph topology. In the second stage, Token-Level Structure Augment, we introduce a cross-modal alignment module that dynamically fuses structural embeddings with token-level predictions. By aligning structural and textual representations at the token level, HSAE ensures that each decoding step is informed by both structural and textual coherence. Experiments on eight benchmarks demonstrate that HSAE outperforms competitive baselines across multiple KGC tasks. The data and code are released at https://anonymous.4open.science/r/HSAE-main/README.md .},
  archive      = {J_KBS},
  author       = {Yifan Xue and Wanqiang Cai and Yingyao Ma and Lotfi Senhadji and Huazhong Shu and Jiasong Wu},
  doi          = {10.1016/j.knosys.2025.114320},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114320},
  shortjournal = {Knowl. Based Syst.},
  title        = {HSAE: Hierarchical structure augment embedding for various knowledge graph completion},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancement of single candidate optimizer for weighted feature fusion and dilation-based cascaded RNN in learning-based recommendation system. <em>KBS</em>, <em>329</em>, 114319. (<a href='https://doi.org/10.1016/j.knosys.2025.114319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation System (RS) plays a vital role in supporting decision-making processes, particularly in the context of online learning, which has gained substantial reputation in recent years. Although various advanced techniques have been proposed for RS, many still fall short of achieving optimal performance due to limitations in handling complex data formats and preprocessing challenges. Existing RS techniques often struggle with managing missing values, ensuring consistent data formatting, and capturing complex non-linear relationships within the input data. To address these issues, this work proposes an intelligent deep learning-based recommendation approach. First, input text data is collected from benchmark datasets and undergoes comprehensive pre-processing. The processed data is then passed through Multi-scale Bidirectional Encoder Representations from Transformers (BERT) and Transformer models to extract complementary and contextualized features. These features are effectively fused using a Weighted Feature Fusion (WFF) technique, where the optimal weight factor is determined by the Modified Alpha in Single Candidate Optimizer (MASCO) . The performance of the proposed model is evaluated across three benchmark datasets. The accuracy of the DCRNN framework reaches 94.4 %, 95.35 %, and 94.82 % for Datasets 1, 2, and 3, indicating consistent and high-performance results. The experimental results demonstrate that the proposed deep learning-based RS significantly outperforms existing techniques, offering improved recommendation accuracy and robustness, particularly in online learning applications.},
  archive      = {J_KBS},
  author       = {Balaji V and Anupam Das and Vishnupriya G and Safak Kayikci},
  doi          = {10.1016/j.knosys.2025.114319},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114319},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancement of single candidate optimizer for weighted feature fusion and dilation-based cascaded RNN in learning-based recommendation system},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ProDG: A proxy-domain-guiding strategy for multi-source-free domain adaptation in EEG emotion recognition. <em>KBS</em>, <em>329</em>, 114318. (<a href='https://doi.org/10.1016/j.knosys.2025.114318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subject-independent Electroencephalogram (EEG) emotion recognition has underperformed due to significant disparities among subjects. Domain adaptation (DA) is a common solution, but traditional methods require access to target domain data, raising privacy concerns. Source-free domain adaptation offers a viable solution, however, researches on it remains unexplored. Moreover, existing methods overlooked the complementary information across source domains. To overcome this challenge, we focus on exploring the inter-domain complementarity. Our core insight is that higher-confidence predictions from source models indicate regions closer to the target domain’s distribution. Based upon, we propose Pro xy- D omain- G uiding ( ProDG ) strategy, which pioneers confidence-guidance to achieve privacy-preserving recognition. First, we propose a Proxy Guiding theory validating that predictions of source models with higher confidence exhibit closer distributional proximity to the target domain. Then, we propose two modules: Pr oxy M utual I nformation Alignment ( PrMI ) constructs a proxy domain by aggregating high-confidence predictions from source models, approximating the target-overlapping region, then each source model is aligned with proxy domain via mutual information maximization; Pr oxy P seudo- L abel Alignment ( PrPL ) refines clustering-based pseudo-labels using cross source confidence evaluation, enhancing supervised loss quality. The whole training process utilize only the source domain model and target data, with source data being inaccessible, ensuring privacy-preserving. Our method attains state-of-the-art accuracy on DEAP(65.3 %), SEED (85.9 %) and SEED-IV (70.4 %), surpassing privacy-preserving methods by a large margin and rivaling non-privacy-preserving approaches. ProDG validates the efficacy of confidence-based proxy guiding in multi-source-free domain adaptation. This work was conducted at the College of Electronics and Information Engineering, Sichuan University in May 2025.},
  archive      = {J_KBS},
  author       = {Bingtao Zhou and Mian Xiang and Qian Ning},
  doi          = {10.1016/j.knosys.2025.114318},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114318},
  shortjournal = {Knowl. Based Syst.},
  title        = {ProDG: A proxy-domain-guiding strategy for multi-source-free domain adaptation in EEG emotion recognition},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-target object detection and classification for cloud based surveillance in smart internet of things using multi-component attention graph convolutional neural network. <em>KBS</em>, <em>329</em>, 114317. (<a href='https://doi.org/10.1016/j.knosys.2025.114317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud-based surveillance in smart Internet of Things (IoT) systems uses object detection and classification to enhance security and monitoring by processing data in the cloud, providing scalability and analysis. In this manuscript, Multi-Target Object Detection and Classification for Cloud-Based Surveillance in Smart Internet of Things using Multi-Component Attention Graph Convolutional Neural Network (MTO-IoT-MCAGCNN) is proposed. Firstly, input images are collected from PASCAL VOC Dataset. The input imagesare fed to pre-processing using Interaction-Aware Labled Multi-Bernoulli Filter (IALMBF)to remove noise from the collected input images; then the Pre-processed images are fed to feature extraction using Spatial-Temporal Knowledge-Embedded Transform (STKET)to extract Semantic features such as colour, shape and object. Then, the extracted images are fed to Multi-Component Attention Graph Convolutional Neural Network (MAGCNN) for object detection and classification. In general, MAGCNN does not express adapting optimization strategies to establish the ideal variables to guarantee the detection and classification the collected image. Hence, the Brown Bear Optimization Algorithm (BBOA) is used to optimize the weight parameter of MAGCNNused to classify the collected images. Then the proposed MTO-IoT-MCAGCNNis implemented in Python. Performance of the MTO-IoT-MCAGCNNapproach attains higher Specificity of 99.12 %, higher Accuracy of 99.55 % and higher (Mean Average Precision (maP)of 99.1 % when analysed through existing techniques like Research of multi-object detection and tracking using machine learning based on knowledge for video surveillance system(MODT-SS-CNN), a feature‐optimized Faster regional convolutional neural network for complex background objects detection (CBOD-RCNN) and deep-learning-enhanced multimarket detection for end–edge–cloud surveillance in smart IoT (MD- IoT-YONet),methods respectively.},
  archive      = {J_KBS},
  author       = {Rajasekaran A and T. Dinesh Kumar and M.A. Archana and S. Malathi and K. Saraswathi},
  doi          = {10.1016/j.knosys.2025.114317},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114317},
  shortjournal = {Knowl. Based Syst.},
  title        = {Multi-target object detection and classification for cloud based surveillance in smart internet of things using multi-component attention graph convolutional neural network},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-guided distribution alignment for cross-domain few-shot learning. <em>KBS</em>, <em>329</em>, 114316. (<a href='https://doi.org/10.1016/j.knosys.2025.114316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain few-shot learning (CD-FSL) aims to recognize novel categories with minimal labeled samples in target domains that differ from source domains. However, difficulty in obtaining valid domain bias guidance leads to negative transfer challenges because the target domain samples are unknown during source domain training. Inspired by human reliance on prior knowledge when adapting to new domains, we propose a knowledge-guided distribution alignment network (KDANet). In contrast to earlier CD-FSL approaches that primarily focus on visual alignment alone, KDANet incorporates textual priors in both the training and adaptation stages, thereby enhancing domain transferability. Specifically, KDANet integrates textual priors as knowledge guidance for visual representation learning during pretraining in the source domain with sufficient samples to establish an initial learning foundation. To tackle the scarcity of target domain samples, available samples and construct pseudo-episodes are expanded through critical region detection. Leveraging the pretrained model and pseudo-episodes, a two-stage progressive finetuning method is employed to refine feature extraction and calibrate prototypes for target domain tasks, with prior knowledge guiding the learning process continuously. Moreover, adaptive distribution alignment is proposed throughout cross-domain training and finetuning to suppress distribution bias interference by utilizing multi-source domain alignment and triplet supervision. Quantitative and qualitative experiments demonstrate the superior performance of proposed method, particularly in challenging 1-shot tasks. Under the CD-FSL benchmark, proposed method achieves an average accuracy improvement of 3 % across all target domains, outperforming state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Jiale Chen and Feng Xu and Xin Lyu and Tao Zeng and Xin Li and Shangjing Chen},
  doi          = {10.1016/j.knosys.2025.114316},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114316},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge-guided distribution alignment for cross-domain few-shot learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning with integration of decision making method and various machine learning algorithms for alzheimer’s prediction. <em>KBS</em>, <em>329</em>, 114315. (<a href='https://doi.org/10.1016/j.knosys.2025.114315'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease, a progressive and debilitating neurodegenerative disorder, presents considerable challenges in early diagnosis and treatment planning. Given the sensitive nature of patient health records and the diversity of medical data sources, there is a pressing need for diagnostic tools that are not only accurate and robust but also privacy-preserving. Federated learning offers a promising solution by enabling collaborative model training across multiple decentralized institutions, allowing each to contribute to a shared global model without exposing raw data. This approach safeguards patient confidentiality while ensuring compliance with data protection regulations. To further enhance the efficiency and effectiveness of federated systems, this research integrates multi-criteria decision-making methods into the federated learning framework. The use of these facilitates informed client selection, balanced model aggregation, and the prioritization of key factors such as accuracy, data distribution, volume, and computational capacity. This integration enables performance-driven decision-making under heterogeneous data conditions and enhances the scalability and personalization of collaborative learning. Various machine learning algorithms are incorporated within this federated decision-making framework to evaluate client contributions, optimize model training, and ensure the selection of top-performing clients based on multiple criteria. These algorithms play a crucial role in constructing accurate, robust and privacy-preserving models across distributed data sources, enabling effective collaboration without compromising data privacy. Together, federated learning and decision-making methods form a powerful paradigm for building intelligent, secure and high-performance diagnostic systems tailored to the complexities of Alzheimer’s disease. This research study provides an in-depth exploration of the working mechanism of federated learning combined with decision-making method. It includes the evaluation metrics calculated by these methods, a comparison of various machine learning algorithms utilized in this federated learning decision-making framework, as well as a discussion of their limitations and future directions.},
  archive      = {J_KBS},
  author       = {Maheen Sultan and Muhammad Akram and Shaista Habib and Cengiz Kahraman},
  doi          = {10.1016/j.knosys.2025.114315},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114315},
  shortjournal = {Knowl. Based Syst.},
  title        = {Federated learning with integration of decision making method and various machine learning algorithms for alzheimer’s prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Question answering over spatio-temporal knowledge graph. <em>KBS</em>, <em>329</em>, 114314. (<a href='https://doi.org/10.1016/j.knosys.2025.114314'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal knowledge graphs (STKGs) enhance traditional KGs by integrating temporal and spatial annotations, enabling precise reasoning over questions with spatio-temporal dependencies. Despite their potential, research on spatio-temporal knowledge graph question answering (STKGQA) remains limited. This is primarily due to the lack of datasets that simultaneously contain spatio-temporal information, as well as methods capable of handling implicit spatio-temporal reasoning. To bridge this gap, we introduce the spatio-temporal question answering dataset (STQAD), the first comprehensive benchmark comprising 10,000 natural language questions that require both temporal and spatial reasoning. STQAD is constructed with real-world facts containing spatio-temporal information, ensuring that the dataset reflects practical scenarios. Furthermore, our experiments reveal that existing KGQA methods underperform on STQAD, primarily due to their inability to model spatio-temporal interactions. To address this, we propose the spatio-temporal complex question answering (STCQA) method, which jointly embeds temporal and spatial features into KG representations and dynamically filters answers through constraint-aware reasoning. STCQA achieves state-of-the-art performance, significantly outperforming existing baselines. Our work not only provides a valuable resource for future research but also advances the field by offering a robust baseline for answering complex spatio-temporal questions.},
  archive      = {J_KBS},
  author       = {Xinbang Dai and Huiying Li and Nan Hu and Yongrui Chen and Rihui Jin and Huikang Hu and Guilin Qi},
  doi          = {10.1016/j.knosys.2025.114314},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114314},
  shortjournal = {Knowl. Based Syst.},
  title        = {Question answering over spatio-temporal knowledge graph},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CTIUFuse: A CNN-transformer-based iterative feature universal fusion algorithm for multimodal images. <em>KBS</em>, <em>329</em>, 114313. (<a href='https://doi.org/10.1016/j.knosys.2025.114313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal image fusion is designed to combine the complementary features of different image modalities, thereby improving data quality. It has numerous applications in medical imaging, industrial inspection, and autonomous driving. To explore detailed information within image scenes in detail and effectively integrate complementary information from images, we propose a universal multimodal image fusion algorithm based on the CNN-Transformer iterative feature fusion (CTIUFuse). We improve a dual-branch CNN-Transformer encoder by incorporating the Residual Gradient Dense Block (RGDB) and a lightweight attention mechanism, which collaboratively extract fine-grained and global features while reducing computational cost. Furthermore, we present an iterative feature fusion network that progressively refines cross-modal complementary features. For self-supervised training, we derive a dynamic texture loss function that adaptively adjusts weights based on the importance of information in each modality, thereby ensuring optimal fusion performance. The experimental results reveal that CTIUFuse achieves superior performance on six datasets composed of infrared-visible and medical images. It outperforms existing methods in terms of both fusion accuracy and computational efficiency, significantly enhancing downstream infrared-visible object detection tasks and demonstrating strong generalizability. The source code of the CTIUFuse algorithm is available at https://github.com/L1nCyk/CTIUFuse .},
  archive      = {J_KBS},
  author       = {Chenyoukang Lin and Tao Liu and Zixi Wang and Bo Wang},
  doi          = {10.1016/j.knosys.2025.114313},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114313},
  shortjournal = {Knowl. Based Syst.},
  title        = {CTIUFuse: A CNN-transformer-based iterative feature universal fusion algorithm for multimodal images},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ConEm: A novel framework for integrating external factors with inner and outer correlations in time series forecasting. <em>KBS</em>, <em>329</em>, 114312. (<a href='https://doi.org/10.1016/j.knosys.2025.114312'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is pivotal in both academic research and practical applications across diverse industries. However, effectively leveraging external factors to enhance forecasting performance remains a significant challenge, necessitating further investigation. Current frameworks exhibit notable limitations in modeling the impact of external factors on both intrinsic and extrinsic correlations within time series data. To address these challenges, we propose a novel mechanism that systematically integrates contextual information from external factors with temporal dependencies, while maintaining compatibility with various encoder-decoder algorithms. This approach enables backbone models to embed dependent patterns from external factors across multiple correlated time series, effectively capturing their influence on both prior and adjacent timesteps. Our study centered on the application of time series forecasting for demand prediction, as sales forecasting poses unique challenges stemming from the complexity and variability of market conditions influenced by numerous external factors. We conducted extensive experiments on three real-world retail datasets, showcasing the substantial performance enhancement of backbone models when integrated with our proposed contextual embedding mechanism. Specifically, our approach achieves improvements of up to 26 % in Mean Squared Error (MSE) and 15 % in Mean Absolute Error (MAE) compared to both the original backbone models and other state-of-the-art (SOTA) baseline methods. The proposed mechanism is also evaluated on Weather and Energy datasets to further verify its generalization capability. We will release the source codes and experimental datasets at our GitHub 1 .},
  archive      = {J_KBS},
  author       = {Hoang Nguyen Nguyen and Wei Xiang and Lianhua Chi and Mike Da Gama and Sanjeevani Avashi and Michael Treloar and Lu Yu},
  doi          = {10.1016/j.knosys.2025.114312},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114312},
  shortjournal = {Knowl. Based Syst.},
  title        = {ConEm: A novel framework for integrating external factors with inner and outer correlations in time series forecasting},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VCE: Visual concept embedding for open-set fine-grained image retrieval. <em>KBS</em>, <em>329</em>, 114311. (<a href='https://doi.org/10.1016/j.knosys.2025.114311'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image retrieval (FGIR) aims to accurately distinguish highly similar subclasses from a large collection of visually similar images. In open-set scenarios, local features of unseen categories often exhibit significant overlap with those of seen categories. Therefore, the model must extract transferable local semantics from seen classes to enable compositional reasoning. However, existing approaches primarily rely on holistic feature association within seen categories, resulting in highly entangled representations that hinder generalization to novel classes in open-set conditions. To address this, we propose a FGIR framework named Visual Concept Embedding (VCE), inspired by the human cognitive process where objects are decomposed into distinct concepts to achieve a better understanding. The VCE consists of two key components: Visual Concept Decoupling (VCD) and Concept-Enhanced Representation (CER). Specifically, the VCD represents objects as a composition of multiple independent concepts by leveraging a set of learnable concept vectors and a cross-attention mechanism. This decoupling allows the model to independently analyze the discriminability of each local feature, rather than relying on entangled global representations. Furthermore, the CER models the structural relationships among concepts, enabling the model to precisely attend to critical regions that reflect fine-grained differences and ensuring alignment between feature dimensions and discriminative local semantics. Extensive experiments demonstrate that VCE effectively learns different visual concepts and validates its effectiveness across three datasets.},
  archive      = {J_KBS},
  author       = {Yuetian Wang and Shuo Ye and Wenjin Hou and Shuhuang Chen},
  doi          = {10.1016/j.knosys.2025.114311},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114311},
  shortjournal = {Knowl. Based Syst.},
  title        = {VCE: Visual concept embedding for open-set fine-grained image retrieval},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing dyslexia intervention through an adaptive sequential recommender system. <em>KBS</em>, <em>329</em>, 114309. (<a href='https://doi.org/10.1016/j.knosys.2025.114309'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Children with dyslexia face significant learning difficulties that require personalized and intensive interventions. Although computer-based support programs exist, they often fail to adapt to the unique needs of each child, representing a major challenge in the field of educational intervention. This article presents a new adaptive sequential guidance system for personalized dyslexia intervention that addresses these limitations. The proposed methodology incorporates several key innovations: (1) a dynamic word generator that creates phonetically modified words and pseudowords from seed words, (2) a three-dimensional matrix structure ( E , W ,and F ) to effectively manage word difficulty and user performance, and (3) a recommendation algorithm based on matrix factorization. To mitigate cold-start problems, the system implements a heuristic initiation process and uses an extension technique to detect difficulties in specific derived words. Additionally, the concept of “virtual children” generated from real data and based on Bayesian Knowledge Tracking is introduced, allowing thorough testing and optimization of the system prior to its actual implementation. The evaluation of the system demonstrates three main results: (1) the use of heat maps and 3D visualization of the E matrix allows identifying specific areas of difficulty for each user, facilitating more targeted interventions; (2) extensive testing confirms the robustness of the system to reduce error rates in multiple trials; and (3) a parametric study evidences the ability of the system to adapt through adjustable parameters, keeping each child in his or her optimal learning zone.},
  archive      = {J_KBS},
  author       = {J. Ignacio Mateo Trujillo and Ignacio Rodríguez-Rodríguez and Diego Castillo-Barnes and Andrés Ortiz and Auxiliadora Sánchez and Juan L. Luque},
  doi          = {10.1016/j.knosys.2025.114309},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114309},
  shortjournal = {Knowl. Based Syst.},
  title        = {Optimizing dyslexia intervention through an adaptive sequential recommender system},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noise-free prototype guided representation calibration under label noise. <em>KBS</em>, <em>329</em>, 114308. (<a href='https://doi.org/10.1016/j.knosys.2025.114308'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world datasets inevitably suffer from label noise, which misleads deep networks and disrupts the underlying representation structures, resulting in poor generalization. As category representatives, prototypes are widely adopted in learning with noisy labels due to their strong semantic expressiveness. Existing works typically obtain prototypes by averaging representations within each class and update them during training. However, prototypes achieved by such label-dependent procedures may deviate from their optimal positions under noisy labels, thereby failing to guide the model towards stable and accurate predictions. In this paper, to mitigate noise-induced prototype deviation, and further learn more robust representations, we propose a novel method called Noise-Free Prototype guided Representation Calibration (NFPRC), which introduces fundamentally different, label-independent prototype construction and utilization. Specifically, NFPRC first leverages unsupervised contrastive learning to extract representations and then applies clustering to assign the nearest prototype to each instance. These noise-free prototypes are then fixed to impose directional constraints and guide robust representation learning. Additionally, NFPRC introduces a dynamic weighting strategy that assigns higher importance to instances with larger cross-entropy losses, thereby prioritizing potentially mislabeled instances and enhancing the model’s adaptability to more complex noisy label scenarios. Extensive experiments on both synthetic and real-world noisy label benchmarks validate the effectiveness of our method in improving representation learning and combating noisy labels. The code is available at: https://github.com/Huiting-hub/NFPRC .},
  archive      = {J_KBS},
  author       = {Huiting Yuan and Tingjin Luo and Xinghao Wu and Jie Jiang},
  doi          = {10.1016/j.knosys.2025.114308},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114308},
  shortjournal = {Knowl. Based Syst.},
  title        = {Noise-free prototype guided representation calibration under label noise},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-powered explanations: Unraveling recommendations through subgraph reasoning. <em>KBS</em>, <em>329</em>, 114307. (<a href='https://doi.org/10.1016/j.knosys.2025.114307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems (RecSys) are pivotal in enhancing user experiences across various web applications by analyzing the complicated relationships between users and items. An explainable RecSys is crucial for the product development and subsequent decision-making. Knowledge graphs (KGs) have been widely used to enhance the performance of RecSys. However, KGs are known to be noisy and incomplete, making it hard to provide reliable explanations for recommendation results. We introduce a novel recommender that synergies Large Language Models (LLMs) and KGs to enhance the recommendation and provide interpretable results. We first harness the power of LLMs to augment KG reconstruction, where LLMs analyze and extract information from user reviews to generate new triples. In this way, we can enrich KGs with explainable paths that express user preferences. In addition, we introduce a novel subgraph reasoning module that effectively measures the importance of nodes and discovers reasoning for recommendation. Finally, these reasoning paths are fed into the LLMs to generate interpretable explanations of the recommendation results. Our approach significantly enhances both the effectiveness and interpretability of RecSys, especially in cross-selling scenarios where traditional methods falter. The effectiveness of our approach has been rigorously tested on four open real-world datasets, with our methods demonstrating a superior performance over contemporary state-of-the-art techniques by an average improvement of 12 %. The application of our model in a cross-selling RecSys for a multinational engineering and technology company further underscores its practical utility and potential to redefine recommendation practices through improved accuracy and user trust.},
  archive      = {J_KBS},
  author       = {Guangsi Shi and Xiaofeng Deng and Linhao Luo and Lijuan Xia and Lei Bao and Bei Ye and Fei Du and Shirui Pan and Yuxiao Li},
  doi          = {10.1016/j.knosys.2025.114307},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114307},
  shortjournal = {Knowl. Based Syst.},
  title        = {LLM-powered explanations: Unraveling recommendations through subgraph reasoning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QC2-VQG: Question context complement for visual question generation. <em>KBS</em>, <em>329</em>, 114306. (<a href='https://doi.org/10.1016/j.knosys.2025.114306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Generation (VQG) is a critical vision-language understanding task that involves generating human-like questions from given images and associated textual information. Most of the existing works are answer-aware and focus on modeling the complex relationship between the answer and its relevant object regions. However, we observe that these approaches disregard question context (e.g., the image description and visual entities) which is indispensable for a large number of questions, making it difficult to generate the desired questions. To address this issue, we present a novel strategy to generate questions by supplementing image-related question context. The key motivation is that the question context can bridge the task gap between visual understanding and question generation. Thus, we propose QC 2 -VQG which can automatically capture the visual information and convert it to the textual question context for the answer-aware QG. Extensive experiments on two widely used datasets demonstrate that QC 2 -VQG outperforms SOTA methods across various evaluation metrics, highlighting its effectiveness in generating high-quality, contextually grounded questions.},
  archive      = {J_KBS},
  author       = {Ying Zhang and Xubo Liu and Ziyu Lu and Wenya Guo and Xumeng Liu and Ruxue Yan},
  doi          = {10.1016/j.knosys.2025.114306},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114306},
  shortjournal = {Knowl. Based Syst.},
  title        = {QC2-VQG: Question context complement for visual question generation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal electric load portrait method for multi-microgrids based on clustering-granulation-clustering. <em>KBS</em>, <em>329</em>, 114305. (<a href='https://doi.org/10.1016/j.knosys.2025.114305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microgrids (MGs) are transforming urban energy management to sustainability by enabling flexible operation and efficient renewable integration. Facilitating electricity exchange among multiple MGs with differentiated demand structures in dual space and time dimensions is of great significance for promoting renewable energy utilization. The feasibility of such coordination for a given region is highly reliant on the characteristics of local demand. However, a systematic analysis of electricity user types and their demand profiles at high spatial and temporal resolution remains absent. Most spatial load forecasting studies only focus on the load quantities or densities at specific nodes. To address this research gap, this paper proposes a multi-source data-driven spatial-temporal electric load portrait method for multi-microgrids (MMGs). First, the functional areas are clustered into multiple MGs with different regional types. Then, typical load curve (TLC) of each functional area is extracted via information granulation. Finally, secondary clustering is performed on TLCs within each MG to reveal user types and their consumption patterns. Rough k-means (RKM) is selected as the clustering algorithm and some improvements are proposed. Case studies in a Chinese city demonstrate that the proposed approach not only outperforms existing methods in terms of clustering performance and computational efficiency, but also uncovers significant spatial and temporal heterogeneity in the user compositions and demand profiles across different MGs. These insights provide actionable references for optimizing demand response (DR) mechanisms, supporting spatial-temporal energy complementarity, and promoting renewable energy consumption.},
  archive      = {J_KBS},
  author       = {Yiling Cheng and Tengfei Zhang and Si Lv and Fumin Ma and Minghao Fan and Gregory M.P. O’hare},
  doi          = {10.1016/j.knosys.2025.114305},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114305},
  shortjournal = {Knowl. Based Syst.},
  title        = {Spatial-temporal electric load portrait method for multi-microgrids based on clustering-granulation-clustering},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic graph-based multi-task learning model for cut-in intention and trajectory prediction. <em>KBS</em>, <em>329</em>, 114304. (<a href='https://doi.org/10.1016/j.knosys.2025.114304'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cut-in intention and trajectory prediction of the target vehicle in front of the autonomous vehicle (AV) are two major concerns relating to the safety of passengers. For both of them, it is important to consider the spatial-temporal information of the neighboring vehicles. It is a challenging task to capture this information precisely from the narrow-ranged neighbor vehicles. In such a scenario, a dynamically prioritized correlated connection is required based on the cut-in scenario of the target vehicle. Therefore, a multi-task learning framework consisting of a shared layer and a task-specific layer is proposed to capture detailed information using the prior trajectory data of vehicles as input for cut-in intention and trajectory forecasting of the target vehicle. The shared layer incorporates graph structure learning for effective graph representation, a graph neural network (GNN) with skip connections that efficiently captures spatial data, and an attentive encoder-decoder that records the sequential information. The task-specific layer utilizes fully connected neural networks with different activation functions to forecast two well-defined related tasks. The performance of the proposed model is evaluated on NGSIM and highD datasets. The experimental results show that the proposed model achieves 2.89–9.53 % more F1 score and 25.92–30.99 % lower Root Mean Square Error (RMSE) than the baseline models in predicting the cut-in intention and trajectory of the target vehicle, respectively. Furthermore, the model demonstrates the effectiveness and generalizability for real-time cut-in trajectory forecasting.},
  archive      = {J_KBS},
  author       = {Pritam Bikram and Shubhajyoti Das and Arindam Biswas},
  doi          = {10.1016/j.knosys.2025.114304},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114304},
  shortjournal = {Knowl. Based Syst.},
  title        = {A dynamic graph-based multi-task learning model for cut-in intention and trajectory prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning enhanced filter and response reliability regularization for aerial object tracking. <em>KBS</em>, <em>329</em>, 114303. (<a href='https://doi.org/10.1016/j.knosys.2025.114303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) tracking is critical in the transport and security sectors, and recent years have seen significant progress in this field. To address the limited computational resources and stringent real-time requirements of aerial platforms, numerous UAV tracking algorithms based on Discriminative Correlation Filters (DCFs) have been developed, aiming to strike a balance between accuracy and efficiency. However, the limited discriminative power of the filters, along with complex appearance variations such as background clutter, occlusion, and camera motion, continues to pose significant challenges and degrade tracking performance. To tackle these issues, we propose an Enhanced Filter and Response Reliability Correlation Filter (EFRCF). This method introduces an Enhanced Filter Reliability (EFR) regularization module, which employs a response map quality evaluation mechanism to guide the self-adaptive learning of regularization coefficients, thereby enhancing discriminative capability. Furthermore, an Enhanced Response Reliability (ERR) regularization module is incorporated to suppress abrupt fluctuations in the response map. Extensive experiments on four popular UAV tracking benchmarks demonstrate that the proposed EFRCF outperforms several mainstream trackers. Notably, it achieves a real-time processing speed of 62.5 frames per second on a low-cost CPU. The source code will be made available at https://github.com/marico2020/EFRCF here.},
  archive      = {J_KBS},
  author       = {Zhi Chen and Lijun Liu and Zhen Yu},
  doi          = {10.1016/j.knosys.2025.114303},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114303},
  shortjournal = {Knowl. Based Syst.},
  title        = {Learning enhanced filter and response reliability regularization for aerial object tracking},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing inductive knowledge graph completion with contextual relation topology learning. <em>KBS</em>, <em>329</em>, 114302. (<a href='https://doi.org/10.1016/j.knosys.2025.114302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion (KGC) plays a crucial role in inferring missing triples within knowledge graphs (KGs), while inductive KGC extends this by enabling predictions for previously unseen entities, allowing dynamic updates in KGs. Recent methods define entity-independent features and utilize Graph Neural Networks (GNNs) to extract them from subgraphs surrounding the target triplet, which are then used to represent relational semantics and logical rules for reasoning. However, the inductive capabilities of existing work is limited as they consider limited entity-independent features. To address this issue, we introduce a novel C ontextual R elation T opology L earning-based GNN framework for inductive KGC, namely CRTL , which considers a broader range of entity-independent features. We observe that subgraph structural features, relation correlation patterns , and entity-relation interactions are crucial entity-independent features for inductive KGC. Moreover, relation correlation patterns and entity-relation interactions are complementary. Specifically, we construct enclosing subgraphs to extract subgraph structural features, relational graphs to model the correlations between relations, and context subgraphs to capture the interactions between entities and relations. In addition, we design a scoring function that dynamically adjusts the contributions of these features. Our extensive experiments on benchmark datasets reveal that CRTL surpasses current state-of-the-art methods, demonstrating improvements of 9.68 % on WN18RR v1 and 12.86 % on FB15K-237 v1 when compared to the suboptimal results.},
  archive      = {J_KBS},
  author       = {Yuxuan Lu and Guojie Ma and Shiyu Yang and Junxiao Wang},
  doi          = {10.1016/j.knosys.2025.114302},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114302},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing inductive knowledge graph completion with contextual relation topology learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cascade stacked autoencoder neural network for intrusion detection in CAN-FD vehicular network. <em>KBS</em>, <em>329</em>, 114301. (<a href='https://doi.org/10.1016/j.knosys.2025.114301'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, an Intrusion Detection System (IDS) for Controller Area Network with Flexible Data Rate (CAN-FD) Vehicle Networks based on hybrid Deep Learning (DL) is proposed. Initially, the CAN-FD vehicular network simulation is carried out, and then, the authentication protocol is utilized to increase the existing security of in-vehicle applications that verify the authenticity of the participating entities. Later, inter-service communication and external communication are established. Finally, IDS is performed, and the proposed IDS in CAN-FD In-Vehicle Networks is developed in the following manner. Initially, the input data undergoes normalization using z-score normalization. After that, feature selection is performed by a hybrid similarity measure based on Tanimoto and Jeffreys similarity to select the relevant features in the input data. Finally, intrusion detection is performed based on a hybrid DL model named Cascade Stacked Autoencoder Neural Network (CSANN). The proposed CSANN is developed using a Deep Stacked Autoencoder (DSA) and Deep Neuro Fuzzy Network (DNFN). Additionally, the performance of the implemented technique is evaluated using metrics such as accuracy, True Positive Rate (TPR), and True Negative Rate (TNR). The method achieved a maximum accuracy of 0.921, a TPR of 0.935, and a TNR of 0.921.},
  archive      = {J_KBS},
  author       = {V. Anjana Devi and P.V. Bhaskar Reddy and Sreenu Ponnada and K. Suresh Kumar},
  doi          = {10.1016/j.knosys.2025.114301},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114301},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cascade stacked autoencoder neural network for intrusion detection in CAN-FD vehicular network},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AutoEnergy: An automated feature engineering algorithm for energy consumption forecasting with AutoML. <em>KBS</em>, <em>329</em>, 114300. (<a href='https://doi.org/10.1016/j.knosys.2025.114300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature engineering (FE) plays a crucial role in Machine Learning pipelines, yet it remains a time-consuming process requiring heavy domain expertise. While Automated Machine Learning (AutoML) has automated model selection and hyperparameter tuning, it often overlooks FE, which is particularly needed in specialised domains such as Energy Consumption Forecasting (ECF). To address this limitation, we introduce AutoEnergy, a novel, domain-aware FE algorithm tailored for ECF. AutoEnergy automatically generates interpretable features from timestamps and past consumption values through rule-based transformations, integrating them with AutoML for fully automated ECF modelling while reducing human intervention. The performance of AutoEnergy was evaluated using eighteen diverse real-world energy consumption datasets spanning residential, commercial, industrial, and grid power domains. Through extensive benchmarking against baseline AutoML without FE and established FE methods, namely TSFresh (with TSEfficient and TSMinimal configurations) and FeatureTools (FT), AutoEnergy demonstrated significant improvements in both predictive accuracy and computational efficiency. AutoEnergy achieved forecasting error reductions of 19.52 % to 84.72 % compared to benchmarking methods, with strong performance on smaller datasets and statistical validation via Friedman and Wilcoxon tests. AutoEnergy demonstrated notable computational efficiency by running 1.31 and 4.41 times faster than FT and TSEff, respectively. Although 1.58 times slower than TSMin, AutoEnergy achieved 82.38 % lower forecasting errors. Integrating AutoEnergy with the state-of-the-art Tabular Prior Data Fitted Network (TabPFN) resulted in significant forecasting error reductions across test sets. These findings highlight AutoEnergy’s potential to improve AutoML performance while reducing reliance on domain expertise for FE, paving the way for fully automated ML pipelines in ECF applications.},
  archive      = {J_KBS},
  author       = {Nasser Alkhulaifi and Alexander L. Bowler and Direnc Pekaslan and Nicholas J. Watson and Isaac Triguero},
  doi          = {10.1016/j.knosys.2025.114300},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114300},
  shortjournal = {Knowl. Based Syst.},
  title        = {AutoEnergy: An automated feature engineering algorithm for energy consumption forecasting with AutoML},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAKEE: Multi-view attribute network and sequence embedding approach for predictive process monitoring. <em>KBS</em>, <em>329</em>, 114299. (<a href='https://doi.org/10.1016/j.knosys.2025.114299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive business process monitoring can help detect and solve problems on time by monitoring the execution of business processes in real time, thereby improving overall business efficiency and performance. Current deep learning-based studies have found that embedding structural information of process models helps neural networks learn the deep logic behind business processes. However, they mainly focus on the control-flow perspective, while other perspectives behind the business process, such as organizational structure, social network, and resource behavior, have been largely overlooked. To address this issue, this study proposes a multi-view learning prediction approach that integrates complementary information from both multiple attribute networks and sequences. We carefully design a deep learning model framework to integrate multi-view structural and sequential information for the next-activity prediction of the running trace. On the one hand, a simple and efficient process mining algorithm is designed to model multiple attribute network graphs, and a graph convolutional network is integrated to learn their multi-view structural information, helping understand the deep features of business scenarios. For this, a node feature enhancement method is proposed to integrate global information from historical business executions to help the proposed neural network understand the structure of a complete business scenario. On the other hand, we construct the feature representation of attribute sequences and integrate the Transformer to capture the dependency relations and sequential features within attribute sequences. Experimental evaluation of twelve real-life event logs shows that the proposed approach performs well in prediction accuracy and robustness.},
  archive      = {J_KBS},
  author       = {Binbin Chen and Shuangyao Zhao and Leilei Lin and Qiang Zhang},
  doi          = {10.1016/j.knosys.2025.114299},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114299},
  shortjournal = {Knowl. Based Syst.},
  title        = {MAKEE: Multi-view attribute network and sequence embedding approach for predictive process monitoring},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAGE-fend: Multimodal adaptive fusion with guidance from LLM expertise for fake news detection on short video platforms. <em>KBS</em>, <em>329</em>, 114298. (<a href='https://doi.org/10.1016/j.knosys.2025.114298'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of fake news on short-video social media platforms presents significant challenges to public awareness and social stability. While prior research has largely concentrated on text-image fake news, fake news in video format remains underexplored due to limited dataset availability and the complexities of multimodal analytical techniques. To bridge these gaps, we introduce TikCron , a large-scale, open-source dataset of short videos collected from Douyin (TikTok China). TikCron provides news videos and rich social context, specifically curated for studying pandemic-related misinformation in the health and political domains. Furthermore, we propose MAGE-fend (Multimodal Adaptive Fusion Guided by LLM Expertise), a novel framework that utilizes Large Language Models (LLMs) to extract high-level semantic information from images and provide inferential reasoning to enhance fake news detection. MAGE-fend integrates an adaptive attention-based fusion mechanism to dynamically integrate multiple modalities, effectively capturing cross-modal consistency and complementary cues. Comprehensive experiments conducted on the TikCron dataset and the publicly available FakeSV dataset demonstrate that MAGE-fend outperforms state-of-the-art methods in various evaluation metrics. This detection framework makes a substantial contribution to addressing potential future pandemic misinformation crises.},
  archive      = {J_KBS},
  author       = {Lingtong Hu and Zituo Wang and Jiayi Zhu and Yifan Hu and Xianbing Wang},
  doi          = {10.1016/j.knosys.2025.114298},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114298},
  shortjournal = {Knowl. Based Syst.},
  title        = {MAGE-fend: Multimodal adaptive fusion with guidance from LLM expertise for fake news detection on short video platforms},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trustworthy knowledge distillation via anchor-guided distribution learning. <em>KBS</em>, <em>329</em>, 114297. (<a href='https://doi.org/10.1016/j.knosys.2025.114297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing knowledge distillation methods typically do not adequately account for the representativeness of sampled training data or the adverse effects of missing classes within mini-batches, both of which can lead to suboptimal knowledge transfer. In this paper, we introduce A nchor-based K nowledge D istillation (AKD), a method that leverages the most informative and representative samples, referred to as anchors , during the transfer process, and matches the representation distribution of the data in the feature space rather than their actual representations. Anchors are strategically chosen based on their ability to encapsulate critical features of the data distribution, ensuring that the student model focuses on the most informative aspects of the teacher’s knowledge. The proposed method enables the introduction of information from a wider variety of classes at each mini-batch iteration, ensuring a more balanced data distribution and thereby improving the knowledge transfer process. Furthermore, by leveraging the static nature of anchors, we enhance the student model’s representation learning through attention maps, improving both convergence and generalization. The proposed approach is extensively evaluated across various datasets and tasks, demonstrating that the incorporation of anchors into the knowledge distillation process improving the accuracy and trustworthiness of the resulting models.},
  archive      = {J_KBS},
  author       = {Dimitrios Spanos and Nikolaos Passalis and Anastasios Tefas},
  doi          = {10.1016/j.knosys.2025.114297},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114297},
  shortjournal = {Knowl. Based Syst.},
  title        = {Trustworthy knowledge distillation via anchor-guided distribution learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative evaluation of machine learning models for predicting clad bead geometry in gas metal arc welding. <em>KBS</em>, <em>329</em>, 114296. (<a href='https://doi.org/10.1016/j.knosys.2025.114296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas metal arc welding (GMAW) is widely utilized for depositing corrosion-resistant austenitic stainless steel claddings on low-carbon steel substrates, where the bead geometry directly influences the structural integrity and service life of the component. The objective of this study is to develop a predictive framework for accurately estimating clad bead geometry parameters, namely bead width, penetration depth, reinforcement height, and percentage dilution, based on key GMAW process variables. To achieve this, five supervised machine learning (ML) models—linear regression (LR), K-Nearest Neighbors (KNN), decision tree (DT), random forest (RF), and support vector regression (SVR)— were trained on experimentally obtained datasets and evaluated using performance metrics including the R² score, the mean absolute error (MAE), the mean squared error (MSE), and the root mean squared error (RMSE). Among the models, the DT demonstrated the best predictive performance, achieving an R² score of 0.959, an MAE of 0.134, an MSE of 0.150, and an RMSE of 0.388. The SVR model also performed exceptionally well, with an R² score of 0.952. This study identified the welding gun angle and wire feed rate as the most influential parameters affecting clad bead geometry. The use of these advanced ML models considerably improves the prediction accuracy of clad bead dimensions in GMAW, enabling intelligent process optimization and consistent production of high-quality weld cladding.},
  archive      = {J_KBS},
  author       = {Kannan Thankappan and Jayaram Radhakrishnan Santhi and Thanammal Indu Vijayalakshmi},
  doi          = {10.1016/j.knosys.2025.114296},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114296},
  shortjournal = {Knowl. Based Syst.},
  title        = {Comparative evaluation of machine learning models for predicting clad bead geometry in gas metal arc welding},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified attacks to large language model watermarks: Spoofing and scrubbing in unauthorized knowledge distillation. <em>KBS</em>, <em>329</em>, 114295. (<a href='https://doi.org/10.1016/j.knosys.2025.114295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Watermarking has emerged as a critical technique for combating misinformation and protecting intellectual property in large language models (LLMs). A particularly promising property, known as watermark radioactivity, offers potential for preventing the unauthorized use of LLM outputs in downstream distillation pipelines. However, the robustness of watermarking against scrubbing attacks and its unforgeability under spoofing attacks in unauthorized knowledge distillation settings remain underexplored. Existing attack methods either assume access to model internals or fail to support both attack types simultaneously. In our work, we propose Contrastive Decoding-guided Knowledge Distillation ( CDG-KD ), a unified framework that enables dual-path attacks under unauthorized knowledge distillation. At the core of CDG-KD is a novel contrastive decoding mechanism with token-level constraint fusion, which integrates a learned watermark discriminator and probability-based constraint component to selectively manipulate watermark-relevant logits. This allows for fine-grained control of watermark strength during generation without compromising fluency or semantics. Our approach employs contrastive decoding to extract corrupted or amplified watermark texts via comparing outputs, followed by dual-path distillation to train new student models capable of watermark removal and watermark forgery, respectively. Extensive experiments show that CDG-KD effectively performs attacks while preserving the general performance of the distilled model. Our findings underscore critical need for developing watermarking schemes that are robust and unforgeable. Our code is available at https://github.com/xinykou/CDG-KD .},
  archive      = {J_KBS},
  author       = {Xin Yi and Yue Li and Shunfan Zheng and Linlin Wang and Xiaoling Wang and Liang He},
  doi          = {10.1016/j.knosys.2025.114295},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114295},
  shortjournal = {Knowl. Based Syst.},
  title        = {Unified attacks to large language model watermarks: Spoofing and scrubbing in unauthorized knowledge distillation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STP-net: Spatiotemporal graph neural network incorporating global brain functional network partitioning for driver fatigue monitoring. <em>KBS</em>, <em>329</em>, 114294. (<a href='https://doi.org/10.1016/j.knosys.2025.114294'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fatigue driving is a leading cause of traffic accidents, underscoring the critical need for effective driver fatigue monitoring to enhance road safety. Electroencephalogram (EEG) signals are widely considered as the gold standard for detecting fatigue. However, many existing methods struggle to comprehensively capture and integrate EEG features across multiple dimensions and scales, resulting in suboptimal monitoring performance. To address this challenge, we propose a spatiotemporal graph neural network with global brain functional network partitioning (STP-Net). STP-Net facilitates the comprehensive extraction and deep fusion of both short-term and long-term temporal features, along with global and local spatial features from EEG signals, producing rich hybrid representations that effectively capture the intrinsic dynamics of EEG activity. Evaluated on the public SEED-VLA dataset, STP-Net achieves superior performance, with an accuracy of 94.09 %, recall of 94.00 %, precision of 89.55 %, and an F1 score of 0.917, outperforming existing mainstream models. Ablation studies demonstrate that the spatiotemporal interaction module, which integrates graph convolutional networks and a transformer, plays a pivotal role in enhancing network performance. Additionally, interpretability analysis of the partitioned brain regions reveals that the perceptual–motor network shows the strongest correlation with fatigue. These results highlight STP-Net’s potential for accurate driver fatigue monitoring and its broader implications for enhancing driving safety.},
  archive      = {J_KBS},
  author       = {Jinglong Zhu and Qiang Liu and Hui Liu and Zeping Chen and Zhangzhen Zhao and Junchen Liao and Qing Li},
  doi          = {10.1016/j.knosys.2025.114294},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114294},
  shortjournal = {Knowl. Based Syst.},
  title        = {STP-net: Spatiotemporal graph neural network incorporating global brain functional network partitioning for driver fatigue monitoring},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated deep learning-based IRACE and convolutional neural networks for chest X-ray image classification. <em>KBS</em>, <em>329</em>, 114293. (<a href='https://doi.org/10.1016/j.knosys.2025.114293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When pre-trained models are applied directly to chest X-ray (CXR) images without appropriate adaptation, they frequently show problems like overfitting, limited generalization, or decreased SE to clinically relevant features because of the unique characteristics of medical data, such as class imbalance and domain-specific noise. Due to the discrepancy between natural image features (used during pre-training) and radiological image characteristics, studies have shown that such models may perform well on training data but poorly on unseen clinical samples. This study comprehensively evaluates the performance of the fine-tuning method using the Iterated Race for Automatic Algorithm Configuration (IRACE) technique on pre-trained models for several medical imaging CXRs. We select five well-known CNN architectures: MobileNet-v2, EfficientNet-b0, ResNet-50, DenseNet-121, and VGG-19, utilizing the IRACE technique for HPT classification of three CXR datasets. The experimental results indicate that the IRACE technique was generally effective across CXR images, producing noticeable improvements on all models. DenseNet-121 outperformed the other architectures across all metrics, achieving accuracies of 99.83 %, 99.98 %, and 99.87 % on the three CXR datasets, respectively. Additionally, we explored the model detection mechanism by interpreting the classification of radiological images using the Gradient-weighted Class Activation Mapping (Grad-CAM) with Layer-wise Relevance Propagation (LRP) approach for CXR imaging. The results obtained have provided information on how the model classifies CXR images, which can assist radiologists in identifying and evaluating visual characteristics.},
  archive      = {J_KBS},
  author       = {Nagwan Abdel Samee and Essam H. Houssein and Eman Saber and Gang Hu and Mingjing Wang},
  doi          = {10.1016/j.knosys.2025.114293},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114293},
  shortjournal = {Knowl. Based Syst.},
  title        = {Integrated deep learning-based IRACE and convolutional neural networks for chest X-ray image classification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdaVAM: Adaptive variance-aware momentum for accelerating deep neural network training. <em>KBS</em>, <em>329</em>, 114292. (<a href='https://doi.org/10.1016/j.knosys.2025.114292'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive optimization methods are fundamental to training deep neural networks, yet their effectiveness is often limited by noisy gradient estimates and unstable learning dynamics. To overcome these challenges, we introduce AdaVAM (Adaptive Variance-Aware Momentum), a novel optimizer that decouples gradient momentum from variance-based normalization. Unlike conventional approaches (e.g., Adam, Adan), AdaVAM employs a delayed variance term computed from historical gradients to dynamically normalize stochastic gradients. This design simultaneously reduces momentum bias and preserves robustness against gradient noise. Theoretically, we prove that AdaVAM attains an optimal O ( 1 / K ) convergence rate for non-convex objectives without requiring bounded gradient assumptions. Comprehensive experiments on image classification and language modeling benchmarks demonstrate that AdaVAM surpasses existing methods in both convergence speed and final task accuracy. By bridging theoretical guarantees with empirical efficacy, our work advances the development of reliable optimizers for deep learning. The PyTorch implementation is available at: https://github.com/xudp100/AdaVAM.git .},
  archive      = {J_KBS},
  author       = {Jinlan Liu and Wenhan Jiang and Xin Deng and Dongpo Xu},
  doi          = {10.1016/j.knosys.2025.114292},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114292},
  shortjournal = {Knowl. Based Syst.},
  title        = {AdaVAM: Adaptive variance-aware momentum for accelerating deep neural network training},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-typed multi-relational heterogeneous graph neural network model for complex networks. <em>KBS</em>, <em>329</em>, 114291. (<a href='https://doi.org/10.1016/j.knosys.2025.114291'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networks are a prevalent relationship in real-world society, and the use of graphs and graph neural networks (GNNs) to model these networks and capture their characteristic relationships has shown tremendous development potential. Due to the inherent complexity of node and edge relationships within networks, heterogeneous graph neural networks (HGNNs) have become the preferred modeling approach. However, existing HGNNs primarily focus on heterogeneous graphs with only single relationships between nodes, which limits their ability to handle complex network graphs with multiple relational interactions. To effectively capture the complex node objects and multi-relational interactions in networks, this paper proposes a neural network model for multi-class multi-relational heterogeneous graphs (MMHGNN), consisting of three modules: structural feature encoding, weighted multi-relation path aggregation, and feature fusion. In the structural feature encoding module, MMHGNN employs the Four Color Theorem to color the graph and generates type encodings of edge relationships along paths, merging color features with path encodings to serve as structural features for different paths, thereby enhancing the distinguishability of nodes under complex relationships and structures. In the weighted multi-relation path aggregation module, MMHGNN aggregates neighbors along paths based on the number of edge relationships between nodes as weights and implements a balancing strategy to prevent excessive weights on long paths. In the feature fusion module, MMHGNN combines the structural features from the structural feature encoding with the embeddings from the relation aggregation module, leveraging a graph-level attention mechanism to fuse node features across different paths and generate the final node embeddings. Experiments conducted on real-world complex network datasets demonstrate the significant advantages of MMHGNN across multiple tasks.},
  archive      = {J_KBS},
  author       = {Yufei Zhao and Junyue Dong and Wenhao Wang and Hua Duan},
  doi          = {10.1016/j.knosys.2025.114291},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114291},
  shortjournal = {Knowl. Based Syst.},
  title        = {A multi-typed multi-relational heterogeneous graph neural network model for complex networks},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SSGNN: Simple siamese graph neural networks for out-of-distribution generalization. <em>KBS</em>, <em>329</em>, 114290. (<a href='https://doi.org/10.1016/j.knosys.2025.114290'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have proven effective for analyzing relational data in a variety of domains. Nevertheless, their performance tends to deteriorate significantly under distribution shifts between training and test datasets, presenting a central challenge for real-world machine learning applications. This work proposes the Simple Siamese Graph Neural Network (SSGNN), a Self-supervised Learning (SSL) method aimed at improving Out-of-Distribution (OOD) generalization in node classification tasks. In contrast to many existing SSL approaches that depend on data augmentation and the creation of positive and negative sample pairs, SSGNN adopts a simplified framework based on a Siamese GNN architecture with integrated dropout, thus avoiding the need for explicit pair generation. The method addresses common shortcomings in graph representation learning—particularly the tendency to capture spurious correlations—by introducing a three-stage training procedure utilizing dual Graph Convolutional Network (GCN) encoders with shared parameters. Furthermore, SSGNN incorporates a composite loss function whose components optimize node representation similarity, label prediction consistency, and overall prediction accuracy. Through this approach, SSGNN learns stable graph representations that demonstrate improved generalization across varying data distributions. Experimental results show that SSGNN outperforms existing methods and enhances generalization by reducing the GAP metric, which quantifies the relative performance difference between IID and OOD settings.},
  archive      = {J_KBS},
  author       = {Seyedeh Hamideh Erfani and Mohammad Javad Fadaeieslam and Reza Mortazavi and Mohammad Rahmanimanesh},
  doi          = {10.1016/j.knosys.2025.114290},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114290},
  shortjournal = {Knowl. Based Syst.},
  title        = {SSGNN: Simple siamese graph neural networks for out-of-distribution generalization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging out-of-distribution unlabeled images: Semi-supervised semantic segmentation with an open-vocabulary model. <em>KBS</em>, <em>329</em>, 114289. (<a href='https://doi.org/10.1016/j.knosys.2025.114289'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semi-supervised semantic segmentation, existing studies have shown promising results in academic settings with controlled splits of benchmark datasets. However, the potential benefits of leveraging significantly larger sets of unlabeled images remain unexplored. In real-world scenarios, abundant unlabeled images are often available from online sources (web-scraped images) or large-scale datasets. However, these images may have different distributions from those of the target dataset, a situation known as out-of-distribution (OOD). Using these images as unlabeled data in semi-supervised learning can lead to inaccurate pseudo-labels, potentially misguiding network training. In this paper, we propose a new semi-supervised semantic segmentation framework with an open-vocabulary segmentation model (SemiOVS) to effectively utilize unlabeled OOD images. Extensive experiments on Pascal VOC and Context datasets demonstrate two key findings: (1) using additional unlabeled images improves the performance of semi-supervised learners in scenarios with few labels, and (2) using the open-vocabulary segmentation (OVS) model to pseudo-label OOD images leads to substantial performance gains. In particular, SemiOVS outperforms existing PrevMatch and SemiVL methods by +3.5 and +3.0 mIoU, respectively, on Pascal VOC with a 92-label setting, achieving state-of-the-art performance. These findings demonstrate that our approach effectively utilizes abundant unlabeled OOD images for semantic segmentation tasks. We hope this work can inspire future research and real-world applications. The code is available at https://github.com/wooseok-shin/SemiOVS .},
  archive      = {J_KBS},
  author       = {Wooseok Shin and Jisu Kang and Hyeonki Jeong and Jin Sob Kim and Sung Won Han},
  doi          = {10.1016/j.knosys.2025.114289},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114289},
  shortjournal = {Knowl. Based Syst.},
  title        = {Leveraging out-of-distribution unlabeled images: Semi-supervised semantic segmentation with an open-vocabulary model},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refining graph representation: Hyperbolic cross-space diffusion for hierarchical structure preservation. <em>KBS</em>, <em>329</em>, 114288. (<a href='https://doi.org/10.1016/j.knosys.2025.114288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has gained significant traction as an effective approach for learning representations across diverse domains. However, current methods confined to Euclidean space face a fundamental limitation: they struggle to preserve the complex topological structures inherent in hierarchical graph data. Existing graphical representation learning methods face three interrelated challenges. Specifically, embedding hierarchical graph structures into Euclidean space inevitably results in topological distortion. Conventional contrastive methods rely heavily on negative samples. In particular, the limited transformation capabilities restrict the model's ability to capture complex hierarchical relationships. To address these challenges, we propose the Hy perbolic Cro ss-space D iffusion ( HyCroD ), which seamlessly integrates hyperbolic geometric diffusion within a multi-scale contrastive learning architecture. It enhances information preservation through a dual-space augmentation strategy, where transformations are performed independently in both Euclidean and Hyperbolic spaces. By incorporating cross-grid and cross-view contrastive objectives alongside carefully designed spatial transformation modules, HyCroD effectively captures and preserves the rich hierarchical information present in graph data. Experiments across five benchmark datasets demonstrate improvements over state-of-the-art methods on node classification tasks. Our findings show that combining dual-space representation learning with self-supervised objectives effectively preserves hierarchical information in graph data, offering a promising direction for learning representations of complex multi-level structures.},
  archive      = {J_KBS},
  author       = {Zhirui Chen and Qiancheng Yu and Xiao Chen and Xuchu Jiang},
  doi          = {10.1016/j.knosys.2025.114288},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114288},
  shortjournal = {Knowl. Based Syst.},
  title        = {Refining graph representation: Hyperbolic cross-space diffusion for hierarchical structure preservation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized multimodal sentiment analysis under uncertain modalities missing via pretraining and online learning. <em>KBS</em>, <em>329</em>, 114287. (<a href='https://doi.org/10.1016/j.knosys.2025.114287'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, multimodal sentiment analysis (MSA) for personalized users under uncertain modalities missing has become a new challenging problem. To address this issue, we propose a two-step idea. First, we propose an effective MSA model under uncertain modalities missing and train it with some public datasets, thus to enable the model to possess better preliminary MSA ability. Then, we make the pretrained model to continuously learn user’s personalized characteristics with online learning methods, thereby enable the model grow into a robust model for personalized MSA. Based on this idea, we propose a Personalized MSA model under uncertain modalities missing via Pretraining and Online Learning (termed as PMSAPO). For Personalized MSA under uncertain modalities missing, PMSAPO firstly generates the fused modality and allocate weights for each modality with a Fully Connected Neural Network Evaluation Module. Then, PMSAPO completes the final sentiment classification based on the fusion modality with a Joint feature optimization module. For the pretrained PMSAPO, we make it autonomously learn the personalized users via our proposed online learning techniques, including an online meta-learning method, a learning rate adaptive adjustment strategy, and a dynamic weight assignment strategy for sample data. Finally, based on three public benchmark datasets (IEMOCAP, MELD and CMU-MOSI), we conduct extensive experiments and prove that PMSAPO completely outperforms the Twelve state-of-the-art baseline models. (Code is available at https://github.com/SHX-AI/PMSAPO .)},
  archive      = {J_KBS},
  author       = {Hongxiang Sun and Zhizhong Liu and Dianhui Chu and Quan Z. Sheng and Zhaowei Liu and Jian Yu},
  doi          = {10.1016/j.knosys.2025.114287},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114287},
  shortjournal = {Knowl. Based Syst.},
  title        = {Personalized multimodal sentiment analysis under uncertain modalities missing via pretraining and online learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AGA: An adaptive group alignment framework for structured medical cross-modal representation learning. <em>KBS</em>, <em>329</em>, 114286. (<a href='https://doi.org/10.1016/j.knosys.2025.114286'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning medical visual representations directly from paired medical images and reports has emerged as a promising direction in representation learning. However, existing vision-language pretraining (VLP) methods in the medical domain often oversimplify clinical reports into single entities or fragmented tokens, overlooking their inherent structured nature. Moreover, contrastive learning paradigms typically rely on large quantities of hard negative samples, which poses challenges when dealing with small scale medical datasets. To address these issues, we propose Adaptive Grouped Alignment (AGA), a novel framework for learning structured information from paired medical images and reports. Specifically, we design a bidirectional grouping mechanism based on a sparse similarity matrix. Given an image-report pair, we first compute a fine-grained similarity matrix between each text token and each image patch. For each token, we select the top-matching patches to form a visual group, and conversely, for each patch, we select the most semantically related tokens to form a language group. To enable adaptive grouping, we introduce two threshold gating modules, Language-grouped Threshold Gate and Vision-grouped Threshold Gate, which dynamically learn similarity thresholds for group construction. The group representation corresponding to each token or patch is computed as a weighted average over the elements in its group, where the weights are given by their similarity scores. To align each token representation with its corresponding group representations, we propose an Instance-aware Group Alignment (IGA) loss, which operates solely within individual image-text pairs, eliminating the need for external negative samples and thereby alleviating the reliance on large scale hard negatives. Finally, we employ a Bidirectional Cross-modal Grouped Alignment (BCGA) module to facilitate fine-grained alignment between visual and linguistic group representations. Extensive experiments on both public and private datasets across various downstream tasks, including image-text retrieval and classification (in both fine-tuning and zero-shot settings), demonstrate the effectiveness of our proposed framework.},
  archive      = {J_KBS},
  author       = {Wei Li and Xun Gong and Jiao Li and Xiaobin Sun},
  doi          = {10.1016/j.knosys.2025.114286},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114286},
  shortjournal = {Knowl. Based Syst.},
  title        = {AGA: An adaptive group alignment framework for structured medical cross-modal representation learning},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CT-SSSA: Malicious traffic augmentation based on classifier transGAN and spatial-channel synergistic self-attention. <em>KBS</em>, <em>329</em>, 114285. (<a href='https://doi.org/10.1016/j.knosys.2025.114285'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing number of network attacks poses serious challenges to device security and data privacy. As an important mean, malicious traffic detection method converts the raw traffic into intermediate representations (such as CSV format or gray-scale images) for feature analysis and protects network devices by identifying malicious traffic. These representations have following limitations: CSV format is difficult to capture the spatiotemporal correlations of traffic sequences, the single channel characteristics of gray-scale images result in the loss of multidimensional features. In addition, existing methods are prone to pattern collapse in imbalanced category scenarios. To solve these problems, this paper proposes a malicious traffic augmentation model called CT-SSSA based on the c lassifier T ransGAN and s patial-channel s ynergistic s elf- a ttention (SCSSA). Its innovations are reflected in: 1) We propose a key feature extraction method based on mutual information, it converts original traffic into RGB images and preserves multidimensional semantic features through three channel superposition; 2) We introduce the SCSSA mechanism into TransGAN to jointly capture the global context dependencies and local fine-grained features, thereby reducing the complexity of generator; 3) We design the auxiliary classifier and dynamic adaptive loss function to constrain the class consistency of generated samples, and alleviate the pattern collapse problem caused by class imbalance. Experiments on three publicly available datasets show that CT-SSSA achieves a 40.5 % and 88.35 % reduction in FID value and FPR compared to advanced baselines, and the accuracy, TPR and F1-score are improved by 1.01 %, 2.4 % and 13.85 %, respectively.},
  archive      = {J_KBS},
  author       = {Saihua Cai and Xingyu Zhao and Jinfu Chen and Yige Zhao and Junyi Chen and Lizhou Chen},
  doi          = {10.1016/j.knosys.2025.114285},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114285},
  shortjournal = {Knowl. Based Syst.},
  title        = {CT-SSSA: Malicious traffic augmentation based on classifier transGAN and spatial-channel synergistic self-attention},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust stock trend prediction via volatility detection and hierarchical multi-relational hypergraph attention. <em>KBS</em>, <em>329</em>, 114283. (<a href='https://doi.org/10.1016/j.knosys.2025.114283'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock trend prediction is challenging due to the nonlinear dynamics of financial markets. Existing approaches often neglect extreme price fluctuations (outliers) and complex inter-stock relationships, limiting predictive performance. In this paper, we propose a novel framework integrating an abnormal volatility point detection mechanism with a multi-relational hypergraph hierarchical attention network. Specifically, we first employ a convolutional LSTM enhanced with an overnight gap price criterion to detect and down-weight abnormal price fluctuations, effectively reducing errors in stock temporal feature extraction. Second, we use temporal attention to emphasize influential historical time steps. Third, to model complex inter-stock dependencies, we construct a multi-relational hypergraph capturing both industry and supply-chain relations. Finally, we develop a hierarchical attention mechanism to adaptively weight stocks within relation groups (intra-hyperedge attention) and assess the relative importance of different relation types (inter-hypergraph attention). Extensive experiments on seven years of NYSE and NasdaqGS data show that our approach significantly outperforms state-of-the-art baselines in prediction accuracy and risk-return performance, demonstrating the effectiveness of capturing abnormal volatility and higher-order stock interactions.},
  archive      = {J_KBS},
  author       = {Suochao Yi and Jing Chi and Yandi Shi and Caiming Zhang},
  doi          = {10.1016/j.knosys.2025.114283},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114283},
  shortjournal = {Knowl. Based Syst.},
  title        = {Robust stock trend prediction via volatility detection and hierarchical multi-relational hypergraph attention},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced temporal graph neural network for predicting future citations on academic graphs: A dual clustering-driven and centrality-guided approach. <em>KBS</em>, <em>329</em>, 114282. (<a href='https://doi.org/10.1016/j.knosys.2025.114282'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the volume of scientific publications grows, predicting the future citation counts of research papers is crucial for identifying influential studies and promising research directions. Existing graph neural network methods often rely solely on neighbor aggregation, which neglects the global heterogeneous nature of academic networks, thereby limiting their ability to fully capture the intricate relationships between different types of nodes and edges. This paper proposes a novel model, named C entrality-guided and D ual C lustering driven H eterogeneous G raph N etwork (CDCHGN) that addresses these limitations. CDCHGN captures both global and local structural dynamics of a dynamic academic graph using node centrality information, dual clustering techniques, and edge-type encoding to enrich semantic representation and effectively model heterogeneous relationships among various node types. Additionally, it incorporates time-injected attention to capture the temporal evolution of node features. Extensive experiments on real-world datasets demonstrate that our model achieves superior performance. Notably, on the APS dataset, CDCHGN achieves a 5.88 % improvement in Mean Absolute Log Error (MALE) and a 6.87 % improvement in Root Mean Squared Log Error (RMSLE) compared to the second-best models.},
  archive      = {J_KBS},
  author       = {Tianming Zhang and Junkai Fang and Xuanyu Chen and Zhengyi Yang and Bin Cao},
  doi          = {10.1016/j.knosys.2025.114282},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114282},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhanced temporal graph neural network for predicting future citations on academic graphs: A dual clustering-driven and centrality-guided approach},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Task assignment strategies for capacitated agents engaged in lifelong pickup and delivery tasks. <em>KBS</em>, <em>329</em>, 114281. (<a href='https://doi.org/10.1016/j.knosys.2025.114281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we tackled the task assignment problem in the capacity-enhanced version of Multi-Agent Pickup and Delivery (MAPD), a lifelong variant of the classical Multi-Agent Path Finding (MAPF) problem. Capacity-enhanced agents can carry multiple items, allowing them to operate several tasks simultaneously by visiting a sequence of pickup and delivery locations (i.e. waypoints) to fulfill their assignments. When determining the next task of the agent from the available options, a method encountered in the literature is to select the task with the nearest pickup location to the agent’s current location. In this research, we suggest that improving task assignments of capacitated agents can significantly enhance the solution quality of multi-agent route plans in lifelong pickup and delivery scenarios. We propose novel task assignment strategies that incorporate waypoints as a factor in the task selection process. We devised three groups of task assignment methods based on Closeness Centrality, Hausdorff Distance, and Cost Estimation within the context of the complete Token Passing with Multiple Capacity (TPMC) algorithm. We evaluated the methods in small and large-scale automated warehouse simulations, assessing their effectiveness in terms of makespan against the contemporary task selection method and one another. As a result of our experiments, the Closeness Centrality class of heuristics failed to enhance solution quality in large majority of cases. The Average Hausdorff Distance heuristic achieved good outcomes in scenarios with higher capacity agents. The Cost-Based Estimation method demonstrated significant improvements across all scenarios.},
  archive      = {J_KBS},
  author       = {Evren Çilden and Faruk Polat},
  doi          = {10.1016/j.knosys.2025.114281},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114281},
  shortjournal = {Knowl. Based Syst.},
  title        = {Task assignment strategies for capacitated agents engaged in lifelong pickup and delivery tasks},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). You only need haze: Bidirectional disentangled translation network for unsupervised image dehazing. <em>KBS</em>, <em>329</em>, 114279. (<a href='https://doi.org/10.1016/j.knosys.2025.114279'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, learning-based methods have achieved notable progress in image dehazing through supervised training on synthetically paired datasets. However, the substantial domain gap between synthetic and real-world hazy images often impairs generalization performance, thereby limiting their effectiveness in practical applications where target domains differ significantly from the training data. Even worse, acquiring sufficient pixel-aligned hazy-clear image pairs in real-world scenarios is costly and challenging. To this end, we introduce a novel Bidirectional Disentangled Translation Network (BDT-Net) for unsupervised dehazing, which regards haze removal as a feature disentanglement task, i.e., separating content-relevant information from the clean factor and haze-related information from the fuzzy factor. Specifically, we design a dual-branch disentanglement framework comprising a Content Recovery Branch (CRB) for extracting structural content information and a Parameter Estimation Branch (PEB) dedicated to capturing haze-related characteristics. Among them, we leverage forward dehazing and reverse rehazing physics-based models to establish haze cycle consistency, thus our BDT-Net can be optimized only needing the hazy image itself. To better distinguish the haze information from the clean content in the latent space, we design an effective Feature-wise Contrastive Representation (FCR), which can not only consider the inherent self-similarity within each information flow but also exploit the mutual exclusivity between different components. Furthermore, a two-way Pixel-wise Contrastive Representation (PCR) is incorporated to enhance the capability of restoring clear image clarity and content. Extensive experimental results on benchmark datasets demonstrate the superiority of our BDT-Net over other compared state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Weichao Yi and Liquan Dong and Ming Liu and Lingqin Kong and Yue Yang and Xuhong Chu and Yuejin Zhao},
  doi          = {10.1016/j.knosys.2025.114279},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114279},
  shortjournal = {Knowl. Based Syst.},
  title        = {You only need haze: Bidirectional disentangled translation network for unsupervised image dehazing},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAFNet: Circular attention fusion for medical image segmentation. <em>KBS</em>, <em>329</em>, 114277. (<a href='https://doi.org/10.1016/j.knosys.2025.114277'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of medical images is crucial for clinical diagnosis and treatment planning. Recently, Transformers have demonstrated promising performance in medical image segmentation tasks, yet the quadratic complexity of the attention mechanism presents difficulties. Various methods attempt to reduce this complexity by constraining the range of attention to local regions, thereby improving efficiency. However, these methods often result in receptive fields that are not large enough, leading to insufficient context modeling. To address this issue, we propose an attention mechanism called Circular Attention (CA), which confines the attention region within a circular window through polar coordinate transformation, and apply it to the Circular Attention Fusion (CAF) module for feature fusion. CAF integrates feature information from both CNNs and Transformers to improve the accuracy of medical image segmentation. The CAF module consists of a circular attention block, a multi-scale convolution module, and a residual block with deep convolution. Furthermore, adjusting the radius and edge width of the circular attention in various CAFs allows CAFNet to perform multi-scale feature fusion by covering different regions during the fusion process. The proposed method achieves state-of-the-art segmentation performance on multiple datasets. The code is available at: https://github.com/EchoSixHIYA/CAFNet},
  archive      = {J_KBS},
  author       = {Xudong Wu and Baohua Yuan and Ning Li and Lin Shi and Mingjie Jiang and Juxiao Zhang and Rui Tang and Qile Qin and Jin Ma and Shoukun Xu},
  doi          = {10.1016/j.knosys.2025.114277},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114277},
  shortjournal = {Knowl. Based Syst.},
  title        = {CAFNet: Circular attention fusion for medical image segmentation},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KDDA-balance: Knowledge-driven domain adaptation with correlated gait information for elderly balance assessment. <em>KBS</em>, <em>329</em>, 114276. (<a href='https://doi.org/10.1016/j.knosys.2025.114276'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decline in balance function is a major contributor to falls among older adults. Assessing balance function can facilitate early detection of potential issues, and reduce the risk of falls and related injuries. However, a significant challenge is the lack of sufficient data on older adults, which leads to poor model evaluation performance and limits its application in daily life. To address this issue, we propose KDDA, a knowledge-driven semi-supervised domain adaptation method that leverages relevant gait information to improve balance assessment across age domains.The KDDA-Balance model incorporates multidimensional features through a gait knowledge computation module to enrich the feature space. A domain adversarial module with dual classifiers is used to reduce feature discrepancies between the target and source domains. Additionally, an alternative loss function integrates the dual classifier module with a multi-source domain adaptation module, further improving evaluation performance in the target domain. Extensive experiments on the Falling Risk Assessment (FRA) dataset and the Impaired Gait Ground Reaction Force (GaitRec) dataset demonstrate the superiority of our proposed model. On the FRA dataset, KDDA-Balance achieved an evaluation accuracy of 90.07 %, representing an average improvement of 7.83 %. On the GaitRec dataset, the model reached an evaluation accuracy of 83.02 %, with an average accuracy gain of 5.46 %. These results validate the effectiveness of KDDA-Balance in cross-domain evaluation, providing a novel approach for assessing fall risk among older adults.},
  archive      = {J_KBS},
  author       = {Zhaoyang Ge and Shujie Huang and Huiqing Cheng and Jingzhe Ma and Zhuang Tong and Liying Zhang and Mingliang Xu},
  doi          = {10.1016/j.knosys.2025.114276},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114276},
  shortjournal = {Knowl. Based Syst.},
  title        = {KDDA-balance: Knowledge-driven domain adaptation with correlated gait information for elderly balance assessment},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MMGCL: Multi-scale and multi-channel graph contrastive learning for flight anomaly detection. <em>KBS</em>, <em>329</em>, 114275. (<a href='https://doi.org/10.1016/j.knosys.2025.114275'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With commercial air traffic’s increasing complexity, intelligent flight anomaly detection becomes crucial in ensuring flight safety. Existing solutions usually aggregate multiple sensor records of one flight to a flat and indivisible atomic sample to be classified. It is hard for them to incorporate outer information from similar flights and identify inner mechanisms between sensors. However, the degree of deviation from similar normal flights can evaluate the flight risks, and the modeling of sensors can reveal where the risk comes from. To this end, we propose MMGCL, a flight anomaly detection model based on m ulti-scale and m ulti-channel g raph c ontrastive l earning. MMGCL first constructs two types of graphs regarding flight similarity and sensor correlations to model the relations between flights and sensors, respectively. Then, multi-channel contrastive learning is proposed to differentiate normal and abnormal flights from different sensor aspects, where each type of sensor is related to one channel and has one normal center. The learnable representations of sensors are further applied to train a classifier judging the risk score. Finally, the risk score and the distances of sensors from their normal centers are combined to determine whether the flight is abnormal. Extensive experiments validate that our model outperforms the compared ones and has good interpretability of identified anomalies. Our code is publicly available at: anonymous.4open.science/r/MMGCL-6768 .},
  archive      = {J_KBS},
  author       = {Nengjun Zhu and Yuqiang Ren and Yu Liu and Hang Yu and Xinzhi Wang and Xiangfeng Luo},
  doi          = {10.1016/j.knosys.2025.114275},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114275},
  shortjournal = {Knowl. Based Syst.},
  title        = {MMGCL: Multi-scale and multi-channel graph contrastive learning for flight anomaly detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust unsupervised method for outlier set detection. <em>KBS</em>, <em>329</em>, 114274. (<a href='https://doi.org/10.1016/j.knosys.2025.114274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a robust method that identifies sets of points that collectively deviate from typical patterns in a dataset, which it calls “outlier sets”, while excluding individual points from detection. This new methodology, Outlier Set Two-step Identification (OSTI) employs a two-step approach to detect and label these outlier sets. First, it uses Gaussian Mixture Models for probabilistic clustering, identifying candidate outlier sets based on cluster weights below a hyperparameter threshold. Second, OSTI measures the Inter-cluster Mahalanobis distance between each candidate outlier set’s centroid and the overall dataset mean. OSTI then tests the null hypothesis that this distance does not significantly differ from its theoretical chi-square distribution, enabling the formal detection of outlier sets. We test OSTI systematically on 8000 synthetic 2D datasets across various inlier configurations and thousands of possible outlier set characteristics. Results show OSTI robustly and consistently detects outlier sets with an average F1 score of 0.92 and an average purity (the degree to which outlier sets identified correspond to those generated synthetically, i.e., our ground truth) of 98.58 %. We also compare OSTI with state-of-the-art outlier detection methods, to illuminate how OSTI fills a gap as a tool for the exclusive detection of outlier sets.},
  archive      = {J_KBS},
  author       = {Amal Sarfraz and Abigail Birnbaum and Flannery Dolan and Jonathan Lamontagne and Lyudmila Mihaylova and Charles Rougé},
  doi          = {10.1016/j.knosys.2025.114274},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114274},
  shortjournal = {Knowl. Based Syst.},
  title        = {A robust unsupervised method for outlier set detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel loan eligibility prediction model with effective use of data transformation methods. <em>KBS</em>, <em>329</em>, 114272. (<a href='https://doi.org/10.1016/j.knosys.2025.114272'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A loan eligibility prediction model (LEP) determines the eligibility of an applicant for a loan based on the applicant’s data. A novel loan eligibility prediction model has been presented in this research work. To improve the prediction performance, we experimented with several data transformation (DT) methods on the data before feeding it to machine learning models. At the end, we chose the adaptive Weight-of-Evidence (aWOE) DT method, which preserves data privacy. Before applying DT, we preprocessed the data (e.g., cleaning, missing value replacement, categorical encoding) to ensure data quality. To mitigate feature redundancy, Pearson correlation was applied. In order to select the most relevant features from the datasets, the Chi-square feature selection technique was employed. Additionally, the Grid Search method was used to identify the optimal hyperparameters for the classifiers. The experiments have been carried out on seven publicly available datasets. Subsequently, the proposed models were evaluated based on standard evaluation metrics. We also conducted a non-parametric statistical test to examine the statistical significance of our results. Our experimental analysis and statistical tests reveal that the proposed aWOE based approach outperforms its counterparts. The privacy assessment demonstrates that the aWOE based model preserves data privacy. To explain our model, we conducted a SHAP analysis, which demonstrated that aWOE prioritizes features which are more aligned with loan eligibility in practice. Our proposed methodology enhanced the prediction performance by as much as 6.3 % and 3.8 % in terms of accuracy and F-measure, respectively. Moreover, the proposed methodology achieved 100 % prediction performance on two datasets across all evaluation metrics. Through comprehensive experimental analysis, the merits of data transformation methods in conjunction with feature selection and optimal hyperparameters have been illustrated for loan eligibility prediction in the context of the lending industry.},
  archive      = {J_KBS},
  author       = {Joydeb Kumar Sana and M. Sohel Rahman and M. Saifur Rahman},
  doi          = {10.1016/j.knosys.2025.114272},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114272},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel loan eligibility prediction model with effective use of data transformation methods},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel framework for effective phishing URL detection using an LSTM-based siamese network. <em>KBS</em>, <em>329</em>, 114271. (<a href='https://doi.org/10.1016/j.knosys.2025.114271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting phishing attacks in the era of generative AI presents a significant challenge due to the increasing sophistication of AI-generated phishing schemes. Neural network-driven approaches, including deep learning-based detection techniques, face notable limitations such as vulnerability to adversarial perturbations, reliance on large labeled datasets, poor generalization to novel attack patterns, and an over-dependence on shallow lexical features that fail to capture deeper semantic patterns. To address these limitations, we propose a pioneering approach leveraging a Siamese network that integrates twin LSTM subnetworks with shared weights, transforming URL sequences into robust feature representations. The Siamese Network effectively distinguishes between phishing and legitimate URLs by comparing the latent representations of URL pairs. Central to this approach is a specially curated pairwise dataset of phishing and legitimate URLs meticulously designed to facilitate fine-grained similarity analysis. This paired dataset enables the model to capture subtle distinctions between the two URL classes. Rigorous evaluation, including a dedicated test set of traditional and AI-generated URLs, demonstrates the model’s robust generalization capability. This innovative twin LSTM-based framework sets a new benchmark in phishing detection, providing a scalable, adaptive solution to combat increasingly sophisticated attacks.},
  archive      = {J_KBS},
  author       = {Sruthi K and Manohar Naik S},
  doi          = {10.1016/j.knosys.2025.114271},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114271},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel framework for effective phishing URL detection using an LSTM-based siamese network},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Style mamba-transformer: A hybrid mamba-transformer unsupervised framework for text style transfer. <em>KBS</em>, <em>329</em>, 114270. (<a href='https://doi.org/10.1016/j.knosys.2025.114270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-style transfer aims to rewrite source texts into a target style while preserving their core content. However, challenges such as the lack of parallel training data and the difficulty in balancing style transfer with content preservation remain significant. To address these issues, we propose a novel unsupervised text-style transfer framework, the Style Mamba Transformer, based on the adversarial generative network (GAN) architecture. This framework includes a hybrid encoder that combines Transformer and Mamba blocks, leverages skip connections to enhance feature reuse, and focuses on the style intensity of individual tokens. This design enables high-precision style transfer while preserving the text content. Our model outperforms other similar style-transfer models, such as MSSRNet, in terms of both style transfer accuracy and content preservation. On two benchmark datasets, the Yelp Review Dataset and IMDb Movie Review Dataset, our model achieved a transfer accuracy of 97.5 % and a BLEU score of 59.3, as well as a transfer accuracy of 95.1 % and a BLEU score of 64.2, respectively.},
  archive      = {J_KBS},
  author       = {Deyu Meng and Ziheng Wang and Wenhao Yan and Tshewang Phuntsho and Tad Gonsalves},
  doi          = {10.1016/j.knosys.2025.114270},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114270},
  shortjournal = {Knowl. Based Syst.},
  title        = {Style mamba-transformer: A hybrid mamba-transformer unsupervised framework for text style transfer},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-based anomaly representation enhancement on graphs. <em>KBS</em>, <em>329</em>, 114268. (<a href='https://doi.org/10.1016/j.knosys.2025.114268'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection is significantly challenged by information loss during graph embedding, label scarcity, and intricate structural patterns. While graph neural networks (GNNs) have advanced the field, their efficacy is often limited by sensitivity to data quality and oversmoothing. This paper introduces DARE-G, a novel diffusion-based anomaly detection framework that leverages conditional and unconditional diffusion models to mitigate these limitations. Our approach features a dual-phase diffusion process: conditional anomaly augmentation to synthesize realistic anomalous patterns, and unconditional graph denoising to alleviate information loss and enhance the distinction between normal and anomalous node representations. Extensive experiments on both synthetic and real-world datasets demonstrate DARE-G’s significant superiority over state-of-the-art methods, achieving an 8.76 percentage point increase in AUC-ROC compared to the best-performing baselines. Ablation studies further validate the framework’s robustness across various GNN backbones, highlighting the critical role of denoising steps in capturing multi-hop structural anomalies. The proposed method establishes new benchmarks for graph anomaly detection, particularly in scenarios with extreme label sparsity and adversarial camouflage.},
  archive      = {J_KBS},
  author       = {Jian Zhang and Yitong Li and Zhen Wang},
  doi          = {10.1016/j.knosys.2025.114268},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114268},
  shortjournal = {Knowl. Based Syst.},
  title        = {Diffusion-based anomaly representation enhancement on graphs},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OTMA: Optimal transfer modality alignment for visible-thermal person re-identification. <em>KBS</em>, <em>329</em>, 114267. (<a href='https://doi.org/10.1016/j.knosys.2025.114267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible thermal person re-identification (VT-ReID) is a crucial task in real-world surveillance systems, primarily challenged by significant cross-modality discrepancies and intra-class variations. While numerous methodologies have been developed to address this issue by optimizing instance similarity across modalities, they often overlook the impact of intra-class variations on cross-modality alignment. To handle this issue, we propose Optimal Transfer Modality Alignment (OTMA), a method designed to mitigate the impact of intra-class variations during cross-modality alignment. Specifically, OTMA utilizes the Earth Mover’s Distance (EMD) to establish an initial transfer strategy between the two modalities. To avoid the unintended alignment of cross-modality negative pairs, OTMA further refines the EMD-based transfer weights by suppressing excessively high weights assigned to negative pairs and enhancing insufficient weights of positive pairs. In this manner, OTMA mitigates the adverse effects of intra-class variations during modality alignment and reduces the risk of aligning cross-modality negative pairs, thereby achieving a better balance between alignment and discriminative optimization. Additionally, two complementary techniques are introduced to further enhance the effectiveness of OTMA. First, Cross-Modality Discrimination Learning (CM-DL) is proposed to alleviate the degradation of feature discrimination caused by OTMA by regulating the variance ratio between intra-class and inter-class distributions. Second, a Multi-Granularity Structure (MGS) is designed to facilitate modality alignment at both coarse and fine levels, enabling OTMA to capture more comprehensive cross-modality correspondences. Extensive experiments conducted on two datasets demonstrate the effectiveness and advantages of the proposed OTMA method, along with its supplementary techniques, in significantly improving cross-modality matching performance.},
  archive      = {J_KBS},
  author       = {Yongguo Ling and Zihao Hu and Gangzhu Lin and Shaozi Li and Min Jiang},
  doi          = {10.1016/j.knosys.2025.114267},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114267},
  shortjournal = {Knowl. Based Syst.},
  title        = {OTMA: Optimal transfer modality alignment for visible-thermal person re-identification},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain pedestrian trajectory prediction via behavioral pattern-aware multi-instance GCN. <em>KBS</em>, <em>329</em>, 114266. (<a href='https://doi.org/10.1016/j.knosys.2025.114266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain pedestrian trajectory prediction is crucial in fields such as autonomous driving, robotics and video surveillance. Due to the inherent diversity and uncertainty of pedestrian trajectories, they exhibit various behavioral patterns. However, most existing cross-domain methods neglect these behavioral differences by employing a unified network with shared parameters, modeling all trajectories in the same manner. This often results in biased knowledge transfer and reduced prediction accuracy. To address this, a model based on behavioral pattern-aware multi-instance graph convolutional networks, called PMITra, is proposed for cross-domain pedestrian trajectory prediction. PMITra consists of three core modules. The trajectory embedding module uses a pretrained micro-model to extract spatiotemporal features from trajectories. The pattern-aware interaction module extracts and aggregates behavioral patterns through deep clustering, and employs a multi-instance graph convolutional network to enable fine-grained knowledge transfer among trajectories exhibiting the same behavioral patterns. The pattern alignment module constructs an attention-based pattern loss to align the pedestrian feature representations weighted by pattern probabilities. PMITra achieves state-of-the-art performance on the ETH/UCY pedestrian trajectory datasets, with comprehensive ablation studies validating the effectiveness of each module.},
  archive      = {J_KBS},
  author       = {Haifeng Yang and Yi Chen and Jianghui Cai and Yuqing Yang and Lichan Zhou and Jianing Tian and Yan Li and Yaling Xun and Xujun Zhao},
  doi          = {10.1016/j.knosys.2025.114266},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114266},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cross-domain pedestrian trajectory prediction via behavioral pattern-aware multi-instance GCN},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFOcc: Enhanced 3D occupancy perception based on scene flow and class-guided sampling. <em>KBS</em>, <em>329</em>, 114265. (<a href='https://doi.org/10.1016/j.knosys.2025.114265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving relies on high-precision 3D perception. Multi-camera 3D object detection is limited by long-tail distribution issues, making it difficult to comprehensively recognize all object categories. In contrast, 3D occupancy prediction unifies the perception of foreground and background by partitioning the 3D space into semantically labeled voxel grids, thereby providing more effective support for driving safety. This paper proposes an innovative panoramic semantic occupancy perception model, DFOcc, designed to enhance the 3D scene understanding capability of autonomous driving systems. DFOcc takes multi-camera images as input and first constructs a 3D voxel feature space through multi-scale feature extraction and the Lift-Splat-Shoot (LSS) method. It then employs an occupancy decoder to predict the occupancy state of each voxel in the scene. To further improve perception accuracy and computational efficiency, ELANet is adopted as the backbone network to enhance 2D visual feature extraction and accelerate model training. Additionally, an improved class-guided sampling strategy combined with the Focal Loss function is proposed to alleviate class imbalance issues, thereby enhancing detection performance for sparse objects and low-frequency categories. Furthermore, an automatic annotation method based on scene flow estimation is introduced, which generates high-quality dense occupancy labels and velocity ground truth labels, eliminating the reliance on 3D bounding box annotations and significantly reducing data construction costs. Experimental results on the nuScenes dataset demonstrate that DFOcc achieves significant improvements in both accuracy and generalization for 3D occupancy perception. Compared to the recently proposed TPVFormer and OccFormer models, DFOcc improves the mean Intersection over Union (mIoU) by 2.1 and 0.9, respectively, and attains performance comparable to state-of-the-art LiDAR-based methods.},
  archive      = {J_KBS},
  author       = {Ruijie Shan and Yanchun Zhang and Jian Zeng},
  doi          = {10.1016/j.knosys.2025.114265},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114265},
  shortjournal = {Knowl. Based Syst.},
  title        = {DFOcc: Enhanced 3D occupancy perception based on scene flow and class-guided sampling},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CogniAlign: Word-level multimodal speech alignment with gated cross-attention for alzheimer’s detection. <em>KBS</em>, <em>329</em>, 114264. (<a href='https://doi.org/10.1016/j.knosys.2025.114264'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection of cognitive disorders such as Alzheimer’s disease is critical for enabling timely clinical intervention and improving patient outcomes. In this work, we introduce CogniAlign, a multimodal architecture for Alzheimer’s detection that integrates audio and textual modalities, two non-intrusive sources of information that offer complementary insights into cognitive health. Unlike prior approaches that fuse modalities at a coarse level, CogniAlign leverages a word-level temporal alignment strategy that synchronizes audio embeddings with corresponding textual tokens based on transcription timestamps. This alignment supports the development of token-level fusion techniques, enabling more precise cross-modal interactions. To fully exploit this alignment, we propose a Gated Cross-Attention Fusion mechanism, where audio features attend over textual representations, guided by the superior unimodal performance of the text modality. In addition, we incorporate prosodic cues, specifically interword pauses, by inserting pause tokens into the text and generating audio embeddings for silent intervals, further enriching both streams. We evaluate CogniAlign on the ADReSSo dataset, where it achieves an accuracy of 87.35 % over a Leave-One-Subject-Out setup and of 90.36 % over a 5 fold Cross-Validation, outperforming existing state-of-the-art methods. A detailed ablation study confirms the advantages of our alignment strategy, attention-based fusion, and prosodic modeling. Finally, we perform a corpus analysis to assess the impact of the proposed prosodic features and apply Integrated Gradients to identify the most influential input segments used by the model in predicting cognitive health outcomes.},
  archive      = {J_KBS},
  author       = {David Ortiz-Perez and Manuel Benavent-Lledo and Javier Rodriguez-Juan and Jose Garcia-Rodriguez and David Tomás},
  doi          = {10.1016/j.knosys.2025.114264},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114264},
  shortjournal = {Knowl. Based Syst.},
  title        = {CogniAlign: Word-level multimodal speech alignment with gated cross-attention for alzheimer’s detection},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BiMT-TCN: A cutting-edge hybrid model for enhanced stock price prediction. <em>KBS</em>, <em>329</em>, 114263. (<a href='https://doi.org/10.1016/j.knosys.2025.114263'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the face of the rapid evolution and escalating complexity of financial markets, precise stock price prediction has become a critical area of research for scholars and practitioners alike. Stock markets are subject to a vast array of influencing factors, both internal and external, which complicates prediction efforts. This study proposes BiMT-TCN, a novel model combining Bidirectional Long Short-Term Memory (BiLSTM), a modified Transformer, and Temporal Convolutional Network (TCN), aimed at enhancing the accuracy and stability in stock price prediction. BiLSTM facilitates the capture of bidirectional dependencies, which aids in decoding the intricate patterns within time-series data. The modified Transformer integrates global information, enhancing the model’s capacity to manage long-range dependencies effectively. TCN, known for its parallel processing and proficiency in capturing deep historical patterns, further bolsters model stability and generalizability. Empirical evaluations on major indices such as SSE, HSI, and NASDAQ demonstrate that BiMT-TCN consistently outperforms state-of-the-art models, achieving R 2 scores of 0.9779, 0.9776, and 0.9969 respectively, along with significantly lower RMSE, MAE, and MAPE values. The implications of this work extend to practical investment decision-making, where improved forecast precision can enhance risk management, optimize trading strategies, and inform financial planning in volatile markets.},
  archive      = {J_KBS},
  author       = {Guangyang Tian and Tingwen Huang and Chengyu Peng and Yin Yang and Shiping Wen},
  doi          = {10.1016/j.knosys.2025.114263},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114263},
  shortjournal = {Knowl. Based Syst.},
  title        = {BiMT-TCN: A cutting-edge hybrid model for enhanced stock price prediction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cardiac disease detection utilizing temporal attention recurrent graph convolutional neural network based smart wearable system. <em>KBS</em>, <em>329</em>, 114261. (<a href='https://doi.org/10.1016/j.knosys.2025.114261'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of people affected by cardiac diseases is increasing extremely. Heart attacks are most common and painful disease. According to the World Health Organization, this disease kills around 17.5 million people each year. In this paper, Cardiac Disease Detection using Temporal Attention Recurrent Graph Convolutional Neural Network based Smart Wearable System (CDD-SWS-TRGCNN) is proposed. The proposed method uses to monitor and signal a patient's current heart status based on necessary heart diagnosis signal. Initially, input data are collected from cardiovascular disease dataset and cardio health risk assessment dataset. The collected dataset are pre-processed with the nonlinear adaptive backscatter filter (NABF) is employed for normalizing the data. After preprocessing, the Lifted Euler Characteristic Transform (LECT) is used to extract statistical features like Mean, Standard Deviation, Kurtosis, Skewness, entropy. These features are then used by TARGCNN for classifying cardiac disease as cardiac and healthy in the cardiovascular disease dataset and presence and absence in the cardio health risk assessment dataset. To enhance accuracy, the Wolf-Bird Optimizer (WBO) is utilized to optimize TARGCNN parameters, ensuring precise cardiac disease classification. The proposed CDD-SWS-TRGCNN method is implemented in Python. The proposed method achieves 23.11%, 24.96%, 25.23% higher accuracy; 31.10%, 33.02% and 29.98% higher precision when compared with existing techniques like SWS-CAM-RFA, PHD-WD-CNN, and WMD-HDD-IoT respectively.},
  archive      = {J_KBS},
  author       = {Mr Jibin E P ( Research Scholar ) and Dr Menaka D ( Associate Professor )},
  doi          = {10.1016/j.knosys.2025.114261},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114261},
  shortjournal = {Knowl. Based Syst.},
  title        = {Cardiac disease detection utilizing temporal attention recurrent graph convolutional neural network based smart wearable system},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DM3diff: A novel multi-center, multi-modality and multi-source medical image segmentation framework based on DWT embeded diffusion model. <em>KBS</em>, <em>329</em>, 114260. (<a href='https://doi.org/10.1016/j.knosys.2025.114260'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of medical images from multi-center, multi-modality, and multi-source datasets (3M Datasets) is critical for clinical applications such as diagnosis and image-guided intervention. However, existing models often struggle with image heterogeneity, blurry boundaries, and low contrast, which severely affect segmentation accuracy. Diffusion Probabilistic Models (DPMs) have shown promise in modeling complex data distributions and capturing fine-grained structures. Yet, their generalization capability and detail recovery remain limited when applied to 3M Datasets. To address these challenges, we propose D M 3 diff, a novel medical image segmentation framework that integrates Discrete Wavelet Transform (DWT) with DPMs. Specifically, we introduce a Self-adaptive Wavelet Transform Feature Aggregation Module (SWT-FAM) to serve as a high-pass filter that preserves high-frequency details while suppressing noise and redundancy. Furthermore, we design a Multi-Stage Detail Control Block (MS-DCB) that utilizes Kullback-Leibler divergence to align the distributions of generated and target images, enabling multi-scale control of structure and detail during the denoising process. We evaluate our method on three benchmark anatomical datasets. D M 3 diff achieves consistent improvements over state-of-the-art methods, with Dice scores reaching up to 92.4 % on ISIC, and notable gains in IOU, sensitivity, and Hausdorff distance across all datasets.},
  archive      = {J_KBS},
  author       = {Dong Sui and Xiao Tian and Yacong Li and Maozu Guo and Xiangyu Li and Kuanquan Wang and Gongning Luo},
  doi          = {10.1016/j.knosys.2025.114260},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114260},
  shortjournal = {Knowl. Based Syst.},
  title        = {DM3diff: A novel multi-center, multi-modality and multi-source medical image segmentation framework based on DWT embeded diffusion model},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lag selection in feature-based clustering of time series. <em>KBS</em>, <em>329</em>, 114258. (<a href='https://doi.org/10.1016/j.knosys.2025.114258'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature-based time series clustering methods typically involve extracting vectors of statistical quantities that capture the serial dependence structure of each time series in the dataset. These feature vectors are then used as input to a standard clustering algorithm. In the feature extraction step, the user usually selects a set of lags of interest in advance, a choice that can significantly affect clustering accuracy. This article addresses this limitation by introducing a natural approach in which the set of lags is automatically selected as part of the clustering optimization process. The effectiveness of the proposed methodology is demonstrated through simulations and real data applications.},
  archive      = {J_KBS},
  author       = {Ángel López-Oriona and Ying Sun},
  doi          = {10.1016/j.knosys.2025.114258},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114258},
  shortjournal = {Knowl. Based Syst.},
  title        = {Lag selection in feature-based clustering of time series},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel model to deal with ambiguous and complex time series: Application to sunspots forecasting. <em>KBS</em>, <em>329</em>, 114257. (<a href='https://doi.org/10.1016/j.knosys.2025.114257'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sunspots, the dark patches observed on the surface of the Sun, exhibit cyclical behavior with significant implications for various terrestrial phenomena. Forecasting sunspots accurately is crucial for understanding solar activity and its impact on Earth’s climate and technology-dependent systems. In this study, we propose a novel approach for sunspots forecasting utilizing ambiguous set theory. Using ambiguous set theory, a time series forecasting model is proposed, called ambiguous time series forecasting model (ATSFM) . We begin by collecting historical sunspots spanning from 1700 to 2023. Next, apply ATSFM, which incorporates the ambiguity inherent in sunspots. The ATSFM begins with the partitioning the sunspots with equal-length intervals. For this purpose, this study employs Riemann integration that assists for partitioning the universe of discourse of the sunspots into various equal-length intervals. Then, ambiguous entropy (AE) is calculated for each of the distributed sunspots in equal-length intervals. Ambiguous entropy relationships (AERs) and ambiguous entropy relationship groups (AERGs) are formulated to describe the relationships between previous and current sunspots. Finally, unambiguousness process is applied to obtain forecasted values from the AERGs. To evaluate the ATSFM’s performance, we compare its forecasting accuracy with existing methods, including traditional statistical and machine learning methods. Various statistical measures are used to assess the ATSFM’s forecasting capability. Our experimental results demonstrate that the ATSFM outperforms existing methods, yielding more accurate forecasting results of sunspots. To enhance reproducibility, the source code will be made available upon request by contacting the corresponding author via email.},
  archive      = {J_KBS},
  author       = {Pritpal Singh},
  doi          = {10.1016/j.knosys.2025.114257},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114257},
  shortjournal = {Knowl. Based Syst.},
  title        = {A novel model to deal with ambiguous and complex time series: Application to sunspots forecasting},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing federated learning model adversarial robustness in autonomous vehicles: A lightweight framework with contrastive learning and spatial clustering. <em>KBS</em>, <em>329</em>, 114253. (<a href='https://doi.org/10.1016/j.knosys.2025.114253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated Vehicles (AVs) promise safer and more efficient transportation but remain vulnerable to security threats when trained using Federated Learning (FL). While FL preserves privacy by enabling decentralized training, it is particularly exposed to model poisoning (Byzantine attacks) and adversarial threats (evasion attacks). Traditional defenses, such as robust aggregation and adversarial training (AT), often degrade accuracy under Non-Independent and Identically Distributed data (non-IID). To overcome these challenges, we propose a lightweight defense framework that combines AT, supervised contrastive learning (SCL), and spatial robust aggregation. It includes (1) Pre-Defense Training , using Wasserstein-based Projected Gradient Descent (PGD) adversarial samples; (2) Robust AT with SCL , extending Model-Contrastive (MOON) with a second contrastive objective to improve model resilience and alignment for both local and FL versions; and (3) Spatial Robust Aggregation , using pairwise Wasserstein distance and 2-median clustering to filter outliers. FL pretraining was applied to accelerate convergence and enhance performance. Extensive experiments conducted with three benchmark datasets confirmed that our defense consistently outperforms other state-of-the-art methods. Our approach effectively defends against stealthy model poisoning and adversarial attacks, with only minor accuracy drops observed under extreme attack scenarios. For instance, in CIFAR-10, the clean accuracy drops from 93 % to 82 % in the IID setting and from 88 % to 75 % in the non-IID setting. This demonstrates that the proposed design represents a new benchmark for secure and reliable FL in adversarial environments. We also aim to demonstrate the practical benefits of our approach in reducing traffic accidents and congestion when deployed in AV systems.},
  archive      = {J_KBS},
  author       = {Suzan Almutairi and Ahmed Barnawi},
  doi          = {10.1016/j.knosys.2025.114253},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114253},
  shortjournal = {Knowl. Based Syst.},
  title        = {Enhancing federated learning model adversarial robustness in autonomous vehicles: A lightweight framework with contrastive learning and spatial clustering},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge distillation and enhanced subdomain adaptation using graph convolutional network for resource-constrained fault diagnosis. <em>KBS</em>, <em>329</em>, 114251. (<a href='https://doi.org/10.1016/j.knosys.2025.114251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearing fault diagnosis under varying working conditions faces challenges, including lack of labeled data, distribution discrepancies, and resource constraints. To address these issues, we propose a progressive knowledge distillation framework that transfers knowledge from a complex teacher model, utilizing a Graph Convolutional Network (GCN) with Autoregressive moving average (ARMA) filters, to a compact and efficient student model. To mitigate distribution discrepancies and labeling uncertainty, we introduce Enhanced Local Maximum Mean Square Discrepancy (ELMMSD), which leverages mean and variance statistics in the Reproducing Kernel Hilbert Space (RKHS) and incorporates a priori probability distributions between labels. This approach increases the distance between clustering centers, bridges subdomain gaps, and enhances subdomain alignment reliability. Experimental results on benchmark datasets (CWRU and JNU) demonstrate that the proposed method achieves superior diagnostic accuracy while significantly reducing computational costs. Comprehensive ablation studies validate the effectiveness of each component, highlighting the robustness and adaptability of the approach across diverse working conditions.},
  archive      = {J_KBS},
  author       = {Mohammadreza Kavianpour and Parisa Kavianpour and Amin Ramezani and Mohammad Th Beheshti},
  doi          = {10.1016/j.knosys.2025.114251},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114251},
  shortjournal = {Knowl. Based Syst.},
  title        = {Knowledge distillation and enhanced subdomain adaptation using graph convolutional network for resource-constrained fault diagnosis},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CUOM: A causal unbiased optimization method for federated domain generalization. <em>KBS</em>, <em>329</em>, 114249. (<a href='https://doi.org/10.1016/j.knosys.2025.114249'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Domain Generalization (FedDG) aims to develop robust models for multi-domain discrete data, enabling generalization to unseen domains while ensuring data privacy. It facilitates collaborative training among multiple institutions, producing efficient models that generalize across diverse contexts. Existing methods emphasize extracting global domain-invariant features but frequently neglect client-specific data biases, resulting in models that learn non-causal, biased feature prototypes with limited generalization. To address this challenge, we propose a Causal Unbiased Optimization Method (CUOM) for FedDG, aimed at achieving unbiased feature learning both within and across domains. Specifically, we introduce a Structural Causal Model (SCM) based on a novel causal inference framework to analyze both data and prototype biases. Leveraging this SCM, we design the Generalization Compensation Module (GCM) and the Unbiased Prototype Learning Module (UPLM). The Generalization Compensation Module facilitates intra- and cross-domain data augmentation separately, distinguishing itself from traditional single perspective approaches. It aims to simulate domain diversity, thereby mitigating data bias more effectively. The Unbiased Prototype Learning Module integrates representation alignment loss and prototype contrastive loss to guide the model in learning instance-level unbiased features robust to prototype bias in both original and augmented data. Extensive experiments show that our method outperforms existing state-of-the-art methods in generalization across multiple benchmarks. Our code is available at https://github.com/dhaksndg/CUOM .},
  archive      = {J_KBS},
  author       = {Mi Wen and Kang Han and DongYang Li and QiYe Cai and HaiLun Shen},
  doi          = {10.1016/j.knosys.2025.114249},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114249},
  shortjournal = {Knowl. Based Syst.},
  title        = {CUOM: A causal unbiased optimization method for federated domain generalization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive active learning framework for sparsely labeled multi-label drifting data streams. <em>KBS</em>, <em>329</em>, 114248. (<a href='https://doi.org/10.1016/j.knosys.2025.114248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label data streams consist of sequential instances, each associated with multiple labels, continuously arriving for classification. This setting presents several challenges, including dynamic data distributions, limited labeled data, high labeling costs, and the computational burden of continuous model updates in the presence of concept drift. Although various solutions have been proposed for multi-label data stream classification, they often exhibit a notable limitation in addressing online learning from sparsely labeled data streams and adapting to concept drift with competitive performance. To approach this gap, this paper introduces Multi-Label Active Learning for Drifting Data Streams (MLALDDS), a novel framework tailored for multi-label drifting streams, tackling key issues through single-pass active learning, incremental updates, and effective adaptation to concept drift. MLALDDS employs a self-adjusting k-nearest neighbor classifier within a binary relevance architecture to decompose the multi-label classification problem into simpler tasks. A budget-aware selective sampling strategy is used to query only the most informative instances, minimizing labeling costs while maintaining classification performance. Model updates are conducted incrementally, and a reflective mechanism leverages ADWIN to deliver precise warnings of potential data distribution changes, ensuring individual label-specific classifiers adapt efficiently to concept drift within their respective subspaces. The proposed framework was evaluated on 30 diverse multi-label datasets against 20 state-of-the-art classifiers using 12 performance metrics. Results from nonparametric statistical analysis demonstrate that MLALDDS consistently outperforms competing methods, confirming the effectiveness of its key components in improving classification performance.},
  archive      = {J_KBS},
  author       = {Reza Rahimian and Hoda Mashayekhi and Maryam Khodabakhsh},
  doi          = {10.1016/j.knosys.2025.114248},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114248},
  shortjournal = {Knowl. Based Syst.},
  title        = {An adaptive active learning framework for sparsely labeled multi-label drifting data streams},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive anchor-based attention networks for large-scale sparse bipartite graph embedding. <em>KBS</em>, <em>329</em>, 114242. (<a href='https://doi.org/10.1016/j.knosys.2025.114242'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipartite graph embedding aims to map each node into compact, low-dimensional vectors that preserve the intrinsic properties of the graph. The effectiveness of these embeddings is crucial for capturing structural information and node relationships, which directly impacts the performance of downstream applications such as recommender systems and bioinformatics. However, due to the inherent sparsity and large scale of many real-world bipartite graphs, existing methods often suffer from missing contextual information and excessive feature smoothing. In this paper, we take the first step toward systematically addressing the challenges of embedding large and sparse bipartite graphs. To this end, we propose Adaptive Anchor-based Graph Attention Networks (A 2 GAT), a novel framework that integrates entropy regularization to ensure a balanced distribution of attention weights, preserve feature distinctiveness, and mitigate over-smoothing. In addition, we design an adaptive anchor node generation mechanism and introduce a fully connected attention (FCA) module that dynamically adjusts interaction weights, effectively addressing sparse connectivity and enhancing representation learning in low-density regions. Extensive experiments on eight benchmark datasets demonstrate the effectiveness and generalizability of our model across both recommendation and link prediction tasks.},
  archive      = {J_KBS},
  author       = {Linlin Ding and Yiming Han and Mo Li and Ningning Cui and Xin Wang and Renata Borovica-Gajic},
  doi          = {10.1016/j.knosys.2025.114242},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114242},
  shortjournal = {Knowl. Based Syst.},
  title        = {Adaptive anchor-based attention networks for large-scale sparse bipartite graph embedding},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LoRA dropout as a sparsity regularizer for overfitting reduction. <em>KBS</em>, <em>329</em>, 114241. (<a href='https://doi.org/10.1016/j.knosys.2025.114241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter-efficient fine-tuning methods, represented by LoRA, play an essential role in adapting large-scale pre-trained models to downstream tasks. However, fine-tuning LoRA-series models also faces the risk of overfitting on small training datasets, and there’s still a lack of theoretical guidance and practical mechanisms to control overfitting on LoRA-based PEFT methods. This paper introduces a novel dropout-based sparsity regularizer for LoRA, dubbed LoRA Dropout, which mitigates overfitting by applying refined dropout to LoRA’s low-rank matrices. We establish a theoretical framework that models dropout in LoRA as a sparse fine-tuning process and derive a generalization error bound under this sparsity regularization. Theoretical results show that appropriate sparsity can tighten the gap between empirical and generalization risks and thereby control overfitting. We further enhance the sparsity patterns in conventional dropout methods and propose an innovative LoRA Dropout method for more precise sparsity regularization to achieve better overfitting reduction. Furthermore, we introduce a test-time ensemble strategy and provide theoretical evidence demonstrating that the ensemble method can further compress the error bound and lead to better performance. Extensive experiments on various tasks validate the effectiveness of our LoRA Dropout framework in improving the model’s performance.},
  archive      = {J_KBS},
  author       = {Yang Lin and Xinyu Ma and Xu Chu and Yujie Jin and Zhibang Yang and Yasha Wang},
  doi          = {10.1016/j.knosys.2025.114241},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114241},
  shortjournal = {Knowl. Based Syst.},
  title        = {LoRA dropout as a sparsity regularizer for overfitting reduction},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential hash representation for deep hashing-based image retrieval. <em>KBS</em>, <em>329</em>, 114229. (<a href='https://doi.org/10.1016/j.knosys.2025.114229'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In computer vision, convolutional neural networks have significantly improved the effectiveness of deep hashing-based image retrieval. However, existing deep hashing techniques often regard hash codes as spatial features. It leads to insensitivity of existing hash representations to spatial shifts in real number space which can be explained by mismatch between the real number space and the Hamming space. In response to these limitations, this paper introduces SeqHash, a novel approach grounded in sequential hash representation. Diverging from existing deep hashing methods, SeqHash treats hash codes as hash sequences. Benefiting from the sequential properties of chaos theory and the robust fitting capabilities of Kolmogorov-Arnold Networks (KANs), SeqHash constructs a hash-coding layer called sequence-KAN layer to produce hash codes as sequential outputs in the processes of hash encoding and category hash centers generation. Furthermore, SeqHash devises a loss function that facilitates convergence of the sequential outputs to reach the stable states of the predefined sequence in temporal domain. The error propagation of sequential hash representation and the randomness of chaos mapping facilitate each hash code bit to be contingent upon its previous bits, and endow hashing with higher sensitivity to spatial shifts in real number space. This property aligns the shifts in Hamming space and real number space during training and capture the differences among samples effectively. The quantitative and qualitative experiments demonstrate that SeqHash offers remarkable performance in image retrieval tasks and yields more discernible hash codes compared to other cutting-edge deep hashing algorithms.},
  archive      = {J_KBS},
  author       = {Yinqi Chen and Yangting Zheng and Zhiyi Lu and Peiwen Li and Wenbin He and Shuo Kang and Xiang Gao},
  doi          = {10.1016/j.knosys.2025.114229},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114229},
  shortjournal = {Knowl. Based Syst.},
  title        = {Sequential hash representation for deep hashing-based image retrieval},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADR-net: Attention-oriented detail recovery network for document image shadow removal. <em>KBS</em>, <em>329</em>, 114228. (<a href='https://doi.org/10.1016/j.knosys.2025.114228'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods based on deep learning have extensively explored the problem of document image shadow removal. However, most of them seldom consider the key regions of complex shadows and ignore detail preservation. Moreover, they usually have large model parameters that limit the potential values in real-world applications. To address these issues, we propose a simple but effective Attention-oriented Detail Recovery Network (ADR-Net) to remove complex shadows while preserving details in low complexity. In particular, on one hand, we explore the properties of shadows in color space and use luminance information to guide and generate shadow attention maps, which can accurately capture complex shadow distributions. For this purpose, we further design a Shadow Attention Generation Sub-Network (SAGN) that uses Multi-scale Large Kernel Attention (MLKA) mechanism to obtain long-range dependencies of shadows at various granularity levels. On the other hand, we propose a Dynamic Fusion (DF) strategy to avoid the ambiguity issues from wrong attention map during the learning process. In addition, we propose a Detail Refinement Sub-Network (DRN) that adopts Lightweight Spatial-Channel Convolution (LSCC) to facilitate recover details while decreasing redundant computing. Extensive experiments on public benchmarks and Optical Character Recognition (OCR) performance validate the effectiveness of our proposed ADR-Net and its superiority over state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Fan Yang and Nanfeng Jiang and Da-Han Wang and Xu-Yao Zhang and Yun Wu and Shunzhi Zhu},
  doi          = {10.1016/j.knosys.2025.114228},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114228},
  shortjournal = {Knowl. Based Syst.},
  title        = {ADR-net: Attention-oriented detail recovery network for document image shadow removal},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic interaction and router selection network for multi-modality biometric recognition. <em>KBS</em>, <em>329</em>, 114223. (<a href='https://doi.org/10.1016/j.knosys.2025.114223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modality biometric recognition has attracted significant attention owing to its benefits of convenient acquisition, high security, and accurate recognition. However, most existing modality-fusion methods are static and rely on expert experience or knowledge to design interaction models, which limits their flexibility. Additionally, these interaction models fail to adaptively respond to the evolving and complex intra- and inter-modal relationships, thereby limiting the ability of the model to capture diverse and intricate patterns. To address these issues, we propose a dynamic interaction and router selection network, enabling the adaptive learning of previously unexplored interaction patterns. We designed three progressive interaction units, which are responsible for preserving unique modality information, aligning and enhancing modality features, and dynamically reinforcing inter-modality channel and intra-modality spatial interactions. Dynamic soft router is incorporated into each interaction unit, enabling the generation of an adaptive interaction path that is determined by sample complexity. In addition, within the interaction units, we propose a novel inter-channel and intra-spatial modality interaction fusion unit, which incorporates a dynamic inter-modality linear channel interaction unit and an intra-modality bidirectional multiscale attention unit. By leveraging dynamically reconstructed inter-modality channel features, the unit progressively guides intra-modality spatial features, thereby enhancing the complementarity of inter-modality features and improving the discriminability of intra-modality features. In contrast to nonextensible methods, which suffer from limitations in constrained by limited flexibility, our approach enables simultaneous integration of data across multiple modalities. Extensive experiments conducted on four databases demonstrate that the proposed model significantly outperforms current state-of-the-art methods.},
  archive      = {J_KBS},
  author       = {Xiao Yang and Hai Yuan and Jie Hu and Zaiyu Pan and Zhengwen Shen and Jun Wang},
  doi          = {10.1016/j.knosys.2025.114223},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114223},
  shortjournal = {Knowl. Based Syst.},
  title        = {Dynamic interaction and router selection network for multi-modality biometric recognition},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ontology-based data federation and query optimization. <em>KBS</em>, <em>329</em>, 114216. (<a href='https://doi.org/10.1016/j.knosys.2025.114216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontology-based data access (OBDA), also known as virtual knowledge graphs (VKG), is a well-established approach to information management that facilitates the access to a (single) relational data source through the mediation of a high-level ontology, and the use of a declarative mapping linking the data layer to the ontology. In order to integrate multiple, possibly distributed and heterogeneous, data sources, in this work we formally introduce an extension of OBDA, called ontology-based data federation (OBDF), by combining OBDA with a data federation layer, which can expose multiple data sources as a single relational database. We discuss opportunities and challenges of OBDF, and provide techniques to deliver efficient query answering in OBDF by exploiting inter-source relations (called data hints) in the federated sources. Such techniques are validated through an extensive experimental evaluation based on the Berlin SPARQL Benchmark.},
  archive      = {J_KBS},
  author       = {Zhenzhen Gu and Davide Lanti and Francesco Corcoglioniti and Marco Di Panfilo and Alessandro Mosca and Diego Calvanese and Guohui Xiao},
  doi          = {10.1016/j.knosys.2025.114216},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114216},
  shortjournal = {Knowl. Based Syst.},
  title        = {Ontology-based data federation and query optimization},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pinpointing visual content: Disentangled features in multimodal model for EEG representation learning and decoding. <em>KBS</em>, <em>329</em>, 114212. (<a href='https://doi.org/10.1016/j.knosys.2025.114212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding how humans process visual information is one of the key steps in revealing the underlying mechanisms of the brain. Recent research has significantly progressed in brain signal decoding and visual content reconstruction. However, due to complex noise and insufficient alignment accuracy, methods for extracting effective information from electroencephalogram (EEG) are still limited. Existing decoding strategies often fail to adequately represent the fine-grained information of visual embeddings and struggle to deal with data scarcity. To address these issues, we propose the PinVC ( P inpointing V isual C ontent) framework, which aims to integrate fine-grained multimodal information in EEG signals and represent similar activation patterns cross-subject to enhance the accuracy of EEG representation and visual decoding. This method introduces a feature adaptation mechanism that mitigates individual differences and noise effects by masking attention, thus ensuring cross-subject generalizability. In addition, we align the EEG with the implicit target semantic embedding of the LLM and construct a spatial information attention (SIA) module to extract spatial features, thus further improving the quality of the multilevel reconstructed images. PinVC provides accurate multimodal guidance for the pre-trained generative model. We conducted rigorous experimental evaluations on different datasets as well as downstream tasks including visual reconstruction and caption generation, demonstrating PinVC’s excellent performance and generalization. Our project is available at https://github.com/HolderXJTU/PinVC .},
  archive      = {J_KBS},
  author       = {Haodong Jing and Yongqiang Ma and Panqi Yang and Haibo Hua and Nanning Zheng},
  doi          = {10.1016/j.knosys.2025.114212},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114212},
  shortjournal = {Knowl. Based Syst.},
  title        = {Pinpointing visual content: Disentangled features in multimodal model for EEG representation learning and decoding},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Citrus plant classification using gated fusion adaptive graph neural network with harbor seal whiskers optimization algorithm. <em>KBS</em>, <em>329</em>, 114093. (<a href='https://doi.org/10.1016/j.knosys.2025.114093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Citrus is vital for vitamin C production, but existing disease classification methods struggle with low accuracy due to poor feature representation, limited complex pattern handling and weak fusion under varied textures and lighting. To overcome these complications, Citrus Plant Classification using Gated Fusion Adaptive Graph Neural Network with Harbor Seal Whiskers Optimization Algorithm (CPC-GFAGNN HSWOA) is proposed. Here, the images are taken from Citrus leaf dataset. Afterwards the images are fed into the pre-processing stage. In preprocessing, Unsharp Structure Guided Filtering (USGF) is applied to eliminate noise from the input images. The pre-processed images are given to the Semantic Invariant Multi-view Clustering (SIMVC) for segmenting region of interest from the citrus leaf images. Next, the segmented images are supplied to the feature extraction process. By using Feature Affine Residual Network (FA-ResNet), the features are extracted, like shapes, colors and textures. The extracted features are fed into the Gated Fusion Adaptive Graph Neural Network (GFAGNN) to classify the citrus leaf images as Black Spot, Canker, Greening, Healthy and Melanose. Finally, Harbor Seal Whiskers Optimization Algorithm (HSWOA) is employed to improve the weight parameter of GFAGNN. This combination effectively mitigates issues such as over fitting, class imbalance and suboptimal feature learning, resulting in robust and accurate classification of citrus leaf diseases. The proposed CPC-GFAGNN HSWOA method is implemented and performance is evaluated using metrics. The experimental results shows that the proposed CPC-GFAGNN HSWOA method achieves 18.75 %, 26.89 %, 32.57 % better accuracy, 18.43 %, 25.64 %, 31.40 % better sensitivity when compared with existing AD-CPL-DNN, SA-DNN CDD and CL-DC CNN models respectively.},
  archive      = {J_KBS},
  author       = {Aswini E and C. Vijayakumaran},
  doi          = {10.1016/j.knosys.2025.114093},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {114093},
  shortjournal = {Knowl. Based Syst.},
  title        = {Citrus plant classification using gated fusion adaptive graph neural network with harbor seal whiskers optimization algorithm},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Embedding word positions with polar coordinates. <em>KBS</em>, <em>329</em>, 113903. (<a href='https://doi.org/10.1016/j.knosys.2025.113903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Word positions provide grammatical information and help identify linguistic structures. Recent works have shown that the positions of words in a sentence play an important role in natural language processing (NLP). In this paper, we propose a novel method using polar coordinates to embed word positions. The main idea is to decouple a position embedding into a semantic component and a sequential order component, which are implemented by the polar radius and the polar angle respectively. We further propose a Polar-Fix module and plug it in the conventional Transformer encoder. This module (1) enables the stacked Transformer networks to maintain the polarized representation and (2) avoids the danger of over tuning the context-free parameters that are independent on the contexts. Experimental results on three classic NLP tasks, i.e., language modeling, text classification and semantic similarity, show that our method achieves significant improvements over the state-of-the-art Transformer based models. The visualization of polar embeddings indicates that our model is highly interpretable.},
  archive      = {J_KBS},
  author       = {Xiaotang Wen and Chen Yan and Huimin Huang and Hong Shen},
  doi          = {10.1016/j.knosys.2025.113903},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {113903},
  shortjournal = {Knowl. Based Syst.},
  title        = {Embedding word positions with polar coordinates},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Redundancy reduction penalty term of loss function in deep neural network. <em>KBS</em>, <em>329</em>, 113776. (<a href='https://doi.org/10.1016/j.knosys.2025.113776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel regularization algorithm that is introduced as a penalty term to the loss function. Differing from conventional L1 and L2 regularization methods, our approach does not aim to diminish the weights of individual neurons or enforce sparsity by driving certain neurons to zero. Instead, it functions by increasing the differences between neurons and enhancing the diversity of neurons within each layer. Our method incorporates ensemble learning techniques by treating the layer weight matrix as a collective learning model, where each neuron serving as a weak learner within the layer. The proposed algorithm improves the performance of DCNN by simultaneously considering the distance between multiple filters in the same layer. This algorithm reduces the redundancy of the parameter layer filters in DCNN and enhances its robustness. The penalty term proposed by our algorithm dynamically adjusts its value in a cyclical manner, compelling the neural network to navigate away from its current gradient state. In the parameter space, different weights correspond to different locations. The proposed algorithm quantifies the distance between neurons and iteratively increases the distance between neurons during thereby encouraging greater diversity within the network. Experimental evaluations demonstrate the effectiveness of our algorithm in enhancing neural network performance without requiring adjustments to other hyper-parameters.},
  archive      = {J_KBS},
  author       = {Xueheng Hu and Shuhuan Wen and H.K. Lam},
  doi          = {10.1016/j.knosys.2025.113776},
  journal      = {Knowledge-Based Systems},
  month        = {11},
  pages        = {113776},
  shortjournal = {Knowl. Based Syst.},
  title        = {Redundancy reduction penalty term of loss function in deep neural network},
  volume       = {329},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="matdes">MATDES - 39</h2>
<ul>
<li><details>
<summary>
(2025). Unveiling the SLM process-structure-property relationship of a moderate mg content al-mg-si-sc-zr-mn alloy. <em>MATDES</em>, <em>259</em>, 114787. (<a href='https://doi.org/10.1016/j.matdes.2025.114787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selective Laser Melting (SLM) holds great promise for fabricating high-precision aluminum alloy components with complex geometries and lightweight structures. However, producing high-strength aluminum alloys with excellent mechanical properties remains hindered by poor printability and complex microstructural control. In this study, an Al-4.79 Mg-1.3Si-0.51Sc-0.27Zr-0.47Mn (wt.%) alloy was developed and processed via SLM. The SLM process-structure-property relationship of this alloy was investigated. Crack-free samples were achieved across a broad process window, indicating excellent crack resistance and adaptability. Good printability and high relative density over 99.5 % can be achieved at a laser power of 200-230 W and scanning speed of 1050 and 1150 mm/s, corresponding to a volumetric energy density (VED) of 60 J/mm 3 -73 J/mm 3 . The increase in the laser energy density promoted the formation of columnar grains and the widening of subgrain structures, and made the Mg 2 Si phase transformed from continuous to discontinuous morphology. The as-printed alloy exhibited 439 MPa tensile strength and 11.3 % elongation, attributed to grain refinement, reduced porosity, and the formation of the high dislocation density, 9R phase, and nanotwin. After aging, strength increased to 483 MPa and elongation decreased to 6.5 %. This study defines the process window and demonstrates a balance between high specific strength and cost efficiency.},
  archive      = {J_MATDES},
  author       = {Rui Liu and Junquan Yu and Wenyou Zhang and Xiebin Wang and Jun Lin and Guoqun Zhao},
  doi          = {10.1016/j.matdes.2025.114787},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114787},
  shortjournal = {Mater. Des.},
  title        = {Unveiling the SLM process-structure-property relationship of a moderate mg content al-mg-si-sc-zr-mn alloy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards understanding the design principle and rotation deformation mechanics of 3D chiral NPR structure with tunable mechanical responses. <em>MATDES</em>, <em>259</em>, 114784. (<a href='https://doi.org/10.1016/j.matdes.2025.114784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an innovative three-dimensional Negative Poisson’s ratio (NPR) chiral structure was designed based on a 2D staggered rib architecture. This design integrates horizontally oriented chiral alternating ribs and vertically oriented Z-shaped configurations. Two optimized architectures, namely the wave-optimized structure (W-NPR) and the node-enhanced structure (N-NPR), were proposed and compared with the original folded structure (F-NPR). Characterization analysis revealed that the N-NPR structure exhibited superior formability, making it suitable for Digital Light Processing (DLP) fabrication. A parametric study on the mechanical performance of the N-NPR structure demonstrated that an increased volume fraction enhances the mechanical properties at the expense of structural compliance. Uniaxial tensile testing along the XY-plane and Z-axis confirmed the anisotropic Young’s modulus. Experimental and finite element simulations further revealed anisotropic behavior and a unique two-stage rotation-torsion compressive deformation mechanism of N-NPR, which enables advanced mechanical designs by enhancing the degree of freedom for deformation mode conversion. This work proposes a novel method for designing 3D NPR structures and elucidates its mechanical deformation mechanism, enabling transformative advances in aerospace, personalized healthcare, and adaptive wearable technologies.},
  archive      = {J_MATDES},
  author       = {Ruiqi Pan and Ruiying Luo and Wei Xiong and Qiaoyu Chen and Jiafeng Wu and Chunze Yan and Liang Hao and Jie Yin and Zheng Li and Ronghong Zhang and Lei Yang and Yan Li},
  doi          = {10.1016/j.matdes.2025.114784},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114784},
  shortjournal = {Mater. Des.},
  title        = {Towards understanding the design principle and rotation deformation mechanics of 3D chiral NPR structure with tunable mechanical responses},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of irradiation temperature on the microstructure and hardness of W-0.3Cr alloy after irradiation with 6.4 MeV fe ions. <em>MATDES</em>, <em>259</em>, 114783. (<a href='https://doi.org/10.1016/j.matdes.2025.114783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The W-0.3 at.% Cr alloy samples were irradiated with 6.4 MeV Fe ions at 773, 1073 and 1273 K, and the damage peak was 0.26 dpa. The evolution of the microstructure, defects, and hardness was investigated using grazing-incidence X-ray diffraction (GIXRD), transmission electron microscopy (TEM) and nanoindentation tests. The GIXRD results showed that diffraction peaks shifted towards lower 2θ values, indicating that lattice swelling was caused by irradiation-induced defects after irradiation at elevated temperatures. According to the TEM observations, the size of the dislocation loops remained nearly constant, while their number density decreased with an increase in irradiation temperature. The precipitation of Cr was not observed in the W-0.3Cr alloy after irradiation at 773 K. In contrast, it was significant in the samples irradiated at temperatures of 1073 and 1273 K, showing increases in both the size and number density of the precipitates. Irradiation hardening was observed in all samples, primarily attributed to the presence of dislocation loops. The hardness change was estimated with the dispersion barrier hardening model by taking into account the contributions of dislocation loops and Cr precipitates. The values evaluated with the model were significantly larger than those obtained with the nanoindentation tests. This difference was ascribed to the depletion of solute Cr atoms from the W matrix by precipitation.},
  archive      = {J_MATDES},
  author       = {Jing Wang and Jingxian Sun and Yingying Jia and Yifan Zhang and Yuji Hatano and Diancheng Geng and Katsuya Suzuki and Chang Chen and Laima Luo and Kiyohiro Yabuuchi and Ryuta Kasada},
  doi          = {10.1016/j.matdes.2025.114783},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114783},
  shortjournal = {Mater. Des.},
  title        = {Effect of irradiation temperature on the microstructure and hardness of W-0.3Cr alloy after irradiation with 6.4 MeV fe ions},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel in-situ gas-phase alloying approach in wire arc additive manufacturing for controlling solidification mode and designing hybrid stainless steels. <em>MATDES</em>, <em>259</em>, 114781. (<a href='https://doi.org/10.1016/j.matdes.2025.114781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a thermodynamically guided in-situ gas-phase alloying approach in wire arc additive manufacturing (WAAM) to enhance duplex stainless steels by shifting the primary solidification mode from δ-ferrite to γ-austenite, producing a nitrogen-enriched alloy with a continuous austenitic matrix that combines duplex-grade strength with superior ductility. Thermodynamic calculations guided nitrogen adjustment in the shielding gas to control solidification and develop high-performance microstructures. Thermodynamic–kinetic modeling predicted nitrogen uptake from the arc plasma, enabling gas composition selection to promote a shift from δ-ferrite to γ-austenite as the primary solidification phase. Nitrogen content analysis and Scheil simulations confirmed a transition to austenite-first solidification at approximately 0.7 wt% nitrogen. Electron Backscatter Diffraction and optical microscopy revealed that nitrogen-enriched (HN) samples exhibited a continuous γ-austenitic matrix with finely dispersed δ-ferrite, whereas nitrogen-lean (LN) samples had a δ-ferritic matrix with isolated γ-austenite islands. HN samples showed greater grain orientation spread, indicating increased internal misorientation. Despite pronounced crystallographic texture, the HN samples demonstrated nearly isotropic tensile behavior along with enhanced yield strength, tensile strength, ∼11 % higher hardness, and improved elongation. These findings demonstrate that melt chemistry control via gas-phase alloying enables phase-engineered microstructures with superior mechanical performance without modifying the filler wire.},
  archive      = {J_MATDES},
  author       = {Elina Akbarzadeh Chiniforoush and Mohammad Reza Jandaghi and Johan Moverare and Tohid Saeid and Koray Yurtışık},
  doi          = {10.1016/j.matdes.2025.114781},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114781},
  shortjournal = {Mater. Des.},
  title        = {A novel in-situ gas-phase alloying approach in wire arc additive manufacturing for controlling solidification mode and designing hybrid stainless steels},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influencing the draping behaviour of solid epoxy prepregs by applying 3D-printed resin patterns. <em>MATDES</em>, <em>259</em>, 114780. (<a href='https://doi.org/10.1016/j.matdes.2025.114780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel strategy to overcome the limitations of solid resin prepregs (SRPs) − namely the inability to drape at room temperature and hindered gas evacuation during vacuum-bag-only (VBO) processing − by 3D-printing a regular, uncured solid epoxy resin (SR) pattern on a dry woven textile. The locally patterned resin distribution preserves dry textile regions, enabling room temperature drapeability and more robust VBO-processing due to improved gas evacuation. By adjusting pattern parameters such as element geometry and coverage, the draping behaviour can be controlled to adapt to a desired draping condition. In order to be able to design the right pattern for given draping conditions, the influence of these parameters on bending and shearing was studied. Manual draping showed that bending radii down to 4 mm were achievable, governed only by the element length in bending direction, while coverage had no significant effect. In contrast, picture-frame-tests showed that the shearing is mainly influenced by the coverage and that a maximal shearing angle of 30° can be achieved. These results show that the SRPs bending and shearing can be independently influenced through pattern design. The derived structure–drapeability relationships enable targeted design of SRPs for robust, autoclave-free composite manufacturing.},
  archive      = {J_MATDES},
  author       = {Jan Philipp Janzen and Hendrik Schäfer and Murat Çelik and Colin Robert and Conchúr M. Ó Brádaigh and David May and Thomas Neumeyer},
  doi          = {10.1016/j.matdes.2025.114780},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114780},
  shortjournal = {Mater. Des.},
  title        = {Influencing the draping behaviour of solid epoxy prepregs by applying 3D-printed resin patterns},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laser powder bed fusion of pure silver sputtering target: Process, microstructure, and sputtering performance. <em>MATDES</em>, <em>259</em>, 114779. (<a href='https://doi.org/10.1016/j.matdes.2025.114779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Silver (Ag) sputtering targets are crucial in electronic information materials, particularly with the rapid advancement of Artificial Intelligence (AI), which has further increased their demand. However, the extremely high reflectivity and poor laser absorption of pure Ag in the infrared range make it challenging to process using conventional laser-based Additive Manufacturing (AM) systems, limiting its wide application. In this study, a novel hatch spacing-to-scanning speed ratio ( h / v )-centered low-energy–density strategy was proposed to overcome this challenge and enable high-quality additive manufacturing of pure Ag. By optimizing the ( h / v ) value to 1.0E-04, we successfully fabricated dense, low-defect Ag sputtering targets without increasing energy input. The results demonstrated that this method significantly shortened the manufacturing cycle and produced high-performance Ag targets with refined grains (3–7 μm), high density (≥99.8 %), a smooth surface (Ra = 11.5 μm), and stable sputtering performance (sputtering rate = 31.8 nm/min). Furthermore, the hardness increased by 45.1 % compared to Ag targets prepared by traditional methods. This work offers a practical pathway for applying laser-based AM in the production of highly reflective metal sputtering targets, advancing their industrialization in thin-film electronics, while also contributing to the understanding of AM process–structure relationships in metallic materials.},
  archive      = {J_MATDES},
  author       = {Zheda Ning and Yipei He and Qi Tang and Yunxiu Chao and Yue Shen and Haozhang Zhong and Ming Wen and Jianfeng Gu},
  doi          = {10.1016/j.matdes.2025.114779},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114779},
  shortjournal = {Mater. Des.},
  title        = {Laser powder bed fusion of pure silver sputtering target: Process, microstructure, and sputtering performance},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving the performance of organic photodetectors by low-temperature electron beam annealing. <em>MATDES</em>, <em>259</em>, 114778. (<a href='https://doi.org/10.1016/j.matdes.2025.114778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organic photodetectors (OPDs) are promising candidates for next-generation optoelectronic devices due to their flexibility, low cost, and scalability. Enhancing OPD performance requires optimizing key layers such as the electron transport layer (ETL) using low-temperature processes to prevent thermal degradation. This study explores the use of low-temperature electron beam annealing (EBA) to improve the performance of Al-doped ZnO (AZO)-based ETLs. The impact of EBA irradiation time (1–8 min) on the structural, morphological, and electrical properties of AZO films was systematically analyzed. EBA effectively modulated oxygen vacancies and reduced surface roughness, lowering trap density and leakage current while enhancing charge transport. An OPD with an ETL treated by 8 min of EBA exhibited superior detectivity (2.22 × 10 13 Jones at 0 V) and significantly reduced leakage current compared to a device with conventionally annealed ETLs. Importantly, the low-temperature EBA process preserved the amorphous state of AZO, making it suitable for heat-sensitive and flexible substrates. These findings demonstrate that EBA is a powerful, scalable method for ETL optimization in OPDs and offers a pathway toward high-performance, energy-efficient, and flexible optoelectronic devices.},
  archive      = {J_MATDES},
  author       = {Jaebum Jeong and Gun woong Kim and Eun Jin Park and Seong Woo Jeong and Seok Hwan Jang and Jae Yeong Jeong and Soo Won Heo and Jun Young Kim},
  doi          = {10.1016/j.matdes.2025.114778},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114778},
  shortjournal = {Mater. Des.},
  title        = {Improving the performance of organic photodetectors by low-temperature electron beam annealing},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustainable biopolymer design: Extraction of chitin and chitosan using natural deep eutectic solvents with improved antibacterial features. <em>MATDES</em>, <em>259</em>, 114775. (<a href='https://doi.org/10.1016/j.matdes.2025.114775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraction of biopolymers using natural deep eutectic solvents (NADES) offers a promising approach for developing sustainable and biocompatible materials for biomedical applications. In this study, a novel and environmentally friendly process has been developed for extracting chitin and chitosan from organic Agaricus bisporus ( A. bisporus ) mushrooms, which serves as a readily available and renewable resource. NADES not only enhances the extraction efficiency but also preserves the structural integrity of the biopolymers. The characteristics of these biopolymers were analyzed by X-ray diffraction (XRD), Fourier transform infrared spectroscopy (FT-IR), thermogravimetric (DTG/TGA) analysis, scanning electron microscopy (SEM), atomic force microscopy (AFM), and nuclear magnetic resonance ( 1 H NMR) techniques. By optimizing the NADES extraction conditions, high-purity chitin (98.58 %) and chitosan (98.69 %) were achieved, surpassing the purity levels achieved by traditional chemical methods. NADES-extracted chitosan exhibited a remarkable degree of deacetylation (DD) of up to 94.22 %, and a crystallinity index (CrI) of up to 61.77 %, highlighting its enhanced functionality for biomedical applications. Moreover, the NADES-derived biopolymers showed excellent biocompatibility with L929 fibroblast cells. They exhibited dose-dependent antibacterial activity against Staphylococcus aureus (S. aureus) and Escherichia coli (E. coli) and exhibited promising antioxidant and biodegradability properties.},
  archive      = {J_MATDES},
  author       = {Issam Thamer and Magdalena Mazurek-Budzyńska and Vignesh Kumaravel},
  doi          = {10.1016/j.matdes.2025.114775},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114775},
  shortjournal = {Mater. Des.},
  title        = {Sustainable biopolymer design: Extraction of chitin and chitosan using natural deep eutectic solvents with improved antibacterial features},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic effect of interfacial silane film and laser texturing on joining characteristics of pretreated Al/CFRTP friction stir welded joints. <em>MATDES</em>, <em>259</em>, 114774. (<a href='https://doi.org/10.1016/j.matdes.2025.114774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by lightweight requirements in the low-altitude economy, a synergistic laser ablation‒silane coupling process was developed to optimize friction stir welded joints between Al alloys and carbon fiber-reinforced thermoplastics (CFRTPs), with a focus on elucidating the sequence-dependent gradient interfacial joining mechanism. A sequence involving silane coupling prior to laser ablation was employed, enabling dual-mode enhancement of the interfacial geometric configuration and chemical bonding. Mechanical interlocking was ensured in laser-ablated zones, whereas the chemical bonding capacity in unablated regions was enhanced. The tensile–shear strength and cross-tension strength of the joints were measured at 32.6 MPa and 3.2 MPa, respectively. Detailed microstructural characterization revealed that mechanical interlocking occurred in the laser-ablated zones of the PA66 resin and that synergistic physicochemical reinforcement was achieved via covalent Al‒O‒Si bonds coupled with molecular chain entanglement/hydrogen bonding in unablated regions. Defect-free continuous interfacial transitions were confirmed through the penetration of nanolamellar structures by amorphous silane films. This synergistic strategy provides new insights for the high-performance joining of dissimilar metal and polymer materials.},
  archive      = {J_MATDES},
  author       = {Suyu Wang and Wenquan Wang and Yuhua Chen and Xinge Zhang and Shanlin Wang and Timing Zhang and Yuxin Xu},
  doi          = {10.1016/j.matdes.2025.114774},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114774},
  shortjournal = {Mater. Des.},
  title        = {Synergistic effect of interfacial silane film and laser texturing on joining characteristics of pretreated Al/CFRTP friction stir welded joints},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microcellular TLCP/SiO2 for high-frequency communication design. <em>MATDES</em>, <em>259</em>, 114772. (<a href='https://doi.org/10.1016/j.matdes.2025.114772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of high-frequency and high-speed communication technologies, especially in microwave/millimeter-wave applications, electronic devices face increased performance demands. Developing low dielectric materials with exceptional properties for these devices has become a significant challenge. Thermotropic liquid crystal polymers (TLCP) are promising due to their excellent high-frequency performance, while microcellular foaming technology is commonly used to enhance dielectric properties. In this study, TLCP was modified with ADR and nano-SiO 2 . The synergistic modification introduces long-chain branched structures and nucleation sites, improving matrix performance and optimizing foaming behavior. In addition, long-chain branched TLCP/SiO 2 foam has highly compressive properties, excellent dimensional stability, ultra-low dielectric stability at high frequencies, great flame retardant and wonderful high-temperature infrared thermal stealth performance. It is also found by simulation that the patch antenna with long-chain branched TLCP/SiO 2 foam substrate has excellent signal transmission performance. The transmission distance up to 4793 m, which is 5.8 times higher than pure TLCP before foaming, which presents a novel solution for high-frequency and high-speed communication. Furthermore, the long-chain branched TLCP/SiO 2 foams with significant performance is expected to be used in sophisticated technology fields such as wide-ranging applications in military, extreme conditions, aviation, microelectronic and other fields.},
  archive      = {J_MATDES},
  author       = {Jiayang Sun and Wenyu Zhong and Yichong Chen and Kuikui Fan and Dongdong Hu and Zhenhao Xi and Tao Gu and Ling Zhao},
  doi          = {10.1016/j.matdes.2025.114772},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114772},
  shortjournal = {Mater. Des.},
  title        = {Microcellular TLCP/SiO2 for high-frequency communication design},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recent progress of manipulating microenvironment for spinal cord injury therapy using nanoparticles. <em>MATDES</em>, <em>259</em>, 114769. (<a href='https://doi.org/10.1016/j.matdes.2025.114769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spinal cord injury (SCI) is a severe traumatic condition that profoundly compromises patients’ health and quality of life. While various therapeutic strategies, including pharmacotherapy, have been developed and demonstrate some efficacy, however their clinical application is significantly limited by challenges, such as low drug bioavailability and undesirable side effects. Moreover, a critical limitation is their frequently neglect the SCI microenvironment, which serves as the essential foundation for nerve regeneration. In contrast, intelligent nanoparticles-based delivery systems, owing to their excellent biocompatibility and high drug-loading capacity, they can modulate the SCI microenvironment on demand, hold great promise for improving SCI therapy. However, how to design intelligent nanoparticles to achieve precise microenvironment regulation for SCI therapy is still lack of a systematic summary. Therefore, this review summarizes recent advances in advances in modulating the microenvironment for treating SCI using targeted nano drug delivery system, hope provide a theoretical basis for the further development of nano-drug to treatment of SCI.},
  archive      = {J_MATDES},
  author       = {Linfeng Xiao and Chunping Tian and Yinshan Hong and Jiajun Wu and Jiani Du and Yanling Yang and Xiaowei Chang},
  doi          = {10.1016/j.matdes.2025.114769},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114769},
  shortjournal = {Mater. Des.},
  title        = {Recent progress of manipulating microenvironment for spinal cord injury therapy using nanoparticles},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advances and challenges of targeted protein degradation in ophthalmology: Future directions and therapeutic potential. <em>MATDES</em>, <em>259</em>, 114767. (<a href='https://doi.org/10.1016/j.matdes.2025.114767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of targeted protein degradation technologies, particularly proteolysis-targeting chimeras (PROTACs) and lysosome-targeting chimeras (LYTACs), is poised to revolutionize therapeutic strategies in ophthalmology. This review presents the first systematic analysis of these protein degradation platforms to address ’undruggable’ targets in ocular pathologies. Harnessing distinct cellular machinery through the engagement of the ubiquitin–proteasome system and the lysosomal pathway with PROTACs and LYTACs, respectively, these heterobifunctional molecules enable the targeted elimination of disease-driving proteins implicated in ocular surface diseases, such as dry eye, and fundus diseases, including age-related macular degeneration, diabetic retinopathy, and glaucoma. We review the mechanistic basis of these technologies, their translational potential in overcoming the limitations of conventional therapies, and ocular-specific challenges such as optimizing bioavailability and intraocular target selectivity. Central to this discussion is the role of advanced linker engineering in achieving spatio-temporal control of degradation activity. While barriers to ocular biodistribution and sustained delivery remain, targeted protein degradation represents a paradigm shift in ophthalmology, offering durable therapeutic effects that could significantly improve clinical outcomes and patient compliance through reduced dosing frequency.},
  archive      = {J_MATDES},
  author       = {Ke Feng and Mingyan Wei and Panqin Ma and Jiaoyue Hu and Caihong Huang and Yi Han and Zuguo Liu},
  doi          = {10.1016/j.matdes.2025.114767},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114767},
  shortjournal = {Mater. Des.},
  title        = {Advances and challenges of targeted protein degradation in ophthalmology: Future directions and therapeutic potential},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bioactive nerve conduit enhance peripheral nerve regeneration through dual functions of ion-regulated dedifferentiation and particle-anchored migration. <em>MATDES</em>, <em>259</em>, 114764. (<a href='https://doi.org/10.1016/j.matdes.2025.114764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The regeneration of long-segment peripheral nerve defects remains a critical and challenging clinical problem. The key step in nerve regeneration involves the dedifferentiation of Schwann cells into a repair phenotype, followed by their orderly migration to form Büngner bands that guide axonal elongation. However, due to the lack of bioactive factors for stimulation, the repair of current nerve conduits is generally slow. In this study, we designed a bioactive glass microspheres-embedded nerve conduit. The ions released from these microspheres activate c-Jun to induce Schwann cell dedifferentiation. Meanwhile, the microspheres coated onto the conduit surface provide physical anchoring sites, which accelerate integrin- β 1-mediated Schwann cell adhesion and orderly migration to facilitate Büngner bands assembly. This study confirms that dual-function bioactive glass microspheres promote nerve regeneration through ion-regulated dedifferentiation and particle-anchored migration, offering a novel approach for the design of nerve conduits.},
  archive      = {J_MATDES},
  author       = {Haohui Huang and Shijing Xu and Yulian Yang and Yonghao Qiu and Yujuan Liu and Xiaofeng Chen and Huichang Gao and Fujian Zhao},
  doi          = {10.1016/j.matdes.2025.114764},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114764},
  shortjournal = {Mater. Des.},
  title        = {Bioactive nerve conduit enhance peripheral nerve regeneration through dual functions of ion-regulated dedifferentiation and particle-anchored migration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of dielectric properties, radiation shielding, and electrical resistivity of alkali-activated blast furnace slag and portland cement binders. <em>MATDES</em>, <em>259</em>, 114763. (<a href='https://doi.org/10.1016/j.matdes.2025.114763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alkali-activated materials (AAMs) are increasingly explored for sustainable construction, yet their electromagnetic and radiation-related properties remain largely unknown. This study explored the radio wave propagation, gamma-ray shielding efficiency, and electrical resistivity of alkali-activated blast furnace slag (BFS-AAM) compared to hydrated Portland cement (PC). BFS-AAM demonstrated superior relative permittivity (ε r ≈ 7.6 at 2.4 GHz) and loss tangent (∼0.33) at lower radio frequencies (0.02–10 GHz), leading to enhanced signal attenuation compared to PC (ε r ≈ 5.6, loss tangent ≈ 0.07). BFS-AAM showed similar performance to PC at frequencies between 10–20 GHz, while its characteristics below 10 GHz make it suitable for secure signal environments. In terahertz spectrum (0.2–2 THz), relevant for 6G wireless communication, both materials displayed comparable permittivity (∼5.3 and ∼4.2) and loss tangent (∼0.09 and ∼0.04), indicating compatibility with residential and commercial applications. Simulations at 0.7, 2.4, and 6.0 GHz confirmed higher signal attenuation by BFS-AAM. Additionally, BFS-AAM exhibited higher resistivity (26–110 Ω·m), greater compressive strength (60 MPa), and lower porosity (∼11 %), contributing to its favorable dielectric properties. Although BFS-AAM demonstrated slightly lower gamma-ray shielding efficiency (at 0.661 MeV) than PC, its multifunctional properties position it as promising material for advanced electromagnetic and radiation shielding technologies.},
  archive      = {J_MATDES},
  author       = {Mehedi Rabbil and Mikko Kokkonen and Elijah Adesanya and Otto Mankinen and Mohammad Bhuyan and Sherif Hegazy and Sami Myllymäki and Juho Yliniemi and Tero Luukkonen},
  doi          = {10.1016/j.matdes.2025.114763},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114763},
  shortjournal = {Mater. Des.},
  title        = {Comparison of dielectric properties, radiation shielding, and electrical resistivity of alkali-activated blast furnace slag and portland cement binders},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of γ′ phase on the microstructural evolution and compressive properties of ni-based single crystal superalloys. <em>MATDES</em>, <em>259</em>, 114760. (<a href='https://doi.org/10.1016/j.matdes.2025.114760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To facilitate the evaluation and prediction of hot-end component performance, scanning electron microscopy and quasi-static compression tests were carried out on Ni-based single crystal superalloys, and the influence of γ′ phase on microstructural evolution and compressive properties was systematically investigated. Results show that γ′ phases exhibit spherical, cubic, or lath-like morphologies, and their average size increases from ∼ 180  nm to ∼ 450  nm after thermal exposure; and superalloys with higher volume fraction of γ′ phase gradually precipitate topologically close-packed (TCP) phase. The compressive properties display pronounced anisotropy, governed by both microstructure and loading direction. For superalloys with lower volume fraction of γ′ phase, yield strength decreases from 670  MPa to 505 MPa and ultimate compressive strength from 4690  MPa to 4240 MPa as the γ′ phase coarsens. In contrast, for superalloys with higher volume fraction of γ′ phase, ultimate compressive strength initially decreases and then increases, accompanied by rise in failure strain from 22 % to 46 % after thermal exposure. With increasing loading angle, ultimate compressive strength initially decreases and then rises, whereas yield strength, failure strain and hardening modulus exhibit more complex trends. These variations are closely related to γ′ and TCP phase, and microstructure and loading direction collectively affect mechanical behavior.},
  archive      = {J_MATDES},
  author       = {Shunyong Zhang and Bin Zhang and Fengpeng Zhao and Jicheng Li and Dong Jia and Xicheng Huang},
  doi          = {10.1016/j.matdes.2025.114760},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114760},
  shortjournal = {Mater. Des.},
  title        = {Influence of γ′ phase on the microstructural evolution and compressive properties of ni-based single crystal superalloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-assembly of bortezomib nanofibers for solid tumor and bone metastasis therapy. <em>MATDES</em>, <em>259</em>, 114758. (<a href='https://doi.org/10.1016/j.matdes.2025.114758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome challenges including insufficient drug loading capacity, limited targeting accuracy, and the complex preparation of conventional nanomedicine, self-assembled nanomaterials have emerged as a viable solution. To explore the peptide self-assembly theory and overcome limitations, this study used bortezomib (BTZ) as the base material, and a novel peptide self-assembly strategy utilizing Zn(II) coordination was employed to prepare cancer cell-targeting nanofiber drugs (cRGD-BTZNDs). The therapeutic efficacy was evaluated in different types of tumors. The results demonstrated that cRGD-BTZNDs effectively entered cancer cells and exhibited enhanced cytotoxic effects against cancer cells compared to BTZ. Moreover, cRGD-BTZNDs exhibited excellent therapeutic efficacy against solid tumors, significantly inhibiting 4 T1 tumor growth while reducing biological toxicity. Additionally, in the treatment of bone metastases, cRGD-BTZNDs demonstrated excellent therapeutic potency, effectively alleviating bone damage in mice with high biocompatibility. This study not only self-assembled nanomaterials with great potential in cancer therapy, but also affirmed the correctness and universality of the Zn(II) coordination peptide self-assembly theory, providing a theoretical basis for the improvement of peptide-based nanomedicine.},
  archive      = {J_MATDES},
  author       = {Dongjie Fu and Yuerong Wang and Jiaqi Xuan and Dingchang Liu and Jiawei Zhao and Yang Lei and Tianwen Xi and Hui Yang and Leming Sun},
  doi          = {10.1016/j.matdes.2025.114758},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114758},
  shortjournal = {Mater. Des.},
  title        = {Self-assembly of bortezomib nanofibers for solid tumor and bone metastasis therapy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming the challenges of fusion-based brass additive manufacturing through solid-state additive friction-stir deposition. <em>MATDES</em>, <em>259</em>, 114756. (<a href='https://doi.org/10.1016/j.matdes.2025.114756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Processing Cu-Zn alloys (brass) using fusion-based additive manufacturing (AM) techniques presents significant challenges due to volatile elements and the inherently high thermal conductivity of these alloys. Addressing these issues often demands increased energy input, modifications to laser systems, and compositional adjustments to mitigate zinc loss. However, such solutions are complex and remain in the early stages of development. In contrast, Additive friction stir deposition (AFSD), a solid-state AM technique, offers a promising alternative to overcome these limitations. This study represents a pioneering effort to deposit dual-phase brass (Cu-40Zn) using a closed-loop temperature-controlled AFSD. The influence of processing temperature (ranging from 0.38 to 0.61 T p /T m ) on microstructural evolution and mechanical performance was systematically investigated along the build and longitudinal direction. The resulting microstructure was predominantly governed by dynamic recrystallization and post-dynamic recrystallization (P-DRX) due to repeated thermal cycles. The as-deposited brass exhibited a balanced strength-ductility combination, with yield strength ranging from 215 to 437 MPa and elongation from 34 % to 67 %. Tensile properties in longitudinal and build directions revealed that grain boundary strengthening was the primary mechanism for improving the mechanical performance. The as-deposited properties were comparable to those of wrought counterparts, thus highlighting the potential of AFSD for fabricating high-performance brass components.},
  archive      = {J_MATDES},
  author       = {Meet Gor and Matthew Barnett and Pinaki Bhattacharjee and Daniel Fabijanic},
  doi          = {10.1016/j.matdes.2025.114756},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114756},
  shortjournal = {Mater. Des.},
  title        = {Overcoming the challenges of fusion-based brass additive manufacturing through solid-state additive friction-stir deposition},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-temperature viscoelastic mechanism for SiC fibers to elucidate creep and recovery behaviors. <em>MATDES</em>, <em>259</em>, 114755. (<a href='https://doi.org/10.1016/j.matdes.2025.114755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mastering the high-temperature creep behavior of SiC fibers plays pivotal role in designing reinforced ceramic matrix composites. Creep viscoelastic behavior is activated at higher temperatures due to complicated interactive coordination between grain interiors and grain boundaries. This study investigated the tensile creep behaviors at different generations of SiC fibers under conditions of various stress and temperatures. The creep recovery behaviors after unloading exhibits the viscoelastic nature, which comes from the possible motion of amorphous phase near massive grain boundaries. It is driven by the release of elastic energy of the grain boundary, evidenced by frequency shifts in Raman spectroscopy. Then classical diffusion creep theory is modified to a viscoelastic model incorporating physical parameters such as the elasticity, viscosity, and threshold stress for SiC fibers. The proposed equations have been well supported by creep test results. The viscosity and elasticity parameters decrease with increasing temperature, the latter being more sensitive. 3rd generation fiber exhibits higher viscosity and elasticity, explaining better creep resistance. The model can evaluate the elastic and plastic contributions and predict creep results at higher temperatures. This work helps to understand high-temperature SiC fiber creep, and to guide optimizing fiber-reinforced composites.},
  archive      = {J_MATDES},
  author       = {Wenguo Jiang and Yi Ru and Jundong Shi and Haozhang Hou and Zexu Sun and Weiwei Qu and Xiaotian Hu and Guoquan Ma and Lianyi Wang and Yanling Pei and Shusuo Li and Shengkai Gong},
  doi          = {10.1016/j.matdes.2025.114755},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114755},
  shortjournal = {Mater. Des.},
  title        = {High-temperature viscoelastic mechanism for SiC fibers to elucidate creep and recovery behaviors},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microstructured Y3Al5O12 single-crystal fibers for high-sensitivity quasi-distributed ultrasonic thermometry based on acoustic anisotropy engineering. <em>MATDES</em>, <em>259</em>, 114751. (<a href='https://doi.org/10.1016/j.matdes.2025.114751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of aerospace, nuclear energy, and advanced manufacturing has created a growing demand for temperature sensing in extreme environments. Ultrasonic temperature sensors (UTS) are widely used in high-temperature sensing due to their extreme operating temperature close to the melting point of the waveguide materials. In this work, YAG single-crystal fibers (SCF) with spatially distributed acoustic reflection microstructures have been successfully fabricated via the laser-heated pedestal growth (LHPG) method and employed as acoustic waveguides. Herein, anisotropic acoustic waveguide behaviors were revealed in YAG SCF, where the [110]-oriented YAG SCF demonstrates enhanced unit sensitivity with the S-wave polarization direction of [ 1 1 ¯ 0 ], primarily attributed to the lower acoustic velocity and the more substantial velocity variations with temperature. Furthermore, quasi-distributed ultrasonic temperature sensing in the range of 30-1800℃ has been achieved based on the [110]-oriented YAG SCF with two discrete sensing units, reaching the maximum unit sensitivities of 47.18 ns·℃ -1 ·m - 1 and an optimal temperature resolution of 5.04℃ at 1800℃. Superior acoustic waveguide characteristics, a wide working temperature range, and the positive temperature-dependent sensor performance suggest that the [110]-oriented microstructured YAG SCF is an ideal candidate for distributed high-temperature sensing in harsh environments.},
  archive      = {J_MATDES},
  author       = {Kaihui Zhang and Tao Wang and Mingji Zhang and Xin Guan and Zhengmin Wang and Wenchang Zhuang and Liang Zhang and Jian Zhang and Zhitai Jia},
  doi          = {10.1016/j.matdes.2025.114751},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114751},
  shortjournal = {Mater. Des.},
  title        = {Microstructured Y3Al5O12 single-crystal fibers for high-sensitivity quasi-distributed ultrasonic thermometry based on acoustic anisotropy engineering},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Static recrystallization characteristics and kinetics of austenitic stainless steels under development for LH2 storage applications. <em>MATDES</em>, <em>259</em>, 114750. (<a href='https://doi.org/10.1016/j.matdes.2025.114750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing high-strength austenitic stainless steel (ASS) grades for lightweight cryogenic storage tanks, particularly for liquefied hydrogen (LH 2 ), demands precise microstructure control achievable via optimized thermomechanically controlled processing (TMCP). In recrystallization–controlled regime of TMCP, successive rolling passes facilitate microstructural refinement through dynamic and static restoration mechanisms. This work illustrates static recrystallization (SRX) characteristics and kinetics in three ASS alloys designed by varying N, Mn and Nb contents. Interrupted (double–hit) compression tests were conducted to characterize the flow behaviour and microstructural evolution across different deformation conditions. SRX kinetics were formulated using a fractional–softening framework, where the time to 50 % recrystallization was correlated with strain, strain rate, temperature, and initial grain size. While the exponents of strain (−3.1) and strain rate (−0.3) were consistent across all compositions, the apparent activation energies of SRX varied in the range 251.5–298 kJ·mol −1 , with 7 wt% Mn showing a more noticeable effect in comparison with 0.1 wt% Nb. Detailed metallographic analysis confirmed the accuracy of the derived models. Suitable semi-empirical relations were established enabling prediction of statically recrystallised grain size across various processing conditions. These results define the processing windows needed to design TMCP schedules for advanced ASSs for LH 2 and cryogenic environments.},
  archive      = {J_MATDES},
  author       = {Mahesh Somani and Sumit Ghosh and Juha Uusitalo and Frank Hoffmann and Marta Muratori and Ali Smith and Ahmed W. Abdelghany},
  doi          = {10.1016/j.matdes.2025.114750},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114750},
  shortjournal = {Mater. Des.},
  title        = {Static recrystallization characteristics and kinetics of austenitic stainless steels under development for LH2 storage applications},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic strength and conductivity enhancement via induced 〈0 0 1〉-textured ultrafine grains in Al2O3/Cu composites. <em>MATDES</em>, <em>259</em>, 114748. (<a href='https://doi.org/10.1016/j.matdes.2025.114748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overcoming the strength–conductivity trade-off in Al 2 O 3 /Cu composites remains a key challenge. Here, we propose a microstructural design strategy that combines 〈0 0 1〉 texture with elongated ultrafine grains. Room-temperature rotary swaging (RS), assisted by the pinning effect of Al 2 O 3 particles, promotes the selective formation of 〈0 0 1〉-oriented grains through compressive–shear deformation and enhances grain aspect ratios. The resulting structure provides texture-dominated conductive paths while reducing transverse grain boundary density. Consequently, the composite achieves a yield strength of 342 MPa and an electrical conductivity of 95.3 % IACS—representing a 56.8 % strength increase over the Cu matrix without sacrificing conductivity. This work demonstrates a scalable, room-temperature route to high-performance Cu-based composites with an exceptional strength–conductivity balance for advanced electrical applications.},
  archive      = {J_MATDES},
  author       = {Song Liu and Shaolin Li and Kexing Song and Xiaowen Peng and Xiuhua Guo and Zhenhan Zhou and Shuaibin Li and Fuxiao Chen},
  doi          = {10.1016/j.matdes.2025.114748},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114748},
  shortjournal = {Mater. Des.},
  title        = {Synergistic strength and conductivity enhancement via induced 〈0 0 1〉-textured ultrafine grains in Al2O3/Cu composites},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D-printed barriers with machine learning powered image analysis for enhanced wound healing assays. <em>MATDES</em>, <em>259</em>, 114746. (<a href='https://doi.org/10.1016/j.matdes.2025.114746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wound healing assay is a standard method enabling investigation of cell proliferation and migration through a cell-free gap in a cell monolayer. Despite very common, it shows several weaknesses: lack of reproducibility and manual and time-based image analysis. Based on novel approach founded on innovative materials and AI-assisted processing of biological images, a promising automated barrier-wound healing assay is realized, achieving consistent results while retaining cells integrity. To increase assay accuracy, biocompatible 3D-printed resin inserts have been developed, facilitating precise control over shape and size of the wound. In parallel, a new image-detection algorithm powered by Deep Learning models was developed to identify cell-free area during the healing process, exceeding limitations of manual analysis. 3D-resin inserts combined with automated image analysis allowed the elimination of subjective errors and provided reproducible quantification of cell-free areas across multiple experiments. Moreover, a dataset to train a Convolutional Neural Network for monitor healing over time was developed. As proof of concept, this algorithm was tested on a cancer cell line stimulated by TGF-β, a drug stimulating cell migration. Innovative design of biocompatible materials combined with Deep Learning for automatically processing high-throughput data enables standardized wound healing assay, increasing efficiency, reliability, and accuracy of results.},
  archive      = {J_MATDES},
  author       = {Alfredo De Cillis and Valeria Garzarelli and Alessia Foscarini and Giuseppe Gigli and Antonio Turco and Elisabetta Primiceri and Maria Serena Chiriacò and Francesco Ferrara},
  doi          = {10.1016/j.matdes.2025.114746},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114746},
  shortjournal = {Mater. Des.},
  title        = {3D-printed barriers with machine learning powered image analysis for enhanced wound healing assays},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultralight pt-ALD-modified graphene aerogel achieving aluminum-class thermal resistance at 12% mass. <em>MATDES</em>, <em>259</em>, 114742. (<a href='https://doi.org/10.1016/j.matdes.2025.114742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphene aerogels (GAs), a class of three-dimensional porous structures, are limited by a fundamental challenge: low thermal conductivity stemming from high interfacial resistance between constituent layers and structural defects. This study systematically investigates a strategy to enhance thermal transport properties by engineering the interlayer bonding via platinum atomic layer deposition (Pt-ALD) and compares it with conventional high-temperature annealing (1873 K). The Pt-ALD-modified graphene aerogel (GA-ALD) exhibited a 199 % increase in thermal conductivity, significantly surpassing the 113 % enhancement from heat treatment. SEM, Raman, XRD, XPS, and FTIR data explicitly indicate that Pt-ALD forms covalent Pt O C bonds that bridge adjacent graphene layers while preserving the original porous morphology. Owing to the synergistic effect of enhanced solid-phase thermal conductivity and efficient convective heat transfer through the preserved porous structure, the GA-ALD sample achieved a total thermal resistance comparable to that of an equal-sized aluminum heat sink under identical forced-convection conditions, while weighing only ∼12 % of its aluminum counterpart. Moreover, cyclic compressive tests confirmed GA-ALD durability, retaining 99.5 % height and 94.7 % stress after 1000 cycles. These findings demonstrate that interfacial bond engineering via ALD is a powerful route to ultralight, high-performance carbon aerogels for weight-sensitive thermal-management applications.},
  archive      = {J_MATDES},
  author       = {Jiho Kang and Viet Phuong Nguyen and Seung-Mo Lee and Duckjong Kim},
  doi          = {10.1016/j.matdes.2025.114742},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114742},
  shortjournal = {Mater. Des.},
  title        = {Ultralight pt-ALD-modified graphene aerogel achieving aluminum-class thermal resistance at 12% mass},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laser powder bed fusion of a novel CoNi-based high entropy superalloy. <em>MATDES</em>, <em>259</em>, 114741. (<a href='https://doi.org/10.1016/j.matdes.2025.114741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser powder bed fusion (L-PBF) is poised to revolutionize the manufacturing of high-value metallic materials, allowing for intricate, geometrically complex designs while minimizing material waste. The primary challenge lies in formulating alloys compatible with L-PBF that also maintain properties suitable for the demanding conditions encountered in energy, space, and nuclear applications. We introduce a category of high strength, defect-resistant octonary CoNi-based high entropy superalloy (CoNi-HESA), comprising roughly equal parts of Co and Ni, along with Cr, Al, V, Ti, Ta, and W. This alloy exhibits as-printed tensile strength exceeding 1 GPa and tensile ductility exceeding 30 % at room temperature. Furthermore, compression tests demonstrate that the as-printed parts maintain a yield strength of about 1 GPa at room temperature up to 700 °C, which decreases to 0.9 GPa and 0.7 GPa as the test temperature reaches 800 °C and 900 °C, respectively. With a careful combination of laser powder and scan speed, the developed HESA is well-suited for crack-resistant, high-density component production through L-PBF. Alloy design principles are elucidated through CALPHAD calculations based on the high entropy alloy (HEA) database, including the structure and properties of L-PBF processed CoNi-HESA.},
  archive      = {J_MATDES},
  author       = {Alessandro De Nardi and Ahad Mohammadzadeh and Amir Mostafaei and Jose Manuel Torralba},
  doi          = {10.1016/j.matdes.2025.114741},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114741},
  shortjournal = {Mater. Des.},
  title        = {Laser powder bed fusion of a novel CoNi-based high entropy superalloy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Al alloying-driven spinodal decomposition enables ultra-strong cast refractory high-entropy alloys. <em>MATDES</em>, <em>259</em>, 114736. (<a href='https://doi.org/10.1016/j.matdes.2025.114736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strengthening in refractory high-entropy alloys (RHEAs) can be achieved through the formation of “compositional heterogeneity” at the atomic scale. Here, we chose Zr 45 Ti 15 Nb 20 Ta 20 alloy with a single-phase body-centered cubic (BCC) structure as a matrix and added a small amount of Al to promote a unique spinodal decomposition. The results show that the introduction of Al-X negative mixing enthalpy induces the RHEAs spinodal decomposition to form a nanocubic structure in the form of a basket-like fabric morphology with a characteristic periodicity of 12 nm. Nanocubic structures consist of (Nb, Ta)-rich cubes and Zr-rich channels as well as generate strong localized strain fields at the interfaces. Spinodal decomposition strengthening enables the as-cast RHEA to achieve a yield strength of 1405 MPa. Periodically distributed nanostructures make dislocations move slowly, causing plugging and cross-slip, facilitating dislocation interactions, multiplication, and accumulation. In summary, the chemical heterostructure produced by spinodal decomposition has been remarkably effective in improving the strength of RHEAs.},
  archive      = {J_MATDES},
  author       = {Yongkang Zhou and Ziyan Zhao and Yuanyuan Wang and Hong Li and Haifeng Zhang and Zhengwang Zhu},
  doi          = {10.1016/j.matdes.2025.114736},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114736},
  shortjournal = {Mater. Des.},
  title        = {Al alloying-driven spinodal decomposition enables ultra-strong cast refractory high-entropy alloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving synergistic strength-ductility enhancement in a hierarchical hetero-lamellar AlCoCrFeNi2.1 eutectic high-entropy alloy via facile hot-rolling strategy. <em>MATDES</em>, <em>259</em>, 114734. (<a href='https://doi.org/10.1016/j.matdes.2025.114734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eutectic high-entropy alloys (EHEAs) have attracted considerable interest due to their superior multifunctional performance. However, the inherent tendency of stress concentration at irregular phase boundaries frequently leads to premature fracture. This study presents a facile hot-rolling strategy to achieve synergistic strength-ductility enhancement in AlCoCrFeNi 2.1 EHEA via constructing a hierarchical hetero-lamellar structure (HHLS). Through controlled per-pass rolling reduction (PPRD), we induce strain-partitioning-mediated microstructural refinement in the hot-rolled EHEA and activate synergistic deformation mechanisms including stacking faults, Lomer-Cottrell locks, and deformation twinning. The resultant HHLS (aligned FCC/B2 lamellae, partially recrystallized FCC regions, and intragranular B2 precipitates) triggers pronounced hetero-deformation-induced (HDI) strengthening. Consequently, the EHEA with HHLS exhibits exceptional properties: yield strength of 1202 MPa, ultimate tensile strength of 1489 MPa, and uniform elongation of 11.5 %, which are 112 %, 45 %, and 6 % higher than those of the as-cast alloy, respectively. The superior properties originate from HDI effect and FCC phase-mediated deformation mechanisms, which enable the EHEA to maintain exceptional work-hardening rate despite high dislocation density, effectively delaying plastic instability. These findings not only establish a readily implementable thermomechanical processing strategy for EHEAs, but also provide a novel paradigm for improving mechanical properties, paving the way for their application in high-performance structural materials.},
  archive      = {J_MATDES},
  author       = {Qidong Ren and Tianxin Li and Hengke Xie and Yuhao Jia and Mingpan Wan and Chaowen Huang and Chaoyi Chen and Junqi Li and Yiping Lu},
  doi          = {10.1016/j.matdes.2025.114734},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114734},
  shortjournal = {Mater. Des.},
  title        = {Achieving synergistic strength-ductility enhancement in a hierarchical hetero-lamellar AlCoCrFeNi2.1 eutectic high-entropy alloy via facile hot-rolling strategy},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In vitro antibacterial and in vivo osteogenesis of 3D-printed magnesium peroxide–doped calcium phosphate silicate scaffolds for revision total knee arthroplasty. <em>MATDES</em>, <em>259</em>, 114731. (<a href='https://doi.org/10.1016/j.matdes.2025.114731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Revision total knee arthroplasty (RTKA) often encounters tibial bone defects and high infection risk, especially from methicillin-resistant Staphylococcus aureus (MRSA). Current strategies rely on bone grafts with antibiotics, but prolonged use promotes resistance. Here, we developed a 3D-printed magnesium peroxide (MgO 2 )–doped calcium phosphate silicate (CSP) scaffold to address both structural and antibacterial demands. The MgO 2 –CSP scaffold exhibited cancellous bone-like strength (∼7.95 MPa) and an interconnected macroporous structure conducive to cell migration and healing. In vitro , the 14 wt% MgO 2 scaffold (B14M) inhibited 80.4 % of Gram-negative bacteria and 74.6 % of MRSA via Mg 2+ and H 2 O 2 release, while both B0M (no MgO 2 ) and B14M promoted BMSC proliferation and osteogenic differentiation. In vivo , the B14M scaffold markedly enhanced bone regeneration in rat tibial defects, achieving a BV/TV of ∼73.09 % versus ∼29.84 % for B0M at 8 weeks. These findings highlight MgO 2 –CSP scaffolds as a promising strategy to promote osteogenesis while combating MRSA-associated infections in RTKA.},
  archive      = {J_MATDES},
  author       = {Lisha Meng and Hao Li and Xujia Hao and Tao Wu and Jingqiu Zhou and Yadong Chen and Qiang Zheng and Xiuhong Cao and Juan Wang and Xinwei Liu and Tongmeng Jiang and Tianxing Gong and Wei Yuan},
  doi          = {10.1016/j.matdes.2025.114731},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114731},
  shortjournal = {Mater. Des.},
  title        = {In vitro antibacterial and in vivo osteogenesis of 3D-printed magnesium peroxide–doped calcium phosphate silicate scaffolds for revision total knee arthroplasty},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of synthesis routes on oxygen content, crystallography, and thermal stability of Ti3AlC2 MAX phases and resulting MXenes. <em>MATDES</em>, <em>259</em>, 114729. (<a href='https://doi.org/10.1016/j.matdes.2025.114729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current MXene research focuses on synthesising high-quality MAX phases with minimal O substitution in the C sublattice. This study provides insights into how different ball milling techniques and elemental compositions used in Ti 3 AlC 2 MAX phase synthesis affect the O incorporation into the lattice structure, which directly impacts the MAX phases’ and the resulting MXenes’ thermal stability. The unit cell lattice parameters (LPs) of a MAX phase are well-established indicators in determining the degree of O substitution. The presence of O reduced the a and c LPs of the MAX phase unit cell. However, the corresponding MXenes exhibited similar a LP ( a = 3.05 Å) values regardless of the LP values of their MAX phases. The LP observations are validated by correlative thermogravimetric analysis (TGA) carried out in air atmosphere. With the decreasing O incorporation in the MAX phase, an increase in the oxidation temperature was observed from 450 °C to 780 °C. However, the corresponding MXenes showed an average oxidation onset around 460 °C. Thus, this study reveals an important structure–property relationship between the Ti 3 AlC 2 MAX phase and the resulting Ti 3 C 2 MXenes.},
  archive      = {J_MATDES},
  author       = {Chathushka D. Hettige Dharmasiri and Konstantin L. Firestein and Joseph F.S. Fernando and Xiaodong Wang and Zhenhuan Chen and Dasun P.W. Guruge and Courtney-Elyce Lewis and Dmitri V. Golberg},
  doi          = {10.1016/j.matdes.2025.114729},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114729},
  shortjournal = {Mater. Des.},
  title        = {Influence of synthesis routes on oxygen content, crystallography, and thermal stability of Ti3AlC2 MAX phases and resulting MXenes},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ex vivo porcine urethral model for investigating intermittent catheter-associated urethral microtrauma. <em>MATDES</em>, <em>259</em>, 114727. (<a href='https://doi.org/10.1016/j.matdes.2025.114727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Catheter-associated urethral microtrauma is a significant complication of intermittent catheterisation, compromising patient quality of life (QOL) and increasing urinary tract infection risk. Current research is hindered by the lack of robust physiological models to evaluate the mechanical interactions between catheter materials and urethral tissue during intermittent catheterisation. This study introduces the first ex vivo porcine urethral model to investigate tribological performance and material-tissue interactions during intermittent catheter (IC) use, enabling more informed catheter design. We examined four commercial hydrophilic polyvinylpyrrolidone (PVP)-coated ICs and a coating-free integrated amphiphilic surfactant (IAS) IC. ICs were inserted into porcine urethras using a texture analyser, held for two minutes, and withdrawn while measuring force and work done. Post-catheterisation, urethras were examined for microtrauma. Three of four PVP-coated catheters required significantly greater withdrawal force compared to the IAS catheter, correlating with increased urethral transitional membrane damage post-catheterisation. Ex vivo findings suggest that IAS catheters may lower the risk of complications compared with PVP-coated catheters in intermittent catheterisation. This study provides a new platform for comprehensive evaluation of IC-tissue interactions. It underscores the importance of tribological design in medical devices, aiding future innovation in device design and ultimately improve the QOL of patients undergoing intermittent catheterisation.},
  archive      = {J_MATDES},
  author       = {Jane Burns and Robyn N. Irwin and James Quinn and Jessica V. Moore and David Pollard and Ased Ali and James Hands and Colin P. McCoy and Louise Carson and Matthew P. Wylie},
  doi          = {10.1016/j.matdes.2025.114727},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114727},
  shortjournal = {Mater. Des.},
  title        = {An ex vivo porcine urethral model for investigating intermittent catheter-associated urethral microtrauma},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DNN-based shape optimization of gradient-index phononic crystals with sensitivity analysis for tunable focal position and robust energy harvesting. <em>MATDES</em>, <em>259</em>, 114723. (<a href='https://doi.org/10.1016/j.matdes.2025.114723'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient-index (GRIN) phononic crystals (PnCs) enable energy harvesting (EH) by focusing elastic waves into electrical energy. Efficient EH requires maximizing focused wave intensity, typically achieved by tuning the GRIN PnCs unit-cell shape. However, existing designs often exhibit energy concentration near the GRIN lens boundary and incorporate narrow gaps and sharp corners, making them susceptible to manufacturing errors and limiting their practical applicability. Understanding the potential performance changes caused by manufacturing errors is important because geometrical alterations can compromise wave-focusing performance. Therefore, this study aims to optimize the unit-cell shape toward maximum focused intensity at the desired locations for EH devices. To assess manufacturability, the effects of minor geometric variations on the focal position and focused intensity are evaluated via a sensitivity analysis. The optimal shape is derived using a deep neural network (DNN) surrogate model trained to predict focal position and focused intensity. This model accelerates a genetic algorithm (GA) used to perform the optimization. Our optimized designs exhibit 1.5 to 2.0 times higher focused intensity across the target focal positions compared with the conventional design. Thus, these optimal shapes, along with their sensitivity analysis results, provide practical guidelines for defining manufacturing tolerances and achieving consistent, efficient EH performance.},
  archive      = {J_MATDES},
  author       = {Mary Kim and Sangryun Lee},
  doi          = {10.1016/j.matdes.2025.114723},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114723},
  shortjournal = {Mater. Des.},
  title        = {DNN-based shape optimization of gradient-index phononic crystals with sensitivity analysis for tunable focal position and robust energy harvesting},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving high oxygen tolerance in Ti6Al4V: Copper-oxygen co-doping strategy for ultrahigh strength-ductility balance. <em>MATDES</em>, <em>259</em>, 114719. (<a href='https://doi.org/10.1016/j.matdes.2025.114719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional α + β Ti6Al4V alloys lack sufficient strengthening mechanisms, limiting strength. While oxygen (O) offers a cost-effective strengthening route, exceeding ∼ 0.33 wt% causes significant embrittlement. Here, we explored how to efficiently utilize interstitial oxygen to enhance the mechanical properties of Ti6Al4V. The copper oxide (CuO) was innovatively employed as a precursor to completely dissolve into Ti6Al4V matrix, interstitial O and substitutional Cu atoms were simultaneously utilized to strengthen the primary α-phase (α p ) while inducing the abundant secondary-α (α s ) nanoprecipitates. Surprisingly, the introduction of Cu element facilitated control of lattice distortion and redistributed oxygen between α p and β-transformed (β trans ) structure, resulting in the Ti6Al4V-2.5CuO (wt.%) alloy with high oxygen tolerance (0.62 wt%) and an ultra-high ultimate strength of ∼ 1635 MPa and a favorable ductility of ∼ 5.3 %. The dual effect of interstitial solid solution strengthening and α s precipitation strengthening were achieved under the Cu/O interaction. Additionally, the addition of Cu promoted the oxygen redistribution and activation of the basal < a > and pyramidal < c + a > slip systems, thereby ensuring improved ductility. This study presented a novel strategy for high-strength Ti alloys using interstitial oxygen, maximizing strengthening while mitigating embrittlement.},
  archive      = {J_MATDES},
  author       = {Hongqiang Duan and Hongmei Zhang and Xingwang Cheng and Xiaonan Mu and Qunbo Fan and Ying Zhang and Ni Xiong and Ke Feng and Yu Wang and Xuexia Li and Taotao Cai and Kefan Zheng},
  doi          = {10.1016/j.matdes.2025.114719},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114719},
  shortjournal = {Mater. Des.},
  title        = {Achieving high oxygen tolerance in Ti6Al4V: Copper-oxygen co-doping strategy for ultrahigh strength-ductility balance},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Crack deflection by design – Utilizing the material inhomogeneity effect on miniaturized additively manufactured structures. <em>MATDES</em>, <em>259</em>, 114718. (<a href='https://doi.org/10.1016/j.matdes.2025.114718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A natural crack exhibits a surrounding stress field, which may overlap considerably with a stress field caused by any material inhomogeneity, influencing the crack driving force and extension direction. To utilize this effect for potentially increasing the apparent toughness, a defined pore is introduced near a potential crack path, whereby upon interaction, the crack tip can be deflected or trapped, depending on the intermediate distance. Since fundamental mechanics is well-known, a miniaturized notched bending specimen geometry incorporating a pore was selected to investigate the application potential for parts manufactured via multi-photon lithography. The size regime is representative of the smallest available objects and requires in situ SEM testing, which was completed with finite element modeling based on crack path prediction through analyzing the local crack driving force. The high dimensional repeatability of the process allowed for testing reliably reproduced specimens with variation of crack to pore distance only. The prediction represented the actual crack paths well, underlining successfully facilitated crack path alteration. The toughness was mainly increased by crack trapping within the pore, where deflection had a quantitatively negligible effect.},
  archive      = {J_MATDES},
  author       = {Alexander Jelinek and Markus Alfreider and Dražen Breščaković and Otmar Kolednik and Daniel Kiener},
  doi          = {10.1016/j.matdes.2025.114718},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114718},
  shortjournal = {Mater. Des.},
  title        = {Crack deflection by design – Utilizing the material inhomogeneity effect on miniaturized additively manufactured structures},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adenosine-loaded adhesive microfluidic hydrogel microspheres stimulate acupoint activation for pain management. <em>MATDES</em>, <em>259</em>, 114708. (<a href='https://doi.org/10.1016/j.matdes.2025.114708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pain represents a significant public health challenge with substantial clinical and economic burdens. While pharmacotherapy remains a mainstay of pain management, its utility is limited by adverse side effects and the potential for dependency. Acupuncture has shown great potential in pain management through its ability to induce analgesic effects via acupoint stimulation. However, its poor specificity and ill-defined stimulation parameters compromise therapeutic specificity and reproducibility. Herein, we developed a biomaterial-based acupoint activation strategy for pain management. Adhesive polydopamine-coated hydrogel microspheres were fabricated using microfluidic techniques for accurate attachment and activation of acupoints. Adhesive hydrogel microspheres loaded with adenosine can slowly release exogenous adenosine at the ST36 acupoint to simulate the analgesic effect of acupuncture. In vitro and in vivo studies demonstrated that single-dose administration of adhesive microspheres can effectively target acupoints, elevate mechanical pain thresholds, and provide systemic anti-inflammatory effects for up to 7 days. Overall, the proposed adhesive hydrogel microsphere system offers a new perspective on acupuncture practice and pain management.},
  archive      = {J_MATDES},
  author       = {Xiujuan Li and Zehao Chen and Songgen Chen and Han Wang and Lin Fu and Ban Feng and Hui Chen and Lize Xiong},
  doi          = {10.1016/j.matdes.2025.114708},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114708},
  shortjournal = {Mater. Des.},
  title        = {Adenosine-loaded adhesive microfluidic hydrogel microspheres stimulate acupoint activation for pain management},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Study and characterization of recycled ABS-GF in large format additive manufacturing to enhance mechanical properties of printed structures. <em>MATDES</em>, <em>259</em>, 114707. (<a href='https://doi.org/10.1016/j.matdes.2025.114707'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large format additive manufacturing (LFAM) has proven its ability to produce high-performance components for competitive markets. By depositing material only where it's needed, it drastically reduces waste material and energy use, obtaining a sustainability advantage that is further enhanced on larger scale. However, a deeper understanding of material recycling is critical to achieving the next milestone in sustainability. In this work, a methodology was proposed that uses both molds and final parts, manufactured in acrylonitrile-butadiene-styrene reinforced with short glass fibers (ABS-GF), which had reached the end of their useful life to be used as feedstock. It is observed that recycling reduces fiber length by 47.3%, which directly impacts the mechanical properties in the longitudinal printing direction, resulting in around a 9% decrease in maximum tensile stress. However, this reduction falls to 5.1% in the transverse direction to the printing, and in some cases, the recycled material even surpasses the virgin material due to improved interlayer adhesion. An analysis on the adhesion reveals that the shorter monomer chains obtained during recycling allow better interlacing between layers. These results suggest that the reuse of the molds is viable and by adjusting the printing parameters we can obtain properties suitable for demanding applications.},
  archive      = {J_MATDES},
  author       = {Javier Bas-Bolufer and Pablo Castelló-Pedrero and Cesar García-Gascón and Juan Antonio García-Manrique},
  doi          = {10.1016/j.matdes.2025.114707},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114707},
  shortjournal = {Mater. Des.},
  title        = {Study and characterization of recycled ABS-GF in large format additive manufacturing to enhance mechanical properties of printed structures},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topology optimization of 3D-printed material architectures: Testing toolpath consideration in design. <em>MATDES</em>, <em>259</em>, 114700. (<a href='https://doi.org/10.1016/j.matdes.2025.114700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topology Optimization (TO) methods applied to the design of material architectures allow for a wider exploration of the possible design space when compared to common geometry parameter controlled design methods. These optimal designs are often realized using Direct Ink Writing methods which exhibit characteristic features of discrete bead sizes and weak bead bonding. The resultant lack of design fidelity and toolpath dependent anisotropy has been found to negatively impact structural performance if not accounted for in the design. This paper addresses both characteristics in the design process of cellular material architectures by expanding upon the Nozzle Constrained Topology Optimization algorithm and experimentally validating the results against a typical baseline. An experimental method of deriving bond region material properties is detailed. A direct toolpath generation method from topology optimized results is proposed. Comparisons are made with conventional topology optimization design methods and performance is measured both experimentally and numerically against theoretical bounds. At relative densities ≤ 70 % , designs with nozzle constraints were able to more closely align numerical and experimental results for both performance and design fidelity (measured by relative density). In contrast, conventional topology optimized designs had higher overall performance, but little alignment between intended design and resultant experimental result. Typical designs consistently overdeposited material and inconsistently predicted performance.},
  archive      = {J_MATDES},
  author       = {Hajin Kim-Tackowiak and Josephine V. Carstensen},
  doi          = {10.1016/j.matdes.2025.114700},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114700},
  shortjournal = {Mater. Des.},
  title        = {Topology optimization of 3D-printed material architectures: Testing toolpath consideration in design},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forming-induced thickness effects on structural response of arched thin-shell metal alloys. <em>MATDES</em>, <em>259</em>, 114692. (<a href='https://doi.org/10.1016/j.matdes.2025.114692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the critical influence of forming-induced thickness variations on arched thin-shell metal components' structural response and rupture behavior, a key challenge in safety-critical applications. An integrated predictive framework combines classical plate theory for initial deformation estimates, explicit dynamic finite element simulations for elastic-plastic analysis, and Kriging-based response surface modeling to map geometric, material, and process parameters to performance metrics. A large-scale simulation campaign across eight isotropic material models and 42,669 configurations identifies the arch rise-to-radius ratio as the dominant factor in post-forming thickness evolution, with non-uniform profiles causing up to deviations in rupture pressures and altering failure modes compared to uniform assumptions. Modal, buckling, and rupture analyses highlight significant impacts on natural frequencies, critical loads, and mechanisms. Experimental validation on 36 Monel Alloy 400 rupture discs achieves high accuracy, with thickness root-mean-square error of (maximum mean absolute percentage error ) and rupture pressure errors below , supported by uncertainty analysis (expanded uncertainties at confidence). The generalizable framework, extensible to non-metallic isotropic shells and non-arched geometries, enables enhanced prediction, optimization, and reliability by linking forming outcomes to structural integrity.},
  archive      = {J_MATDES},
  author       = {Shilin Chen and Qingxi Yang and Qingzhou Yu and Genmu Shi and Haotian Yin},
  doi          = {10.1016/j.matdes.2025.114692},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114692},
  shortjournal = {Mater. Des.},
  title        = {Forming-induced thickness effects on structural response of arched thin-shell metal alloys},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond diameters: Decoding fabrication patterns of hierarchical micro-nano titanium implants via anodization and their geometries on region-specific soft-tissue integration. <em>MATDES</em>, <em>259</em>, 114691. (<a href='https://doi.org/10.1016/j.matdes.2025.114691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrochemical anodization creates titania nanopores (TNPs) on Ti implants with distinctive micro-nano geometries to enhance their surface bioactivity, showing the potential to improve soft-tissue integration at varied transmucosal regions. However, understanding how topography regulates TNP dimensions under voltage, and the clinical feasibility of diverse TNP geometries was limited. More crucially, existing research predominantly focused on nanopore diameter, neglecting other geometric characteristics (alignment, texture/roughness) on soft-tissue cells that impeded optimized TNPs design for ideal soft-tissue integration. This study showed nanopore dimensions were voltage-dependent on micro-patterned Ti but remain stable on smooth counterparts. Varied TNPs with similar diameters but different alignment/roughness were selected and identified with similar chemistry/hydrophilicity, but their protein adhesion and stability were length-dependent, showing their feasibility as implant devices. Finally, human gingival fibroblasts (HGFs) and HaCaT epithelial cells functions on varied selected TNPs reflected that nanopores inherently promoted cell responses, but hybrid microgroove-nanopores dramatically enhanced HGF’s collagen and fibronectin secretion, while irregular textured nanopores significantly improved HaCaT adhesion. By addressing the gaps in understanding topographical regulation and the influence of overlooked geometric features beyond diameter, this work advances spatially optimized implant designs for improved epithelial sealing and connective tissue integration at different transmucosal zones for improved implant health.},
  archive      = {J_MATDES},
  author       = {Tianqi Guo and Miaoxuan Dai and Xinxin Ding and Xiaomeng Zhang and Yingxin Gu and Hongchang Lai},
  doi          = {10.1016/j.matdes.2025.114691},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114691},
  shortjournal = {Mater. Des.},
  title        = {Beyond diameters: Decoding fabrication patterns of hierarchical micro-nano titanium implants via anodization and their geometries on region-specific soft-tissue integration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of particle size on powder velocity distribution at the nozzle outlet in directed energy deposition. <em>MATDES</em>, <em>259</em>, 114680. (<a href='https://doi.org/10.1016/j.matdes.2025.114680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal-based Directed Energy Deposition (DED) is considered one of the variations of additive manufacturing with the highest potential, particularly for space industry and in-orbital manufacturing. The technology however still faces various challenges, many of which can be traced back to poor control and understanding of the powder delivery. Velocity distribution of powder particles at the DED nozzle outlet has a key influence on the results of any predictive model of powder stream and yet remains largely disputed. Certain numerical studies highlighted a possible influence of powder particle size on the velocity condition at the nozzle exit, yet no experimental studies confirmed this effect. The experimental campaign described in this paper quantifies this relation between powder particle size and velocity distribution at the nozzle outlet and a strong decrease of particle speed with particle size is observed. Moreover, smaller particles are observed to travel at speeds higher than the mean carrier gas speed suggesting powder particle segregation within the nozzle as one of the mechanisms driving speed differences at the nozzle outlet.},
  archive      = {J_MATDES},
  author       = {Tijan Mede and Andrej Jeromen and Edvard Govekar and Michael Mallon and Matjaž Godec},
  doi          = {10.1016/j.matdes.2025.114680},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114680},
  shortjournal = {Mater. Des.},
  title        = {Influence of particle size on powder velocity distribution at the nozzle outlet in directed energy deposition},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The role of orifice geometry in determining fibre production efficiency in pressurized gyration. <em>MATDES</em>, <em>259</em>, 114670. (<a href='https://doi.org/10.1016/j.matdes.2025.114670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pressurized gyration allows the scaled-up production of polymeric fibre under the simultaneous application of pressure and rotation. This study investigates the influence of orifice design on fibre formation and production rate in pressurized gyration, aiming to optimize the technique for industrial-scale applications. Transparent vessels with varying orifice heights (7.5 mm, 15 mm, and 22.5 mm), orifice numbers (24 and 48), and dual-level orifice distributions were fabricated and tested under pressures of 0.1, 0.2, and 0.3 MPa. Morphological analysis showed that fibre diameter decreased from 2.2 µm to 1.8 µm when pressure was raised from 0.1 to 0.3 MPa when increasing the number of orifices to 48. Two-level orifice designs yielded mixed diameter distributions, enabling tunable fibre architectures. High-speed imaging revealed that the 7.5 mm orifice height achieved fluid ejection 7.5 % faster than 22.5 mm at 0.1 MPa and increasing pressure from 0.1 to 0.2 MPa reduced ejection time by up to 33 %. Production rate increased with more orifices (48 compared to 24), by 9.8 % at 0.2 MPa, and declined at higher pressure for vessels with dual-level designs. Overall, the findings provide quantitative insights into how vessel geometry influences fibre morphology and throughput in pressurized gyration systems.},
  archive      = {J_MATDES},
  author       = {Ahmed Alneyadi and Alexander Smith and Anthony Harker and Mohan Edirisinghe},
  doi          = {10.1016/j.matdes.2025.114670},
  journal      = {Materials & Design},
  month        = {11},
  pages        = {114670},
  shortjournal = {Mater. Des.},
  title        = {The role of orifice geometry in determining fibre production efficiency in pressurized gyration},
  volume       = {259},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="mla">MLA - 6</h2>
<ul>
<li><details>
<summary>
(2025). Structure-aware stable diffusion for traditional architectural decoration design. <em>MLA</em>, <em>22</em>, 100735. (<a href='https://doi.org/10.1016/j.mlwa.2025.100735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intelligent generation of traditional architectural styles faces significant challenges in structural integrity and style consistency. While existing methods can generate numerous realistic images, they lack a deep understanding of structural elements in traditional architectural decorative design. This paper proposes a Structure-aware Stable Diffusion (SSD) model, which enhances the model's comprehension of architectural features through three key innovations. First, we design a structure-aware feature injection module that adaptively fuses extracted architectural structural information with original features during the U-net upsampling phase, enhancing the model's understanding of geometric structures. Second, we introduce a dual-path text enhancement strategy that combines structural descriptions with original descriptions to provide richer textual guidance signals for the generation process. Finally, we design a progressive injection strategy that dynamically controls the injection intensity of structural information through cosine scheduling, ultimately achieving effective internalization of structural knowledge. Experimental results show that compared to existing methods, our model effectively improves both the diversity of generated traditional architectural decorations and the rationality of their structures, thus providing an effective new technical approach for traditional architectural decorative design.},
  archive      = {J_MLA},
  author       = {Jianhong Yang and Guoyong Wang},
  doi          = {10.1016/j.mlwa.2025.100735},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100735},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Structure-aware stable diffusion for traditional architectural decoration design},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature importance analysis of optimized machine learning modeling for predicting customers satisfaction at the united states airlines. <em>MLA</em>, <em>22</em>, 100734. (<a href='https://doi.org/10.1016/j.mlwa.2025.100734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer experience is crucial in the airline industry, as understanding passenger satisfaction helps airlines improve service quality. This study evaluates hyperparameter optimization and feature interpretability in machine learning models for predicting airline passenger satisfaction. Support Vector Machine (SVM) and Multilayer Perceptron (MLP) models were tested for binary classification, labeling passengers as ‘Satisfied’ or ‘Neutral or Dissatisfied’ using a Kaggle dataset with ∼104,000 training and ∼26,000 test records. Hyperparameter tuning used grid search with 10-fold cross-validation. For SVM, the optimal setup included the RBF kernel, C = 10, and gamma = ‘auto’, achieving a mean score of 0.9606. For MLP, the best configuration used no regularization, "he" initialization, ReLU activation, 30 epochs, batch size of 32, two hidden layers with 32 neurons each, and a learning rate of 0.001, yielding a mean score of 0.9556. Performance metrics included accuracy, precision, recall, and F1-Score, with SVM achieving a test accuracy of 0.96, precision of 0.97, and F1-Score of 0.95, slightly outperforming MLP by <1 %, though MLP was faster at 0.3 s versus SVM’s 18 s. Both models surpassed baseline models and prior studies, benefiting from robust preprocessing and a large dataset. Permutation importance analysis identified Type of Travel, Inflight Wi-Fi Service, Customer Type, and Online Boarding as key predictors, emphasizing passenger needs for digital connectivity and personalized services. These insights guide airlines to prioritize reliable Wi-Fi and efficient online boarding to enhance satisfaction, loyalty, and competitive positioning.},
  archive      = {J_MLA},
  author       = {Hamid Mirzahossein and Soheil Rezashoar},
  doi          = {10.1016/j.mlwa.2025.100734},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100734},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Feature importance analysis of optimized machine learning modeling for predicting customers satisfaction at the united states airlines},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformal validation: A deferral policy using uncertainty quantification with a human-in-the-loop for model validation. <em>MLA</em>, <em>22</em>, 100733. (<a href='https://doi.org/10.1016/j.mlwa.2025.100733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Validating performance is a key challenge facing the adoption of machine learning models in high risk applications. Current validation methods assess performance marginally over the entire testing dataset, which can fail to identify regions in the distribution with insufficient performance. In this paper, we propose Conformal Validation, a systems-based approach with a calibrated form of uncertainty quantification using a conformal prediction framework as a part of the validation process to reduce performance gaps. Specifically, the policy defers a subset of observations for which the predictive model is most uncertain and provides a human with informative prediction sets to make the ancillary decision. We evaluate this policy on an image classification task where images are distorted with varying levels of gaussian blur for a quantifiable measure of added difficulty. The model is compared to human performance on the most difficult observations, i.e., those where the model is most uncertain, to simulate the scenario when a human is the alternative decision-maker. We evaluate performance on three arms: the model independently, humans with access to a set of classes the model is most confident in, and humans independently. The deferral policy is simple to understand, applicable to any predictive model, and easy to implement while, in this case, keeping humans in the loop for improved trustworthiness. Conformal Validation incorporates a risk assessment that is conditioned on the prediction set length and can be tuned to the needs of the application.},
  archive      = {J_MLA},
  author       = {Paul Horton and Alexandru Florea and Brandon Stringfield},
  doi          = {10.1016/j.mlwa.2025.100733},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100733},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Conformal validation: A deferral policy using uncertainty quantification with a human-in-the-loop for model validation},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of machine learning technologies in construction maintenance: A strategic analysis. <em>MLA</em>, <em>22</em>, 100731. (<a href='https://doi.org/10.1016/j.mlwa.2025.100731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current predictive maintenance systems in construction rely on static machine learning approaches that fail to adapt to evolving operational environments, achieving only 3%–7% performance improvements over individual models and suffering 15%–25% performance degradation when transferred across domains. This research develops and validates an Adaptive Ensemble Framework that dynamically optimizes algorithm selection through real-time data assessment and performance feedback. The framework’s meta-learning architecture continuously adapts ensemble weights using data complexity measures, temporal pattern analysis, and uncertainty quantification metrics. Unlike static approaches, the system integrates scikit-learn and TensorFlow models through dynamic optimization algorithms that respond to changing conditions without manual reconfiguration. The framework provides uncertainty-aware predictions with confidence intervals essential for safety-critical construction decisions. Comprehensive evaluation across four industries using 50,000+ maintenance records from major construction firms demonstrates substantial improvements. The adaptive ensemble achieves F1-score of 0.934 in construction delay prediction, representing 15.3% improvement over individual models and 8.7% enhancement over static ensembles. Cross-industry validation reveals successful knowledge transfer with minimal performance degradation ( < 5%). This research contributes three scholarly advances: (i) the first real-time adaptive ensemble framework eliminating manual hyperparameter tuning, (ii) uncertainty quantification mechanisms for safety-critical applications, and (iii) robust cross-industry transferability through systematic domain adaptation. The framework extends beyond construction to manufacturing, energy, and transportation sectors, demonstrating computational efficiency with sub-100ms latency and linear scaling characteristics. These contributions establish new benchmarks for adaptive machine learning in industrial predictive maintenance.},
  archive      = {J_MLA},
  author       = {Assane Lo and Aysha Alshehhi},
  doi          = {10.1016/j.mlwa.2025.100731},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100731},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Implementation of machine learning technologies in construction maintenance: A strategic analysis},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine-learning based li-ion cell state prediction using impedance spectroscopy. <em>MLA</em>, <em>22</em>, 100729. (<a href='https://doi.org/10.1016/j.mlwa.2025.100729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable monitoring of battery state parameters is crucial for ensuring optimal battery performance, safety, and lifetime. Existing methods have limitations, such as requiring modeling of each degradation mechanism involved or relying on direct measurement techniques that impose restrictions on field studies or end-user use. In this paper, we propose a machine learning-based approach that combines the strengths of electrochemical impedance spectroscopy (EIS) and machine learning algorithms to predict battery state parameters. We have developed an efficient prediction system that can learn from EIS data and accurately predict battery state parameters. Our approach is trained on an open dataset comprising of over 30,000 spectra, generated using an automated measurement technique that outperforms current machine learning-based models, particularly in terms of generalization across different cells and measurement setups.},
  archive      = {J_MLA},
  author       = {Carl Philipp Klemm and Till Frömling},
  doi          = {10.1016/j.mlwa.2025.100729},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100729},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine-learning based li-ion cell state prediction using impedance spectroscopy},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the latent distribution of logistic regression — An empirical study on spectroscopic profiling datasets. <em>MLA</em>, <em>22</em>, 100712. (<a href='https://doi.org/10.1016/j.mlwa.2025.100712'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logistic regression is a simple yet widely used classification model in spectroscopic profiling analysis. Considering the model’s output represents a probability, this paper will investigate its latent distribution assumption, i.e., its inner linear regressor unit follows a standard logistic distribution. An empirical study on five spectroscopic profiling open datasets, i.e., wine, coffee, olive oil, cheese, and milk powder, was conducted to verify this latent distribution assertion. This paper measured the GoF (Goodness of Fit) of each dataset’s latent variable from three aspects, i.e., curve fitting, P–P and Q–Q plots, and K–S test. After hyper-parameter optimization and proper training, the latent variable, as a weighted sum of the original features, has demonstrated a high level of GoF on all the five datasets. This study verifies the suitability of logistic regression in spectroscopic profiling analysis and answers why the model output can be interpreted as a conditional probability.},
  archive      = {J_MLA},
  author       = {Yinsheng Zhang and Mingming He and Haiyan Wang},
  doi          = {10.1016/j.mlwa.2025.100712},
  journal      = {Machine Learning with Applications},
  month        = {12},
  pages        = {100712},
  shortjournal = {Mach. Learn. Appl.},
  title        = {On the latent distribution of logistic regression — An empirical study on spectroscopic profiling datasets},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="neucom">NEUCOM - 78</h2>
<ul>
<li><details>
<summary>
(2025). Predicting nonlinear dynamic systems by causal physics-informed neural networks with ResNet blocks. <em>NEUCOM</em>, <em>656</em>, 131589. (<a href='https://doi.org/10.1016/j.neucom.2025.131589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of data computational science, the prediction of nonlinear systems has provided effective support for investigating complex problems in the field of natural sciences. Physics-Informed Neural Networks (PINNs) are playing an increasingly prominent role in nonlinear system prediction. Although PINNs have been widely applied across various engineering domains, their utilization in chaotic system prediction remains notably scarce. This paper proposes a novel causal PINNs framework integrated with ResNet blocks. On the one hand, the framework incorporates temporal weighting into the residual loss, utilizing maximum temporal weight as the training termination criterion. Additionally, an annealing strategy is adopted to adaptively adjust the causal parameters, ensuring that the model adheres to physical causality constraints throughout the training process. On the other hand, the framework employs a ResNet-block-based network, which transforms identity mappings into residual mappings. This architectural design significantly enhances training stability when utilizing deep networks. To validate the performance of the proposed method, numerical experiments are conducted on the Lorenz system, Dadras system, and Kuramoto-Sivashinsky equation. The results demonstrate that the causal PINNs with ResNet blocks significantly outperform conventional PINNs in predicting chaotic systems.},
  archive      = {J_NEUCOM},
  author       = {Man-Hong Fan and Jun-Hao Zhao and Lin Ding and Xiao-Ying Ma and Rui-Lin Fu},
  doi          = {10.1016/j.neucom.2025.131589},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131589},
  shortjournal = {Neurocomputing},
  title        = {Predicting nonlinear dynamic systems by causal physics-informed neural networks with ResNet blocks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-stream diffusion graph convolutional model with adaptive motion-aware attention and self-supervised pretraining for continuous sign language recognition. <em>NEUCOM</em>, <em>656</em>, 131567. (<a href='https://doi.org/10.1016/j.neucom.2025.131567'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous Sign Language Recognition (CSLR) requires capturing both spatial and temporal dependencies to accurately model sign sequences. To enhance CSLR performance, we propose a Multi-Stream Diffusion Graph Convolution Network (MSD-GCN) from input skeleton data that introduces three key innovations. First, Adaptive Motion-aware Graph Convolution with Bi-level Attention (AMGC-BA) dynamically refines joint connectivity by leveraging semantic motion correlations, improving robustness to signer variations, and enhancing long-term dependencies. Second, signal-enhanced multi-stream representation learning integrates advanced signal processing techniques, including the Adaptive Ridgelet Transform (ART) for pose representation, Variational Mode Decomposition (VMD) for motion decomposition, and Empirical Wavelet Transform (EWT) for contextual feature extraction, ensuring feature robustness, reducing noise, and improving discriminability. Third, self-supervised pretraining leverages contrastive learning, graph reconstruction, and cross-stream feature alignment to mitigate data scarcity, enhance domain adaptation, and improve representation learning. These innovations enable the proposed graph to effectively capture complex motion patterns, distinguish between critical and redundant gestures, and generalize well across diverse signers and datasets. By improving recognition accuracy, robustness, and adaptability, the proposed approach provides a significant advancement in CSLR, addressing the challenges of signer variability, limited labeled data, and the need for fine-grained motion representation. Results on three datasets confirm the superiority of the proposed model compared to 35 comparative models. To the best of our knowledge, this is the first study in CSLR to employ such an extensive range of comparative models for performance evaluation.},
  archive      = {J_NEUCOM},
  author       = {Razieh Rastgoo},
  doi          = {10.1016/j.neucom.2025.131567},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131567},
  shortjournal = {Neurocomputing},
  title        = {A multi-stream diffusion graph convolutional model with adaptive motion-aware attention and self-supervised pretraining for continuous sign language recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGFCNN: A synergistic framework integrating graph-based spatial filter and lightweight CNN for SSVEP recognition. <em>NEUCOM</em>, <em>656</em>, 131561. (<a href='https://doi.org/10.1016/j.neucom.2025.131561'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing the feature representation and decoding efficiency of the steady-state visual evoked potentials (SSVEPs) is critical to enhancing the performance of neural signal decoding systems. Current deep learning models often overlook the physical topological information of EEG channels, resulting in suboptimal feature extraction and limited recognition performance. To address these challenges, this study proposes a synergistically designed SSVEP recognition framework to alleviate data insufficiency, improve the feature representation, and enhance decoding efficiency. Specifically, a slicing-and-scaling technique is adopted to improve the model generalization under limited-sample scenarios. A graph-based spatial filter leverages the topological relationships among EEG channels to suppress redundant information and enhance spatial feature quality. A lightweight convolutional neural network (CNN) with fewer parameters is developed to efficiently extract discriminative temporal–spatial features for accurate SSVEP classification. Experimental results on two public benchmark datasets and one self-collected dataset demonstrate that the proposed framework outperforms baseline deep learning models, yielding improvements of at least 6.8 %, 8.5 %, and 0.5 % in peak average classification accuracy, respectively. The maximum average information transfer rates (ITRs) achieved on the three datasets were 221.4 bits/min ,106.7 bits/min , and 133.9 bits/min , respectively. By simultaneously reducing model complexity and improving decoding performance, the proposed framework offers an effective and promising approach for efficient neural signal decoding in SSVEP recognition.},
  archive      = {J_NEUCOM},
  author       = {Rui Ma and Yu Cao and Sheng Quan Xie and Mingming Zhang and Jun Li and Zhi-Qiang Zhang},
  doi          = {10.1016/j.neucom.2025.131561},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131561},
  shortjournal = {Neurocomputing},
  title        = {LGFCNN: A synergistic framework integrating graph-based spatial filter and lightweight CNN for SSVEP recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double missing multi-view multi-label classification via an attention-guided multi-space consistency alignment framework. <em>NEUCOM</em>, <em>656</em>, 131558. (<a href='https://doi.org/10.1016/j.neucom.2025.131558'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view multi-label classification (MVMLC) seeks to enhance classification by integrating diverse data views, but its practical use is hindered by missing views and labels, posing the significant challenge of incomplete MVMLC(IMVMLC). Although various IMVMLC approaches have been proposed, most of them handle multiple objectives in a single feature space and thus overlook the conflict between learning consistent common semantics and reconstructing view-specific information. In addition, existing multi-view classification methods mainly consider utilizing the features of each view, while ignoring the inconsistent contributions of each view and usually relying on static average weighting strategies. To this end, we propose our Attention-Guided MultiSpace Consistency Alignment Framework (AMCA). In Stage 1, AMCA introduces multi-space representation learning with dual-level contrastive objectives, explicitly disentangling shared and view-specific semantics to resolve the objective conflict and yield more informative embeddings. In Stage 2, AMCA employs an attention-guided fusion module that dynamically evaluates and integrates multi-view features based on their relevance to the classification task, enabling robust decision-making even with missing data. Extensive experiments validate the effectiveness and superiority of our proposal.},
  archive      = {J_NEUCOM},
  author       = {Bingyan Nie and Wulin Xie and Lian Zhao and Jiang Long and Xiaohuan Lu and Yinghao Ye},
  doi          = {10.1016/j.neucom.2025.131558},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131558},
  shortjournal = {Neurocomputing},
  title        = {Double missing multi-view multi-label classification via an attention-guided multi-space consistency alignment framework},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end transformer-based detection with density-guided query selection for small objects. <em>NEUCOM</em>, <em>656</em>, 131554. (<a href='https://doi.org/10.1016/j.neucom.2025.131554'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small object detection remains a persistent challenge in transformer-based detectors due to their limited localization precision and reliance on fixed query mechanisms. In this paper, we propose Hybrid Density-Transformer (HyDeTr), a novel transformer-based object detection framework designed to improve the detection of small and densely packed objects with only a slight trade-off in inference complexity. HyDeTr introduces several key innovations: (1) a Context-Selective Hybrid Attention Encoder (CS-HAE) that distills global context from low-resolution features through efficient kernelized attention while preserving local detail via deformable attention on higher-resolution maps; (2) a Density Map Prediction module that generates a spatial prior highlighting high-object-density regions, facilitating focus on crowded scenes; (3) a Density-Guided Uncertainty-Minimal Query Selection strategy that identifies the most informative query locations based on both classification confidence and predicted density, ensuring that even low-confidence small objects in dense areas are effectively queried; and (4) an improved Query Formulation with dual embeddings, consisting of a content embedding and a 4D anchor box, refined iteratively by the decoder. Our design enables precise, density-aware query initialization and scale adaptation, leading to improved recall and accuracy for small objects. Extensive evaluations demonstrate that HyDeTr outperforms existing methods in detecting small objects, offering significant accuracy gains with only a modest increase in inference complexity, thereby maintaining near real-time performance and full end-to-end trainability.},
  archive      = {J_NEUCOM},
  author       = {Nguyen Hoanh and Tran Vu Pham},
  doi          = {10.1016/j.neucom.2025.131554},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131554},
  shortjournal = {Neurocomputing},
  title        = {End-to-end transformer-based detection with density-guided query selection for small objects},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel dynamic sparse graph attention framework for cross-domain intelligent diagnosis of rotating machinery. <em>NEUCOM</em>, <em>656</em>, 131553. (<a href='https://doi.org/10.1016/j.neucom.2025.131553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mechanical equipment prognostics, conventional graph neural networks encounter significant limitations when processing high-dimensional dynamic sensor data: inadequate modeling of complex feature interdependencies, insufficient sensitivity to transient fault signatures, and ineffective knowledge transfer in cross-domain applications. To overcome these challenges, we present a DSGA-SAGE, which stands for Dynamic Sparse Graph Attention - SAmpling and aGgrEgation framework. Our approach presents innovations in three aspects: (1) A decentralized graph construction paradigm establishes dynamic associations among multivariate time-series features, enabling precise identification of critical fault patterns through adaptive node-edge interactions. (2) A sparse attention mechanism with trainable topology constraints optimizes the structural weights of graph in the real-time scenarios, achieving 23 % overhead computational reduction while maintaining the accuracy of feature discriminability. (3) A unified cross-domain learning strategy synchronizes multi-condition knowledge transfer through hierarchical loss optimization, ensuring robust generalization across various operational scenarios. Extensive experiments on five industrial datasets demonstrate state-of-the-art performance: achieving the highest accuracy of 96.29 % in fault diagnosis, while realizing 99.87 % Macro-F1 and 99.88 % Micro-F1 scores in cross-domain tasks. Through a comprehensive performance analysis, the superiority of the efficiency and cross-domain adaptability in dynamic sparse graph attention mechanism has been convincingly validated.},
  archive      = {J_NEUCOM},
  author       = {Ying Xie and Jixiang Wang and Zhiqiang Xu and Junnan Shen and Lijie Wen and Rongbin Xu and Yun Yang},
  doi          = {10.1016/j.neucom.2025.131553},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131553},
  shortjournal = {Neurocomputing},
  title        = {A novel dynamic sparse graph attention framework for cross-domain intelligent diagnosis of rotating machinery},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A collaborative decision framework for dynamic control of gear remaining useful life using multi-source information in active health management. <em>NEUCOM</em>, <em>656</em>, 131536. (<a href='https://doi.org/10.1016/j.neucom.2025.131536'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing demand for intelligent operation and maintenance of vertical mill gearboxes in the cement industry, traditional passive maintenance methods are increasingly inadequate for supporting efficient, proactive management under complex operational conditions. In particular, sudden gear failures often result in unplanned downtime, causing significant economic losses. To address this challenge, this paper proposes a dynamic control approach for gear remaining useful life (RUL) that integrates multi-source information through collaborative decision-making to enable active health management. First, a novel RUL prediction method based on multilevel multi-source domain adaptation (MMDA) is proposed to enhance the generalization capability of the model. By minimizing discrepancies between local and global feature distributions under varying working conditions and aligning the prediction boundaries among predictors, the proposed method achieves accurate RUL predictions. Then, a gear RUL dynamic control method based on multi-information collaborative decision-making is developed. This method dynamically regulates gear RUL using a model-free adaptive control (MFAC) strategy, leveraging multi-source information such as online RUL prediction results, expected usage duration, and real-time working conditions. Finally, a collaborative decision framework for dynamic control of gear RUL is proposed, which enables active gear health management to be implemented, thereby minimizing unscheduled downtime. The effectiveness of the proposed gear RUL dynamic control method is validated on a self-made gear transmission system experimental platform, achieving a 27.6 % reduction in average RMSE compared with state-of-the-art baselines and extending the operational life of gear by approximately 61 h under dynamic control.},
  archive      = {J_NEUCOM},
  author       = {Xuegang Li and Yuanyue Pu and Nian Wu and Huajun Cao and Xiaoxi Ding and Wenbin Huang},
  doi          = {10.1016/j.neucom.2025.131536},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131536},
  shortjournal = {Neurocomputing},
  title        = {A collaborative decision framework for dynamic control of gear remaining useful life using multi-source information in active health management},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A prototype-guided federated learning based fault diagnosis method of mechanical transmission system under label distribution skew. <em>NEUCOM</em>, <em>656</em>, 131532. (<a href='https://doi.org/10.1016/j.neucom.2025.131532'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the label distribution skew in federated learning based mechanical fault diagnosis, a federated learning based diagnosis framework combining prototypes and hybrid classifier is proposed. Firstly, prototypes are constructed based on sample feature means, and an exponential moving average strategy is introduced to smooth the aggregation of prototypes across rounds, while the prototype constraint loss function is constructed to guide the convergence of client features to the global prototype and compress the distance between similar samples. Secondly, a hybrid classifier architecture combining a local classifier with a global prototype classifier is proposed to learn local feature and global class prototypes through a two-branch structure, and a dynamic weighting strategy is used to achieve the output fusion. Finally, a prototype separation strategy is introduced on the server side, which detects pairs of confused class prototypes by Euclidean distance, increases the distance between similar prototypes, and avoids the prototype overlapping issue. In order to verify the effectiveness of the proposed method, nine kinds of faults of bearings, rotors and gears in mechanical transmission system are fabricated, and four types of fault diagnosis experiments with different degrees of label skew are designed, and the results show that the proposed method can effectively identify all the fault classes, and it still achieves an accuracy of 91.00 % in the extreme distribution skew task, which is significantly better than the other comparative methods, which provides a new feasible way for the distributed data driven federated learning based intelligent mechanical fault diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Hongwei Fan and Shenglin Liu and Xiangang Cao and Xuhui Zhang},
  doi          = {10.1016/j.neucom.2025.131532},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131532},
  shortjournal = {Neurocomputing},
  title        = {A prototype-guided federated learning based fault diagnosis method of mechanical transmission system under label distribution skew},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A predefined-time double-integral zeroing neural network model for linear equations flows and its application on dynamic position. <em>NEUCOM</em>, <em>656</em>, 131531. (<a href='https://doi.org/10.1016/j.neucom.2025.131531'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving time-varying linear equation flows presents a significant challenge in dynamic systems due to the continuously evolving coefficients, which undermine the effectiveness of traditional numerical methods. Moreover, the presence of external noise further exacerbates the difficulty of obtaining accurate solutions. To address these issues, this paper proposes a predefined-time double-integral zeroing neural network (PTDIZNN) model, inspired by the enhanced robustness of the conventional DIZNN framework. Specifically, a novel time-based gain is incorporated into the design of the DIZNN, ensuring predefined-time convergence of the proposed PTDIZNN model. A comprehensive theoretical analysis is conducted to verify its stability, convergence, and robustness properties. Furthermore, comparative simulations demonstrate that the PTDIZNN outperforms existing models in terms of solution accuracy and robustness under both column-full-rank and square-array coefficient scenarios. Finally, the effectiveness of the PTDIZNN is verified through its successful application in dynamic target positioning, highlighting its potential for broader real-time applications.},
  archive      = {J_NEUCOM},
  author       = {Jialiang Chen and Linju Li and Lin Xiao},
  doi          = {10.1016/j.neucom.2025.131531},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131531},
  shortjournal = {Neurocomputing},
  title        = {A predefined-time double-integral zeroing neural network model for linear equations flows and its application on dynamic position},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAFE-TAP: Semantic-aware and fused embedding for TAP rule security detection. <em>NEUCOM</em>, <em>656</em>, 131529. (<a href='https://doi.org/10.1016/j.neucom.2025.131529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trigger-Action Programming (TAP) has emerged as a widely adopted paradigm for enabling automated interoperability among IoT devices. Despite its convenience, TAP introduces significant security vulnerabilities. To address this issue, we propose SAFE-TAP, a novel framework for detecting malicious TAP rules that integrates global semantic understanding with temporal feature analysis. To further enhance the detection performance, we introduce an innovative data augmentation strategy that leverages Large Language Models (LLMs) to generate semantically consistent rule variations. This approach improves data set balance and enhances the generalizability of the model. Experimental results demonstrate that SAFE-TAP outperforms baseline methods, and the incorporation of LLM-based data augmentation significantly improves detection performance under imbalanced data scenarios.},
  archive      = {J_NEUCOM},
  author       = {Zhejun Kuang and Yusheng Zhu and Dawen Sun and Jian Zhao and Yongheng Xing and Feng Wang and Lei Sun},
  doi          = {10.1016/j.neucom.2025.131529},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131529},
  shortjournal = {Neurocomputing},
  title        = {SAFE-TAP: Semantic-aware and fused embedding for TAP rule security detection},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The framework and memristive circuit design for attention-regulated working memory. <em>NEUCOM</em>, <em>656</em>, 131525. (<a href='https://doi.org/10.1016/j.neucom.2025.131525'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive behavior and decision-making depend on constantly selecting relevant information from the external environment and internal states. Inspired by the working memory structure and the top-down and bottom-up attention mechanisms in cognitive neuroscience, this work proposes an attention-regulated working memory model. This model provides a brain-inspired approach to integrate perception, long-term memory, and action. It processes current external multisensory stimuli and retrieves stored knowledge from internal reinforcement simultaneously, leading to adaptive and rapid executive actions. On this basis, a memristive circuit is designed to realize rich cognitive functions in an online in-situ learning and in-memory computing manner. The designed circuit consists of four main components: (1) the phonological loop and visuospatial sketchpad consider different audio-visual input patterns and varying stimulus salience, realizing the filtration, synchronization, and encoding of multimodal signals; (2) the attention control module captures and maintains attention driven by multisensory stimulation; (3) the episodic buffer achieves reward reinforcement, forming or resetting the top-down attentional bias signal; (4) the central executive control module regulates the relationships between the two attentional pathways, thus transforming the random exploration process into a learnable final action. Finally, simulation results in LTSPICE demonstrate that our circuit can be adaptively applied to the cognitive control and execution system of robots within complicated circumstances.},
  archive      = {J_NEUCOM},
  author       = {Jihong Zhang and Xiaoping Wang and Zhanfei Chen and Chao Yang},
  doi          = {10.1016/j.neucom.2025.131525},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131525},
  shortjournal = {Neurocomputing},
  title        = {The framework and memristive circuit design for attention-regulated working memory},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A temporally coded multilayer spiking neural network and its memristor-based hardware implementation. <em>NEUCOM</em>, <em>656</em>, 131523. (<a href='https://doi.org/10.1016/j.neucom.2025.131523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) have demonstrated remarkable progress in various domains. However, ANNs suffer from enormous time and energy consumption during training and inference processes. Brain-inspired spiking neural networks (SNNs) have recently attracted more attention due to their higher biological plausibility and potential cost-efficient properties. However, most existing SNNs significantly degrade in performance and efficiency when simulated on conventional CPU/GPU hardware. Therefore, a novel temporally coded multilayer SNN (TMSNN) is proposed in this study. It is a typical event-driven model, which encodes information in the relative timing of spikes rather than in firing rates and uses the leaky integrate-and-fire neuron as the basic unit to pursue high biological plausibility. Its multilayer architecture enables the model to solve complicated problems effectively. On the other hand, the proposed TMSNN can be implemented on memristor-based hardware, which uses customized weight quantization and sharing techniques to mitigate the size restrictions of the memristor crossbars. After refining the weights using the simulated annealing algorithm, the hardware implementation of TMSNN can achieve very competitive performance on benchmark datasets, outperforming state-of-the-art temporally coded SNNs in our experiments. The source code of TMSNN is available at https://github.com/jhc050998/Memristor-Crossbar-Based-SNN .},
  archive      = {J_NEUCOM},
  author       = {Haochang Jin and Xiuzhi Yang and Shuangbao Song and Zhenyu Song and Junkai Ji},
  doi          = {10.1016/j.neucom.2025.131523},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131523},
  shortjournal = {Neurocomputing},
  title        = {A temporally coded multilayer spiking neural network and its memristor-based hardware implementation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential extended dissipative synchronization control of Cohen–Grossberg neural networks with four kinds of time-varying delays. <em>NEUCOM</em>, <em>656</em>, 131522. (<a href='https://doi.org/10.1016/j.neucom.2025.131522'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the exponential extended dissipative synchronization control problem of Cohen–Grossberg neural networks (CGNNs) with four kinds of time-varying delays. The types of delays involve time-varying leakage, neutral, distributed and transmission delays. Due to the increasing complexity of control requirements and time delays in practice, some performance analysis approaches and techniques cannot be directly applied, or are faced with the problem of high computational complexity. To this end, a more general and computationally efficient novel method is proposed. Firstly, a sufficient condition to guarantee the existence and uniqueness of the solution of CGNN is presented by defining a new norm, and a representation of the unique solution is first put forward. Then, the state-feedback controller and novel system solutions-based inequality are constructed to obtain exponential extended dissipative synchronization criteria. This proposed approach overcomes the difficulty of constructing a suitable Lyapunov–Krasovskii functional (LKF) under complex time delays and control requirements, and reduces computational complexity. Furthermore, to solve the nonlinear terms in the obtained criteria, an algorithm is designed. Finally, the derived results are validated for feasibility by three numerical examples, and their potential applications in image processing are showcased.},
  archive      = {J_NEUCOM},
  author       = {Kairong Tu and Yu Xue},
  doi          = {10.1016/j.neucom.2025.131522},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131522},
  shortjournal = {Neurocomputing},
  title        = {Exponential extended dissipative synchronization control of Cohen–Grossberg neural networks with four kinds of time-varying delays},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MLFork: Bearing fault diagnosis via mamba-powered few-shot learning model with multi-level architecture enhanced by spatial-wise and channel-wise local vector attention. <em>NEUCOM</em>, <em>656</em>, 131518. (<a href='https://doi.org/10.1016/j.neucom.2025.131518'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearings are one of the most important components of electrical machines and devices; however, they are prone to damage, leading to the lack of safety and the malfunction of machines. Some methods including deep-learning ones can be used for bearing fault diagnosis; however, in reality, the models have to adapt to the shortage of training data from clients while still maintaining good performance. To overcome this issue, the novel “MLFork” model is proposed, following the Few-shot algorithm for limited training with improvements in the feature extraction and the pre-classification steps. For feature extraction, a new Bi-Context Visual State Space Block is introduced, which excellently learns the global context of the sample in multiple ways. Before the Multi-Level classification module, separate routes for spatial-wise and channel-wise local vector attention are used to highlight the important details of the local descriptor. To evaluate the performance of the model, various experiments were done on the Case Western Reserve University dataset (CWRU) and the Paderborn University dataset (PU), where the “MLFork" model showed promising results. The code for this model will be available at: https://github.com/thzhere/MLFork .},
  archive      = {J_NEUCOM},
  author       = {Duy-Thai Nguyen and Van-Quoc-Viet Nguyen and Thi-Thao Tran and Van-Truong Pham},
  doi          = {10.1016/j.neucom.2025.131518},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131518},
  shortjournal = {Neurocomputing},
  title        = {MLFork: Bearing fault diagnosis via mamba-powered few-shot learning model with multi-level architecture enhanced by spatial-wise and channel-wise local vector attention},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). All-in-one image restoration via diffusion models with degradation perception and semantic enhancement. <em>NEUCOM</em>, <em>656</em>, 131517. (<a href='https://doi.org/10.1016/j.neucom.2025.131517'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration is a fundamental task in computer vision. However, most existing methods are tailored for single-degradation scenarios, limiting their applicability in real-world conditions where multiple degradations often co-occur. To address this issue, we propose a degradation-aware image restoration framework. A bidirectional Mamba module is introduced to process fused spatial-frequency features, enabling accurate identification of degradation types via a multi-degradation encoding strategy. Based on the predicted degradation, a fine-tuned CLIP model with an attention mechanism is employed to extract semantic features. These features are then integrated with degradation representations and fed into a conditional denoising diffusion model to progressively reconstruct high-quality images. To facilitate evaluation, we construct the Multi-Degradation Perception Dataset (MDPD), specifically designed for complex degradation scenarios. Experimental results demonstrate that our method achieves over 98 % classification accuracy in identifying degradation types. On the MDPD dataset, it achieves a PSNR of 36.25 dB and improves SSIM by 0.01 to 0.04 across various degradation combinations.},
  archive      = {J_NEUCOM},
  author       = {Jiangang Jiang and Zhe Chen and Yuxin Su and Pancheng Zhang and Yihui Hu},
  doi          = {10.1016/j.neucom.2025.131517},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131517},
  shortjournal = {Neurocomputing},
  title        = {All-in-one image restoration via diffusion models with degradation perception and semantic enhancement},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural operator-based composite learning adaptive backstepping control for linear 2×2 hyperbolic PDE systems. <em>NEUCOM</em>, <em>656</em>, 131516. (<a href='https://doi.org/10.1016/j.neucom.2025.131516'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel neural operator (NO)-based composite learning adaptive backstepping control scheme for stabilizing uncertain linear 2 × 2 hyperbolic PDE systems. This method addresses key challenges arising from complex PDE dynamics, model uncertainties, and high computational costs, within a backstepping design framework. Our approach integrates two main components: 1) A composite learning adaptive controller, which combines both historical and real-time data to construct informative matrices for parameter updates. This strategy enables accurate and exponential parameter convergence under finite excitation (FE) conditions, thereby improving transient performance and guaranteeing exponential system stability. 2) An efficient NO-based approximation method, where a deep operator network (DeepONet) is trained to approximate the nonlinear mapping from composite parameter estimates to backstepping kernel gains. The controller is constructed using the approximate kernels, which eliminates the need to repeatedly solve kernel PDE online, significantly improving the computational efficiency and accelerating real-time control. Furthermore, theoretical analysis proves closed-loop boundedness and exponential stability under the proposed scheme. Numerical simulations verify its effectiveness and superiority.},
  archive      = {J_NEUCOM},
  author       = {Xianhe Zhang and Yu Xiao and Xiaodong Xu and Biao Luo and Weihua Gui and Tingwen Huang},
  doi          = {10.1016/j.neucom.2025.131516},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131516},
  shortjournal = {Neurocomputing},
  title        = {Neural operator-based composite learning adaptive backstepping control for linear 2×2 hyperbolic PDE systems},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RAG-LER: Ranking adapted generation with language-model enabled regulation. <em>NEUCOM</em>, <em>656</em>, 131514. (<a href='https://doi.org/10.1016/j.neucom.2025.131514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have demonstrated impressive capabilities across diverse NLP tasks, yet they still struggle with hallucination due to limited parametric knowledge. Retrieval Augmented Generation (RAG) addresses this issue by integrating non-parametric data stores. However, straightforward integration of information retrieval or end-to-end training of these components often leads to suboptimal results or computational inefficiency. In this work, we introduce RAG-LER, a framework that enhances an LM’s context understanding and improves the quality and accuracy of provided passages through an LM-supervised re-ranker. RAG-LER fine-tunes a pre-trained LM to follow instructions and discriminately use provided information. It then leverages this fine-tuned LM to generate ranking scores, which serve as supervised labels for training the re-ranker. We also introduce a confidence-weighted objective that filters unreliable LLM supervision signals while preserving the original re-ranker capabilities. By harnessing LLMs’ strong capabilities, our approach eliminates the need for manual human labeling in re-ranker training while achieving improved performance. Experiments demonstrate that RAG-LER outperforms existing retrieval-augmented LMs on open-domain QA and fact-checking tasks, while exhibiting consistently improved performance when applied to different retrieval methods, highlighting its versatility and effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Fengwen Zhai and Wenyang Tang and Jing Jin},
  doi          = {10.1016/j.neucom.2025.131514},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131514},
  shortjournal = {Neurocomputing},
  title        = {RAG-LER: Ranking adapted generation with language-model enabled regulation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental algorithms on low-rank approximation of large-scale kernel matrices based on perturbation of invariant subspaces. <em>NEUCOM</em>, <em>656</em>, 131512. (<a href='https://doi.org/10.1016/j.neucom.2025.131512'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel methods are one of the most commonly used techniques in machine learning. In Mitz and Shkolnisky (2022) [27] , a framework of perturbation-based kernel matrix approximation is proposed, which is based on the tool of matrix perturbation analysis. However, there are two shortcomings in this framework. First, it requires that some dominant eigenvalues of kernel matrices are distinct in theory. However, in practical applications, when using a randomly sampled dataset, some kernel matrices generated by certain kernel functions are prone to having multiple eigenvalues due to data distribution or parameter settings. Second, from the algorithmic perspective, one has to know the error matrix of the kernel matrix in advance, which is unrealistic for real-world applications. Thus, the most common situation in practical applications is to pay attention to the case of multiple eigenvalues, and it is interesting to generalize the original perturbation-based kernel approximation framework to the scenario where there are multiple eigenvalues. In this work, we present a perturbation result on eigenvalues and eigenspaces of a kernel matrix whose dominant eigenvalues can be multiple. Based on this result, we propose a low-rank approximation to kernel matrix. On the other hand, as far as we are aware, efficient algorithms are still lacking for updating large-scale kernel matrices, and there are few algorithms addressing batch-incremental kernel methods. Based on our proposed truncated formula, we consider the incremental problem of large-scale kernel matrices and propose two incremental algorithms for updating large-scale kernel matrices. Numerical experiments demonstrate the efficiency of the proposed algorithms for solving incremental data problems and incremental kernel ridge regression.},
  archive      = {J_NEUCOM},
  author       = {Xiaxin Li and Gang Wu},
  doi          = {10.1016/j.neucom.2025.131512},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131512},
  shortjournal = {Neurocomputing},
  title        = {Incremental algorithms on low-rank approximation of large-scale kernel matrices based on perturbation of invariant subspaces},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FMSF: Future-preference modeling with similar-user features for next POI recommendation. <em>NEUCOM</em>, <em>656</em>, 131511. (<a href='https://doi.org/10.1016/j.neucom.2025.131511'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abundant user check-in records in location-based social networks enhance the development of point-of-interest (POI) recommendation systems. The existing studies attempt to learn users’ past, current, and future preferences from their own sequential behaviors. Various approaches have been explored to model user visiting behaviors for the prediction of future preferences and have achieved considerable performance. However, most previous work ignores the impact of other users’ preferences on the prediction of current users’ future preferences. Thus, this work proposes a novel Future-preference Modeling with Similar-user Features (FMSF) model for next POI recommendation. It integrates the preferences of a user and those of other users to accurately model his/her multi-step future preferences. Specifically, it adopts a dynamically-updated similarity matrix to extract the information of similar users. Then, it incorporates an attention mechanism to assign distinct attention weights to the characteristics of both the current and similar users, which promotes the prediction of the future preferences of the current users. Therefore, the method proposed in this paper can offer users more precise recommendation results. Extensive experiments are conducted on three real-world datasets, which demonstrate the advantages of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Luan and Zhichao Feng and Liang Qi and Xiaoyu Sean Lu},
  doi          = {10.1016/j.neucom.2025.131511},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131511},
  shortjournal = {Neurocomputing},
  title        = {FMSF: Future-preference modeling with similar-user features for next POI recommendation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Permutation XOR cellular automata and direct stable periodic orbits. <em>NEUCOM</em>, <em>656</em>, 131510. (<a href='https://doi.org/10.1016/j.neucom.2025.131510'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a permutation XOR cellular automaton (PXCA), a simple three-layer discrete-time dynamical system. The input-to-hidden layer corresponds to an elementary cellular automaton of the XOR rule and the hidden-to-output layer is the shift-type one-to-one permutation connection. The dynamics are described by an autonomous difference equation of binary state variables. Depending on the permutation connection, the PXCA generates a variety of direct stable periodic orbits (DBPOs) characterized by strong stability and fast transient phenomena. As a main result, we provide theoretical evidence that clarifies the number, period, and stability of DBPOs for general odd-dimensional PXCAs. Performing a precise numerical analysis, we have clarified that, depending on the dimension and a parameter, the period of DBPOs varies complicatedly and can become very long. Applications of the DBPOs include time series approximation and switching circuit control. As a fundamental step toward the applications, we present a simple FPGA based hardware prototype and have confirmed typical DBPOs experimentally.},
  archive      = {J_NEUCOM},
  author       = {Mikito Onuki and Yosuke Suzuki and Toshimichi Saito},
  doi          = {10.1016/j.neucom.2025.131510},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131510},
  shortjournal = {Neurocomputing},
  title        = {Permutation XOR cellular automata and direct stable periodic orbits},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal dynamic brain graph representation learning for brain disorder diagnosis via temporal sequence model. <em>NEUCOM</em>, <em>656</em>, 131509. (<a href='https://doi.org/10.1016/j.neucom.2025.131509'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain network representation learning leverages graph-based algorithms to enhance understanding of functional brain organization. Recently, deep learning approaches based on graph neural network (GNN) have shown promising results in various brain network analysis tasks. Nevertheless, despite significant achievements in brain graph learning, early models still exhibit limitations in dynamic modeling and multi-modal network fusion. Dynamic modeling of brain networks entails learning sequential spatial interactions across time. Inspired by recent advances in large language model architectures, particularly RWKV, which combines the strengths of recurrent neural networks (RNNs) and Transformers. We propose an e fficient t emporal m ulti-modal g raph n eural n etwork (ET_MGNN), that captures complex temporal dependencies while integrating dynamic functional connectivity (DFC) and structural connectivity (SC) into a unified brain network representation. The proposed model demonstrates competitive performance in brain disorder classification on three datasets, outperforming several strong baselines. For instance, ET_MGNN an average classification accuracy improvement of 11.8 % on autism spectrum disorder (ASD) vs healthy controls, 32.9 % on Alzheimer's disease (AD) vs. mild cognitive impairment (MCI), compared to the well-suited STAGIN model. Furthermore, we introduce an interpretable graph reading mechanism that can identify disorder-relevant brain regions. In summary, ET_MGNN combines large-scale language sequence modeling with dynamic brain graph representation learning to improve the accuracy of brain disease diagnosis, providing insightful findings for dynamic brain network modeling.},
  archive      = {J_NEUCOM},
  author       = {Jinwei Lang and Li-Zhuang Yang and Hai Li},
  doi          = {10.1016/j.neucom.2025.131509},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131509},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal dynamic brain graph representation learning for brain disorder diagnosis via temporal sequence model},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PVFT-net: A point-voxel fusion method for self-supervised scene flow estimation with transformer. <em>NEUCOM</em>, <em>656</em>, 131508. (<a href='https://doi.org/10.1016/j.neucom.2025.131508'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene flow estimation is a computer vision task that aims to estimate the 3D motion field of points from two consecutive frames of point clouds, and has a wide range of applications in various fields such as robotics and autonomous driving. Most of the existing methods estimate scene flow through point-based models, but ignore the irregularity of point clouds and the inefficiency of point-level computation. And voxel-based methods can hardly avoid the loss of detailed information. Therefore, we propose a point-voxel fusion method that contains a point branch and a voxel branch. The voxel branch projects the point cloud to regular local grids and captures coarse-grained local features from non-empty voxels through Sparse Grid Attention (SGA) with the shift window strategy. And the point branch captures fine-grained global features through dual attention consisting of Deformable Global Attention (DGA) and Channel Self-Attention (CSA), while compensating for the information loss in the voxel branch. Considering that it is difficult to directly describe the local geometric structure of complex objects in the scene with the shape of 3D objects potentially learned only through xyz coordinates, we explicitly encode the local surface information of the point cloud through the Umbrella Surface Feature Extraction (USFE) module. In addition, we introduce Density Sensitive Metric(DSM) loss to reduce the impact of outliers and density distribution mismatch problems. We validate the effectiveness of our method by performing experiments on the Flyingthings3D and KITTI datasets. Our method outperforms all other self-supervised methods and achieves highly competitive results compared to fully supervised methods. We achieve improvements in all metrics, especially EPE, which is decreased by 8.51 % on the KITTI o dataset and 15.79 % on the KITTI s dataset.},
  archive      = {J_NEUCOM},
  author       = {Xuezhi Xiang and Xi Wang and Xiaoheng Li and Xiankun Zhou and Lei Zhang and Xiantong Zhen},
  doi          = {10.1016/j.neucom.2025.131508},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131508},
  shortjournal = {Neurocomputing},
  title        = {PVFT-net: A point-voxel fusion method for self-supervised scene flow estimation with transformer},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text-to-image person re-identification via collaborating pre-trained diffusion and discriminative models. <em>NEUCOM</em>, <em>656</em>, 131505. (<a href='https://doi.org/10.1016/j.neucom.2025.131505'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image person re-identification (TIReID) aims to retrieve pedestrian images from a database that match given text queries. Currently, the most advanced methods involve transferring powerful multi-modal knowledge from the contrastive language-image pretraining (CLIP) model to perform cross-modal matching. However, CLIP primarily focuses on coarse-grained global contextual modeling of single image-text pairs, neglecting fine-grained compositional matching of complex visual-textual concepts. This makes it challenging to ensure fine-grained cross-modal matching between pedestrians and text queries. To address this issue, a novel framework, Collaborating Pre-trained Diffusion and Discriminative Models (CPDD), is proposed in this work. The CPDD comprises three modules: a fine-grained features learning (FFL) module, a semantic consistency alignment (SCA) module, and a masked-text interactive modeling (MIM) module. Firstly, the FFL learns feature representations containing fine-grained matching information between images and text through the reverse denoising process of a diffusion model. Next, a semantic consistency loss is designed in the SCA, which ensures the semantic consistency between the fine-grained matching information and the input image and text information. Then, the MIM propagates fine-grained matching information into the visual- textual context by a cross-modal interactive encoder, achieving fine-grained matching between images and text and enabling fine-grained cross-modal matching. Extensive experiments on the CUHK-PEDES, ICFG-PEDES, and RSTPReid datasets show that the proposed method achieves significant performance improvements compared to current research results, achieving Rank-1 accuracy of 74.87 %, 63.31 %, and 61.26 %, respectively.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Zhang and Chenyue Xu and Huajing Wu and Quange Tan and Qianli Zhou and Rong Wang},
  doi          = {10.1016/j.neucom.2025.131505},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131505},
  shortjournal = {Neurocomputing},
  title        = {Text-to-image person re-identification via collaborating pre-trained diffusion and discriminative models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Layer-wise contrastive learning BERT for sentence representation of GitHub. <em>NEUCOM</em>, <em>656</em>, 131504. (<a href='https://doi.org/10.1016/j.neucom.2025.131504'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every day, on GitHub, end-users submit a large number of issues that must be addressed to ensure the success of software projects. Though BERT-based pre-trained language models achieve high performance on many downstream tasks, the sentence representation of [CLS] from the top layer of BERT has a limited ability to capture the semantic meaning of sentences. GitHub issue reports often include code snippets and user-generated terms not found in standard vocabularies. Therefore, the classification predictions of BERT are affected. To generate better sentence semantic representations of BERT for GitHub, we propose a layer-wise Contrastive Learning BERT (CLBERT), which uses contrastive learning to enhance the representation ability by contrasting the layer-by-layer representation. Further, to obtain as comprehensive information as possible, representations of each layer are extracted and learned by an attention mechanism as the final classification features. Finally, experiments conducted on two GitHub data sets show that our proposed model significantly improves classification performance.},
  archive      = {J_NEUCOM},
  author       = {Daoquan Chen and Wei Zhang and Shengyu Lu and Yuanguo Lin and Xinyu Gu and Xiuze Zhou},
  doi          = {10.1016/j.neucom.2025.131504},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131504},
  shortjournal = {Neurocomputing},
  title        = {Layer-wise contrastive learning BERT for sentence representation of GitHub},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attacking all tasks at once using adversarial examples in multi-task learning. <em>NEUCOM</em>, <em>656</em>, 131503. (<a href='https://doi.org/10.1016/j.neucom.2025.131503'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual content understanding frequently relies on multi-task models to extract robust representations of a single visual input for multiple downstream tasks. However, in comparison to extensively studied single-task models, the adversarial robustness of multi-task models has received significantly less attention and many questions remain unclear: (1) How robust are multi-task models to single task adversarial attacks, (2) Can adversarial attacks be designed to simultaneously attack all tasks in a multi-task model, and (3) How does parameter sharing across tasks affect multi-task model robustness to adversarial attacks? This paper aims to answer these questions through careful analysis and rigorous experimentation. First, we analyze the inherent drawbacks of two commonly-used adaptations of single-task white-box attacks in attacking multi-task models. We then propose a novel attack framework, Dynamic Gradient Balancing Attack (DGBA). Our framework poses the problem of attacking all tasks in a multi-task model as an optimization problem that can be efficiently solved through integer linear programming. Extensive evaluation on two popular MTL benchmarks, NYUv2 and Tiny-Taxonomy, demonstrates the effectiveness of DGBA compared to baselines in attacking both clean and adversarially trained multi-task models. Our results also reveal a fundamental trade-off between improving task accuracy via parameter sharing across tasks and undermining model robustness due to increased attack transferability from parameter sharing.},
  archive      = {J_NEUCOM},
  author       = {Lijun Zhang and Xiao Liu and Kaleel Mahmood and Caiwen Ding and Hui Guan},
  doi          = {10.1016/j.neucom.2025.131503},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131503},
  shortjournal = {Neurocomputing},
  title        = {Attacking all tasks at once using adversarial examples in multi-task learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolutional neural network combined with edge complexity and channel attention mechanism for unsupervised superpixel segmentation. <em>NEUCOM</em>, <em>656</em>, 131502. (<a href='https://doi.org/10.1016/j.neucom.2025.131502'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Superpixel segmentation is crucial for enhancing image processing efficiency and accuracy. To address the challenges of decreased accuracy and insufficient stability in adaptive superpixel generation faced by existing algorithms in complex image segmentation, we propose ECN, an unsupervised superpixel segmentation algorithm based on convolutional neural networks (CNN) integrating edge complexity and channel attention mechanisms. The ECN algorithm first calculates edge complexity using the Sobel operator, which guides the sequential network in determining the number of feature channels and the kernel size of the fast 1D convolution. Subsequently, low-level features with positional information are transformed into deep features through the sequential network, dynamically adjusting the weights of each feature channel using the channel attention mechanism. Finally, the target function is minimized during inference, enabling unsupervised superpixel generation. We validate ECN's applicability by combining it with Linear Discriminant Analysis (LDA) and Locality Fisher Discriminant Analysis (LFDA) to develop Superpixel Unsupervised Linear Discriminant Analysis (SULDA). Experimental results on BSDS500 and NYUv2 datasets show ECN outperforms existing methods, producing stable and higher-quality superpixel segmentation. Application tests on Indian Pines and Pavia University scenes confirm ECN's significant practical utility.},
  archive      = {J_NEUCOM},
  author       = {Fugui Luo and Shihua Li and Minghui Chang and Yuting Liu and Kaitong Liu},
  doi          = {10.1016/j.neucom.2025.131502},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131502},
  shortjournal = {Neurocomputing},
  title        = {Convolutional neural network combined with edge complexity and channel attention mechanism for unsupervised superpixel segmentation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge distillation-based object detection model focused on road scene perception and localization. <em>NEUCOM</em>, <em>656</em>, 131501. (<a href='https://doi.org/10.1016/j.neucom.2025.131501'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is crucial for unmanned systems, as it enables real-time classification and localization of objects in road scenes. Besides detection accuracy, which remains robust to variations in object scales, an effective object detection algorithm also demands superior performance in processing time. To address these issues, this paper proposes a knowledge distillation-based object detection model, PLE-RepPoints-Lite, to compromise the performance of detection accuracy and speed for unmanned systems. We also design perception and localization enhancement (PLE) strategies, which consist of parallel dynamic attention, multi-scale composite localization confidence, and a feedback closed-loop structure, to enhance the capabilities of perception and localization in complex road environments. To improve the real-time performance, a hybrid lightweight approach for road scenes is designed. Experimental results on the Cityscapes and BDD100K datasets show that our approach achieves state-of-the-art results with average precision (AP) of 34.6 and 40.1, respectively. Furthermore, it operates at 34.2 frames per second (FPS) at a 1280 × 640 resolution, satisfying real-time requirements.},
  archive      = {J_NEUCOM},
  author       = {Yufei Xie and Ying Shi and Changjun Xie and Qin Hu and Yue Liu and Chaojun Lin},
  doi          = {10.1016/j.neucom.2025.131501},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131501},
  shortjournal = {Neurocomputing},
  title        = {A knowledge distillation-based object detection model focused on road scene perception and localization},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confident neural network regression with bootstrapped deep ensembles. <em>NEUCOM</em>, <em>656</em>, 131500. (<a href='https://doi.org/10.1016/j.neucom.2025.131500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise in the popularity and usage of neural networks, trustworthy uncertainty estimation is becoming increasingly essential. One of the most prominent uncertainty estimation methods is Deep Ensembles [20]. A classical parametric model has uncertainty in the parameters due to the fact that the data on which the model is built is a random sample. A modern neural network has an additional uncertainty component since the optimization of the network is random. Lakshminarayanan et al. [20] noted that Deep Ensembles do not incorporate the classical uncertainty induced by the effect of finite data. In this paper, we present a computationally cheap extension of Deep Ensembles for the regression setting, called Bootstrapped Deep Ensembles , that explicitly takes this classical effect of finite data into account using a modified version of the parametric bootstrap. We demonstrate through an experimental study that our method significantly improves upon standard Deep Ensembles. The resulting confidence intervals demonstrate superior coverage without sacrificing accuracy.},
  archive      = {J_NEUCOM},
  author       = {Laurens Sluijterman and Eric Cator and Tom Heskes},
  doi          = {10.1016/j.neucom.2025.131500},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131500},
  shortjournal = {Neurocomputing},
  title        = {Confident neural network regression with bootstrapped deep ensembles},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameter-free multi-view clustering via refined tensor learning. <em>NEUCOM</em>, <em>656</em>, 131497. (<a href='https://doi.org/10.1016/j.neucom.2025.131497'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As multi-view data becomes more prevalent in real-world applications, multi-view clustering (MVC) has emerged as a powerful technique for unsupervised representation learning. To uncover the intrinsic structure, it is crucial to consider information from different spaces. Focusing solely on the sample space limits the method’s ability to effectively model multi-view data, as the informative patterns embedded in the feature space are often overlooked. Furthermore, to integrate high-order correlations, tensor-based MVC methods have been widely adopted to preserve the low rank structure of multi-view data. Traditional tensors can not achieve selective tensor rank minimization as they lack an explicit mechanism to model the retention of singular values based on their individual information contributions. Additionally, existing methods rely on hyper-parameters, undermining generalizability across different datasets. In response to these limitations, we propose a novel Parameter-free Multi-view Clustering via Refined Tensor Learning (PRTL), which is based on bidirectional regression matrices to perform data reconstruction and extract salient features. To further achieve an adaptive low-rank tensor structure, we propose a Quadratic Decay Tensor (QDT) regularization as a non-convex alternative to conventional rank minimization, which selectively retains salient information while filtering out noise dynamically, resulting in a more expressive joint representation. Meanwhile, we incorporate the hyper-Laplace graph to capture richer relationships than those modeled by conventional pairwise graphs. Notably, PRTL eliminates the need for hyper-parameters, making it more practical and robust. Experiments on diverse datasets demonstrate that PRTL consistently surpasses existing state-of-the-art clustering methods. Our code is available at https://github.com/jiaxinyang04/PRTL .},
  archive      = {J_NEUCOM},
  author       = {Jiaxin Yang and Qian Liu and Yuemeng Huang and Chunyan Yang and Wengeng Chen and Yu Lu and Jiale Wang and Wenzhe Liu and Huibing Wang},
  doi          = {10.1016/j.neucom.2025.131497},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131497},
  shortjournal = {Neurocomputing},
  title        = {Parameter-free multi-view clustering via refined tensor learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extensive multi-variant deep neural network approach to enhance genomic prediction of endometriosis. <em>NEUCOM</em>, <em>656</em>, 131496. (<a href='https://doi.org/10.1016/j.neucom.2025.131496'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have shown significant advancements in modelling complex non-linear relationships in high-dimensional biomedical data. Understanding the interplay between genetic variants and disease susceptibility is still a considerable challenge that prevents certain genomic diseases to be predicted accurately for clinical interventions. In this study, we introduce the Extensive Multi-Variant Deep Neural Network (EMV-DNN), an innovative deep learning methodology designed to enhance polygenic risk prediction. Unlike conventional polygenic risk score methods, EMV-DNN incorporates single nucleotide polymorphisms (SNPs) alongside structural variants including insertions and deletions (indels), short tandem repeats (STRs), and copy number variants (CNVs) using variant-specific subnetworks to extract informative embeddings which capture a richer and holistic genomic context. Evaluated on real-world cohorts from the UK Biobank and All of Us, EMV-DNN outperforms conventional PRS methods and classic machine learning algorithms across binary and multi-class prediction tasks. Beyond predictive performance, SHapley Additive exPlanations (SHAP) analysis revealed biologically plausible variant–gene–disease associations, highlighting pathways related to endometrial cell proliferation, fibrosis, and immune regulation. Our findings underscore the value of multi-variant integration and non-linear approaches to capture the intricate genetic architecture of complex genomic diseases. Despite challenges such as dataset limitations and the complexity of diseases with multiple contributing factors, the EMV-DNN methodology presents a promising avenue for enhancing the predictive accuracy of PRS, thereby facilitating personalized healthcare interventions and advancing our understanding of genetic predispositions to disease.},
  archive      = {J_NEUCOM},
  author       = {Zelia Soo and Hua Lin and Yue Yang and Mark Grosser and Mengjia Wu and Yi Zhang and Jie Lu},
  doi          = {10.1016/j.neucom.2025.131496},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131496},
  shortjournal = {Neurocomputing},
  title        = {An extensive multi-variant deep neural network approach to enhance genomic prediction of endometriosis},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised facial expression restoration and recognition method based on improved masked auto-encoder. <em>NEUCOM</em>, <em>656</em>, 131495. (<a href='https://doi.org/10.1016/j.neucom.2025.131495'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a method for reconstructing occluded facial expressions. Firstly, a self-supervised learning Masked Auto-Encoder based facial expression recognition (MAE-FER) method is introduced, which effectively reduces the computational cost and parameter count by enhancing the multi-scale local-global self-attention interaction encoder, thereby improving the training efficiency and generalization capability of the model. Secondly, to address the problem of facial expression occlusion in real-world scenarios, a MAE-based occlusion detector is designed to detect occluded parts of the face, providing effective support for subsequent reconstruction tasks. Subsequently, the Dynamic Weight Allocation Generative Adversarial Network (DWA-GAN) for facial expression occlusion recovery is proposed, which achieves precise occlusion recovery by dynamically allocating weights to reference image blocks, significantly improving the accuracy of reconstruction. Finally, feature fusion is performed on the reconstructed results and applied to the FER task to further enhance classification accuracy and stability. Utilizing the pre-trained MAE-FER model, key hidden vectors are extracted from facial expression images, containing important feature information related to expression recognition. Through this step, closely related features to expression recognition are selected while irrelevant details are discarded, optimizing the inter-class distance issue of facial expressions. Next, to address the performance degradation caused by label ambiguity, an improved Rotate Erasing Attention Consistency (REAC) method is adopted, which effectively mitigates the negative impact of label ambiguity, further improving the accuracy and stability of FER. Experimental results demonstrate that the method achieves the best performance on the RAF-DB dataset.},
  archive      = {J_NEUCOM},
  author       = {Chaolong Zhang and Yuanping Xu and Zhijie Xu and Rongqiang Gou and Weiye Wang and Jin Jin and Jian Huang},
  doi          = {10.1016/j.neucom.2025.131495},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131495},
  shortjournal = {Neurocomputing},
  title        = {A self-supervised facial expression restoration and recognition method based on improved masked auto-encoder},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scattered data augmentation for generalization in visual reinforcement learning. <em>NEUCOM</em>, <em>656</em>, 131492. (<a href='https://doi.org/10.1016/j.neucom.2025.131492'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation (DA) has shown a significant potential to enhance generalization performance in visual reinforcement learning (VRL). However, existing research on DA-based methods is predominantly empirical, and the mechanism for why DA enhances generalization remains theoretically under-explored. To bridge this gap, we derive a generalization error upper bound for VRL from the perspective of data distribution distance. Based on this bound, we provide a theoretical explanation of the mechanism by which DA improves generalization: we find that DA that satisfies certain conditions can reduce the distance between the training and test distributions, thus making the training and test samples closer. In addition, we conditionally prove that training data with higher variance can provide a higher generalization performance. Motivated by our analysis, we propose Scattered Data Augmentation (ScDA) framework. ScDA constructs a data transformation system with the agent serving as the discriminator, aiming to provide more diverse training data for agent training. Experiments are conducted across various tasks and numerous test modes in DeepMind Control Generalization Benchmark2 (DMC-GB2) and robotic tasks. Results demonstrate that our ScDA framework can be integrated with different baseline algorithms and significantly enhance policy generalization, outperforming the current state-of-the-art methods in the DMC-GB2 tests, confirming the effectiveness of the theoretical analysis in this work. The code for this work can be found at: https://github.com/scdadev/scdadev .},
  archive      = {J_NEUCOM},
  author       = {Hao Lei and Yu Zhao and Yi Xin and Zhang Shaonan and Ke Liangjun},
  doi          = {10.1016/j.neucom.2025.131492},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131492},
  shortjournal = {Neurocomputing},
  title        = {Scattered data augmentation for generalization in visual reinforcement learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monotonic convergence of adaptive caputo fractional gradient descent for temporal convolutional networks. <em>NEUCOM</em>, <em>656</em>, 131491. (<a href='https://doi.org/10.1016/j.neucom.2025.131491'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fractional derivatives have gained prominence in optimization for their inherent non-locality and memory-dependent properties, effectively capturing historical dependencies. This work introduces an Adaptive Fractional-order Gradient Descent (AFGD) algorithm based on Caputo fractional derivatives, with deep integration into Temporal Convolutional Networks (TCNs). Unlike conventional fixed-order methods, AFGD employs an adaptive fractional-order mechanism to enhance optimization. Theoretically, we establish rigorous proofs for AFGD’s monotonic convergence in loss function minimization, supported by numerical simulations of its convergence behavior. Evaluated on the MIT-BIH arrhythmia five-class classification benchmark, TCNs optimized with AFGD achieve superior accuracy over established methods, demonstrating the efficacy of the proposed gradient scheme for deep learning optimization.},
  archive      = {J_NEUCOM},
  author       = {Zhiwei Xiao and Jiejie Chen and Xuewen Zhou and Bin Wei and Ping Jiang and Zhigang Zeng},
  doi          = {10.1016/j.neucom.2025.131491},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131491},
  shortjournal = {Neurocomputing},
  title        = {Monotonic convergence of adaptive caputo fractional gradient descent for temporal convolutional networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive PID-guided tensor wheel decomposition model for dynamic weighted network representation. <em>NEUCOM</em>, <em>656</em>, 131490. (<a href='https://doi.org/10.1016/j.neucom.2025.131490'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Weighted Networks (DWN) usually appear in various big data-related complex systems and can describe real-time interactions between a large number of entities. As the number of entities increases dramatically, it is impossible for each entity to have complete interaction with each other, which results in such a DWN being High-Dimensional and Incomplete (HDI). Tensor Wheel Decomposition (TWD), as a novel tensor network, has powerful representation capabilities, but existing TWD-based methods require additional computational and storage costs to process an HDI DWN. To address these challenges, we propose an Adaptive integral separation PID–guided Tensor Wheel Decomposition (APTWD) model that: 1) employs a data density-oriented loss function, ensuring the representation learning is focused on the existing information in the target network to obtain more accurate low-rank embedding; and 2) develops a parameter learning scheme with error control feedback based on the integral separation PID controller to minimize the convergence iteration process. Experiments on six real-world DWN datasets demonstrate that APTWD consistently outperforms state-of-the-art methods, delivering higher representation accuracy and significantly reduced computational cost.},
  archive      = {J_NEUCOM},
  author       = {Jiqiu Chen and Qu Wang and Hao Wu},
  doi          = {10.1016/j.neucom.2025.131490},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131490},
  shortjournal = {Neurocomputing},
  title        = {An adaptive PID-guided tensor wheel decomposition model for dynamic weighted network representation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view unsupervised feature selection based on graph discrepancy learning. <em>NEUCOM</em>, <em>656</em>, 131487. (<a href='https://doi.org/10.1016/j.neucom.2025.131487'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-view learning, unsupervised feature selection plays a vital role in reducing dimensionality while preserving discriminative information distributed across diverse data modalities. Despite notable progress, existing approaches frequently exhibit two key limitations: they often overlook the complementary benefits of integrating global and local structural information, and they inadequately model complex nonlinear relationships or align structural representations across views. To address these challenges, we propose a novel framework, termed Multi-view unsupervised feature selection based on graph discrepancy learning (GDFS). The proposed method jointly constructs global graph structures in a projected low-dimensional space and local graphs in a nonlinear kernel-induced space, effectively capturing both high-level semantic structures and fine-grained neighborhood dependencies. A graph discrepancy term is introduced to explicitly reduce structural discrepancies between global and local representations, thus enhancing consistency and robustness. In addition, a low-rank tensor constraint is applied to the stack of global graphs to uncover high-order correlations across views. A consensus clustering matrix is further learned to provide pseudo-label supervision, which guides the selection of discriminative features. Extensive experiments on six benchmark multi-view datasets demonstrate that GDFS consistently surpasses state-of-the-art methods in terms of clustering performance, thereby confirming its effectiveness, scalability, and generalizability. The code is available at https://github.com/xyw0111/2025-GDFS .},
  archive      = {J_NEUCOM},
  author       = {Yiwan Xu and Xijiong Xie and Xianliang Jiang and Yujie Xiong},
  doi          = {10.1016/j.neucom.2025.131487},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131487},
  shortjournal = {Neurocomputing},
  title        = {Multi-view unsupervised feature selection based on graph discrepancy learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel mixed-attribute data anomaly detection method based on granular-ball multi-kernel fuzzy rough sets. <em>NEUCOM</em>, <em>656</em>, 131486. (<a href='https://doi.org/10.1016/j.neucom.2025.131486'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rough sets have established a novel approach to anomaly detection through uncertainty handling. Nevertheless, traditional approaches are susceptible to noise. Existing kernelized methods improve feature representation via kernel transformations. However, they are typically restricted to a single-kernel framework, which limits the capacity to model the heterogeneous nature of mixed-attribute data. To address this issue, this study proposes a granular-ball generation algorithm tailored to the characteristics of mixed-attribute data. Multiple kernel functions are employed to effectively integrate the fuzzy relations of various attribute types. By integrating fuzzy rough set theory, granular-ball computing, and multi-kernel methods, a granular-ball multi-kernel fuzzy rough set model is proposed. Besides, a novel unsupervised anomaly detection method is proposed to effectively process mixed-attribute data. This method integrates kernelized fuzzy relations across various attribute types, constructs kernelized fuzzy information granules, and computes anomaly scores based on multiple granular-ball kernelized fuzzy information granules. Finally, an anomaly factor is introduced to quantify the anomaly degree of data objects. Comparative experiments were conducted on 16 public datasets. The novel approach consistently outperformed current methodologies in AUC metrics while demonstrating superior robustness across diverse data samples.},
  archive      = {J_NEUCOM},
  author       = {Cong Gao and Qiu Wang and Yanping Chen and Qingqi Pei and Zhongmin Wang},
  doi          = {10.1016/j.neucom.2025.131486},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131486},
  shortjournal = {Neurocomputing},
  title        = {A novel mixed-attribute data anomaly detection method based on granular-ball multi-kernel fuzzy rough sets},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-guided encoder-decoder network for soft sensor of copper matte grade in flash smelting process. <em>NEUCOM</em>, <em>656</em>, 131485. (<a href='https://doi.org/10.1016/j.neucom.2025.131485'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate real-time detection of copper matte grade is critical for state identification and optimization control in flash smelting, yet remains challenging due to the complex and harsh industrial environment. To address this issue, this study proposes a knowledge-guided encoder-decoder network. In this method, Bidirectional Gated Recurrent Unit serves as the backbone architecture for both the encoding and decoding processes, enabling nonlinear dynamic modeling in the temporal domain. The encoder integrates a composite variable attention mechanism, which leverages process knowledge to prioritize key variables based on their importance. A temporal decay attention mechanism is added to the decoder, endowing the model with the ability to simulate the temporal dependency between copper matte grade and process variables through prior knowledge. These knowledge-guided designs strengthen the ability of model to capture process-specific relationships between input variables and copper matte grade. Industrial experiments based on real production data from a smelting plant in China, show that the proposed model achieves optimal performance, with 96 % absolute errors not exceeding 0.5 %. It demonstrates that the proposed model not only provides accurate and real-time copper matte grade estimation but also maintains robustness in industrial environments, verifying its potential for practical application in flash smelting process.},
  archive      = {J_NEUCOM},
  author       = {Zhou Zou and Can Zhou and Chunhua Yang},
  doi          = {10.1016/j.neucom.2025.131485},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131485},
  shortjournal = {Neurocomputing},
  title        = {Knowledge-guided encoder-decoder network for soft sensor of copper matte grade in flash smelting process},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-resolution QP-adaptive generative face video compression using multi-level generator. <em>NEUCOM</em>, <em>656</em>, 131484. (<a href='https://doi.org/10.1016/j.neucom.2025.131484'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a multi-resolution quantization parameter (QP)-adaptive generative face video compression (GFVC) framework to realize face video communication at an ultra-low bitrate. By leveraging deep generative models and semantic feature representation, the proposed framework achieves high perceptual quality while significantly reducing bitrate. The proposed framework dynamically adjusts feature granularity based on QP values and integrates modules such as multi-level multi-DConv head transposed attention (MDTA) and multi-level spatially adaptive denormalization (SPADE) to enhance both spatial fidelity and temporal consistency. To ensure adaptability and standardization, we further extend the proposed framework to support multi-resolution inputs and incorporate feature encoding based on Supplemental Enhancement Information (SEI) in VVC. Specifically, we introduce the flag gfv_enhancement_matrix_flag to transmit an optional 8 × 8 enhancement matrix, enabling precise refinement of inter-frame reconstruction in compliance with VVC. A multi-reference frame buffer mechanism is also implemented to improve long-term temporal coherence through attention-guided reference selection. Experimental results demonstrate that the proposed GFVC framework achieves average BD-rate gains of 63.87 % in DISTS and 61.99 % in LPIPS on benchmark datasets compared to the VVC anchor (VTM-22.2 LDB mode). Without retraining, the proposed framework operates smoothly even on face videos with a resolution of 512 × 512 , achieving 23.40 % BD-rate gain in DISTS and indicating strong scalability. These results validate the practical feasibility of the proposed GFVC framework in real-world video conferencing and telepresence scenarios, especially under ultra-low bandwidth conditions.},
  archive      = {J_NEUCOM},
  author       = {Wenbo Kang and Lu Liu and Cheolkon Jung},
  doi          = {10.1016/j.neucom.2025.131484},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131484},
  shortjournal = {Neurocomputing},
  title        = {Multi-resolution QP-adaptive generative face video compression using multi-level generator},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Filter bank convolutional network with dual channel attention for multi-class fine joint motor imagery decoding. <em>NEUCOM</em>, <em>656</em>, 131480. (<a href='https://doi.org/10.1016/j.neucom.2025.131480'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective Motor imagery brain-computer interface (MI-BCI) is a representative BCI system. Recent studies in MI-BCI focus on Fine Joint MI (FJMI) decoding that recognizes the motor intention of different joints from one upper limb. However, due to the low spatial difference between EEG patterns of FJMI, achieving optimal performance remains a challenge of multi-class FJMI decoding studies. Methods: We proposed a novel approach named Filter Bank Convolutional Network with Dual Channel Attention (FB-DCANet) that enables feature extraction and selection in MI-EEG across multi-class FJMI tasks. This network features a combined filter bank in frequency and time domain that simultaneously extracts spatio-temporal information from four frequency bands (alpha, beta, theta, and low gamma), accompanied with temporal convolutional modules for additional temporal information extraction. Moreover, a feature selection method based on Dual Channel Attention was proposed combining preliminary intra-band feature selection via Residual Channel Self-Attention (RCSA) and further inter-band feature selection from different frequency bands by Efficient Channel Attention (ECA). Results: We performed experiments using FJMI-EEG data from the unilateral upper limb, and FB-DCANet achieved an accuracy of 59.34 % in a 4-class classification scenario (hand MI, elbow MI, shoulder MI, and resting state), and interpretability of FB-DCANet was analyzed by visualization of Class Activation Map (CAM) and attention values. Conclusion and Significance: This work presents a novel approach with a time-frequency filter bank and Dual Channel Attention-based feature selection for multi-class FJMI decoding, which can be utilized to develop a rehabilitation system based on FJMI-BCI.},
  archive      = {J_NEUCOM},
  author       = {Jiaming Chen and Yueqi Zhang and Kaide Liu and Xinkang Hu and Meng Xu and Dan Wang and Weibo Yi},
  doi          = {10.1016/j.neucom.2025.131480},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131480},
  shortjournal = {Neurocomputing},
  title        = {Filter bank convolutional network with dual channel attention for multi-class fine joint motor imagery decoding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Output-feedback synchronization of semi-markov jump two-time-scale neural networks: Dual event-triggered scheme. <em>NEUCOM</em>, <em>656</em>, 131479. (<a href='https://doi.org/10.1016/j.neucom.2025.131479'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of synchronization control for semi-Markov jump two-time-scale neural networks, in which the output-feedback mechanism is adopted and a dual event-triggered scheme is employed using a double-rate sampling method to balance system performance and communication efficiency. First, considering the two-time-scale property of the semi-Markov jump neural networks, the dual-rate sampling strategy is adopted such that two independent event-triggered conditions for different time scales can be designed, which ensure efficient resource utilization while maintaining system performance. Then, a Lyapunov–Krasovskii functional with the singular perturbation parameter is constructed to deduce sufficient conditions ensuring that the synchronization error system is stochastically stable and satisfies a given H ∞ performance index. Moreover, the solution for obtaining the controller gains is presented to guarantee synchronization of the considered system under a dual event-triggered scheme. Finally, the feasibility of the methods is demonstrated by two examples, including a numerical example and an image encryption. They show that this event-triggered mechanism provides an efficient new synchronization control scheme for semi-Markov jump two-time-scale neural network systems while reducing the network burden.},
  archive      = {J_NEUCOM},
  author       = {Wenyan Zuo and Ya-Nan Wang and Feng Li and Sangmoon Lee},
  doi          = {10.1016/j.neucom.2025.131479},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131479},
  shortjournal = {Neurocomputing},
  title        = {Output-feedback synchronization of semi-markov jump two-time-scale neural networks: Dual event-triggered scheme},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient multi-view graph condensation via gradient-flow induced graph convolutional networks. <em>NEUCOM</em>, <em>656</em>, 131478. (<a href='https://doi.org/10.1016/j.neucom.2025.131478'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning based on graph convolutional networks boosts performance by incorporating diverse perspectives, leading to significant achievements and successful applications across various academic and practical fields. However, multi-view graph convolutional networks suffer from substantial computational challenges on large-scale graphs. To address this limitation, graph condensation has emerged as a promising direction by creating a smaller composite graph that allows for efficient network training while preserving performance. Furthermore, previous studies have demonstrated that encouraging performance in graph learning is achieved via graph compression. To this end, we attempt to introduce graph condensation into the multi-view learning for computation acceleration. This approach not only reduces training costs significantly but also achieves sub-linear time complexity and memory consumption during network training. Further, we propose a gradient flow induced graph convolutional network from partial differential equations, which offers theoretical guarantees and potential new insights for the graph-related network architecture construction with transparent model interpretability. Extensive experiments on seven real-world multi-view datasets demonstrate that the proposed method sharply decreases model training time while ensuring competitive multi-view semi-supervised classification.},
  archive      = {J_NEUCOM},
  author       = {Lu Liu and Yang Huang and Yueyang Pi and Zhicheng Wei and Jinbo Li and Shiping Wang},
  doi          = {10.1016/j.neucom.2025.131478},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131478},
  shortjournal = {Neurocomputing},
  title        = {Efficient multi-view graph condensation via gradient-flow induced graph convolutional networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal bayesian regression with a non-informative prior: Order-recursive and incremental learning. <em>NEUCOM</em>, <em>656</em>, 131476. (<a href='https://doi.org/10.1016/j.neucom.2025.131476'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal Bayesian regression (OBR) for data generated from a multidimensional vector autoregressive process of order p , denoted as VAR ( p ) , has a closed-form analytic expression that has been previously obtained. Despite the closed-form expressions to compute the “OBR-VAR”, in certain practical scenarios the computational cost involved in training OBR-VAR is a bottleneck. From a computational perspective, two common scenarios that incur excessive computational cost are: 1) given a set of training data, estimating the unknown model order p generally entails computing the OBR-VAR from scratch for every p in a range from 1 to a maximum value; and 2) in dynamic environments where data arrives sequentially, currently one must recompute OBR-VAR from scratch for every new upcoming observation. To address the first issue, in this paper, an order-recursive OBR-VAR regressor using QR decomposition is proposed. This method efficiently updates the regressor without recalculating it from scratch for each p , significantly reducing computational complexity while preserving model accuracy. Analytical results demonstrate that the proposed order-recursive method achieves a computational complexity reduction by a factor proportional to p , making it scalable to larger datasets and higher model orders. To address the second issue, an incremental version of the OBR-VAR algorithm is developed for real-time data processing. This method updates the regressor incrementally as new data points arrive, maintaining accuracy without the need for costly recomputation of key matrices. Its capability makes it well-suited for continuous-time data acquisition and streaming applications, where timely and accurate responses are critical. In all cases we assume an improper non-informative prior to model the case of having no prior knowledge about the problem. Theoretical analysis and empirical evaluations using synthetic and real datasets demonstrate that both methods significantly outperform the standard OBR-VAR algorithm in terms of computational complexity while preserving accuracy.},
  archive      = {J_NEUCOM},
  author       = {Samira Reihanian and Amin Zollanvari and Siamac Fazli},
  doi          = {10.1016/j.neucom.2025.131476},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131476},
  shortjournal = {Neurocomputing},
  title        = {Optimal bayesian regression with a non-informative prior: Order-recursive and incremental learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-stream GCN-based action recognition framework using trustworthy fusion decision from different skeleton descriptors. <em>NEUCOM</em>, <em>656</em>, 131475. (<a href='https://doi.org/10.1016/j.neucom.2025.131475'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex motion processes, different human skeleton descriptors can characterize skeletal features across various dimensions. The frequency of spatiotemporal changes in different joints is largely influenced by the type of action. This paper presents a dual-stream GCN-based action recognition framework, which involves Slow-stream and Fast-stream networks to process skeletal features of different spatiotemporal change characteristics. In the parallel processing architecture of graph convolutional layers, adaptive adjacency matrices that strengthen spatial and temporal feature extraction are proposed to learn the implicit relationships between skeletal joints. Furthermore, different skeletal features have significantly varying impacts on the accuracy of action recognition. The Dirichlet distribution and an optimized Dempster combination rule are introduced for trustworthy decision when fusing multi-branch opinions obtained from different skeleton descriptors. Extensive experiments on three authoritative datasets demonstrate that the proposed method achieves state-of-the-art performance while reducing uncertainty in action recognition.},
  archive      = {J_NEUCOM},
  author       = {Wenrui Zhu and Donghui Shi and Junqi Yu},
  doi          = {10.1016/j.neucom.2025.131475},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131475},
  shortjournal = {Neurocomputing},
  title        = {A dual-stream GCN-based action recognition framework using trustworthy fusion decision from different skeleton descriptors},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous federated semantic segmentation. <em>NEUCOM</em>, <em>656</em>, 131470. (<a href='https://doi.org/10.1016/j.neucom.2025.131470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) offers a promising solution for semantic segmentation in scenarios involving data distribution across isolated clients. Despite recent advances, federated semantic segmentation (FSS) continues to face key challenges. One major issue is the shift from centralized to decentralized training, where diverse and limited local data hinder consistent pixel-level representation learning. Another challenge is data heterogeneity from imbalanced class distributions across clients, which weakens feature consistency and degrades global performance. These limitations often lead to inconsistent feature learning and degraded global performance. To address the challenges of class heterogeneity and insufficient pixel-level representation learning in FSS, we propose a novel pixel-aware FSS framework that improves local adaptation and semantic consistency. Specifically, we design a fine-tuning strategy that initializes each client with a lightweight pre-trained model and performs local updates over multiple epochs. This improves model adaptability to local distributions while reducing communication overhead. To further enhance semantic consistency across heterogeneous clients, we introduce a client clustering strategy based on pixel-level semantic features. Clients with similar class distributions are grouped to encourage consistent feature learning within clusters. Cluster-level training and aggregation are then followed by a global aggregation step, promoting more robust and aligned semantic understanding. Empirical evaluation across multiple benchmark datasets confirms that our method achieves consistently high segmentation precision and enhanced model adaptability in highly heterogeneous federated scenarios.},
  archive      = {J_NEUCOM},
  author       = {Chen Zhang and Jiarui Wang and Yu Xie and Xinlei Wang and Bin Yu},
  doi          = {10.1016/j.neucom.2025.131470},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131470},
  shortjournal = {Neurocomputing},
  title        = {Heterogeneous federated semantic segmentation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CBH-YOLO: A steel surface defect detection algorithm based on cross-stage mamba enhancement and hierarchical semantic graph fusion. <em>NEUCOM</em>, <em>656</em>, 131467. (<a href='https://doi.org/10.1016/j.neucom.2025.131467'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of surface defects in steel materials plays a pivotal role in ensuring industrial production quality and operational safety. However, existing deep learning-based detection methods face significant challenges in steel surface defect detection, including limited receptive field coverage, inadequate multi-scale feature integration, and insufficient feature discrimination under complex backgrounds. To address these limitations, this work introduces CBH-YOLO, a novel steel surface defect detection algorithm. The proposed framework incorporates three fundamental innovation modules: (1) Cross-stage Mamba-Enhanced Multi-scale Convolution (CMMC) module, which synergistically combines the advantages of state space models with large kernel convolutions alongside adaptive attention mechanisms, substantially expanding receptive field coverage while enhancing multi-scale feature extraction capabilities; (2) Binary Amplification Matrix (BAM) module, which innovatively integrates FlexWave (FXW) dynamic activation functions with OmniScale (OSC) multi-scale perception mechanisms to achieve adaptive nonlinear feature mapping and refined representation; (3) Hierarchical Semantic Graph Fusion Network (HSGFN), which models high-order correlations among features through hypergraph structures combined with adaptive feature fusion mechanisms, enabling more effective multi-scale feature integration. Comprehensive experimental validation on NEU-DET and GC10-DET benchmark datasets demonstrates that CBH-YOLO achieves improvements of 2.7 % and 3.2 % in mAP@50 metrics compared to the baseline YOLOv11 model, while maintaining exceptional computational efficiency. This research provides a high-precision, high-efficiency solution for steel surface defect detection, offering significant theoretical value and practical application prospects.},
  archive      = {J_NEUCOM},
  author       = {Bo Gao and Jingcheng Tong and RongRong Fu and ZhenZhen Zhang and YiLin Yuan},
  doi          = {10.1016/j.neucom.2025.131467},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131467},
  shortjournal = {Neurocomputing},
  title        = {CBH-YOLO: A steel surface defect detection algorithm based on cross-stage mamba enhancement and hierarchical semantic graph fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMNet: Incomplete multi-modal alzheimer’s disease diagnosis with dual memory network. <em>NEUCOM</em>, <em>656</em>, 131465. (<a href='https://doi.org/10.1016/j.neucom.2025.131465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the challenge of missing modality, existing multi-modal learning methods become impractical and missing modality is a serious impediment to a good multi-modal learning performance. Meanwhile, we note that the existing methods for addressing missing modality issue tend to explore complete information by using either cross-generative approaches via simply filling in missing modality data, and do not consider the specific information, resulting in a sub-optimal performance for Alzheimer’s Disease diagnosis with multi-modal data. To address this problem, we propose a novel Dual Memory Network (DMNet) that comprises the Tabular Alignment Memory bank (TAM) and Dynamic Re-optimizing Memory bank (DRM) to complement the missing modality information in multi-modal learning for Alzheimer’s disease diagnosis. More specifically, TAM stores the information aligned with clinical tabular data, and maintains the feature distribution alignment between clinical tabular data and imaging modalities. Besides, TAM is updated by a memory aligning strategy. Then, DRM stores modality specific information from complete modalities, and we design a memory optimizing strategy that incorporates Feature Consistency (FC) loss and Memory Correspondence (MC) loss to update the memory items in DRM to effectively represent specific information of modalities. This novel dual memory network enhances model performance and improves model usability in multi-modal learning with missing modality, providing a more informative feature distribution to complement the missing modality. Extensive experiments, including quantitative and qualitative analyses, as well as various ablation studies, demonstrate that our proposed method achieves state-of-the-art performance in the classification task on the ADNI dataset.},
  archive      = {J_NEUCOM},
  author       = {Nana Jia and Zhiao Zhang and Tong Jia},
  doi          = {10.1016/j.neucom.2025.131465},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131465},
  shortjournal = {Neurocomputing},
  title        = {DMNet: Incomplete multi-modal alzheimer’s disease diagnosis with dual memory network},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WDWorm: A runtime-efficient and user-friendly GUI-based toolbox for experimenting with the nerve net of c. elegans. <em>NEUCOM</em>, <em>656</em>, 131464. (<a href='https://doi.org/10.1016/j.neucom.2025.131464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nerve net simulators of C. elegans heavily support research on its nerve net functionality by offering the possibility to conduct digital experiments instead of real ones. However, current software tools are complex and difficult to use for non-programmers. With WDWorm, we offer a user-friendly toolbox with graphical user interface for simulating and experimenting with C. elegans’ nerve net. It does not require an installation and allows for several modifications of the nerve net, including parameter changes for each neuron and connection or the deactivation of individual neurons. Furthermore, a comparison with other software tools highlights that WDWorm is currently the most runtime-efficient approach for simulating and digitally experimenting with C. elegans . To invite other developers and researchers, we provide the source code in an open-access format under a CC-BY 4.0 Creative Commons license. The code is publicly available at https://github.com/dsacri/WDWorm .},
  archive      = {J_NEUCOM},
  author       = {Sebastian Jenderny and Daniel Sacristán and Philipp Hövel and Christian Albers and Isabella Beyer and Karlheinz Ochs},
  doi          = {10.1016/j.neucom.2025.131464},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131464},
  shortjournal = {Neurocomputing},
  title        = {WDWorm: A runtime-efficient and user-friendly GUI-based toolbox for experimenting with the nerve net of c. elegans},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Curriculum learning-based slimmable cross-component prediction for video coding. <em>NEUCOM</em>, <em>656</em>, 131463. (<a href='https://doi.org/10.1016/j.neucom.2025.131463'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-component prediction plays an important role in video coding, which aims to eliminate redundancy between color components under the guidance of luma information. Recently, learning-based cross-component prediction has made significant strides in performance. However, current cross-component prediction methods typically train models directly on a dataset with different types of data, which generally results in overfitting for the flat textured data and underfitting for the complex textured data. To improve coding performance without excessively increasing the complexity, a cost-effective attention-based slimmable cross-component prediction network (SCCPN) is proposed. Although trained as a single model, SCCPN is capable of being executed at different levels of capacity, resulting in varying prediction results tailored to data with different characteristics. With the goal of further improving the generalization capability and prediction accuracy of the network, a curriculum learning strategy combined with slimmable convolutions is then designed, which employs the classification of prediction difficulty to represent whether the texture is flat or complex, and fits complex data with a small number of additional parameters. An adaptive search strategy is also introduced to speed up the selection of channels for slimmable convolutions. Experimental results demonstrate that when integrated into H.266/Versatile Video Coding (VVC), SCCPN achieves up to −0.62 %/−3.34 %/−2.68 % BD-rate reductions on Y/Cb/Cr components, respectively, over the H.266/VVC anchor. The performance gain outperforms the state-of-the-art learning-based cross-component prediction methods, while the increased complexity in both encoding and decoding is lower than the other compared cross-component prediction methods using neural networks. Moreover, performance gain can also be observed when SCCPN is integrated into the latest reference software of Beyond VVC, with BD-rate reductions of −0.17 %/−1.00 %/−1.02 % on Y/Cb/Cr components respectively.},
  archive      = {J_NEUCOM},
  author       = {Chengyi Zou and Shuai Wan and Marc Gorriz Blanch and Luka Murn and Juil Sock and Fei Yang and Luis Herranz},
  doi          = {10.1016/j.neucom.2025.131463},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131463},
  shortjournal = {Neurocomputing},
  title        = {Curriculum learning-based slimmable cross-component prediction for video coding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Representative negative sampling for graph positive-unlabeled learning. <em>NEUCOM</em>, <em>656</em>, 131462. (<a href='https://doi.org/10.1016/j.neucom.2025.131462'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph positive-unlabeled (GPU) learning is an important task that aims to develop binary classifiers using only positive and unlabeled nodes, which are commonly encountered in real-life applications. Although selecting reliable negative samples is a highly promising approach, it typically only selects high-confidence examples, which lack representativeness and fail to fully capture the diversity of the negative example space. To address this gap, our key insight, inspired by galactic dynamics, is to model the positive prototype center as a continuously evolving gravitational center maintained via a momentum moving average, just like the stars in the universe are always moving forward rather than remaining still. This dynamic anchor allows us to robustly define a reliable negative region—its “gravitational field”—for sampling representative “planets” (negative examples). We propose StarHunter-PU (SH-PU), a framework that operationalizes this insight by unifying graph representation learning with our dynamic, prototype-guided representative sampling algorithm. This ensures the sampled negatives are both diverse and informative, providing accurate information for training a robust binary classification model. Experimental results on real-world datasets show that our StarHunter-PU method significantly outperforms existing methods and even achieves competitive performance compared to fully labeled methods.},
  archive      = {J_NEUCOM},
  author       = {Luyue Wang and Xinyuan Feng and Rui Mao and Yin Li and Chunquan Liang},
  doi          = {10.1016/j.neucom.2025.131462},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131462},
  shortjournal = {Neurocomputing},
  title        = {Representative negative sampling for graph positive-unlabeled learning},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance and interpretability analysis of code generation large language models. <em>NEUCOM</em>, <em>656</em>, 131461. (<a href='https://doi.org/10.1016/j.neucom.2025.131461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Large Language Models (LLMs) are increasingly getting integrated into software development workflows, understanding their reliability, error patterns and interpretability in real-world development scenarios is crucial for establishing their practical utility. This study evaluates and interprets the performance of 15 open-source LLM models, including Code LLaMa, Granite Code, DeepSeek-Coder-V2, and Yi-Coder on code translation and generation from requirements using the Rosetta Code dataset across diverse programming languages and tasks. Syntactic correctness and code quality are quantified using metrics such as CodeBLEU, chrF, and METEOR. Interpretability is explored through Feature Ablation and Shapley Value Sampling to elucidate prompt processing mechanisms. Results indicate high syntactic correctness and quality scores for models such as DeepSeek-Coder-V2 and Yi-Coder, alongside observed sensitivities to specific prompt components. This research provides quantitative and qualitative insights into the capabilities and limitations of open-source code-generating LLMs, informing model selection and the understanding of LLM-generated code.},
  archive      = {J_NEUCOM},
  author       = {Vishnu S. Pendyala and Neha B. Thakur},
  doi          = {10.1016/j.neucom.2025.131461},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131461},
  shortjournal = {Neurocomputing},
  title        = {Performance and interpretability analysis of code generation large language models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing long-term memory in federated class continual learning with lightweight adapters. <em>NEUCOM</em>, <em>656</em>, 131459. (<a href='https://doi.org/10.1016/j.neucom.2025.131459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) collaboratively trains a global model by aggregating local model parameters rather than raw data. Traditional FL frameworks assume that data classes are predefined and static. However, clients often encounter continuous data streams with dynamically emerging classes in practical applications, leading to a phenomenon known as catastrophic forgetting. Federated Class-Continual Learning (FCCL) has been introduced to address this challenge but still suffers from significant performance deterioration in scenarios with expanding task scales, particularly for tasks learned in the distant past. We propose a novel FCCL framework leveraging lightweight adapters to mitigate catastrophic forgetting as the number of tasks scales. To tackle the challenge of long-term memory decline, we developed task-specific adapters for clients to enhance memory retention. Additionally, we developed an image generation method tailored for lightweight adapters and trained task discriminators using the generated images. This enables the automatic loading of lightweight modules during inference, reducing human intervention. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet achieve significant performance improvements ranging from 1.73 to 4.07 times compared to baseline methods, effectively mitigating catastrophic forgetting in class-scaling scenarios. The complete implementation is available at https://github.com/notaerfa/FCLORA .},
  archive      = {J_NEUCOM},
  author       = {Pan Wang and Ji Wang and Zhengyi Zhong and Weidong Bao and Yaohong Zhang and Jianguo Chen},
  doi          = {10.1016/j.neucom.2025.131459},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131459},
  shortjournal = {Neurocomputing},
  title        = {Enhancing long-term memory in federated class continual learning with lightweight adapters},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive granular-ball based density peak clustering. <em>NEUCOM</em>, <em>656</em>, 131458. (<a href='https://doi.org/10.1016/j.neucom.2025.131458'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of data processing, the Granular-ball (GB) provides a coarse-grained data representation, offering a novel approach to improving clustering efficiency. The Fast Density Peak Clustering Algorithm based on Granular-balls (GB-DP) reduces computational granularity, which not only decreases operation time in large-scale data processing but also produces good clustering results. However, the GB-DP algorithm faces two main issues: sensitivity to the threshold parameter for generating GB and the requirement for manually selecting clustering centers, both of which affect the algorithm's efficiency and stability. To address these challenges, this paper proposes an Adaptive Granular-ball based Density Peak Clustering Algorithm (AGB-DP). First, a weighted Distribution Measure (DM) is used to dynamically generate GB. In contrast to the fixed threshold strategy used in GB-DP, this method effectively captures the data's distribution characteristics, mitigating the problem of parameter sensitivity. Second, by integrating two factors—data volume and geometric compactness—the density of GB is redefined, enhancing the accuracy of density calculations. Finally, an automatic screening strategy is employed to select GB as clustering centers, eliminating the instability introduced by manual intervention. Experimental results on both synthetic and real-world datasets demonstrate that AGB-DP, requiring only the number of clusters to be specified, achieves superior clustering results on most datasets compared to classical clustering algorithms and recent DP-based methods and shows greater robustness and stability.},
  archive      = {J_NEUCOM},
  author       = {Xingguo Zhang and Li Xu and Weikuan Jia},
  doi          = {10.1016/j.neucom.2025.131458},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131458},
  shortjournal = {Neurocomputing},
  title        = {Adaptive granular-ball based density peak clustering},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting the connections between images and deep feature vectors in model inversion attacks. <em>NEUCOM</em>, <em>656</em>, 131457. (<a href='https://doi.org/10.1016/j.neucom.2025.131457'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model inversion attack aims to reconstruct private samples from given deep neural networks. As the connections between the images and their corresponding deep feature vectors are unknown, it is difficult to utilize the information in the feature vectors during inversion. In this paper, connections between the images and their deep convolutional feature vectors are investigated. The directions of the vectors are used to represent the structures of both image vectors and feature vectors. Cosine similarity is further used to measure the structural similarity between different vectors. For a given target feature extractor, we find that the structures of the images and their feature vectors are highly correlated. Using this-property, Aug-MIA is proposed to perform model inversion with a few leaked feature vectors. In Aug-MIA, the feature vectors are first augmented by the proposed Structure Augmentation Algorithm. Then, a reconstruction model is trained using these augmented feature vectors to reconstruct images. Various experiments are performed on different datasets to validate our ideas. The results show that Aug-MIA performs better when fewer feature vectors are available. Specifically, when only 1 feature vector per class is leaked, it can improve the reconstruction rate by about 10.7 % on FaceScrub and about 4.2 % on MNIST, respectively.},
  archive      = {J_NEUCOM},
  author       = {Zeping Zhang and Jie Huang},
  doi          = {10.1016/j.neucom.2025.131457},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131457},
  shortjournal = {Neurocomputing},
  title        = {Exploiting the connections between images and deep feature vectors in model inversion attacks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent-space diffusion models for stealthy and transferable adversarial attacks on object detection. <em>NEUCOM</em>, <em>656</em>, 131456. (<a href='https://doi.org/10.1016/j.neucom.2025.131456'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tons of prior works have leveraged Generative Adversarial Networks (GANs) to synthesize adversarial examples that exhibit visual fidelity. Nonetheless, the intricacy of GANs’ latent space complicates the generation of imperceptible adversarial noises, rendering the process difficult to control. The emergence of diffusion models, which iteratively refine images through a progressive denoising mechanism, offers a more tractable and interpretable solution for a controllable generation. Inspired by this, we propose a latent-space-based covert adversarial attack framework (LSDM) grounded in diffusion models to craft adversarial examples that are both visually natural and highly effective against object detection models. Central to our approach is the Latent Space Perceptual Consistency Constraint, which ensures visual-consistency by embedding perturbations into the latent space for each denoising step, while utilizing the original image as a condition guider during the de-noising pass. Moreover, to balance attack performance and the risk of overfitting, we also propose a Stepwise Prediction and Adaptive Optimization strategy, which dynamically modulates the perturbations at the current time step and determines optimal number of diffusion time steps based on the transferability of the attack against diverse black-box models. To further enhance the framework’s attacking transferability, we introduce a novel Multi-box Translation Attack strategy, which augments the spatial location diversities for each bounding box. Extensive experiments demonstrate that, compared with state-of-the-art methods, LSDM further reduces the average black-box detection mAP by 1.52 %, while improving image quality scores by 1.71 % on object detection datasets such as COCO and VOC, showcasing superior attack effectiveness and visual fidelity. The source code is publicly available at https://github.com/LSDM .},
  archive      = {J_NEUCOM},
  author       = {Wenxuan Wang and Huihui Qi and Zhixiang Huang and Bangjie Yin and Peng Wang},
  doi          = {10.1016/j.neucom.2025.131456},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131456},
  shortjournal = {Neurocomputing},
  title        = {Latent-space diffusion models for stealthy and transferable adversarial attacks on object detection},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User intent disentanglement for multi-behavior recommendation via information bottleneck principle. <em>NEUCOM</em>, <em>656</em>, 131454. (<a href='https://doi.org/10.1016/j.neucom.2025.131454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-behavior recommendation systems have advanced rapidly by leveraging users’ diverse auxiliary behavior interactions to improve recommendations for the target behavior (a.k.a. purchase). While existing methods have made strides by integrating auxiliary behaviors with purchase histories to deliver high-quality recommendations, they often fail to identify spurious correlation intents within auxiliary behaviors that conflict with users’ target intents. Indiscriminately incorporating such correlations into the prediction of target intents may lead to performance degradation. To address this issue, we propose a Multi-Behavior Intent Disentanglement framework (MBID) for multi-behavior recommendation, which focuses on disentangling spurious correlation intents via the Information Bottleneck (IB) principle. In particular, we first design a time-sensitive spurious correlation coefficient to quantify spurious correlation intents and guide the subsequent multi-intent learning. Then, to disentangle spurious correlation intents, we propose a projection-based intent extraction method to decompose the genuine and spurious correlation intents within auxiliary behaviors. Based on this, we conceive an IB-based multi-intent learning task to disentangle the spurious correlation intents and transfer the genuine correlation intents from auxiliary behaviors into the target behavior, thereby obtaining high-quality representations of the target intent. Extensive experiments on three real-world datasets demonstrate that MBID significantly outperforms the state-of-the-art baselines by effectively disentangling the spurious correlation intents. We release our model implementation at: https://github.com/LokHsu/MBID .},
  archive      = {J_NEUCOM},
  author       = {Chenzhong Bin and Tongxin Xu and Feng Zhang},
  doi          = {10.1016/j.neucom.2025.131454},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131454},
  shortjournal = {Neurocomputing},
  title        = {User intent disentanglement for multi-behavior recommendation via information bottleneck principle},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PolyModNet: Advanced positional encodings and ethical bias mitigation in adaptive multimodal fusion for multilingual language understanding. <em>NEUCOM</em>, <em>656</em>, 131450. (<a href='https://doi.org/10.1016/j.neucom.2025.131450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural Language Understanding (NLU) plays a crucial role in Natural Language Processing (NLP), enabling machines to interpret and process human language across various applications. Despite advancements, challenges remain, including variations in data types, inconsistencies in labeling, computational demands, and biases in training datasets. These challenges emphasize the need for ethical and effective NLU solutions. To address these issues, the proposed PolyModNet combines techniques from NLP and computer vision to improve both text and image understanding. The model enhances data representation and compensates for limited training data using advanced augmentation methods such as mixup, gridmask, and positional encoding, optimized for Vision Transformer. By integrating RoBERTa-BERT and Vision Transformer, PolyModNet ensures accurate alignment of text and image features through Transformer-based encoding, specialized transformations, and structured positional encodings. Additionally, it employs a universal multilingual framework that enables language-independent retrieval and flexible task adaptation. Ethical concerns are addressed through bias detection and adversarial training, ensuring fairness in multimodal analysis. Extensive evaluations demonstrate the model’s effectiveness across multiple NLP tasks, achieving 85.71 % accuracy in sentiment analysis, strong text classification performance (CoLA: 64.1 %, SST2: 96.4 %), and high accuracy in text-image retrieval (R@1: 72.00, R@5: 89.25, R@10: 92.10). The model also delivers competitive results in multimodal translation (BLEU: 45.36, METEOR: 55.62) and cross-modal retrieval (text-to-image: R@1: 67.4, image-to-text: R@1: 82.3).},
  archive      = {J_NEUCOM},
  author       = {Shaharyar Alam Ansari and Mohd Anas Wajid and Mohd Arif and Mohammad Saif Wajid},
  doi          = {10.1016/j.neucom.2025.131450},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131450},
  shortjournal = {Neurocomputing},
  title        = {PolyModNet: Advanced positional encodings and ethical bias mitigation in adaptive multimodal fusion for multilingual language understanding},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wavelet attention is all you need in multimodal medical image fusion. <em>NEUCOM</em>, <em>656</em>, 131448. (<a href='https://doi.org/10.1016/j.neucom.2025.131448'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the multimodal medical image fusion, the fusion method based on frequency domain features is a research hotspot. However, “how to effectively enhance the high frequency and low frequency information in frequency domain?”, “how to fully interact the cross-modal spatial features in feature fusion?” are the keys to improve the fusion performance. To solve this problem, this paper proposes a multimodal medical image fusion network (WTA-Net) based on Wavelet Attention. The main innovations are as follows: Firstly, the Encoder-Decoder fusion network WTA-Net with dual-encoder and single-decoder is proposed. The network effectively capture the frequency domain features in different modal images and enhance the ability of information flow between modalities. Secondly, a Wavelet Attention(WA) is designed in the encoder, which effectively enhance the high frequency and low frequency information of the lesion. Thirdly, the Cross Modal Information Fusion Module(CMIFM) is designed in the fusion stage, which fully interactive cross-modal spatial features. Finally, experiments are performed on the Whole Brain Atlas dataset and the PET-CT lung dataset. In brain MRI images and PET images comparison experiment, IE, AG and EN evaluation indexes are improved by 18.92 %, 14 % and 18.25 %, respectively. In CT mediastinal window images and PET images comparison experiment, IE and SF evaluation indexes are improved by 12.08 % and 49.4 %, respectively, WTA-Net highlight the lession information, which has positive significance for computer-aided diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Tao Zhou and Mingzhe Zhang and Zhe Zhang and Jiaqi Wang and Yang Liu and Huiling Lu},
  doi          = {10.1016/j.neucom.2025.131448},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131448},
  shortjournal = {Neurocomputing},
  title        = {Wavelet attention is all you need in multimodal medical image fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-domain mutual compensation network for multi-modality image fusion. <em>NEUCOM</em>, <em>656</em>, 131443. (<a href='https://doi.org/10.1016/j.neucom.2025.131443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing research has demonstrated that fusing both spatial and frequency domain information from images can enhance fusion model performance, particularly in terms of saliency preservation and texture enhancement. However, designing effective fusion strategies to coordinate complementary information from both domains, while maximizing the unique characteristics and advantages of each and avoiding information conflict or redundancy, remains a challenge that requires further exploration and optimization. To address this issue, we propose a spatial–frequency Dual-Domain Mutual Compensation Network, termed D2Fusion. In our approach, the Mamba module serves as the core component of the spatial branch, capturing long-range dependencies to enhance the focus on the global spatial structure of input features. Simultaneously, the frequency branch utilizes fast Fourier Transform and convolutional neural networks to extract local texture details from the phase and magnitude components of the input features. Unlike traditional dual-branch networks, we introduce a novel phase fusion operation within the frequency branch, which combines phase information from different modalities to generate salient target features that complement and enhance the spatial features. Furthermore, to maximize the exchange of complementary characteristics between spatial, frequency, and salient target features, we design a Mutual Compensation Block (MCB) that accounts for feature differences and a decomposition loss function based on discrete cosine distance. The MCB facilitates compensatory fusion, while the decomposition loss function reduces feature similarity prior to compensation, maximizing the complementary information between domain features. Extensive experiments validate the superiority of our method, demonstrating that D2Fusion outperforms existing state-of-the-art approaches in both multi-modal image fusion and downstream task performance. The code for this framework is available at https://github.com/hz777xx/D2Fusion .},
  archive      = {J_NEUCOM},
  author       = {Jiwei Hu and Zhen Hu and Ping Lou and Kin-Man Lam and Qiwen Jin},
  doi          = {10.1016/j.neucom.2025.131443},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131443},
  shortjournal = {Neurocomputing},
  title        = {A dual-domain mutual compensation network for multi-modality image fusion},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchor-aware representation learning for multi-view clustering. <em>NEUCOM</em>, <em>656</em>, 131441. (<a href='https://doi.org/10.1016/j.neucom.2025.131441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anchor-based multi-view clustering has garnered considerable attention in recent years owing to its ability to reduce computational overhead and enable efficient processing of large-scale datasets. However, existing anchor-based multi-view clustering models still present limitation: while orthogonality constraints are imposed on anchors to enhance their discriminative properties, the inherent relationships among anchors are neglected. To address this limitation, a novel Anchor-Aware Representation Learning for Multi-view Clustering (AARLMC) model is proposed. Specifically, anchor-wise self-representation learning is implemented, with orthogonality constraints applied to the anchor self-representation matrices to uncover intrinsic relationships among anchors. Furthermore, enhanced anchor representations are generated through this process. The anchor graphs are stacked into a third-order tensor with tensor nuclear norm constraint to explore the high-order correlations among multi-view data. Anchor-wise self-representation learning, enhanced anchor representations, and tensor representation are integrated into a unified framework. An optimization algorithm is developed to solve the proposed model. Comparative experiments on twelve benchmark datasets against thirteen state-of-the-art multi-view clustering methods demonstrate that the proposed model achieves superior performance. The source code is available on https://github.com/guowei1314/AARLMC .},
  archive      = {J_NEUCOM},
  author       = {Haotian Zhang and Wei Guo and Ruiyin Liu and Qiang Yang and Xuefei Xiao and Jilin Li and Gang Lei and Gang Chen},
  doi          = {10.1016/j.neucom.2025.131441},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131441},
  shortjournal = {Neurocomputing},
  title        = {Anchor-aware representation learning for multi-view clustering},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft-label generator based on classifier weights. <em>NEUCOM</em>, <em>656</em>, 131436. (<a href='https://doi.org/10.1016/j.neucom.2025.131436'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft labels provide rich information between classes. Classification models obtain better generalization ability when soft labels are used as training targets in addition to hard ground-truth labels. In this paper, we propose a new approach named TarSamp to derive effective soft-targets only with the model’s classifier layer. This approach offers a simple, generic, and low-cost solution for soft label generation by fully leveraging the class-level semantics captured by the classifier layer and uncertainty injection with random sampling. We apply TarSamp to both teacher-free and teacher-available scenarios by using the classifier layer from the online model and a pre-trained teacher model, respectively. Extensive experiments on five standard image datasets are provided to evaluate the proposed approach for classifier training. TarSamp achieves more than 8 % accuracy on average for the teacher-free setting with ResNet-18, and gives on par performance by getting rid of querying to the teacher model in each forward pass during distillation for the teacher-available situation. Our results demonstrate that the proposed approach makes as a fundamental yet competitive baseline for a wide range of soft label based supervised learning.},
  archive      = {J_NEUCOM},
  author       = {Xinkai Chu and Jian-Ping Mei and Hang Zhou and Jie Chen and Rui Yan and Jing Fan},
  doi          = {10.1016/j.neucom.2025.131436},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131436},
  shortjournal = {Neurocomputing},
  title        = {Soft-label generator based on classifier weights},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CESDet: Hard pedestrian object detection architecture based on the cognitive experience of structure of human body. <em>NEUCOM</em>, <em>656</em>, 131429. (<a href='https://doi.org/10.1016/j.neucom.2025.131429'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional deep learning pedestrian detection methods usually only use the information of the current image itself. Incorrect results that go against common sense are prone to occur when dealing with hard objects with small size, unusual pose, or occlusions. Recent approaches try to enhance the hard objects by constructing and utilizing empirical information. However, due to an insufficient understanding of human body structure, the constructed experience exhibits poor generalization ability to diverse poses. Furthermore, when leveraging experiential features to enhance the features of hard objects, the process is susceptible to interference from occlusions and background. Inspired by human vision, we propose CESDet, a novel pedestrian detection network that constructs and utilizes Cognition Experience of Structure of human body in an unsupervised manner. The key technical innovations are three folds: (1) an unsupervised Cognition Experience of Structure construction module that addresses pose generalization by automatically forming decoupled body parts and pose semantics, (2) a part-level fine-grained verification and feature enhancement module that addresses the interference of occlusions and background with the guidance of Cognition Experience of Structure, and (3) an end-to-end pedestrian detection network for hard objects based on the two proposed modules. Experiments comparing with seven methods on three datasets demonstrate that CESDet achieves state-of-the-art performance, with highest AP on the training dataset, and lowest degradation of AP on a novel unseen dataset. The proposed framework advances the detection of hard objects by exploiting the automatically constructed Cognition Experience of Structure with decoupled part-level appearance and pose.},
  archive      = {J_NEUCOM},
  author       = {Yanglin Pu and Xiaohui Hao and Shan Yang and Hangyuan Yang and Shengxin Dai},
  doi          = {10.1016/j.neucom.2025.131429},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131429},
  shortjournal = {Neurocomputing},
  title        = {CESDet: Hard pedestrian object detection architecture based on the cognitive experience of structure of human body},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-related potential extraction workflow based on kernel density estimation. <em>NEUCOM</em>, <em>656</em>, 131425. (<a href='https://doi.org/10.1016/j.neucom.2025.131425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event-related potentials (ERPs) are a critical neuroscientific tool for investigating brain responses to external stimuli and serve as a key linking mechanism in brain–computer interface systems. Traditional ERP extraction methods rely on threshold-based trial rejection and time-locked averaging techniques, which often have limited ability to handle outlier data and are susceptible to random artifacts. To address this, we propose a novel ERP extraction workflow based on kernel density estimation. We construct trial-wise datasets at the sampling-point granularity and model the probability distribution of each trial using Gaussian kernel density estimation, effectively reducing outlier influence while preserving all trial data. The fitted probability density function serves as the objective function for ERP extraction, enabling active reconstruction of optimal ERP waveforms by incorporating inherent EEG temporal dependencies. Specifically targeting uneven noise distribution across multiple channels, we introduce an adaptively steering kernel dynamically generated from electrode covariance matrices, which optimizes the adaptive matching of inter-channel noise structures to ensure more precise density function fitting. Using two real datasets and simulated datasets, our comparative analyses of baseline root mean square error, component-level statistical metrics, and residual correlations demonstrate that, compared with the traditional trial rejection and time-locked averaging methods, our approach exhibits outstanding effectiveness in isolating ERP components from raw signals and significantly reduces the impact of outlier contamination.},
  archive      = {J_NEUCOM},
  author       = {Weizhuang Kong and Zihao Zhang and Jing Zhu and Yizhou Li and Xiaowei Li and Bin Hu},
  doi          = {10.1016/j.neucom.2025.131425},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131425},
  shortjournal = {Neurocomputing},
  title        = {Event-related potential extraction workflow based on kernel density estimation},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view optimization and refinement for high-fidelity 4D gaussian splatting. <em>NEUCOM</em>, <em>656</em>, 131424. (<a href='https://doi.org/10.1016/j.neucom.2025.131424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing dynamic 3D scenes from 2D images and synthesizing temporally diverse views is challenging due to the interplay between scene complexity and temporal dynamics. While 3D Gaussian Splatting offers an efficient solution for static scene modeling, extending it to dynamic scenes faces significant challenges in motion representation and texture fidelity. We propose a novel framework based on multi-view interpolation and joint optimization to address these challenges in sparse-view dynamic scenes. This framework combines linear and spherical interpolation strategies to generate novel views, producing high-quality interpolated images from multiple fitted viewpoints. Additionally, it incorporates consistency constraints to optimize texture representation, enhancing the reconstruction performance for dynamic scenes. Experimental results demonstrate that the proposed framework significantly improves detail fidelity and motion representation in dynamic scene reconstruction.},
  archive      = {J_NEUCOM},
  author       = {Jinhui Lin and Zhenyang Wei and Silei Shen and Fang Zhou and Xiaobin Zhu and Xu-Cheng Yin},
  doi          = {10.1016/j.neucom.2025.131424},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131424},
  shortjournal = {Neurocomputing},
  title        = {Multi-view optimization and refinement for high-fidelity 4D gaussian splatting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KD-KI: Knowledge distillation with knowledge infusion for anomaly detection and localization. <em>NEUCOM</em>, <em>656</em>, 131423. (<a href='https://doi.org/10.1016/j.neucom.2025.131423'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection and localization are crucial for improving product reliability in industrial quality inspection. Existing knowledge distillation methods often cause student networks to merely mimic features of teacher networks, which makes it difficult to achieve stable and generalized detection performance. This paper introduces the KD-KI framework, which uses a knowledge infusion mechanism to transfer structured hierarchical knowledge from the teacher network to the student network. This guides the student to learn more robust representations of normal samples. Additionally, a feature bias loss is used to optimize the similarity of shallow-layer features, improving detection accuracy and localization precision. KD-KI can be deployed with standard convolutional networks and is suitable for real-time industrial inspection systems. Experimental results demonstrate that the proposed KD-KI model can yield improved performance in anomaly detection and localization compared to other competing models.},
  archive      = {J_NEUCOM},
  author       = {Wei Huang and Zhaonan Xu and Rongchun Wan and Xuhua Yang and Bingyang Zhang},
  doi          = {10.1016/j.neucom.2025.131423},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131423},
  shortjournal = {Neurocomputing},
  title        = {KD-KI: Knowledge distillation with knowledge infusion for anomaly detection and localization},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFCon: Dominant frequency enhanced ultra-long time series contrastive forecasting. <em>NEUCOM</em>, <em>656</em>, 131418. (<a href='https://doi.org/10.1016/j.neucom.2025.131418'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultra-long time series forecasting (ULTSF) is crucial for fields like energy management, traffic planning, and climate prediction. However, as the forecast horizon increases, concept drift becomes a major challenge, as a fixed-length historical window struggles to generalize ultra-long temporal patterns. Extending the input series length increases computational costs and demands a higher model capacity for capturing longer temporal dependencies. To address these issues, we propose DFCon, a dominant frequency enhanced contrastive learning framework for ULTSF. DFCon combines dilated convolutions for feature extraction and multi-layer perceptrons for forecasting, with a dual contrastive loss based on dominant frequency enhancement. We introduce Temporal DFCon, which enhances the model’s sensitivity to these frequency-domain features during training, thereby improving its ability to model global temporal dependencies in the input series. Furthermore, cross-window Autocorrelated DFCon is proposed, which mitigates concept drift by constructing autocorrelated relative positive and negative samples without introducing noisy data. Experiments on five benchmark datasets show that DFCon outperforms existing methods, demonstrating its effectiveness in ULTSF. The code for this work is publicly available at: https://github.com/coding4qq/DFCon .},
  archive      = {J_NEUCOM},
  author       = {Qiaoqiao Liu and Hui Liu and MingJie Yang and Yuheng Wei and Junzhao Du},
  doi          = {10.1016/j.neucom.2025.131418},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131418},
  shortjournal = {Neurocomputing},
  title        = {DFCon: Dominant frequency enhanced ultra-long time series contrastive forecasting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Breaking the alignment barrier: A spatiotemporal alignment-free RGBT tracking approach. <em>NEUCOM</em>, <em>656</em>, 131382. (<a href='https://doi.org/10.1016/j.neucom.2025.131382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-Thermal (RGBT) tracking leverages complementary information from visible and infrared modalities to improve tracking robustness in complex environments. However, its practical deployment remains constrained by the stringent requirement for precise spatiotemporal alignment between heterogeneous modalities—a condition rarely satisfied in real-world applications. To overcome this limitation, we present SAFNet, a novel Spatiotemporal Alignment-Free Network that eliminates the need for precise cross-modal alignment through innovative architectural designs. Our framework develops a spatiotemporal interaction query module incorporating cross-modal temporal attention, which re-establishes inter-modal temporal correlations for unregistered inputs by leveraging similarity learning across asynchronous data streams. For spatial discrepancy mitigation, we propose a dual-branch pre-tracking network employing deep cross-correlation analysis, combined with an adaptive feature fusion strategy under the guidance of joint response distribution. Furthermore, we devise an innovative dynamic template update mechanism that adaptively adjusts modal update rates to maintain temporal consistency across heterogeneous data streams. Comprehensive evaluations validate SAFNet’s state-of-the-art performance across four benchmark datasets (GTOT, RGBT210, RGBT234, LasHeR), demonstrating significant improvements in tracking accuracy. The proposed architecture represents a significant advancement toward practical deployment of robust RGBT tracking systems in real-world environments with asynchronous multimodal inputs.},
  archive      = {J_NEUCOM},
  author       = {Xiaodong Liu and Meibo Lv and Daming Zhou and Lingyu Si and Ruiheng Zhang and Hui Xu},
  doi          = {10.1016/j.neucom.2025.131382},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131382},
  shortjournal = {Neurocomputing},
  title        = {Breaking the alignment barrier: A spatiotemporal alignment-free RGBT tracking approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring cycle cover variants: A dataless neural networks approach. <em>NEUCOM</em>, <em>656</em>, 131361. (<a href='https://doi.org/10.1016/j.neucom.2025.131361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cycle Cover, a fundamental concept in graph theory, plays a critical role in various applications, including network design, transportation optimization, and bioinformatics. A Cycle Cover is a collection of cycles covering all the vertices of a given graph, ensuring that each vertex belongs to exactly one cycle. In this paper, we explore various aspects of Cycle Cover variants. We employ the dataless neural networks framework to establish single differentiable functions for each of these variants. Recent research has demonstrated the capability of the dataless neural networks framework in representing a host of combinatorial optimization problems. Motivated by these findings, we propose dataless neural networks tailored for the Cycle Cover variants. Additionally, we present a rigorous proof of the correctness of our approach.},
  archive      = {J_NEUCOM},
  author       = {Sangram K. Jena and K. Subramani and Alvaro Velasquez},
  doi          = {10.1016/j.neucom.2025.131361},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131361},
  shortjournal = {Neurocomputing},
  title        = {Exploring cycle cover variants: A dataless neural networks approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight deep learning for visual perception: A survey of models, compression strategies, and edge deployment challenges. <em>NEUCOM</em>, <em>656</em>, 131357. (<a href='https://doi.org/10.1016/j.neucom.2025.131357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for the deployment of deep neural networks (DNNs) in edge devices has led to the development of lightweight deep learning (LDL) models designed to operate efficiently under resource constraints. Although DNNs have achieved remarkable success in various applications, their high computational requirements often limit their deployment on devices with restricted memory and processing power. This challenge has motivated researchers to develop optimized LDL models that balance accuracy, speed, and efficiency while maintaining competitive performance. Despite existing surveys covering specific aspects of LDL models, a comprehensive review encompassing image classification, object detection, and segmentation remains limited. This proposed survey systematically explores recent advancements in LDL models, highlighting their architectures, optimization techniques, and real-world applications. This survey conducts an empirical evaluation by testing latest state-of-the-art LDL models on the Jetson Orin edge device using benchmark datasets: ImageNet for classification, VisDrone for object detection, and COCO for segmentation. The experimental analysis focuses on key performance metrics, including inference speed, model accuracy, and computational efficiency, while comparing LDL models with their conventional counterparts. This study provides a holistic understanding of the role of LDL models in edge computing, providing insight into emerging trends, challenges, and future research directions in the field.},
  archive      = {J_NEUCOM},
  author       = {Syed Muhammad Raza and Syed Murtaza Hussain Abidi and Md Masuduzzaman and Soo Young Shin},
  doi          = {10.1016/j.neucom.2025.131357},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131357},
  shortjournal = {Neurocomputing},
  title        = {Lightweight deep learning for visual perception: A survey of models, compression strategies, and edge deployment challenges},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LaSNN: Layer-wise ANN-to-SNN distillation for effective and efficient training in deep spiking neural networks. <em>NEUCOM</em>, <em>656</em>, 131351. (<a href='https://doi.org/10.1016/j.neucom.2025.131351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are biologically realistic and practically promising in low-power computation because of their event-driven mechanism. Usually, the training of SNNs suffers from accuracy loss on various tasks, yielding an inferior performance compared with ANNs. A conversion scheme is proposed to obtain competitive accuracy by mapping trained ANNs’ parameters to SNNs with the same structures. However, an enormous number of time steps are required for these converted SNNs, thus losing the energy-efficient benefit. Utilizing both the accuracy advantages of ANNs and the computing efficiency of SNNs, a novel SNN training framework is proposed, namely layer-wise ANN-to-SNN knowledge distillation (LaSNN). In order to achieve competitive accuracy and reduced inference latency, LaSNN transfers the learning from a well-trained ANN to a small SNN by distilling the knowledge rather than converting the parameters of ANN. The information gap between heterogeneous ANN and SNN is bridged by introducing the attention scheme. The knowledge in an ANN is effectively compressed and then efficiently transferred by utilizing our layer-wise distillation paradigm. We conduct detailed experiments to demonstrate the effectiveness, efficacy, and scalability of LaSNN on three benchmark data sets (CIFAR-10, CIFAR-100, and Tiny ImageNet). We achieve competitive top-1 accuracy compared to ANNs and faster inference than converted SNNs with similar performance. More importantly, LaSNN is dexterous and extensible that can be effortlessly developed for SNNs with different architectures/depths and input encoding methods, contributing to their potential development.},
  archive      = {J_NEUCOM},
  author       = {Di Hong and Yu Qi and Yueming Wang},
  doi          = {10.1016/j.neucom.2025.131351},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131351},
  shortjournal = {Neurocomputing},
  title        = {LaSNN: Layer-wise ANN-to-SNN distillation for effective and efficient training in deep spiking neural networks},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing spatio-temporal information using supervised local low-rank correlation embedding for depression recognition. <em>NEUCOM</em>, <em>656</em>, 131350. (<a href='https://doi.org/10.1016/j.neucom.2025.131350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) signals contain rich spatio-temporal information that reflects the brain’s dynamic activity, making it widely used in depression recognition. However, effectively integrating this information to capture discriminative and complementary features remains a key challenge. To address this issue, we propose a novel Discriminative Local Low-Rank Correlation Embedding (DLLCE) to fuse spatio-temporal information of EEG. DLLCE integrates shared low-rank representation, local invariance, discriminative constraints, and enhanced correlation analysis into a unified framework. Specifically, the shared low-rank representation is used to capture the common structural patterns, while the correlation analysis aims to reduce redundancy among feature sets. In addition, the Laplacian regularization is applied to the shared representation to preserve the local geometric structure of the original data. To further enhance discriminative capability, a discriminant graph embedding term is incorporated to exploit label information. Experimental results on EEG datasets demonstrate that DLLCE achieves superior performance compared to existing methods. This work provides new insights into EEG-based mental health assessment and holds promise for early depression diagnosis and clinical decision support.},
  archive      = {J_NEUCOM},
  author       = {Lu Zhang and Peng Xu and Zhijun Yao and Xinyan Zhang and Juan Wang and Bin Hu and Gang Feng and Hong Peng},
  doi          = {10.1016/j.neucom.2025.131350},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131350},
  shortjournal = {Neurocomputing},
  title        = {Fusing spatio-temporal information using supervised local low-rank correlation embedding for depression recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-driven baseline for few-shot fine-grained visual recognition. <em>NEUCOM</em>, <em>656</em>, 131302. (<a href='https://doi.org/10.1016/j.neucom.2025.131302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot fine-grained visual recognition (FS-FGVR), a practical yet challenging task, aims to break the dilemma of having scarce training examples for new fine-grained tasks. Meta-learning-based methods target this issue by employing the learning-to-learn strategy to train a well-generalized meta-learner from seen fine-grained tasks for unseen fine-grained tasks. However, most existing works rely too much on small-scale fine-grained training tasks. Specifically, these works demand large amounts of fine-grained data to sample these training tasks, and they are unable to generalize well to new tasks. Consequently, model capacity can be highly restricted when limited training references are available. This paper presents a novel coarse-to-fine framework named Knowledge-Driven baseline for FS-FGVR by transferring knowledge from large-scale and coarse-grained datasets. This framework departs the meta-training phase into the coarse-grained meta-pretraining and fine-grained meta-finetuning phases. First, off-the-shelf coarse-grained data is introduced to build the initialization correlations as prior knowledge. Then, we use prior knowledge to infer the representational interactions and correlations of the fine-grained representations. Extensive experiments show that our method outperforms the current methods on the public few-shot fine-grained benchmarks. We also develop extensive studies to extend our method to few-shot texture visual recognition scenarios.},
  archive      = {J_NEUCOM},
  author       = {Jieqi Sun and Jian Li and Yafeng Li},
  doi          = {10.1016/j.neucom.2025.131302},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131302},
  shortjournal = {Neurocomputing},
  title        = {Knowledge-driven baseline for few-shot fine-grained visual recognition},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BMTM-net: A rotating machinery fault diagnosis network based on 2D-1D fusion with bidirectional multi-granularity transformer-mamba. <em>NEUCOM</em>, <em>656</em>, 131293. (<a href='https://doi.org/10.1016/j.neucom.2025.131293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotating machinery plays a critical role in industrial operations, yet existing diagnostic methods often struggle with missing correlations between sensor data, weak noise immunity, and insufficient long-range feature extraction. To address these challenges, this paper proposes BMTM-Net, a fault diagnosis network based on 2D-1D fusion with Bidirectional Multi-granularity Transformer-Mamba (BMTM). The network consists of two main components: a 2D sequential information interaction network and a 1D temporal information extraction network. The 2D network captures inter-sensor sequence relationships and temporal dependencies using a Bidirectional Multi-granularity Transformer (BM-Transformer) and an embedded Sequential-Temporal Attention Module (ST-Attention), while the 1D network enhances feature completeness and extracts temporal information through a Bidirectional Multi-granularity Mamba (BM-Mamba) network, integrated with a Channel Attention-based Fusion Module (CAFM) for adaptive feature fusion. To evaluate BMTM-Net’s effectiveness and stability, experiments were conducted on datasets from Southeast University and a Self-Built bogie integrated test stand, with various levels of noise introduced to assess noise immunity. The results demonstrate that BMTM-Net achieves over 99 % accuracy across all four datasets and maintains high accuracy even under severe noise interference (SNR = −10 dB), outperforming other state-of-the-art methods with accuracy rates of 99.60 %, 99.40 %, 98.54 %, and 94.38 %, respectively. Additionally, the model exhibits low complexity, further confirming its robustness and effectiveness in noisy environments.},
  archive      = {J_NEUCOM},
  author       = {E. Xia and Yirong Liu and Jinyang Gong and Xunhua Dai and Tongyang Pan and Shiyi Wang},
  doi          = {10.1016/j.neucom.2025.131293},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131293},
  shortjournal = {Neurocomputing},
  title        = {BMTM-net: A rotating machinery fault diagnosis network based on 2D-1D fusion with bidirectional multi-granularity transformer-mamba},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancements in radiomics: A comprehensive survey of feature types and their correlation on modalities and regions. <em>NEUCOM</em>, <em>656</em>, 131192. (<a href='https://doi.org/10.1016/j.neucom.2025.131192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey paper provides an overview of different feature types used in radiomics research and their applications across various medical imaging modalities and disease domains. The paper delves into the key aspects of the radiomics workflow, including data engineering techniques for image acquisition, preprocessing, fusion, and segmentation. It then presents a comprehensive review of the most commonly employed feature categories in radiomics, such as shape-based, first-order statistical, second-order texture, and transform-based features. The paper also discusses the emerging role of deep learning features extracted using convolutional neural networks, recurrent neural networks, and transformers. The analysis of feature usage trends across different anatomical regions and imaging modalities offers valuable insights that can guide the optimization of feature engineering strategies in future radiomics research. The survey concludes by highlighting several opportunities for further advancement in the field, including the need for larger multi-center datasets, multi-modal data fusion, self-supervised learning, and the development of efficient embedded models for on-device deployment.},
  archive      = {J_NEUCOM},
  author       = {Luca Zedda and Andrea Loddo and Cecilia Di Ruberto},
  doi          = {10.1016/j.neucom.2025.131192},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131192},
  shortjournal = {Neurocomputing},
  title        = {Advancements in radiomics: A comprehensive survey of feature types and their correlation on modalities and regions},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive low-confidence pseudolabeling for semisupervised node classification. <em>NEUCOM</em>, <em>656</em>, 131166. (<a href='https://doi.org/10.1016/j.neucom.2025.131166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have demonstrated remarkable achievements in handling graph-structured data. However, the performance of GNNs is typically limited by the lack of sufficient labeled data, which are time-consuming to obtain in real-world scenarios. Pseudolabeling has been applied to GNNs by augmenting the training set data with unlabeled data. Most pseudolabeling methods on graphs assign pseudolabels to nodes based on high-confidence thresholds. However, nodes near labeled ones generally obtain high confidence scores during training. This results in an increasing number of similar nodes being assigned pseudolabels during training, which potentially leads to a distribution shift between the labeled dataset and the augmented dataset. The distribution of the augmented dataset diverges significantly from that of the entire graph data, causing the GNNs to perform poorly on test data. In this paper, we propose a progressive low-confidence pseudolabeling (PLCP) method to progressively leverage the low-confidence data. Specifically, pseudolabels are assigned to nodes within a predefined confidence-based ranking range. To alleviate distribution shift, we keep this range constant throughout the training process to prevent excessive nodes from being assigned pseudolabels. The range is designed to be sufficiently wide to leverage low-confidence nodes. Low-confidence nodes from the range propagate information to their neighbors, which helps the model capture patterns in uncertain regions. To alleviate the impact of noisy pseudolabels, a validation-based reassignment scheme is proposed to utilize validation metrics to assign more reliable pseudolabels. Numerous experiments are conducted to demonstrate that our proposed PLCP improves the performance of state-of-the-art GNNs on graph datasets in comparison with several established methods.},
  archive      = {J_NEUCOM},
  author       = {Tao Zhu and Hua Mao and Hui Liu and Jie Chen},
  doi          = {10.1016/j.neucom.2025.131166},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131166},
  shortjournal = {Neurocomputing},
  title        = {Progressive low-confidence pseudolabeling for semisupervised node classification},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep-DFVAR: Dynamic factor vector autoregression with deep learning for regional house price index forecasting. <em>NEUCOM</em>, <em>656</em>, 131103. (<a href='https://doi.org/10.1016/j.neucom.2025.131103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {House Price Index (HPI) is an indicator that reflects changes in residential house prices over time. Predicting HPI is crucial for homebuyers to determine the right time to purchase and for policymakers to formulate housing policies. Recent studies have reported that neural network approaches outperform classical methods in HPI forecasting. However, challenges remain due to limited monthly HPI data and its time-varying statistical properties. As a result, state-of-the-art time series forecasting models often respond slowly to abrupt changes and lack economic interpretability. To address these issues, we propose Deep-DFVAR, a hybrid framework that decomposes regional HPI into shared (common trends) and idiosyncratic (regional variations) components. The shared component is predicted with Vector Autoregression (VAR) based on Granger causality, which improves interpretability and responds faster to changes. The idiosyncratic component is modeled with our deep learning model, which benefits from reduced distribution shift (train–test gap). We evaluate Deep-DFVAR on South Korean and United States datasets, empirically demonstrating that our framework outperforms traditional and recent time series forecasting models. All data and code are publicly available at: https://github.com/YeoJiSu/House-Price-Index-Prediction .},
  archive      = {J_NEUCOM},
  author       = {Jisu Yeo and Artyom Stitsyuk and Jaesik Choi},
  doi          = {10.1016/j.neucom.2025.131103},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131103},
  shortjournal = {Neurocomputing},
  title        = {Deep-DFVAR: Dynamic factor vector autoregression with deep learning for regional house price index forecasting},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-based triple asynchronous switching control for fuzzy neural networks: A full-information dependent lyapunov approach. <em>NEUCOM</em>, <em>656</em>, 131097. (<a href='https://doi.org/10.1016/j.neucom.2025.131097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper employs the full-information dependent Lyapunov-Krasovskii functional (LKF) analysis approach to investigate the multiple weighting adaptive event-triggered triple asynchronous switching control problem for Takagi-Sugeno fuzzy neural networks with semi-Markov jump parameters. Considering the influence of factors such as network delays and disturbances, there may be asynchronous premise variables and modes among the system, event generator and controller. Therefore, a triple asynchronous switching control framework under the multiple weighting adaptive event-triggered scheme is developed. Under this control framework, a novel full-information dependent LKF analysis approach is proposed to analyze the stability of neural networks, which fully considers the system information, such as the membership functions (MFs) information, modes information and state information. Meanwhile, a new MFs dependent optimal H ∞ performance index is introduced to achieve better disturbance attenuation ability. The proposed analysis approach is helpful in determining the controller gains and reducing the conservatism. Ultimately, four simulation examples are provided to show the effectiveness and superiority of proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Yiteng Zhang and Linchuang Zhang and Yonghui Sun and Wen Yang},
  doi          = {10.1016/j.neucom.2025.131097},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131097},
  shortjournal = {Neurocomputing},
  title        = {Event-based triple asynchronous switching control for fuzzy neural networks: A full-information dependent lyapunov approach},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCHF_T: A multi-dimensional adaptive compression approach for transformer-based models. <em>NEUCOM</em>, <em>656</em>, 131071. (<a href='https://doi.org/10.1016/j.neucom.2025.131071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, pre-trained language models based on the Transformer architecture have achieved significant results in many natural language processing tasks. However, the high computational cost limits their application in real-world scenarios. Previous Transformer compression methods typically focus on single-dimensional compression, which may cause over-compression and consequently degrade model performance. Additionally, these methods lack targeted optimization for specific downstream tasks. In this paper, we propose DCHF_T, a multi-dimensional adaptive compression approach that compresses Transformer models through token compression, attention head pruning, and a lightweight FFN. This approach selects the most informative tokens during training, prunes unimportant tokens, and retains their information in a compressed form, allowing the model to focus more on task-relevant inputs. Furthermore, DCHF_T combines attention head pruning and a lightweight FFN to reduce computation and parameter size across multiple dimensions. We employ multi-objective evolutionary search to optimize the trade-off between accuracy and efficiency under various computational budgets. Experimental results on the GLUE benchmark demonstrate that DCHF_T achieves the best compression–performance trade-off. While maintaining the highest accuracy, DCHF_T achieves a reduction of 3.7 × and 3.6 × in FLOPs on BERT-base and RoBERTa-base, respectively. By implementing adaptive multi-dimensional compression, DCHF_T provides a systematic solution for deploying Transformer models in resource-constrained scenarios.},
  archive      = {J_NEUCOM},
  author       = {Yaoyao Yan and Da Wang and Jing Ye and Hui Yu and Dianjie Lu and Yuang Zhang and Weizhi Xu and Fang’ai Liu},
  doi          = {10.1016/j.neucom.2025.131071},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {131071},
  shortjournal = {Neurocomputing},
  title        = {DCHF_T: A multi-dimensional adaptive compression approach for transformer-based models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key-concept thinking prompting for improved reasoning in large language models. <em>NEUCOM</em>, <em>656</em>, 130986. (<a href='https://doi.org/10.1016/j.neucom.2025.130986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in large language models (LLMs) have significantly accelerated the development of natural language processing (NLP) research, demonstrating remarkable capabilities in understanding and generating human-like text. However, these models face limitations when it comes to system 2 tasks, which require slow, multi-step, and conscious reasoning. To address these limitations, we introduce a method called Key-Concept Thinking (KCT), which enhances the model’s reasoning ability by directing it to identify and prioritize key concepts within a problem. Building on the Chain-of-Thought (CoT) prompting method, KCT anchors its approach in core ideas, allowing the model to form a deeper understanding of the problem’s structure and purpose. This targeted approach aims to improve both the accuracy and efficiency of the model’s reasoning, making it better equipped to handle tasks that require precision and deep understanding. We evaluate our proposed prompting strategies using 24 reasoning tasks across four categories: arithmetic, commonsense, symbolic, and other logical reasoning tasks, with three prominent large models: ChatGLM4, Baichuan2, and DeepSeek, respectively. The results show that the Zero-shot-KCT and Zero-shot-CoT-KCT strategies outperform traditional zero-shot and few-shot prompting strategies, highlighting the effectiveness of incorporating key concept thinking into the reasoning processes of LLMs. Our findings have implications for the development of more effective prompting strategies for LLMs that can handle complex reasoning tasks with higher accuracy and coherence.},
  archive      = {J_NEUCOM},
  author       = {Minghua Tang and Chen Bian and Liming Yang and Xueling Zhong},
  doi          = {10.1016/j.neucom.2025.130986},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {130986},
  shortjournal = {Neurocomputing},
  title        = {Key-concept thinking prompting for improved reasoning in large language models},
  volume       = {656},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="nn">NN - 31</h2>
<ul>
<li><details>
<summary>
(2026). DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation. <em>NN</em>, <em>194</em>, 108118. (<a href='https://doi.org/10.1016/j.neunet.2025.108118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vascular morphology plays a crucial role in diagnosing diseases such as diabetes, glaucoma, and hypertension, making accurate segmentation of retinal vessels essential for early intervention. Traditional segmentation methods assume that training and testing data share similar distributions, which can lead to poor performance on unseen domains due to domain shifts caused by variations in imaging devices and patient demographics. This paper presents a novel approach, DGSSA, for retinal vessel image segmentation that enhances model generalization by combining structural and stylistic augmentation strategies. We utilize a space colonization algorithm to generate diverse vascular-like structures that closely mimic actual retinal vessels, which are then used to generate pseudo-retinal images with an improved Pix2Pix model, allowing the segmentation model to learn a broader range of structure distributions. Additionally, we utilize PixMix to apply random photometric augmentations and introduce uncertainty perturbations, enriching the stylistic diversity of fundus images and further improving the model’s robustness and generalization across varying imaging conditions. Our framework, which employs a DeepLabv3+ model with a MobileNetV2 backbone as its segmentation network, has been rigorously evaluated on four challenging datasets—DRIVE, CHASEDB1, HRF, and STARE—achieving Dice Similarity Coefficient (DSC) of 78.45%, 78.62%, 72.66% and 82.17%, respectively, with an average DSC of 77.98%. These results demonstrate that our method surpasses existing approaches, validating its effectiveness and highlighting its potential for clinical application in automated retinal vessel analysis.},
  archive      = {J_NN},
  author       = {Bo Liu and Yudong Zhang and Shuihua Wang and Siyue Li and Jin Hong},
  doi          = {10.1016/j.neunet.2025.108118},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108118},
  shortjournal = {Neural Netw.},
  title        = {DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution. <em>NN</em>, <em>194</em>, 108116. (<a href='https://doi.org/10.1016/j.neunet.2025.108116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data distribution discrepancy across datasets is one of the major obstacles hindering the improvement of the accuracy of cross-domain adaptive detection of medical images. To address this challenge, we propose a novel lightweight cross-modal adaptive detection module named LCA-Med (LCaM). The proposed module boasts a lightweight structure and a minimalistic parameter count, thereby facilitating its integration into the anterior segment of a diverse array of foundational and downstream networks. It is adept at serving as a feature preprocessor, proficiently extracting pertinent information regrading pathologies from a array of images (image modality) produced through varied medical imaging techniques, all guided by the input of prompts (text modality). We also propose a novel cross-modal medical image adaptive detection method, LCA-Med CNX (LCaM-CNX), and a novel cross-domain adaptive detection training paradigm that incorporates generated dataset groups, an attention module, and a meta-heuristic algorithm. Experimental results on six medical image datasets compared with ten state-of-the-art methods demonstrate that the LCaM-CNX trained following the proposed paradigm achieves the best performance on five datasets and competitive performance on the other dataset. Notably, our method outperforms the state-of-the-art methods more when the data distribution is more imbalanced.},
  archive      = {J_NN},
  author       = {Xiang Li and Long Lan and Husam Lahza and Shaowu Yang and Shuihua Wang and Yong Liang and Hudan Pan and Wenjing Yang and Hengzhu Liu and Yudong Zhang},
  doi          = {10.1016/j.neunet.2025.108116},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108116},
  shortjournal = {Neural Netw.},
  title        = {LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Counterfactual causal inference for robust visual question answering. <em>NN</em>, <em>194</em>, 108115. (<a href='https://doi.org/10.1016/j.neunet.2025.108115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) systems have seen remarkable progress with the incorporation of multimodal data. However, their performance is still hampered by biases ingrained in language and vision modalities, frequently resulting in subpar generalization. In this study, we introduce a novel counterfactual causal framework (CC-VQA). This framework utilizes Counterfactual Sample Synthesis (CSS) and causal inference to tackle cross-modality biases. Our approach innovatively employs a strategy based on causal graphs, which effectively disentangles spurious correlations in multimodal data. This ensures a balanced and precise multimodal reasoning process, enabling the model to make more accurate and unbiased decisions. Moreover, we propose a contrastive loss mechanism. By contrasting the embeddings of positive and negative samples, this mechanism significantly enhances the robustness of VQA models. Additionally, we develop a robust training strategy that improves both the visual-explainable and question-sensitive capabilities of these models. Our experimental evaluations on benchmark datasets, such as VQA-CP v2 and VQA v2, demonstrate substantial improvements in bias mitigation and overall accuracy. The proposed CC-VQA framework outperforms state-of-the-art methods, highlighting its effectiveness in enhancing the performance of VQA systems.},
  archive      = {J_NN},
  author       = {Wei Li and Zhixin Li and Fuyun Deng and Kun Zeng and Canlong Zhang},
  doi          = {10.1016/j.neunet.2025.108115},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108115},
  shortjournal = {Neural Netw.},
  title        = {Counterfactual causal inference for robust visual question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the theoretical expressive power of graph transformers for solving graph problems. <em>NN</em>, <em>194</em>, 108112. (<a href='https://doi.org/10.1016/j.neunet.2025.108112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Transformers have become the dominant neural architecture in the fields of natural language processing and computer vision. The generalization of Transformers to graphs, so-called Graph Transformers, have recently emerged as a promising alternative to the successful message passing Graph Neural Networks (MPNNs). While the expressive power of MPNNs has been intensively studied in the past years, that of Graph Transformers is still underexplored. Existing results mostly rely on the employed structural/positional encodings and not on the pure architecture itself. However, gaining an understanding of the strengths and limitations of Graph Transformers would be very useful both for the scientific community and the practitioners. In this paper, we derive a connection between Graph Transformers and the Congested clique , a popular model in distributed computing. This connection allows us to translate theoretical results for different graph problems from the latter to the former. We show that under certain conditions, Graph Transformers with depth 2 are Turing universal. We also show that there exist Graph Transformers that can solve problems which cannot be solved by MPNNs. We empirically investigate whether Graph Transformers and MPNNs with depth 2 can solve graph problems on some molecular datasets. Our results demonstrate that Graph Transformers can generally address the underlying tasks, while MPNNs are incapable of learning any information about the graph.},
  archive      = {J_NN},
  author       = {Giannis Nikolentzos and Dimitrios Kelesis and Michalis Vazirgiannis},
  doi          = {10.1016/j.neunet.2025.108112},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108112},
  shortjournal = {Neural Netw.},
  title        = {On the theoretical expressive power of graph transformers for solving graph problems},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders. <em>NN</em>, <em>194</em>, 108110. (<a href='https://doi.org/10.1016/j.neunet.2025.108110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodevelopmental disorders exhibit highly similar behavioral characteristics in clinical assessments, heavily relying on subjective behavioral reports, leading to insufficient understanding of the neurobiological mechanisms behind inter-patient heterogeneity and symptom overlap between diseases. To address this issue, this study proposes a graph neural network framework that integrates neuroimaging data, focusing on three key problems: Firstly, enhance the nonlinear features in brain neural activity by introducing the Neurodynamics Rössler system. Transform raw static neural signals into simulated signals with nonlinear, temporal, and dynamic features, thereby more accurately reflecting the process of brain neural activity. Secondly, improve feature discrimination by integrating the spatial adjacency characteristics of local brain regions with the topological structure information of the global brain network to highlight key features. Thirdly, improve noise resistance and generalization ability. Introducing adaptive controllers and cross-site adversarial learning mechanisms, the interference of heterogeneous noise is effectively reduced. This study conducted experimental validation on data from neurodevelopmental disorders such as ADHD and ASD. The results indicate that this framework not only has advantages in classification accuracy but also possesses good interpretability, making it a promising tool for imaging biomarker research and auxiliary diagnosis.},
  archive      = {J_NN},
  author       = {Qiulei Han and Hongbiao Ye and Miaoshui Bai and Lili Wang and Yan Sun and Ze Song and Jian Zhao and Lijuan Shi and Zhejun Kuang},
  doi          = {10.1016/j.neunet.2025.108110},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108110},
  shortjournal = {Neural Netw.},
  title        = {MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stability of large-scale probabilistic boolean networks via network aggregation. <em>NN</em>, <em>194</em>, 108108. (<a href='https://doi.org/10.1016/j.neunet.2025.108108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale probabilistic Boolean networks (LSPBNs) are a modeling tool used to simulate and analyze the dynamics of complex systems with uncertainty. However, due to its high computational complexity, previous research methods cannot be directly applied to study such systems. Inspired by network aggregation, this paper conducts network aggregation on LSPBNs to investigate its global stability with probability 1. It is worth mentioning that the stability conclusion proposed in this article holds for any form of network aggregation. First, the entire network is partitioned and the algebraic expressions for each subnetwork are given through the semi-tensor product of matrices. And then, a set of iterative formulas is constructed to describe and reflect the input-output coordination relationship among the subnetworks, and based on which, a sufficient condition for the global stability of LSPBNs is derived, greatly reducing computational complexity. The feasibilities of the proposed method and results are verified through examples.},
  archive      = {J_NN},
  author       = {Wen Liu and Shihua Fu and Jianjun Wang and Renato De Leone and Jianwei Xia},
  doi          = {10.1016/j.neunet.2025.108108},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108108},
  shortjournal = {Neural Netw.},
  title        = {Stability of large-scale probabilistic boolean networks via network aggregation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPC: Self-supervised point cloud completion. <em>NN</em>, <em>194</em>, 108107. (<a href='https://doi.org/10.1016/j.neunet.2025.108107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape incompleteness is a common issue in point clouds acquired by depth sensors. Point cloud completion aims to restore partial point clouds to their complete form. However, most existing point cloud completion methods rely on complete point clouds or multi-view information of the same object during training, which is not practical for real-world scenarios with high information acquisition costs. To overcome the above limitation, a self-supervised point cloud completion (SPC) method is proposed, which uses the training set consisting of only a single partial point cloud for each object. Specifically, an autoencoder-like network architecture that includes a two-step strategy is developed. First, a compression-reconstruction strategy is proposed to enable the network to learn the representation of complete point clouds from existing knowledge. Then, considering the potential problem of overfitting in self-supervised training, a global enhancement strategy is further designed to maintain the positional coherence of predicted points. Comprehensive experiments are conducted on the ScanNet, MatterPort3D, KITTI, and ShapeNet datasets. On real-world datasets, the unidirectional Chamfer distance (UCD) and the unidirectional Hausdorff distance (UHD) of the method are reduced by an average of 2.3 and 2.4, respectively, compared to the state-of-the-art method. In addition to its excellent completion capabilities, the proposed method has a positive impact on downstream tasks. In point cloud classification, applying the proposed method improves classification accuracy by an average of 14 %. Extensive experimental results demonstrate that the proposed SPC has a high practical value.},
  archive      = {J_NN},
  author       = {Jie Song and Xing Wu and Junfeng Yao and Qi Zhang and Chenhao Shang and Quan Qian and Jun Song},
  doi          = {10.1016/j.neunet.2025.108107},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108107},
  shortjournal = {Neural Netw.},
  title        = {SPC: Self-supervised point cloud completion},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition. <em>NN</em>, <em>194</em>, 108106. (<a href='https://doi.org/10.1016/j.neunet.2025.108106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Named Entity Recognition (MNER) integrates complementary information from both text and images to identify named entities within text. However, existing methods face three key issues: imbalanced handling of modality noise, the cascading effect of semantic mismatch, and information loss resulting from the lack of text dominance. To address these issues, this paper proposes a M ulti-stage I nteraction N etwork I nspired by G ene E diting for MNER (MINIGE-MNER). The core innovations of this method include: A gene knockout module based on the variational information bottleneck, which removes inferior genes (modality noise) from the text, raw image, and generated image features. This approach retains the superior genes, achieving balanced filtering of modality noise. A determination of gene recombination sites module that maximizes the mutual information between superior genes across modalities, reducing the spatial distance between them and ensuring precise, fine-grained semantic alignment. This helps to prevent the cascading effect of semantic mismatch. A text-guided gene recombination module that implements a “text-dominant, vision-supplementary” cross-modal fusion paradigm. This module dynamically filters out visual noise unrelated to the text while avoiding excessive reliance on visual information that could obscure the unique contextual information of the text, effectively mitigating information loss. Experimental results show that MINIGE-MNER achieves F1 scores of 76.45 % and 88.67 % on the Twitter-2015 and Twitter-2017 datasets, respectively, outperforming existing state-of-the-art methods by 0.83 % and 0.42 %. In addition, this paper presents comprehensive experiments that demonstrate the superiority of MINIGE-MNER and the effectiveness of its individual modules.},
  archive      = {J_NN},
  author       = {Bo Kong and Shengquan Liu and Liruizhi Jia and Yi Liang and Dongfang Han and Xu Zhang},
  doi          = {10.1016/j.neunet.2025.108106},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108106},
  shortjournal = {Neural Netw.},
  title        = {MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified gradient regularization method for heterogeneous graph neural networks. <em>NN</em>, <em>194</em>, 108104. (<a href='https://doi.org/10.1016/j.neunet.2025.108104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Graph Neural Networks (HGNNs) are advanced deep learning methods widely applied for learning representations of heterogeneous graphs. However, they face challenges such as over-smoothing and non-robustness. Existing methods can mitigate these issues by applying gradient regularization to one of the three information dimensions: node, edge, or propagation message. However, these methods have problems such as unstable training, difficulty in parameter convergence, and inadequate utilization of heterogeneous information. We propose a novel gradient regularization method called Grug, which iteratively applies regularization to the gradients derived from both node type and message matrix during the message-passing process. A detailed theoretical analysis demonstrates its advantages in Stability and Diversity. Notably, Grug potentially exceeds the theoretical upper bounds set by DropMessage. In addition, Grug offers a unified gradient regularization framework that integrates the existing dropping and adversarial training methods, and provides theoretical guidance for their further optimization in different data and tasks. We validate Grug through extensive experiments on six public datasets, showing significant improvements in performance and effectiveness.},
  archive      = {J_NN},
  author       = {Xiao Yang and Xuejiao Zhao and Zhiqi Shen},
  doi          = {10.1016/j.neunet.2025.108104},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108104},
  shortjournal = {Neural Netw.},
  title        = {A unified gradient regularization method for heterogeneous graph neural networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-level graph contrastive learning for community value prediction. <em>NN</em>, <em>194</em>, 108103. (<a href='https://doi.org/10.1016/j.neunet.2025.108103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community Value Prediction (CVP) is an important emerging task in the field of social commerce, which aims to predict the community values. However, due to the complex structure of communities and individuals, previous graph machine learning methods have struggled to adequately address this task. This study endeavors to bridge this gap by introducing a cross-level graph contrastive learning method called Cross-level Community Contrastive Learning (CCCL) to handle such subgraph-level tasks. Specifically, we generate two views that describe different levels of social connections, the augmented node-level graph and the community-level graph that is produced by graph coarsening. Subsequently, CCCL captures the mutual information between the two views through a cross-view contrastive loss. The learned embeddings utilize community and node information at various levels, making them capable of handling subgraph-level regression problems. To the best of our knowledge, CCCL is the first graph contrastive learning method that addresses the CVP problem. We theoretically show that CCCL maximizes a lower bound of the mutual information shared between node-view and community-view representations. Experimental results demonstrate that our proposed approach is highly effective for the CVP task, outperforming both end-to-end and self-supervised baselines. Furthermore, our model also exhibits robust resistance to edge perturbation attacks.},
  archive      = {J_NN},
  author       = {Wenjie Yang and Shengzhong Zhang and Zengfeng Huang},
  doi          = {10.1016/j.neunet.2025.108103},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108103},
  shortjournal = {Neural Netw.},
  title        = {Cross-level graph contrastive learning for community value prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training. <em>NN</em>, <em>194</em>, 108102. (<a href='https://doi.org/10.1016/j.neunet.2025.108102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation, which aims to provide accurate descriptions of both normal and abnormal regions, has been attracting growing research attention. Recently, despite considerable progress, data-driven deep-learning based models still face challenges in capturing and describing the abnormalities, due to the data bias problem. To address this problem, we propose to generate radiology reports via the Visual-Semantic Ambivalence-Aware Network (VSANet) and the Focal Self-Critical Sequence Training (FSCST). In detail, our VSANet follows the encoder-decoder framework. In the encoder part, we first deploy a multi-grained abnormality extractor and a visual extractor to capture both semantic and visual features from given images, and then introduce a Parameter Shared Dual-way Encoder (PSDwE) to delve into the inter- and intra-relationships among these features. In the decoder part, we propose the Visual-Semantic Ambivalence-Aware (VSA) module to generate the abnormality-aware visual features to mitigate the data bias problem. In implementation, our VSA introduces three sub-modules: Dual-way Attention (DwA), introduced to generate both the word-related visual and semantic features; Dual-way Attention on Attention (DwAoA), designed to mitigate redundant information; Score-based Feature Fusion (SFF), constructed to fuse the visual and semantic features in an ambivalence way. We further introduce the FSCST to enhance the overall performance of our VSANet by allocating more attention toward difficult samples. Experimental results demonstrate that our proposal achieves superior performance on various evaluation metrics. Source code have released at https://github.com/SKD-HPC/VSANet .},
  archive      = {J_NN},
  author       = {Xiulong Yi and You Fu and Enxu Bi and Jianguo Liang and Hao Zhang and Jianzhi Yu and Qianqian Li and Rong Hua and Rui Wang},
  doi          = {10.1016/j.neunet.2025.108102},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108102},
  shortjournal = {Neural Netw.},
  title        = {Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discriminative representation learning via attention-enhanced contrastive learning for short text clustering. <em>NN</em>, <em>194</em>, 108101. (<a href='https://doi.org/10.1016/j.neunet.2025.108101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has gained significant attention in short text clustering, yet it has an inherent drawback of mistakenly identifying samples from the same category as negatives and separating them in the feature space (i.e., the false negative separation problem). To generate discriminative representations for short text clustering, we propose a novel clustering method, called Discriminative Representation learning via A ttention- E nhanced C ontrastive L earning for Short Text Clustering ( AECL ). The AECL consists of two modules which are the contrastive learning module and the pseudo-label assisting module. Both modules utilize a sample-level attention mechanism to extract similarities between samples, based on which cross-sample features are aggregated to form a consistent representation for each sample. The contrastive learning module explores the similarity relationships and the consistent representations to form positive samples, effectively addressing the false negative separation issue, and the pseudo-label assisting module utilizes the consistent representations to produce reliable supervision information to assist the clustering task. Experimental results demonstrate that AECL outperforms state-of-the-art methods. The code is available at https://github.com/YZH0905/AECL-STC .},
  archive      = {J_NN},
  author       = {Zhihao Yao and Bo Li and Yufei Liao},
  doi          = {10.1016/j.neunet.2025.108101},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108101},
  shortjournal = {Neural Netw.},
  title        = {Discriminative representation learning via attention-enhanced contrastive learning for short text clustering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects. <em>NN</em>, <em>194</em>, 108100. (<a href='https://doi.org/10.1016/j.neunet.2025.108100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the fixed-time synchronization (FXTS) and prescribed-time synchronization (PSTS) problems of state-dependent switching neural networks (SDSNNs) with stochastic disturbances and impulsive effects. By leveraging the average impulsive interval, comparison principle, and interval matrix methodology, this study advances a novel analytical framework. Departing from conventional approaches, we reformulate stochastic disturbed and impulsive SDSNNs as interval-parameter systems through rigorous interval matrix transformation. Consequently, we derive some sufficient conditions in the form of linear matrix inequalities (LMIs) to ensure the realization of FXTS and PSTS. Since impulsive effects can potentially compromise synchronization stability, careful controller design becomes critical. To address this challenge, we develop a unified proportional integral (PI) control framework. Through proper adjustment of its control parameters, this framework enables the system to achieve both FXTS and PSTS. Moreover, by reasonably configuring the relationship between the impulsive intensity and the prescribed time, the synchronization performance can be balanced. Finally, we demonstrate the effectiveness of the theoretical results through two examples.},
  archive      = {J_NN},
  author       = {Guici Chen and Houxuan Zhang and Shiping Wen and Junhao Hu and Leimin Wang},
  doi          = {10.1016/j.neunet.2025.108100},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108100},
  shortjournal = {Neural Netw.},
  title        = {Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories. <em>NN</em>, <em>194</em>, 108099. (<a href='https://doi.org/10.1016/j.neunet.2025.108099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of long-tail visual recognition, the imbalance in data distribution leads to a significant performance gap between head and tail classes. Improving the tail-class performance and alleviating the decline in head class are two critical questions. Although many methods have proposed solutions for the former, most of them fall short in the latter. Introducing additional knowledge is a novel view to address the problem, however, how to attain useful knowledge and further transfer the knowledge to the target model is the core. This paper proposes a novel method called Expert Knowledge Distillation for Specific Categories (EKDSC). Firstly, we propose a kind of well-trained teacher model ensuring each expert concentrates on its specialized field while being less affected by other interference. Furthermore, the teacher model including three categories of experts: head, mid, and tail classes, is utilized to distill their specialized knowledge to the student model. Experimental results demonstrate that EKDSC effectively improves the accuracy of tail classes, and mitigates the common decreases of head classes’ performance. Our proposed method achieves a high accuracy, exceeding the current state-of-the-art (SOTA) by 1–5 % on benchmark datasets including the small-scale CIFAR-10 LT and CIFAR-100 LT. Furthermore, it demonstrates outstanding performance on large-scale datasets such as ImageNet-LT, iNaturalist 2018, and Places-LT.},
  archive      = {J_NN},
  author       = {Yaping Bai and Jinghua Li and Dehui Kong and Suqiao Yang and Baocai Yin},
  doi          = {10.1016/j.neunet.2025.108099},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108099},
  shortjournal = {Neural Netw.},
  title        = {EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations. <em>NN</em>, <em>194</em>, 108098. (<a href='https://doi.org/10.1016/j.neunet.2025.108098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal imitation learning enables the agent to learn demonstrations of multiple modes at the same time. However, as expert demonstrations in practice tend to have incomplete labels for behavior modes, most methods are inefficient. To address this issue, an approach capable of imitation learning from incompletely labeled expert demonstrations, referred to as Weakly Supervised Multi-modal Imitation Learning (WSMIL), is proposed. WSMIL incorporates weakly supervised learning into multi-modal imitation learning by adding a behavior mode classifier to the adversarial network, thus forming adversaries among three players (generator, classifier and discriminator). Both labeled and unlabeled data are fully utilized in this adversarial process where fake state-action-label pairs generated by the generator and the classifier try to deceive the discriminator that tries to identify them and limited labeled expert demonstrations. Additionally, in order to ensure the data distribution of classifier and generator individually to converge to the expert’s real distribution, three extra losses are employed, where simulated annealing behavioral cloning is also added to the generator network to improve the generalization of policy. Experiments show that WSMIL accurately distinguishes modes with incomplete modal labels in demonstrations, learns close to the expert standard for each mode, and is more stable than other multi-modal methods.},
  archive      = {J_NN},
  author       = {Sijia Gu and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108098},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108098},
  shortjournal = {Neural Netw.},
  title        = {Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection. <em>NN</em>, <em>194</em>, 108097. (<a href='https://doi.org/10.1016/j.neunet.2025.108097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightweight salient object detection (SOD) is widely used in various downstream applications due to its low resource requirements and fast inference speed. The use of hybrid encoders offers the potential to achieve a better balance between efficiency and accuracy for SOD task. However, the aggregation of features from convolutional neural networks (CNNs) and transformers remains challenging, and most existing lightweight SOD models rarely explore the efficient aggregation of cross-architecture features derived from hybrid encoders. In this paper, we propose a hybrid aggregation strategy network (HASNet) that balances accuracy and efficiency for lightweight SOD by grouping and aggregating features to leverage salient information across different architectures. Specifically, the features obtained after hybrid encoder processing are divided into convolutional and transformer features for shallow and deep aggregation respectively. Deep aggregation uses the global inverted residual block (GIRB) to facilitate the transfer of salient information encoded within transformer features across various levels. Meanwhile, shallow aggregation uses the lightweight inverted residual block (LIRB) to efficiently integrate the spatial information inherent in convolutional features. The GIRB incorporates an efficient global operation to extract channel semantic information from the high-dimensional transformer features. The LIRB fuses low-level features by efficiently exploiting the spatial information in features at extremely low computational cost. Comprehensive experiments conducted across five datasets demonstrate that our HASNet significantly outperform existing methods in a thorough evaluation encompassing parameter sizes, inference speed, and accuracy. The source code will be publicly available at https://github.com/LitterMa-820/HASNet .},
  archive      = {J_NN},
  author       = {Jianhua Ma and Mingfeng Jiang and Xian Fang and Jiatong Chen and Yaming Wang and Guang Yang},
  doi          = {10.1016/j.neunet.2025.108097},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108097},
  shortjournal = {Neural Netw.},
  title        = {Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing image restoration through learning context-rich and detail-accurate features. <em>NN</em>, <em>194</em>, 108096. (<a href='https://doi.org/10.1016/j.neunet.2025.108096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration aims to recover high-quality images from their degraded counterparts, necessitating a delicate balance between preserving spatial details and capturing contextual information. Although some methods attempt to address this trade-off, they tend to focus primarily on spatial features while overlooking the importance of understanding frequency variations. Moreover, these approaches commonly utilize skip connections–implemented via addition or concatenation–to fuse encoder and decoder features for improved restoration. However, since encoder features may still carry degradation artifacts, such direct fusion strategies risk introducing implicit noise, ultimately hindering restoration performance. In this paper, we present a multi-scale design that optimally balances these competing objectives, seamlessly integrating spatial and frequency domain knowledge to selectively recover the most informative information. Specifically, we develop a hybrid scale frequency selection block (HSFSBlock), which not only captures multi-scale information from the spatial domain, but also selects the most informative components for image restoration in the frequency domain. Furthermore, to mitigate the inherent noise introduced by skip connections employing only addition or concatenation, we introduce a skip connection attention mechanism (SCAM) to selectively determines the information that should propagate through skip connections. The resulting tightly interlinked architecture, named as LCDNet. Extensive experiments conducted across diverse image restoration tasks showcase that our model attains performance levels that are either superior or comparable to those of state-of-the-art algorithms. The code and the pre-trained models are released at https://github.com/Tombs98/LCDNet .},
  archive      = {J_NN},
  author       = {Hu Gao and Xiaoning Lei and Depeng Dang},
  doi          = {10.1016/j.neunet.2025.108096},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108096},
  shortjournal = {Neural Netw.},
  title        = {Enhancing image restoration through learning context-rich and detail-accurate features},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation. <em>NN</em>, <em>194</em>, 108095. (<a href='https://doi.org/10.1016/j.neunet.2025.108095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter-efficient fine-tuning (PEFT) has emerged as a critical paradigm for adapting large pre-trained models to downstream tasks, offering a balance between computational efficiency and model performance. Among these methods, Low-Rank Adaptation (LoRA) has gained significant popularity due to its efficiency; it freezes the pre-trained weights and decomposes the incremental matrices into two trainable low-rank matrices. However, a critical limitation of LoRA lies in its uniform rank assignment across all layers, which fails to account for the heterogeneous importance of different layers in contributing to task performance, potentially resulting in suboptimal adaptation. To address this limitation, we propose Layer-wise Adaptive Low-Rank Adaptation (La-LoRA), a novel approach that dynamically allocates rank to each layer based on Dynamic Contribution-Driven Parameter Budget (DCDPB) and Truncated Norm Weighted Dynamic Rank Allocation (TNW-DRA) during training. By treating each layer as an independent unit and progressively adjusting its rank allocation, La-LoRA ensures optimal model performance while maintaining computational efficiency and adapting to the complexity of diverse tasks. We conducted extensive experiments across multiple tasks and models to evaluate the effectiveness of La-LoRA. The results demonstrate that La-LoRA consistently outperforms existing benchmarks, validating its effectiveness in diverse scenarios.},
  archive      = {J_NN},
  author       = {Jiancheng Gu and Jiabin Yuan and Jiyuan Cai and Xianfa Zhou and Lili Fan},
  doi          = {10.1016/j.neunet.2025.108095},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108095},
  shortjournal = {Neural Netw.},
  title        = {La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-level dynamic heterogeneous graph network for video question answering. <em>NN</em>, <em>194</em>, 108094. (<a href='https://doi.org/10.1016/j.neunet.2025.108094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Video Question Answering (VideoQA) has garnered considerable research interest as a pivotal task within the realm of vision-language understanding. However, existing Video Question Answering datasets often lack sufficient entity and event information. Thus, the Vision Language Models (VLMs) struggle to complete intricate grounding and reasoning among multi-modal entities or events and heavily rely on language short-cut or irrelevant visual context. To address these challenges, we make improvements from both data and model perspectives. In terms of VideoQA data, we focus on supplementing the missing specific entities and events with the proposed event and entity augmentation strategies. Based on the augmented data, we propose a Dual-Level Dynamic Heterogeneous Graph Network (DDHG) for Video Question Answering. DDHG incorporates transformer layers to capture the dynamic temporal-spatial changes of visual entities. Then, DDHG establishes multi-modal semantic grounding ability between vision and text with entity-level and event-level heterogeneous graphs. Finally, the Dual-level Cross-modal Interaction Module integrates the dual-level features to predict correct answers. Our method not only significantly outperforms existing VideoQA models on two complex event-based benchmark datasets (Causal-VidQA and NExT-QA) but also demonstrates superior event content prediction ability over several state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Zefan Zhang and Yanhui Li and Weiqi Zhang and Tian Bai},
  doi          = {10.1016/j.neunet.2025.108094},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108094},
  shortjournal = {Neural Netw.},
  title        = {Dual-level dynamic heterogeneous graph network for video question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction. <em>NN</em>, <em>194</em>, 108093. (<a href='https://doi.org/10.1016/j.neunet.2025.108093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug–target interaction (DTI) prediction plays a crucial role in drug discovery and repurposing by efficiently and accurately identifying potential therapeutic targets. Existing methods face challenges in capturing high-order semantic relationships in heterogeneous graphs and effectively integrating multi-meta-path information while also suffering from low computational efficiency. To address these challenges, a pre-computation-style hierarchical meta-path learning framework named HMT-DTI is proposed. HMT-DTI can effectively capture rich semantic information about drugs and targets while ensuring high computational efficiency. Specifically, during the pre-collection stage, HMT-DTI employs a Transformer-based message passing mechanism to evaluate neighbors’ importance and adaptively collect meta-path information. The incorporation of even-relation propagation reduces redundant iterations and improves efficiency. During training, HMT-DTI adopts a hierarchical knowledge extraction strategy to evaluate the importance of multi-hop neighbors and different meta-path patterns, capturing fine-grained semantic representations of drugs and targets. HMT-DTI is evaluated on three heterogeneous biological datasets and compared with several state-of-the-art methods. The results demonstrate the superiority of HMT-DTI in DTI prediction.},
  archive      = {J_NN},
  author       = {Dianlei Gao and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108093},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108093},
  shortjournal = {Neural Netw.},
  title        = {HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis. <em>NN</em>, <em>194</em>, 108091. (<a href='https://doi.org/10.1016/j.neunet.2025.108091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal neuroimaging techniques are widely employed for the accurate diagnosis of Alzheimer’s Disease (AD). Existing fusion methods typically focus on capturing semantic correlations between modalities through feature-level interactions. However, they fail to suppress redundant cross-modal information, resulting in sub-optimal multi-modal representation. Moreover, these methods ignore subject-specific differences in modality contributions. To address these challenges, we propose a novel Multi-modal Orthogonal Fusion Network via cross-layer guidance (MOFNet) to effectively fuse multi-modal information for AD diagnosis. We first design a Cross-layer Guidance Interaction module (CGI), leveraging high-level features to guide the learning of low-level features, thereby enhancing the fine-grained representations on disease-relevant regions. Then, we introduce a Multi-modal Orthogonal Compensation module (MOC) to realize bidirectional interaction between modalities. MOC encourages each modality to compensate for its limitations by learning orthogonal components from other modalities. Finally, a Feature Enhancement Fusion module (FEF) is developed to adaptively fuse multi-modal features based on the contributions of different modalities. Extensive experiments on the ADNI dataset demonstrate that MOFNet achieves superior performance in AD classification tasks.},
  archive      = {J_NN},
  author       = {Yumiao Zhao and Bo Jiang and Yuan Chen and Ye Luo and Jin Tang},
  doi          = {10.1016/j.neunet.2025.108091},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108091},
  shortjournal = {Neural Netw.},
  title        = {Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ClickAttention: Click region similarity guided interactive segmentation. <em>NN</em>, <em>194</em>, 108090. (<a href='https://doi.org/10.1016/j.neunet.2025.108090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive segmentation algorithms based on click points have attracted significant attention from researchers in recent years. However, most existing methods rely on sparse click maps as model inputs to segment specific target objects. These clicks primarily affect local regions, limiting the model’s ability to focus on the entire target object and often resulting in a higher number of required clicks. Additionally, many current algorithms struggle to balance performance and efficiency effectively. To address these challenges, we propose a click attention algorithm that expands the influence of positive clicks by leveraging the similarity between positively-clicked regions and the entire input. We further introduce a discriminative affinity loss to reduce attention coupling between positive and negative click regions, minimizing accuracy degradation caused by mutual interference. On the DAVIS dataset, our method achieves a 2 % performance gain (NoC@90) over the state-of-the-art SimpleClick-ViT-L, while using only 15.6 % of its parameters. Extensive experiments demonstrate that our approach outperforms existing methods and achieves state-of-the-art performance with fewer parameters. Data and code are published.},
  archive      = {J_NN},
  author       = {Long Xu and Yongquan Chen and Shanghong Li and Junkang Chen and Ziyuan Tang},
  doi          = {10.1016/j.neunet.2025.108090},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108090},
  shortjournal = {Neural Netw.},
  title        = {ClickAttention: Click region similarity guided interactive segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A vision-language model for multitask classification of memes. <em>NN</em>, <em>194</em>, 108089. (<a href='https://doi.org/10.1016/j.neunet.2025.108089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of social media and online memes has led to an increasing demand for automated systems that can analyse and classify multimodal data, particularly in online forums. Memes blend text and graphics to express complicated ideas, sometimes containing emotions, satire, or inappropriate material. Memes often represent cultural prejudices such as objectification, sexism, and bigotry, making it difficult for artificial intelligence to classify these components. Our solution is the vision-language model ViT-BERT CAMT (cross-attention multitask), which is intended for multitask meme categorization. Our model uses a linear self-attentive fusion mechanism to combine vision transformer (ViT) features for image analysis and bidirectional encoder representations from transformers (BERT) for text interpretation. In this way, we can see how text and images relate to space and meaning. We tested the ViT-BERT CAMT on two difficult datasets: the SemEval 2020 Memotion dataset, which contains a multilabel classification of sentiment, sarcasm, and offensiveness in memes, and the MIMIC dataset, which focuses on detecting sexism, objectification, and prejudice. The findings show that the ViT-BERT CAMT achieves good accuracy on both datasets and outperforms many current baselines in multitask settings. These results highlight the importance of combined image-text modelling for correctly deciphering nuanced meanings in memes, particularly when spotting abusive and discriminatory content. By improving multimodal categorization algorithms, this study helps better monitor and comprehend online conversation.},
  archive      = {J_NN},
  author       = {Md. Mithun Hossain and Md. Shakil Hossain and M.F. Mridha and Nilanjan Dey},
  doi          = {10.1016/j.neunet.2025.108089},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108089},
  shortjournal = {Neural Netw.},
  title        = {A vision-language model for multitask classification of memes},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view learning meets state-space model: A dynamical system perspective. <em>NN</em>, <em>194</em>, 108088. (<a href='https://doi.org/10.1016/j.neunet.2025.108088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning exploits the complementary nature of multiple modalities to enhance performance across diverse tasks. While deep learning has significantly advanced these fields by enabling sophisticated modeling of intra-view and cross-view interactions, many existing approaches still rely on heuristic architectures and lack a principled framework to capture the dynamic evolution of feature representations. This limitation hampers interpretability and theoretical understanding. To address these challenges, this paper introduces the Multi-view State-Space Model (MvSSM), which formulates multi-view representation learning as a continuous-time dynamical system inspired by control theory. In this framework, view-specific features are treated as external inputs, and a shared latent representation evolves as the internal system state, driven by learnable dynamics. This formulation unifies feature integration and label prediction within a single interpretable model, enabling theoretical analysis of system stability and representational transitions. Two variants, MvSSM-Lap and MvSSM-iLap, are further developed using Laplace and inverse Laplace transformations to derive system dynamics representations. These solutions exhibit structural similarities to graph convolution operations in deep networks, supporting efficient feature propagation and theoretical interpretability. Experiments on benchmark datasets such as IAPR-TC12, and ESP demonstrate the effectiveness of the proposed method, achieving up to 4.31 % improvement in accuracy and 4.27 % in F1-score over existing state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Weibin Chen and Ying Zou and Zhiyong Xu and Li Xu and Shiping Wang},
  doi          = {10.1016/j.neunet.2025.108088},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108088},
  shortjournal = {Neural Netw.},
  title        = {Multi-view learning meets state-space model: A dynamical system perspective},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph convolutional network with adaptive grouping aggregation strategy. <em>NN</em>, <em>194</em>, 108086. (<a href='https://doi.org/10.1016/j.neunet.2025.108086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of graph convolutional networks (GCNs) with naive aggregation functions on nodes has reached the bottleneck, rendering a gap between practice and theoretical expressity. Some learning-based aggregation strategies have been proposed to improve the performance. However, few of them focus on how these strategies affect the expressity and evaluate their performance in an equal experimental setting. In this paper, we point out that the generated features lack discrimination because naive aggregation functions cannot retain sufficient node information, largely leading to the performance gap. Accordingly, a novel Adaptive Grouping Aggregation (AGA) strategy is proposed to remedy this drawback. Inspired by the label histogram in the Weisfeiler-Lehman (WL) Test, this strategy assigns each node to a unique group to retain more node information, which is proven to have a strictly more powerful expressity. In this work setting, the nodes are grouped according to a modified Student’s t-Distribution between node features and a set of learnable group labels, where the Gumbel Softmax is employed to implement this strategy in an end-to-end trainable pipeline. As a result, such a design can generate more discriminative features and offer a plug-in module in most architectures. Extensive experiments have been conducted on several benchmarks to compare our method with other aggregation strategies. The proposed method improves the performance in all control groups of all benchmarks and achieves the best result in most cases. Additional ablation studies and comparisons with state-of-the-art methods on the large-scale benchmark also indicate the superiority of our method.},
  archive      = {J_NN},
  author       = {Ruixiang Wang and Chunxia Zhang and Chunhong Pan},
  doi          = {10.1016/j.neunet.2025.108086},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108086},
  shortjournal = {Neural Netw.},
  title        = {Graph convolutional network with adaptive grouping aggregation strategy},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive behavior with stable synapses. <em>NN</em>, <em>194</em>, 108082. (<a href='https://doi.org/10.1016/j.neunet.2025.108082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral changes in animals and humans, triggered by errors or verbal instructions, can occur extremely rapidly. While learning theories typically attribute improvements in performance to synaptic plasticity, recent findings suggest that such fast adaptations may instead result from dynamic reconfiguration of the networks involved without changes to synaptic weights. Recently, similar capabilities have been observed in transformers, foundational architecture in machine learning widely used in applications such as natural language and image processing. Transformers are capable of in-context learning, the ability to adapt and acquire new information dynamically within the context of the task or environment they are currently engaged in, without changing their parameters. We argue that this property may stem from gain modulation–a feature widely observed in biological networks, such as pyramidal neurons through input segregation and dendritic amplification. We propose a constructive approach to induce in-context learning in an architecture composed of recurrent networks with gain modulation, demonstrating abilities inaccessible to standard networks. In particular, we show that, such architecture can dynamically implement standard gradient-based by encoding weight changes in the activity of another network. We argue that, while these algorithms are traditionally associated with synaptic plasticity, their reliance on non-local terms suggests that they may be more naturally realized in the brain at the level of neural circuits. We demonstrate that we can extend our approach to temporal tasks and reinforcement learning. We further validate our approach in a MuJoCo ant navigation task, showcasing a neuromorphic control paradigm via real-time network reconfiguration.},
  archive      = {J_NN},
  author       = {Cristiano Capone and Luca Falorsi},
  doi          = {10.1016/j.neunet.2025.108082},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108082},
  shortjournal = {Neural Netw.},
  title        = {Adaptive behavior with stable synapses},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Disentangled self-supervised video camouflaged object detection and salient object detection. <em>NN</em>, <em>194</em>, 108077. (<a href='https://doi.org/10.1016/j.neunet.2025.108077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video tasks play an important role in multimedia fields. In various video tasks, such as video camouflaged/salient object detection (VCOD/VSOD), motion and context information are two important aspects. Despite the fact that many existing works have already achieved promising results in VCOD and VSOD tasks, they still have limitations when it comes to leveraging motion and context information. In this paper, we propose a new disentangled perspective to treat motion and context information in VCOD and VSOD tasks. Our proposed model can respectively utilize context and motion information in ContextNet and MotionNet, without conflicting with each other as there can be biases between these two types of information in certain circumstances. Moreover, we further explore how to apply disentangled perspective in the self-supervised manner, which can reduce annotation costs. Specifically, we first design a self-supervised adaptive frame routing mechanism to determine whether each video frame belongs to ContextNet or MotionNet. Then we design a cross-supervision for ContextNet and MotionNet to train these two segmentation networks in self-supervised mechanism. In experiments, our proposed self-supervised disentangled model consistently outperforms state-of-the-art unsupervised methods on VCOD and VSOD datasets.},
  archive      = {J_NN},
  author       = {Haoke Xiao and Lv Tang and Bo Li and Zhiming Luo and Shaozi Li},
  doi          = {10.1016/j.neunet.2025.108077},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108077},
  shortjournal = {Neural Netw.},
  title        = {Disentangled self-supervised video camouflaged object detection and salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WPDA: Frequency-based backdoor attack with wavelet packet decomposition. <em>NN</em>, <em>194</em>, 108074. (<a href='https://doi.org/10.1016/j.neunet.2025.108074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores backdoor attack, which is an emerging security threat against deep neural networks (DNNs). The adversary aims to inject a backdoor into the model by manipulating a portion of training samples, such that the backdoor could be activated by a particular trigger to make a target prediction at inference. Currently, existing backdoor attacks often require moderate or high poisoning ratios to achieve the desired attack performance, but making them susceptible to some advanced backdoor defenses ( e . g . , poisoned sample detection). One possible solution to this dilemma is enhancing the attack performance at low poisoning ratios, which has been rarely studied due to its high challenge. To achieve this goal, we propose an innovative frequency-based backdoor attack via wavelet packet decomposition (WPD), which could finely decompose the original image into multiple sub-spectrograms with semantic information. It facilitates us to accurately identify the most critical frequency regions to effectively insert the trigger into the victim image, such that the trigger information could be sufficiently learned to form the backdoor. The proposed attack stands out for its exceptional effectiveness, stealthiness, and resistance at an extremely low poisoning ratio. Notably, it achieves the 98.12 % attack success rate on CIFAR-10 with an extremely low poisoning ratio of 0.004 % ( i.e. , only 2 poisoned samples among 50,000 training samples), and bypasses several advanced backdoor defenses. Besides, we provide more extensive experiments to demonstrate the efficacy of the proposed method, as well as in-depth analyses to explain its underlying mechanism.},
  archive      = {J_NN},
  author       = {Zhengyao Song and Yongqiang Li and Danni Yuan and Li Liu and Shaokui Wei and Baoyuan Wu},
  doi          = {10.1016/j.neunet.2025.108074},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108074},
  shortjournal = {Neural Netw.},
  title        = {WPDA: Frequency-based backdoor attack with wavelet packet decomposition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts. <em>NN</em>, <em>194</em>, 108064. (<a href='https://doi.org/10.1016/j.neunet.2025.108064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are gaining popularity for processing graph data. In real-world scenarios, graph data within the same dataset can vary significantly in scale. This variability leads to depth-sensitivity, where the optimal depth of GNN layers depends on the scale of the graph data. Empirically, fewer layers are sufficient for message passing in smaller graphs, while larger graphs typically require deeper networks to capture long-range dependencies and global features. However, existing methods generally use a fixed number of GNN layers to generate representations for all graphs, overlooking the depth-sensitivity issue in graph data. To address this challenge, we propose the depth adaptive mixture of expert (DA-MoE) method, which incorporates two main improvements to GNN backbone: 1) DA-MoE employs different GNN layers, each considered an expert with its own parameters. Such a design allows the model to flexibly aggregate information at different scales, effectively addressing the depth-sensitivity issue in graph data. 2) DA-MoE utilizes GNN to capture the structural information instead of the linear projections in the gating network. Thus, the gating network enables the model to capture complex patterns and dependencies within the data. By leveraging these improvements, each expert in DA-MoE specifically learns distinct graph patterns at different scales. Furthermore, comprehensive experiments on the TU dataset and open graph benchmark (OGB) have shown that DA-MoE consistently surpasses existing baselines on various tasks, including graph, node, and link-level analyses. The code are available at https://github.com/Celin-Yao/DA-MoE .},
  archive      = {J_NN},
  author       = {Zelin Yao and Mukun Chen and Chuang Liu and Xianke Meng and Yibing Zhan and Jia Wu and Shirui Pan and Huiting Xu and Wenbin Hu},
  doi          = {10.1016/j.neunet.2025.108064},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108064},
  shortjournal = {Neural Netw.},
  title        = {DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic graph representation learning with disentangled information bottleneck. <em>NN</em>, <em>194</em>, 108056. (<a href='https://doi.org/10.1016/j.neunet.2025.108056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph representation learning recently garnered enormous research attention. Despite the notable successes of existing methods, they usually characterize dynamic graphs as a perceptual whole and learn dynamic graph representations within an entangled feature space, which overlook different temporal dependencies inherent in the data. Specifically, the evolution of dynamic graphs is usually decided by a dichotomy in properties: time-invariant properties and time-varying properties. Existing holistic works fail to distinguish these temporal properties and may suffer suboptimal performance in downstream tasks. To tackle this problem, we propose to learn macro-disentangled dynamic graph representations based on the Information Bottleneck theory, leading to a novel dynamic graph representation learning method, Disentangled Dynamic Graph Information Bottleneck (DDGIB). Our DDGIB explicitly embeds the dynamic graphs into a time-invariant representation space and a time-varying representation space. The time-invariant representation space encapsulates stable properties across the temporal span of dynamic graphs, whereas the time-varying representation space encapsulates time-fluctuating properties. The macro disentanglement on the temporal dependencies facilitates the representations’ performance on downstream tasks. Furthermore, we theoretically prove the sufficiency and macro disentanglement of DDGIB. The sufficiency demonstrates that DDGIB can achieve sufficient representations for any possible downstream tasks, while the macro disentanglement certifies that DDGIB can embed the different temporal properties into their corresponding temporal representation space. Extensive experimental results on various datasets and downstream tasks demonstrate the superiority of our method.},
  archive      = {J_NN},
  author       = {Jihong Wang and Yuxin Bai and Chunqiang Zhu and Hao Qian and Ziqi Liu and Minnan Luo},
  doi          = {10.1016/j.neunet.2025.108056},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108056},
  shortjournal = {Neural Netw.},
  title        = {Dynamic graph representation learning with disentangled information bottleneck},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning. <em>NN</em>, <em>194</em>, 108023. (<a href='https://doi.org/10.1016/j.neunet.2025.108023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral diversity emerges as a crucial factor for achieving effective collaboration in Multi-Agent Reinforcement Learning (MARL). Current methods often use partial parameter sharing, such as sharing the same representation layer, to balance behavioral diversity and algorithmic scalability. However, this approach ignores that different agents need different decision knowledge, causing training conflicts and knowledge redundancy. To solve these, we propose Tailoring Knowledge for Empowered Cooperative Actions in Multi-Agent Reinforcement Learning (TKCA). Specially, we employ a set of Knowledge Encoders to encode different environment types of knowledge and utilize a Knowledge Selector network to assist each agent in decision-making by selecting the corresponding knowledge. We evaluated TKCA in challenging StarCraftII micromanagement games and Google Research Football games, and the results demonstrate the superior performance of TKCA.},
  archive      = {J_NN},
  author       = {Hu Fu and Yihua Tan and Hao Chen and Pengyi Li},
  doi          = {10.1016/j.neunet.2025.108023},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108023},
  shortjournal = {Neural Netw.},
  title        = {Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="orl">ORL - 1</h2>
<ul>
<li><details>
<summary>
(2026). Monotone convergence of spreading processes on networks. <em>ORL</em>, <em>64</em>, 107363. (<a href='https://doi.org/10.1016/j.orl.2025.107363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the Bass and SI models for the spreading of innovations and epidemics, respectively, on homogeneous complete networks, on one-dimensional networks, and on heterogeneous two-groups complete networks. We allow the network parameters to be time dependent, which is a prerequisite for the analysis of optimal promotional strategies on networks. Using a novel top-down analysis of the master equations, we present a simple proof for the monotone convergence of these models to their respective infinite-population limits. This leads to explicit expressions for the expected adoption or infection level in the Bass and SI models with time-dependent parameters on infinite homogeneous complete and circular networks, and on heterogeneous two-groups complete networks.},
  archive      = {J_ORL},
  author       = {Gadi Fibich and Amit Golan and Steven Schochet},
  doi          = {10.1016/j.orl.2025.107363},
  journal      = {Operations Research Letters},
  month        = {1},
  pages        = {107363},
  shortjournal = {Oper. Res. Lett.},
  title        = {Monotone convergence of spreading processes on networks},
  volume       = {64},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="parco">PARCO - 5</h2>
<ul>
<li><details>
<summary>
(2025). Software acceleration of multi-user MIMO uplink detection on GPU. <em>PARCO</em>, <em>125</em>, 103150. (<a href='https://doi.org/10.1016/j.parco.2025.103150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the exploration of GPU-accelerated block-wise decompositions for zero-forcing (ZF) based QR and Cholesky methods applied to massive multiple-input multiple-output (MIMO) uplink detection algorithms. Three algorithms are evaluated: ZF with block Cholesky decomposition, ZF with block QR decomposition (QRD), and minimum mean square error (MMSE) with block Cholesky decomposition. The latter was the only one previously explored, but it used standard Cholesky decomposition. Our approach achieves an 11% improvement over the previous GPU-accelerated MMSE study. Through performance analysis, we observe a trade-off between precision and execution time. Reducing precision from FP64 to FP32 improves execution time but increases bit error rate (BER), with ZF-based QRD reducing execution time from 2 . 04 μ s to 1 . 24 μ s for a 128 × 8 MIMO size. The study also highlights that larger MIMO sizes, particularly 2048 × 32, require GPUs to fully utilize their computational and memory capabilities, especially under FP64 precision. In contrast, smaller matrices are compute-bound. Our results recommend GPUs for larger MIMO sizes, as they offer the parallelism and memory resources necessary to efficiently handle the computational demands of next-generation networks. This work paves the way for scalable, GPU-based massive MIMO uplink detection systems.},
  archive      = {J_PARCO},
  author       = {Ali Nada and Hazem Ismail Ali and Liang Liu and Yousra Alkabani},
  doi          = {10.1016/j.parco.2025.103150},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103150},
  shortjournal = {Parallel Comput.},
  title        = {Software acceleration of multi-user MIMO uplink detection on GPU},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enable cross-iteration parallelism for PIM-based graph processing with vertex-level synchronization. <em>PARCO</em>, <em>125</em>, 103149. (<a href='https://doi.org/10.1016/j.parco.2025.103149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Processing-in-memory (PIM) architectures have emerged as a promising solution for accelerating graph processing by enabling computation in memory and minimizing data movement. However, most existing PIM-based graph processing systems rely on the Bulk Synchronous Parallel (BSP) model, which frequently enforces global barriers that limit cross-iteration computational parallelism and introduce significant synchronization and communication overheads. To address these limitations, we propose the Cross Iteration Parallel (CIP) model, a novel vertex-level synchronization approach that eliminates global barriers by independently tracking the synchronization states of vertices. The CIP model enables concurrent execution across iterations, enhancing computational parallelism, overlapping communication and computation, improving core utilization, and increasing resilience to workload imbalance. We implement the CIP model in a PIM-based graph processing system, GraphDF, which features a few specially designed function units to support vertex-level synchronization. Evaluated on a PyMTL3-based cycle-accurate simulator using four real-world graphs and four graph algorithms, CIP running on GraphDF achieves an average speedup of 1.8 × and a maximum of 2.3 × compared to Dalorex, the state-of-the-art PIM-based graph processing system.},
  archive      = {J_PARCO},
  author       = {Xiang Zhao and Haitao Du and Yi Kang},
  doi          = {10.1016/j.parco.2025.103149},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103149},
  shortjournal = {Parallel Comput.},
  title        = {Enable cross-iteration parallelism for PIM-based graph processing with vertex-level synchronization},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-workflow fault-tolerance scheduling strategy considering resources supply delay in WaaS platforms. <em>PARCO</em>, <em>125</em>, 103148. (<a href='https://doi.org/10.1016/j.parco.2025.103148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workflow as a Service (WaaS) platforms rent virtual machines (VMs) from IaaS providers to run scientific workflows for users. However, current researches on workflow scheduling in WaaS platforms did not consider the possibility of VMs downtime leading to task failures or the resources (such as VMs and containers) supply delay affecting scheduling efficiency. To address this issue, this paper proposes a multi-workflow fault-tolerance scheduling strategy for WaaS platforms. Firstly, since WaaS platforms do not manage hardware directly but schedule workflows at the level of VMs and containers, we establish a workflow scheduling model suitable for WaaS platforms, taking into account the impact of resources supply delay on workflow scheduling. Secondly, we propose a multi-workflow fault-tolerance scheduling strategy for WaaS platforms, which includes preprocessing, fault-tolerance selection, task assignment, and resource adjustment. It involves an improved deadline division algorithm to determine the scheduling order, a fault-tolerance selection algorithm combining two fault-tolerance strategies (replication and re-submission), task assignment algorithm considering task attributes and resource supply delay to schedule tasks, and a resource adjustment algorithm to pre-deploy resources for upcoming tasks. Finally, we compare the proposed scheduling strategy with three other algorithms, and the results also demonstrate its effectiveness.},
  archive      = {J_PARCO},
  author       = {Hui Zhao and Wentao Zhi and Xiaoqin Lu and Jing Wang and Nan Luo and Bo Wan and Quan Wang},
  doi          = {10.1016/j.parco.2025.103148},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103148},
  shortjournal = {Parallel Comput.},
  title        = {Multi-workflow fault-tolerance scheduling strategy considering resources supply delay in WaaS platforms},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ALBBA: An efficient ALgebraic bypass BFS algorithm on long vector architectures. <em>PARCO</em>, <em>125</em>, 103147. (<a href='https://doi.org/10.1016/j.parco.2025.103147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breadth First Search (BFS) is a fundamental algorithm in scientific computing, databases, and network analysis applications. In the algebraic BFS paradigm, each BFS iteration is expressed as a sparse matrix–vector multiplication, allowing BFS to be accelerated and analyzed through well-established linear algebra primitives. Although much effort has been made to optimize algebraic BFS on parallel platforms such as CPUs, GPUs, and distributed memory systems, vector architectures that exploit Single Instruction Multiple Data (SIMD) parallelism, particularly with their high performance on sparse workloads, remain relatively underexplored for BFS. In this paper, we propose the ALgebraic Bypass BFS Algorithm (ALBBA), a novel and efficient algebraic BFS implementation optimized for long vector architectures. ALBBA utilizes a customized variant of the SELL- C - σ data structure to fully exploit the SIMD capabilities. By integrating a vectorization-friendly search method alongside a two-level bypass strategy, we enhance both sparse matrix-sparse vector multiplication (SpMSpV) and sparse matrix-dense vector multiplication (SpMV) algorithms, which are crucial for algebraic BFS operations. We further incorporate merge primitives and adopt an efficient selection method for each BFS iteration. Our experiments on an NEC VE20B processor demonstrate that ALBBA achieves average speedups of 3.91 × , 2.88 × , and 1.46 × over Enterprise, GraphBLAST, and Gunrock running on an NVIDIA H100 GPU, respectively.},
  archive      = {J_PARCO},
  author       = {Yuyao Niu and Marc Casas},
  doi          = {10.1016/j.parco.2025.103147},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103147},
  shortjournal = {Parallel Comput.},
  title        = {ALBBA: An efficient ALgebraic bypass BFS algorithm on long vector architectures},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using java to create and analyze models of parallel computing systems. <em>PARCO</em>, <em>125</em>, 103146. (<a href='https://doi.org/10.1016/j.parco.2025.103146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of the study is to develop optimal solutions for models of parallel computing systems using the Java language. During the study, programs were written for the examined models of parallel computing systems. The result of the parallel sorting code is the output of a sorted array of random numbers. When processing data in parallel, the time spent on processing and the first elements of the list of squared numbers are displayed. When processing requests asynchronously, processing completion messages are displayed for each task with a slight delay. The main results include the development of optimization methods for algorithms and processes, such as the division of tasks into subtasks, the use of non-blocking algorithms, effective memory management, and load balancing, as well as the construction of diagrams and comparison of these methods by characteristics, including descriptions, implementation examples, and advantages. In addition, various specialized libraries were analyzed to improve the performance and scalability of the models. The results of the work performed showed a substantial improvement in response time, bandwidth, and resource efficiency in parallel computing systems. Scalability and load analysis assessments were conducted, demonstrating how the system responds to an increase in data volume or the number of threads. Profiling tools were used to analyze performance in detail and identify bottlenecks in models, which improved the architecture and implementation of parallel computing systems. The obtained results emphasize the importance of choosing the right methods and tools for optimizing parallel computing systems, which can substantially improve their performance and efficiency.},
  archive      = {J_PARCO},
  author       = {Harish Padmanaban and Nurkasym Arkabaev and Maher Ali Rusho and Vladyslav Kozub and Yurii Kozub},
  doi          = {10.1016/j.parco.2025.103146},
  journal      = {Parallel Computing},
  month        = {9},
  pages        = {103146},
  shortjournal = {Parallel Comput.},
  title        = {Using java to create and analyze models of parallel computing systems},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="pr">PR - 110</h2>
<ul>
<li><details>
<summary>
(2026). Condense loss: Exploiting vector magnitude during person re-identification training process. <em>PR</em>, <em>172</em>, 112443. (<a href='https://doi.org/10.1016/j.patcog.2025.112443'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The magnitudes of features and weights significantly affect the gradients during the training process. L2 normalized softmax losses (such as NormFace, CosFace, ArcFace, etc.) and Naive softmax losses both reduce the magnitudes of image features in the training process and achieve good results in face recognition and person re-identification tasks, respectively. In this paper, we fully utilize the feature vector magnitudes and propose Condense loss for Re-ID tasks, which replaces the inner production of Naive softmax loss with the negative Euclidean distance. Condense loss generates negative radial gradients when updating weight parameters to push all features compacter. Because the coefficients of tangential gradients (the tangential component of the gradients) are related to feature magnitudes, it ideally provides monotonically decreasing tangential gradients, resulting in gradually diminishing updates that enhance the stability of the training process. We also introduce a margin parameter into Condense loss to enlarge inter-class distances and thus help the model learn more discriminative features. Mathematical analysis is given in this paper, and we have conducted sufficient experiments focusing on Re-ID tasks to prove the corresponding conclusion. The experimental results demonstrate that the Condense loss achieves competitive results compared to the state-of-the-art methods in the person re-identification task. At the same time, it also has a good performance in face recognition tasks.},
  archive      = {J_PR},
  author       = {Xi Yang and Wenjiao Dong and Yingzhi Tang and Gu Zheng and Nannan Wang and Xinbo Gao},
  doi          = {10.1016/j.patcog.2025.112443},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112443},
  shortjournal = {Pattern Recognition},
  title        = {Condense loss: Exploiting vector magnitude during person re-identification training process},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Buffer-free class-incremental learning with out-of-distribution detection. <em>PR</em>, <em>172</em>, 112441. (<a href='https://doi.org/10.1016/j.patcog.2025.112441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class-incremental learning (CIL) poses significant challenges in open-world scenarios, where models must learn new classes over time without forgetting previous ones and handle inputs from unknown classes that a closed-set model would misclassify. In this paper, we present an in-depth analysis of post-hoc OOD detection methods and investigate their potential to eliminate the need for a memory buffer. When post hoc OOD detection is applied at inference time, we discover that it can effectively replace buffer-based strategies. We examine the performance of these methods in terms of classification accuracy of seen samples and rejection rates of unseen samples. We show that our approach achieves competitive performance compared to recent multi-head and single-head methods that rely on memory buffers and other buffer-free approaches. The results show that the proposed approach outperforms them in a closed-world setting and detects unseen samples while being significantly resource-efficient. Experimental results on CIFAR-10, CIFAR-100, and Tiny ImageNet support our findings and offer new insights into the design of efficient and privacy-preserving CIL systems for open-world settings.},
  archive      = {J_PR},
  author       = {Srishti Gupta and Daniele Angioni and Maura Pintor and Ambra Demontis and Lea Schönherr and Fabio Roli and Battista Biggio},
  doi          = {10.1016/j.patcog.2025.112441},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112441},
  shortjournal = {Pattern Recognition},
  title        = {Buffer-free class-incremental learning with out-of-distribution detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Corrigendum to “DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction” [Pattern recognition 172 (2026) 112339]. <em>PR</em>, <em>172</em>, 112440. (<a href='https://doi.org/10.1016/j.patcog.2025.112440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_PR},
  author       = {Chengcheng Li and Luqi Gong and Leiheng Xu and Xin Wang},
  doi          = {10.1016/j.patcog.2025.112440},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112440},
  shortjournal = {Pattern Recognition},
  title        = {Corrigendum to “DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction” [Pattern recognition 172 (2026) 112339]},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A progressive attention network with transformer for multi-label image recognition. <em>PR</em>, <em>172</em>, 112439. (<a href='https://doi.org/10.1016/j.patcog.2025.112439'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research typically improves the performance of multi-label image recognition by constructing higher-order pairwise label correlations. However, these methods lack the ability to effectively learn multi-scale features, which makes it difficult to distinguish small-scale objects. Moreover, most current attention-based methods to capture local salient features may ignore many useful non-salient features. To address the aforementioned issues, we propose a Transformer-based Progressive Attention Network (TPANet) for multi-label image recognition. Specifically, we first design a new adaptive multi-scale feature attention (AMSA) module to learn cross-scale features in multi-level features. Then, to excavate various useful object features, we introduce the transformer encoder to construct a semantic spatial attention (ESA) module and also propose a context-aware feature enhanced (CAFE) module. The former ESA module is used to discover complete object regions and capture discriminative features, and the latter CAFE module leverages object-local features to enhance pixel-level global features. The proposed TPANet model can generate more accurate object labels in three popular benchmark datasets (i.e., MS-COCO 2014, Pascal VOC 2007 and Visual Genome), and is competitive to state-of-the-art models (e.g., SST and FL-Tran, etc.).},
  archive      = {J_PR},
  author       = {Sulan Zhang and Zhenwen Liao and Jianeng Li and Lihua Hu and Jifu Zhang},
  doi          = {10.1016/j.patcog.2025.112439},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112439},
  shortjournal = {Pattern Recognition},
  title        = {A progressive attention network with transformer for multi-label image recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Layer-wise correlation and attention discrepancy distillation for semantic segmentation. <em>PR</em>, <em>172</em>, 112438. (<a href='https://doi.org/10.1016/j.patcog.2025.112438'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) has recently garnered increased attention in segmentation tasks due to its effective balance between accuracy and computational efficiency. Nonetheless, existing methods mainly rely on structured knowledge from a single layer, overlooking the valuable discrepant knowledge that captures the diversity and distinctiveness of features across various layers, which is essential for the KD process. We present Layer-wise Correlation and Attention Discrepancy Distillation (LCADD) to tackle this issue, training compact and accurate semantic segmentation networks by considering layer-wise discrepancy knowledge. Specifically, we employ two distillation schemes: (i) correlation discrepancy distillation, which constructs a pixel-wise correlation discrepancy matrix across various layers to seize more detailed spatial dependencies, and (ii) attention discrepancy self-distillation, which aims to guide the shallower layers of the student network to emulate the attention discrepancy maps of the deeper layers, facilitating self-learning of attention discrepancy knowledge within the student network. Each proposed method is designed to work collaboratively in learning discrepancy knowledge, allowing the student network to better imitate the teacher from the perspective of layer-wise discrepancy. Our method has demonstrated superior performance on various semantic segmentation datasets, including Cityscapes, Pascal VOC 2012, and CamVid, compared to the latest knowledge distillation techniques, thereby validating its effectiveness.},
  archive      = {J_PR},
  author       = {Jianping Gou and Kaijie Chen and Cheng Chen and Weihua Ou and Xin Luo and Zhang Yi},
  doi          = {10.1016/j.patcog.2025.112438},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112438},
  shortjournal = {Pattern Recognition},
  title        = {Layer-wise correlation and attention discrepancy distillation for semantic segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gradient semi-masking for improving adversarial robustness. <em>PR</em>, <em>172</em>, 112433. (<a href='https://doi.org/10.1016/j.patcog.2025.112433'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In gradient masking, certain complex signal processing and probabilistic optimization strategies exhibit favorable characteristics such as nonlinearity, irreversibility, and feature preservation, thereby providing new solutions for adversarial defense. Inspired by this, this paper proposes a plug-and-play gradient semi-masking module ( GSeM ) to improve the adversarial robustness of neural networks. GSeM primarily contains a feature straight-through pathway that allows for normal gradient propagation and a feature mapping pathway that interrupts gradient flow. The multi-pathway and semi-masking characteristics cause GSeM to exhibit opposing behaviors when processing data and gradients. Specifically, during data processing, GSeM compresses the state space of features while introducing white noise augmentation. However, during gradient processing, it leads to inefficient updates to certain parameters and ineffective generation of training examples. To address this shortcoming, we correct gradient propagation and introduce gradient-corrected adversarial training. Extensive experiments demonstrate that GSeM differs fundamentally from earlier gradient masking methods: it can genuinely enhance the adversarial defense performance of neural networks, surpassing previous state-of-the-art approaches.},
  archive      = {J_PR},
  author       = {Xinlei Liu and Tao Hu and Peng Yi and Baolin Li and Jichao Xie and Hailong Ma},
  doi          = {10.1016/j.patcog.2025.112433},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112433},
  shortjournal = {Pattern Recognition},
  title        = {Gradient semi-masking for improving adversarial robustness},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Structural-prior guided bi-generative network for image inpainting. <em>PR</em>, <em>172</em>, 112432. (<a href='https://doi.org/10.1016/j.patcog.2025.112432'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image inpainting is a great challenge when reconstructed with realistic textures and required to enhance the consistency of semantic structures in large-scale missing regions. However, popular structural prior guidance methods primarily rely on the reconstruction of structural features. Due to the Markovian property inherent in purely feedforward architectures, noise undergoes persistent accumulation and propagation in early network layers. Without intermediate feedback mechanisms, minor artifacts in shallow layers would be nonlinearly amplified through successive convolution operations and cannot be timely corrected, thereby hindering the extraction of valid structural information. To this end, we presents a bi-generative network (Bi-GNet) guided by specific semantic structures, including an auxiliary network N s and an inpainting network N inp . Here N s provides the structural prior information to N inp for reconstructing the texture details of images. Additionally, we provide the spatial coordinate attention (SCA) and the adaptive feature filtering (AFF) module to ensure structural consistency and texture plausibility in the reconstructed content. Experiments demonstrate that Bi-GNet significantly outperforms other state-of-the-art approaches on three datasets and achieves good inpainting results on the Mogao Grottoes mural dataset.},
  archive      = {J_PR},
  author       = {Jiajun Zhang and Jizhao Liu and Huaikun Zhang and Jibao Zhang and Jing Lian},
  doi          = {10.1016/j.patcog.2025.112432},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112432},
  shortjournal = {Pattern Recognition},
  title        = {Structural-prior guided bi-generative network for image inpainting},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning from majority label: A novel problem in multi-class multiple-instance learning. <em>PR</em>, <em>172</em>, 112425. (<a href='https://doi.org/10.1016/j.patcog.2025.112425'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes a novel multi-class Multiple-Instance Learning (MIL) problem called Learning from Majority Label (LML). In LML, the majority class of instances in a bag is assigned as the bag-level label. The goal of LML is to train a classification model that estimates the class of each instance using the majority label. This problem is valuable in a variety of applications, including pathology image segmentation, political voting prediction, customer sentiment analysis, and environmental monitoring. To solve LML, we propose a Counting Network trained to produce bag-level majority labels, estimated by counting the number of instances in each class. Furthermore, analysis experiments on the characteristics of LML revealed that bags with a high proportion of the majority class facilitate learning. Based on this result, we developed a Majority Proportion Enhancement Module (MPEM) that increases the proportion of the majority class by removing minority class instances within the bags. Experiments demonstrate the superiority of the proposed method on four datasets compared to conventional MIL methods. Moreover, ablation studies confirmed the effectiveness of each module. The code is available at here .},
  archive      = {J_PR},
  author       = {Kaito Shiku and Shinnosuke Matsuo and Daiki Suehiro and Ryoma Bise},
  doi          = {10.1016/j.patcog.2025.112425},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112425},
  shortjournal = {Pattern Recognition},
  title        = {Learning from majority label: A novel problem in multi-class multiple-instance learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Feature subset weighting for distance-based supervised learning. <em>PR</em>, <em>172</em>, 112424. (<a href='https://doi.org/10.1016/j.patcog.2025.112424'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces feature subset weighting using monotone measures for distance-based supervised learning. The Choquet integral is used to define a distance function that incorporates these weights. This integration enables the proposed distances to effectively capture non-linear relationships and account for interactions both between conditional and decision attributes and among conditional attributes themselves, resulting in a more flexible distance measure. In particular, we show how this approach ensures that the distances remain unaffected by the addition of duplicate and strongly correlated features. Another key point of this approach is that it makes feature subset weighting computationally feasible, since only m feature subset weights should be calculated each time instead of calculating all feature subset weights ( 2 m ), where m is the number of attributes. Next, we also examine how the use of the Choquet integral for measuring similarity leads to a non-equivalent definition of distance. The relationship between distance and similarity is further explored through dual measures. Additionally, symmetric Choquet distances and similarities are proposed, preserving the classical symmetry between similarity and distance. Finally, we introduce a concrete feature subset weighting distance, evaluate its performance in a k -nearest neighbours (KNN) classification setting, and compare it against Mahalanobis distances and weighted distance methods.},
  archive      = {J_PR},
  author       = {Adnan Theerens and Yvan Saeys and Chris Cornelis},
  doi          = {10.1016/j.patcog.2025.112424},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112424},
  shortjournal = {Pattern Recognition},
  title        = {Feature subset weighting for distance-based supervised learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive integration of textual context and visual embeddings for underrepresented vision classification. <em>PR</em>, <em>172</em>, 112420. (<a href='https://doi.org/10.1016/j.patcog.2025.112420'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of deep learning has significantly improved image classification performance; however, handling long-tail distributions remains challenging due to the limited data available for rare classes. Existing approaches predominantly focus on visual features, often neglecting the valuable contextual information provided by textual data, which can be especially beneficial for classes with sparse visual examples. In this work, we introduce a novel method addressing this limitation by integrating textual data generated by advanced language models with visual inputs through our newly proposed Adaptive Integration Block for Vision-Text Synergy (AIB-VTS). Specifically designed for Vision Transformer architectures, AIB-VTS adaptively balances visual and textual information during inference, effectively utilizing textual descriptions generated from large language models. Extensive experiments on benchmark datasets demonstrate substantial performance improvements across all class groups, particularly in underrepresented (tail) classes. These results confirm the effectiveness of our approach in leveraging textual context to mitigate data scarcity issues and enhance model robustness.},
  archive      = {J_PR},
  author       = {Seongyeop Kim and Hyung-Il Kim and Yong Man Ro},
  doi          = {10.1016/j.patcog.2025.112420},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112420},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive integration of textual context and visual embeddings for underrepresented vision classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PCFFusion: Progressive cross-modal feature fusion network for infrared and visible images. <em>PR</em>, <em>172</em>, 112419. (<a href='https://doi.org/10.1016/j.patcog.2025.112419'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion (IVIF) aims to fuse thermal target information in infrared images and spatial texture information in visible images, improving the observability and comprehensibility of the fused images. Currently, most IVIF methods suffer from the loss of salient target information and texture details in fused images. To alleviate this problem, a progressive cross-modal feature fusion network (PCFFusion) for IVIF is proposed, which comprises two stages: feature extraction and feature fusion. In the feature extraction stage, to enhance the network’s feature representation capability, a feature decomposition module (FDM) is constructed to extract two modal features of different scales by defining a feature decomposition operation (FDO). In addition, by establishing correlations between the high- frequency and low-frequency components of two modal features, a cross-modal feature enhancement module (CMFEM) is built to realize correction and enhancement of the two features at each scale. The feature fusion stage achieves the fusion of two modal features at each scale and the supplementation of adjacent scale features by constructing three cross-domain fusion module (CDFMs). To constrain the fused results preserve more salient targets and richer texture details, a dual-feature fidelity loss function is defined by constructing a salient weight map to balance the two loss terms. Extensive experiments demonstrate that fusion results of the proposed method highlight prominent targets from infrared images while retaining rich background details from visible images, and the performance of PCFFusion is superior to some advanced methods. Specifically, compared to the optimal results obtained by other comparison methods, the proposed network achieves an average increase of 30.35 % and 10.9 % in metrics Mutual Information (MI) and Standard deviation (SD) on the TNO dataset, respectively.},
  archive      = {J_PR},
  author       = {Shuying Huang and Kai Zhang and Yong Yang and Weiguo Wan},
  doi          = {10.1016/j.patcog.2025.112419},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112419},
  shortjournal = {Pattern Recognition},
  title        = {PCFFusion: Progressive cross-modal feature fusion network for infrared and visible images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time series adaptive mode decomposition (TAMD): Method for improving forecasting accuracy in the apparel industry. <em>PR</em>, <em>172</em>, 112417. (<a href='https://doi.org/10.1016/j.patcog.2025.112417'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of apparel sales is critical for inventory management, supply chain optimization, and market strategy planning. However, existing forecasting models often struggle to effectively capture the complex characteristics of apparel sales data, such as distinct seasonality, cyclicality, and strongly nonlinear fluctuations, which significantly hinder prediction accuracy and generalization ability. To address these challenges, this study introduces a novel Time series Adaptive Mode Decomposition (TAMD)-based forecasting algorithm. The proposed method: (1) employs Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and sample entropy-guided Variational Mode Decomposition (VMD) to separate the input time series into noise components and multiple smooth Intrinsic Mode Functions (IMFs), to better capture intrinsic data dynamics; (2) refines the sub-series distribution features via an adaptive module guided by sample entropy, dividing each sub-series into subsequences with maximal distribution difference to improve adaptability to periodic changes and market volatility; (3) predicts each subsequence with adaptive distribution matching based on discontinuous random subsequence combinations, and then linearly superposes the prediction results as a final output, thereby boosting accuracy and generalizability. Comprehensive experiments on both public and self-constructed datasets (including four years of Taobao sales data for dresses, jeans, sweatshirts, and sweaters, totaling over 44.7 million records) demonstrate that TAMD outperforms existing methods significantly, highlighting its effectiveness in revealing the complexity of apparel market data and enhancing prediction performance.},
  archive      = {J_PR},
  author       = {Guangbao Zhou and Pengliang Liu and Quanle Lin and Miao Qian and Zhong Xiang and Zeyu Zheng and Lixian Liu},
  doi          = {10.1016/j.patcog.2025.112417},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112417},
  shortjournal = {Pattern Recognition},
  title        = {Time series adaptive mode decomposition (TAMD): Method for improving forecasting accuracy in the apparel industry},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A framework for bias-aware dataset evaluation in soft facial attribute recognition. <em>PR</em>, <em>172</em>, 112416. (<a href='https://doi.org/10.1016/j.patcog.2025.112416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft Facial Attribute Recognition (FAR) remains largely unexplored in terms of demographic fairness. To the best of our knowledge, this study presents one of the first comprehensive analyses of demographic bias in FAR, proposing a systematic framework to detect, quantify, and promote awareness of both representational and stereotypical biases, supporting their mitigation. Leveraging established taxonomies, we evaluate state-of-the-art datasets using a rigorous set of interpretable bias metrics to uncover hidden demographic imbalances. To support reliable fairness assessment, we first enrich the datasets with standardized demographic annotations using the FairFace model. We then address label inconsistencies through the integration of predictions from advanced Vision-Language Models (VLMs). Our analysis reveals substantial imbalances across gender, age, and racial categories-specifically White, Black, and Asian- affecting dataset composition. Furthermore, we show that conventional fairness metrics often yield divergent assessments, highlighting the importance of multi-metric evaluation. This study provides a replicable methodology and actionable insights to support bias-aware facial analysis.},
  archive      = {J_PR},
  author       = {Lucia Cascone and Michele Nappi and Chiara Pero and Xinggang Wang},
  doi          = {10.1016/j.patcog.2025.112416},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112416},
  shortjournal = {Pattern Recognition},
  title        = {A framework for bias-aware dataset evaluation in soft facial attribute recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fast multi-view discrete clustering with two solvers. <em>PR</em>, <em>172</em>, 112415. (<a href='https://doi.org/10.1016/j.patcog.2025.112415'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view graph clustering follows a three-phase process: constructing view-specific similarity graphs, fusing information from different views, and conducting eigenvalue decomposition followed by post-processing to obtain the clustering indicators. However, it encounters two key challenges: the high computational cost of graph construction and eigenvalue decomposition, and the inevitable information deviation introduced by the last process. To tackle these obstacles, we propose Fast Multi-view Discrete Clustering with two solvers (FMDC), to directly and efficiently solve the multi-view graph clustering problem. FMDC involves: (1) generating a compact set of representative anchors to construct anchor graphs, (2) automatically weighting them into a symmetric and doubly stochastic aggregated similarity matrix, (3) executing clustering on the aggregated form with the discrete indicator matrix directly computed through two efficient solvers that we devised. The linear computational complexity of FMDC w.r.t. data size is a notable improvement over traditional quadratic or cubic complexity. Extensive experiments confirm the superior performance of FMDC both in efficiency and in effectiveness.},
  archive      = {J_PR},
  author       = {Qianyao Qiang and Bin Zhang and Jason Chen Zhang and Feiping Nie},
  doi          = {10.1016/j.patcog.2025.112415},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112415},
  shortjournal = {Pattern Recognition},
  title        = {Fast multi-view discrete clustering with two solvers},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Asymmetric simulation-enhanced flow reconstruction for incomplete multimodal learning. <em>PR</em>, <em>172</em>, 112413. (<a href='https://doi.org/10.1016/j.patcog.2025.112413'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multimodal learning addresses the common real-world challenge of missing modalities, which undermines the performance of standard multimodal methods. Existing solutions struggle with distribution mismatches between reconstructed and observed data, asymmetric cross-modal structures, and insufficient cross-modal knowledge sharing. To tackle these issues, we propose an asymmetric simulation-enhanced flow reconstruction (ASE-FR) framework, which contains following contributions: (1) Distribution-consistent flow reconstruction module that align available and missing modality distributions by normalizing flows; (2) Asymmetric simulation module that perturbs and randomly masks features to mimic real-world modality absence and improve robustness; (3) Modal-shared knowledge distillation that transfers shared representations from teacher encoders to a student encoder through contrastive learning. This framework is applicable to a range of real-world scenarios, such as multi-sensor networks in smart manufacturing, medical diagnostic systems combining imaging and electronic health records, and autonomous driving platforms that integrate camera and LiDAR data. The experimental results show that our ASE-FR method achieves 94.71 %, 41.85 % and 81.90 % accuracy on Audiovision-MNIST, MM-IMDb and IEMOCAP datasets, as well as 1.1376 error rate on CMU-MOSI dataset, which exhibits competitive performance.},
  archive      = {J_PR},
  author       = {Jiacheng Yao and Jing Zhang and Yixiao Wang and Li Zhuo},
  doi          = {10.1016/j.patcog.2025.112413},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112413},
  shortjournal = {Pattern Recognition},
  title        = {Asymmetric simulation-enhanced flow reconstruction for incomplete multimodal learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Benchmarking the spatial robustness of DNNs via natural and adversarial localized corruptions. <em>PR</em>, <em>172</em>, 112412. (<a href='https://doi.org/10.1016/j.patcog.2025.112412'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robustness of deep neural networks is a crucial factor in safety-critical applications, particularly in complex and dynamic environments (e.g., medical or driving scenarios) where localized corruptions can arise. While previous studies have evaluated the robustness of semantic segmentation (SS) models under whole-image natural or adversarial corruptions, a comprehensive investigation into the spatial robustness of dense vision models under localized corruptions remained underexplored. This paper fills this gap by introducing novel, region-aware metrics for benchmarking the spatial robustness of segmentation models, along with an evaluation framework to assess the impact of natural localized corruptions. Furthermore, it uncovers the inherent complexity of evaluating worst-case spatial robustness using only a single localized adversarial attack. To address this, the work proposes a region-aware multi-attack adversarial analysis to systematically assess model robustness across specific image regions. The proposed metrics and analysis were exploited to evaluate 14 segmentation models in driving scenarios, uncovering key insights into the effects of localized corruption in both natural and adversarial forms. The results reveal that models respond to these two types of threats differently; for instance, transformer-based segmentation models demonstrate notable robustness to localized natural corruptions but are highly vulnerable to adversarial ones, and vice versa for CNN-based models. Consequently, we also address the challenge of balancing robustness to both natural and adversarial localized corruptions by means of ensemble models, thereby achieving a broader threat coverage and improved reliability for dense vision tasks.},
  archive      = {J_PR},
  author       = {Giulia Marchiori Pietrosanti and Giulio Rossolini and Alessandro Biondi and Giorgio Buttazzo},
  doi          = {10.1016/j.patcog.2025.112412},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112412},
  shortjournal = {Pattern Recognition},
  title        = {Benchmarking the spatial robustness of DNNs via natural and adversarial localized corruptions},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Preserving privacy without compromising accuracy: Machine unlearning for handwritten text recognition. <em>PR</em>, <em>172</em>, 112411. (<a href='https://doi.org/10.1016/j.patcog.2025.112411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten Text Recognition (HTR) is crucial for document digitization, but handwritten data can contain user-identifiable features, like unique writing styles, posing privacy risks. Regulations such as the “right to be forgotten” require models to remove these sensitive traces without full retraining. We introduce a practical encoder-only transformer baseline as a robust reference for future HTR research. Building on this, we propose a two-stage unlearning framework for multihead transformer HTR models. Our method combines neural pruning with machine unlearning applied to a writer classification head, ensuring sensitive information is removed while preserving the recognition head. We also present Writer-ID Confusion (WIC), a method that forces the forget set to follow a uniform distribution over writer identities, unlearning user-specific cues while maintaining text recognition performance. We compare WIC to Random Labeling, Fisher Forgetting, Amnesiac Unlearning, and DELETE within our prune-unlearn pipeline and consistently achieve better privacy and accuracy trade-offs. This is the first systematic study of machine unlearning for HTR. Using metrics such as Accuracy, Character Error Rate (CER), Word Error Rate (WER), and Membership Inference Attacks (MIA) on the IAM and CVL datasets, we demonstrate that our method achieves state-of-the-art or superior performance for effective unlearning. These experiments show that our approach effectively safeguards privacy without compromising accuracy, opening new directions for document analysis research. Our code is publicly available at https://github.com/leitro/WIC-WriterIDConfusion-MachineUnlearning .},
  archive      = {J_PR},
  author       = {Lei Kang and Xuanshuo Fu and Lluis Gomez and Alicia Fornés and Ernest Valveny and Dimosthenis Karatzas},
  doi          = {10.1016/j.patcog.2025.112411},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112411},
  shortjournal = {Pattern Recognition},
  title        = {Preserving privacy without compromising accuracy: Machine unlearning for handwritten text recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated automatic latent variable selection in multi-output gaussian processes. <em>PR</em>, <em>172</em>, 112410. (<a href='https://doi.org/10.1016/j.patcog.2025.112410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores a federated learning approach that automatically selects the number of latent processes in multi-output Gaussian processes (MGPs). The MGP has seen great success as a transfer learning tool when data is generated from multiple sources/units/entities. A common approach in MGPs to transfer knowledge across units involves gathering all data from each unit to a central server and extracting common independent latent processes to express each unit as a linear combination of the shared latent patterns. However, this approach poses key challenges in (i) determining the adequate number of latent processes and (ii) relying on centralized learning which leads to potential privacy risks and significant computational burdens on the central server. To address these issues, we propose a hierarchical model that places spike-and-slab priors on the coefficients of each latent process. These priors help automatically select only needed latent processes by shrinking the coefficients of unnecessary ones to zero. To estimate the model while avoiding the drawbacks of centralized learning, we propose a variational inference-based approach, that formulates model inference as an optimization problem compatible with federated settings. We then design a federated learning algorithm that allows units to jointly select and infer the common latent processes without sharing their data. We also discuss an efficient learning approach for a new unit within our proposed federated framework. Simulation and case studies on Li-ion battery degradation and air temperature data demonstrate the advantageous features of our proposed approach.},
  archive      = {J_PR},
  author       = {Jingyi Gao and Seokhyun Chung},
  doi          = {10.1016/j.patcog.2025.112410},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112410},
  shortjournal = {Pattern Recognition},
  title        = {Federated automatic latent variable selection in multi-output gaussian processes},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive multi-view consistency clustering via structure-enhanced contrastive learning. <em>PR</em>, <em>172</em>, 112409. (<a href='https://doi.org/10.1016/j.patcog.2025.112409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current state-of-the-art deep multi-view clustering methods resort to contrastive learning to learn consensus representations with Cross-View Consistency ( CVC ). However, contrastive learning has inherent limitations when being applied to the multi-view clustering. On one hand, contrastive learning suffers from class collision issue, compromising the discriminability of consensus representation. On the other hand, contrastive alignment of two views of different quality could lead to representation degradation for the higher-quality view, weakening the robustness of the consensus representation. To alleviate these issues, this paper presents an Adaptive Multi-view consistency clustering method via structure-enhanced contrastive learning ( A da M ), which learns multi-faceted consensus representation that balances view-consistency, discriminability and robustness, forming an optimal consensus representation. Specifically, we first design a view fusion module and a structural learning module to learn view weights and structural relationships among samples, respectively, to derive the consensus representation. Second, beyond CVC , we propose a novel clustering framework called Adaptive Multi-View Consistency ( AMVC ), which adaptively aligns specific view representation with consensus representation based on the learned view weights. Furthermore, compared to CVC , we theoretically demonstrate the superiority of AMVC in learning robust consensus representation. Third, A da M leverages the structural relationships among samples to refine the conventional contrastive loss, further enhancing the discriminability of the consensus representation. Extensive experimental results on eight datasets demonstrate the superior performance of A da M over eight advanced multi-view clustering baselines.},
  archive      = {J_PR},
  author       = {Xuqian Xue and Qi Cai and Zhanwei Zhang and Yiming Lei and Hongming Shan and Junping Zhang},
  doi          = {10.1016/j.patcog.2025.112409},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112409},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive multi-view consistency clustering via structure-enhanced contrastive learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A text-only weakly supervised learning framework for text spotting via text-to-polygon generator. <em>PR</em>, <em>172</em>, 112408. (<a href='https://doi.org/10.1016/j.patcog.2025.112408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced text spotting methods typically rely on large-scale, meticulously labeled datasets to achieve satisfactory performance. However, annotating fine-grained positional information of texts in real-world scene images is extremely costly and time-consuming. Although some weakly supervised methods have been developed to reduce annotation costs, they face two major challenges: 1) their performance significantly lags behind the fully supervised counterparts, and 2) They are tightly coupled with specific text spotting models, meaning that switching to a different model would require retraining and incur substantial computational costs. To address these limitations, we propose a novel text-only weakly supervised learning framework for text spotting via text-to-polygon generator. In the first stage, we pretrain a text-to-polygon generator on an auxiliary dataset, e.g., synthetic or public datasets, where full annotations are readily accessible. In the second stage, given real-world target datasets annotated with text-only labels, we employ the pretrained generator to produce pseudo polygon labels, thereby constructing a pseudo-labeled supervised dataset for training text spotting models. To ensure high-quality pseudo polygon labels, the text-to-polygon generator first identifies all candidate text regions, then filters those that are relevant to the target text, and finally predicts their precise spatial locations. Notably, this generator requires only a single pretraining session and can subsequently be applied to any text spotting model and target text-only dataset without incurring additional costs. Extensive experiments on public benchmarks demonstrate that our method can significantly reduce labeling costs while maintaining competitive performance.},
  archive      = {J_PR},
  author       = {Gege Zhang and Zhiyong Gan and Ling Deng and Shuaicheng Niu and Zhenghua Peng and Gang Dai and Shuangping Huang and Xiangmin Xu},
  doi          = {10.1016/j.patcog.2025.112408},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112408},
  shortjournal = {Pattern Recognition},
  title        = {A text-only weakly supervised learning framework for text spotting via text-to-polygon generator},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Leveraging synthetic data for zero–shot and few–shot circle detection in real–world domains. <em>PR</em>, <em>172</em>, 112407. (<a href='https://doi.org/10.1016/j.patcog.2025.112407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circle detection plays a pivotal role in computer vision, underpinning applications from industrial inspection and bioinformatics to autonomous driving. Traditional methods, however, often struggle with real–world complexities, as they demand extensive parameter tuning and adaptation across different domains. In this paper, we present the Synthetic Circle Dataset (SynCircle), a large synthetic image dataset designed to train a YOLO v10 network for circle detection. The YOLO v10 network, pre–trained solely on synthetic data, demonstrates remarkable off–the–shelf performance that surpasses conventional methods in various practical scenarios. Furthermore, we show that incorporating just a few labeled real images for fine–tuning can significantly boost performance, reducing the need for large annotated datasets. To promote reproducibility and streamline adoption, we publicly release both the trained YOLO v10 weights and the full SynCircle dataset.},
  archive      = {J_PR},
  author       = {Paolo Andreini and Marco Tanfoni and Simone Bonechi and Monica Bianchini},
  doi          = {10.1016/j.patcog.2025.112407},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112407},
  shortjournal = {Pattern Recognition},
  title        = {Leveraging synthetic data for zero–shot and few–shot circle detection in real–world domains},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DURN: Data uncertainty-driven robust network for mural sketch detection. <em>PR</em>, <em>172</em>, 112404. (<a href='https://doi.org/10.1016/j.patcog.2025.112404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mural sketches reveal both the content and structure of the murals and are crucial for the preservation of murals. However, existing methods lack robustness, making it difficult to suppress noise while preserving sketches on damaged murals and fully capturing details on clear murals. To address this, we propose a Data Uncertainty-Driven Robust Network (DURN) for mural sketch detection. DURN uses uncertainty to quantify noise in the murals, converting prediction into a learnable normal distribution, where the mean represents the sketch and the variance denotes the uncertainty. This enables the model to learn both the sketch and the noise simultaneously, achieving noise suppression while preserving the sketches. To enhance sketches, we design an Adaptive Fusion Feature Enhancement Module (AFFE) to dynamically adjust the fusion strategy according to the contribution of features at different scales and reduce the information loss caused by feature dimensionality reduction to maximize the utility of each feature. We develop a novel Deep-Shallow Supervision (DSS) module to mitigate background noise using deep semantic information to guide shallow features without adding parameters. Additionally, we achieve model lightweighting through pruning techniques, ensuring competitive performance while reducing the number of parameters to only 4.5 % of the original. The experimental results show an improvement of 10. 4 % AP over existing methods, demonstrating the robustness of DURN for complex and damaged murals. The source code is available at https://github.com/TIVEN-Z/DURN .},
  archive      = {J_PR},
  author       = {Shenglin Peng and Xingguo Zhao and Jun Wang and Lin Wang and Shuyi Qu and Jingye Peng and Xianlin Peng},
  doi          = {10.1016/j.patcog.2025.112404},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112404},
  shortjournal = {Pattern Recognition},
  title        = {DURN: Data uncertainty-driven robust network for mural sketch detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learn depth space from light field via a distance-constraint query mechanism. <em>PR</em>, <em>172</em>, 112403. (<a href='https://doi.org/10.1016/j.patcog.2025.112403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Light Field (LF) captures both spatial and angular information of scenes, enabling precise depth estimation. Recent advancements in deep learning have led to significant success in this field; however, existing methods primarily focus on modeling surface characteristics (e.g., depth maps) while overlooking the depth space, which contains additional valuable information. The depth space consists of numerous space points and provides substantially more geometric data than a single depth map. In this paper, we conceptualize depth prediction as a spatial modeling problem, aiming to learn the entire depth space rather than merely a single depth map. Specifically, we define space points as signed distances relative to the scene surface and propose a novel distance-constraint query mechanism for LF depth estimation. To model the depth space effectively, we first develop a mixed sampling strategy to approximate its data representation. Subsequently, we introduce an encoder-decoder network architecture to query the distances of each point, thereby implicitly embedding the depth space. Finally, to extract the target depth map from this space, we present a generation algorithm that iteratively invokes the decoder network. Through extensive experiments, our approach achieves the highest performance on LF depth estimation benchmarks, and also demonstrates superior performance on various synthetic and real-world scenes.},
  archive      = {J_PR},
  author       = {Hao Sheng and Rongshan Chen and Ruixuan Cong and Da Yang and Zhenglong Cui and Sizhe Wang},
  doi          = {10.1016/j.patcog.2025.112403},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112403},
  shortjournal = {Pattern Recognition},
  title        = {Learn depth space from light field via a distance-constraint query mechanism},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised instance segmentation with superpixels. <em>PR</em>, <em>172</em>, 112402. (<a href='https://doi.org/10.1016/j.patcog.2025.112402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance segmentation is essential for numerous computer vision applications, including robotics, human-computer interaction, and autonomous driving. Currently, popular models bring impressive performance in instance segmentation by training with a large number of human annotations, which are costly to collect. For this reason, we present a new framework that efficiently and effectively segments objects without the need for human annotations. Firstly, a MultiCut algorithm is applied to self-supervised features for coarse mask segmentation. Then, a mask filter is employed to obtain high-quality coarse masks. To train the segmentation network, we compute a novel superpixel-guided mask loss, comprising hard loss and soft loss, with high-quality coarse masks and superpixels segmented from low-level image features. Lastly, a self-training process with a new adaptive loss is proposed to improve the quality of predicted masks. We conduct experiments on public datasets in instance segmentation and object detection to demonstrate the effectiveness of the proposed framework. The results show that the proposed framework outperforms previous state-of-the-art methods.},
  archive      = {J_PR},
  author       = {Cuong Manh Hoang},
  doi          = {10.1016/j.patcog.2025.112402},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112402},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised instance segmentation with superpixels},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MIGF-net: Multimodal interaction-guided fusion network for image aesthetics assessment. <em>PR</em>, <em>172</em>, 112401. (<a href='https://doi.org/10.1016/j.patcog.2025.112401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of social media, people like to post images and comments to share their ideas, which provides rich visual and textural semantic information for image aesthetics assessment (IAA). However, most previous works either extracted the unimodal aesthetic features from image due to the difficulty of obtaining comments, or combined multimodal information together but ignoring the interactive relationship between image and comment, which limits the overall performance. To solve the above problem, we propose a Multimodal Interaction-Guided Fusion Network (MIGF-Net) for image aesthetics assessment based on both image and comment semantic information, which can not only solve the challenge of comment generating, but also provide the multimodal feature interactive information. Specifically, considering the coupling mechanism of the image theme, we construct a visual semantic fusion module to extract the visual semantic feature based on the visual attributes and the theme features. Then, a textural semantic feature extractor is designed to mine the semantic information hidden in comments, which not only addresses the issue of missing comments but also effectively complements the visual semantic features. Furthermore, we establish a Dual-Stream Interaction-Guided Fusion module to fuse the semantic features of images and comments, fully exploring the interactive relationship between images and comments in the human brain’s perception mechanism. Experimental results on two public image aesthetics evaluation datasets demonstrate that our model outperforms the current state-of-the-art methods. Our code will be released at https://github.com/wenzhipeng123/MIGF-Net .},
  archive      = {J_PR},
  author       = {Yun Liu and Zhipeng Wen and Leida Li and Peiguang Jing and Daoxin Fan},
  doi          = {10.1016/j.patcog.2025.112401},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112401},
  shortjournal = {Pattern Recognition},
  title        = {MIGF-net: Multimodal interaction-guided fusion network for image aesthetics assessment},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IRIS: An information path planning method based on reinforcement learning and information-directed sampling. <em>PR</em>, <em>172</em>, 112400. (<a href='https://doi.org/10.1016/j.patcog.2025.112400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information Path Planning (IPP) is a critical aspect of robotics, aimed at intelligently selecting information-rich paths to optimize robot trajectories and significantly enhance the efficiency and quality of data collection. However, in the process of maximizing information acquisition, IPP must also account for energy consumption, time constraints, and physical obstacles, which often lead to inefficiencies. To address these challenges, we propose an Information Path Planning method based on Reinforcement Learning and Information-Directed Sampling (IRIS). This model is the first to integrate Reinforcement Learning (RL) with Information-Directed Sampling (IDS), ensuring both immediate rewards and the potential for greater information gain through exploratory actions. IRIS employs an off-policy deep reinforcement learning framework, effectively overcoming the limitations observed in on-policy methods, thereby enhancing the model’s adaptability and efficiency. Simulation results demonstrate that the IRIS algorithm performs exceptionally well across various IPP scenarios. Once training stabilizes, IDS will dominate decision-making with a probability of approximately 1.3 % to yield better outcomes, highlighting its significant potential in this field. The relevant code is available at https://github.com/SUTLZY/IRIS .},
  archive      = {J_PR},
  author       = {Ziyuan Liu and Yan Zhuang and Peng Wu and Yuanchang Liu},
  doi          = {10.1016/j.patcog.2025.112400},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112400},
  shortjournal = {Pattern Recognition},
  title        = {IRIS: An information path planning method based on reinforcement learning and information-directed sampling},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge tailoring: Bridging the teacher-student gap in semantic segmentation. <em>PR</em>, <em>172</em>, 112399. (<a href='https://doi.org/10.1016/j.patcog.2025.112399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation transfers knowledge from a high-capacity teacher network to a compact student network, but a large capacity gap often limits the student’s ability to fully benefit from the teacher’s guidance. In semantic segmentation, another major challenge is the difficulty in predicting accurate object boundaries, as even strong teacher models can produce ambiguous or imprecise outputs. To address both challenges, we present Knowledge Tailoring, a novel distillation framework that adapts the teacher’s knowledge to better match the student’s representational capacity and learning dynamics. Much like a tailor adjusts an oversized suit to fit the wearer’s shape, our method reshapes the teacher’s abundant but misaligned knowledge into a form more suitable for the student. KT introduces feature tailoring, which restructures intermediate features based on channel-wise correlation to narrow the representation gap, and logit tailoring, which improves boundary prediction by refining class-specific logits. The tailoring strategy evolves throughout training, offering guidance that aligns with the student’s progress. Experiments on Cityscapes, Pascal VOC, and ADE20K confirm that KT consistently enhances performance across a variety of architectures including DeepLabV3, PSPNet, and SegFormer. Our code is available for https://github.com/seok-hwa/KT .},
  archive      = {J_PR},
  author       = {Seokhwa Cheung and Seungbeom Woo and Taehoon Kim and Wonjun Hwang},
  doi          = {10.1016/j.patcog.2025.112399},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112399},
  shortjournal = {Pattern Recognition},
  title        = {Knowledge tailoring: Bridging the teacher-student gap in semantic segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Understanding and tackling the modality imbalance problem in multimodal survival prediction. <em>PR</em>, <em>172</em>, 112398. (<a href='https://doi.org/10.1016/j.patcog.2025.112398'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the in-depth integration of multimodal data, survival prediction has emerged as a pivotal task in cancer prognosis by facilitating personalized treatment planning and medical resource allocation. In this study, we report an intriguing phenomenon of inter-modality capability gap (ICG) enlargement during joint survival modelling of genomics data and pathology images. This observation, supported by our dedicated theoretical analysis, uncovers a previously unrecognized modality imbalance problem, where pathology modality suffers from limited gradient propagation and insufficient learning while genomics modality dominates in reducing survival loss. To tackle this problem, we further propose a balanced multimodal learning approach for survival prediction named BMLSurv, which introduces two innovative auxiliary learning strategies: self-enhancement learning (SEL) and peer-assistance learning (PAL). The SEL strategy exploits a real-time imbalance measure to guide extra task-aware supervision, therefore dynamically strengthening pathology-specific gradient propagation in a self-enhanced manner. Meanwhile, the PAL strategy leverages the stronger genomics modality as a “helpful peer” to assist the sufficient learning of pathology modality via a new risk-ranking distillation technique. Extensive experiments on representative cancer datasets demonstrate that by successfully address the modality imbalance problem, BMLSurv remarkably narrows the ICG in joint survival modelling and consistently outperforms state-of-the-art methods by a large margin. These results underscore the potential of BMLSurv to advance multimodal survival prediction and enhance clinical decision-making in cancer prognosis.},
  archive      = {J_PR},
  author       = {Chicheng Zhou and Minghui Wang and Yi Shi and Anli Zhang and Ao Li},
  doi          = {10.1016/j.patcog.2025.112398},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112398},
  shortjournal = {Pattern Recognition},
  title        = {Understanding and tackling the modality imbalance problem in multimodal survival prediction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hyper-network curvature: A new representation method for high-order brain network analysis. <em>PR</em>, <em>172</em>, 112397. (<a href='https://doi.org/10.1016/j.patcog.2025.112397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human brain is a complex system and contains abundant high-order interactions among multiple brain regions, which can be described by brain hyper-network. In brain hyper-networks, nodes represent brain regions of interest (ROIs), while edges describe the interactions of multiple ROIs, providing important high-order information for brain disease analysis and diagnosis. However, most of the existing hyper-network studies focused on the hyper-connection (i.e. hyper-edge) analysis and ignored the local topological information on nodes. To address this problem, we propose a new representation method (i.e., hyper-network curvature) for brain hyper-network analysis. Compared with the existing hyper-network representation methods, the proposed hyper-network curvature can be used to analyze the local topologies of nodes in brain hyper-networks. Based on hyper-network curvature, we further propose a novel graph kernel called brain hyper-network curvature kernel to measure the similarity of a pair of brain hyper-networks. We have proved that the proposed hyper-network curvature is bounded and brain hyper-network curvature kernel is positive definite. To evaluate the effectiveness of our proposed method, we perform the classification experiments on functional magnetic resonance imaging data of brain diseases. The experimental results demonstrate that our proposed method can significantly improve classification accuracy compared to the state-of-the-art graph kernels and graph neural networks for classifying brain diseases.},
  archive      = {J_PR},
  author       = {Kai Ma and Tianyu Du and Qi Zhu and Xuyun Wen and Jiashuang Huang and Xibei Yang and Daoqiang Zhang},
  doi          = {10.1016/j.patcog.2025.112397},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112397},
  shortjournal = {Pattern Recognition},
  title        = {Hyper-network curvature: A new representation method for high-order brain network analysis},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated cross-source learning for lung nodule segmentation with data characteristic-aware weight optimization. <em>PR</em>, <em>172</em>, 112396. (<a href='https://doi.org/10.1016/j.patcog.2025.112396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning enables multiple medical institutions to undertake distributed training while protecting patient privacy. Nevertheless, the significant variance in data distributions across diverse sites results in imbalanced knowledge acquisition, thereby affecting the performance of the global model. To tackle this challenge, we propose a novel federated algorithm for lung nodule segmentation, incorporating a Cross-source Learning (CSL) method. This method generates pseudo nodules by synthesizing the nodule phase spectrum with the nodule amplitude spectrum from other clients. These pseudo nodules are subsequently embedded into pulmonary regions to augment the data. By incorporating knowledge from various clients, which alleviates the challenges posed by non-IID data. On the server side, a Data Characteristic-aware Weight Optimization (DCWO) method is proposed to incorporate client data quality assessment and the size of lung nodule volume as weights to optimize both model performance and fairness. On the client side, we design a Multi-scale Attention Dynamic Convolution (MADC) lightweight network, which dynamically adapts attention to different spatial regions and extracts features at multiple scales. The performance of our method is superior to the state-of-the-art methods on six public and in-house CT datasets of lung cancer.},
  archive      = {J_PR},
  author       = {Xinjun Bian and Huan Lin and Yumeng Wang and Lingqiao Li and Zhenbing Liu and Huadeng Wang and Zhenwei Shi and Yi Qian and Zaiyi Liu and Rushi Lan and Xipeng Pan},
  doi          = {10.1016/j.patcog.2025.112396},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112396},
  shortjournal = {Pattern Recognition},
  title        = {Federated cross-source learning for lung nodule segmentation with data characteristic-aware weight optimization},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Joint luminance-chrominance learning for quality assessment of low-light image enhancement. <em>PR</em>, <em>172</em>, 112395. (<a href='https://doi.org/10.1016/j.patcog.2025.112395'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods for low-light enhancement quality assessment (LEQA) often underperform across diverse scenarios. One reason is that most of them rely on shallow feature respresentations, while another is that deep-learning-based counterparts fail to make full use of the unique characteristics of low-light enhanced images (LEIs), such as luminance enhancement and color refinement. In this paper, we propose a novel Joint Luminance-Chrominance Learning Network (JLCLNet) for LEQA to comprehensively assess the effects of low-light image enhancement (LLIE) algorithms. Specifically, we construct a two-branch network architecture consisting of a luminance learning branch and a chrominance learning branch. In the luminance learning branch, the low- and high-frequency subbands of the luminance channel in the CIELAB color space, derived from the dual-tree complex wavelet transform (DTCWT), focus on measuring contrast enhancement and structure preservation. Meanwhile, the chrominance learning branch addresses potential color distortions by integrating perceptual information from the two parallel chrominance channels of the CIELAB color space. Finally, the complementary features from both branches are fused to predict quality scores. Experimental results on four public LEQA databases demonstrate the performance advantages of the proposed method compared to the state-of-the-art approaches. The source code of JLCLNet is available at https://github.com/li181119/JLCLNET .},
  archive      = {J_PR},
  author       = {Tuxin Guan and Qiuping Jiang and Xiongli Chai and Chaofeng Li},
  doi          = {10.1016/j.patcog.2025.112395},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112395},
  shortjournal = {Pattern Recognition},
  title        = {Joint luminance-chrominance learning for quality assessment of low-light image enhancement},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A graph contrastive learning network for change detection with heterogeneous remote sensing images. <em>PR</em>, <em>172</em>, 112394. (<a href='https://doi.org/10.1016/j.patcog.2025.112394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land cover change detection (LCCD) with heterogeneous remote sensing images (Hete-RSIs) is an attractive topic in the community of remote sensing applications. Intuitively, Hete-RSIs are acquired with different remote sensors, and they cannot be compared directly for LCCD because of the different imaging modalities. In this paper, a graph contrastive learning network (GCLN) is proposed for LCCD with bitemporal Hete-RSIs. First, with the motivation of smoothing the noise and utilizing contextual information, the k-nearest neighbor algorithm is used to improve the spectral homogeneity of the pixels within a superpixel. Then, a pairwise graph is constructed on the basis of each superpixel from spectral similarity and dissimilarity perspectives, and a graph feature learning network is designed to learn the near-far dependencies of graph features for change detection. Finally, the similarity and dissimilarity loss functions are coupled as a contrastive loss function to expand the difference between similar and dissimilar features. Comparisons with seven advanced methods on five pairs of Hete-RSIs demonstrate the feasibility and superiority of the proposed GCLN for LCCD with Hete-RSIs. For example, the improvements on the five datasets are 3.63 % , 8.47 % , 4.17 % , 8.23 % , and 4.98 % in terms of overall accuracy. The code of the proposed approach can be available at: https://github.com/ImgSciGroup/2024-GCLN .},
  archive      = {J_PR},
  author       = {Zhiyong Lv and Sizhe Cheng and Linfu Xie and Junhuai Li and Minghua Zhao},
  doi          = {10.1016/j.patcog.2025.112394},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112394},
  shortjournal = {Pattern Recognition},
  title        = {A graph contrastive learning network for change detection with heterogeneous remote sensing images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Edge craft odyssey: Navigating guided super-resolution with a fast, precise, and lightweight network. <em>PR</em>, <em>172</em>, 112392. (<a href='https://doi.org/10.1016/j.patcog.2025.112392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal imaging technology is exceptionally valuable in environments where visibility is limited or nonexistent. However, the high cost and technological limitations of high-resolution thermal imaging sensors restrict their widespread use. Many thermal cameras are now paired with high-resolution visible cameras, which can help improve low-resolution thermal images. However, aligning thermal and visible images is challenging due to differences in their spectral ranges, making pixel-wise alignment difficult. Therefore, we present the Edge Craft Odyssey Network (ECONet), a lightweight transformer-based network designed for Guided Thermal Super-Resolution (GTSR) to address these challenges. Our approach introduces a Progressive Edge Prediction module that extracts edge features from visible images using an adaptive threshold within our innovative Edge-Weighted Gradient Blending technique. This technique provides precise control over the blending intensity between low-resolution thermal and visible images. Additionally, we introduce a lightweight Cascade Deep Feature Extractor that focuses on efficient feature extraction and edge weight highlighting, enhancing the representation of high-frequency details. Experimental results show that ECONet outperforms state-of-the-art methods across various datasets while maintaining a relatively low computational and memory requirements. ECONet improves performance by up to 0.20 to 1.3 dB over existing methods and generates super-resolved images in a fraction of a second, approximately 91 % faster than the other methods. The code is available at https://github.com/Rm1n90/ECONet .},
  archive      = {J_PR},
  author       = {Armin Mehri and Parichehr Behjati and Dario Carpio and Angel D. Sappa},
  doi          = {10.1016/j.patcog.2025.112392},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112392},
  shortjournal = {Pattern Recognition},
  title        = {Edge craft odyssey: Navigating guided super-resolution with a fast, precise, and lightweight network},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Jailbreak attack with multimodal virtual scenario hypnosis for vision-language models. <em>PR</em>, <em>172</em>, 112391. (<a href='https://doi.org/10.1016/j.patcog.2025.112391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inherent vulnerabilities of large Vision-Language Models (VLMs), security governance has emerged as a critical concern, particularly given the risks posed by noisy and biased training data as well as adversarial attacks, including data poisoning and prompt injection. These perturbations can significantly degrade model performance and introduce multifaceted societal risks. To verify the safe robustness of VLMs and further inspire the design of defensive AI frameworks, we propose Virtual Scenario Hypnosis (VSH), a multimodal prompt injection jailbreak method that embeds malicious queries into prompts through a deceptive narrative framework. This approach strategically distracts the model while compromising its resistance to jailbreak attempts. Our methodology features two key innovations: 1) Targeted adversarial image prompts that transform textual content into visual layouts through optimized typographic designs, circumventing safety alignment mechanisms to elicit harmful responses; and 2) An information veil encrypted In-Context Learning (ICL) method for text prompts that systematically evades safety detection protocols. To streamline evaluation, we employ Large Language Models (LLMs) to facilitate an efficient assessment of jailbreak success rates, supported by a meticulously designed prompt template incorporating multi-dimensional scoring rules and evaluation metrics. Extensive experiments demonstrate the efficacy of VSH, achieving an overall success rate exceeding 82% on 500 harmful queries spanning multiple domains when tested against LLaVA-v1.5-13B and GPT-4o mini.},
  archive      = {J_PR},
  author       = {Xiayang Shi and Shangfeng Chen and Gang Zhang and Wei Wei and Yinlin Li and Zhaoxin Fan and Jingjing Liu},
  doi          = {10.1016/j.patcog.2025.112391},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112391},
  shortjournal = {Pattern Recognition},
  title        = {Jailbreak attack with multimodal virtual scenario hypnosis for vision-language models},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A locality-sensitive hashing based instance selection method with its application to acceleration of feature selection. <em>PR</em>, <em>172</em>, 112390. (<a href='https://doi.org/10.1016/j.patcog.2025.112390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of important data preprocessing techniques, feature selection aims to remove redundant and irrelevant features and has been extensively applied to many fields. At present, however, the evaluation of existing feature selection algorithms focuses mainly on the scale of the selected features and the performance of models formulated by the selected features, while the running time of feature selection algorithms is usually neglected. It is noted that the computation complexity of the majority of feature selection algorithms is the square order of the number of instances, resulting in an exponential increase of the running time for large-scale data. In this paper, we propose an algorithm of core instance selection based on the locality-sensitive hashing (CISLSH) to improve the computation efficiency of feature selection algorithms by alleviating the instances used for feature selection. Specifically, all the instances are firstly considered to map them into the one-dimensional integer space using a locality-sensitive hashing (LSH) function. Given a set of hash functions families, a bucket index matrix is constructed to integrate all the mapping results of the set of hash functions families. Then, a voting mechanism is designed according to the bucket index matrix, which motivates to present a novel data partitioning method dividing similar instances into the same bucket (partition) as many as possible. Furthermore, the CISLSH algorithm is developed by selecting a core instance from each non-empty bucket. Finally, numerical experiments are conducted to assess the performance of CISLSH. The experimental results show that the execution of feature selection using the representative instances selected by CISLSH can not only significantly reduce the running time of feature selection but also guarantee the effectiveness of the selected features.},
  archive      = {J_PR},
  author       = {Fan Song and Xiao Zhang and Jinhai Li and Changlin Mei},
  doi          = {10.1016/j.patcog.2025.112390},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112390},
  shortjournal = {Pattern Recognition},
  title        = {A locality-sensitive hashing based instance selection method with its application to acceleration of feature selection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive latent disease state learning for multimodal alzheimer’s disease biomarker detection with missing modalities. <em>PR</em>, <em>172</em>, 112389. (<a href='https://doi.org/10.1016/j.patcog.2025.112389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal neuroimaging genetics is a crucial approach for identifying biomarkers of Alzheimer’s disease (AD) by leveraging the inherent relationships between genetic and neuroimaging data. However, existing methods are limited by susceptibility to input noises, underutilization of complementary information across neuroimaging modalities, and ineffective handling of samples with incomplete modalities. To address these challenges, we propose an Adaptive Latent Disease State Learning (ALDSL) method, which integrates noise reduction, latent space learning, adaptive regularization, and feature selection into a unified framework for detecting AD biomarkers from incomplete multimodal data. ALDSL introduces a noise reduction strategy based on inter-variable correlations and tailored distance metrics to eliminate noises in the input data, thereby obtaining high-quality representations for each modality. Additionally, latent disease state learning with adaptive regularization is proposed to capture inter-modality correlations by projecting the high-quality representations from multiple modalities into a common latent space. To utilize samples with incomplete modalities, we design a modality-specific weight matrix that accounts for the missing information in the latent disease state learning. Furthermore, an adaptive weighting determination strategy is developed to ensure that the modalities with different data types and varying sample sizes contribute on the same scale. We develop an efficient alternating optimization algorithm to solve the objective function of ALDSL. Experimental results on synthetic datasets and the ADNI GO/2 dataset demonstrate the effectiveness of ALDSL in detecting AD biomarkers.},
  archive      = {J_PR},
  author       = {Zhi Chen and Fengli Zhang and Yun Zhang and Jiajing Zhu and Qiaoqin Li and Yongguo Liu},
  doi          = {10.1016/j.patcog.2025.112389},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112389},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive latent disease state learning for multimodal alzheimer’s disease biomarker detection with missing modalities},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MMP: Enhancing unsupervised graph anomaly detection with multi-view message passing. <em>PR</em>, <em>172</em>, 112388. (<a href='https://doi.org/10.1016/j.patcog.2025.112388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complementary and conflicting relationships between views are two fundamental issues when applying Graph Neural Networks (GNNs) to multi-view attributed graph anomaly detection. Most existing approaches do not address the inherent multi-view properties in the attribute space or leverage complementary information through simple representation fusion, which overlooks the conflicting information among different views. In this paper, we argue that effectively applying GNNs to multi-view anomaly detection necessitates reinforcing complementary information between views and, more importantly, managing conflicting information. Building on this perspective, this paper introduces Multi-View Message Passing (MMP), a novel and effective message passing paradigm specifically designed for multi-view anomaly detection. In the multi-view aggregation phase of MMP, views containing different types of information are integrated using view-specific aggregation functions. This approach enables the model to dynamically adjust the amount of information aggregated from complementary and conflicting views, thereby mitigating issues arising from insufficient complementary information and excessive conflicting information, which can lead to suboptimal representation learning. Furthermore, we propose an innovative aggregation loss mechanism that enhances model performance by optimizing the reconstruction differences between aggregated representations and the original views, thereby improving both detection accuracy and model interpretability. Extensive experiments on synthetic and real-world datasets validate the effectiveness and robustness of our method. The source code is available at https://github.com/weihus/MMP .},
  archive      = {J_PR},
  author       = {Weihu Song and Lei Li and Mengxiao Zhu and Yue Pei and Haogang Zhu},
  doi          = {10.1016/j.patcog.2025.112388},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112388},
  shortjournal = {Pattern Recognition},
  title        = {MMP: Enhancing unsupervised graph anomaly detection with multi-view message passing},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HopGAT: A multi-hop graph attention network with heterophily and degree awareness. <em>PR</em>, <em>172</em>, 112387. (<a href='https://doi.org/10.1016/j.patcog.2025.112387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In highly heterophilic graphs, where nodes frequently connect across categories, the attention learning mechanism by dynamically adjusting neighboring node weights, may struggle to capture intricate node relationships. Furthermore, first-hop neighbor information is usually insufficient to encompass the global structure, but multi-hop increases complexity. To address these challenges, we propose HopGAT, a multi-hop graph attention network with heterophily and degree awareness. Firstly, we design heterophily-based neighbor sampling to sequentially filter high-hop neighbors by degree. Next, to obtain comprehensive global information, we construct a multi-hop recursive learning method with head and tail attention vectors to learn multi-hop neighbor features. Finally, we combine the average node degree of the graph with hop decay modeling to learn importance coefficients at different hops and adaptively aggregate the learned multi-hop features. Experimental results demonstrate that HopGAT significantly improves performance across 9 benchmark datasets with various heterophily and different average degrees.},
  archive      = {J_PR},
  author       = {Han Zhang and Huan Wang and Mingjing Han},
  doi          = {10.1016/j.patcog.2025.112387},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112387},
  shortjournal = {Pattern Recognition},
  title        = {HopGAT: A multi-hop graph attention network with heterophily and degree awareness},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A boundary-enhanced and target-driven deformable convolutional network for abdominal multi-organ segmentation. <em>PR</em>, <em>172</em>, 112386. (<a href='https://doi.org/10.1016/j.patcog.2025.112386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is crucial to accurately segment organs from abdominal CT images for clinical diagnosis, treatment planning, and surgical guidance, which remains an extremely challenging task due to low contrast between organs and surrounding tissues and the difference of organ size and shape. Previous works mainly focused on complex network architectures or task-specific modules but frequently failed to learn irregular boundaries and did not consider that different slices from the same case might contain targets of different numbers of categories. To tackle these issues, this paper proposes UAMSNet for abdominal multi-organ segmentation. In UAMSNet, a hybrid receptive field extraction (HRFE) module is introduced to adaptively learn the features of irregular targets, which has an adaptive dilation factor containing distance information to facilitate spatial and channel attention. The HRFE module can simultaneously learn multiple scales and deformations of different organs. Furthermore, a multi-organ boundary-enhanced attention (MBA) module in the encoder and decoder is designed to provide effective boundary information for feature extraction based on the large peak of the organ edge. Finally, the difference in the number of organ categories between different slices is first considered using a loss function, which can adjust the loss computation based on organ categories in the image. The loss function mitigates the effect of false positives during training to ensure the model can adapt to small organ segmentation. Experimental results on WORD and Synapse datasets demonstrate that our UAMSNet outperforms the existing state-of-the-art methods. Ablation experiments confirm the effectiveness of our designed modules and loss function. Our code is publicly available on https://github.com/HeyJGJu/UAMSNet .},
  archive      = {J_PR},
  author       = {Jianguo Ju and Menghao Liu and Wenhuan Song and Tongtong Zhang and Jindong Liu and Pengfei Xu and Ziyu Guan},
  doi          = {10.1016/j.patcog.2025.112386},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112386},
  shortjournal = {Pattern Recognition},
  title        = {A boundary-enhanced and target-driven deformable convolutional network for abdominal multi-organ segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distantly supervised reinforcement localization for real-world object distribution estimation. <em>PR</em>, <em>172</em>, 112385. (<a href='https://doi.org/10.1016/j.patcog.2025.112385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the distribution of objects in the real world from monocular images is a challenging task due to the disparity between object distributions in perspective images and reality. Many researchers focus on predicting object distributions by converting perspective images into Bird’s-Eye View (BEV) images. In scenarios where camera parameter information is unavailable, the prediction of vanishing lines becomes critical for performing inverse perspective transformations. However, accurately predicting vanishing lines necessitates accounting for variations in object size, which cannot be effectively captured through simple regression models. Therefore, this paper proposes a size variation-aware method, utilizing expert knowledge from object detection to build a reinforcement learning framework for predicting vanishing lines in traffic scenes. Specifically, this method leverages size information from trained detectors to convert perspective images into BEV images without the need for additional camera intrinsic parameters. First, we design a novel reward mechanism that utilizes prior knowledge of scale differences between similar objects in perspective images, allowing the network to automatically update and learn specific vanishing line positions. Second, we propose a fast inverse perspective transformation method, which accelerates the training speed of the proposed approach. To evaluate the effectiveness of the method, experiments are conducted on two traffic flow datasets. The experimental results demonstrate that the proposed algorithm accurately predicts vanishing line positions and successfully transforms perspective images into BEV images. Furthermore, the proposed algorithm performs competitively with directly supervised methods. The code is available at: https://github.com/HotChieh/DDRL.},
  archive      = {J_PR},
  author       = {Haojie Guo and Junyu Gao and Yuan Yuan},
  doi          = {10.1016/j.patcog.2025.112385},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112385},
  shortjournal = {Pattern Recognition},
  title        = {Distantly supervised reinforcement localization for real-world object distribution estimation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A variable gaussian kernel scale active contour model based on jeffreys divergence for ICT image segmentation. <em>PR</em>, <em>172</em>, 112384. (<a href='https://doi.org/10.1016/j.patcog.2025.112384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial computed tomography (ICT), factors like beam scattering, insufficient beam intensity, and detector dark current often lead to weak edges, scattering artifacts, and severe Gaussian noise in ICT images. These issues pose significant difficulties for accurate segmentation of high-density complex structures using existing active contour models (ACMs). To address these limitations, this paper presents a variable Gaussian kernel scale active contour model based on Jeffreys divergence (VGJD). Firstly, the Jeffreys divergence (JD) is incorporated into the energy function to replace the conventional Euclidean distance, enhancing the contour’s ability to quantify pixel value disparity during evolution. Additionally, a filter weight is introduced to minimize the impact of noise. Moreover, a variable Gaussian kernel scale strategy is adopted to effectively integrate both global and local image information, thereby enhancing the robustness of the initial contour and improving the precision of detail segmentation. Finally, optimized length and regularity terms are employed to enforce constraints on the level set function. Extensive experimental results demonstrate that the VGJD model can effectively segment various complex ICT images, achieving superior precision in comparison to other ACM models. The code is available at https://github.com/LiuZX599/ACM-VGJD.git},
  archive      = {J_PR},
  author       = {Zexin Liu and Qi Li and Junyao Wang and Tingyuan Deng and Rifeng Zhou and Yufang Cai and Fenglin Liu},
  doi          = {10.1016/j.patcog.2025.112384},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112384},
  shortjournal = {Pattern Recognition},
  title        = {A variable gaussian kernel scale active contour model based on jeffreys divergence for ICT image segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust spatio-temporal graph neural networks with sparse structure learning. <em>PR</em>, <em>172</em>, 112383. (<a href='https://doi.org/10.1016/j.patcog.2025.112383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of spatio-temporal graph classification by introducing sparse structure learning to enhance its robustness and explainability. Spatio-temporal graph neural networks (STGNN) integrate spatial structure and temporal sequential features into GNN learning, resulting in promising performance in many applications. However, current STGNN models often fail to capture the discriminative sparse substructure and the smooth distribution of these samples. To this end, this paper introduces RostGNN, robust spatio-temporal graph neural networks, for achieving more discriminative graph representations. Concretely, RostGNN extracts the spatial and temporal features by performing gated recurrent units on the given time series data and calculating adjacent matrixes for graphs. Then, we impose the iterative hard-thresholding approach on the final association matrix to obtain a sparse graph. Meanwhile, we calculate a similarity matrix from the side information of samples to smooth the achieved data representations and use fully connected networks for graph classification. We finally applied RostGNN to brain graph classification in experiments on real-world datasets. The results demonstrate that RostGNN delivers robust and discriminative graph representations and performs better than compared methods, benefiting from the sparsity and manifold regularizers. Furthermore, RostGNN can potentially yield useful findings for data understanding.},
  archive      = {J_PR},
  author       = {Yupei Zhang and Yuxin Li and Shuhui Liu and Xuequn Shang},
  doi          = {10.1016/j.patcog.2025.112383},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112383},
  shortjournal = {Pattern Recognition},
  title        = {Robust spatio-temporal graph neural networks with sparse structure learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DiscDC: Unsupervised discriminative deep image clustering via confidence-driven self-labeling. <em>PR</em>, <em>172</em>, 112382. (<a href='https://doi.org/10.1016/j.patcog.2025.112382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep clustering, as an important research topic in machine learning and data mining, has been widely applied in many real-world scenarios. However, existing deep clustering methods primarily rely on implicit optimization objectives such as contrastive learning or reconstruction, which do not explicitly enforce cluster-level discrimination. This limitation restricts their ability to achieve compact intra-cluster structures and distinct inter-cluster separations. To overcome this limitation, we propose a novel unsupervised discriminative deep clustering (discDC) method, which explicitly integrates cluster-level discrimination into the learning process. The proposed discDC framework projects data into a nonlinear latent space with compact and well-separated cluster representations. It explicitly optimizes clustering objectives by minimizing intra-cluster discrepancy and maximizing inter-cluster discrepancy. Additionally, to tackle the lack of label information in unsupervised scenarios, we introduce a confidence-driven self-labeling mechanism, which iteratively derives reliable pseudo-labels to enhance discriminative analysis. Extensive experiments on five benchmark datasets demonstrate the superiority of discDC over state-of-the-art deep clustering approaches.},
  archive      = {J_PR},
  author       = {Jinyu Cai and Wenzhong Guo and Yunhe Zhang and Jicong Fan},
  doi          = {10.1016/j.patcog.2025.112382},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112382},
  shortjournal = {Pattern Recognition},
  title        = {DiscDC: Unsupervised discriminative deep image clustering via confidence-driven self-labeling},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MCoCa: Towards fine-grained multimodal control in image captioning. <em>PR</em>, <em>172</em>, 112381. (<a href='https://doi.org/10.1016/j.patcog.2025.112381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controllable image captioning (CIC) models have traditionally focused on generating controlled descriptions using specific text styles. However, these approaches are limited as they rely solely on text control signals, which often fail to align with complex human intentions, such as selecting specific areas in images. To enhance multimodal interactivity, we propose to augment current CIC systems with diverse and joint visual-text controls. To achieve this, we first create a comprehensive Multimodal Controllable Image Captioning Corpus (MCoCa) dataset by leveraging language rewriting ability of GPT-3.5, containing 0.97M image-captions pairs along with 21 visual-text control signals. By training the visual and textual adapters equipped on the multimodal large language model with newly proposed instructional prompts on MCoCa, we observe emergent combinatory multimodal controllability and significant improvement in text controllability. We present exhaustive quantitative and qualitative results, benchmarking our trained model’s state-of-the-art zero-shot captioning performance on SentiCap and FlickrStyle10K in terms of both fidelity and controllability. For regional understanding ability of visual-controlled captioning, our method achieves obvious improvement compared with the baseline models.},
  archive      = {J_PR},
  author       = {Shanshan Zhao and Teng Wang and Jinrui Zhang and Xiangchen Wang and Feng Zheng},
  doi          = {10.1016/j.patcog.2025.112381},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112381},
  shortjournal = {Pattern Recognition},
  title        = {MCoCa: Towards fine-grained multimodal control in image captioning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning interpretable binary codes via semantic alignment for customized image retrieval. <em>PR</em>, <em>172</em>, 112380. (<a href='https://doi.org/10.1016/j.patcog.2025.112380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single modality hashing (SMH) has achieved impressive performance on image retrieval task in recent years. The only fly in the ointment is that most of the methods mainly measure the image similarity based on the high-level class labels. The retrieval needs in the real world are diverse in form of different subsets of the semantics (not only the category labels) presented in the query image. However, existing SMH methods fail to account for such customized image retrieval task that allows users to select visual semantics or their combinations present in the query and retrieve similar images based on such selected semantic descriptions. To address such practical issues, we propose a deep hashing to learn Interpretable Binary Codes (IBC), endowing the hashing bits with semantic interpretability rather than purely entangling the class information in the whole codes, i.e., aligning the criteria of binary space partition of each bit with a particular visual semantic concept. Specifically, binary encoding is a highly non-linear operation of dimension reduction, the semantic and spatial information of which has respectively been abstract and lost heavily. In light of the rich semantic interpretability and binary concept detection ability of convolutional filters, we innovatively transfer the semantic knowledge from filters to hashing bits by align the distributions of the binary codes and filter activations that capture the presence/absence of visual patterns in images. To further improve the semantics of filters/bits, the shared and learnable classification rules are introduced and optimized to disentangle the sparse composition between the category label and encoded semantics in filters/bits. With high interpretability, we can selectively combine bits corresponding to the target semantics during retrieval, thereby enabling flexible and customized similarity searches. Extensive experiments on several large-scale datasets covering general objects and scenes, single and multiple label scenarios, demonstrate the interpretability and functionalities of learned binary codes for the customized image retrieval tasks.},
  archive      = {J_PR},
  author       = {Shishi Qiao and Ruiping Wang and Xilin Chen},
  doi          = {10.1016/j.patcog.2025.112380},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112380},
  shortjournal = {Pattern Recognition},
  title        = {Learning interpretable binary codes via semantic alignment for customized image retrieval},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AFFusion: Atmospheric scattering enhancement and frequency integrated spatial-channel attention for infrared and visible image fusion. <em>PR</em>, <em>172</em>, 112379. (<a href='https://doi.org/10.1016/j.patcog.2025.112379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion (IVIF) seeks to generate fused images that combine rich texture details with distinct thermal radiation features by integrating and leveraging complementary information from multiple sources. However, existing fusion methods frequently neglect the challenges posed by illumination degradation and inaccurate color contrast, which arise due to light energy loss and light scattering during atmospheric transmission. To address these limitations, this study introduces an innovative IVIF framework, termed AFFusion, which integrates an atmospheric scattering physical model with a frequency-domain feature component. By accurately predicting and estimating two key physical parameters-the transmission map and atmospheric light-within the scattering model, AFFusion harnesses atmospheric scattering principles to produce enhanced visible images, thereby mitigating the adverse effects of energy attenuation and scattering. Furthermore, to resolve artifacts and texture loss caused by traditional atmospheric scattering models, AFFusion incorporates Fourier transform in conjunction with spatial and channel attention mechanisms to selectively amplify amplitude and phase features in the frequency domain, thereby enhancing texture fidelity and detail representation within the fused images. Comprehensive experimental evaluations demonstrate that AFFusion surpasses state-of-the-art methods in both qualitative and quantitative performance metrics, while also providing robust support for high-level visual tasks. The implementation code is publicly accessible at https://github.com/cici0206/AFFusion .},
  archive      = {J_PR},
  author       = {Jiwei Hu and Chengcheng Song and Qiwen Jin and Kin-Man Lam},
  doi          = {10.1016/j.patcog.2025.112379},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112379},
  shortjournal = {Pattern Recognition},
  title        = {AFFusion: Atmospheric scattering enhancement and frequency integrated spatial-channel attention for infrared and visible image fusion},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Vision-by-prompt: Context-aware dual prompts for composed video retrieval. <em>PR</em>, <em>172</em>, 112378. (<a href='https://doi.org/10.1016/j.patcog.2025.112378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Composed video retrieval (CoVR) is a challenging task of retrieving relevant videos in a corpus by using a query that integrates both a relative change text and a reference video. Most existing CoVR models simply rely on the late-fusion strategy to combine visual and change text. Furthermore, various methods have been proposed to generate pseudo-word tokens from the reference video, which are then integrated into the relative change text for CoVR. However, these pseudo-word-based techniques exhibit limitations when the target video involves complex changes from the reference video, e.g. , object removal. In this work, we propose a novel CoVR framework that learns context information via context-aware dual prompts for relative change text to achieve effective composed video retrieval. The dual prompts cater to two aspects: 1) Global descriptive prompts generated from the pretrained V-L models, e.g. , BLIP-2, to get concise textual representations of the reference video. 2) Local target prompts to learn the target representations that the change text pays attention to. By connecting these prompts with relative change text, one can easily use existing text-to-video retrieval models to enhance CoVR performance. Our proposed framework can be flexibly used for both composed video retrieval (CoVR) and composed image retrieval (CoIR) tasks. Moreover, we take a pioneering approach by adopting the CoVR model to achieve zero-shot CoIR for remote sensing. Experiments on four datasets show that our approach achieves state-of-the-art performance in both CoVR and zero-shot CoIR tasks, with improvements of as high as around 3.5 % in terms of recall@K=1 score.},
  archive      = {J_PR},
  author       = {Hao Wang and Fang Liu and Licheng Jiao and Jiahao Wang and Shuo Li and Lingling Li and Puhua Chen and Xu Liu},
  doi          = {10.1016/j.patcog.2025.112378},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112378},
  shortjournal = {Pattern Recognition},
  title        = {Vision-by-prompt: Context-aware dual prompts for composed video retrieval},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient and compact tensor wheel decomposition for tensor completion. <em>PR</em>, <em>172</em>, 112377. (<a href='https://doi.org/10.1016/j.patcog.2025.112377'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor wheel (TW) decomposition has recently emerged as a powerful technique for achieving state-of-the-art recovery performance in tensor completion tasks. However, its widespread application has been hindered by issues related to rank sensitivity and high computational cost. To address these limitations, we introduce an efficient and compact TW decomposition method for low-rank tensor completion. Specifically, we demonstrate that the model complexity of TW decomposition is controlled simultaneously by two elements, namely, the explicit TW rank and implicit sparsity in the core tensor. Therefore, low-rank and sparsity regularization are introduced to ring factors and core factor, respectively, to achieve a compact TW decomposition. Furthermore, to alleviate the computational bottleneck of TW decomposition, we propose a novel generalized inverse operation, which reduces the computational complexity of vanilla TW decomposition from O ( I N R 2 N ) to O ( I N R N ) . Subsequently, we develop an efficient alternating direction method of multipliers (ADMM) algorithm with theoretical convergence guarantees. Numerical tensor completion experiments on color images, multispectral images, and color videos demonstrate that the proposed method achieves superior performance while significantly reducing runtime compared to state-of-the-art methods. The code is available at: https://github.com/justicbro/TWLRS .},
  archive      = {J_PR},
  author       = {Peilin Yang and Yuning Qiu and Zhenhao Huang and Guoxu Zhou and Qibin Zhao},
  doi          = {10.1016/j.patcog.2025.112377},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112377},
  shortjournal = {Pattern Recognition},
  title        = {Efficient and compact tensor wheel decomposition for tensor completion},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning to complement with multiple humans. <em>PR</em>, <em>172</em>, 112376. (<a href='https://doi.org/10.1016/j.patcog.2025.112376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solution for addressing real-world image classification challenges. Human-AI collaborative classification (HAI-CC) aims to synergise the efficiency of machine learning classifiers and the reliability of human experts to support decision making. Learning to defer (L2D) has been one of the promising HAI-CC approaches, where the system assesses a sample and decides to defer to one of human experts when it is not confident. Despite recent progress, existing L2D methods rely on the strong assumption of ground truth label availability for training, while in practice, most datasets often contain multiple noisy annotations per data sample without well-curated ground truth labels. In addition, current L2D methods either consider the setting of a single human expert or defer the decision to one human expert, even though there may be multiple experts available, resulting in a suboptimal utilisation of available resources. Furthermore, current HAI-CC evaluation frameworks often overlook processing costs, making it difficult to assess the trade-off between computational efficiency and performance when benchmarking different methods. To address these gaps, this paper introduces LECOMH – a new HAI-CC method that learns from noisy labels without depending on clean labels for training, simultaneously maximising collaborative accuracy with either one or multiple human experts, while minimising the cost of human collaboration. The paper also introduces benchmarks featuring multiple noisy labels per data sample for both training and testing to evaluate HAI-CC methods. Through quantitative comparisons on these benchmarks, LECOMH consistently outperforms HAI-CC methods and baselines, including human experts alone, multi-rater learning and noisy-label learning methods across both synthetic and real-world datasets.},
  archive      = {J_PR},
  author       = {Zheng Zhang and Cuong Nguyen and Kevin Wells and Thanh-Toan Do and Gustavo Carneiro},
  doi          = {10.1016/j.patcog.2025.112376},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112376},
  shortjournal = {Pattern Recognition},
  title        = {Learning to complement with multiple humans},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Noise-aware state-space method for underwater object detection. <em>PR</em>, <em>172</em>, 112375. (<a href='https://doi.org/10.1016/j.patcog.2025.112375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater Object Detection (UOD) faces significant challenges due to complex degradation factors, such as color shifts caused by light absorption and scattering, spatially varying noise induced by plankton and sea snow, and motion blur resulting from dynamic water currents. Among existing methods, Convolutional Neural Networks (CNNs) are limited by fixed receptive fields, making it difficult to model long-range noise patterns; while Transformers excel at modeling global dependencies, they suffer from high computational complexity and weak capability in restoring fine-grained local features. Neither can effectively address the demands of detecting underwater-specific noise and small objects. To tackle these issues, we propose UOD-Mamba, a state space model (SSM)-based framework for underwater object detection. At its core is the Noise-Aware Dual-path Mamba (NADM) module, which integrates a global-local dual-path fusion strategy to enable both long-range noise modeling and local feature enhancement. The global path balances noise in input features through the Noise-Balanced Preprocessing Module (NBPM) and leverages Mamba’s long-range modeling capability to extract global noise patterns; the local path fuses the Underwater Enhanced Multi-scale Attention Module (UEMA) with CSP convolution to model edge and detail features at a fine-grained level, thereby compensating for the loss of local information. By explicitly learning the distribution characteristics of underwater noise and capturing the differences between noise and target features, the framework enhances detection robustness in noisy environments. Experimental validation on the DUO and RUOD datasets demonstrates that UOD-Mamba sets a new state-of-the-art in detection performance. It also exhibits advantages in explicit modeling of diverse noises, preservation of local details, and computational efficiency across multi-noise scenarios, enabling effective handling of complex underwater interference environments.},
  archive      = {J_PR},
  author       = {Jingchun Zhou and Xudong Wang and Mingjie Li and Zongxin He and Wentian Xin and Xiuguo Zhang},
  doi          = {10.1016/j.patcog.2025.112375},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112375},
  shortjournal = {Pattern Recognition},
  title        = {Noise-aware state-space method for underwater object detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-domain-aware deep unfolding transformer for hyperspectral image super-resolution. <em>PR</em>, <em>172</em>, 112374. (<a href='https://doi.org/10.1016/j.patcog.2025.112374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fusing low-spatial-resolution hyperspectral images with high-spatial-resolution (HSR) multispectral images is pivotal for generating HSR hyperspectral images (HSR-HSIs). While current deep unrolling-based multi-stage frameworks have shown notable advancements due to their robustness and interpretability, they still exhibit limitations in adequately harnessing the HSI prior knowledge. This deficiency is principally attributed to three factors: (1) prior knowledge learned from training samples often overlooks target-specific characteristics; (2) insufficient feature representation within and across stages; and (3) insufficient modeling of spatial–spectral dependencies. To address these issues, we propose a novel Cross-domain-aware Transformer (CaFormer). Specifically, a cross-domain aware attention mechanism is investigated to capture intrinsic joint spatial–spectral dependencies through unified cross-domain feature representation. The attention mechanism models HSI eigenfeatures to derive spatial and spectral representations while preserving their mutual correlations. Furthermore, we introduce a Fourier Domain Perception Block to enhance structural and semantic representations by exploiting amplitude and phase components in the frequency domain, thereby strengthening feature aggregation across stages. To further improve adaptability while preserving the interpretability of deep unrolling networks, CaFormer employs a dual-stage prior learning strategy, transferring prior knowledge learned from general training data to the specific observed scene. Our experimental evaluations on four public datasets and Worldview-2 satellite images confirm that our proposed method outperformed eleven state-of-the-art methods. The code is available at https://github.com/Caoxuheng/HIFtool .},
  archive      = {J_PR},
  author       = {Xuheng Cao and Xuquan Wang and Xiong Dun and Yusheng Lian and Xinbin Cheng and Xiaopeng Hao},
  doi          = {10.1016/j.patcog.2025.112374},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112374},
  shortjournal = {Pattern Recognition},
  title        = {Cross-domain-aware deep unfolding transformer for hyperspectral image super-resolution},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-teacher self-distillation registration for multi-modality medical image fusion. <em>PR</em>, <em>172</em>, 112373. (<a href='https://doi.org/10.1016/j.patcog.2025.112373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Misaligned multimodal medical images pose challenges to the fusion task, resulting in structural distortions and edge artifacts in the fusion results. Existing registration networks primarily consider single-scale deformation fields at each stage, thereby neglecting long-range connections between non-adjacent stages. Moreover, in the fusion task, due to the quadratic computational complexity faced by Transformers during feature extraction, they are unable to effectively capture long-range correlated features. To address these problems, we propose an image registration and fusion method called DTMFusion. DTMFusion comprises two main networks: a Dual-Teacher Self-Distillation Registration (DTSDR) network and a Mamba-Conv-based Fusion (MCF) network. The registration network employs a pyramid progressive architecture to generate independent deformation fields at each layer. We introduce a dual-teacher self-distillation scheme that leverages past learning history and the current network structure as teacher guidance to constrain the generated deformation fields. For the fusion network, we introduced Mamba to address the quadratic complexity problem of Transformers. Specifically, the fusion network involves two key components: the Shallow Fusion Module (SFM) and the Cross-Modality Fusion Module (CFM). The SFM achieves lightweight cross-modality interaction through channel exchange, while the CFM leverages inherent cross-modality relationships to enhance the representation capability of fusion results. Through the collaborative effort of these components, the network can effectively integrate cross-modality complementary information and maintain appropriate apparent strength from a global perspective. Extensive experimental analysis demonstrates the superiority of this method in fusing misaligned medical images.},
  archive      = {J_PR},
  author       = {Aimei Dong and Jingyuan Xu and Long Wang},
  doi          = {10.1016/j.patcog.2025.112373},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112373},
  shortjournal = {Pattern Recognition},
  title        = {Dual-teacher self-distillation registration for multi-modality medical image fusion},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FSF-net: Enhance 4D occupancy forecasting with coarse BEV scene flow for autonomous driving. <em>PR</em>, <em>172</em>, 112372. (<a href='https://doi.org/10.1016/j.patcog.2025.112372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {4D occupancy forecasting is one of the important techniques for autonomous driving, which can avoid potential risk in the complex traffic scenes. Scene flow is a crucial element to describe 4D occupancy map tendency. However, an accurate scene flow is difficult to predict in the real scene. In this paper, we find that BEV scene flow can approximately represent 3D scene flow in most traffic scenes. And coarse BEV scene flow is easy to generate. Under this thought, we propose 4D occupancy forecasting method FSF-Net based on coarse BEV scene flow. At first, we develop a general occupancy forecasting architecture based on coarse BEV scene flow. Then, to further enhance 4D occupancy feature representation ability, we propose a vector quantized based Mamba (VQ-Mamba) network to mine spatial-temporal structural scene feature. After that, to effectively fuse coarse occupancy maps forecasted from BEV scene flow and latent features, we design a U-Net based quality fusion (UQF) network to generate the fine-grained forecasting result. Extensive experiments are conducted on public Occ3D dataset. FSF-Net has achieved IoU and mIoU 9.56 % and 10.87 % higher than state-of-the-art method. Hence, we believe that proposed FSF-Net benefits to the safety of autonomous driving.},
  archive      = {J_PR},
  author       = {Erxin Guo and Pei An and You Yang and Qiong Liu and An-An Liu},
  doi          = {10.1016/j.patcog.2025.112372},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112372},
  shortjournal = {Pattern Recognition},
  title        = {FSF-net: Enhance 4D occupancy forecasting with coarse BEV scene flow for autonomous driving},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel image enhancement method based on image decomposition and deep neural networks. <em>PR</em>, <em>172</em>, 112371. (<a href='https://doi.org/10.1016/j.patcog.2025.112371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image decomposition and deep learning are active research areas in computer vision tasks, such as cartoon texture decomposition, low-light image enhancement, rain streak removal, image recovery, etc. This paper proposes a novel low-light image enhancement method by joining image decomposition and deep neural network techniques. We introduce a new image decomposition-based optimization model by incorporating the Tikhonov regularization and multi-scale convolutional sparse coding (MSCSC) to enhance image visual effects. To enhance robustness performance, we introduce a noise-free image decomposition error term to effectively suppress noise in low-light images. To effectively implement the proposed method, we incorporate a deep-unfolding neural network and an adaptive denoiser into the alternating direction method of multipliers (ADMM) framework. Since the deep unfolding network can effectively simulate the optimization algorithm process, the interpretability of the network model is increased. Moreover, through end-to-end training, we can automatically estimate the two priors and parameter settings from training samples. Finally, qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art image enhancement methods in terms of visual quality and robustness. The source code is available at https://github.com/cassiopeia-yxx/LLIE .},
  archive      = {J_PR},
  author       = {Yao Xiao and Youshen Xia},
  doi          = {10.1016/j.patcog.2025.112371},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112371},
  shortjournal = {Pattern Recognition},
  title        = {A novel image enhancement method based on image decomposition and deep neural networks},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nonuniform low-light image enhancement via noise-aware decomposition and adaptive correction. <em>PR</em>, <em>172</em>, 112370. (<a href='https://doi.org/10.1016/j.patcog.2025.112370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured under low-illumination conditions often exhibit low brightness with nonuniform distribution, low contrast, and noise, negatively affecting the human visual experience and the accuracy of image-based computer vision tasks. Enhancing nonuniform low-light images is challenging considering the requirement of simultaneously reducing noise, enhancing low-light regions, and suppressing high-light regions. To address these challenges, we innovatively propose a noise-aware decomposition and adaptive correction method (NDAC) to enhance the nonuniform low-light images without the need for paired high-quality training data. Specifically, a noise-aware image decomposition network (NIDNet) is first presented to decompose the input images into illumination, reflection, and noise components, while suppressing the noise in the reflection component through a variable gradient operator and estimating the noise component. Besides, we devise a novel nonlinear adaptive brightness mapping function (NABM), whose parameters are optimized via a designed automatic light enhancement network (ALENet) to brighten the illumination component. The enhancements are obtained by fusing the noiseless reflection component with the brightened illumination component. Extensive experiments on both public and industrial datasets demonstrate that the proposed NDAC method outperforms state-of-the-art approaches in both qualitative and quantitative evaluations.},
  archive      = {J_PR},
  author       = {Jiancai Huang and Zhaohui Jiang and Xingjian Liu and Yap-Peng Tan and Weihua Gui},
  doi          = {10.1016/j.patcog.2025.112370},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112370},
  shortjournal = {Pattern Recognition},
  title        = {Nonuniform low-light image enhancement via noise-aware decomposition and adaptive correction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fourier-enhanced semi-supervised proxy learning for ultra-fine-grained novel class discovery. <em>PR</em>, <em>172</em>, 112369. (<a href='https://doi.org/10.1016/j.patcog.2025.112369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operating in open-world environments requires recognizing known categories and discovering new ones, especially in ultra-fine-grained task, where distinguishing similar categories is challenging. The task of Ultra-Fine-Grained Novel Class Discovery (UFG-NCD) intensifies this challenge by requiring systems to identify previously unseen classes within unlabeled data. However, existing UFG-NCD methods fall short in extracting critical visual cues and efficiently transferring knowledge from known to novel categories. To overcome these limitations, this paper proposes Fourier-Enhanced Semi-supervised Proxy Learning (FESPL), a novel framework for UFG-NCD. FESPL incorporates a Fourier amplitude guided block that leverages frequency domain analysis to capture high-frequency details often missed by traditional approaches, enhancing ultra-fine-grained discrimination. Additionally, the semi-supervised proxy learning strategy maximizes information extraction from limited labeled data and promotes robust generalization across known and unseen categories. Our approach achieves substantial improvements in both novel category discovery and known category classification on seven popular UFG-NCD datasets, with average performance gains of 10.41 % in the accuracy of the old class and 4.27 % in the accuracy of the new class in task-agnostic evaluation, while with average performance gains of 4.40 % in clustering accuracy on the unlabeled training data in task-aware evaluation.},
  archive      = {J_PR},
  author       = {Qiupu Chen and Hongkui Jiang and Lin Jiao and Zhou Li and Taosheng Xu and Xue Wang and Rujing Wang},
  doi          = {10.1016/j.patcog.2025.112369},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112369},
  shortjournal = {Pattern Recognition},
  title        = {Fourier-enhanced semi-supervised proxy learning for ultra-fine-grained novel class discovery},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive weighted active contour based HRNet for underwater image segmentation. <em>PR</em>, <em>172</em>, 112368. (<a href='https://doi.org/10.1016/j.patcog.2025.112368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acquiring optimal results in underwater environments remains challenging due to light absorption, scattering, and suspended particles. Furthermore, the low-resolution outputs from traditional semantic segmentation often result in spatial information loss and blurred segmentation boundaries. To address these issues, we first propose a low-level image enhancement preprocessing module as an independent preliminary stage to improve underwater image quality, thereby enhancing subsequent high-level semantic segmentation performance. Second, leveraging the region-based active contour model-which is independent of image gradients and adept at handling complex contour topology changes-we design a novel level set function to serve as the level set in the geometric active contour model. While this new level set exhibits formal similarity to classical level sets in representing binary segmentation contours, its formulation is derived from network prediction outputs. Third, we construct an adaptive weighted active contour energy function as a loss function within HRNet for multi-class segmentation. This loss function preserves geometric information while penalizing deviations between network-predicted probabilities and ground truth, effectively mitigating spatial information loss and optimizing boundary. Comparative experiments demonstrate that our model outperforms classical methods on objective metrics including mIoU and mPA.},
  archive      = {J_PR},
  author       = {Bo Chen and Jing Ji and Junwei Li and Xiaoli Sun and Feng Gong},
  doi          = {10.1016/j.patcog.2025.112368},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112368},
  shortjournal = {Pattern Recognition},
  title        = {An adaptive weighted active contour based HRNet for underwater image segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BORT2: Bi-level optimization for robust target training in multi-source domain adaptation. <em>PR</em>, <em>172</em>, 112367. (<a href='https://doi.org/10.1016/j.patcog.2025.112367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both conventional and source-free multi-source domain adaptation (MSDA) tasks often face bias toward source domains, because more numerous labeled data in these domains, compared with a single unlabeled target domain, can dominate the training process. To alleviate the bias, target adaptation techniques train a target model on the pseudo-labeled target domain data only, with the source-domain-biased models used as the labeling function for pseudo-label generation. However, the pseudo labels may contain noise and harm performance when directly used for supervision. To tackle label noise, we introduce a novel Bi-level Optimization for Robust Target Training (BORT 2 ) scheme. BORT 2 trains a noise-robust target model on pseudo-labeled target data only and meanwhile updates the labeling function (i.e., the source-domain-biased models) to improve pseudo-label quality. Specifically, the target model is a stochastic network designed to be robust to label noise. Such a stochastic network exploits a Gaussian distribution to model the feature of each target instance and deploys an entropy maximization regularizer to the Gaussian to quantify the uncertainty of each pseudo-label, where the uncertainty is utilized to mitigate the negative effects of label noise. In addition, BORT 2 leverages the entropy to update the labeling function for better pseudo-label quality. Updating both the labeling function and the stochastic network involves a nested bi-level optimization problem, addressed using implicit differentiation. Extensive experiments demonstrate that BORT 2 achieves state-of-the-art performance for both conventional and source-free MSDA, as verified on Office-Home, Office-Caltech, PACS, Digit-Five, and the large-scale DomainNet datasets.},
  archive      = {J_PR},
  author       = {Zhongying Deng and Da Li and Xiaojiang Peng and Yi-Zhe Song and Tao Xiang},
  doi          = {10.1016/j.patcog.2025.112367},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112367},
  shortjournal = {Pattern Recognition},
  title        = {BORT2: Bi-level optimization for robust target training in multi-source domain adaptation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Ultra-efficient 3D shape reconstruction: Line-coded absolute phase unwrapping algorithm. <em>PR</em>, <em>172</em>, 112366. (<a href='https://doi.org/10.1016/j.patcog.2025.112366'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Absolute phase unwrapping-based fringe projection profilometry (APU-FPP) has the advantages of pixel-wise calculation, high precision, and full-field sensing of 3D shape information. To the best of our knowledge, existing APU-FPP methods have a general contradiction between accuracy and efficiency because of projecting extra auxiliary coded fringes (ACFs). In this paper, a line-coded absolute phase unwrapping (LCAPU) algorithm is presented for absolute 3D shape reconstruction of the scene with non-uniform reflectivity and complex surfaces. Firstly, a sequence of single-pixel lines is successively embedded into two sets of 3-step phase-shifting patterns to mark fringe periods, which can thoroughly avoid extra ACFs to disrupt the coherence of adjacent morphological information. Secondly, two line-coded phase-shifting patterns with the same phase shift are used to recognize the corresponding coded lines containing the fringe order cue, which can be simultaneously used to guide fringe mutual compensation, thereby extracting a high-quality phase. Finally, according to the pixel positions and the fringe indices of the decoded lines, a multi-layer decoding (MLD) algorithm is developed to iteratively generate a fringe order map, which can adapt to the randomness of morphological changes. Compared to other methods, the proposed LCAPU can not only perform a one-shot 3D shape reconstruction with a single image acquisition, but also automatically correct phase errors, balancing ultra-efficiency and high accuracy. Experimental results demonstrate the superior performance and the practical application potential in dynamic complex scenes.},
  archive      = {J_PR},
  author       = {Haihua An and Yiping Cao and Hechen Zhang},
  doi          = {10.1016/j.patcog.2025.112366},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112366},
  shortjournal = {Pattern Recognition},
  title        = {Ultra-efficient 3D shape reconstruction: Line-coded absolute phase unwrapping algorithm},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning label-specific features for multi-dimensional classification. <em>PR</em>, <em>172</em>, 112365. (<a href='https://doi.org/10.1016/j.patcog.2025.112365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-dimensional classification (MDC), instances are associated with multiple class variables that are assumed in the output space, and each class variable corresponds to one heterogeneous class space and characterizes the objects’ semantics from one dimension. Learning from MDC examples poses challenges due to the heterogeneity of class spaces, since the outputs from different class spaces are not directly comparable. Moreover, existing approaches often use identical data representation for all labels in a class, which may lead to suboptimal results as each label might be determined by its own specific characteristics. Critically, the inherent incomparability of raw heterogeneous labels prevents existing methods from effectively capturing label correlations, which are essential for guiding feature learning. In this paper, we propose a novel algorithm named LEAD, i.e., learning Label-spEcific feAtures for multi-Dimensional classification. LEAD first resolves label heterogeneity by transforming the original output space into a unified encoded label space through one-hot label encoding. This critical alignment enables explicit extraction of label correlations from the encoded space. To enhance the reliability of the estimation of label correlations, LEAD then leverages feature-space manifold structures via locally linear embedding, propagating labeling information across similar instances to counteract sparsity. Finally, LEAD jointly learns label-specific feature representations and constructs the classifier through sparse learning while incorporating label correlations. Experimental comparisons on fifteen datasets demonstrate that our proposed method outperforms state-of-the-art multi-dimensional classification methods. The code is available at https://github.com/ZhangZan-source/LEAD .},
  archive      = {J_PR},
  author       = {Zan Zhang and Jialin Zhou and Jialu Yao and Lin Liu and Jiuyong Li and Lei Li and Xindong Wu},
  doi          = {10.1016/j.patcog.2025.112365},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112365},
  shortjournal = {Pattern Recognition},
  title        = {Learning label-specific features for multi-dimensional classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TSAR: A two-stage approach to motion artifact reduction in OCTA images. <em>PR</em>, <em>172</em>, 112364. (<a href='https://doi.org/10.1016/j.patcog.2025.112364'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical Coherence Tomography Angiography (OCTA) is an innovative and non-invasive imaging technique that leverages motion contrast imaging to generate angiographic images from high-resolution volumetric blood flow data rapidly. However, OCTA imaging is vulnerable to various artifacts induced by eye movements, including displacement artifacts, duplicated scanning artifacts, and white line artifacts. Previous methods that attempted to mitigate eye motion artifacts necessitated costly hardware upgrades. However, despite the availability of advanced eye-tracking hardware and software correction in commercial machines, motion artifacts persist in real-world usage. Recently developed cost-effective learning-based methods only focus on the removal of white line artifacts while neglecting the displacement artifacts and duplicated scanning artifacts. To address this challenge, we propose a comprehensive framework, TSAR, to remove three types of eye motion artifacts in OCTA images. In the first stage, we leverage the intrinsic axial and directional attributes of these artifacts in the first phase to develop an innovative hierarchical transformer network. This network is designed to capture global-wise, local-wise, and vertical-wise features effectively while also removing displacement and duplicate scanning artifacts. Afterward, we leverage the contextual information and develop a residual conditional diffusion model (RCDM) to remove the white line artifacts. By applying our TSAR to the degraded OCTA images, we aim to eliminate all three types of motion artifacts. We evaluate the superior performance of our proposed methodology in artifact removal and image quality enhancement compared to other methods by conducting experiments on both synthetic and real-world OCTA images. The code is available at https://github.com/btma48/TSAR},
  archive      = {J_PR},
  author       = {Benteng Ma and Xiaomeng Li and Xu Lin and Xiaoyu Bai and Dongping Shao and Chubin Ou and Lin An and Jia Qin and Kwang-Ting Cheng},
  doi          = {10.1016/j.patcog.2025.112364},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112364},
  shortjournal = {Pattern Recognition},
  title        = {TSAR: A two-stage approach to motion artifact reduction in OCTA images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quaternionic reweighted amplitude flow for phase retrieval in image reconstruction. <em>PR</em>, <em>172</em>, 112363. (<a href='https://doi.org/10.1016/j.patcog.2025.112363'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quaternionic signal processing provides powerful tools for efficiently managing color signals by preserving the intrinsic correlations among signal dimensions through quaternion algebra. In this paper, we address the quaternionic phase retrieval problem by systematically developing novel algorithms based on an amplitude-based model. Specifically, we propose the Quaternionic Reweighted Amplitude Flow (QRAF) algorithm, which is further enhanced by three of its variants: incremental, accelerated, and adapted QRAF algorithms. In addition, we introduce the Quaternionic Perturbed Amplitude Flow (QPAF) algorithm, which has linear convergence. Extensive numerical experiments on both synthetic data and real images demonstrate that our proposed methods significantly improve recovery performance and computational efficiency compared to state-of-the-art approaches.},
  archive      = {J_PR},
  author       = {Ren Hu and Pan Lian},
  doi          = {10.1016/j.patcog.2025.112363},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112363},
  shortjournal = {Pattern Recognition},
  title        = {Quaternionic reweighted amplitude flow for phase retrieval in image reconstruction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust scene text understanding with OCR token and word alignment for text-VQA and text-caption. <em>PR</em>, <em>172</em>, 112362. (<a href='https://doi.org/10.1016/j.patcog.2025.112362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve vision-language tasks incorporating scene text, such as Text-VQA and Text-Caption, recognizing and understanding scene text within image is the first priority. However, the scene text recognized by Optical Character Recognition (OCR) systems often includes spelling errors, such as “pepsi” being recognized as “peosi”. These OCR errors are one of the major challenges for Text-VQA and Text-Caption systems. To address this, we propose a novel multi-modal OCR Token and Word Alignment (TWA) method to alleviate OCR errors in these tasks. First, we artificially create the misspelled OCR tokens and render them onto the RGB images, which can effectively simulates OCR errors. Second, we propose an OCR token-word contrastive learning task to pre-train OCR token representation, making the system more robust to OCR errors. Finally, we introduce a vocabulary predictor with character-level semantic matching, which enables the model to recover the correct word from the vocabulary even with misspelled OCR tokens. A variety of experimental evaluations demonstrate that our method outperforms the state-of-the-art methods on both Text-VQA and Text-Caption datasets.},
  archive      = {J_PR},
  author       = {Zan-Xia Jin and Pinle Qin and Suzhen Lin and Jia Qin and Shuangjiao Zhai and Jianchao Zeng and Xu-Cheng Yin},
  doi          = {10.1016/j.patcog.2025.112362},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112362},
  shortjournal = {Pattern Recognition},
  title        = {Robust scene text understanding with OCR token and word alignment for text-VQA and text-caption},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prior tokenization-based interactive segmentation with vision transformers. <em>PR</em>, <em>172</em>, 112361. (<a href='https://doi.org/10.1016/j.patcog.2025.112361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively leveraging the provided priors is crucial for interactive segmentation. Existing approaches typically encode clicks via distance-based maps, which are then concatenated or added to the original image as network input. However, these methods do not fully exploit the semantic information embedded in the provided priors, leading to confusion in the feature distribution of different targets and reducing the segmentation quality. To address this issue, we propose a prior tokenization-based interactive segmentation method that uses simple Vision Transformers. By extending the original image tokens with prior tokens, each token represents the semantic features of the foreground and background related to the priors. These tokens participate in the self-attention operation alongside regular image tokens, gradually extracting semantic features from the image tokens to the prior tokens. In addition, we introduce a discriminative loss function to enforce inter-class separation and intra-class compactness of the prior tokens. Subsequently, we employ a cross-attention mechanism to couple the prior tokens with the regular image block token features, ensuring that the features extracted by the network are aligned with the user’s intent. Finally, we use the register method to suppress artifacts and enhance the segmentation performance further. Extensive experiments demonstrate that our method achieves superior interaction efficiency, robustness, and generalization ability across various medical image segmentation benchmarks. The source codes are available at https://github.com/dzyha2011/PT-SimpleClick},
  archive      = {J_PR},
  author       = {Zongyuan Ding and Boyu Wang and Hongyuan Wang and Tao Wang},
  doi          = {10.1016/j.patcog.2025.112361},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112361},
  shortjournal = {Pattern Recognition},
  title        = {Prior tokenization-based interactive segmentation with vision transformers},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CTNet: Color transformation network for low-light image enhancement. <em>PR</em>, <em>172</em>, 112360. (<a href='https://doi.org/10.1016/j.patcog.2025.112360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light images are often plagued by low visibility, poor contrast, and high noise levels, which significantly impair both subjective visual quality and the performance of downstream tasks. Existing enhancement methods typically struggle with color-related degradations such as color casting, artifacts, and distortion. To address these challenges, we propose an end-to-end Color Transformation Network for low-light image enhancement, with a specific focus on improving color restoration. By leveraging the complementary strengths of the HSV and RGB color spaces in capturing color attributes, our approach enables effective interaction between these color spaces at the feature level. The HSV branch simultaneously enhances the V component while extracting features from the H and S components, thereby providing a more comprehensive set of cues for color recovery. To facilitate interaction, we design a learnable Color Transformation Block that bridges the HSV and RGB feature domains, effectively simulating the HSV-to-RGB conversion. Furthermore, a Cross-Integration Block, employing an attention-based cross-guidance mechanism, enables bi-directional information flow between the two color spaces. Extensive experiments on both real and synthetic datasets demonstrate that our method achieves superior performance, surpassing existing approaches both qualitatively and quantitatively. The project is available at https://github.com/1013990424/CTNet .},
  archive      = {J_PR},
  author       = {Lidong Xie and Runmin Cong and Ju Dai and Wenhan Yang and Junjun Pan and Hao Wu},
  doi          = {10.1016/j.patcog.2025.112360},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112360},
  shortjournal = {Pattern Recognition},
  title        = {CTNet: Color transformation network for low-light image enhancement},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Joint adversarial attack: An effective approach to evaluate robustness of 3D object tracking. <em>PR</em>, <em>172</em>, 112359. (<a href='https://doi.org/10.1016/j.patcog.2025.112359'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have widely been used in 3D object tracking, thanks to its superior capabilities to learn from geometric training samples and locate tracking targets. Although the DNN based trackers show vulnerability to adversarial examples, their robustness in real-world scenarios with potentially complex data defects has rarely been studied. To this end, a joint adversarial attack method against 3D object tracking is proposed, which simulates defects of the point cloud data in the form of point filtration and perturbation simultaneously. Specifically, a voxel-based point filtration module is designed to filter points of the tracking template, which is described by the voxel-wise binary distribution regarding the density of the point cloud. Furthermore, a voxel-based point perturbation module adds voxel-wise perturbations to the filtered template, whose direction is constrained by local geometrical information of the template. Experiments conducted on popular 3D trackers demonstrate that the proposed joint attack have decreased the success and precision of existing 3D trackers by 30.2% and 35.4% respectively in average, which made an improvement of 30.5% over existing attack methods.},
  archive      = {J_PR},
  author       = {Riran Cheng and Xupeng Wang and Ferdous Sohel and Hang Lei},
  doi          = {10.1016/j.patcog.2025.112359},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112359},
  shortjournal = {Pattern Recognition},
  title        = {Joint adversarial attack: An effective approach to evaluate robustness of 3D object tracking},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-channel blur invariants of color and multispectral images. <em>PR</em>, <em>172</em>, 112358. (<a href='https://doi.org/10.1016/j.patcog.2025.112358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper deals with the recognition of blurred color/multispectral images directly without any deblurring. We present a general theory of invariants of multispectral images with respect to blur. The paper is a significant non-trivial extension of the recent theory of blur invariants of graylevel images. The main original contribution of the paper lies in introducing cross-channel blur invariants in Fourier domain. We also developed an algorithm for their stable and fast calculation in the moment domain. Moreover, the cross-channel invariants can be found for blurs for which single-channel invariants do not exist. The experiments on simulated and real data demonstrate that incorporating the new cross-channel invariants significantly improves the recognition power and surpasses other existing approaches. The outlook for a possible implementation of the blur invariants into neural networks is briefly sketched in the conclusion.},
  archive      = {J_PR},
  author       = {Václav Košík and Jan Flusser and Filip Šroubek},
  doi          = {10.1016/j.patcog.2025.112358},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112358},
  shortjournal = {Pattern Recognition},
  title        = {Cross-channel blur invariants of color and multispectral images},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UniForCE: The unimodality forest method for clustering and estimation of the number of clusters. <em>PR</em>, <em>172</em>, 112357. (<a href='https://doi.org/10.1016/j.patcog.2025.112357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the number of clusters k while clustering the data is a challenging task. An incorrect cluster assumption indicates that the number of clusters k gets wrongly estimated. Consequently, the model fitting becomes less important. In this work, we focus on the concept of unimodality and propose a flexible cluster definition called locally unimodal cluster . A locally unimodal cluster extends for as long as unimodality is locally preserved across pairs of subclusters of the data. Then, we propose the UniForCE method for locally unimodal clustering. The method starts with an initial overclustering of the data and relies on the unimodality graph that connects subclusters forming unimodal pairs. Such pairs are identified using an appropriate statistical test. UniForCE identifies maximal locally unimodal clusters that are statistically significant by computing a spanning forest in the unimodality graph. Experimental results on both real and synthetic datasets illustrate that the proposed methodology is particularly flexible and robust in discovering regular and highly complex cluster shapes. Most importantly, it automatically provides an adequate estimation of the number of clusters.},
  archive      = {J_PR},
  author       = {Georgios Vardakas and Argyris Kalogeratos and Aristidis Likas},
  doi          = {10.1016/j.patcog.2025.112357},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112357},
  shortjournal = {Pattern Recognition},
  title        = {UniForCE: The unimodality forest method for clustering and estimation of the number of clusters},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SequencePAR: Understanding pedestrian attributes via a sequence generation paradigm. <em>PR</em>, <em>172</em>, 112356. (<a href='https://doi.org/10.1016/j.patcog.2025.112356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current pedestrian attribute recognition (PAR) algorithms use multi-label or multi-task learning frameworks with specific classification heads. These models often struggle with imbalanced data and noisy samples. Inspired by the success of generative models, we propose Sequence Pedestrian Attribute Recognition (SequencePAR), a novel sequence generation paradigm for PAR. SequencePAR extracts pedestrian features using a language-image pre-trained model and embeds the attribute set into query tokens guided by text prompts. A Transformer decoder generates human attributes by integrating visual features and attribute query tokens. The masked multi-head attention layer in the decoder prevents the model from predicting the next attribute during training. The extensive experiments on multiple PAR datasets validate the effectiveness of SequencePAR. Specifically, we achieve 84.92 %, 90.44 %, 90.73 %, and 90.46 % in accuracy, precision, recall, and F1-score on the PETA dataset.},
  archive      = {J_PR},
  author       = {Jiandong Jin and Xiao Wang and Yin Lin and Chenglong Li and Lili Huang and Aihua Zheng and Jin Tang},
  doi          = {10.1016/j.patcog.2025.112356},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112356},
  shortjournal = {Pattern Recognition},
  title        = {SequencePAR: Understanding pedestrian attributes via a sequence generation paradigm},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SATE: Efficient knowledge distillation with implicit student-aware teacher ensembles. <em>PR</em>, <em>172</em>, 112355. (<a href='https://doi.org/10.1016/j.patcog.2025.112355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent findings suggest that with the same teacher architecture, a fully converged or “stronger” checkpoint surprisingly leads to a worse student. This can be explained by the Information Bottleneck (IB) principle, as the features of a weaker teacher transfer more “dark” knowledge because they maintain higher mutual information with the inputs. Meanwhile, various works have shown that severe teacher-student structural disparity or capability mismatch often leads to worse student performance. To deal with these issues, we propose a generalizable and efficient Knowledge Distillation (KD) framework with implicit Student-Aware Teacher Ensembles (SATE). The SATE framework simultaneously trains a student network and a student-aware intermediate teacher as a learning companion. With the proposed co-training strategy, the intermediate teacher is trained gradually and forms implicit ensembles of weaker teachers along the learning process. Such a design enables the student model to retain more dark knowledge for better generalization ability. The proposed framework improves the training scheme in a plug-and-play way so that it can be applied to improve various classic and state-of-the-art KD methods on both intra-domain (up to 2.184 % ) and cross-domain (up to 7.358 % ) settings, under a diversified configurations on teacher-student architectures, and achieves a major efficient advantage over other generic frameworks. The code is available at https://github.com/diqichen91/SATE.git .},
  archive      = {J_PR},
  author       = {Diqi Chen and Yang Li and Jiajun Liu and Jun Zhou and Yongsheng Gao},
  doi          = {10.1016/j.patcog.2025.112355},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112355},
  shortjournal = {Pattern Recognition},
  title        = {SATE: Efficient knowledge distillation with implicit student-aware teacher ensembles},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discriminative attention based weighted sparse representation of visual objects in complex scenarios. <em>PR</em>, <em>172</em>, 112354. (<a href='https://doi.org/10.1016/j.patcog.2025.112354'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse subspace representation (SSR) is an attractive technique for subspace segmentation of high-dimensional data through a self-representation manner to reveal its algebraic structure. Numerous generalizations of SSR have been developed to meet different applications. However, a fatal limitation in those extensions is their neglect of feature weights in visual samples, which play crucial roles in segmenting or recognizing specific objects. This paper introduces a discriminative attention based weighted SSR model to tackle visual objects. In the proposed model, the prior information is empirically constructed for intra-cluster features and inter-cluster ones, aided by the sparse representation of samples. An attention mechanism is introduced to learn weights of features of samples. The attention based weights of objects in samples and sparse representation of samples are collaboratively learned from the prior information. A hard version and a soft one of attention based sparse subspace representation, abbreviated as HDAWSSR and SDAWSSR, are specified by assigning attention of features by a Boolean matrix and a fuzzy matrix. Algorithms for solving both models are meticulously developed, respectively. Applications of both algorithms in clustering and moving object detection within high-dimensional image data are investigated. Experimental results show that both models outperform the state-of-the-art subspace based segmentation methods.},
  archive      = {J_PR},
  author       = {Ge Yang and Tingquan Deng and Ming Yang and Changzhong Wang},
  doi          = {10.1016/j.patcog.2025.112354},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112354},
  shortjournal = {Pattern Recognition},
  title        = {Discriminative attention based weighted sparse representation of visual objects in complex scenarios},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-scale feature sharing and collaborative sampling for unsupervised vehicle re-identification. <em>PR</em>, <em>172</em>, 112353. (<a href='https://doi.org/10.1016/j.patcog.2025.112353'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle Re-identification (Re-ID) retrieves target vehicle images from non-overlapping cameras. To address label noise in pseudo-labels, we propose the Multi-scale Feature Sharing and Collaborative Sampling (MFSCS) method. Specifically, the designed multi-scale feature sharing module moves beyond reliance on global features, efficiently promoting the exchange of characteristics between global and local aspects. This shared feature approach collectively mitigates the label noise arising from clustering. Recognizing that clustering methods are highly sensitive to outliers, we introduce a collaborative sampling module that cooperatively combines samples in the clustering process before training the model. This cooperative sampling module is better equipped to handle outliers in the samples and update label information more efficiently. As a result, it asymptotically improves the accuracy and stability of the model. The effectiveness of the proposed method in terms of performance is demonstrated through extensive experiments conducted on both the latest challenging truck Re-ID dataset, Truck-ID and VeRi-776.},
  archive      = {J_PR},
  author       = {Jia-Jia Li and Si-Bao Chen and Chris Ding and Bin Luo},
  doi          = {10.1016/j.patcog.2025.112353},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112353},
  shortjournal = {Pattern Recognition},
  title        = {Multi-scale feature sharing and collaborative sampling for unsupervised vehicle re-identification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). You look from old classes: Towards accurate few shot class-incremental learning. <em>PR</em>, <em>172</em>, 112352. (<a href='https://doi.org/10.1016/j.patcog.2025.112352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot class incremental learning (FSCIL) is a common but difficult task that faces two challenges: catastrophic forgetting of old classes and insufficient learning of new classes with limited samples. Recent wisdom focuses on preventing catastrophic forgetting yet overlooks the limited samples issue, resulting in poor new class performance. In this paper, we argue that old class samples contain rich knowledge, which can be exploited to supplement the learning of new classes. To this end, we propose to Look from Old Classes (YLOC) for FSCIL, enhancing both the base and incremental sessions. In the base session, we develop a prototype centered loss (PCL) to obtain a compact distribution of old classes. During incremental sessions, we devise a prototype augmentation learning (PAL) method to aid the learning of new classes by exploiting old classes. Extensive experiments on three FSCIL benchmark datasets demonstrate the superiority of our method.},
  archive      = {J_PR},
  author       = {Yijie Hu and Kaizhu Huang and Wei Wang and Xiaowei Huang and Qiufeng Wang},
  doi          = {10.1016/j.patcog.2025.112352},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112352},
  shortjournal = {Pattern Recognition},
  title        = {You look from old classes: Towards accurate few shot class-incremental learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-decoder collaborative learning with multi-hybrid view augmentation for self-supervised 3D action recognition. <em>PR</em>, <em>172</em>, 112351. (<a href='https://doi.org/10.1016/j.patcog.2025.112351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised methods, including contrastive learning and masked skeleton modeling, have demonstrated considerable potential in the field of skeleton-based action recognition. While contrastive learning captures fine-grained details at the instance level, masked skeleton modeling emphasizes joint-level features. Recent studies have begun to combine these two approaches. However, existing combination methods primarily focus on integrating the tasks within the skeleton space. Moreover, existing contrastive learning methods often fail to exploit the comprehensive interaction information in skeletal structures, resulting in suboptimal performance when recognizing actions involving multiple individuals. To overcome these limitations, we introduce the Dual-Decoder Collaborative Learning (DDC) with Multi-Hybrid View Augmentation (MHGNA) method, which connects these two tasks across multiple spaces. Specifically, the masked skeleton modeling task provides diverse views for the contrastive learning task in the skeleton space, while the contrastive method aligns the features generated by both tasks within the feature space. We further present an innovative view augmentation method that enhances the model’s capacity to understand human interaction relationships by shuffling and replacing data across temporal, spatial, and personal dimensions. Extensive experiments on four downstream tasks across three large-scale datasets demonstrate that DDC exhibits stronger representational capabilities compared to state-of-the-art methods. Our code is available at https://github.com/Yingfei-Wu/DDC .},
  archive      = {J_PR},
  author       = {Wenming Cao and Yingfei Wu and Xinpeng Yin},
  doi          = {10.1016/j.patcog.2025.112351},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112351},
  shortjournal = {Pattern Recognition},
  title        = {Dual-decoder collaborative learning with multi-hybrid view augmentation for self-supervised 3D action recognition},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). D3PD: Dual distillation and dynamic fusion for camera-radar 3D perception. <em>PR</em>, <em>172</em>, 112350. (<a href='https://doi.org/10.1016/j.patcog.2025.112350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving perception is driving rapid advancements in Bird’s-Eye-View (BEV) technology. The synergy of surround-view imagery and radar is seen as a cost-friendly approach that enhances the understanding of driving scenarios. However, current methods for fusing radar and camera features lack effective environmental perception guidance and dynamic adjustment capabilities, which restricts their performance in real-world scenarios. In this paper, we introduce the D3PD framework, which combines fusion techniques with knowledge distillation to tackle the dynamic guidance deficit in existing radar-camera fusion methods. Our method includes two key modules: Radar-Camera Feature Enhancement (RCFE) and Dual Distillation Knowledge Transfer. The RCFE module enhances the areas of interest in BEV, addressing the poor object perception performance of single-modal features. The Dual Distillation Knowledge Transfer includes four distinct modules: Camera Radar Sparse Distillation (CRSD) for sparse feature knowledge transfer and teacher-student network feature alignment. Position-guided Sampling Distillation(SamD) for refining the knowledge transfer of fused features through dynamic sampling. Detection Constraint Result Distillation (DcRD) for strengthening the positional correlation between teacher and student network outputs in forward propagation, achieving more precise detection perception. and Self-learning Mask Focused Distillation (SMFD) for focusing perception detection results on knowledge transfer through self-learning, concentrating on the reinforcement of local key areas. The D3PD framework outperforms existing methods on the nuScenes benchmark, achieving 49.6 % mAP and 59.2 % NDS performance. Moreover, in the occupancy prediction task, D3PD-Occ has achieved an advanced performance of 37.94 % mIoU. This provides insights for the design and model training of camera and radar-based 3D object detection and occupancy network prediction methods. The code will be available at https://github.com/no-Name128/D3PD .},
  archive      = {J_PR},
  author       = {Junyin Wang and Chenghu Du and Tongao Ge and Bingyi Liu and Shengwu Xiong},
  doi          = {10.1016/j.patcog.2025.112350},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112350},
  shortjournal = {Pattern Recognition},
  title        = {D3PD: Dual distillation and dynamic fusion for camera-radar 3D perception},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TBiGAN-based parallel networks for remaining useful life prediction of multi-stage degraded bearings. <em>PR</em>, <em>172</em>, 112349. (<a href='https://doi.org/10.1016/j.patcog.2025.112349'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of the remaining useful life (RUL) of rolling bearings is crucial for ensuring the safe and reliable operation of rotating machinery. However, existing methods generally overlook the correlation between different degradation stages and RUL, thereby limiting the accuracy of RUL prediction for rolling bearings. To address this challenge, a novel adaptive RUL prediction method for multi-stage degrading rolling bearings is proposed. Specifically, a new Transformer-based network is designed to classify the degradation stages of bearings. Additionally, a parallel RUL prediction model incorporating attention mechanisms is introduced, which integrates Temporal Convolutional Networks (TCN) and Bidirectional Gated Recurrent Units (BiGRU) to capture degradation features from multiple dimensions automatically and enhance the model’s ability to capture long-term dependencies in sequence tasks. Finally, the RUL prediction results from different stages are adaptively integrated using a smoothing technique to generate the final RUL. The accuracy and superiority of the proposed method are validated on the PHM2012 bearing dataset.},
  archive      = {J_PR},
  author       = {Zheng Jianfei and Chen Dongnan and Hu Changhua and Han Qihui and Pei Hong},
  doi          = {10.1016/j.patcog.2025.112349},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112349},
  shortjournal = {Pattern Recognition},
  title        = {TBiGAN-based parallel networks for remaining useful life prediction of multi-stage degraded bearings},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MChartQA and mChartQABench: A multimodal-only solution for complex chart question-answering. <em>PR</em>, <em>172</em>, 112348. (<a href='https://doi.org/10.1016/j.patcog.2025.112348'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal chart question-answering (QA) is essential for applications such as financial report analysis, decision support, and invoice parsing. Current methods typically convert charts to text for processing by large language models (LLMs) or use direct multimodal processing. This raises an important question: under what conditions is a multimodal approach essential for chart question-answering? We observe that these traditional approaches often struggle with complex color patterns, structural intricacies, and implicit numerical data. Yet, limited research addresses these challenges. To bridge this gap, we introduce a new multimodal chart dataset, mChartQABench, constructed by consolidating data from existing open-source datasets to address challenges with color, structure, and textless chart data. To handle these complex multimodal scenarios effectively, we propose mChartQA, a framework integrating the advanced language processing of LLMs with a state-of-the-art table-to-text engine. This framework excels in aligning visual and textual data, enhancing deep reasoning and contextual understanding within charts. Experimental results show that mChartQA achieves superior performance across four datasets, with over 20 % overall accuracy improvement on mChartQABench.},
  archive      = {J_PR},
  author       = {Jingxuan Wei and Nan Xu and Guiyong Chang and Yin Luo and Bihui Yu and Ruifeng Guo},
  doi          = {10.1016/j.patcog.2025.112348},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112348},
  shortjournal = {Pattern Recognition},
  title        = {MChartQA and mChartQABench: A multimodal-only solution for complex chart question-answering},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Copula-based conformal prediction for prioritized heterogeneous multi-task learning. <em>PR</em>, <em>172</em>, 112347. (<a href='https://doi.org/10.1016/j.patcog.2025.112347'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformal prediction (CP) has emerged as a standard for finite-sample and distribution-free uncertainty quantification (UQ). Although CP is widely used as a post-processing step (on the outputs of machine learning models) to produce reliable set-valued predictions, it is still challenging to post-process heterogeneous (i.e., categorical & numerical) predictions since the traditional CP procedures are either exclusively designed for classification or only tailored to regression. This article proposes the use of a simple yet novel copula-based CP method that jointly produces (discrete) set-valued predictions and (continuous) interval-valued predictions. This approach offers flexibility by allowing the prioritization of specific outputs’ reliability and applies to general heterogeneous multi-task problems. We demonstrate its effectiveness in the context of autonomous driving, on two popular multi-class object detection benchmarks, where it effectively infers set values for object classes and bounding boxes with the specified confidence levels. Experimental results validate our method’s ability in handling heterogeneous multi-task conformal predictions: we achieve high confidence levels without losing the informativeness of the prediction regions.},
  archive      = {J_PR},
  author       = {Bruce Cyusa Mukama and Soundouss Messoudi and Sébastien Destercke and Sylvain Rousseau},
  doi          = {10.1016/j.patcog.2025.112347},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112347},
  shortjournal = {Pattern Recognition},
  title        = {Copula-based conformal prediction for prioritized heterogeneous multi-task learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A deep spatio-temporal architecture for dynamic ECN analysis with granger causality based causal discovery. <em>PR</em>, <em>172</em>, 112346. (<a href='https://doi.org/10.1016/j.patcog.2025.112346'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurobrain science provides the motivation for research on causal modeling. The existing causal discovery methods have shown promising results in effective connectivity network analysis, however, they often overlook the dynamics of causality, in addition to the incorporation of spatio-temporal information in data. Dynamic effective connectivity networks (dECNs) reveal the changing directed brain activity and the dynamic causal influences among brain regions, which facilitate the identification of individual differences and enhance the understanding of human brain. To learn dynamic causality, we propose a deep spatio-temporal fusion architecture, which employs a dynamic causal deep encoder to incorporate spatio-temporal information into dynamic causality modeling, and a dynamic causal deep decoder to verify the discovered causality. The effectiveness of the proposed method is first illustrated with simulated data. Then, experimental results from Philadelphia Neurodevelopmental Cohort (PNC) demonstrate the superiority of the proposed method in inferring dECNs, which reveal the dynamic evolution of directed flow between brain regions. The analysis shows the difference of dECNs between young adults and children. Specifically, the directed brain functional networks transit from fluctuating undifferentiated systems to more stable specialized networks as one grows. This observation provides further evidence on the modularization and adaptation of brain networks during development, leading to higher cognitive abilities observed in young adults.},
  archive      = {J_PR},
  author       = {Faming Xu and Yiding Wang and Gang Qu and Vince D. Calhoun and Julia M. Stephen and Tony W. Wilson and Yu-Ping Wang and Chen Qiao},
  doi          = {10.1016/j.patcog.2025.112346},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112346},
  shortjournal = {Pattern Recognition},
  title        = {A deep spatio-temporal architecture for dynamic ECN analysis with granger causality based causal discovery},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised domain adaptation via style-aware self-intermediate domain. <em>PR</em>, <em>172</em>, 112344. (<a href='https://doi.org/10.1016/j.patcog.2025.112344'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) has garnered significant attention for its ability to transfer knowledge from a label-rich source domain to a related but unlabeled target domain, with minimizing inter-domain discrepancies being crucial, especially when a substantial gap exists between the domains. To address this, we introduce the novel Style-aware Self-Intermediate Domain (SSID), which effectively bridges large domain gaps by facilitating knowledge transfer while preserving class-discriminative information. Inspired by human transitive inference and learning capabilities, SSID connects seemingly unrelated concepts through a sequence of intermediate, auxiliary synthesized concepts. Meanwhile, an external memory bank is designed to store and update designated labeled features, ensuring the stability of class-specific and class-wise style features. Additionally, we also proposed a novel intra- and inter-domain loss functions that enhance class recognition and feature compatibility, with their convergence rigorously validated through a novel analytical approach. Comprehensive experiments demonstrate that SSID achieves accuracies of 85.4 % and 85.3 % on two widely recognized UDA benchmarks, outperforming the second-best methods by 0.94 % and 1.17 %, respectively. As a plug-and-play solution, SSID integrates seamlessly with various backbone networks, showcasing its effectiveness and versatility in domain adaptation scenarios.},
  archive      = {J_PR},
  author       = {Lianyu Wang and Meng Wang and Daoqiang Zhang and Huazhu Fu},
  doi          = {10.1016/j.patcog.2025.112344},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112344},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised domain adaptation via style-aware self-intermediate domain},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing visual representation of untrimmed videos by counteracting visuality threatening content. <em>PR</em>, <em>172</em>, 112343. (<a href='https://doi.org/10.1016/j.patcog.2025.112343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the remarkable growth of the video platform industry and the surge in video uploads, Content-Based Video Retrieval (CBVR), which finds videos on desired topics from a collection of untrimmed videos using solely the visual modality, is gaining increased attention. However, the challenge of accurate retrieval persists due to the varied and complex content in untrimmed videos, and there has been a lack of discussion on which types of content compromise visual representations. In this paper, we found that text and blur texture are of this nature, grounded in empirical observations. Indeed, in models focusing on the visual modality, both the visual structure of text (without semantics) and the smoothness of blur texture (with few edges and corners) interfere with decision-making. To address them, we propose two strategies: text-masking learning, which excludes the effect of text in the descriptor for inputs that may contain text content, and blur texture filtering, a re-scaling strategy that mitigates the impact of blur textures by exploiting the neural network’s insensitivity to the smoothed pixel-wise gradients. Furthermore, through empirical observations, we demonstrate that our proposed method effectively handles visuality-threatening content. Additionally, we show that our method can lead to state-of-the-art performance across multiple benchmarks of untrimmed videos.},
  archive      = {J_PR},
  author       = {Gwangjin Lee and Won Jo and Hyunwoo Kim and Yukyung Choi},
  doi          = {10.1016/j.patcog.2025.112343},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112343},
  shortjournal = {Pattern Recognition},
  title        = {Enhancing visual representation of untrimmed videos by counteracting visuality threatening content},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Texture-aware transformer with pose-patch mapping for occluded person re-identification. <em>PR</em>, <em>172</em>, 112341. (<a href='https://doi.org/10.1016/j.patcog.2025.112341'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occluded person re-identification (re-ID) aims to retrieve the target person from occluded images captured by different cameras, where the challenges lie in identity loss caused by different types of occlusion. To alleviate the occlusion interference, some methods rely on external clues or generate more occlusion samples. However, these methods fail to address the issues of pose misalignment under extreme occlusion and identity confusion caused by non-target pedestrian occlusion. To solve these problems, we design a novel T exture-Aware T ransformer with P ose-Patch M apping (TTPM), which does not require generating any occlusion samples. Specifically, a Multi-patch Feature Encoder is proposed to encode discriminative features from inter patches and intra patches. Afterwards, the Pose-Patch Mapping is designed to construct a positional mapping between poses and patches, which highlights human patches and weakens the impact of occluded patches. Finally, to mitigate the non-target pedestrian occlusion, a Texture-Aware Decoder is introduced to perceive texture features and leverage their distinctiveness to enhance the representation of important regions. Extensive experiments show that our method achieves state-of-the-art results on Occluded-Duke and Occluded-REID datasets.},
  archive      = {J_PR},
  author       = {Dengwen Wang and Guanyu Xing and Yanli Liu},
  doi          = {10.1016/j.patcog.2025.112341},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112341},
  shortjournal = {Pattern Recognition},
  title        = {Texture-aware transformer with pose-patch mapping for occluded person re-identification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient community-aware pre-training method for graph neural networks. <em>PR</em>, <em>172</em>, 112340. (<a href='https://doi.org/10.1016/j.patcog.2025.112340'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While graph neural networks (GNNs) have demonstrated widespread success in various domains, their pre-training techniques lag behind those in computer vision and natural language processing, typically exhibiting limited performance gains and high computational costs. This paper introduces Community-Aware Pre-training (CAP), a novel approach that leverages the inherent community structures prevalent in real-world networks to enhance GNN pre-training efficiency and effectiveness. CAP employs a self-supervised contrastive learning framework to learn node representations that are highly discriminative of their respective communities. To further optimize the pre-training process, we introduce a Monte Carlo Tree Search-based community sampler that efficiently extracts representative subgraphs, mitigating noise and enhancing sample quality. CAP is versatile and can be applied to a broad range of node classification tasks due to the commonly existing community structures within networks. Extensive evaluations on diverse node classification benchmarks demonstrate that CAP consistently outperforms state-of-the-art methods, achieving accuracy improvements of up to 4.34 % while significantly reducing pre-training time by up to 14.87 times compared to existing techniques. Furthermore, CAP enhances the predictive confidence and visualization distinctiveness of node representations, paving a new path for effective and efficient GNN pre-training.},
  archive      = {J_PR},
  author       = {Zhenhua Huang and Wenhao Zhou and Yihang Jiang and Zhaohong Jia and Linyuan Lü and Yunjie Ma},
  doi          = {10.1016/j.patcog.2025.112340},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112340},
  shortjournal = {Pattern Recognition},
  title        = {An efficient community-aware pre-training method for graph neural networks},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction. <em>PR</em>, <em>172</em>, 112339. (<a href='https://doi.org/10.1016/j.patcog.2025.112339'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have made significant progress in trajectory prediction tasks but still face several critical challenges. The ordinary differential equation (ODE) solving methods used in standard diffusion models often suffer from error accumulation during multi-step iterations. Additionally, the denoising process is highly time-consuming due to the large number of computational steps, which significantly hinders inference efficiency and makes real-time applications challenging. To address these issues, we propose a diffusion-based method, DiffTrajectory, which integrates the Runge-Kutta (RK4) method, a Leap Initializer Module (LIM), and an Adaptive Dynamic Step-size Strategy (ADSS) to enhance generation accuracy and greatly optimize inference efficiency. Specifically, to tackle the problem of error accumulation, DiffTrajectory formalizes the denoising process as an ODE-solving problem and adopts the RK4 as a numerical solution. By computing multiple intermediate points at each iteration, this approach significantly reduces error accumulation. To improve the efficiency of the denoising process, DiffTrajectory introduces LIM, which leverages a pre-trained initial model to quickly generate a high-quality starting point for denoising, thereby reducing the computational burden during the initial denoising stages. Furthermore, we design the ADSS that adjusts the step size dynamically based on the results of each denoising stage, ensuring the quality of the generated results while substantially shortening inference time. Extensive experiments on the ETH/UCY and NBA datasets demonstrate that DiffTrajectory achieves substantial improvements in both accuracy and efficiency.},
  archive      = {J_PR},
  author       = {Chengcheng Li and Luqi Gong and Leiheng Xu and Xin Wang},
  doi          = {10.1016/j.patcog.2025.112339},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112339},
  shortjournal = {Pattern Recognition},
  title        = {DiffTrajectory: Mitigating cumulative errors and enhancing inference efficiency in diffusion-based trajectory prediction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A mondrian conformal predictive system with improved decision trees for uncertainty quantification under heteroscedasticity. <em>PR</em>, <em>172</em>, 112338. (<a href='https://doi.org/10.1016/j.patcog.2025.112338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing application of machine learning in industrial production, model uncertainty quantification has become a critical tool to evaluate the prediction reliability and guide decision-making. The Conformal Predictive System (CPS), which generates Cumulative Distribution Functions (CDFs), provides valuable support for uncertainty quantification. However, CPS faces limitations when addressing heteroskedasticity. This paper proposes a Mondrian Conformal Predictive System (LWT-MCPS) based on an enhanced Decision Tree. The proposed approach constructs decision trees using splitting criteria derived from Levene’s test and Welch’s t -test, ensuring that the variance and mean within each partition remain as homogeneous as possible. Furthermore, it incorporates predicted values and prediction variances estimated using the k -Nearest Neighbors (KNN) as splitting features, effectively mitigating the impact of high-dimensional data on tree partitioning and enhancing the model’s ability to identify heterogeneous regions. Experiments conducted on simulated data, public datasets, and blast furnace ironmaking data demonstrate that LWT-MCPS generates CDFs with lower Continuous Ranked Probability Scores (CRPS) than traditional CPS. These results validate its significant advantages in addressing heteroskedasticity challenges.},
  archive      = {J_PR},
  author       = {Ruiyao Zhang and Ping Zhou},
  doi          = {10.1016/j.patcog.2025.112338},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112338},
  shortjournal = {Pattern Recognition},
  title        = {A mondrian conformal predictive system with improved decision trees for uncertainty quantification under heteroscedasticity},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial multi-semantic features guided spectral-friendly transformer network for hyperspectral image classification. <em>PR</em>, <em>172</em>, 112337. (<a href='https://doi.org/10.1016/j.patcog.2025.112337'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image classification (HSIC) is a foundational topic in remote sensing. However, the high correlations between bands and the spectral correlations often result in redundant data. Moreover, traditional convolutional neural networks (CNNs) compress spatial dimensions through pooling layers or strides during spatial information extraction, resulting in the loss of spatial information. To overcome these challenges, we propose a spatial multi-semantic features guided spectral-friendly Transformer network (SFTN), which effectively extracts the spectral and spatial features of HSIs. Specifically, a multi-semantic spatial attention (MsSA) module applies unidirectional spatial compression along the height and width dimensions. Thus, this module maintains spatial structure in one direction while aggregating global spatial information, thereby minimizing information loss during compression. It then employs multi-scale depth-shared 1D convolutions to capture multi-semantic spatial information. Furthermore, the spectral-friendly Transformer replaces the traditional multi-head self-attention (MHSA) with spectral correlation self-attention (ECSa), which effectively captures spectral differences and thus reduces the redundancy of spectral information. Extensive experiments on several HSI datasets show that the proposed SFTN method outperforms other state-of-the-art methods in HSIC applications. The source code for this work will be released later.},
  archive      = {J_PR},
  author       = {Xiaoyan Yu and Mingzhu Tai and Yuyang Wang and Zhenqiu Shu and Liehuang Zhu},
  doi          = {10.1016/j.patcog.2025.112337},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112337},
  shortjournal = {Pattern Recognition},
  title        = {Spatial multi-semantic features guided spectral-friendly transformer network for hyperspectral image classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Backdoor defense based on adversarial prediction proximity and contrastive knowledge distillation. <em>PR</em>, <em>172</em>, 112336. (<a href='https://doi.org/10.1016/j.patcog.2025.112336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have become indispensable across various fields; however, their susceptibility to backdoor attacks poses significant security risks. In this paper, we propose a backdoor defense scheme based on adversarial prediction proximity and contrastive knowledge distillation. This scheme not only detects poisoned models and labels but also effectively unlearns backdoors while preserving the model’s benign functionality. Based on the observation that untargeted adversarial examples and poisoned samples exhibit proximity in feature space within poisoned models (i.e., adversarial prediction proximity), we first detect backdoors by analyzing changes in the prediction behavior of untargeted adversarial examples for models before and after fine-tuning. Next, we purify the poisoned model using a triplet loss that incorporates clean samples and untargeted adversarial examples. This process is guided by contrastive knowledge distillation, where a fine-tuned model acts as a “benign teacher”, and a backdoor-retained model serves as a “malicious teacher”, encouraging the poisoned model to align its feature representations with clean behavior. Comprehensive experimental results demonstrate that our scheme achieves high accuracy in detecting poisoned models and labels, even with limited access to clean samples. Furthermore, our scheme provides effective backdoor purification, while preserving the integrity and performance of models.},
  archive      = {J_PR},
  author       = {Lin Huang and Leo Yu Zhang and Ching-Chun Chang and Wei Wang and Chuan Qin},
  doi          = {10.1016/j.patcog.2025.112336},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112336},
  shortjournal = {Pattern Recognition},
  title        = {Backdoor defense based on adversarial prediction proximity and contrastive knowledge distillation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hyperspectral space transformations for texture classification. <em>PR</em>, <em>172</em>, 112335. (<a href='https://doi.org/10.1016/j.patcog.2025.112335'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D color space transformations are widely used in color imaging to enhance the results of various tasks, including image segmentation, object recognition, and texture classification. However, such useful transformations are much more limited in hyperspectral imaging, where images contain hundreds to thousands of spectral bands. To improve the performance of hyperspectral image analysis, we introduce four new hyperspectral space transformations in this paper: the Hyper-Chrominance-Luminance (H-CL), the Hyper-Hue-Chroma-Luminance (H-HCL), the Hyper-Hue-Saturation-Intensity (H-HSI), and the Hyper-Hue-Saturation-Value (H-HSV). These transformations extend the corresponding CL, HCL, HSI, and HSV 3D color spaces to multiple dimensions. To investigate their suitability in the context of texture classification, several well-known texture descriptors, including both theory-driven (handcrafted) and data-driven (deep learning) methods, are used in the experiments. Ten hyperspectral datasets are considered: HyTexila, SpecTex, HyperPlastic, and seven datasets extracted from the Timbers database. Among these datasets, six new ones are introduced in this paper. The proposed H-CL, H-HCL, H-HSI, and H-HSV transformations are also compared with state-of-the-art transformation strategies. The experiments conducted in this paper demonstrate the efficacy of the proposed space transformations with an accuracy improvement that can reach +43.47 %.},
  archive      = {J_PR},
  author       = {Alice Porebski and Souraya Ouaidar Hadir and Thierry Gensane and Nicolas Vandenbroucke},
  doi          = {10.1016/j.patcog.2025.112335},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112335},
  shortjournal = {Pattern Recognition},
  title        = {Hyperspectral space transformations for texture classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-target federated backdoor attack based on feature aggregation. <em>PR</em>, <em>172</em>, 112333. (<a href='https://doi.org/10.1016/j.patcog.2025.112333'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current federated backdoor attacks focus on collaboratively training backdoor triggers, where multiple compromised clients train their local trigger patches and then merge them into a global trigger during the inference phase. However, these methods require careful design of the shape and position of trigger patches and lack the feature interactions between trigger patches during training, resulting in poor backdoor attack success rates. Moreover, the pixels of the patches remain untruncated, thereby making abrupt areas in backdoor examples easily detectable by the detection algorithm. To this end, we propose a novel benchmark for the federated backdoor attack based on feature aggregation. Specifically, we align the dimensions of triggers with images, constrain the trigger’s pixel boundaries so that it is within a small range to avoid being detected, and aggregate trigger features from multiple compromised clients to enhance the global trigger’s ability to capture distributed data patterns. Furthermore, leveraging the intra-class attack strategy to train specific triggers for each class of samples, we propose the simultaneous generation of backdoor triggers for all target classes, significantly reducing the overall production time for triggers across all target classes and increasing the risk of the federated model being attacked. Experiments demonstrate that our method can not only bypass the detection of defense methods while patch-based methods fail, but also achieve a zero-shot backdoor attack with a success rate of 77.39 %. To the best of our knowledge, our work is the first to implement such a zero-shot attack in federated learning. Finally, we evaluate attack performance by varying the trigger’s training factors, including poison location, ratio, pixel bound, and trigger training duration (local epochs and communication rounds).},
  archive      = {J_PR},
  author       = {Lingguag Hao and Kuangrong Hao and Bing Wei and Xue-Song Tang},
  doi          = {10.1016/j.patcog.2025.112333},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112333},
  shortjournal = {Pattern Recognition},
  title        = {Multi-target federated backdoor attack based on feature aggregation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LayerMix: Enhanced data augmentation for robust deep learning. <em>PR</em>, <em>172</em>, 112332. (<a href='https://doi.org/10.1016/j.patcog.2025.112332'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) models have demonstrated remarkable performance across various computer vision tasks, yet their vulnerability to distribution shifts remains a critical challenge. Despite sophisticated neural network architectures, existing models often struggle to maintain consistent performance when confronted with Out-of-Distribution (OOD) samples, including natural corruptions, adversarial perturbations, and anomalous patterns. We introduce LayerMix, an innovative Data Augmentation (DA) approach that systematically enhances model robustness through structured fractal-based image synthesis. By meticulously integrating structural complexity into training datasets, our method generates semantically consistent synthetic samples that significantly improve neural network generalization capabilities. Unlike traditional augmentation techniques that rely on random transformations, LayerMix employs a structured mixing pipeline that preserves original image semantics while introducing controlled variability. Extensive experiments across multiple benchmark datasets, including CIFAR-10, CIFAR-100, ImageNet-200, and ImageNet-1K demonstrate LayerMix’s superior performance in classification accuracy and substantially enhances critical Machine Learning (ML) safety metrics, including resilience to natural image corruptions, robustness against adversarial attacks, improved model calibration and enhanced prediction consistency. LayerMix represents a significant advancement toward developing more reliable and adaptable artificial intelligence systems by addressing the fundamental challenges of DL generalization. The code is available at https://github.com/ahmadmughees/layermix .},
  archive      = {J_PR},
  author       = {Hafiz Mughees Ahmad and Dario Morle and Afshin Rahimi},
  doi          = {10.1016/j.patcog.2025.112332},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112332},
  shortjournal = {Pattern Recognition},
  title        = {LayerMix: Enhanced data augmentation for robust deep learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A query-driven twin network framework with optimization-based meta-learning for few-shot hyperspectral image classification. <em>PR</em>, <em>172</em>, 112331. (<a href='https://doi.org/10.1016/j.patcog.2025.112331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has achieved remarkable results in hyperspectral image (HSI) classification due to its powerful deep feature extraction and nonlinear relationship processing capabilities. However, the success of deep learning methods is largely dependent on extensive labeled samples, which is both time-consuming and labor-intensive. To address this issue, a novel query-driven meta-learning twin network (QMTN) framework is proposed for HSI few-shot learning. QMTN uses two meta-learning channels, allowing for the comprehensive learning of meta-knowledge across diverse meta-tasks and enhancing learning efficiency. Within the QMTN framework, a lightweight spectral-spatial attention residual network is proposed for extraction of HSI features. The network incorporates a residual mechanism in both spectral and spatial feature extraction processes and includes an attention block to improve network performance by focusing on key locations in the spatial features. To maximize the use of the limited samples for constructing diverse meta-tasks, two meta-task generation approaches are employed, with and without simulated noise. Experiments on three public HSI datasets demonstrate that the QMTN framework effectively reduces the dependence on labeled samples in a single scene and significantly improves the classification performance and convergence of the internal network. The meta-task generation method with simulated noise can improve the classification performance of the QMTN.},
  archive      = {J_PR},
  author       = {Jian Zhu and Pengxin Wang and Jian Hui and Xin Ye},
  doi          = {10.1016/j.patcog.2025.112331},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112331},
  shortjournal = {Pattern Recognition},
  title        = {A query-driven twin network framework with optimization-based meta-learning for few-shot hyperspectral image classification},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reliable classification through rank-based conformal prediction sets. <em>PR</em>, <em>172</em>, 112330. (<a href='https://doi.org/10.1016/j.patcog.2025.112330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning classification tasks often benefit from predicting a set of possible labels with confidence scores to capture uncertainty. However, existing methods struggle with the high-dimensional nature of the data and the lack of well-calibrated probabilities from modern classification models. We propose a novel conformal prediction method that utilizes a rank-based score function suitable for classification models that predict the order of labels correctly, even if not well-calibrated. Our approach constructs prediction sets that achieve the desired coverage rate while managing their size. We provide a theoretical analysis of the expected size of the conformal prediction sets based on the rank distribution of the underlying classifier. Through extensive experiments, we demonstrate that our method outperforms existing techniques on various datasets, providing reliable uncertainty quantification. Our contributions include a novel conformal prediction method, theoretical analysis, and empirical evaluation. This work advances the practical deployment of machine learning systems by enabling reliable uncertainty quantification.},
  archive      = {J_PR},
  author       = {Rui Luo and Zhixin Zhou},
  doi          = {10.1016/j.patcog.2025.112330},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112330},
  shortjournal = {Pattern Recognition},
  title        = {Reliable classification through rank-based conformal prediction sets},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised domain adaptation for cardiac MRI segmentation via adversarial learning in latent space. <em>PR</em>, <em>172</em>, 112328. (<a href='https://doi.org/10.1016/j.patcog.2025.112328'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) imaging is crucial for visualizing myocardial infarction (MI), with accurate segmentation of the ventricles and myocardium being essential for effective MI treatment. However, due to the complex myocardial structure and the limited availability of pixel-level annotations in LGE CMR images, accurate segmentation using supervised deep learning methods remains challenging. To address this, we propose an unsupervised domain adaptation framework for LGE CMR segmentation, utilizing CMR images from other modalities. First, we transform balanced Steady-State Free Precession (bSSFP) CMR images, which have abundant annotations, into LGE-like images using an enhanced CycleGAN. This CycleGAN incorporates an adversarial sample mining technique in the latent space to improve the quality of synthetic images. Next, we modify the nnU-Net architecture by introducing non-local blocks to train on these synthetic images, enabling precise segmentation of the myocardium and ventricular regions. We evaluate our method on the MS-CMRSeg 2019 dataset and MyoPS 2020 dataset, achieving an average Dice score of 88.0 % and 82.6 % respectively. Our experimental results demonstrate superior performance compared to state-of-the-art methods. The code for our approach is available at https://github.com/Lucarqi/Adv-CycleGAN .},
  archive      = {J_PR},
  author       = {Fan Zheng and Hengfei Cui and Yanning Zhang and Yong Xia},
  doi          = {10.1016/j.patcog.2025.112328},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112328},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised domain adaptation for cardiac MRI segmentation via adversarial learning in latent space},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficacy of varying sensing features for enhanced performance of deep-learning-informed multidimensional force platform. <em>PR</em>, <em>172</em>, 112327. (<a href='https://doi.org/10.1016/j.patcog.2025.112327'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL)-informed vision-based 3D force platforms have demonstrated significant potential for simultaneous assessment of pressure and shear stresses. However, the enhancement of force decoupling capacity is widely recognized as a difficult challenge in the field. For vision-based designs, the marker-embedded sensing layer serves as the pivotal element of the force platform, unveiling diverse sensing characteristics throughout the learning process. However, none of the previous studies have thoroughly investigated the differences among these sensing features and leveraged them to optimize DL models for enhanced performance in multidimensional force detection. This study addresses this gap by systematically evaluating five distinct features (including optical flow, original images, and their derivatives) using four classic CNN architectures. Our comparative analysis reveals a clear feature-force specialization: gray images are most effective for pressure decoupling, while arrow images are superior in decoupling shear stress. Based on this finding, we proposed and validated a dual-branch DL model that fuses these two specialized features. The model achieves a strong, comprehensive performance on both tasks simultaneously, demonstrating the efficacy of our evidence-based feature-fusion strategy. This study provides new insights into sensing feature selection and evidence-based neural network design for vision-based multidimensional force platforms. These advancements have the potential to expedite the deployment of high-performance multidimensional force platforms in real-life applications.},
  archive      = {J_PR},
  author       = {Hu Luo and Yuxin Ma and Zesheng Wang and Jiewen Li and Xin Ma and Wen-Ming Chen},
  doi          = {10.1016/j.patcog.2025.112327},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112327},
  shortjournal = {Pattern Recognition},
  title        = {Efficacy of varying sensing features for enhanced performance of deep-learning-informed multidimensional force platform},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TP-LReID: Lifelong person re-identification using text prompts. <em>PR</em>, <em>172</em>, 112326. (<a href='https://doi.org/10.1016/j.patcog.2025.112326'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong person re-identification (LReID) aims to develop a single model that is capable of continuously learning from new domain (present) while retaining knowledge from previously encountered ones (past) and generalizing to unseen domains (future). However, distribution shifts across these domains pose a significant challenge in maintaining performance across past, present, and future domains, that is, causing the catastrophic forgetting on previously seen domains and limited generalization to unseen ones. To address the above issues, we propose to guide consistent feature extraction to bridge distribution shifts using text prompts designed to remain invariant across domains. First, identity-consistent text prompts capturing high-level image semantics are extracted and aligned with image features throughout the lifelong learning pipeline. Moreover, to enhance generalization to unseen domains, we introduce an adversarial training that text features are contrastively aligned with both original and future-style image features, the latter generated by applying gradient-based perturbations in the feature space. Compared with 21 representative models on 11 benchmark datasets, our proposed model, trained without access to historical data, achieves performance comparable to the model trained using a joint training approach, and it performs well on all of the past, present, and future domains. We further explored the forgetting of the first historical domain and the generalization to all unseen domains under all 24 orders, and the results confirmed the superiority of our model. Codes will be released if this paper is accepted.},
  archive      = {J_PR},
  author       = {Zhaoshuo Liu and Zhiwei Guo and Chaolu Feng and Wei Li and Kun Yu and Jun Hu and Jinzhu Yang},
  doi          = {10.1016/j.patcog.2025.112326},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112326},
  shortjournal = {Pattern Recognition},
  title        = {TP-LReID: Lifelong person re-identification using text prompts},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Zoom-shot: Fast, efficient and unsupervised zero-shot knowledge transfer from CLIP to vision encoders. <em>PR</em>, <em>172</em>, 112323. (<a href='https://doi.org/10.1016/j.patcog.2025.112323'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models like CLIP demonstrate exceptional capabilities over a broad domain of knowledge, such as with zero-shot classification; however, they also require significant computational resources, narrowing their real-world utility. Recent studies have shown that mapping features from pre-trained vision encoders into CLIP’s latent space can transfer some of CLIP’s abilities to smaller vision encoders, offering a promising alternative. Yet, the performance of these vision encoders still falls short of CLIP’s native capabilities, particularly in low-data regimes. In this work, we argue that enhancing training data coverage/diversity significantly improves mapping efficacy. We achieve this using tailored loss functions rather than relying on data augmentation or increasing training samples. For instance, we exploit the inherent multimodal nature of CLIP’s latent space, by incorporating cycle-consistency loss as one of our loss functions. Moreover, the mapping is learned using entirely unlabelled and unpaired data, eliminating the need for manual labelling or data pairing in novel domains. From these findings, our resulting method (Zoom-shot) offers a viable path to flexible zero-shot models for resource-limited, data-scarce settings. We test Zoom-shot’s zero-shot performance across various pre-trained vision encoders on coarse- and fine-grained datasets and achieve superior performance compared to recent works. In our ablations, we find Zoom-shot allows for a trade-off between data and compute during training; allowing for a significant reduction in required training data. All code and models are available on GitHub.},
  archive      = {J_PR},
  author       = {Jordan Shipard and Arnold Wiliem and Kien Nguyen Thanh and Wei Xiang and Clinton Fookes},
  doi          = {10.1016/j.patcog.2025.112323},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112323},
  shortjournal = {Pattern Recognition},
  title        = {Zoom-shot: Fast, efficient and unsupervised zero-shot knowledge transfer from CLIP to vision encoders},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Wavelet-guided diffusion enhancement network with directional learning for single-pixel imaging. <em>PR</em>, <em>172</em>, 112322. (<a href='https://doi.org/10.1016/j.patcog.2025.112322'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-pixel imaging provides significant advantages for non-visible wavelength detection and ultra-compressed sensing. However, accurate reconstruction from severely under-sampled measurements remains challenging. To tackle this, we propose a novel wavelet-guided diffusion enhancement network with directional learning for single-pixel imaging (WGDNet), which hierarchically reconstructs images through wavelet component-aware reinforcement. Specifically, we design a sampling-guided model to capture essential textures and produce an initial image decomposed into high- and low-frequency components. The low-frequency part is enhanced with adaptive diffusion to preserve structure, while the high-frequency part is directionally incorporated through a multi-frequency adaptive fusion attention (MAFA) mechanism to refine details. Building on this, we develop a residual spatial adaptive fusion (RSAF) module to effectively combine low-frequency structures and high-frequency details. Extensive experiments on five public datasets demonstrate that our method achieves superior performance in both structural preservation and detail recovery. Successful implementation in the imaging system validates the applicability in real scenarios.},
  archive      = {J_PR},
  author       = {Dawei Song and Qiurong Yan and Hui Wang and Jian Yang and Xiaolong Luo},
  doi          = {10.1016/j.patcog.2025.112322},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112322},
  shortjournal = {Pattern Recognition},
  title        = {Wavelet-guided diffusion enhancement network with directional learning for single-pixel imaging},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical community-based graph generation model for improving structural diversity. <em>PR</em>, <em>172</em>, 112320. (<a href='https://doi.org/10.1016/j.patcog.2025.112320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph generation remains a challenging task due to the high dimensionality of graphs and the complex dependencies among their edges. Existing models often struggle to produce structurally diverse graphs. To address this limitation, we propose a novel generative framework specifically designed to capture structural diversity in graph generation. Our approach follows a sequential process: initially, a community detection algorithm partitions the input graph into distinct communities. Each community is then generated independently using deep generative models, while a dedicated module concurrently learns the interconnections between communities. To scale to graphs with a larger number of communities, we extend our approach into a hierarchical generative model. The proposed framework not only improves generation accuracy but also significantly reduces generation time for large-scale graphs. Moreover, it enables the application of prior methods that were previously incapable of handling such graphs. To highlight the shortcomings of existing approaches, we conduct experiments on a synthetic dataset comprising diverse graph structures. The results demonstrate substantial improvements in standard evaluation metrics as well as in the quality of the generated graphs.},
  archive      = {J_PR},
  author       = {Masoomeh Sadat Razavi and Abdolreza Mirzaei and Mehran Safayani},
  doi          = {10.1016/j.patcog.2025.112320},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112320},
  shortjournal = {Pattern Recognition},
  title        = {Hierarchical community-based graph generation model for improving structural diversity},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GLGF-CR: A gated local-global fusion approach for cloud removal in real-world remote sensing. <em>PR</em>, <em>172</em>, 112319. (<a href='https://doi.org/10.1016/j.patcog.2025.112319'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical satellite imagery is a critical data source for Earth observation in remote sensing. However, cloud cover often degrades image quality, hindering its application and analysis. Therefore, effective cloud removal from optical satellite images has become a prominent research direction. In real-world scenarios, thick clouds act as pure noise, completely obscuring underlying information, while thin clouds provide partially beneficial information that can be leveraged for reconstruction. Traditional cloud removal methods often fail to distinguish between these two types of noise, leading to suboptimal performance. To address this limitation, we propose a novel cloud removal model, GLGF-CR, which incorporates a Gated Local-Global Fusion module. This module is designed to effectively separate and process the distinct characteristics of thick and thin clouds. For thick clouds, which contain no recoverable information, the model focuses on robust reconstruction using complementary data sources. For thin clouds, the model extracts and utilizes the beneficial information embedded in the partially obscured regions, enabling more accurate and detailed reconstruction. Additionally, a Dual Cross-Attention mechanism is introduced to establish robust mappings between SAR and optical modalities, further improving fusion accuracy. To handle domain shifts between source and target domains, we incorporate a domain adaptation module, which enhances the model’s ability to generalize across diverse real-world scenarios. The proposed algorithm not only outperforms existing methods on the large-scale real-world dataset SEN12MS-CR but also demonstrates strong cross-domain transferability on the Henan flood dataset. By explicitly addressing the dual nature of cloud noise–pure noise in thick clouds and partially beneficial information in thin clouds–this work advances the field of beneficial noise learning, demonstrating how noise can be systematically analyzed and utilized to improve model performance in complex scenarios.},
  archive      = {J_PR},
  author       = {Ganchao Liu and Jiawei Qiu and Jincheng Huang and Yuan Yuan},
  doi          = {10.1016/j.patcog.2025.112319},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112319},
  shortjournal = {Pattern Recognition},
  title        = {GLGF-CR: A gated local-global fusion approach for cloud removal in real-world remote sensing},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semi-supervised feature selection with concept factorization and robust label learning. <em>PR</em>, <em>172</em>, 112317. (<a href='https://doi.org/10.1016/j.patcog.2025.112317'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is essential for improving model performance in high-dimensional data by identifying the most relevant features. Concept Factorization (CF), building on Non-negative Matrix Factorization (NMF), is valued for revealing meaningful data structure and producing interpretable concept vectors. However, existing CF-based FS methods are typically unsupervised and do not leverage label information, leading to a bias toward high-variance features. This bias can result in the omission of low-variance features that may be highly discriminative, ultimately reducing the effectiveness of FS and compromising model performance, especially in tasks where subtle or rare patterns are important. To address these limitations, this paper proposes SCFLR, a novel semi-supervised FS method that combines CF with robust label learning. SCFLR establishes the CF framework based on the feature space by expressing each concept vector as a conic combination of the feature vectors, thereby leveraging both the underlying data structure and available label information to select a more informative and balanced set of features. To this end, SCFLR defines a linear regression-based loss function derived from the generated concept vectors to leverage information from labeled data. This loss function is further enhanced through a label learning framework based on the L 2 , 1 -norm to ensure a robust label approximation. SCFLR also utilizes the dual-graph regularization to maintain the local geometric structures in both feature and data spaces. In order to tackle the optimization problem of SCFLR, an efficient algorithm, with proof of its convergence, is introduced. Finally, the experimental validation of the SCFLR method on multiple datasets highlights its effectiveness and superior performance compared to other FS methods.},
  archive      = {J_PR},
  author       = {Razieh Sheikhpour and Farid Saberi-Movahed and Mahdi Jalili and Kamal Berahmand},
  doi          = {10.1016/j.patcog.2025.112317},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112317},
  shortjournal = {Pattern Recognition},
  title        = {Semi-supervised feature selection with concept factorization and robust label learning},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep learning for DBT classification with saliency-guided 2D synthesis. <em>PR</em>, <em>172</em>, 112316. (<a href='https://doi.org/10.1016/j.patcog.2025.112316'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital Breast Tomosynthesis (DBT) is a key imaging modality for breast cancer detection, improving lesion visibility by reducing tissue overlap inherent in conventional mammography. In this work, we propose a novel deep learning framework that classifies DBT volumes as malignant or non-malignant, while simultaneously generating a synthetic 2D image to assist diagnostic interpretation. This image is derived from a 3D saliency map computed by the internal attention mechanisms of the model, which highlights and preserves the most diagnostically relevant regions from the original volume. A surface is defined in this saliency space, enabling sampling and projection into a 2D diagnostic representation. This projection offers a compact summary of the volumetric scan, assisting clinicians in diagnostic interpretation and potentially alleviating the cognitive workload. A standard convolutional neural network trained on these synthetic 2D images achieves classification performance comparable to models operating directly on full 3D volumes. We train and evaluate our method on the OPTIMAM dataset and assess generalization through external validation on the independent BCS-DBT dataset without retraining. Results show that the model performs robustly across different clinical sources and provides an interpretable, computationally efficient tool for DBT-based breast cancer diagnosis.},
  archive      = {J_PR},
  author       = {Marco Cantone and Ciro Russo and Federico~V.~L. Dell’Ascenza and Claudio Marrocco and Alessandro Bria},
  doi          = {10.1016/j.patcog.2025.112316},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112316},
  shortjournal = {Pattern Recognition},
  title        = {Deep learning for DBT classification with saliency-guided 2D synthesis},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Noise-tolerant scheme and explicit regularizer for deep active learning with noisy oracles. <em>PR</em>, <em>172</em>, 112313. (<a href='https://doi.org/10.1016/j.patcog.2025.112313'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring the query strategies based on deep learning shows promising results in terms of designing the criteria for active learning. However, the labels provided by the oracles might be noisy (inaccurate) due to similarities across several classes causing ambiguity, leading to unreliable results. To address this issue, we propose a noise-tolerant deep active learning method. Specifically, we design a consistency regularization for deep attention network as explicit regularizer, which is used to measure the uncertainty of examples. Besides, we develop the robust model for dealing with the noisy oracles , which first take the associations that make from embeddings of labeled data to those of unlabeled data and back, then we employ the association probability as a weighting fusion schema into angular margin based loss. Moreover, we design the submodular maximization function for reducing the redundancy of selected batch examples. Finally, the formulation is encapsulated into the multi-task framework that helps to adaptive learning towards more generalizable performance. Experimentally, we conduct extensive experiments on classification and segmentation tasks, and the results clearly demonstrate the superiority of the proposed method to the existing state-of-the-art deep active learning approaches.},
  archive      = {J_PR},
  author       = {Yanchao Li and Ziteng Xie and Hongwu Zhong and Guangwei Gao},
  doi          = {10.1016/j.patcog.2025.112313},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112313},
  shortjournal = {Pattern Recognition},
  title        = {Noise-tolerant scheme and explicit regularizer for deep active learning with noisy oracles},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Linguistic query-guided mask generation for referring image segmentation. <em>PR</em>, <em>172</em>, 112306. (<a href='https://doi.org/10.1016/j.patcog.2025.112306'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring image segmentation aims to segment the image region of interest according to the given language expression, which is a typical multi-modal task. Existing methods either adopt the pixel classification-based or the learnable query-based framework for mask generation, both of which are insufficient to deal with various text-image pairs with a fix number of parametric prototypes. The motivation of this work is to propose an end-to-end framework built on transformer to perform Linguistic query-Guided mask generation, dubbed LGFormer. It views the linguistic features as query to generate a specialized prototype for arbitrary input image-text pair, thus generating more consistent segmentation results. Moreover, we design several cross-modal interaction modules (e.g. vision-language bidirectional attention module, VLBA) in both encoder and decoder to achieve better cross-modal alignment. Extensive experiments demonstrate that our LGFormer achieves a new state-of-the-art performance on ReferIt, RefCOCO+, and RefCOCOg by large margins. Code is available at https://github.com/mqchen1993/LGFormer .},
  archive      = {J_PR},
  author       = {Zhichao Wei and Xiaohao Chen and Mingqiang Chen and Hao Li and Zilong Dong and Siyu Zhu},
  doi          = {10.1016/j.patcog.2025.112306},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112306},
  shortjournal = {Pattern Recognition},
  title        = {Linguistic query-guided mask generation for referring image segmentation},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TransSTC: Transformer tracker meets efficient spatial-temporal cues. <em>PR</em>, <em>172</em>, 112303. (<a href='https://doi.org/10.1016/j.patcog.2025.112303'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, researchers have started developing trackers using the powerful global modeling capabilities of transformer networks. However, existing transformer trackers usually model all template spatial cues indiscriminately and ignore temporal cues of target state changes. This distracts the tracker’s attention and gradually fails to understand the target’s latest state. Therefore, we propose a new tracker called TransSTC, which explores the effective spatial cues in the template and temporal cues during tracking to improve the tracker’s performance. Specifically, we design the target-aware focused coding network to emphasize the efficient spatial cues in the templates, alleviating the impact of spatial cues with low associations of targets in templates on the tracker’s localization accuracy. Additionally, we employ the multi-temporal template update structure that accurately captures variations in the target’s appearance. Within this structure, the collected samples are assessed for target appearance similarity and environmental interference, followed by a three-level sample selection process to ensure the accurate template update. Finally, we introduce the motion constraint framework to dynamically adjust the classification results based on the target’s historical motion trajectory. Extensive experimental results on seven tracking benchmarks demonstrate that TransSTC achieves competitive tracking performance.},
  archive      = {J_PR},
  author       = {Hong Zhang and Wanli Xing and Yifan Yang and Hanyang Liu and Ding Yuan},
  doi          = {10.1016/j.patcog.2025.112303},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112303},
  shortjournal = {Pattern Recognition},
  title        = {TransSTC: Transformer tracker meets efficient spatial-temporal cues},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MGFNet: Multi-granularity medical pattern fusion network for patient risk prediction. <em>PR</em>, <em>172</em>, 112302. (<a href='https://doi.org/10.1016/j.patcog.2025.112302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of patient risk prediction tasks is to predict a patient’s future disease or mortality risk based on his/her historical electronic health record (EHR). Most prior works focus on learning patient evolution patterns from longitudinal EHR data, while ignoring the differences in temporal granularity in medical data, resulting in insufficient information exploitation. To address these limitations, we propose the M ulti- G ranularity Medical Pattern F usion Net work (MGFNet) for patient risk prediction based on temporal data. It learns the evolutionary patterns of medical data at different temporal granularities (both at the vital sign-level and visit-level), and introduces a gated filtering function and a contrastive learning strategy for multi-granularity fusion, which captures fused information from different temporal granularities and supervises each other to obtain a more effective information representation. In addition, for patients with variable visit lengths, we introduce a soft curriculum learning method to learn these patterns by assigning different weights to medical samples to improve prediction accuracy. The final experimental results demonstrate that MGFNet effectively improves the performance of risk prediction compared with state-of-the-art approaches.},
  archive      = {J_PR},
  author       = {Lin Cheng and Yuliang Shi and Xiaojing Yu and Xinyu Li and Xinjun Wang and Zhongmin Yan and Zhiyong Chen},
  doi          = {10.1016/j.patcog.2025.112302},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112302},
  shortjournal = {Pattern Recognition},
  title        = {MGFNet: Multi-granularity medical pattern fusion network for patient risk prediction},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning multi-scale spatial-frequency features for image denoising. <em>PR</em>, <em>172</em>, 112300. (<a href='https://doi.org/10.1016/j.patcog.2025.112300'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in multi-scale architectures have demonstrated exceptional performance in image denoising tasks. However, existing architectures mainly depends on a fixed single-input single-output Unet architecture, ignoring the multi-scale representations of pixel level. In addition, previous methods treat the frequency domain uniformly, ignoring the different characteristics of high-frequency and low-frequency noise. In this paper, we propose a novel multi-scale adaptive dual-domain network (MADNet) for image denoising. We use image pyramid inputs to restore noise-free results from low-resolution images. In order to realize the interaction of high-frequency and low-frequency information, we design an adaptive spatial-frequency learning unit (ASFU), where a learnable mask is used to separate the information into high-frequency and low-frequency components. In the skip connections, we design a global feature fusion block to enhance the features at different scales. Extensive experiments on both synthetic and real noisy image datasets verify the effectiveness of MADNet compared with current state-of-the-art denoising approaches.},
  archive      = {J_PR},
  author       = {Xu Zhao and Chen Zhao and Xiantao Hu and Hongliang Zhang and Ying Tai and Jian Yang},
  doi          = {10.1016/j.patcog.2025.112300},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112300},
  shortjournal = {Pattern Recognition},
  title        = {Learning multi-scale spatial-frequency features for image denoising},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep intrinsic image decomposition via physics-aware neural networks. <em>PR</em>, <em>172</em>, 112299. (<a href='https://doi.org/10.1016/j.patcog.2025.112299'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrinsic image decomposition (IID) aims to separate an observed image into its underlying reflectance and shading components. This task is challenging due to the complex interplay of lighting, surface geometry, and material reflectance in real-world scenes. To address these challenges, this paper proposes a physics-aware deep neural network with a single-encoder, double-decoder architecture. The encoder incorporates an explicit alternating process inspired by a physics-guided model, enabling iterative decoupling of image features into reflectance and shading. Two asymmetric decoders are designed to reconstruct reflectance and shading maps based on their distinct properties. In addition, we introduce a shading loss function leverages spatial distributions of texture and structure. Unlike standard total variation (TV) losses, it employs a texture-likelihood-weighted TV norm, where weights are derived via a patch-matching scheme to distinguish isotropic textures from anisotropic image edges. This design enhances the model’s ability to suppress texture while preserving structure. Experimental results on three datasets (MIT, MPI-Sintel, and IIW) show the effectiveness of our method: on MIT and MPI-Sintel, it reduces the mean-squared-errors of both reflectance and shading by over 40 % compared to existing works, and on IIW, it achieves a superior WHDR score of 13.2, outperforming all existing methods.},
  archive      = {J_PR},
  author       = {Yan Huang and Kangjie Liu and Tengyue Chen and Yong Xu and Hui Ji},
  doi          = {10.1016/j.patcog.2025.112299},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112299},
  shortjournal = {Pattern Recognition},
  title        = {Deep intrinsic image decomposition via physics-aware neural networks},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Domain adapter for visual object tracking based on hyperspectral video. <em>PR</em>, <em>172</em>, 112296. (<a href='https://doi.org/10.1016/j.patcog.2025.112296'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object tracking based on hyperspectral video attracts increasing attention due to the rich material and motion information in the hyperspectral videos. The prevailing hyperspectral methods adapt pretrained RGB-based object tracking networks for hyperspectral tasks by converting the hyperspectral images into false-color images and fine-tuning the whole network on hyperspectral datasets, which achieves impressive results in challenging scenarios. However, the performance of hyperspectral trackers is limited by the spectral information loss during the transformation, and fine-tuning the entire pretrained network is inefficient for practical applications. To address the issues, a new hyperspectral object tracking method based on domain adaption, hyperspectral adapter for tracking (HyA-T), is proposed in this work. The hyperspectral adapter for the self-attention (HAS) and the hyperspectral adapter for the multilayer perceptron (HAM) are proposed to generate the adaption information and to transfer the multi-head self-attention (MSA) module and the multilayer perceptron (MLP) in pretrained network for the hyperspectral object tracking task by augmenting the spectral information in the original hyperspectral images into the calculation of the MSA and MLP. Additionally, the hyperspectral enhancement of input (HEI) is proposed to augment the original spectral information into the input of the tracking network. The proposed methods extract spectral information directly from the hyperspectral images, which reduce the negative impact of the spectral information loss caused by the transformation. Moreover, only the parameters in the proposed methods are fine-tuned, which is more efficient than the existing methods. Extensive experiments were conducted on four datasets with various spectral bands, verifying the effectiveness of the proposed methods. The HyA-T achieves state-of-the-art performance on all the datasets.},
  archive      = {J_PR},
  author       = {Long Gao and Yunhe Zhang and Langkun Chen and Yan Jiang and Gang He and Weiying Xie and Yunsong Li},
  doi          = {10.1016/j.patcog.2025.112296},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112296},
  shortjournal = {Pattern Recognition},
  title        = {Domain adapter for visual object tracking based on hyperspectral video},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Few-shot image generation via information transfer from the built geodesic surface. <em>PR</em>, <em>172</em>, 112293. (<a href='https://doi.org/10.1016/j.patcog.2025.112293'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models trained with limited data often struggle with poor fidelity and diversity. While adapting large pre-trained models is a common solution, such an approach requires significant resources and suitable source domains, which are often unavailable. To address these limitations, we propose Information Transfer from the Built Geodesic Surface (ITBGS), a framework that generates high-quality images from scratch. The core of ITBGS is our Feature Augmentation on Geodesic Surface (FAGS) module, which constructs a Geodesic surface to create a diverse pseudo-source domain from the initial samples. By transferring structural information from the augmented domain to guide the generator’s training, our method completely removes the need for pre-trained models. To refine the output, a supporting Interpolation and Regularization (I&R) module is also introduced to enhance the smoothness and perceptual quality of generated images. Extensive experiments demonstrate that ITBGS achieves state-of-the-art or comparable performance on various few-shot datasets, successfully balancing image fidelity and diversity.},
  archive      = {J_PR},
  author       = {Yuexing Han and Liheng Ruan and Bing Wang},
  doi          = {10.1016/j.patcog.2025.112293},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112293},
  shortjournal = {Pattern Recognition},
  title        = {Few-shot image generation via information transfer from the built geodesic surface},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FADMB: Fully attention-based dual memory bank network for weakly supervised video anomaly detection. <em>PR</em>, <em>172</em>, 112288. (<a href='https://doi.org/10.1016/j.patcog.2025.112288'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection is crucial for analyzing surveillance videos and plays a significant role in maintaining public safety. Recent advances in weakly supervised methods, utilizing video-level labels, have improved performance based on techniques like multi-instance learning and temporal modeling. Furthermore, memory banks demonstrate great potential in unsupervised anomaly detection, prompting their integration into weakly supervised setups. However, these methods depend on the Top- k selection mechanism to update the prototypes within memory banks, which has limitations such as overlooking valuable prototypes, leading to a biased updating process, and requiring hyperparameters. To tackle these challenges, we introduce a novel video anomaly detection model, FADMB ( F ully A ttention-based D ual M emory B ank network), which replaces the Top- k selection mechanism with an innovative attention-based prototype updating paradigm to obtain a more comprehensive and robust memory bank. Additionally, we design a Hybrid Encoder that encodes local and global temporal information to produce superior video representations. Extensive experiments demonstrate the superiority of FADMB, achieving 85.79 % AUC on UCF-Crime dataset and 83.29 % AP on XD-Violence dataset.},
  archive      = {J_PR},
  author       = {Zhiming Luo and Shuheng Huang and Kun Yang and Jianzhe Gao and Shaozi Li},
  doi          = {10.1016/j.patcog.2025.112288},
  journal      = {Pattern Recognition},
  month        = {4},
  pages        = {112288},
  shortjournal = {Pattern Recognition},
  title        = {FADMB: Fully attention-based dual memory bank network for weakly supervised video anomaly detection},
  volume       = {172},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="ras">RAS - 4</h2>
<ul>
<li><details>
<summary>
(2026). Neuromorphic visuotactile slip perception for robotic manipulation. <em>RAS</em>, <em>195</em>, 105191. (<a href='https://doi.org/10.1016/j.robot.2025.105191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visuotactile sensing technology has received extensive attention in the tactile sensing community due to its stable high-resolution deformation sensing capabilities. However, the existing visuotactile sensing methods are far from humanoid neural information processing mechanism. To address this gap, we propose a neuromorphic visuotactile slip detection method named VT-SNN using Tactile Address-Event Representation (TAER) encoding combined with brain-inspired Spiking Neural Network (SNN) modeling in this paper. Our extensive experimental results demonstrate that the VT-SNN achieves slip detection accuracy of 99.59% and F1 score of 99.28%, which is comparable to Artificial Neural Networks (ANNs) while exhibiting significant advantages in power dissipation and inference time. Furthermore, we deployed the VT-SNN on Intel neuromorphic computing chip–Loihi and performed closed-loop slip-feedback robotic manipulation tasks such as bottle-cap tightening and loosening. Our closed-loop neuromorphic visuotactile sensing system shows significant promise for high accuracy, low latency, and low power dissipation for robotic dexterous manipulation.},
  archive      = {J_RAS},
  author       = {Yiming Qiao and Chaofan Zhang and Shaowei Cui and Lu Cao and Zhigang Wang and Peng Wang and Shuo Wang},
  doi          = {10.1016/j.robot.2025.105191},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105191},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Neuromorphic visuotactile slip perception for robotic manipulation},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RRT-based CPC: A configuration planning method for continuum robots using rapidly-exploring random tree algorithm. <em>RAS</em>, <em>195</em>, 105190. (<a href='https://doi.org/10.1016/j.robot.2025.105190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstacle-aware configuration control represents a critical challenge in the deployment of continuum robots for advanced applications such as robotic-assisted laparoscopic surgery and intelligent industrial grasping systems. At present, in order to realize the obstacle avoidance function of flexible robots, inverse kinematic calculations are usually unavoidable. The problems of large amount of computation, long solution time, and non-convergence of results make the configuration control for flexible robots still challenging. Most of the current studies use the inverse kinematics calculation of end tracking, and for flexible robots with multiple degrees of freedom, the success rate of obstacle avoidance is low and the computational cost is large. In this paper, a three-segment continuum configuration planning method based on Rapidly-exploring Random Tree (RRT) algorithm is proposed, in which the rough obstacle avoidance path is obtained by RRT algorithm, then the three-segment fitting is carried out by using the second-order Bézier curve, and the length error is evaluated to meet the planning requirements. Experiments such as obstacle avoidance tests, the arrival of target endpoints at different positions and different obstacle environments show that the proposed method can effectively map the feasible solution to the actual configuration. Compared with the inverse kinematics method, the proposed approach improves the success rate of obtaining feasible solutions by at least 14.8% and reduces the solution time by at least 55%. In addition, no prior curvature information and traditional inverse kinematics calculation are needed for the configuration control.},
  archive      = {J_RAS},
  author       = {Qiqi Pan and Hongbo Wang and Yongfei Feng and Shijie Guo and Jingjing Luo},
  doi          = {10.1016/j.robot.2025.105190},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105190},
  shortjournal = {Robot. Auton. Syst.},
  title        = {RRT-based CPC: A configuration planning method for continuum robots using rapidly-exploring random tree algorithm},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The sequences of bundles of line segments for autonomous robots with limited vision range to escape from blind alley regions. <em>RAS</em>, <em>195</em>, 105185. (<a href='https://doi.org/10.1016/j.robot.2025.105185'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the following problem: A robot operating in a 2D environment with a limited vision range finds a path to a goal in an unknown environment containing obstacles. In this paper, we propose a novel algorithm to solve the problem. In some special cases, our algorithm is convergent with respect to ‖ . ‖ . The problem involves discovering the environmental map and blind alley regions, that are bounded by obstacles, and it provides no possible passage for robots except in and out of their path entry occur, the robot has to return back to some positions outside to escape from such regions such that the returned path is not longer than the path entry (Blind Alley Region problem, (BAR) problem, in short). To solve the (BAR) problem, sequences of bundles of line segments during the robot’s traveling are constructed in our algorithm. Some advantages of our algorithm are that (a) It reduces search space in blind alley regions because it only works on the sequences of bundles of the line segments built by the robot’s limited vision range. (b) Our algorithm ensures that the returned path to escape from the regions is not longer than the previous path of the robot. (c) Due to the construction of the sequences of bundles of line segments, our paths are not always “close” obstacles and the number of turns of such paths is smaller ones determined by other shortest path algorithms (e.g., A*, RRT*). Our algorithm is implemented in Python and we experience the algorithm on some autonomous robots with different vision ranges in real environment. We also compare our result with RRTX, a state-of-art local path-planning algorithm, and A ∗ , a basic one. The experimental results show that our algorithm provides better solutions than RRTX and A* results in some specific circumstances.},
  archive      = {J_RAS},
  author       = {Phan Thanh An and Pham Hoang Anh and Tran Thanh Binh and Tran Van Hoai},
  doi          = {10.1016/j.robot.2025.105185},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105185},
  shortjournal = {Robot. Auton. Syst.},
  title        = {The sequences of bundles of line segments for autonomous robots with limited vision range to escape from blind alley regions},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved prescribed performance control for multi-quadrotor payload transport under unknown disturbances. <em>RAS</em>, <em>195</em>, 105184. (<a href='https://doi.org/10.1016/j.robot.2025.105184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a robust and enhanced control strategy for a multi-quadrotor suspended payload system, which is characterized by complex nonlinear dynamics and unknown external disturbances. A precise dynamic model of the system is formulated using the Udwadia–Kalaba method. A distributed cooperative planning framework, based on graph theory, is employed to enable effective information exchange and cooperative control among multiple quadrotors. To mitigate the impact of unknown disturbances, such as wind fields and variations in payload mass, a disturbance observer is developed to estimate and compensate for these disturbances, thereby enhancing system robustness. Furthermore, an improved prescribed performance control method is proposed to address the issue of exceeding performance boundaries. The steady-state error of the system is effectively reduced by adaptively adjusting the prescribed performance boundary and combining it with integral backstepping, and real-time constraints on tracking errors and closed-loop stability are achieved. Simulation results validate that the proposed control strategy significantly enhances the control performance and disturbance rejection capability of the multi-quadrotor suspended payload system, demonstrating superior robustness.},
  archive      = {J_RAS},
  author       = {Xinyu Chen and Yunsheng Fan and Guofeng Wang and Dongdong Mu},
  doi          = {10.1016/j.robot.2025.105184},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105184},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Improved prescribed performance control for multi-quadrotor payload transport under unknown disturbances},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="spa">SPA - 3</h2>
<ul>
<li><details>
<summary>
(2026). Convergence of adapted smoothed empirical measures. <em>SPA</em>, <em>191</em>, 104775. (<a href='https://doi.org/10.1016/j.spa.2025.104775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adapted Wasserstein distance ( AW -distance) controls the calibration errors of optimal values in various stochastic optimization problems, pricing and hedging problems, optimal stopping problems, etc. However, statistical aspects of the AW -distance are bottlenecked by the failure of empirical measures ( Emp ) to converge under this distance. Kernel smoothing and adapted projection have been introduced to construct converging substitutes of empirical measures, known respectively as smoothed empirical measures ( S - Emp ) and adapted empirical measures ( A - Emp ). However, both approaches have limitations. Specifically, S - Emp lack comprehensive convergence results, whereas A - Emp in practical applications lead to fewer distinct samples compared to standard empirical measures. In this work, we address both of the aforementioned issues. First, we develop comprehensive convergence results of S - Emp . We then introduce a smoothed version for A - Emp , which provide as many distinct samples as desired. We refer them as AS - Emp and establish their convergence in mean, deviation and almost sure convergence. The convergence estimation incorporates two results: the empirical analysis of the smoothed adapted Wasserstein distance ( AW ( σ ) -distance) and its bandwidth effects. Both results are novel and their proof techniques could be of independent interest.},
  archive      = {J_SPA},
  author       = {Songyan Hou},
  doi          = {10.1016/j.spa.2025.104775},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104775},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Convergence of adapted smoothed empirical measures},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A tamed euler scheme for SDEs with non-locally integrable drift coefficient. <em>SPA</em>, <em>191</em>, 104772. (<a href='https://doi.org/10.1016/j.spa.2025.104772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we show that for SDEs with a drift coefficient that is non-locally integrable, one may define a tamed Euler scheme that converges in L p at rate 1 / 2 to the true solution. The taming is required in this case since one cannot expect the regular Euler scheme to have finite moments in L p . Our proof strategy involves controlling the inverse moments of the distance of scheme and the true solution to the singularity set. We additionally show that our setting applies to the case of two scalar valued particles with singular interaction kernel. To the best of the authors’ knowledge, this is the first work to prove strong convergence of an Euler-type scheme in the case of non-locally integrable drift.},
  archive      = {J_SPA},
  author       = {Tim Johnston and Sotirios Sabanis},
  doi          = {10.1016/j.spa.2025.104772},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104772},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {A tamed euler scheme for SDEs with non-locally integrable drift coefficient},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scaling limit and large deviation for 3D globally modified stochastic Navier–Stokes equations with transport noise. <em>SPA</em>, <em>191</em>, 104770. (<a href='https://doi.org/10.1016/j.spa.2025.104770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the globally modified stochastic (hyperviscous) Navier–Stokes equations with transport noise on 3D torus. We first establish the existence and pathwise uniqueness of the weak solutions, and then show their convergence to the solutions of the deterministic 3D globally modified (hyperviscous) Navier–Stokes equations in an appropriate scaling limit. Furthermore, we prove a large deviation principle for the stochastic globally modified hyperviscous system.},
  archive      = {J_SPA},
  author       = {Chang Liu and Dejun Luo},
  doi          = {10.1016/j.spa.2025.104770},
  journal      = {Stochastic Processes and Their Applications},
  month        = {1},
  pages        = {104770},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Scaling limit and large deviation for 3D globally modified stochastic Navier–Stokes equations with transport noise},
  volume       = {191},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

<h2 id="swevo">SWEVO - 22</h2>
<ul>
<li><details>
<summary>
(2025). A preference modified inverted generational distance indicator guided algorithm for evolutionary multi-objective optimization. <em>SWEVO</em>, <em>99</em>, 102169. (<a href='https://doi.org/10.1016/j.swevo.2025.102169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preference-based evolutionary multi-objective optimization algorithms have attracted much attention in the area of evolutionary computation. However, there are only a few researchers incorporating performance indicators for designing preference-based evolutionary algorithm. In this paper, we propose a preference modified inverted generational distance indicator guided algorithm, named PIGA, for evolutionary multi-objective optimization. The main purpose is that decision-makers provide their preferences, ultimately identifying the portion of Pareto optimal solutions where are located in region of interest. A new preference construction strategy based on coordinate transformation is first proposed. The reference points in the whole objective space can be projected into the preference space, obtaining the preferred reference points. The non-preferred reference points remain in the original objective space, outside the specified preference region. In addition, we define the distance between the candidate solution and preferred reference points as the preference distance and the distance to non-preferred reference points as the penalty distance. Finally, a preference-based modified inverted generational distance indicator is formulated to obtain the preferred optimal solutions according to the preferences and penalty distances. The comparative results are comprehensively analyzed by comparing it with some related preference-based evolutionary algorithms on some test instances. Experimental results have validated the effectiveness and feasibility of the proposed algorithm under different scenarios with the given preference range.},
  archive      = {J_SWEVO},
  author       = {Fei Li and Hao Tian and Hao Shen and Xingyi Zhang and Jianchang Liu and Zaiwu Gong},
  doi          = {10.1016/j.swevo.2025.102169},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102169},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A preference modified inverted generational distance indicator guided algorithm for evolutionary multi-objective optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Material delivery optimization for make-to-order reconfigurable job shops using an improved chaotic multi-verse algorithm. <em>SWEVO</em>, <em>99</em>, 102167. (<a href='https://doi.org/10.1016/j.swevo.2025.102167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for product customization has highlighted the importance of make-to-order (MTO) material delivery. Although manufacturers have deployed intelligent reconfigurable job shops equipped with flexible workstations and automated guided vehicles (AGVs), challenges remain due to inefficient material scheduling, delayed deliveries, and the complexity arising from diverse material types. This study proposes an active delivery strategy based on a workshop material supermarket, in which both AGV path planning and workstation layout are jointly optimized in response to dynamically changing orders. A multi-objective delivery path model is formulated to support demand splitting while minimizing material delivery costs and maximizing timeliness satisfaction. The model incorporates constraints related to AGV capacity, path feasibility, and demand alignment. To address the nonlinearity and complexity of the problem, an improved chaotic multi-verse optimizer (ICMVO) is proposed. The algorithm employs chaotic encoding to enhance population diversity and mitigate premature convergence. It further integrates gravitational and collision operators to improve global and local search capabilities and adopts adaptive orbital dynamics control to balance exploration and exploitation. A dual-population iterative strategy is employed to enable joint decision-making on workstation coordinates, path direction, and vehicle assignment. Through comprehensive comparisons with state-of-the-art meta-heuristics, the superiority of the ICMVO algorithm and the effectiveness of its components are demonstrated. Moreover, the proposed material delivery optimization method is implemented in a cloud–edge–terminal system and validated in practical MTO reconfigurable job shops through improvements in productivity and cost efficiency.},
  archive      = {J_SWEVO},
  author       = {Qinge Xiao and Kai Wang and Chi Ma and Ye Chen},
  doi          = {10.1016/j.swevo.2025.102167},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102167},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Material delivery optimization for make-to-order reconfigurable job shops using an improved chaotic multi-verse algorithm},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid metaheuristic algorithms for image watermarking: An experimental study. <em>SWEVO</em>, <em>99</em>, 102163. (<a href='https://doi.org/10.1016/j.swevo.2025.102163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Invisible image watermarking is a promising method for protecting the copyright of digital images such as photographs, illustrations, and scans. An effective watermarking algorithm embeds a special mark into an image that does not change the image content but can be extracted from it even after some common post-processing operations such as cropping or compression. Many authors use metaheuristic optimization algorithms to achieve a trade-off between imperceptibility and robustness of embedding. In recent years, researchers have been interested in hybrid metaheuristics, which combine operations of individual metaheuristics in some way. However, designs and compositions of hybrid metaheuristic optimization schemes for image watermarking have not been sufficiently studied to date. In this paper, we present an experimental study of various hybrid metaheuristics including sequential, interleaved, and parallel schemes for popular bioinspired optimization algorithms including genetic algorithm, differential evolution algorithm, particle swarm optimization algorithm, firefly algorithm, and artificial bee colony algorithm. We evaluate the effectiveness of hybrid metaheuristics for image watermarking using an algorithm based on changing the ratio between absolute values ​​of sums of discrete cosine transform coefficient groups as an example and perform an experimental comparison of different schemes. The results of the study show that a approach to metaheuristic hybridization and a composition of hybrid scheme significantly affect the imperceptibility and robustness of the image watermarking algorithm. In particular, the interleaved hybridization type provides the best results for the algorithm under consideration.},
  archive      = {J_SWEVO},
  author       = {Anna Melman and Oleg Evsutin},
  doi          = {10.1016/j.swevo.2025.102163},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102163},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Hybrid metaheuristic algorithms for image watermarking: An experimental study},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal financial portfolio selection using a metaheuristic approach with multiple strategies. <em>SWEVO</em>, <em>99</em>, 102162. (<a href='https://doi.org/10.1016/j.swevo.2025.102162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio optimisation with cardinality constraints has been extensively studied in the realm of financial investment, recognised as an NP-hard quadratic programming problem. As an innovative metaheuristic approach, the dung beetle optimiser leverages its unique optimisation search mechanism to effectively tackle unconstrained optimisation problems. However, the realities of portfolio optimisation involve various constraints; thus, the original dung beetle optimiser may not suffice. Consequently, this study develops an improved dung beetle optimiser to address cardinality constrained portfolio optimisation, incorporating a new decision variable update strategy, a constraint handling strategy, and a local search strategy. These techniques facilitate the efficient selection of assets from among multiple candidate assets. To validate the capabilities of the indicated methodologies, five datasets from OR-Library and six datasets from NGINX are employed for testing. The results from these datasets consistently indicate that the proposed strategies outperform existing alternatives. Furthermore, the comparison results with various methods presented in other works demonstrate that the proposed technology is competitive in the realm of cardinality constrained portfolio optimisation.},
  archive      = {J_SWEVO},
  author       = {Limin Wang and Guosen Lin and Qijun Zhang and Muhammet Deveci and Seifedine Kadry and Mingyang Li},
  doi          = {10.1016/j.swevo.2025.102162},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102162},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Optimal financial portfolio selection using a metaheuristic approach with multiple strategies},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An evolutionary method with shift pattern learning for real-world multi-skilled personnel scheduling with flexible shifts. <em>SWEVO</em>, <em>99</em>, 102160. (<a href='https://doi.org/10.1016/j.swevo.2025.102160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personnel scheduling remains a significant organizational challenge with substantial potential for cost and time savings. Despite extensive research in this domain, few studies have been successfully implemented in practice, and even fewer have gained widespread acceptance among end-users. This gap between research and application often arises from oversimplified real-world models, which may result from subjective solution evaluations or a lack of collaboration between modelers and end-users. To bridge this gap, this paper proposes a machine learning-enhanced memetic algorithm (MLMA) that mimics schedules created by experts to solve a highly complex personnel scheduling problem involving multi-skilled workers and flexible shift types (irregular workforce)—a real-world challenge commonly faced in the hospitality sector. By leveraging historical scheduling preferences, the MLMA generates solutions that align with past practices, enhancing their practicality and appeal to end-users. Experiments conducted on real-life instances demonstrate the effectiveness of the proposed approach in addressing real-world problems, where the workforce is predominantly part-time, possesses mixed skills, and requires flexible shifts. Furthermore, the results highlight the MLMA’s ability to identify shift patterns that closely resemble historical schedules, underscoring its potential for practical implementation and its role in bridging the gap between research and real-world application.},
  archive      = {J_SWEVO},
  author       = {Ning Xue and Ruibin Bai and Huan Jin and Tianxiang Cui},
  doi          = {10.1016/j.swevo.2025.102160},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102160},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An evolutionary method with shift pattern learning for real-world multi-skilled personnel scheduling with flexible shifts},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A learning-and-knowledge-assisted multi-population collaborative evolutionary algorithm for integrated design-production-distribution scheduling problems in mass personalized customization. <em>SWEVO</em>, <em>99</em>, 102158. (<a href='https://doi.org/10.1016/j.swevo.2025.102158'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, new requirements are proposed for the manufacturing industry transitioning to distributed production models due to emergence of mass personalized customization. Integrated scheduling of design, production and distribution, mixed management of batch and flexible manufacturing are becoming the imminent challenges faced by enterprises. This article proposes an integrated design-production-distribution scheduling problem in distributed mixed shops. It considers distributed flow shops for batch manufacturing and distributed flexible job shops for flexible manufacturing. First, a mixed integer linear programming model is formulized to minimize the maximum completion time, total costs, and total tardiness. Second, a learning-and-knowledge-assisted multi-population collaborative evolutionary algorithm is developed to settle the model. Genetic operators are adopted to improve the global and local search abilities. Three subpopulations with adaptive crossover and mutation probabilities are constructed to enhance the convergence and diversity of population. A Q-learning-assisted cooperative approach is adopted to realize the information communication among subpopulations in the genetic operations. The Q-learning method is used to intelligently choose parent individuals from three subpopulations by utilizing its self-learning strategies. A variable neighborhood search approach considering problem-knowledge neighborhood structures is devised to refine the excellent individuals in population. Finally, the presented algorithm is compared against three well-known intelligent optimization methods on a collection of instances. Comparison outcomes verify the superiority of the developed algorithm in handling the considered problem.},
  archive      = {J_SWEVO},
  author       = {Yanhe Jia and Wei Wang and Jian Zhang},
  doi          = {10.1016/j.swevo.2025.102158},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102158},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A learning-and-knowledge-assisted multi-population collaborative evolutionary algorithm for integrated design-production-distribution scheduling problems in mass personalized customization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster and reinforcement learning-based multi-objective evolutionary algorithm for joint scheduling of virtual machines and prioritize tasks in cloud computing. <em>SWEVO</em>, <em>99</em>, 102156. (<a href='https://doi.org/10.1016/j.swevo.2025.102156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world, cloud computing is considered an essential on-demand service that is facing an ongoing problem in Virtual Machine (VM) placement and task scheduling optimization that simultaneously improves server efficiency and user experience. Considering these challenges, this paper aims to reduce the makespan, cost, and total tardiness in Joint Scheduling of Virtual Machines and Prioritize Tasks (JSVPT) by a multi-objective optimization framework. We designed a novel Cluster-Based Multi-Objective Evolutionary Algorithm (MOEA-CD/RLPD) framework, which includes a three-tier encoding scheme with Reinforcement Learning (RL)-guided local search, preselection, and dynamic resource allocation strategy to solve the problem. To guide the search process, we employ K-means clustering to decompose the population into diverse subgroups, promoting balanced exploration. The pre-selection mechanism uses a classifier to identify promising solutions in the decision space, which allows resources to be used effectively. Reinforcement learning adaptively selects intensification operators based on reward feedback, improving exploitation by intensifying promising regions of the search space. An Improved Strength Pareto Evolutionary Algorithm 2 (ISPEA2) is incorporated to maintain a diverse and high-quality Pareto archive. The performance of the proposed algorithm is assessed on multiple test instances covering different scales and benchmarked against five state-of-the-art Multi-Objective Evolutionary Algorithms (MOEAs). Experimental studies demonstrate that the proposed algorithm outperforms most existing algorithms in the literature.},
  archive      = {J_SWEVO},
  author       = {Aanchal Agrawal and Arun Kumar Pal},
  doi          = {10.1016/j.swevo.2025.102156},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102156},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Cluster and reinforcement learning-based multi-objective evolutionary algorithm for joint scheduling of virtual machines and prioritize tasks in cloud computing},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAFSP with limited assembly buffers: A deadlock-free coding-decoding paradigm and hybrid cooperative co-evolutionary approach. <em>SWEVO</em>, <em>99</em>, 102155. (<a href='https://doi.org/10.1016/j.swevo.2025.102155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most prior studies on the Distributed Assembly Flowshop Scheduling Problem (DAFSP) presume infinite buffer capacity for assembly machines. However, in practical DAFSP, assembly buffers are often limited, potentially leading to a deadlock where buffers are full of jobs yet none of them can be assembled into a product. Since the deadlock in DAFSP is caused by incorrect jobs’ sequences in assembly buffers, we formulate a Petri net to model this entry process for the first time. Based on this Petri net model and improved Banker algorithm (IBA), we develop a polynomial-complexity algorithm IDAM to ensure the deadlock-free decoding of a DAFSP solution, which is coded by job and factory permutations. The makespan of such a solution is calculated backward to maintain its deadlock-free property. Furthermore, according to the proposed coding-decoding paradigm for deadlock-free solutions, we propose a hybrid cooperative co-evolution (HCCE) algorithm for DAFSP to minimize the makespan. Notably, our HCCE algorithm incorporates an elite archive (EAR) and two subpopulations. It employs problem-specific operators for heuristic initialization and global-search procedures, and four local-search operators are successively applied to every individual in the EAR. Finally, comprehensive experiments demonstrate the effectiveness and superiority of the proposed HCCE algorithm.},
  archive      = {J_SWEVO},
  author       = {Siyi Wang and Yanxiang Feng and Xiaoling Li and Guanghui Zhang},
  doi          = {10.1016/j.swevo.2025.102155},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102155},
  shortjournal = {Swarm Evol. Comput.},
  title        = {DAFSP with limited assembly buffers: A deadlock-free coding-decoding paradigm and hybrid cooperative co-evolutionary approach},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective combination of mechanisms for particle swarm optimization-based ensemble strategy. <em>SWEVO</em>, <em>99</em>, 102154. (<a href='https://doi.org/10.1016/j.swevo.2025.102154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A high-quality ensemble strategy can effectively integrate several coefficients, mechanisms, and algorithms into a single framework. The adaptability, timing of intervention, and complementarity are the key factors to consider for the selected coefficients, mechanisms, and algorithms. In this study, two complementary variants based on Particle Swarm Optimization (PSO), namely Modified PSO (MPSO) and Social Learning PSO (SLPSO), were selected, forming IMPSO and ISLPSO after improvements. IMPSO excels at exploration, while ISLPSO excels at exploitation. The Improved Novel Ratio Adaptation Scheme (INRAS) is employed as a selection strategy and provides the ability to abandon less-optimal particles. The Modified Nonlinear Population Size Reduction (MNLPSR) enables the extension of generations, allowing for more sufficient evolution in later stages. Due to the use of MNLPSR, an improved inertia weight and adaptive acceleration coefficients are introduced to ensure compatibility with the proposed algorithm. Additionally, an improved dynamic differential mutation strategy is designed not only to be compatible with the proposed algorithm but also to enhance particle diversity. Both the Improved Sine Cosine Algorithm (ISCA) and Sequential Quadratic Programming (SQP), which focus on searching near the global best particles, are incorporated into the proposed ensemble strategy. This PSO-based variant is named the Effective Combination of Mechanisms for a PSO-based Ensemble Strategy (ECM-PSOES). Ablation experiments demonstrated the effectiveness of the individual coefficients and mechanisms. The novel PSO-based variant was evaluated on the CEC2017 benchmarks and compared with 14 state-of-the-art PSO-based variants and 11 non-PSO algorithms. Additionally, to evaluate the flexible and robust capability of the proposed algorithm, three real-world applications for long-term Transmission Network Expansion Planning (TNEP), Planetary Gear Train Design (PGTD), and Robot Gripper Design (RGD) were tested. The experimental results illustrate that the proposed algorithm displays superior performance compared to recently proposed PSO-based variants and most non-PSO algorithms. However, the proposed algorithm falls short of outperforming Differential Evolution (DE)-based algorithms and still requires time to match the performance of top-tier metaheuristics. The source code of ECM-PSOES is provided at https://github.com/microhard1999/CODES .},
  archive      = {J_SWEVO},
  author       = {Libin Hong and Zhantao Gu and Ruibin Bai and John Woodward and Ender Özcan},
  doi          = {10.1016/j.swevo.2025.102154},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102154},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An effective combination of mechanisms for particle swarm optimization-based ensemble strategy},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive weight optimization algorithm based on decision variable grouping for large-scale multi-objective optimization problems. <em>SWEVO</em>, <em>99</em>, 102149. (<a href='https://doi.org/10.1016/j.swevo.2025.102149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving large-scale multi-objective optimization problems (LSMOPs), the optimization effect of traditional multi-objective optimization algorithms deteriorates as the number of decision variables increases. The weight optimization method based on problem transformation can effectively address LSMOPs, demonstrating superior convergence compared to most evolutionary algorithms. However, existing problem transformation methods often fail to balance convergence and diversity, leading to get trapped in local optima. In order to effectively solve this problem, we propose an adaptive weight optimization algorithm based on variable grouping (GWOEA). The algorithm optimizes weights within groups to accelerate population convergence, while the adaptive control strategy boosts diversity, avoiding local optima and ensuring a balance between convergence and diversity during the optimization process. To reduce the size of solving LSMOPs, weight optimization is performed by grouping decision variables. The weights of variables within each group are first computed, and then these weights are directly optimized instead of the decision variables. The adaptive control strategy is designed to detect whether population evolution has stagnated and to handle stagnant populations, ensuring that the population retains its ability to explore. To evaluate the effectiveness of GWOEA, comprehensive comparative experiments are conducted on benchmark test problems, including variable sizes ranging from 500 to 5000. The results show that the proposed algorithm has relatively better optimization performance.},
  archive      = {J_SWEVO},
  author       = {Hao Wang and Shuwei Zhu and Wei Fang and Kalyanmoy Deb},
  doi          = {10.1016/j.swevo.2025.102149},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102149},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An adaptive weight optimization algorithm based on decision variable grouping for large-scale multi-objective optimization problems},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GTG-ACO: Graph transformer guided ant colony optimization for learning heuristics and pheromone dynamics for combinatorial optimization. <em>SWEVO</em>, <em>99</em>, 102147. (<a href='https://doi.org/10.1016/j.swevo.2025.102147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial optimization (CO) problems are fundamental to numerous real-world applications, ranging from logistics and scheduling to resource allocation. For solving CO problems, Ant Colony Optimization (ACO) is a widely used metaheuristic that simulates cooperative foraging behavior to iteratively construct high-quality solutions. However, traditional ACO suffers from handcrafted heuristic functions that fail to generalize across different instances and uniform pheromone initialization, which results in inefficient exploration and slow convergence. To address these limitations, we introduce G raph T ransformer G uided A nt C olony O ptimization- GTG-ACO , a novel approach that jointly learns both heuristic and initial pheromone matrices, enabling the model to generalize across diverse problem instances without manual tuning. Additionally, GTG-ACO employs Graph Transformer augmented with Squeeze-and-Excitation (SE) network as the backbone for heuristic and pheromone learner. The Graph Transformers enable adaptive representation learning by leveraging attention mechanisms to dynamically capture structural relationships in graph representation of combinatorial optimization problems. Additionally, SE networks enhance the model by recalibrating feature importance, ensuring that critical information is amplified while suppressing less relevant features. Extensive evaluations on four combinatorial optimization problems—Traveling Salesman Problem (TSP), Capacitated Vehicle Routing Problem (CVRP), Single Machine Total Weighted Tardiness Problem (SMTWTP) and Bin Packing Problem (BPP)—demonstrate that GTG-ACO consistently outperforms state-of-the-art baselines achieving improvements ranging from 1% to 56%. Furthermore, we validate its real-world applicability by evaluating it on benchmark datasets TSPLIB and CVRPLIB. Thus, GTG-ACO establishes itself as a powerful and generalizable framework by jointly learning heuristic and pheromone matrices, enabling more informed exploration, which leads to superior solution quality in combinatorial optimization problems. Our code is publicly available at https://github.com/abrarrahmanabir/GTG-ACO .},
  archive      = {J_SWEVO},
  author       = {Abrar Rahman Abir and Muhammad Ali Nayeem and M. Sohel Rahman and Md Adnan Arefeen},
  doi          = {10.1016/j.swevo.2025.102147},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102147},
  shortjournal = {Swarm Evol. Comput.},
  title        = {GTG-ACO: Graph transformer guided ant colony optimization for learning heuristics and pheromone dynamics for combinatorial optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic performance evaluation of evolutionary multi-objective optimization algorithms for gait cycle optimization of a 25-DOFs NAO humanoid robot. <em>SWEVO</em>, <em>99</em>, 102144. (<a href='https://doi.org/10.1016/j.swevo.2025.102144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers are increasingly using optimization methods to achieve optimal dynamic performance of humanoid robots, often involving multiple conflicting objectives. Multi-objective optimization algorithms (MOAs) aim to find a Pareto front of optimal solutions, but selecting the best algorithm based on solution quality and computational efficiency remains challenging. This study comprehensively evaluates MOAs from different paradigms: swarm intelligence (CMOPSO), genetic algorithms (NSGA-II, DCNSGA-III), and decomposition-based approaches (CMOEA/D) for optimizing the gait cycle of a 25 DOF NAO humanoid robot during single support phase (SSP) and double support phase (DSP) scenarios. The algorithms’ convergence, diversity, and constraint-handling capabilities are systematically analyzed in solving the gait generation problem. The bi-objective optimization simultaneously minimizes power consumption and maximizes dynamic stability subject to eight functional constraints with 12-13 decision parameters. Through performance evaluation using running inverted generational distance (IGD) and hypervolume (HV) metrics across eleven independent runs of each algorithm, NSGA-II emerges as the most suitable algorithm, demonstrating superior convergence and solution quality, while CMOPSO shows competitive performance with faster initial convergence. DCNSGA-III exhibits moderate performance with constraint-handling difficulties, and CMOEA/D demonstrates poor convergence characteristics requiring significantly more computational resources. Two distinct knee regions emerge during both SSP and DSP, representing optimal trade-off solutions, with a systematic framework provided for practitioners to select appropriate gait parameters based on operational priorities. The running IGD metric combined with HV validation demonstrates effectiveness in providing robust algorithmic insights, enabling practitioners to select suitable algorithms for similar complex real-world optimization problems.},
  archive      = {J_SWEVO},
  author       = {Pushpendra Gupta and Dilip Kumar Pratihar and Kalyanmoy Deb},
  doi          = {10.1016/j.swevo.2025.102144},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102144},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Dynamic performance evaluation of evolutionary multi-objective optimization algorithms for gait cycle optimization of a 25-DOFs NAO humanoid robot},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive landscape-aware repelling restart covariance matrix adaptation-evolution strategy for multimodal and global optimization. <em>SWEVO</em>, <em>99</em>, 102143. (<a href='https://doi.org/10.1016/j.swevo.2025.102143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multimodal optimization using Covariance Matrix Adaptation-Evolution Strategy (CMA-ES), redundant restarts are caused by repeated convergence to previously explored local basins, which leads to significant computational resource waste. To address this problem, previous research proposed the concept of Repelling Restart and developed RR-CMA-ES, but issues remain regarding rigid repulsion and gradient information of local basin structures. Building on this foundation, we propose an Adaptive Landscape-aware Repelling Restart CMA-ES (ALR-CMA-ES) that enhances the original RR-CMA-ES through three key improvements: 1) A fitness sensitive dynamic exclusion mechanism that adaptively adjusts tabu region radius based on local optimality and convergence frequency, prioritizing avoidance of high-quality basins; 2) A covariance matrix mechanism preserving convergence history to geometrically align hyper-ellipsoidal exclusion regions with explored local basin landscapes; 3) A Boltzmann-like probabilistic acceptance scheme incorporating exclusion regions, permit- ting controlled exploration near tabu boundaries. Experiments on the BBOB benchmark demonstrate that ALR-CMA-ES outperforms RR-CMA-ES in 90% of tested problems spanning 2D to 50D. This method provides a practical solution for expensive black-box optimization by systematically integrating landscape topology awareness into tabu mechanisms, while proposing a new solution for multimodal optimization problems.},
  archive      = {J_SWEVO},
  author       = {Xikang Wang and Tongxi Wang and Hua Xiang},
  doi          = {10.1016/j.swevo.2025.102143},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102143},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Adaptive landscape-aware repelling restart covariance matrix adaptation-evolution strategy for multimodal and global optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-learning classification-based multi-objective evolutionary algorithm for machine multi-state energy-efficient flexible job shop scheduling under time-of-use pricing. <em>SWEVO</em>, <em>99</em>, 102142. (<a href='https://doi.org/10.1016/j.swevo.2025.102142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the “dual carbon” strategic goals, the coordinated optimization of energy consumption and production efficiency has become a core issue for manufacturing industries. As an important means to promote energy structure transformation, electric substitution has made significant progress in industrial manufacturing, transportation, household electrification, and other fields. Among them, industrial production accounts for over 60% of the total electric energy substitution, becoming the largest electricity consumer. Note that the electricity price is based on time-of-use pricing (TOU), meanwhile, electric consumption is related to the machine multi-state (MM). Regarding these matters, this study focuses on determining sensible machine states and formulating reasonable production scheduling plan, to minimize both production time and power consumption. First, a novel energy-efficient flexible job shop scheduling problem is developed, which considers both the TOU strategy and the MM conditions (EFJSP-MM-TOU). Second, a self-learning classification-based multi-objective evolutionary algorithm (SCMOEA) is proposed to solve the EFJSP-MM-TOU. In specific, the SCMOEA enhances population diversity through a hybrid initialization strategy, adopts a dynamic selection of cross individuals based on the self-learning classification mechanism to improve the search efficiency, and designs four local search operators to increase the potential for approaching better positions. Third, by employing the MK standard dataset in EFJSP-MM-TOU, the proposed SCMOEA is compared with its three variants and five state-of-the-art algorithms to verify its optimization performance. The experimental results suggest that SCMOEA has advantages in terms of Pareto optimal solutions’ diversity and convergence. Finally, by testing in an actual enterprise case, the results further support the effectiveness of the EFJSP-MM-TOU and the significance of SCMOEA.},
  archive      = {J_SWEVO},
  author       = {Da Wang and Lina Qian and Kai Zhang and Dengwang Li and Shicun Zhao and Junqing Li},
  doi          = {10.1016/j.swevo.2025.102142},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102142},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A self-learning classification-based multi-objective evolutionary algorithm for machine multi-state energy-efficient flexible job shop scheduling under time-of-use pricing},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using genetic programming to improve data collection for offline reinforcement learning. <em>SWEVO</em>, <em>99</em>, 102140. (<a href='https://doi.org/10.1016/j.swevo.2025.102140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline Reinforcement Learning (RL) learns policies solely from fixed pre-collected datasets, making it applicable to use-cases where data collection is expensive or risky. Consequently, the performance of these offline learners is highly dependent on the dataset used. Still the questions of how this data is collected and what dataset characteristics are needed are not thoroughly investigated. Simultaneously, evolutionary methods have reemerged as a promising alternative to classic RL, leading to the field of evolutionary RL (EvoRL), combining the two learning paradigms to exploit their supplementary attributes. This study aims to join these research directions and examine the effects of Genetic Programming (GP) on dataset characteristics in RL and its potential to enhance the performance of offline RL algorithms. A comparative approach was employed, comparing Deep Q-Networks (DQN) and GP for data collection across multiple environments and collection modes. The exploration and exploitation capabilities of these methods were quantified and a comparative analysis was conducted to determine whether data collected through GP led to superior performance in multiple offline learners. The findings indicate that GP demonstrates strong and stable performance in generating high-quality experiences with competitive exploration. GP exhibited lower uncertainty in experience generation compared to DQN and produced high trajectory quality datasets across all environments. More offline algorithms showed statistically significant performance gains with GP-collected data than trained on DQN-collected trajectories. Furthermore, their performance was less dependent on the environment, as the GP consistently generated high-quality datasets. This study showcases the effective combination of GP's properties with offline learners, suggesting a promising avenue for future research in optimizing data collection for RL.},
  archive      = {J_SWEVO},
  author       = {David Halder and Georgios Douzas and Fernando Bacao},
  doi          = {10.1016/j.swevo.2025.102140},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102140},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Using genetic programming to improve data collection for offline reinforcement learning},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiple direction search algorithm for continuous optimization. <em>SWEVO</em>, <em>99</em>, 102138. (<a href='https://doi.org/10.1016/j.swevo.2025.102138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The particle swarm optimization algorithm has been successfully applied to various optimization problems. One of its key features is the combination of particle velocity and search direction towards the optimal position in the history and swarm. Recognizing the limitations of the particle swarm optimization algorithm, this paper proposes a new evolutionary algorithm called the multiple direction search algorithm. The algorithm integrates five different search directions, including a multi-point direction constructed using principal component analysis. The integrated direction is generated by the weighted sum of the search directions. Theoretical analysis shows that under mild conditions, the rate of convergence along the weighted direction is no worse than the rate of convergence along the best of single search directions by a positive constant, or even faster in certain cases. The performance of the proposed algorithm was evaluated on three benchmark test suites by computer simulation. Experimental results demonstrate that the proposed method outperforms seven state-of-the-art particle swarm optimization algorithms.},
  archive      = {J_SWEVO},
  author       = {Wei Huang and Jun He and Liehuang Zhu},
  doi          = {10.1016/j.swevo.2025.102138},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102138},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A multiple direction search algorithm for continuous optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constraint-tightening based adaptive two-stage evolutionary algorithm for constrained multi-objective optimization. <em>SWEVO</em>, <em>99</em>, 102137. (<a href='https://doi.org/10.1016/j.swevo.2025.102137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems (CMOPs) are prevalent in practical applications, yet existing methods often struggle to handle their diverse characteristics, such as disconnected feasible regions and infeasible solutions near the true constraints Pareto front (CPF). To address these challenges, this paper proposes a constraint-tightening based adaptive two-stage evolutionary algorithm (CT-TSEA) for CMOPs, incorporating a constraint boundary tightening strategy and parameter dynamic adjustment strategy. In the first stage, a constraint boundary tightening strategy based on evaluation counts guides the population toward feasible regions. Initially, constraint boundaries are relaxed to explore the solution space thoroughly, identifying promising solutions. As evaluations increase, the search boundaries shrink, enhancing the feasibility of solutions. Additionally, a step-size adaptive adjustment method improves infeasible solutions using their information, boosting search efficiency and solution diversity. The second stage introduces a dynamic adjustment method for crossover probability and scaling factor, balancing exploration and exploitation. It better balances the exploration and exploitation capabilities of the population. The proposed method is validated via comparing with seven state-of-the-art peer competitors across 59 test instances from four benchmark suites and 21 real-world problems. The corresponding results demonstrate that CT-TSEA has the higher competitiveness in addressing complex CMOPs.},
  archive      = {J_SWEVO},
  author       = {Cunyan Liu and Qingda Chen and Junhua Liu and Wei Zhang and Meng Wang and Can Liu},
  doi          = {10.1016/j.swevo.2025.102137},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102137},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Constraint-tightening based adaptive two-stage evolutionary algorithm for constrained multi-objective optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploratory landscape analysis on black-box optimization problems via graph neural network. <em>SWEVO</em>, <em>99</em>, 102136. (<a href='https://doi.org/10.1016/j.swevo.2025.102136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most real-world optimization problems are poorly understood, some of which are black-box optimization problems (BBOPs). Exploratory landscape analysis (ELA) paves the way for algorithm design to deal with BBOPs. Existing ELA methods have limitations on unseen problems and lack analysis on the problem itself. To this end, this study introduces a novel ELA framework leveraging Graph Neural Network (GNN) upon BBOP’s surrogate model. Specifically, a neural network surrogate model is constructed whose architecture is utilized to represent BBOP in the form of graph. Then, GNN is responsible for capturing the relationships between the graph-represented BBOP and high-level features. As one of the most notable features in optimization, multimodality of multi-objective problems is to be identified for illustration. More than 99% accuracy on independent test set demonstrates the effectiveness of the proposed framework with simultaneously avoiding the effect of problem dimensions.},
  archive      = {J_SWEVO},
  author       = {Xu Yang and Rui Wang and Kaiwen Li and Wenhua Li and Tao Zhang},
  doi          = {10.1016/j.swevo.2025.102136},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102136},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Exploratory landscape analysis on black-box optimization problems via graph neural network},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An attention-based joint value estimation strategy for multi-agent coordination optimization. <em>SWEVO</em>, <em>99</em>, 102132. (<a href='https://doi.org/10.1016/j.swevo.2025.102132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coordination optimization plays a vital role in complex multi-agent systems, and Multi-Agent Reinforcement Learning (MARL) has emerged as a widely adopted solution. However, MARL still faces significant challenges in this domain, including low coordination efficiency and inaccurate value estimation. To address these issues, we propose MVAPO, a novel Multi-Head Joint Value Attention-based Policy Optimization algorithm that improves policy learning through enhanced value approximation and selective attention to agent contributions. The key innovation of MVAPO lies in the introduction of a joint value network augmented with a multi-head attention mechanism. In this mechanism, context-aware team rewards serve as query inputs, directing attention to the most relevant agents in different situations. This allows the model to dynamically focus on the agents that are most critical at any given time, thus improving coordination efficiency and the accuracy of value estimates. Furthermore, MVAPO incorporates feedforward and residual layers, eliminating linear and monotonic constraints, which significantly enhances its representational capacity. Extensive experiments on a multi-UAV benchmark across a variety of scenarios demonstrate that MVAPO consistently outperforms state-of-the-art methods in both reward acquisition and win rates, highlighting its superior performance and robustness.},
  archive      = {J_SWEVO},
  author       = {Ze Wang and Ni Li and Guanghong Gong and Haitao Yuan},
  doi          = {10.1016/j.swevo.2025.102132},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102132},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An attention-based joint value estimation strategy for multi-agent coordination optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DA2MODE: Dynamic archive with adaptive multi-operator differential evolution for numerical optimization. <em>SWEVO</em>, <em>99</em>, 102130. (<a href='https://doi.org/10.1016/j.swevo.2025.102130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Dynamic Archive with Adaptive Multi-Operator Differential Evolution (DA2MODE), a new algorithm that aims to boost the performance of meta-heuristic and evolutionary methods in numerical optimization. DA2MODE introduces a Progressive Adaptive Selector with Exponential Smoothing (PASES), which dynamically updates the selection probabilities of both mutation and crossover operators. Unlike prior approaches that emphasize only mutation operators or rely on short-term success within the current generation, PASES adapts based on cumulative operator performance over time, thus favoring the best-performing operators more reliably. DA2MODE employs an Adaptive Non-Elite Archive Update (ANEAU) mechanism that injects a controlled fraction of non-elite solutions into the archive. ANEAU promotes early exploration, which is gradually reduced to strengthen exploitation. Additionally, the control parameters (crossover probability and mutation factor) are automatically tuned in DA2MODE, allowing full adaptivity of both operator selection and parameter control. Extensive experiments on the CEC2017/2018, CEC2020-2022, and 1000-dimensional CEC2013 benchmarks, along with four real-world engineering design problems, confirm that DA2MODE consistently outperforms 33 competitive algorithms, including CEC winners and recent advanced DE variants. It achieves top performance across all statistical tests, demonstrating superior convergence speed and final accuracy. These results establish DA2MODE as a robust, scalable, and reliable algorithm for solving complex numerical optimization problems. The source code of the DA2MODE algorithm is publicly available at: URL https://github.com/MohamedRedaMu/DA2MODE-Algorithm and URL https://uk.mathworks.com/matlabcentral/fileexchange/182019-da2mode-algorithm .},
  archive      = {J_SWEVO},
  author       = {Mohamed Reda and Ahmed Onsy and Amira Y. Haikal and Ali Ghanbari},
  doi          = {10.1016/j.swevo.2025.102130},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102130},
  shortjournal = {Swarm Evol. Comput.},
  title        = {DA2MODE: Dynamic archive with adaptive multi-operator differential evolution for numerical optimization},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large-scale multi-objective optimization framework based on a dual-space attention mechanism. <em>SWEVO</em>, <em>99</em>, 102089. (<a href='https://doi.org/10.1016/j.swevo.2025.102089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing attention-based methods for large-scale multi-objective optimization (LMOAM) focus only on decision variables, using their variance to guide search behavior. However, single-space strategies ignore critical information in the objective space and the diversity and search efficiency are often degraded for solving multimodal multi-objective optimization problems (MOPs). To address this problem, a novel large-scale optimization framework that integrates a dual-space attention mechanism is proposed in this paper. Different from building attention only with information in decision space, a dual-space Key matrix that quantifies variable importance by combining decision-variable and objective-space distributions is first designed in the framework to refine the precision of the attention. Subsequently, a cross-space clustering method is adopted to select the representative solutions by analyzing the characteristics of individuals in both spaces to construct the Query matrix. The accuracy of attention allocation is improved. Finally, A linear inverse mapping strategy is used to enhance the diversity of the population by translating promising objective-space solutions back to the decision space. Unlike existing approaches, the characteristics of decision and objective space are linked with a new attention mechanism, and the exploration and exploitation of the population are well balanced. Three types of experiments are designed on two benchmark test sets with 500-dimensional and 1000-dimensional decision variables and the voltage transformer optimization problem to demonstrate the efficacy of the AIDF framework, experimental results indicate that AIDF surpasses comparative algorithms in terms of the average performance of IGD and HV.},
  archive      = {J_SWEVO},
  author       = {Xu Li and Debao Chen and Feng Zou and Fangzhen Ge and Zhenghua Xin},
  doi          = {10.1016/j.swevo.2025.102089},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102089},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A large-scale multi-objective optimization framework based on a dual-space attention mechanism},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PheroCom: Decentralised and asynchronous robot swarm coordination framework based on virtual pheromone and vibroacoustic communication. <em>SWEVO</em>, <em>99</em>, 102083. (<a href='https://doi.org/10.1016/j.swevo.2025.102083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representing and controlling the dynamics of stigmergic substances used by bio-inspired approaches pose significant challenges when applied to robotics. In order to overcome this challenge, this work proposes a framework based on the virtualisation and control of these substances at a local scope, with the primary goal of coordinating robot swarms. This framework introduces a novel pheromone representation that enables decentralisation and decision asynchronicity, while its lightweight design ensures accessibility to resource-constrained platforms. Each robot maintains an independent virtual pheromone map in its memory, which is continuously updated through its own pheromone deposits and evaporation. Additionally, each robot’s pheromone map is also updated by aggregating information from other robots that are exploring nearby areas. Consequently, individual and independent maps eliminate the need for a centralised agent to manage and distribute pheromone information. This propagation mechanism is inspired by ants’ vibroacoustic communication, which is characterised as a form of indirect communication. The framework was evaluated using an agent-based mass simulation tool and a real-world simulation platform. Experiments were conducted to validate the framework in diverse environments, with variations in shapes, sizes, and the number of robots. Results demonstrated that this proposal can effectively perform the coordination of robot swarms, and the robots have exhibited satisfactory performance while executing the surveillance task.},
  archive      = {J_SWEVO},
  author       = {Claudiney R. Tinoco and Luiz Gustavo A. Martins and Gina M.B. Oliveira},
  doi          = {10.1016/j.swevo.2025.102083},
  journal      = {Swarm and Evolutionary Computation},
  month        = {12},
  pages        = {102083},
  shortjournal = {Swarm Evol. Comput.},
  title        = {PheroCom: Decentralised and asynchronous robot swarm coordination framework based on virtual pheromone and vibroacoustic communication},
  volume       = {99},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

<h2 id="tcs">TCS - 3</h2>
<ul>
<li><details>
<summary>
(2025). Optimal gathering of robots in anonymous butterfly networks via leader election. <em>TCS</em>, <em>1057</em>, 115553. (<a href='https://doi.org/10.1016/j.tcs.2025.115553'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots with very weak capabilities placed on the vertices of a graph are required to move toward a common vertex from where they do not move anymore. The task is known as the Gathering problem and it has been extensively studied in the last decade with respect to both general graphs and specific topologies. Most of the challenges faced are due to possible isometries observable from the placement of the robots with respect to the underlying topology. Rings, Grids, and Complete graphs are just a few examples of very regular topologies where the placement of the robots and suitable movements are crucial for succeeding in Gathering. Here we are interested in understanding what can be done in Butterfly graphs where really many isometries are present and most importantly unavoidable by any movement. We propose a Gathering algorithm for the so-called leader configurations, i.e., those where the initial placement of the robots admits the detection (and election) of one robot as the leader. We introduce a non-trivial technique to elect the leader which is of its own interest. We also prove that the proposed Gathering algorithm is asymptotically optimal in terms of synchronous rounds required.},
  archive      = {J_TCS},
  author       = {Serafino Cicerone and Alessia Di Fonso and Gabriele Di Stefano and Alfredo Navarra},
  doi          = {10.1016/j.tcs.2025.115553},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115553},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Optimal gathering of robots in anonymous butterfly networks via leader election},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient shape formation by 3D hybrid programmable matter: An algorithm for low diameter intermediate structures. <em>TCS</em>, <em>1057</em>, 115552. (<a href='https://doi.org/10.1016/j.tcs.2025.115552'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the shape formation problem within the 3D hybrid model, where a single agent with a strictly limited viewing range and the computational capacity of a deterministic finite automaton manipulates passive tiles through pickup, movement, and placement actions. The goal is to reconfigure a set of tiles into a specific shape termed an icicle . The icicle, identified as a dense, hole-free structure, is strategically chosen to function as an intermediate shape for more intricate shape formation tasks. It is designed for easy exploration by a finite-state agent, enabling the identification of tiles that can be lifted without breaking connectivity. Compared to the line shape, the icicle presents distinct advantages, including a reduced diameter and the presence of multiple removable tiles. We propose an algorithm that transforms an arbitrary initially connected tile structure into an icicle in O ( n 3 ) steps, matching the runtime of the line formation algorithm from prior work. Our theoretical contribution is accompanied by an extensive experimental analysis, indicating that our algorithm decreases the diameter of tile structures on average.},
  archive      = {J_TCS},
  author       = {Kristian Hinnenthal and David Liedtke and Christian Scheideler},
  doi          = {10.1016/j.tcs.2025.115552},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115552},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Efficient shape formation by 3D hybrid programmable matter: An algorithm for low diameter intermediate structures},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On shuffling and splitting automata. <em>TCS</em>, <em>1057</em>, 115539. (<a href='https://doi.org/10.1016/j.tcs.2025.115539'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of finite state three-tape transducers which models the operation of shuffling and splitting words. We present them as automata over the so-called Shuffling Monoid. These automata can be seen as either shufflers or splitters interchangeably. We prove that functionality is decidable for splitters, and we also show that the equivalence between functional splitters is decidable. Moreover, in the deterministic case, the algorithm for equivalence is polynomial on the number of states of the splitter.},
  archive      = {J_TCS},
  author       = {Ignacio Mollo Cunningham},
  doi          = {10.1016/j.tcs.2025.115539},
  journal      = {Theoretical Computer Science},
  month        = {12},
  pages        = {115539},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On shuffling and splitting automata},
  volume       = {1057},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
