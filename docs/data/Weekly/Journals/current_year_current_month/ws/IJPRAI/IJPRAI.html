<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJPRAI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijprai">IJPRAI - 149</h2>
<ul>
<li><details>
<summary>
(2025). Explainable modeling of quality anomaly traceability in industrial processes. <em>IJPRAI</em>, <em>39</em>(13), 2559018. (<a href='https://doi.org/10.1142/S0218001425590189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the defect traceability challenges caused by the complexity of modern industrial process operation mechanisms and high-dimensional parameter coupling, a quality anomaly diagnosis framework integrating interpretable machine learning and knowledge graph is proposed. The quantitative contributions of process parameters to quality indicators are assessed by constructing an architecture combining XGBoost prediction model and SHAP (SHapley Additive exPlanation) interpretable analysis. Structured storage of variable association patterns of historical data based on a knowledge graph. The K Nearest Neighbors (KNN) algorithm is further introduced to construct a data matching mechanism to achieve causal traceability of real-time anomalies through similarity-driven historical defect retrieval. The experimental results show that the method has a good ability to identify the root cause parameters of defects under multiple working condition scenarios, and provides a solution with both data-driven characteristics and knowledge interpretability for the quality control of complex industrial processes.},
  archive      = {J_IJPRAI},
  author       = {Biqing Wang},
  doi          = {10.1142/S0218001425590189},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2559018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Explainable modeling of quality anomaly traceability in industrial processes},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization method of intelligent cleaning control strategy for cleaning of Rice–Wheat combine harvester. <em>IJPRAI</em>, <em>39</em>(13), 2559012. (<a href='https://doi.org/10.1142/S0218001425590128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key stage of the intelligent cleaning control strategy for rice–wheat combine harvesters is the initial setting of cleaning operation parameters. There is a lack of research on intelligent control methods that reveal the correlation between rice and wheat attributes such as variety, moisture content, and grass to grain ratio, and the initial values of cleaning device operating parameters, as well as the correlation between cleaning loss rate and cleaning impurity rate. This paper constructs an optimization model for the initial operation parameters of the cleaning, and based on the dynamic monitoring and control system of the cleaning’s operation quality and parameters, intelligently regulates the cleaning of the rice–wheat combine harvester. Field experiments and analysis demonstrated that the intelligent control system, guided by the initial parameter setting model, successfully stabilized the cleaning quality metrics (e.g. impurity rate and loss rate) of the rice–wheat combine harvester, thereby validating the effectiveness of the optimized cleaning control strategy based on the perceptual neural vision algorithm.},
  archive      = {J_IJPRAI},
  author       = {Zusheng Li and Yang Liu and Qing Jiang and Jing Zhang and YuQing Zhang and JiaHan Yu and ChangMin Zhan},
  doi          = {10.1142/S0218001425590128},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2559012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimization method of intelligent cleaning control strategy for cleaning of Rice–Wheat combine harvester},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BC-MBINet: A novel architecture for accurate classification of breast cancer with microscopic biopsy images using deep convolutional neural networks. <em>IJPRAI</em>, <em>39</em>(13), 2557015. (<a href='https://doi.org/10.1142/S0218001425570150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer (BC) is the second most frequent malignancy, accounting for roughly 25% of all cases of cancer. BC is caused by genetic, epigenetic, and environmental factors, and their interaction too. The diagnosis of a BC is a critical step in the treatment process, and histopathological imaging is required to determine the type of illness. Identifying a disease is an important stage in the treatment process. However, this time-consuming task is exhausting, and people are prone to making mistakes that go unnoticed, making it difficult to determine the severity of the condition and this diagnosing step also relies on a pathologist’s expertise. In this paper, we have developed a novel BC with microscopic biopsy images network (BC-MBINet) model using deep convolutional neural networks. Feature extraction is handled by a sequence of convolutional layers, nonlinearity is handled using LeakyReLU activations, and learning is stabilized by batch normalization. A last Softmax layer is employed for binary classification into benign and malignant tumors, and dropout layers are included to decrease overfitting. The model achieves state-of-the-art accuracy and resilience in discriminating BC types by being trained on a publically available dataset of microscopic biopsy images. The proposed model is capable of classifying between the benign and malignant BC tumors with 99.04% accuracy. The model gives state-of-the-art results in its accuracy in classifying BC tumors into Benign or Malignant.},
  archive      = {J_IJPRAI},
  author       = {Kuljeet Singh and Amrit Sudershan and Sachin Kumar and Sourabh Shastri and Vibhakar Mansotra},
  doi          = {10.1142/S0218001425570150},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2557015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {BC-MBINet: A novel architecture for accurate classification of breast cancer with microscopic biopsy images using deep convolutional neural networks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CVD-M3NET: Cardiovascular disease stage classification via mamdani fuzzy-based modified mobile network. <em>IJPRAI</em>, <em>39</em>(13), 2557014. (<a href='https://doi.org/10.1142/S0218001425570149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Globally, cardiovascular diseases (CVDs) remain an important cause of mortality, for early and precise diagnosis. Traditional machine learning (ML) models struggle with feature redundancy, data imbalance, and suboptimal performance due to inefficient feature selection and lack of robust deep learning (DL) architectures. To overcome these challenges, we propose a novel Cardiovascular Disease Stage Classification via the Mamdani Fuzzy-based Modified Mobile Network (CVD-M 3 Net) by integrating hybrid feature selection, DL network and Fuzzy logic for improved CVD stage classification. The proposed CVD-M 3 Net utilizes data from multiple sources including Cleveland, MIMIC-IV, UK Biobank, Statlog, Switzerland, Hungary, and VA Long Beach datasets. The Boruta-LASSO and Fast ICA techniques are used for feature selection by ensuring the retention of critical diagnostic attributes while eliminating irrelevant ones. The selected features undergo Z -score normalization for improved data consistency between the 15 features. The Modified MobileNet (MOMO-Net) is introduced with the integration of 1D convolutional and transformer layers in the MobileNet structure to categorize the tabular data for real-time CVD stage detection. The proposed CVD-M 3 Net utilizes the Mamdani fuzzy inference system (FIS) with a trapezoidal membership function to predict the CVD Stage Score (CSS). The efficiency of the proposed CVD-M 3 Net was estimated with the Accuracy, Sensitivity, Precision, Recall, and F1-score. From the experimental analysis, the proposed CVD-M 3 Net achieves an overall accuracy of 98.61% for efficient classification of CVD stages. The proposed CVD-M 3 Net increases the accuracy by 0.11%, 0.62%, 3.25%, and 0.38% better than ML algorithms, O-SBGC-LSTM, MaLCaDD, and DL-based CNN, respectively.},
  archive      = {J_IJPRAI},
  author       = {Lijetha Christopher Jaffrin and Visumathi James},
  doi          = {10.1142/S0218001425570149},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2557014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CVD-M3NET: Cardiovascular disease stage classification via mamdani fuzzy-based modified mobile network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving brain tumor stage diagnosis with multi-stage hybrid classifier models. <em>IJPRAI</em>, <em>39</em>(13), 2557013. (<a href='https://doi.org/10.1142/S0218001425570137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To make informed clinical decisions and plan successful treatments, it is essential that magnetic resonance imaging (MRI) identify and diagnose brain tumors accurately. This research introduces a new method for multi-stage tumor detection and classification that uses a hybrid classifier (HC) to improve the accuracy of diagnoses. The first step of the suggested method is to identify possible tumor areas by obtaining features from grey-scale intensity analysis of successive pixels, which captures important differences. A systematic categorization technique relates these traits to distinct tumor stages. The HC uses rectilinear classifiers to analyze linear pixel changes and expanded classifiers to find bounded edges within regional pixel distributions. With this two-pronged strategy, tumors of any shape or size may be detected. Training classifiers on datasets with restricted edge characteristics and linear variation patterns allows for exact stage distinction, which is essential for learning. Compared to traditional classification approaches, the multi-stage framework greatly improves the capacity to detect complicated and nuanced tumor traits. Our powerful diagnostic approach permits precise and effective tumor identification and stage categorization to facilitate prompt treatments. The hybrid technique highlights its promise as a dependable, scalable solution to improve patient outcomes in medical imaging applications and advance brain tumor diagnosis.},
  archive      = {J_IJPRAI},
  author       = {S. R. Sowmiya and N. Sabiyath Fatima},
  doi          = {10.1142/S0218001425570137},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2557013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Improving brain tumor stage diagnosis with multi-stage hybrid classifier models},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SRGAN-based input enhancement and attention-guided YOLOv5s for real-time excavator pose estimation. <em>IJPRAI</em>, <em>39</em>(13), 2554014. (<a href='https://doi.org/10.1142/S021800142554014X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The measurement of excavator pose information is crucial for advancing intelligent excavator control systems. To address challenges in excavator pose detection — such as small pose measurement targets and blurred images — a high-speed, high-accuracy visual technology-based pose recognition algorithm, super-resolution input-YOLOv5s, was developed. This algorithm includes an image target designed specifically to facilitate the detection of the excavator arm’s pose angles. Excavator pose information is derived through the analysis of the target image data. The SRGAN model is used to enhance the quality of input data for YOLOv5, while attention mechanisms are introduced at the terminal stage of the backbone network. Focal loss is employed as the loss function to improve the detection accuracy and stability for small targets in complex construction environments, while also mitigating class imbalance. Experimental results demonstrate that the improved algorithm, SRI-YOLOv5s, achieved a detection speed of 59.20 FPS, with a mean average precision (mAP) of 89.46%, precision of 91.7%, and recall of 92.1%, outperforming the original model. The model’s real-time performance and robustness meet the requirements for excavator pose detection in practical environments.},
  archive      = {J_IJPRAI},
  author       = {Wangting Zeng and Qixiang Huang and Ke Wu and Xuedong Zhang and Bo Cui},
  doi          = {10.1142/S021800142554014X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2554014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {SRGAN-based input enhancement and attention-guided YOLOv5s for real-time excavator pose estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploration of simulation environments for visual question answering: 3D dense captioning for outdoor scenes. <em>IJPRAI</em>, <em>39</em>(13), 2552020. (<a href='https://doi.org/10.1142/S0218001425520202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel simulation framework tailored for Visual Question Answering (VQA) in complex outdoor environments, where existing datasets and systems fall short in semantic density and spatial reasoning. The proposed pipeline integrates procedural 3D scene generation, region-level dense captioning augmented with geometric priors, and structured scene graph construction to bridge vision and language understanding. A transformer-based reasoning module processes joint embeddings of questions and scene graphs to produce interpretable answers grounded in 3D semantics. The system supports diverse spatial and contextual queries and enables large-scale dataset synthesis with region-aligned captions and question–answer pairs. Extensive experiments across four datasets — Outdoor-Sim, SYNTHIA, StreetLearn, and ScanNet-VQA — demonstrate the framework’s superior performance over three strong baselines in accuracy, MRR, and convergence stability. Visualizations show robust alignment between captions, object layout, and semantic graphs. This study advances outdoor VQA by introducing a scalable, interpretable, and semantically grounded solution suitable for downstream robotics and scene understanding applications.},
  archive      = {J_IJPRAI},
  author       = {Renyue Wu and Kalama Bitur},
  doi          = {10.1142/S0218001425520202},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2552020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Exploration of simulation environments for visual question answering: 3D dense captioning for outdoor scenes},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-assisted localized content-based image retrieval framework with multiple-instance learning algorithm. <em>IJPRAI</em>, <em>39</em>(13), 2552019. (<a href='https://doi.org/10.1142/S0218001425520196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional content-based image retrieval (CBIR) searches a database for pictures that match a single, unannotated query image. A comprehensive (or worldwide) perspective of the picture is essential for this kind of search. However, the intended picture content is frequently not global rather regional. Computer vision, pattern recognition, and CBIR are just a few of the applications that have long faced the “semantic gap” issue: how to bridge the gap between human perception of low-level semantic concepts and machine collection of high-level image pixels. In light of the recent achievements in deep learning research, there is hope for bridging the semantic gap. Therefore, the deep learning-assisted localized content-based image retrieval framework (DL-LCBIRF) was suggested in this study to rank photos in the database according to a similarity metric dependent upon specific areas inside the image. The first layer consists of “generic” descriptors that stand in for groups of feature vectors that are comparable and rotationally invariant. The combined probability of the frequencies of the “generic” descriptions over neighborhoods makes up the second layer. The proposed DL-LCBIR uses labelled images combined with a multiple-instance learning algorithm (MILA) to locate the target item and adjust the feature weights. This multi-modal probability is shown as a collection of “spatial frequency” clusters. It augments rotationally invariant statistical spatial constraints. In addition to enhancing the model’s performance, choosing a unique structure determines the model’s distinguishing features, which are common in good cases and seldom in negative ones.},
  archive      = {J_IJPRAI},
  author       = {P. Arulmozhi and R. Gopi},
  doi          = {10.1142/S0218001425520196},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2552019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep learning-assisted localized content-based image retrieval framework with multiple-instance learning algorithm},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Action space pruning for deep reinforcement learning in dou di zhu. <em>IJPRAI</em>, <em>39</em>(13), 2552014. (<a href='https://doi.org/10.1142/S0218001425520147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The card game Dou Di Zhu (competitive two-against-one game) presents a challenging multiplayer imperfect-information game problem due to its large action space. We developed a deep Monte Carlo (DMC) reinforcement learning (RL) framework called ASP-DouZero, which employs dynamic programming (DP) to prune the action space effectively, using statistical analysis results. The pruned action space was then applied to self-play data generation and neural network decision processes. We evaluated ASP-DouZero against the state-of-the-art DouZero framework under identical training conditions. Results showed the proposed approach achieved a 5% higher win rate in standardized matches after convergence while requiring 50% less training time on equivalent hardware. These findings demonstrate that action space pruning significantly improves decision-making performance and training efficiency in DMC-based approaches for Dou Di Zhu.},
  archive      = {J_IJPRAI},
  author       = {Shanglin Li and Jiabao Du and Yu Zhao and Tianle Xiang and Yulin Lan},
  doi          = {10.1142/S0218001425520147},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2552014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Action space pruning for deep reinforcement learning in dou di zhu},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight object detection for real-time aerial video analysis on edge-deployed UAVs. <em>IJPRAI</em>, <em>39</em>(13), 2550025. (<a href='https://doi.org/10.1142/S0218001425500259'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time object detection in aerial videos captured by Unmanned Aerial Vehicles (UAVs) plays a vital role in applications such as traffic surveillance, disaster response, and intelligent aerial operations. However, deploying deep learning models directly on UAV platforms faces significant challenges due to limited onboard computing capabilities and strict power constraints imposed by the aircraft’s propulsion system. The efficiency of the detection algorithm directly impacts not only processing latency but also the energy consumption and endurance of the UAVs flight dynamics. To address these challenges, this paper presents UAVDet, a lightweight object detection framework optimized for edge-deployed UAVs operating under propulsion-aware constraints. UAVDet comprises three modules: a Multi-Scale Lightweight Backbone (MSLB) for efficient multi-resolution feature extraction, a Temporal-Consistent Feature Alignment (TCFA) module that enhances inter-frame stability under aerial motion, and an Adaptive Context Enhancement Head (ACEH) for spatially and semantically precise detection. Extensive experiments on a custom UAV dataset demonstrate that UAVDet achieves a superior balance between detection accuracy and runtime efficiency. Moreover, its low computational overhead supports deployment on energy-constrained UAV platforms, reducing the burden on the propulsion system and enabling longer, smarter missions.},
  archive      = {J_IJPRAI},
  author       = {Hong Zhu and He Qin},
  doi          = {10.1142/S0218001425500259},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2550025},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lightweight object detection for real-time aerial video analysis on edge-deployed UAVs},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic detection of obstacles in underground railway tracks for collision prevention. <em>IJPRAI</em>, <em>39</em>(13), 2550024. (<a href='https://doi.org/10.1142/S0218001425500247'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned underground vehicles (UUVs) offer significant advantages for coal mine transportation. However, the subterranean environment is often complex and prone to unexpected obstacles, particularly pedestrians, which pose substantial safety risks. To mitigate these risks, we developed an automated collision avoidance system. Additionally, we established an information network enabling real-time map tracking of UUVs to facilitate efficient dispatch and operation. Advanced deep learning algorithms detect tracks, obstacles, and pedestrians. Within the track detection zone, the system employs the Hough transform to identify line segments. These segments are then assigned weighting factors based on clarity, clustering, and fitting techniques, enabling accurate reconstruction of the track’s left and right boundaries. Furthermore, a defined safety zone effectively assesses the distance between pedestrians and vehicles. In practical operation, UUVs autonomously trigger audible alarms or initiate braking when pedestrians enter a critical proximity, when other UUVs obstruct the roadway, or when vehicles approach from the opposite direction. This integrated system significantly enhances safety for underground coal mine transportation.},
  archive      = {J_IJPRAI},
  author       = {Kai Zhao and Xuenan Zhang and Liwei Chen},
  doi          = {10.1142/S0218001425500247},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2550024},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automatic detection of obstacles in underground railway tracks for collision prevention},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human–Machine coupling study for fast visual target capture. <em>IJPRAI</em>, <em>39</em>(13), 2550023. (<a href='https://doi.org/10.1142/S0218001425500235'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of computer vision, human–computer interaction, and intelligent sensing technologies, accurate line-of-sight (LOS) tracking has become a critical research topic. However, traditional gaze tracking systems face significant limitations under conditions of natural head movement. The direction of human vision is determined jointly by head posture and eye movement, and precise acquisition of head pose remains a key challenge in gaze tracking technology. To address the limitations imposed by head movement, this study aims to improve the robustness of gaze tracking in natural interaction scenarios. This paper proposes a novel head pose estimation method based on the 3D spatial information of facial feature points. The method utilizes stereo vision to reconstruct 3D feature points and employs a geometric model to calculate head pose, effectively decoupling head movement from eye movement in gaze tracking. In the experimental setup, two interaction modalities were tested: head pointing combined with key pressing, and gaze estimation combined with head pointing. Experimental results demonstrate that the proposed method achieves interaction latency between 100 ms and 200 ms, with a fast capture success rate of up to 85%, slightly outperforming traditional visual target acquisition algorithms. These results indicate the method’s superior responsiveness and stability under natural head movement conditions. The research provides an important technical foundation for achieving natural, efficient human–computer interaction in complex environments.},
  archive      = {J_IJPRAI},
  author       = {Wenbo Huang and Mingwei Zhao and Heng Zhang and Xiaoqiao Wang},
  doi          = {10.1142/S0218001425500235},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2550023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Human–Machine coupling study for fast visual target capture},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AN advanced AI approach-based skin disease prediction system utilizing EN-QNN and grad-CAM in IoMT environment. <em>IJPRAI</em>, <em>39</em>(13), 2550013. (<a href='https://doi.org/10.1142/S0218001425500132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin acts as a natural shield, protecting the body from ultraviolet rays, extreme weather, and harmful chemicals. However, it can be affected by pollution, weakened immunity, and unhealthy lifestyles, leading to various skin diseases. Early detection of these conditions is crucial for timely treatment and better outcomes. Existing research has often overlooked skin diseases with similar visual characteristics, making it challenging to distinguish between different conditions using visual inspection alone. To address this, the paper proposes an AI-enabled prediction framework for skin disease prediction using EN-QNN and Grad-CAM. Initially, the images are collected using IoMT devices of skin diseases and undergo preprocessing, which includes resizing, noise removal and contrast enhancement using AK-CLAHE, followed by color analysis and segmentation using YCbCr and DF-U-Net. Morphological operations are then applied during post-processing. The shape and structure of lesions are analyzed using CMED. Meanwhile, using Grad-CAM, Contextual Information Analysis (CIA) is performed on preprocessed data. Concurrently, disease symptom prediction data (i.e. clinical data) are collected, and features are extracted from this data, including boundary localization and CIA. Finally, skin diseases are classified using EN-QNN. The proposed model achieved a high accuracy of 98.68051%, surpassing current techniques.},
  archive      = {J_IJPRAI},
  author       = {Bhavya Kadiyala and Sunil Kumar Alavilli and Rajani Priya Nippatla and Subramanyam Boyapati and Chaitanya Vasamsetty and Harleen Kaur},
  doi          = {10.1142/S0218001425500132},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2550013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {AN advanced AI approach-based skin disease prediction system utilizing EN-QNN and grad-CAM in IoMT environment},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SUMMR: A unified multimodal representation framework for songs. <em>IJPRAI</em>, <em>39</em>(12), 2558001. (<a href='https://doi.org/10.1142/S0218001425580017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The understanding and representation of songs is a crucial issue in music platforms, as it can facilitate numerous applications in the music field. Songs are a common multimodal art form within the music domain, achieving rich musical connotations and strong expressiveness. However, the data of songs exhibit obvious multimodal and heterogeneous characteristics, presenting significant challenges to the understanding and representation of songs. Regrettably, the current methods do not respond to these challenges effectively. To this end, in this study, a unified multimodal representation framework for songs, namely SUMMR, is proposed. Specifically, first, a two-layer framework is put forward. In embedding layer, the features of different modalities data are embedded into a unified space. In content layer, a novel cross-modal attention mechanism is designed, which effectively capture the cross-modal semantic associations and deep music features, thereby obtaining a unified representation of songs. Then, a two-level hierarchical pre-training algorithm is proposed, which can effectively lower the training cost. Finally, experiments are conducted on two typical music tasks with public datasets of songs, where the experimental results demonstrate the effectiveness of SUMMR for understanding and representation of songs, and also show that SUMMR has good capability of being fine-tuned in many song-based tasks.},
  archive      = {J_IJPRAI},
  author       = {Lei Ye and Bing Shen and Yu Su and Xiao Chen and Yi Gong and Yifei Zhou and JunYu Lu},
  doi          = {10.1142/S0218001425580017},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2558001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {SUMMR: A unified multimodal representation framework for songs},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal medical image fusion based on total variation decomposition and spectral residual saliency. <em>IJPRAI</em>, <em>39</em>(12), 2557016. (<a href='https://doi.org/10.1142/S0218001425570162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image fusion is an image processing method that uses computer technology to integrate medical images of different modalities to achieve synchronous visualization of multiple types of information; in this way, multiple medical images complement each other, increasing the accuracy and completeness of clinical diagnosis and treatment. Multiple medical image fusion algorithms have been developed, but they all have drawbacks. One of these is that they are not always reusable or portable due to issues such as faulty fusion rule design. Image reconstruction leads to a decrease in image quality, as the reconstruction process may lose some original information, and the complexity of transformation algorithms and medical images can easily affect performance and robustness. By merging spectral residual (SR) saliency with total variation decomposition, this paper presents a medical image fusion method that addresses current issues. Using total variation, we first dissect the source images to identify their structural and textural elements. Additionally, SRs are utilized for the extraction of saliency images. Moreover, separate procedures are used to merge the structural, textural, and saliency pictures. Finally, the three fused images are added together to form the final product. In terms of both clarity of detail and information retention, our experimental results show that this approach is superior to competing methods. In addition, our Q SD increased by 31.76%, and our Q RMSE increased by 48.19% compared with the average value of the reference algorithms.},
  archive      = {J_IJPRAI},
  author       = {Xiaolong Gu and Ying Xia and Ying Wei},
  doi          = {10.1142/S0218001425570162},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2557016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multimodal medical image fusion based on total variation decomposition and spectral residual saliency},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient prediction and analysis of diabetics based on hybrid convolutional pyramid squeeze attention network with explainable AI. <em>IJPRAI</em>, <em>39</em>(12), 2557012. (<a href='https://doi.org/10.1142/S0218001425570125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes is a chronic metabolic condition that manifests early as high blood sugar levels brought on by the body’s incapacity to properly metabolize or use insulin. The increasing incidence of diabetes worldwide highlights the urgent need for early detection and prediction methods to enable timely management and intervention. This study proposes a four-phase optimized lightweight convolutional pyramid squeeze attention (LwCPSA) model for diabetes prediction. The log-sinh with adaptive Box-Cox transformation is used to handle outliers, normalize data, and improve model robustness, ensuring accurate diabetes prediction. The LwCPSA model enhances multi-scale feature extraction, and the improved gold rush optimization (GRO) fine-tunes model parameters to improve accuracy while reducing computational complexity. The improved GRO is used to further tune the LwCPSA parameters, which lowers computing complexity. SHAP-based explainability is utilized to identify the most influential features contributing to diabetes prediction, providing transparent insights into how the model weighs different risk factors, such as glucose levels, BMI, and HbA1c, to make accurate predictions. The proposed method is implemented using Python. The proposed approach achieves remarkable results, with an F1-score of 99.47%, an accuracy of 99.65%, a precision of 99.45%, a recall of 99.23%, a specificity of 99.56%, and so on. These findings improve prediction accuracy and provide a flexible, scalable approach for diabetes prediction, which greatly increases the effectiveness of medical applications. Furthermore, the proposed approach has the potential to improve diabetes diagnosis and treatment outcomes by enabling early and accurate prediction, ultimately reducing the risk of complications and improving patient quality of life.},
  archive      = {J_IJPRAI},
  author       = {S. Sai Prakash and A. C. Subhajini},
  doi          = {10.1142/S0218001425570125},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2557012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An efficient prediction and analysis of diabetics based on hybrid convolutional pyramid squeeze attention network with explainable AI},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight low-light image enhancement network via channel prior and gamma correction. <em>IJPRAI</em>, <em>39</em>(12), 2554013. (<a href='https://doi.org/10.1142/S0218001425540138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human vision relies heavily on available ambient light to perceive objects. Low-light scenes pose two distinct challenges: information loss due to insufficient illumination and undesirable brightness shifts. Low-light image enhancement (LLIE) refers to image enhancement technology tailored to handle this scenario. We introduce CPGA-Net, an innovative LLIE network that combines dark/bright channel priors and gamma correction via deep learning and integrates features inspired by the atmospheric scattering model and the Retinex theory. This approach combines the use of traditional and deep learning methodologies, designed within a simple yet efficient architectural framework that focuses on essential feature extraction. The resulting CPGA-Net is a lightweight network with only 0.025 million parameters and 0.030 s for inference time, yet it achieves superior performance over existing LLIE methods on both objective and subjective evaluation criteria. Furthermore, we utilized knowledge distillation with explainable factors and proposed an efficient version that achieves 0.018 million parameters and 0.006 s for inference time. The proposed approaches inject new solution ideas into LLIE, providing practical applications in challenging low-light scenarios.},
  archive      = {J_IJPRAI},
  author       = {Shyang-En Weng and Shaou-Gang Miaou and Ricky Christanto},
  doi          = {10.1142/S0218001425540138},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2554013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A lightweight low-light image enhancement network via channel prior and gamma correction},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A GPU-based framework for adaptive kernel size selection in visual pattern recognition. <em>IJPRAI</em>, <em>39</em>(12), 2552017. (<a href='https://doi.org/10.1142/S0218001425520172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual pattern recognition systems relying on fixed-kernel Convolutional Neural Networks (CNNs) often struggle with heterogeneous image regions, leading to suboptimal feature extraction. This paper introduces a GPU-based framework that addresses the challenges of adaptive kernel size selection, including parallelism disruption, resource contention, and real-time constraints. The framework comprises three key innovations: (1) an online feature analysis module with lightweight reinforcement learning (RL) for dynamic kernel selection, leveraging multi-scale feature pyramids and a Q-learning model optimized for GPU parallel execution; (2) a dynamic resource allocation strategy that partitions GPU resources by kernel size, predicts register/shared memory requirements, and optimizes memory access patterns; and (3) a pipeline folding and cache-aware scheduling framework that integrates feature analysis, decision-making, and convolution into a single kernel while enabling priority-driven preemption for real-time performance. Extensive experiments on datasets like CIFAR-100, ImageNet-1K, and VOC2012 demonstrate that the framework achieves up to 39% higher inference throughput, 2.2% improved recognition accuracy, and 16% better GPU utilization compared to state-of-the-art methods, all while maintaining sub-30 ms end-to-end latency. The proposed approach bridges the gap between adaptive kernel intelligence and GPU efficiency, offering a robust solution for real-time visual pattern recognition tasks.},
  archive      = {J_IJPRAI},
  author       = {Jiahong Wang and Zixuan Wang},
  doi          = {10.1142/S0218001425520172},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2552017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A GPU-based framework for adaptive kernel size selection in visual pattern recognition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Jaya-waterwheel plant algorithm with hybrid deep learning and probabilistic fusion for image inpainting. <em>IJPRAI</em>, <em>39</em>(12), 2552015. (<a href='https://doi.org/10.1142/S0218001425520159'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a memory-efficient and high-resolution image inpainting framework called Jaya Waterwheel Plant Algorithm-Hybrid Context Deep Learning (JWWPA-Hybrid DL). Designed to address the limitations of conventional Deep Learning (DL) models that handle only low-resolution images due to memory constraints, the proposed method integrates optimization and DL for more accurate and realistic image restoration. The workflow involves: (1) acquiring a damaged input image from the Figshare database, (2) applying inpainting via a Context-Conditional Generative Adversarial Networks (CC-GAN) and a context encoder, both optimized using the JWWPA — a hybrid of the Jaya algorithm and the Waterwheel Plant Algorithm (WWPA), and (3) combining the outputs through probabilistic function-based image fusion. The proposed JWWPA-Hybrid DL achieves a PSNR of 38.555 dB, SDME of 58.472 dB, SSIM of 0.817, and UQI of 0.827, demonstrating superior performance compared to existing approaches.},
  archive      = {J_IJPRAI},
  author       = {T. M. Sivanesan and N. Vijayaraj},
  doi          = {10.1142/S0218001425520159},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2552015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Jaya-waterwheel plant algorithm with hybrid deep learning and probabilistic fusion for image inpainting},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transformer-based method for few-shot image recognition in federated learning environments. <em>IJPRAI</em>, <em>39</em>(12), 2551015. (<a href='https://doi.org/10.1142/S0218001425510152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot image recognition in federated learning (FL) environments presents unique challenges due to data heterogeneity, limited local samples, and strict privacy constraints. To address these issues, we propose a novel Transformer-based approach that enables effective visual recognition with minimal labeled data on distributed clients. The proposed model introduces an adaptive multi-scale window attention mechanism to enhance feature extraction under sparse data conditions. Furthermore, a collaborative attention strategy is developed to enable privacy-preserving semantic knowledge exchange across clients. To alleviate the class imbalance and overfitting problems common in few-shot settings, we design an improved Focal Loss function guided by class-wise entropy. Additionally, a progressive knowledge distillation framework is incorporated to maintain model consistency across training rounds. Extensive experiments conducted on multiple few-shot image benchmarks under federated settings demonstrate that our method significantly outperforms existing baselines in terms of accuracy, communication efficiency, and generalization.},
  archive      = {J_IJPRAI},
  author       = {Guodong Wang and Qianqian Li and Xinyi Lin and Zixuan Wang and Fengjun Zhou and Qun Wang and Weiguo Lai and Xueqiang Gao},
  doi          = {10.1142/S0218001425510152},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2551015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A transformer-based method for few-shot image recognition in federated learning environments},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A framework for damage detection of building facades using three-dimensional laser scanning and the revit model. <em>IJPRAI</em>, <em>39</em>(12), 2550022. (<a href='https://doi.org/10.1142/S0218001425500223'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid urbanization and proliferation of high-rise buildings in China, facade damage such as cracking, peeling, and tile detachment has become increasingly prevalent, posing severe safety risks to the public. Traditional visual inspection methods are labor-intensive, subjective, and lack quantitative standards, often resulting in missed or inaccurate damage detection. This study proposes a systematic framework that leverages high-precision three-dimensional (3D) laser scanning and Revit model to detect facade anomalies efficiently and quantitatively. Using a dormitory building in Yibin City, Sichuan Province as a case study, we employed the Z + F IMAGER 5010C laser scanner to capture dense point cloud data of the building facade. This model was then quantitatively compared with the Revit solid model to establish a spatial information database for facade damage. This database was further calibrated with actual site conditions. The case study demonstrated that using a deviation threshold of ± 6 mm as the demarcation point effectively identified hollowing and peeling damage, and other issues on a building facade. A total of 18 bulges on the example building facade were identified via the proposed framework; the detection results allowed for quantification and visualization of the facade issues. The results were integrated into a digital building management platform that supports damage classification, spatial mapping, task scheduling, and closed-loop maintenance tracking. This integrated approach enhances facade safety monitoring by providing a quantifiable, repeatable, and automated detection workflow, providing a scalable solution for digitalized facade condition monitoring in urban environments.},
  archive      = {J_IJPRAI},
  author       = {Yi Wu and Zhewei Wang and Hong Wen and Xuebin Tang and Dan Yuan and Zhihao Chen and Liang Zeng},
  doi          = {10.1142/S0218001425500223},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2550022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A framework for damage detection of building facades using three-dimensional laser scanning and the revit model},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UNet and swin transformer fusion network for lesion segmentation in biological kidney imaging. <em>IJPRAI</em>, <em>39</em>(12), 2550021. (<a href='https://doi.org/10.1142/S0218001425500211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We research the segmentation of lesions in medical images using the PST-UNet model, verifying the preservation of spatial features of medical lesions, and improving the accuracy of medical lesion segmentation. The PST-UNet (positive distribution data Swin transformer) model combines transformer and U-shaped structures. It uses cascaded convolution fusion modules to integrate the encoder’s multi-scale features. The encoder includes the Swin transformer block and the entire Gaussian Error Linear Unit (GELU) activation function. The decoder uses the Swin transformer block, upsampling, and skip connections from the cascaded convolution fusion modules. This approach effectively preserves more spatial features of medical lesions and improves the accuracy of kidney lesion segmentation, achieving a 0.02289 improvement in accuracy. The PST-UNet model can improve the segmentation accuracy of normally distributed medical lesion data, which has a positive effect on the treatment of kidney disease.},
  archive      = {J_IJPRAI},
  author       = {Xuemei Shi and Xiedong Song and Ming Deng and Dalei Zhang and Xiaoyan Li and Baoguo Chen},
  doi          = {10.1142/S0218001425500211},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2550021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {UNet and swin transformer fusion network for lesion segmentation in biological kidney imaging},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAR-FPN: Scale adaptive and reverse fusion object detection. <em>IJPRAI</em>, <em>39</em>(12), 2550020. (<a href='https://doi.org/10.1142/S021800142550020X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is widely used in many fields, and multi-scale feature extraction is crucial for accurate detection. The Feature Pyramid Network (FPN) is a commonly adopted feature extraction approach in object detection. Nevertheless, direct fusion between top-down feature layers in FPN leads to misalignment and loss of feature information. To address these limitations, this paper proposes a novel feature pyramid network based on FPN, termed SAR-FPN, which consists of two components: the Scale Adaptive Triple-Branch Module (SATM) and the Reverse Feature Fusion Module (RFFM). Specifically, SATM enhances the performance for large objects through its triple-branch design. It selects the appropriate branch based on object scale, assigns suitable receptive fields for objects of different sizes, and performs feature alignment. The RFFM addresses the issue of poor performance in small object detection by implementing a bottom-up feature fusion pathway. Extensive experiments on the PASCAL VOC 2012 and MS COCO 2017 datasets validated the effectiveness of SAR-FPN.},
  archive      = {J_IJPRAI},
  author       = {Nuo Cheng and TaiPing Xiong and Gengshen Cui and Minghua Pan and Xiangjie Wu},
  doi          = {10.1142/S021800142550020X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2550020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {SAR-FPN: Scale adaptive and reverse fusion object detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-based sensitive data recognition with stepwise chain-of-thought reasoning. <em>IJPRAI</em>, <em>39</em>(12), 2550019. (<a href='https://doi.org/10.1142/S0218001425500193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying sensitive text data remains a critical challenge for industrial data protection, as conventional methods lack flexibility and demand extensive manual labeling. While Large Language Models (LLMs) offer a promising avenue for automated sensitive data recognition (SDR), their susceptibility to “hallucination” often leads to misclassification. To overcome this, we introduce an LLM-based SDR framework powered by stepwise Chain-of-Thought (CoT) reasoning. Our approach employs a rigorously designed prompt template to enable LLMs to iteratively reassess and refine their output, leading to precise identification of sensitive text positions and highly fine-grained recognition results. Experiments on a real-world dataset from the electric sector demonstrate the superior performance of our method in domain-specific SDR tasks, highlighting its strong potential for robust and scalable application in complex industrial environments.},
  archive      = {J_IJPRAI},
  author       = {Honggang Wang and Shenglong Liu and Yiwen Jiang and Zhenqi Guo and Jiehao Tang},
  doi          = {10.1142/S0218001425500193},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2550019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {LLM-based sensitive data recognition with stepwise chain-of-thought reasoning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application exploration of multi-scale edge detection and SIFT feature fusion in digital twin pattern recognition for power grids. <em>IJPRAI</em>, <em>39</em>(12), 2550016. (<a href='https://doi.org/10.1142/S0218001425500168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital twin technology is transforming the way power grid infrastructure is monitored and managed, yet accurate pattern recognition under complex visual conditions remains a significant challenge. Traditional edge- or feature-based methods struggle to maintain robustness in environments affected by fog, shadow, or occlusion. This paper proposes a fusion framework that combines multi-scale edge detection and SIFT-based local descriptors, integrated through a learnable attention mechanism that adaptively weights features at each pixel location. The method is evaluated on a custom UAV-acquired dataset containing high-resolution power grid imagery under diverse environmental scenarios. Experimental results demonstrate that the proposed approach significantly outperforms edge-only, SIFT-only, and U-Net models across SSIM, F 1-score, and IoU metrics, while maintaining practical inference speed. The model also achieves the lowest 3D registration error in point cloud alignment. These results confirm the effectiveness of our method and highlight its potential for accurate, robust digital twin construction in real-world grid inspection systems.},
  archive      = {J_IJPRAI},
  author       = {Chunmei Zhang and Xingque Xu and Yongjian Li and Silin Liu and Jianyi Li},
  doi          = {10.1142/S0218001425500168},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2550016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Application exploration of multi-scale edge detection and SIFT feature fusion in digital twin pattern recognition for power grids},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse gaussian harmonic filter (IGHF): Spatial filter with contrast stretching priority. <em>IJPRAI</em>, <em>39</em>(12), 2534001. (<a href='https://doi.org/10.1142/S0218001425340018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images are corrupted by the Additive White Gaussian Noise (AWGN) from imaging devices. Existing spatial-domain filters often introduce edge distortion at high noise levels. We propose the Inverse Gaussian Harmonic Filter (IGHF), a novel training-free denoising framework that inverts the Gaussian kernel and employs harmonic weighting on standard deviation terms. The first closed-form mathematical model provides superior edge preservation while effectively suppressing noise. We evaluate hybrid approaches combining IGHF with BM3D [K. Dabov, A. Foi, V. Katkovnik and K. Egiazarian, Image denoising by sparse 3-D transform-domain collaborative filtering, IEEE Trans. Image Process . 8 (2007) 2080–2095.] and DnCNN [K. Zhang K, W. Zuo W, Y. Chen, D. Meng and L. Zhang, Beyond a Gaussian denoiser: Residual learning of deep CNN for image denoising, IEEE Trans. Image Process . 7 (2017) 3142–3155.], achieving up to 1.50 dB PSNR gain over the state-of-the-art spatial methods. Quantitative evaluation on eight benchmark images demonstrates effectiveness across noise levels ( σ 2 = 0 . 0 1 –0.05). Triple-Hybrid fusion achieves 31.96 dB PSNR with superior SSIM (0.912) and edge-preservation FOM (0.850), outperforming BM3D by 0.35 dB through systematic grid-search optimization. Runtime analysis confirms real-time capability: Enhanced IGHF processes HD frames in < 2 0 0 ms with minimal memory footprint ( < 8 MB), enabling consumer-grade deployment. The deterministic approach provides a novel mathematical foundation for spatial-domain denoising with applications in deep-learning architectures.},
  archive      = {J_IJPRAI},
  author       = {Fatih Marasli and Serkan Ozturk},
  doi          = {10.1142/S0218001425340018},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2534001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Inverse gaussian harmonic filter (IGHF): Spatial filter with contrast stretching priority},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personality traits prediction methods: A survey. <em>IJPRAI</em>, <em>39</em>(12), 2530002. (<a href='https://doi.org/10.1142/S0218001425300024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personality traits prediction plays a significant role in several real-world applications, such as improving the education system, improving production in manufacturing, monitoring social media content, sentiment analysis of crowds for opinion mining, judging abnormalities in personal behavior, etc. The demand for personality traits prediction has increased drastically after COVID-19. Therefore, numerous methods have emerged to predict personality traits from a variety of sources, including handwriting, interviews, social media, text, images, and audio. This review focuses on methods developed between the years 2020 and 2024, categorizing them into Handwriting (Graphology), Vision (images and videos), Audio (speech and acoustic signals), Textual (status updates, descriptions), and Multimodal (combinations of the aforementioned) approaches. We critically analyze the methods proposed, the datasets, the scope of the work, the results obtained, and noteworthy remarks. Based on our critical analysis, we notice that increasingly methods tend to use deep learning over handcrafted features. Additionally, personality traits prediction methods are trending more toward multimodal methods because they consistently achieve the highest accuracy among the input modalities. Detailed discussions, tabular presentations, and figures facilitate easy comprehension and future reference. Then, we shed light on the challenges in this field. Many key applications are detailed. Additionally, we highlight significant limitations and offer insights into potential future directions.},
  archive      = {J_IJPRAI},
  author       = {Kunal Biswas and Shivakumara Palaiahnakote and Umapada Pal and Ram Sarkar},
  doi          = {10.1142/S0218001425300024},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2530002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Personality traits prediction methods: A survey},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The time and frequency distribution characteristics of interference signals based on artificial intelligence technology. <em>IJPRAI</em>, <em>39</em>(11), 2559014. (<a href='https://doi.org/10.1142/S0218001425590141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a method with artificial intelligence to optimize manual astronomical observation works. For the large amount of data generated by radio astronomy monitoring, we compile 4 algorithms including VTD, WSV, MAD, and MAS in the procedure of data analysis. Then the platform can recognize the radio interference signals from radio astronomy monitoring data and analyze the spatiotemporal distribution characteristics, and generate reports automatically. Through this method, the amount of work would greatly improve work efficiency and accuracy. The distribution patterns and changes of radio frequency interference signals in the area can be grasped and analyzed efficiently and quickly by astronomy researchers.},
  archive      = {J_IJPRAI},
  author       = {Shengyang Li and Zhixiang Zhao and Bin Tian and Junwen Tang and Ning Fu and Liang Dong},
  doi          = {10.1142/S0218001425590141},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2559014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {The time and frequency distribution characteristics of interference signals based on artificial intelligence technology},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bipartite coordination control for multi-robot systems with coopetition-interaction. <em>IJPRAI</em>, <em>39</em>(11), 2559013. (<a href='https://doi.org/10.1142/S021800142559013X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed bipartite coordination control problem of multi-robot systems (MRSs) with coopetition-interaction is investigated in this paper. First, a novel symmetric positive definite matrix is constructed based on bipartite consensus protocol without taking into account mutual velocity information, where the control gain constant is determined by the properties of the Laplacian matrix corresponding to the directed graph. Second, leveraging matrix decomposition properties, our schemes ensure the symmetric evolution of the convergence state and the explicit expression of the bipartite containment solution for all followers. Finally, two numerical simulations are presented to demonstrate the feasibility and effectiveness of the proposed algorithms.},
  archive      = {J_IJPRAI},
  author       = {Jingyi Liu and Hengyu Li and Hongkun Zhou},
  doi          = {10.1142/S021800142559013X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2559013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Bipartite coordination control for multi-robot systems with coopetition-interaction},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local attention mechanism and temporal prediction-based multi-person pose estimation. <em>IJPRAI</em>, <em>39</em>(11), 2557018. (<a href='https://doi.org/10.1142/S0218001425570186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, attention mechanisms have been widely used in many fields due to their excellent image focusing ability to produce more discriminative feature representations. However, in human pose estimation, methods based on attention mechanisms tend to have high computational overhead and are difficult to process video data in real time. In addition, existing algorithms do not make good use of the similarity between consecutive frames, and often repeat the computation many times on the same image. Therefore, this paper proposes a method based on a local attention mechanism and temporal prediction. The method first passes the input image through a body detector and then focuses attention on the head of the person, generating a large module of head information perception. This helps to find all the people in the image, avoiding missed detections, and this approach, which uses a local attention mechanism, has a small computational overhead. Then, to make the network layers closer to each other while keeping the parameters sparse, the features generated by the deep network will be reconstructed and compared with the input image. Finally, in order to reduce repetitive computation, the method determines the similarity between the preceding and following frames by means of multiple sampling points, which is used to determine whether the information from the previous frame is used to guide the localization of the nodes in the following frame. This allows the algorithm to remain real time when processing video. Experiments on the COCO and PoseData I datasets show that the algorithm outperforms all 10 comparison algorithms in terms of both accuracy and image continuity.},
  archive      = {J_IJPRAI},
  author       = {Jianghai He and Ting Wu and Ronghua Shang and Weitong Zhang and Yangyang Li},
  doi          = {10.1142/S0218001425570186},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2557018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Local attention mechanism and temporal prediction-based multi-person pose estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MFAF-net: Lung lobe segmentation in CT images based on multiscale feature and attention fusion network. <em>IJPRAI</em>, <em>39</em>(11), 2557017. (<a href='https://doi.org/10.1142/S0218001425570174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computed tomography (CT) images are widely used as clinical aids. Accurate lung lobe segmentation in CT images provides a strong basis for the diagnosis and treatment of lung diseases, but challenges arise from incomplete fissures, unpredictable pathological deformations, indistinguishable pulmonary arteries and veins, and severe injuries to the lung airways. To tackle these issues, we propose a multiscale feature and attention fusion network (MFAF-Net), which emphasizes lung fissure representations and suppresses the influence of other structures in lung lobe segmentation. First, the network follows the traditional encoder–decoder structure, incorporating FastKANConv-based residual modules to prevent gradient vanishing and further improve the spatial feature information extraction capability. Second, the adaptive spatial feature fusion module (ASFF), the atrous spatial pyramid pooling module (ASPP), and the feature fusion strategy are fused to address the target feature information loss issue effectively. Third, a stronger spatial and channel squeezing and excitation module (scSE) is improved to extract semantic information in both the spatial and channel domains in the skip connection part. The efficacy of the presented model is validated through experiments conducted on an existing dataset, which demonstrate superior intersection over union (IoU) values and lower Hausdorff distances (HD) than other efficient segmentation networks. The experimental results substantiate that the designed framework can effectively segment lung lobes in CT images.},
  archive      = {J_IJPRAI},
  author       = {Yuanyuan Peng and Jiawei Liao},
  doi          = {10.1142/S0218001425570174},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2557017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {MFAF-net: Lung lobe segmentation in CT images based on multiscale feature and attention fusion network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual rhythms-based video face spoofing detection using deformable self-attention ResNet model. <em>IJPRAI</em>, <em>39</em>(11), 2557010. (<a href='https://doi.org/10.1142/S0218001425570101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are primarily three types of techniques that may compromise face authentication: print, replay, as well as 3D mask. It seems that video replay assaults are the most difficult to detect out of all of them. Even if there are a lot of ways to prevent spoofing assaults, especially with high-quality videos, a sophisticated detector is still required. This study describes video-based spoofing techniques by analyzing the frequency-domain noise residual and extracting discriminative features with a dynamic texture descriptor. We present a potential detector that outperforms the state-of-the-art on the most difficult video spoofing dataset. On the other side, inexperienced camera operators often introduce undesired camera shake or motion into their recordings. The goal of video face spoofing methods is to improve the quality of the captured image by identifying and fixing any imperfections that may have occurred during capture. To assess video face spoofing techniques qualitatively, we offer and examine a new representation using Visual Rhythms (VR). The efficiency of the visual representation as a qualitative metric for analyzing spoofing attacks is shown via experiments done on various video sequences. Using ResNet-18, our database achieved a spoofing detection accuracy of 99.75%. Spoof detection abilities were better for photographs with a pinch angle, close distance images, with replay assaults compared to front images, far distance visuals, with print attacks, respectively, according to the trial findings for different circumstances. Compared to testing with6 other databases (DBs) before training with our DB, the results of the cross-database verification showed an improvement in performance. Since there was little variation in the findings of the cross-device verification based on camera type, we can say that the detection accuracy is unaffected by the kind of image sensor. We also provide a method to objectively determine a measure derived from VR. The experiment found that the Total Error Rate (HTER) for the four independent data sets was 3.5%, whereas the synthesized data set had an HTER of 1%.},
  archive      = {J_IJPRAI},
  author       = {Devi Palanisamy and S. Anila},
  doi          = {10.1142/S0218001425570101},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2557010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Visual rhythms-based video face spoofing detection using deformable self-attention ResNet model},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time application-based bidirectional long short-term memory-based adam optimizer for leaf disease classification in sugarcane leaves. <em>IJPRAI</em>, <em>39</em>(11), 2557009. (<a href='https://doi.org/10.1142/S0218001425570095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sugarcane is considered to be a vital crop across worldwide, but the production of it is impacted by the effect of different diseases. Early diagnosis and detection are mandatory for the timely intervention and yield preservation. This will ensure the optimal yield of the crop and its quality. Hence in this approach a real-time hybrid approach BADAM is proposed for the detection and classification of the sugarcane leaf diseases. The hybrid approach BADAM consists of Bidirectional Long Short-Term Memory (BiLSTM) network combined with the Adam optimizer. For training the model both disease-affected leaves and the nonaffected leaves are considered and initially subjected to preprocessing model for enhancing the feature extraction process. The BiLSTM model is designed to capture both temporal and spatial dependencies within the image sequences, effectively addressing the challenges posed by varying leaf conditions and environmental factors. The Adam optimizer is employed to improve convergence rates and enhance model performance through adaptive learning rates. The model’s performance is evaluated using the metrics like accuracy, recall, F 1 -score and precision by demonstrating significant improvements over traditional classification methods. The experimentation results indicate that the proposed approach provides better accuracy by facilitating the real-time disease detection by making it comfortable by providing a valuable tool for farmers and agricultural practitioners. The implications of this work extend to the development of smart agricultural systems that leverage deep learning technologies for sustainable farming practices. This approach not only provides an effective tool for leaf disease classification but also establishes a foundation for future research in precision agriculture and plant health monitoring, promoting sustainable farming practices through early disease detection and intervention.},
  archive      = {J_IJPRAI},
  author       = {J. Chandraleka and P. Selvaraj},
  doi          = {10.1142/S0218001425570095},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2557009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A real-time application-based bidirectional long short-term memory-based adam optimizer for leaf disease classification in sugarcane leaves},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective image denoising model using improved deep learning techniques with optimization algorithm. <em>IJPRAI</em>, <em>39</em>(11), 2552018. (<a href='https://doi.org/10.1142/S0218001425520184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physicians and radiologists utilize medical image processing to diagnose diseases. However, medical images can be compromised by noise introduced through various imaging processes, leading to diminished image quality. This degradation manifests as blurred boundaries, suppressed edges, and loss of structural details. Preserving edges and details is crucial for accurate disease diagnosis. Therefore, medical image denoising is essential in aiding physicians with diagnosis. MRI, CT, X-ray, and ultrasound images are examples of common medical image types. To overcome the above problems, this work implemented an Improved Convolutional Neural Network (ICNN) with the Self-Improved Orca Predation Algorithm (SI-OPA) for image denoising for medical image denoising. ICNN has been used to treat noise-distorted medical images. The CNN’s weights are modified by SI-OPA, increasing the precision of denoising. Comprehensive evaluations concern cutting-edge denoising approaches, encompassing conventional, and deep learning-based methods, emphasizing denoising efficacy, computing efficiency, and picture detail retention. Compared to traditional image denoising algorithms, the proposed method offers superior noise suppression, as evidenced by improved accuracy, Structural Similarity (SSIM), Peak Signal-to-Noise Ratio (PSNR), and Standard Deviation (STD) metrics. Additionally, experimental findings support the suggested denoising algorithm’s viability and efficiency. Finally, the findings show that whereas the current approaches only reach 86%, 82%, 78%, and 65% of the study results, the suggested model achieves a high 94%. Accuracy is 91%, SSIM is 0.91, PSNR is 45.75%, and STD metrics is 43.89%.},
  archive      = {J_IJPRAI},
  author       = {S. Mythili and S. S. Sivaraju and T. Anuradha and S. Sivarajan},
  doi          = {10.1142/S0218001425520184},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2552018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An effective image denoising model using improved deep learning techniques with optimization algorithm},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic compiler tuning for inlining with machine learning. <em>IJPRAI</em>, <em>39</em>(11), 2552016. (<a href='https://doi.org/10.1142/S0218001425520160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic compiler tuning has become one of the hot research areas attracting extensive attention in recent years. By using machine learning models to learn from large-scale experimental samples, it can efficiently search through the massive combinations of compiler optimization parameters within limited time, identifying parameter sets that better suit the current microprocessor architecture and application programs, thereby achieving higher execution efficiency of target programs than default compilation options. This paper designs and implements an automatic compiler tuning mechanism, employing an XGBoost performance model built through a “learn-while-searching” approach to guide the search process of simulated annealing algorithm (SA). The XGBoost model can predict the performance deltas of different GCC optimization parameters, and these deltas are used to bias the annealing acceptance probability. This mechanism combines the global modeling capability of machine learning with the local search advantages of the SA, enhancing both search efficiency and effectiveness. Based on this tuning mechanism, the paper conducts in-depth research on the inlining optimization process inside the GCC compiler, proposing and implementing two automatic tuning schemes: (1) automatic tuning of inlining compilation options, which influences the number of inlined functions through different values of these options, thereby affecting program performance; (2) automatic tuning of function inlining at call sites, which uses GCC plugins technology to replace the ipa-inline pass in GCC optimization, enabling control over whether to inline functions at each call site and thus impacting program performance. Extensive experiments are conducted on benchmark suites such as SPEC CPU2006, cBench, and WRF. The results show that compared with the Critical Flag Selection-based Compiler Auto-tuning (CFSCA) method published in ASE2023, the Bayesian Optimization-based Compiler Auto-tuning (BOCA) method published in ICSE2021, and other traditional search algorithms, the proposed tuning mechanism achieves better optimization effects on most benchmarks.},
  archive      = {J_IJPRAI},
  author       = {Da Huang and Xiaohua Shi and Yuchen Feng and Changhai Zhao and Jiamin Wen and Minqiang Shang},
  doi          = {10.1142/S0218001425520160},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2552016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automatic compiler tuning for inlining with machine learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedIoT: Optimizing the communication-efficient federated learning aggregation algorithm under heterogeneous data for large-scale IoT. <em>IJPRAI</em>, <em>39</em>(11), 2552013. (<a href='https://doi.org/10.1142/S0218001425520135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training machine learning models effectively under severe communication, computation, and privacy restrictions has become more challenging due to the fast proliferation of Internet of Things (IoT) networks. With federated learning, dispersed IoT devices may train together without exposing any sensitive data. Unfortunately, privacy concerns, device heterogeneity, and communication constraints are common issues with large-scale installations. Through the utilization of adaptive asynchronous training, dynamic communication optimization, hierarchical aggregation, and differential privacy enhancement, we present a new federated learning communication framework that can withstand device delays, minimize bandwidth usage, improve scalability through edge-cloud coordination, and guarantee the protection of user data. Extensive testing on both real-world and synthetic datasets shows that the suggested architecture drastically cuts down on communication cost and training delay in heterogeneous IoT environments, all while keeping model accuracy high and privacy resilient.},
  archive      = {J_IJPRAI},
  author       = {Qing Yan and Guoshi Wang and Dazhi Zhu and Jinxun Li},
  doi          = {10.1142/S0218001425520135},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2552013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {FedIoT: Optimizing the communication-efficient federated learning aggregation algorithm under heterogeneous data for large-scale IoT},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ResCap-MobileNet: Integrating multi-modal feature extraction and ensemble learning for osteoporotic fracture detection. <em>IJPRAI</em>, <em>39</em>(11), 2551013. (<a href='https://doi.org/10.1142/S0218001425510139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Osteoporotic fracture risk prediction algorithms using clinical risk factors, with or without bone mineral density measurements, have improved the accuracy of treatment targeting, yet current methods often suffer from limitations in image quality, computational cost, and diagnostic precision. To address these challenges, this methodology proposes a novel ensemble learning framework that introduces a novel ensemble learning framework called ResCap-MobileNet, to improve osteoporosis diagnosis using multi-modal medical imaging data taken from X-ray images. The approach begins with preprocessing, where contrast-limited adaptive histogram equalization (CLAHE) enhances image quality, followed by guided filtering for denoising and augmentation techniques like shearing and flipping. Segmentation is performed using a dual-scale residual U-Net (DSR_U-Net) for accurate identification of osteoporotic regions. For feature extraction, graph convolution networks (GCNs) preserve node connectivity in irregular data, while spherical harmonic transforms (SHTs) and topological data analysis (TDA) capture spatial and topological patterns. Feature selection is optimized through the self-adaptive hippopotamus optimization (SAHO) algorithm, which enhances global exploration with predator defense and exploration strategies. The classification stage utilizes ResCap-MobileNet, which integrates ResNeXt-101, MobileNetV3, and a capsule network (CapsNet) to ensure precise identification of osteoporotic fractures.},
  archive      = {J_IJPRAI},
  author       = {Srilatha Yelamati and Srikanth Thota},
  doi          = {10.1142/S0218001425510139},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2551013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {ResCap-MobileNet: Integrating multi-modal feature extraction and ensemble learning for osteoporotic fracture detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metric-based shape segmentation and retrieval. <em>IJPRAI</em>, <em>39</em>(11), 2550018. (<a href='https://doi.org/10.1142/S0218001425500181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton cut space has been used in shape segmentation and shape retrieval, and gives comparable good results in these two fields. However, only the cut length of the skeleton cut model has been used for these two research topics. So, we propose other three metrics extracted from the skeleton cut model for shape segmentation and retrieval. These metrics are max distance metric, average distance metric, and max–min distance metric. Finally, we show shape segmentation and retrieval experimental results by using our metrics. Our proposed metrics have added value to part-based segmentation and shape retrieval.},
  archive      = {J_IJPRAI},
  author       = {Cong Feng and Fangfang Peng and Ning Wang},
  doi          = {10.1142/S0218001425500181},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2550018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Metric-based shape segmentation and retrieval},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint waveform design of cognitive MIMO radar for multi-target detection. <em>IJPRAI</em>, <em>39</em>(11), 2550015. (<a href='https://doi.org/10.1142/S0218001425500156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The waveform design for cognitive multiple input multiple output (MIMO) radar systems remains an active area of research in modern radar signal processing. This study tackles the critical challenge of multi-target detection in cognitive MIMO radar by maximizing the minimum output signal-to-interference-plus-noise ratio (SINR) across all the detected targets. To resolve the nonconvex optimization problem arising from multi-target scenarios, we implement a semi-definite programming (SDP) algorithm incorporating approximate output SINR. Joint waveforms, including intra-pulse and inter-pulse, are applied to improve the freedom of the radar. The proposed work specifically integrates practical peak-to-average ratio (PAR) limitations, ensuring waveform feasibility for implementation in physical radar systems. Simulation results show that the proposed joint waveform can achieve more robust simultaneous multi-target detection performance in coherent clutter, while suppressing coherent interferences from other targets when detecting a certain target. Besides, our optimization algorithm has better real-time performance than existing algorithms.},
  archive      = {J_IJPRAI},
  author       = {Yunlei Zhang and Ke Li and Tingli Shen and Pei Peng},
  doi          = {10.1142/S0218001425500156},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2550015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Joint waveform design of cognitive MIMO radar for multi-target detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pedestrian detection using event cameras and YOLOv8: An optimized event stream to event frame conversion algorithm. <em>IJPRAI</em>, <em>39</em>(11), 2532002. (<a href='https://doi.org/10.1142/S0218001425320027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian detection is a crucial aspect of intelligent transportation systems and autonomous driving technologies, ensuring the safety and reliability of these systems. This paper presents a novel approach to pedestrian detection utilizing event cameras and the YOLOv8 model. The core of our methodology lies in a newly optimized algorithm for converting event streams to event frames, specifically tailored for pedestrian recognition. By addressing the unique challenges posed by high-speed and dynamic environments, our approach enhances the accuracy and efficiency of pedestrian detection systems. The proposed algorithm leverages the temporal and spatial resolution advantages of event cameras, effectively reducing noise and improving the clarity of the event frames through advanced denoising techniques such as temporal filtering, spatial filtering, and polarity consistency checks. These techniques ensure precise feature extraction and robust pedestrian identification. We conducted extensive road tests using the EVK4 event camera, capturing dynamic scenes involving pedestrian movement in various real-world conditions. Our experimental results demonstrate significant improvements in detection performance, achieving an Average Precision (AP) of 88.6%, a detection speed of 114 FPS, and high robustness under low light and high contrast conditions.},
  archive      = {J_IJPRAI},
  author       = {Qiufeng Wang and Qianying Guo and Kui Zhang and Lin Liu},
  doi          = {10.1142/S0218001425320027},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2532002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Pedestrian detection using event cameras and YOLOv8: An optimized event stream to event frame conversion algorithm},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent predictive battery management system with optimized bayesian LSTM network for lithium-ion batteries. <em>IJPRAI</em>, <em>39</em>(10), 2559011. (<a href='https://doi.org/10.1142/S0218001425590116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an Intelligent Predictive Battery Management System (IPBMS) designed to enhance the longevity, safety, and performance of lithium-ion batteries in e-bikes. Conventional battery management systems often estimate State of Charge (SoC), State of Health (SoH), or Remaining Useful Life (RUL) independently, limiting their effectiveness in predictive maintenance. To bridge this gap, the proposed IPBMS provides a comprehensive framework that simultaneously estimates SoC, SoH, and RUL, enabling a holistic battery health assessment. Hot Deck Imputation addresses missing and inconsistent data to ensure data reliability, while an Unscented Kalman Filter models battery nonlinearities, enhancing SoC estimation accuracy. Additionally, an Optimized Bayesian LSTM, refined with Mountain Gazelle Optimization, captures temporal dependencies to improve SoH and RUL predictions, further refined using a dense regression layer that minimizes errors. The model achieves Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE) of 0.59, 1.28, and 1.13 for SoC; 0.87, 1.50, and 1.22 for SoH; and 1.60, 1.28, and 2.69 for RUL, outperforming conventional models. Beyond prediction, the IPBMS offers actionable insights for charging optimization, early fault detection, energy-saving strategies, and adaptive riding modes, ensuring safer and more efficient battery utilization. This framework extends battery lifespan, minimizes unnecessary replacements, and enhances sustainability by optimizing energy management and reducing environmental impact, providing a novel, practical solution to improve battery reliability and efficiency in modern electric transportation.},
  archive      = {J_IJPRAI},
  author       = {P. Suresh Kumar and Niresh Jayarajan},
  doi          = {10.1142/S0218001425590116},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2559011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Intelligent predictive battery management system with optimized bayesian LSTM network for lithium-ion batteries},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heart disease detection using green anaconda optimization selection and MLGConv-based LWTNet classification with enhanced PeaFowl-based artificial intelligence algorithm. <em>IJPRAI</em>, <em>39</em>(10), 2557011. (<a href='https://doi.org/10.1142/S0218001425570113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The leading cause of death worldwide is heart disease. To counter this, a Deep Learning (DL) system, a subset of Artificial Intelligence (AI), has been developed to lower mortality rates by utilizing clinical insights for early detection. This study presents a novel method for diagnosing heart disease in patients and improving their prognosis. The extensive analysis is supported by multiple datasets sourced from repositories like UCI and Kaggle and locations like Long Beach, Cleveland, Switzerland, and Hungary. Gaussian Noise Removal, Motion Noise Reduction, and Contact Loss Handling (CLH) are used with a Fuzzy Inference System (KL-based FIS) integrated with Kalman filtering during the data preprocessing stage. The state-of-the-art Green Anaconda Optimization (GAO) is used for feature selection, simulating the stages of exploration and exploitation seen in wild green anacondas (GAs). The Multi-Level Group Convolution Light Weight Transformer Network, or LWTNet, which is based on MLGConv, is the foundation of the heart disease classification model. MLGConv is a module that effectively maintains lower computational costs while simultaneously representing multi-level and multi-group features, thereby improving local feature diversity. The Light Former transformer block comes from MLGConv and uses the least processing power to capture global dependencies, resulting in the final LWTNet. The Enhanced PeaFowl Optimization Algorithm (EPFOA) is utilized in the hyperparameter tuning of the classifier model. Interestingly, the suggested model outperforms earlier versions, with a remarkable accuracy rate of 99.87% in a comparative study.},
  archive      = {J_IJPRAI},
  author       = {Priyan Malarvizhi Kumar and C. Gokulnath and Jeeva Selvaraj and Balasubramanian Prabhu Kavin},
  doi          = {10.1142/S0218001425570113},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2557011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Heart disease detection using green anaconda optimization selection and MLGConv-based LWTNet classification with enhanced PeaFowl-based artificial intelligence algorithm},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepSkinGuard: A robust skin cancer detection framework integrating modified U-net segmentation and QuadraBlendNet fusion. <em>IJPRAI</em>, <em>39</em>(10), 2557007. (<a href='https://doi.org/10.1142/S0218001425570071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Global concern over skin cancer prompts the need for early detection to improve patient outcomes. This research addresses the critical issue of skin cancer detection, emphasizing the significance of early diagnosis for improved patient outcomes. The study identifies existing challenges in accuracy and robustness within current detection systems. To overcome these limitations, an advanced methodology is proposed, integrating cutting-edge techniques at every stage of the process. Methods: The research outlines key objectives, including the development of a comprehensive image augmentation strategy, the implementation of sophisticated preprocessing techniques, and the design of a modified U-Net architecture for accurate Region of Interest (ROI) identification. The hybrid optimization model, Bridging Optimization: Eagles’ Cruise Attack Fusion (BOECAF) Algorithm, merges the strengths of the Bald Eagle Search Optimization (BES) and Golden Eagle Optimizer (GEO) to effectively optimize the batch size of the U-Net. Deep learning-based feature extraction is employed using a pre-trained Inception V3, complemented by the extraction of color-based and texture-based features. A weighted feature fusion approach is introduced to effectively combine these diverse features. The integration of the QuadraBlendNet model, incorporating SqueezeNet, Xception, ResNet50, and DenseNet201, culminates in a comprehensive and diverse representation for skin cancer detection. Results: Utilizing Python, the model is implemented and yielded an accuracy of 98%, showcasing its high performance in classification tasks, and the ISIC dataset is used for evaluation. Conclusion: Anticipated outcomes include enhanced accuracy, improved generalization capabilities, and a significant advancement in early skin cancer diagnosis. This research contributes to the field by offering a more reliable and effective approach to address current limitations in skin cancer detection methodologies.},
  archive      = {J_IJPRAI},
  author       = {Joseph George and A. Parivazhagan},
  doi          = {10.1142/S0218001425570071},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2557007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DeepSkinGuard: A robust skin cancer detection framework integrating modified U-net segmentation and QuadraBlendNet fusion},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic attention-augmented neural network for accurate and efficient brain tumor classification and segmentation using MRI. <em>IJPRAI</em>, <em>39</em>(10), 2557005. (<a href='https://doi.org/10.1142/S0218001425570058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic Resonance Imaging (MRI) classification and segmentation of brain tumors are still an important problem in medical imaging because tumors are typically heterogeneous and multicellular. Old-fashioned diagnostics do not scale, generalize or compute efficiently, and hence do not apply clinically. In order to overcome these problems, the research introduces a new Dynamic Attention-Augmented Neural Network (DAANN) that will improve the classification accuracy, robustness and computational efficiency of brain tumors. The proposed DAANN features a dynamic attention system that enables it to choose the diagnostically relevant areas from MRI images automatically, enabling it to perform even in noisy or sparse data. Combined with feature extraction over time, the model captures morphological and sequential dependencies to render full tumor analysis. When trained on benchmark MRI images, the DAANN had a classification precision of 94.8% and topped models like CNN and BiLSTM. The model was also robust to noise — with 89.0% accuracy under moderate noise levels — and operated efficiently using very little training data, with 78.0% accuracy on 10% of the training set. These findings point to the DAANN’s real-time clinical availability in resource-constrained settings. As it takes up the challenge of what is possible, this work adds value to medical imaging as it provides a scalable and reproducible way to diagnose brain tumors. The work in the future will be to extend the model to multi-organ classification and to make it more easily read by clinical decision makers.},
  archive      = {J_IJPRAI},
  author       = {Manjunathan Alagarsamy and Jeevitha Sakkarai and E. Mariappan and K. Malathi and G. K. Kamalam and Arun Anthonisamy and Faisal Alshanketi and A. Rajaram},
  doi          = {10.1142/S0218001425570058},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2557005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Dynamic attention-augmented neural network for accurate and efficient brain tumor classification and segmentation using MRI},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Some efficient stock price trend prediction based on multi-category textual information and support vector machines. <em>IJPRAI</em>, <em>39</em>(10), 2555014. (<a href='https://doi.org/10.1142/S0218001425550146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a selected portfolio of large-cap blue-chip stocks in China A-share market, this study selects and quantifies three categories of textual information with comparatively notably low average daily volume: responses from Secretaries of the Boards of Listed Companies (RSB), Comments by Internet Influencers on Listed Companies (CII), and Official Press Releases of High-level Meetings of the Communist Party of China and Central Government (R-M-P&G). Then, for every category of textual information, the predictive role of a Gaussian Kernel Learning-Support Vector Machine(GKL-SVM) model, employing the information independently, is explored and assessed on stock (price) trends. Based on a comparative analysis of A-share market transaction data for this investment portfolio over the past three years, the GKL-SVM model, individually utilizing any type of textual information, demonstrates some enhancement in predicting short-term trends of Daily Closing (DC) stock prices compared to the coin-toss benchmark. These improvements further enable the corresponding Intraday Decision-making Short-term (IDS) trading strategy to achieve positive average daily returns in a simulated trading environment. Furthermore, by innovatively adapting the Multi-Kernel Learning (MKL) applied in Support Vector Machine (SVM) models into a Multi-Gauss-Kernel Learning (MGKL) framework consisting of the three GKs employed, respectively, for the above three different categories of textual information, i.e. RSB, CII, and R-M-P&G, the corresponding MGKL-SVM model is constructed for DC stock (price) trend prediction. This novel modeling approach integrating multiple categories of textual information not only significantly reduces the volume of textual data required and the computational complexity for intelligent analysis but also achieves a 10 + percentage point improvement in prediction accuracy compared to the three single-category (text-processing) GKL-SVM models (termed RSB, CII, and R-M-P&G (category) GKL-SVM models). The simulated trading results further demonstrate that the IDS trading strategy generates superior average daily returns relative to its single-category GKL-SVM counterparts. Finally, applying the MGKL-SVM model to Weekly Closing (WC) stock (price) trend prediction achieves significantly higher accuracy than daily prediction, indicating its potential practical value for medium-to-long-term value investing.},
  archive      = {J_IJPRAI},
  author       = {Yangsong He and Yao Ge and Gengyu Zhan and Yanhong Gu},
  doi          = {10.1142/S0218001425550146},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2555014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Some efficient stock price trend prediction based on multi-category textual information and support vector machines},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TNet: Power pole classification with deep learning for automated inspection in smart grids. <em>IJPRAI</em>, <em>39</em>(10), 2555013. (<a href='https://doi.org/10.1142/S0218001425550134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With advancements in artificial intelligence, the field of power inspection faces challenges in utilizing upgraded AI technologies to improve operational efficiency. As part of the smart grid initiative, each power pole must be accurately modeled. However, manual classification of strain poles and tangent poles remains hindered by three primary limitations: low accuracy, high costs, and poor timeliness. To address these issues, this paper introduces the following contributions: (1) A computer vision model, TNet, is proposed to distinguish strain poles from tangent poles, leveraging a stable T module and ResNet to extract fine-grained features from images. This approach utilizes high-speed computing to enhance timeliness and mitigates high costs by reducing manual labor, with electricity being the only primary operational cost. (2) We introduce a newly collected power pole classification dataset, featuring images of pole heads from 6 and 10 kV power lines in a specific city. This dataset includes 695 images of tangent poles and 329 images of strain poles, with a total size of 3.52 GB. Finally, the model can achieve an accuracy of 93.76% and an F 1-score of 0.91 on the MyGT2.0 dataset. Our work has been practically applied to the circuit maintenance work of a certain power supply company in 2024.},
  archive      = {J_IJPRAI},
  author       = {Zishuo Gao and Ge Gao and Chen Liu and Yiteng Xu and Chaopeng Liu and Zhuang Luo and Yi Hu},
  doi          = {10.1142/S0218001425550134},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2555013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {TNet: Power pole classification with deep learning for automated inspection in smart grids},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing video captioning via visual-linguistic feature fusion. <em>IJPRAI</em>, <em>39</em>(10), 2555012. (<a href='https://doi.org/10.1142/S0218001425550122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video captioning is a challenging multimodal task that combines computer vision and natural language processing. Previous methods primarily extract useful information from visual features by designing sophisticated encoders. Natural language descriptions generated solely from visual features often fall short of expected performance due to the semantic gap between the visual modality and the textual modality. In this paper, we propose a novel encoder–decoder-based approach for video captioning, which enhances video feature representations by incorporating object and action-centric linguistic features from upstream encoders. Specially, we leverage a cross-attention mechanism to incorporate textual information into visual features, thereby enhancing their expressive capability. Additionally, we introduce a fusion layer to facilitate the interaction between heterogeneous representations and mitigating irrelevant noise. Extensive experiments on the MSVD, MSR-VTT and VATEX datasets demonstrate the superiority of our method and achieve significantly superior performance across standard evaluation metrics.},
  archive      = {J_IJPRAI},
  author       = {Guanghua Chen and Bin Fang},
  doi          = {10.1142/S0218001425550122},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2555012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Advancing video captioning via visual-linguistic feature fusion},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image super-resolution with dense-parallel swin transformer. <em>IJPRAI</em>, <em>39</em>(10), 2554012. (<a href='https://doi.org/10.1142/S0218001425540126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Swin Transformer-based image super-resolution (SR) methods have demonstrated remarkable progress through efficient modeling capabilities and feature extraction. However, existing approaches still have limitations: in hierarchical feature representation architectures, inter-layer feature propagation efficiency progressively degrades with increasing network depth. For this, the paper proposes an SR model, namely, SwinDPSR, composed of Dense-Parallel Swin Transformer (DPST) blocks. The proposed method innovatively constructs a densely connected parallel Swin Transformer architecture that enhances information flow through multi-level feature reuse mechanisms. Simultaneously, we introduce the Spatial Frequency Block (SFB) that establishes global contextual correlations in the frequency domain branch to precisely compensate for local detail loss. Experiments demonstrate significant improvements over the SwinIR across five benchmarks (Set5, Set14, BSD100, Urban100, and Manga109), achieving an average PSNR gain of 0.28 dB in 4 × SR tasks. Theoretical analysis and experimental validation confirm the effectiveness of the parallel architecture, which improves FPS by 6.8% through enhanced computational parallelism. Ablation studies verify the synergistic optimization effect of dense connections and SFB.},
  archive      = {J_IJPRAI},
  author       = {Guojin Pei and Zekun Wang and Xinxing Yang and Genke Yang and Jian Chu},
  doi          = {10.1142/S0218001425540126},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2554012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Image super-resolution with dense-parallel swin transformer},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rearranging multidimensional graphic elements for graphic design applications of image enhancement. <em>IJPRAI</em>, <em>39</em>(10), 2554011. (<a href='https://doi.org/10.1142/S0218001425540114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study looks into rearranging multidimensional visual elements in graphic design for picture enhancement. It also suggests a multidimensional method for enhancing histograms and combining graphic elements that are based on the framework of a visual communication system. The three primary components of the system are an output and visual graphic display module, a data processing module, and an image collector. First, the Scale-Invariant Feature Transform (SIFT) feature description method is used to extract the multidimensional features from the graphical elements, and the feature transformation matrix calculation is used to achieve feature alignment. Subsequently, employing the window-based graphic element fusion technique, the “energy” metric determines the ideal pixel value to guarantee the correctness and smoothness of the fusion outcome. The graphic design image’s histogram is then created, denoised, and enhanced utilizing a combination of standard variance and entropy as the local complexity measurement factor. In the end, MATLAB 2020a simulation tests are conducted, and peak signal-to-noise ratio and structure similarity index are used to confirm the effectiveness of this paper’s approach. The experimental findings demonstrate that the suggested method effectively denoises and enhances photos and can greatly increase images’ visual impact and detail richness. This work offers theoretical justification and a novel, efficient technique for optimizing graphic design pictures.},
  archive      = {J_IJPRAI},
  author       = {Zhongda Cao},
  doi          = {10.1142/S0218001425540114},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2554011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Rearranging multidimensional graphic elements for graphic design applications of image enhancement},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Breakpoint resumption migration method of two-level sharding for single table with billion data. <em>IJPRAI</em>, <em>39</em>(10), 2554010. (<a href='https://doi.org/10.1142/S0218001425540102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the arrival of the big data era, tens of billions of single-table big data generation, the increasing data scale shows how to efficiently and quickly big data migration has become a key challenge. Current traditional big data migration methods have the problem of slow migration speed, and the risk of abnormal interruptions. This paper proposes a method for breakpoint resumption migration of secondary sharding for single-table data at the billion-scale level. Dividing primary shards into secondary shards, and employing a dynamic load balancing strategy to migrate to multiple databases enhance the independence and controllability of data migration, consequently reducing overall migration time. Additionally, in case of any anomalies during the migration process, simply rolling back and re-migrating the affected data shards ensure minimal impact on other shards or the overall migration process. To evaluate the efficacy of this method, our study conducted experiments on migrating Oracle database to other databases. The findings confirmed that the proposed approach supports migration to diverse databases, and as the number of nodes increases, migration efficiency grows exponentially. Additionally, comparative experiments were conducted between the data migration tool developed by this method and both DataX and the DaMeng Transfer Service (DTS), with equivalent data volumes. The experimental results indicate that this method performs comparably well to the leading DTS in terms of migration efficiency. However, this method’s advantage lies in its support for distributed deployment, resulting in the highest overall migration efficiency. Furthermore, unlike other migration tools, it also supports migration to multiple database platforms.},
  archive      = {J_IJPRAI},
  author       = {Wensheng Tang and Zesan Liu and Tian Tian and Yanjie Wang},
  doi          = {10.1142/S0218001425540102},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2554010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Breakpoint resumption migration method of two-level sharding for single table with billion data},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of ultra-wideband millimeter-wave circularly polarized 3D-printed lens antenna using optimized convolutional spiking network for biomedical application. <em>IJPRAI</em>, <em>39</em>(10), 2553003. (<a href='https://doi.org/10.1142/S0218001425530039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel approach to wireless communication is presented by the Circularly Polarized (CP) 3D-printed metalens lens antenna, an ultra-wideband millimeter-wave (mm-wave) antenna. Combining 3D printing technology with advanced metalens construction, it offers wide bandwidth, circular polarization, and a compact form factor, promising enhanced performance for future millimeter-wave communication systems. In this research work, an optimized Convolutional Spiking Neural Network (CSNN)-based Ultra-wideband mm-wave CP 3D-printed metalens lens antenna is proposed for kidney tumor detection. The proposed method combines phase compensation, UC design, and EM response prediction of CP 3D-printed metalens in a single framework using CSNN with Improved Poplar Optimization Algorithm (IPOA). The proposed CSNN consists of two input modules with two attention layers. The initial module smartly furnishes the necessary constraints of the Unit Cells (UC) and forecasts the transmission magnitudes. The next module predicts the geometric parameters for a CP 3D-printed metalens lens antenna. At last, the attention layer combines the geometric parameters and optimizes the design process. The error rate of CSNN is optimized by IPOA. A compact CP metalens antenna was created via 3D printing in order to evaluate the concept. The measured results indicate an 8.2% gain and a 3-dB gain bandwidth achieved by this antenna. Furthermore, the 3-dB Axial Ratio (AR) covers the whole 80–120 GHz W-band. Subsequently, the developed antenna is utilized for kidney cancer detection. The reflection coefficient was simulated using the CST microwave studio for both renal cancer and non-cancerous situations.},
  archive      = {J_IJPRAI},
  author       = {M. Ramkumar and P. Karthigaikumar and M. S. Gowtham and Sathish Kumar Nagarajan},
  doi          = {10.1142/S0218001425530039},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2553003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Design of ultra-wideband millimeter-wave circularly polarized 3D-printed lens antenna using optimized convolutional spiking network for biomedical application},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information-enhanced image denoising method based on deep learning. <em>IJPRAI</em>, <em>39</em>(10), 2552012. (<a href='https://doi.org/10.1142/S0218001425520123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image denoising is a fundamental task in computer vision, essential for enhancing visual quality and facilitating downstream applications. Traditional denoising methods often rely on handcrafted priors or statistical assumptions, which limit their effectiveness in real-world scenarios with complex noise patterns. Recent advances in deep learning have led to significant improvements by leveraging data-driven approaches. In this paper, we propose an information-enhanced image denoising framework based on deep convolutional neural networks (CNNs), which incorporates both spatial and frequency-domain features to improve denoising performance. Our method integrates a dual-branch architecture: one branch extracts spatial features using a residual CNN, while the other encodes frequency components through discrete wavelet transform (DWT) and learns texture-aware representations. A feature fusion module adaptively combines multi-scale information, enabling robust noise suppression while preserving fine structural details. Extensive experiments on standard benchmarks such as BSD68, Set12, and Urban100 demonstrate that our approach outperforms state-of-the-art denoising methods in terms of PSNR and SSIM, particularly under challenging noise levels and non-Gaussian conditions. The results confirm the effectiveness of information enhancement in deep learning-based image denoising.},
  archive      = {J_IJPRAI},
  author       = {Haocheng Luo},
  doi          = {10.1142/S0218001425520123},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2552012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Information-enhanced image denoising method based on deep learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel adaptive data transformation for contrastive learning. <em>IJPRAI</em>, <em>39</em>(10), 2551012. (<a href='https://doi.org/10.1142/S0218001425510127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although contrastive learning has been playing a critical role in pattern recognition, how to optimize positive pairs through data transformation is still not well developed up to now. In this paper, we propose a novel Adaptive Data Transformation , named ADTrans , to identify an optimal sequence of data transformations, which enables generating high-quality positive pairs adaptively during contrastive training. Extensive experiments on benchmark datasets have shown that ADTrans can improve the performance of representation learning on downstream tasks significantly, including image classification, instance segmentation, and object detection. It can achieve a classification accuracy of 12% and 9% higher than the existing MOCO v2, SimSiam, and BYOL on the STL 10 and TinyImageNet datasets, respectively, with the ResNet-18 backbone. Moreover, it outperforms MOCO v2 on COCO instance segmentation, object detection, and Pascal VOC instance segmentation.},
  archive      = {J_IJPRAI},
  author       = {Yucong Shen and Hai Phan and Frank Y. Shih},
  doi          = {10.1142/S0218001425510127},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2551012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel adaptive data transformation for contrastive learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced segmentation techniques for early detection of uterine fibroids using multi-scale feature extraction and hybrid ensemble classification. <em>IJPRAI</em>, <em>39</em>(10), 2551011. (<a href='https://doi.org/10.1142/S0218001425510115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early uterine fibroids detection must be essential because it will avoid complications and improve patient outcomes. Segmentation techniques in medical imaging, such as MRI and ultrasound, have been used to identify and delineate fibroids for diagnosis. Traditional approaches with Thresholding, region growth, and edge detection approaches showed various degrees of success. Still, they always encountered problems such as poor boundary delineation, sensitivity to noise, and inability to distinguish fibroids from surrounding tissues. All these issues reflect the shortcomings of current technology approaches toward dealing with complexity and variability in shapes and sizes of fibroids, calling for more advanced techniques for segmenting these structures to enhance detection accuracy and minimize false negatives. The proposed work introduces two novel segmentation and classification frameworks that could improve the accuracy of uterine fibroid detection by removing the limitations that have been mentioned. First, this work presents in the first phase an adaptive multi-scale feature segmentation model for fibroid features across multiple scales with improved boundary detection using an Adaptive Multi-Scale Feature Segmentation Network (AMFS-Net). It applies edge-water segmentation (EWS), one of the developed hybrid techniques combining the well-known ‘Edge Detection Algorithm’ with the very popular ‘Watershed Algorithm’. The EWS method aims to combine the advantages of both algorithms to offer better segmentation accuracy and reliability in areas where traditional methods cannot be used due to high levels of noise or complexities within the images. The second phase of the proposed work realizes the hybrid multi-layer ensemble classification model (HME-CM), which combines the strengths of multiple classifiers for boosting segmentation performances. This is superior in performance, with detection accuracy being 98.4%. Thus, the resultant work is improved and not limited by the state-of-the-art methods, providing a more reliable early detection system of uterine fibroids.},
  archive      = {J_IJPRAI},
  author       = {Minu Inba Shanthini Watson Benjamin and J. Visumathi},
  doi          = {10.1142/S0218001425510115},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2551011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Enhanced segmentation techniques for early detection of uterine fibroids using multi-scale feature extraction and hybrid ensemble classification},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improvement of the control and surveillance process for automotive diagnostic centers through the development of a computer vision and deep learning-based software. <em>IJPRAI</em>, <em>39</em>(9), 2557008. (<a href='https://doi.org/10.1142/S0218001425570083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the development and implementation of the “Manhattan” system, a proprietary software solution designed to enhance control and surveillance processes in Automotive Diagnostic Centers (CDAs) in Colombia carried out by Compaa Internacional de Integracin S.A. (CI2). The primary objective of this project was to address critical inefficiencies and fraud risks in vehicle inspections by leveraging Industry 4.0 technologies, including Computer Vision, Deep Learning, and Artificial Intelligence. The system integrates modular applications such as Oslo (for real-time license plate recognition using YOLO-Darknet with 98.8% accuracy), Platino (for video consolidation), and Gambito (for secure data transmission), ensuring seamless coordination with regulatory entities like the Superintendence of Ports and Transport. Validated across 2 CDAs that involbe 2.094 characters, and later deployed in 419 centers (covering 60% of the national market), the system demonstrated a 70% reduction in operational costs, a 40% improvement in video processing speed, and a 45% increase in data transmission capacity. These results highlight its scalability and effectiveness in automating inspections, reducing fraud, and optimizing resource utilization. The project underscores the transformative potential of AI-driven solutions in regulatory compliance and industrial automation.},
  archive      = {J_IJPRAI},
  author       = {Leonel Alberto Forero Forero and Giovanny Andres Diaz Vargas and Sergio Guarin Valencia and Jhon Jairo Ayala and Jhonathan Mauricio Vargas Barbosa},
  doi          = {10.1142/S0218001425570083},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2557008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Improvement of the control and surveillance process for automotive diagnostic centers through the development of a computer vision and deep learning-based software},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-step multi-frame inpainting framework for real-time lip-sync digital human generation. <em>IJPRAI</em>, <em>39</em>(9), 2557006. (<a href='https://doi.org/10.1142/S021800142557006X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, audio-driven lip-synching generation for digital humans has attracted considerable attention. However, the prevailing methodologies frequently encounter challenges pertaining to elevated computational complexity and deficient real-time performance. Although the MuseTalk framework has achieved notable progress in inference efficiency through its end-to-end, latent-space-based single-step generation algorithm, it still suffers from noticeable lip jitter and insufficient synchronization between audio and lip movements. To address these limitations, we propose an enhanced multi-frame inpainting framework that integrates Variational Autoencoders (VAE) and a multi-scale U-Net architecture. Specifically, our approach directly synthesizes the occluded lip region by leveraging multi-frame visual references combined with corresponding audio embeddings, thereby effectively improving lip synchronization and maintaining identity consistency. Furthermore, we introduce a landmark-guided multi-frame sampling strategy designed to enhance model attention towards lip dynamics. To facilitate deeper feature extraction and fusion, we propose a hierarchical latent-space feature fusion network (FusionNet), incorporating global and local residual connections and an enhanced Convolutional Block Attention Module. Additionally, a frame interpolation technique is employed during inference to further smooth lip movements and significantly mitigate lip jitter. The model has been trained on a large-scale Chinese dataset and comprehensively evaluated using both Chinese and English datasets. The experimental results demonstrate that the proposed framework achieves high visual accuracy, consistent lip synchronization, and efficient real-time inference, highlighting its strong cross-lingual generalization capability.},
  archive      = {J_IJPRAI},
  author       = {Yijun Bei and Yunze Qi and Hengrui Lou and Erteng Liu and Ke Wang and Hongchang Zhang},
  doi          = {10.1142/S021800142557006X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2557006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {One-step multi-frame inpainting framework for real-time lip-sync digital human generation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Video compression optimization and rate control for cyberspace application. <em>IJPRAI</em>, <em>39</em>(9), 2556002. (<a href='https://doi.org/10.1142/S0218001425560026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video traffic has become the principal part of data resources in the current cyberspace which brings many challenges such as security, stability and scalability of streaming transmission. Moreover, how to ensure high visual quality while obtaining a significant bit-rate reduction has always been the focus of the industry. By constructing a source distortion temporal propagation (SDTP) model, this paper proposes a temporal dependent RDO (TDRDO) algorithm to resolve the global RDO problem in the temporal domain. Besides, a fuzzy logic based rate control (FLRC) algorithm is proposed to robustly regulate encoding bit-rates. The two algorithms have previously been adopted by Audio Video Coding Standard Workgroup of China and integrated into the second generation (AVS2). Experimental results prove the excellence of the proposed algorithms, for significantly improving the AVS2 video coding performance and providing AVS2 with superb efficiency to compete with HEVC/H.265 in modern video compression.},
  archive      = {J_IJPRAI},
  author       = {Yimin Zhou and Chengzong Peng and Jie Luo and Juelin Liu and Siqi Yang and Juan Wang and Yang Bai},
  doi          = {10.1142/S0218001425560026},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2556002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Video compression optimization and rate control for cyberspace application},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting object in remote sensing image based on improved RT-DETR. <em>IJPRAI</em>, <em>39</em>(9), 2555011. (<a href='https://doi.org/10.1142/S0218001425550110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to tackle the challenges associated with low detection performance and high computational resource consumption, which result from diverse scenes, complex backgrounds, small and dense targets, and large data volumes in remote sensing images, we propose an improvement on real-time detection transformer (RT-DETR) for detecting objects in remote sensing images. By introducing the Mosaic9 data augmentation technique, we enhance the model’s adaptability to multi-scene targets, as well as its target recognition performance in different backgrounds. Furthermore, to decrease resource usage without compromising detection precision, we replace the Basic Block structure in the backbone of RT-DETR with the more lightweight FasterNet Block. Finally, we enhance the adaptive intra-scale feature interaction (AIFI) by replacing multi-head self-attention (MHSA) with deformable attention, enabling the model to dynamically adjust its attention range and better capture distinctive target features in complex scenarios. Experimental validation conducted on the DSTD dataset reveals that the modified RT-DETR model achieves a detection accuracy of 94.9%, representing an improvement of 1% compared to the baseline RT-DETR. Simultaneously, the improvements reduce GFLOPs, total parameters, and overall model size by approximately 12.4%, 15.5%, and 15.2%, respectively, thus realizing a balance between performance and lightweight architecture. Moreover, generalization experiments on the NWPU VHR-10 dataset further substantiate the enhanced model’s robustness and adaptability across diverse remote sensing scenes, confirming the efficacy and practical value of the proposed enhancements.},
  archive      = {J_IJPRAI},
  author       = {Jinyan Bai and Tao Jiang and Zhengbin Zou and Yizheng Wang and Tiancheng Xue},
  doi          = {10.1142/S0218001425550110},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2555011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Detecting object in remote sensing image based on improved RT-DETR},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Underwater image enhancement based on U-net architecture and channel attention mechanism fusion generative adversarial network. <em>IJPRAI</em>, <em>39</em>(9), 2555008. (<a href='https://doi.org/10.1142/S0218001425550080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the challenges of blur distortion, low contrast and color fading in underwater images, caused by complex environmental factors and light attenuation, this study presents a novel underwater image enhancement method that leverages the U-Net architecture and channel attention mechanism fusion generative adversarial network (GAN), named UAEGAN. UAEGAN is built on the framework of GAN, combining the U-Net structure with a channel attention mechanism to construct a generator network, reducing the loss of low-level information during feature extraction and enhancing image details. Additionally, the algorithm employs a PatchGAN discriminator, which improves image resolution and detail representation by performing fine-grained true/false judgments on local image patches. Finally, the visual quality of the enhanced image is further optimized through the weighted fusion of multiple loss functions. Experimental results on the UIEB dataset indicate that UAEGAN outperforms the latest methods in terms of both visual quality and numerical metrics. The algorithm effectively enhances the clarity and visual quality of underwater images, providing strong support for subsequent underwater image processing tasks and applications.},
  archive      = {J_IJPRAI},
  author       = {Gang Li and Jiaqing Fan and Chenyu Cheng},
  doi          = {10.1142/S0218001425550080},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2555008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Underwater image enhancement based on U-net architecture and channel attention mechanism fusion generative adversarial network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A joint entity and relation extraction model driven by fine-grained feature extraction. <em>IJPRAI</em>, <em>39</em>(9), 2554009. (<a href='https://doi.org/10.1142/S0218001425540096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint entity and relation extraction plays a crucial role in various fields, including natural language processing, knowledge graph construction, and question answering systems. Among these methods, the joint extraction approach based on table filling has become a focal point for researchers due to its excellent performance and ability to accurately extract entities and relations from intricate sentences. Despite this, there is still potential to be further explored in such methods. Currently, most methods focus on learning relational features between words but neglect the relational features between labels and between labels and words. These relations are also important because a relation triplet can only be correctly identified when all labels are predicted correctly. This some what increases the risk of missing key information and inefficient decoding in the entity and relation extraction process. To overcome this limitation, we design a fine-grained relation feature extraction module that aims to encourage the model to fully consider the associations between words and labels, as well as between labels, while focusing on the relationships between words. Specifically, we create label representations and embed them into fine-grained relation extraction, enabling it to treat labels and word representations as queries, keys, and values, and then utilize the self-attention mechanism to model the associations between them. Additionally, the table labeling strategy has a significant impact on model performance, especially in terms of decoding efficiency. We propose a vertex labeling method to label the table, enhancing the model’s accuracy in entity recognition and overall decoding efficiency. We evaluate our proposed model on three benchmark datasets. The experimental results demonstrate that our model is effective and achieves state-of-the-art performance on all these datasets.},
  archive      = {J_IJPRAI},
  author       = {Hongli Yu and Han Cao and Chenxi Dong and Haihang Wang and Hanwen Liang and Yachao Cui},
  doi          = {10.1142/S0218001425540096},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2554009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A joint entity and relation extraction model driven by fine-grained feature extraction},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long short-term multivariate time series anomaly detection via double-branch attention and dynamic graph attention network. <em>IJPRAI</em>, <em>39</em>(9), 2554008. (<a href='https://doi.org/10.1142/S0218001425540084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the industrial Internet, intelligent operation and maintenance can ensure the secure and stable operation of industrial software. To achieve effective intelligent operation and maintenance, it’s essential to conduct time series anomaly detection within software systems and other devices. To enhance the detection effectiveness, extensive research has been conducted. However, multivariate time series are composed of high-dimensional, high-noise, and random data. These anomalies are both subtle and dense. It is difficult to detect anomalies accurately. The increased complexity of existing methods results in lower operational efficiency. To address these issues, this paper proposes the time series anomaly detection method DG-LSFNet. DG-LSFNet adeptly captures feature correlations across various temporal states to extract additional valuable insights. Next, DG-LSFNet establishes long-term and short-term temporal correlations. It can capture normal information within short intervals between anomalies, thereby reducing false alarm in anomaly detection. Then, DG-LSFNet approximate and unearth the original data information to improve anomaly detection performance. In addition, DG-LSFNet reduces time complexity by simplifying the model structure and effectively improves the efficiency of anomaly detection. This paper conducts experiments to compare DG-LSFNet with state-of-the-art methods on four benchmark datasets. The experimental results indicate that DG-LSFNet outperforms state-of-the-art methods in terms of anomaly detection performance, enhancing the interpretability of anomaly detection.},
  archive      = {J_IJPRAI},
  author       = {Xiangheng Huang and Fei Zhou and Tao Deng and Fanglin Chen and Jining Chen and Ningjiang Chen},
  doi          = {10.1142/S0218001425540084},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2554008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Long short-term multivariate time series anomaly detection via double-branch attention and dynamic graph attention network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of well-logging curves based on MPSO/D-optimized deep neural networks. <em>IJPRAI</em>, <em>39</em>(9), 2553001. (<a href='https://doi.org/10.1142/S0218001425530015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the limitations of traditional logging curve prediction methods in complex reservoirs, particularly their inadequate generalization ability and the challenges associated with high-dimensional nonlinear modeling. We propose a deep neural network (DNN) logging curve prediction method, which is based on a multi-objective particle swarm optimization algorithm with target space decomposition (MPSO/D). This method effectively balances prediction accuracy and model complexity through target space decomposition, dynamic neighborhood search, and a constraint adaptive adjustment mechanism. This approach surmounts the issue of traditional parameter tuning, which often falls into local optima. The global search capability of MPSO/D is well-suited to the high-dimensional noise environment of logging data, thereby significantly enhancing the robustness of DNN in heterogeneous reservoirs. We applied this method to predict the resistivity curves in the logging data of wells B1, B2, and B3 in the A block of the Songliao Basin in the Daqing Oilfield. We compared our prediction results with those obtained from four other improved algorithms. The experimental findings indicate that the mean squared error values derived from MPSO/D-DNN are markedly lower than those produced by other models. Furthermore, the prediction curve exhibits the highest degree of congruence with actual values, thereby substantiating the efficacy and practicality of this method.},
  archive      = {J_IJPRAI},
  author       = {Yanan Hu and Jian-Gang Dong and Xiao-Qing Zhao and Dan Wang and Xing-Wang Li},
  doi          = {10.1142/S0218001425530015},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2553001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Prediction of well-logging curves based on MPSO/D-optimized deep neural networks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DLA-FCIL: Federated class-incremental learning for dynamic data with forgetting compensation and auxiliary generators. <em>IJPRAI</em>, <em>39</em>(9), 2552010. (<a href='https://doi.org/10.1142/S021800142552010X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Class-Incremental Learning (FCIL) enables dynamic model updates, but suffers from local and global catastrophic forgetting due to limited client storage and cross-client class non-i.i.d. issues. To address catastrophic forgetting, we propose a multi-scale FCIL scheme, DLA-FCIL, which incorporates a Double-Loss-assisted forgetting compensation mechanism and the Auxiliary generators based on data characteristics. Specifically, to mitigate local catastrophic forgetting, we incorporate an auxiliary generator on local clients for knowledge replay, augmenting the training datasets with generated samples to form hybrid datasets. Then, to fully leverage the hybrid datasets, we design a double-loss forgetting compensation mechanism. This mechanism includes a gradient-weighted compensation loss that normalizes forgetting rates across old class knowledge, and a semantic-transition compensation loss that extracts the semantic relationships between old and new classes, preventing abrupt shifts in semantic consistency during the class transitions. Besides, to effectively alleviate the catastrophic forgetting problem caused by global class imbalance, the trained auxiliary generator is sent to a proxy server with minimal communication cost to build an i.i.d. dataset, enabling the development of an optimal global model. Finally, comparison experiments on CIFAR100, ImageNet-Subset, and Tiny-ImageNet datasets demonstrate that DLA-FCIL consistently outperforms other FCIL baselines by approximately 3–15% in test accuracy.},
  archive      = {J_IJPRAI},
  author       = {Bowen Xing and Junqing Le and Di Zhang and Xiaofeng Liao},
  doi          = {10.1142/S021800142552010X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2552010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DLA-FCIL: Federated class-incremental learning for dynamic data with forgetting compensation and auxiliary generators},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed intelligence in IoHT using federated learning and edge AI for chronic kidney disease prediction using ReLU and bi-directional GRU with feature-wise dropout and fuzzy neural network. <em>IJPRAI</em>, <em>39</em>(9), 2552009. (<a href='https://doi.org/10.1142/S0218001425520093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research aims to enhance the forecasting of Chronic Kidney Disease (CKD) by discovering the importance of collective intelligence within the Internet of Healthcare Things (IoHT), by focusing on combining Edge Artificial Intelligence (AI) and Federated Learning. This method safeguards the patients’ information to stay localized, capturing the circulated flora of Federated Learning to uphold confidentiality and fulfill serious data security parameters that are challenging in Medicare backgrounds. The presence of Bi-directional Gated Recurrent Unit (Bi-GRU) with a Rectified Linear Unit (ReLU) improves the algorithm’s forecasting competencies by efficiently obtaining both the past and future needs in consecutive medical information. Moreover, the algorithm’s flexibility has been enhanced via feature-wise regressive dropout that decreases overfitting and guarantees its aptness to various datasets of patients. Thus, this agenda surpasses convolutional DL models like ALO-CNN-GRU, CNN, and LSTM exhibiting supremacy in handling complicated medical datasets with an excellent accuracy of about 99.98%. When compared to the existing algorithms, the adoption of Fuzzy Neural Network (FNN) for the forecasting of CKD efficiently reduces the computational times by allowing the algorithm to analyze irregular and confusing data. Thus, the advanced method not just allows real-time and précised findings of CKD but also proves the real-world application of Federated Learning and Edge AI for maintaining the medical data securely. The results demonstrate how this approach has the possibility to change healthcare, cheer initial detection and improve the overall results of the health by contributing extensible, efficient and patient-focused treatments inside the IoHT environment.},
  archive      = {J_IJPRAI},
  author       = {Vijaykumar Mamidala and Rama Krishna Mani Kanta Yalla and Thirusubramanian Ganesan and Akhil Raj Gaius Yallamelli and Mohanarangan Veerapperumal Devarajan and Aceng Sambas},
  doi          = {10.1142/S0218001425520093},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2552009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Distributed intelligence in IoHT using federated learning and edge AI for chronic kidney disease prediction using ReLU and bi-directional GRU with feature-wise dropout and fuzzy neural network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized parameter prediction for aluminum alloy 7075 machining using a hybrid experimental design strategy. <em>IJPRAI</em>, <em>39</em>(9), 2552006. (<a href='https://doi.org/10.1142/S0218001425520068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a high-performance machining accuracy and parameter prediction algorithm was proposed that better meets specific surface roughness requirements of the boring machining of aluminum alloy 7075. First, a hybrid experiment design strategy that incorporates factor range segmentation and exchange methods was used to improve data collection and ensure that the model accurately reflects the processing characteristics of the machine used. Then, a 1D CNN deep learning algorithm was used to model the relationship between boring parameters and the machining results, integrated with a particle swarm optimization algorithm to solve the parameter optimization problem for different processing objectives. The results proved that the proposed method was useful for the solution of the parameter prediction problem in specific machining objectives.},
  archive      = {J_IJPRAI},
  author       = {Yu-Chi Liu and Tzu-Wei Hsu},
  doi          = {10.1142/S0218001425520068},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2552006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimized parameter prediction for aluminum alloy 7075 machining using a hybrid experimental design strategy},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLOv7-DBV: A lightweight object detection algorithm based on cross-stage local network. <em>IJPRAI</em>, <em>39</em>(9), 2550014. (<a href='https://doi.org/10.1142/S0218001425500144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection algorithms that achieve high accuracy in complex application scenarios often result in complex network structures and exhibit poor detection performance for deformed objects and densely distributed small objects. These complex networks have high hardware requirements for mobile terminals or devices that are resource-constrained, significantly limiting their practical applications. To balance detection accuracy and network complexity, we propose a lightweight object detection algorithm based on a cross-stage local network, termed YOLOv7-DBV. First, a lightweight VoV-GSDSBCSP structure is designed to optimize the Head network structure of YOLOv7. Next, DCNv3 is introduced to enhance the YOLOv7 backbone network, improving the extraction of feature information for deformed objects. Finally, a Bi-level Routing Attention (BRA) mechanism is incorporated to further optimize the backbone network of YOLOv7, emphasizing the feature information of small objects. Experiments on a public underwater object detection dataset demonstrate that the YOLOv7-DBV model increases mAP0.5 by 1.05% and reduces the number of parameters by 15.31% compared to the original YOLOv7 model. The proposed algorithm achieves a better balance between detection accuracy and network complexity, outperforming YOLOv7, YOLOv6l, YOLOv5l, and other algorithms.},
  archive      = {J_IJPRAI},
  author       = {Danyang Cao and Yongfu Wong and Fangfang Liu},
  doi          = {10.1142/S0218001425500144},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2550014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {YOLOv7-DBV: A lightweight object detection algorithm based on cross-stage local network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient bearing fault diagnosis using depthwise separable convolution and transformer with SSA multi-objective optimization. <em>IJPRAI</em>, <em>39</em>(9), 2550012. (<a href='https://doi.org/10.1142/S0218001425500120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the challenges of computational overhead and reliance on manual hyperparameter tuning in bearing fault diagnosis models, this study presents an optimized DSCNN-Transformer framework enhanced by the Sparrow Search Algorithm (SSA). The proposed framework employs Depthwise Separable Convolution (DSCNN) significantly mitigating computational costs in resource-limited setups. The Transformer module captures intricate global dependencies in time-series data to boost feature representation and diagnostic accuracy. A novel multi-objective optimization strategy utilizing SSA balances classification precision and parameter efficiency through dynamic weight adjustments. Experimental validation on the Case Western Reserve University (CWRU) bearing dataset highlights the model’s outstanding performance, achieving a 99.55% accuracy in a 10-class classification task, coupled with excellent real-time efficiency and adaptability. Future efforts will optimize the model’s lightweight design further, especially targeting edge computing applications.},
  archive      = {J_IJPRAI},
  author       = {Fang Han and Yuqin Zhu and Wenyan Nie},
  doi          = {10.1142/S0218001425500120},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2550012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Efficient bearing fault diagnosis using depthwise separable convolution and transformer with SSA multi-objective optimization},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PFE-KD: A defense method against membership inference attack without loss of accuracy. <em>IJPRAI</em>, <em>39</em>(9), 2450020. (<a href='https://doi.org/10.1142/S0218001424500204'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the usage of deep learning applications continues to proliferate, concerns surrounding the privacy and security of deep learning models have intensified. Recent research has pointed out that deep learning models are vulnerable to various privacy attacks, with Membership Inference Attacks (MIAs) being particularly prevalent. MIA can compromise privacy by revealing the presence of unknown data points in a model’s training set, posing a significant threat especially when the training data contains sensitive information. To this end, scholars have proposed many defense strategies, but striking a balance between protecting model privacy and maintaining utility remains a difficult challenge. In this paper, we propose a defense method against membership inference attacks, called RFE-KD, which integrates feature extraction technology and knowledge distillation technology. Extensive experiments show that our approach significantly reduces the accuracy of membership inference attacks without sacrificing model accuracy, consistently outperforming the most existing defense methods.},
  archive      = {J_IJPRAI},
  author       = {Hao Liu and Shuyao He and Ting Xu},
  doi          = {10.1142/S0218001424500204},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2450020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {PFE-KD: A defense method against membership inference attack without loss of accuracy},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing stability of multi-underwater robot swarms based on the fusion of social force and vicsek models. <em>IJPRAI</em>, <em>39</em>(8), 2559010. (<a href='https://doi.org/10.1142/S0218001425590104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the demand for marine environmental monitoring and deep-sea operations continues to grow, AUV swarm systems have become a research hotspot due to their high flexibility. This paper proposes a navigation control method for multi-AUV swarms that integrates the Social Force Model (SFM) with the Vicsek model to improve collaboration efficiency and motion stability in dynamic underwater environments. The proposed control strategy incorporates both physical forces and alignment mechanisms to achieve dynamic behavioral coordination among the robots in the swarm. The SFM is used to characterize interactions between individuals, ensuring collision avoidance, while the Vicsek model provides a neighborhood-based velocity alignment mechanism to enhance swarm coherence. Additionally, the control framework introduces a leader-follower structure, effectively integrating local perception with global navigation information. Simulation results indicate that the robot swarm can maintain effective obstacle avoidance and structural stability even in complex environments with obstacles. In the absence of the Vicsek model, navigation tasks may fail or significantly increase navigation time. Even with low alignment strength and higher speeds, navigation time can be reduced by 35%, while higher alignment strength combined with lower speeds can shorten navigation time by up to 50%. Tests with large-scale swarms demonstrate that the proposed method exhibits good scalability and effectively prevents excessive aggregation within the group. Future research will focus on integrating intelligent optimization methods, such as deep reinforcement learning, to enhance the generalization ability of the control strategy in unstructured and dynamic environments.},
  archive      = {J_IJPRAI},
  author       = {Qiang Zhao and Bing Li and Gang Wang},
  doi          = {10.1142/S0218001425590104},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2559010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Enhancing stability of multi-underwater robot swarms based on the fusion of social force and vicsek models},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-aided multiple-symbol noncoherent detection scheme of LDPC coded MPSK receiver for unmanned aerial vehicle communications. <em>IJPRAI</em>, <em>39</em>(8), 2558003. (<a href='https://doi.org/10.1142/S0218001425580030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple-symbol noncoherent detection (MSND) with the aid of Neural Networks (NNs) for low-density parity-check (LDPC) coded multiple phase shift keying (MPSK) signals is studied for Unmanned aerial vehicle (UAV) communications. In the traditional MSND scheme, the number of the candidate sequences grows exponentially with respect to the length of the symbol observation period. Implementing the optimal bit log-likelihood ratio (LLR) for decoding is challenging, even when the observed symbol period is two. In this paper, we first proposed an improved scheme to reduce the number of the candidate sequences by phase combination, the phase is uniformly quantized into L discrete values. We find that the performance requirements can be well met when the phase quantization order is only 4. Then we utilize Back Propagation neural networks (BPN) to compute the bit LLR. To enhance the training efficiency of our NNs and achieve better performance, we also uniformly quantize the carrier phase offset (CPO) into discrete states. The decoding convergence is accelerated significantly compared to the improved traditional scheme. The complexity is reduced to a certain extent within the acceptable range of performance loss.},
  archive      = {J_IJPRAI},
  author       = {Di Wu and Gege Wei and Gaolei Song and Yongen Li and Gaoyuan Zhang},
  doi          = {10.1142/S0218001425580030},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2558003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Neural network-aided multiple-symbol noncoherent detection scheme of LDPC coded MPSK receiver for unmanned aerial vehicle communications},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot counting with multi-scale vision transformers and attention mechanisms. <em>IJPRAI</em>, <em>39</em>(8), 2556001. (<a href='https://doi.org/10.1142/S0218001425560014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object counting is a fundamental task in computer vision, with critical applications in areas such as crowd monitoring and ecological conservation. Traditional methods typically rely on large-scale annotated datasets, which are costly and time-consuming to obtain. Few-shot object counting has emerged as a promising solution, enabling accurate counting with minimal annotated samples. However, in real-world scenarios, objects often exhibit significant scale variations due to factors such as view distortion, varying shooting distances, and inherent size differences. Existing few-shot methods usually struggle to address this challenge effectively. To address these issues, we propose a Scale-Aware Vision Transformer (SAViT) framework. Specifically, we design a multi-scale dilated convolution module in SAViT, which can adaptively adjust convolution kernel sampling rates to handle objects of varying sizes. Additionally, we incorporate a global channel attention mechanism to strengthen the model’s ability to capture robust feature representations, thereby improving detection accuracy. For practical usability, we integrate the Segment Anything Model (SAM) to create an exemplar box selection module, simplifying the process by allowing users to generate precise exemplar boxes with a single line drawn on the target object. Extensive experiments on the FSC-147 dataset demonstrate the effectiveness of our approach, achieving a Mean Absolute Error (MAE) of 8.92 and a Root Mean Squared Error (RMSE) of 31.26. Compared to the state-of-the-art method, CACViT, our model reduces MAE by 0.21 (2.30% improvement) and RMSE by 17.7 (36.15% improvement). Our approach not only provides an effective solution for few-shot object counting but also provides a new practical paradigm for extending few-shot learning to complex vision tasks requiring multi-scale reasoning. The code of our paper is available at https://github.com/BlouseDong/SAViT .},
  archive      = {J_IJPRAI},
  author       = {Xiaopan Chen and Zhiwei Dong and Xiaoke Zhu and Fan Zhang and Caihong Yuan},
  doi          = {10.1142/S0218001425560014},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2556001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Few-shot counting with multi-scale vision transformers and attention mechanisms},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal pre-trained framework for aligning Image–Text relation semantics. <em>IJPRAI</em>, <em>39</em>(8), 2555010. (<a href='https://doi.org/10.1142/S0218001425550109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image–text relation (ITR) in social media plays a crucial role in mining the semantics of the posts. Vision and language pre-trained models (PTMs) or multimodal PTMs have been used to create multimodal embeddings. The conventional practice of fine-tuning pre-trained models with labeled data for specific image–text relation tasks often falls short due to misalignment between general pre-training objectives and task-specific requirements. In this research, we introduce a cutting-edge pre-trained framework tailored for aligning image–text relation semantics. Our novel framework leverages unlabeled data to enhance learning of image–text relation representations through deep multimodal clustering and multimodal contrastive learning tasks. Our method significantly narrows the disparity between generic Vision-Language Pre-trained Models (VL-PTMs) and image–text relation tasks, showcasing an impressive performance boost of up to 10.4 points in linear probe tests. By achieving state-of-the-art results on image–text relation datasets, our pre-training framework stands out for its effectiveness in capturing and aligning image–text semantics. The visualizations generated by class activation map (CAM) also demonstrate that our models provide more accurate image–text semantic correspondence. The code is available on the website: https://github.com/qingyuannk/ITR .},
  archive      = {J_IJPRAI},
  author       = {Lin Sun and Yindu Su and Zhewei Zhou and Qingyuan Li and Ruichen Xia},
  doi          = {10.1142/S0218001425550109},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2555010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multimodal pre-trained framework for aligning Image–Text relation semantics},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BFC-cap: Background and frequency-guided contextual image captioning. <em>IJPRAI</em>, <em>39</em>(8), 2555009. (<a href='https://doi.org/10.1142/S0218001425550092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective image captioning relies on both visual understanding and contextual relevance. In this paper, we present two approaches, BFC-Cap b –a novel background-based image captioning and its extension BFC-Cap f –frequency-guided, to achieve the above goals. First, we develop an Object-Background Attention (OBA) module to capture the interaction and relationship between objects and background features. Then, we incorporate feature fusion with spatial shift operation, enabling alignment with neighbors and avoiding potential redundancy. This framework is extended to transform grid features into frequency domain and filter out low-frequency components to enhance fine details. Our approaches are evaluated using traditional and recent metrics on MS COCO image captioning benchmark. Experimental results show the effectiveness of our proposed approaches, achieving better quantitative scores as compared to the relevant existing methods. Furthermore, our methods show improved qualitative captions with more background and concise contextual information, including more accurate information regarding the objects and their attributes.},
  archive      = {J_IJPRAI},
  author       = {Al Shahriar Rubel and Frank Y. Shih and Fadi P. Deek},
  doi          = {10.1142/S0218001425550092},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2555009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {BFC-cap: Background and frequency-guided contextual image captioning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive SURELET-based image denoising in wavelet domain with spatially varying noise. <em>IJPRAI</em>, <em>39</em>(8), 2554007. (<a href='https://doi.org/10.1142/S0218001425540072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image denoising is a critical task in numerous real-world applications. This paper presents an innovative method for image denoising in the wavelet domain, extending the SURELET approach to handle spatially varying noise levels. Traditional methods often assume a constant noise level across the entire image, which is unrealistic in practical scenarios. Our proposed method estimates the noise level locally within small neighborhoods in the wavelet domain, adapting well to images with spatially varying noise. This approach effectively reduces both uniform and spatially varying noise, as demonstrated through extensive experiments on six test images with five distinct noise patterns. The results, evaluated using peak signal-to-noise ratio (PSNR), show that our method outperforms existing denoising techniques, particularly in scenarios with spatially varying noise. This study not only advances the state-of-the-art in image denoising but also highlights the importance of adaptive noise estimation in real-world applications.},
  archive      = {J_IJPRAI},
  author       = {Guang Yi Chen and Yaser Esmaeili Salehani and Sepehr Ghamari},
  doi          = {10.1142/S0218001425540072},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2554007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Adaptive SURELET-based image denoising in wavelet domain with spatially varying noise},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EAUR-net: Enhancing MRI reconstruction with edge-aware undersampling and deep learning. <em>IJPRAI</em>, <em>39</em>(8), 2552011. (<a href='https://doi.org/10.1142/S0218001425520111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) is an essential imaging technique used for detailed anatomical assessment and clinical decision-making. Conventional MRI acquisition methods, however, are often time-consuming and resource-demanding. To overcome these limitations, compressed sensing (CS) approaches have been developed to accelerate MRI data acquisition by exploiting image sparsity. In this work, we present the Edge-Aware Undersampling and Reconstruction Network (EAUR-Net), an innovative deep learning architecture designed to enhance MRI reconstruction by incorporating dynamic edge-based sampling strategies. EAUR-Net focuses on intelligently sampling data points based on edge information, which is critical for preserving key structural details and improving reconstruction quality while reducing the amount of acquired data. This paper provides a thorough evaluation of EAUR-Net, detailing its architectural components, training procedures, experimental outcomes, and potential future improvements.},
  archive      = {J_IJPRAI},
  author       = {Libya Thomas and Joseph Zacharias},
  doi          = {10.1142/S0218001425520111},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2552011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {EAUR-net: Enhancing MRI reconstruction with edge-aware undersampling and deep learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight and effective YOLO model for infrared small object detection. <em>IJPRAI</em>, <em>39</em>(8), 2551009. (<a href='https://doi.org/10.1142/S0218001425510097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting small targets in infrared images presents significant challenges due to low resolution, lack of texture information, and high noise interference. To address these issues, this paper proposes an improved YOLO model aimed at enhancing the accuracy and efficiency of small target detection in infrared images. First, we integrate the Coordinate Attention (CA) mechanism into the backbone network to improve the model’s feature extraction capability in complex scenes. Second, we introduce the Contextual Feature Aggregation (CFA) module into the neck network, effectively merging multi-level contextual information and enhancing the detection capability for small targets. To further optimize the model, we simplify the detection layers for large targets in YOLO, reducing the number of parameters while maintaining high detection accuracy. Finally, we incorporate the Normalized Wasserstein Distance (NWD) loss function, which is insensitive to target size and can accelerate model convergence while improving small target detection performance. We evaluated the model on public datasets such as VisDrone2019 and FLIR, using metrics like mean Average Precision (mAP) to assess performance. Experimental results indicate that the proposed method achieves higher detection accuracy and efficiency while maintaining a low parameter count compared to baseline models.},
  archive      = {J_IJPRAI},
  author       = {Shiyi Wen and Liangfu Li and Wenchao Ren},
  doi          = {10.1142/S0218001425510097},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2551009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A lightweight and effective YOLO model for infrared small object detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RFA: Regularized feature alignment method for cross-subject human activity recognition. <em>IJPRAI</em>, <em>39</em>(8), 2551008. (<a href='https://doi.org/10.1142/S0218001425510085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-subject activity recognition is challenging in the human activity recognition field. Previous studies have often assumed that training and test data follow the same distribution, which is impractical in real-world applications. Thus, models’ performance will significantly decline when applied to data collected from new unseen subjects because of the different physical conditions and human habits. To solve the above challenges, we proposed the regularized feature alignment (RFA) network. The RFA introduces a source domain selection mechanism (SDSM) based on calculating the Wasserstein distance between different subjects. Through SDSM, subjects with high similarity in the source domain can be retained, which implicitly compacts the feature subspace distribution. We implemented linear data augmentation on the retained subjects to mitigate the effects of the decline in the training set. In addition, the regularized dropout method was adopted to explicitly compact the feature subspace distributions. Finally, multi-level feature alignment is performed via maximum mean discrepancy regularization to precisely match the source and target domain. To demonstrate the effectiveness of RFA, comprehensive experiments were conducted on four public datasets under the iterative left-one-subject-out setting. The experimental results demonstrate that RFA outperformed the state-of-the-art methods in datasets with a large divergence between subjects and achieved performance comparable to the state-of-the-art methods in a subject-balanced dataset.},
  archive      = {J_IJPRAI},
  author       = {Zhe Yang and Hao Fu and Ruohong Huan and Mengjie Qu and Yun Pan},
  doi          = {10.1142/S0218001425510085},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2551008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {RFA: Regularized feature alignment method for cross-subject human activity recognition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRF-YOLO: A transformer-enhanced framework for underwater image enhancement and object detection. <em>IJPRAI</em>, <em>39</em>(8), 2550011. (<a href='https://doi.org/10.1142/S0218001425500119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater aquatic systems play a crucial role in maintaining ecological balance and supporting marine biodiversity. However, due to low visibility, color distortion, and scattering effects caused by light absorption, efficient monitoring and detecting objects in such environments remain challenging. Deep learning-based image processing techniques have revolutionized underwater exploration by providing robust solutions for enhancing image quality, extracting meaningful features, and enabling precise classification. Integrating advanced image enhancement methods with deep learning architectures facilitates accurate detection and monitoring of aquatic species, objects, and anomalies. This study introduces a novel approach that synergistically combines the Multiscale Retinex (MSR) and Dark Channel Prior (DCP) approaches for underwater image enhancement in the form of the Dark Retinex Fusion (DRF) model. The DRF model is further integrated with a YOLO-based Transformer framework, leveraging attention mechanisms to enhance feature extraction and classification. The proposed DRF-YOLO-based Transformer framework effectively reduces haze, enhances contrast, and balances colors for an underwater environment. It incorporates advanced spatial precision features in the YOLO backbone and applies the attention module from the Transformer model that captures the long-range dependencies for better contextual understanding. The model was tested on underwater object datasets, achieving an accuracy of 98% and a loss of 0.2, outperforming traditional methods. Additionally, the framework demonstrated resilience to overfitting and local minima, maintaining consistent performance under varying conditions.},
  archive      = {J_IJPRAI},
  author       = {Manikandan Sundaram and S. Vinoth Kumar and R. Lakshmana Kumar and P. Punitha},
  doi          = {10.1142/S0218001425500119},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2550011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DRF-YOLO: A transformer-enhanced framework for underwater image enhancement and object detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization calculating of artificial intelligence IPGA algorithm. <em>IJPRAI</em>, <em>39</em>(7), 2559009. (<a href='https://doi.org/10.1142/S0218001425590098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional genetic algorithm (GA) known as the island model parallel genetic algorithm (IPGA) has limitations regarding speed and accuracy, especially when applied to large-scale datasets in parallel computing environments. This study addresses the optimization challenges associated with IPGA in the context of big data. Initially, an enhanced adaptive covariance matrix evolution strategy (CMA-ES) is implemented to replace the conventional Gaussian evolution strategy used in traditional IPGA. Additionally, a normalization function is integrated into the CMA-ES framework to constrain the range of random values during the iterative optimization process, thereby improving both the speed and accuracy of IPGA in managing big data computations. Furthermore, the MapReduce paradigm is utilized within a Hadoop cluster to optimize the computational process of IPGA, making it more suitable for distributed parallel operations on extensive datasets. Experimental findings indicate that the proposed methodologies significantly enhance the speed and accuracy of IPGA optimization, particularly in the context of large-scale and ultra-large-scale datasets, with a marked improvement in computational speed.},
  archive      = {J_IJPRAI},
  author       = {Zhenliu Zhou and Yan Xia and Shun Yu and Junyu Hu and Liming Wang and Rongxu Hou},
  doi          = {10.1142/S0218001425590098},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2559009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimization calculating of artificial intelligence IPGA algorithm},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive AI-enhanced signal processing framework for optimized communication in the internet of underwater things (IOUT). <em>IJPRAI</em>, <em>39</em>(7), 2558002. (<a href='https://doi.org/10.1142/S0218001425580029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Underwater Things (IoUT) is an emerging revolution in underwater monitoring and communication, offering real-time detection of objects and data collection in harsh aquatic conditions. Severe communication problems, including signal attenuation, high latency, limited bandwidth, and noise/interference vulnerability, reduce underwater network performance and impede IoUT deployment. The proposed work introduces three new techniques to tackle these problems. The first work introduces the Sequential Memory Fusion Network (SMFN) for predicting environmental changes using historical and real-time data and predicting factors such as signal degradation and noise levels. In the second work, the Adaptive Condition-Based Binary Phase-Shift Keying system (ACB-BPSK) dynamically switches between modulation schemes of high-noise and low-noise modes with the help of real-time feedback to achieve signal robustness and optimized data rates. ACB-EBPSK handles adaptation in modulation techniques according to environmental conditions for enhancing wireless communication’s reliability and efficiency. The third contribution is an Energy-Efficient Reinforcement Learning (EERL) framework for routing decisions, which learns from network feedback, packet loss, and congestion-allows inserting energy into the routing policy and prolonging the lifetime of battery-operated devices considering the dynamic natures of network conditions. The developed techniques’ advantages include increased communication reliability, higher data transmission rates, and prolonged network lifetime.},
  archive      = {J_IJPRAI},
  author       = {V. Padmavathi and C. Suresh and R. Lakshmana Kumar and P. Punitha},
  doi          = {10.1142/S0218001425580029},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2558002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Adaptive AI-enhanced signal processing framework for optimized communication in the internet of underwater things (IOUT)},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection and control in supply chains based on image feature modeling. <em>IJPRAI</em>, <em>39</em>(7), 2554006. (<a href='https://doi.org/10.1142/S0218001425540060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring process quality in supply chains is a critical challenge due to the complexity and variability of production processes. Conventional methods often struggle to accurately detect and address quality issues in such dynamic environments. This paper proposes a novel anomaly detection and control method based on image feature modeling to enhance process monitoring and decision-making in supply chain operations. By leveraging advanced image processing techniques, key features of production processes are extracted and modeled, enabling accurate identification of deviations and anomalies. Experimental results demonstrate that the proposed method significantly improves detection accuracy and response time compared to traditional approaches. This study contributes to the development of intelligent quality control solutions, offering scalability and robustness for real-world supply chain applications.},
  archive      = {J_IJPRAI},
  author       = {Yue Pan},
  doi          = {10.1142/S0218001425540060},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2554006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Anomaly detection and control in supply chains based on image feature modeling},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid deep learning-based automatic diagnosis of breast cancer from mammograms using segmentation and feature selection. <em>IJPRAI</em>, <em>39</em>(7), 2554004. (<a href='https://doi.org/10.1142/S0218001425540047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image processing plays a crucial role in the early detection and classification of diseases, particularly breast cancer, which is a leading cause of death among women. Mammography is widely used for breast cancer diagnosis, but accurately interpreting mammograms remains challenging even for expert radiologists. To address this, we propose a novel framework for automatic breast cancer diagnosis that integrates mass segmentation, feature selection, and a hybrid deep learning-based classifier. Our approach introduces the enhanced black widow optimization (EBWO) algorithm for mass segmentation, effectively identifying the region of interest (ROI) in mammograms. The Improved UNet model is used for deep feature extraction, enhancing feature representations from the segmented masses. To tackle the issue of high-dimensional data, we employ the modified snow ablation optimization (MSAO) algorithm for optimal feature selection, ensuring the best features are chosen for classification. The optimal threshold graph neural network (OT-GNN) is then utilized for classifying breast cancer into three categories: normal, benign, and malignant. In comparison with existing methods, our framework demonstrates superior performance. We validate the proposed UNet+MSAO+OT-GNN method using augmented datasets such as DDSM and INbreast, achieving IOU scores of 99.912% and 99.909%, respectively. Our method outperforms existing classifiers, achieving accuracy scores of 99.523% and 99.859% on DDSM and INbreast datasets, respectively, showcasing significant improvements in both segmentation and classification accuracy. This highlights the effectiveness and novelty of our approach in comparison to traditional methods.},
  archive      = {J_IJPRAI},
  author       = {N. Rajesh Pandian and N. Selvaganesh and D. Shanthi},
  doi          = {10.1142/S0218001425540047},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2554004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hybrid deep learning-based automatic diagnosis of breast cancer from mammograms using segmentation and feature selection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning research on quantitative evaluation model of tea taste based on NAR neural network. <em>IJPRAI</em>, <em>39</em>(7), 2552008. (<a href='https://doi.org/10.1142/S0218001425520081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for tea from consumers exhibits a diversified and personalized trend. Initiating from the scientific analysis of tea taste, this paper addresses issues such as the incomplete cognition standard of tea market taste, varying evaluation criteria for tea, and the development of a young tea consumption group, utilizing the Nonlinear Auto-Regressive (NAR) model, a quantitative evaluation of tea taste is conducted. In this study, raw and ripe tea samples from Pu-erh tea were used as training data, and the NAR was employed for deep learning, error analysis, and comparison. The aim was to predict the taste resulting from different content ratios of chemical components in tea, further verifying the feasibility and scientific accuracy of the quantitative evaluation of tea taste based on the NAR. This study not only broadens the research field of NAR neural network, but also further enables tea enterprises to better provide consumers with diversified tea taste, and provides an important reference for tea taste evaluation.},
  archive      = {J_IJPRAI},
  author       = {Mingxin Ji and Xingrui Wang and Di Wu and Siyi Wu and Meng Yang and Yue Li},
  doi          = {10.1142/S0218001425520081},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2552008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep learning research on quantitative evaluation model of tea taste based on NAR neural network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Source-free domain adaptation via enhanced self-supervised learning. <em>IJPRAI</em>, <em>39</em>(7), 2552007. (<a href='https://doi.org/10.1142/S021800142552007X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenge of Source-free Domain Adaptation (SFDA), where knowledge is transferred from a labeled source domain to an unlabeled target domain without requiring access to the source data during adaptation. Traditional Unsupervised Domain Adaptation (UDA) methods typically depend on source data availability during training, which raises concerns related to privacy, security, and scalability. Our proposed approach eliminates this dependency by leveraging only a pre-trained source model for adaptation to the target domain. We introduce a comprehensive framework that incorporates iterative centroid refinement for pseudo-labeling, enhanced self-supervised learning strategies, advanced regularization techniques, and dynamic loss weighting mechanisms. These innovations improve feature alignment and classification performance in the target domain. Extensive experiments conducted on diverse datasets, including digital and object benchmarks, demonstrate that our method consistently outperforms state-of-the-art techniques in both accuracy and robustness. Additionally, this study delves into the theoretical foundations of SFDA, providing insights into its efficacy and exploring its practical applications across various domains.},
  archive      = {J_IJPRAI},
  author       = {Jih Pin Yeh and Yihjia Tsai and Hsiau-Wen Lin and Hwei Jen Lin and Yoshimasa Tokuyama},
  doi          = {10.1142/S021800142552007X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2552007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Source-free domain adaptation via enhanced self-supervised learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JFD-GNN: A joint graph neural network approach for detecting fake news. <em>IJPRAI</em>, <em>39</em>(7), 2552005. (<a href='https://doi.org/10.1142/S0218001425520056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news is often designed to closely mimic legitimate news, making its detection based on content analysis alone unreliable. Hence, we propose a deeper exploration of the correlation between fake news and user profiles to understand its widespread. For this purpose, we propose a Joint Fake News Detection framework, called JFD-GNN, which consists of two distinct models designed to integrate user profiles, internal preferences, and external context. The first model, based on Graph Neural Networks (GNN), incorporates user preferences and leverages the tweet history of the post’s publisher as endogenous features. Additionally, it utilizes propagation graphs as exogenous features to derive a joint representation of user engagement. The second model focuses on user profile details and textual embeddings of comments as user features, constructing a GNN-based model for user profile analysis. We use BERT and Word2Vec as data encoders. To enhance the performance of the joint model, the fused output is passed through a fully connected layer to compute the final output and then compare it with the target. We conducted several experiments on two publicly available fake news datasets, Politifact and Gossipcop, where our approach achieved 97.99% accuracy on Gossipcop dataset and 95.16% accuracy on Politifact dataset. This illustrates the effectiveness of JFD-GNN for identifying fake news, and the proposed method reaches a comparatively high level by combining various information levels from different modalities.},
  archive      = {J_IJPRAI},
  author       = {Soufiane Khedairia and Hafed Zarzour and Djalel Chefrour},
  doi          = {10.1142/S0218001425520056},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2552005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {JFD-GNN: A joint graph neural network approach for detecting fake news},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable multiple kernel K-means clustering with entropy regularization. <em>IJPRAI</em>, <em>39</em>(7), 2551010. (<a href='https://doi.org/10.1142/S0218001425510103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-kernel k-means clustering (MKC) aims to learn a composite kernel from multiple precomputed basic kernels to better reflect the data distribution. In the existing MKC models, the optimal composite kernel is linearly combined by basic kernels with varying weights, subject to different constraints. While some state-of-the-art models have achieved satisfactory clustering performance, they often do so at the expense of model interpretability. To address this issue, this paper proposes a new M ulti- K ernel K -means C lustering model with maximized E ntropy regularization (MKKC-E). In the new model, convex combination of basic kernels is used to learn the optimal composite kernel to enhance interpretability. Meanwhile, an entropy regularization term is introduced to prevent the kernel weights from becoming overly sparse, thereby improving the model’s robustness. Experimental results demonstrate that the proposed model’s interpretability and robustness are validated on synthetic datasets, while its superior clustering performance is confirmed on benchmark datasets. In conclusion, the MKKC-E model not only achieves excellent clustering performance but also offers significant interpretability.},
  archive      = {J_IJPRAI},
  author       = {Fengjiao Peng and Shuisheng Zhou},
  doi          = {10.1142/S0218001425510103},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2551010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Interpretable multiple kernel K-means clustering with entropy regularization},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity semantic convolutional model for pig face recognition. <em>IJPRAI</em>, <em>39</em>(7), 2550009. (<a href='https://doi.org/10.1142/S0218001425500090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intensification and automation of the pig farming industry have created an urgent need for cost-effective and efficient identification of individual pigs. Pig identification is crucial for disease prevention and control, pork quality traceability, genetic breeding, and insurance services. To address the challenges faced by existing noncontact pig face recognition models in overcoming strong environmental interference in pigsties and the minimal differences among pig faces, this paper proposes a convolutional neural network based on multi-granularity semantic analysis (MGSNet). By integrating pixel-level, component-level, and object-level semantic features, the model significantly improves recognition performance in complex scenarios. Specifically, the model addresses challenges such as environmental interference and high similarity among individual pigs. Experimental results show that the algorithm achieves a high test accuracy of 92.50% on a dataset of 10 pigs collected from actual pig farms, with lightweight network parameters. Through deconvolution and gradient-weighted class activation mapping techniques, the feature extraction process of the model is visually interpretable, providing reliable technical support for farmers. The research findings can be directly applied to precision feeding, disease monitoring, breeding optimization, and other scenarios, promoting the comprehensive adoption of smart agriculture.},
  archive      = {J_IJPRAI},
  author       = {Yadong Yang and Yourui Huang and Deyong She and Jing Zhang and Mingjing Pei and Xiancun Zhou},
  doi          = {10.1142/S0218001425500090},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2550009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-granularity semantic convolutional model for pig face recognition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A small target recognition method based on an improved YOLOv8. <em>IJPRAI</em>, <em>39</em>(7), 2550008. (<a href='https://doi.org/10.1142/S0218001425500089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognition of small-size targets presents a significant challenge in computer vision, as their reduced dimensions often lead to diminished detection accuracy. To address this issue, this paper proposes an enhanced small-size target recognition method based on an improved version of You Only Look Once Version 8 (YOLOv8). The proposed improvements include integrating the dynamic attention mechanism of BiFormer (Vision Transformer with Bi-level Routing Attention), which leverages the sparsity of dynamic and query perception to enable more flexible and adaptive content perception. Additionally, the Weighted Intersection over Union (WIOU) loss function is introduced to address the imbalance in Bounding Box Regression (BBR) between samples, enhancing the overall accuracy of the model. Furthermore, a specialized detection head for small targets and a confidence-adaptive module are added at the detection head’s end, improving feature extraction and continuous tracking capabilities for small targets, especially under conditions of low visibility and target occlusion. Experimental results demonstrate that the improved model significantly enhances the detection of incomplete and small-sized targets, providing robust performance in scenarios with occlusion and reduced visibility. This study emphasizes the potential of the enhanced YOLOv8 model in real-world applications, providing new improvement ideas for the development of occluded and small target recognition.},
  archive      = {J_IJPRAI},
  author       = {Saibiao Jiang and Jianan Fan and Zhijin Sun and Kaitao Deng and Yanbing Huang},
  doi          = {10.1142/S0218001425500089},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2550008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A small target recognition method based on an improved YOLOv8},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing visual transformer and faster R-CNN integration for efficient object detection. <em>IJPRAI</em>, <em>39</em>(6), 2559008. (<a href='https://doi.org/10.1142/S0218001425590086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Visual Transformers (ViTs) with Faster R-CNN has shown significant promise in computer vision tasks requiring both high accuracy and efficient object detection. However, the computational cost and resource requirements of these models often limit their application in real time, resource-constrained environments. This paper proposes a novel optimization strategy for integrating ViT with Faster R-CNN to enhance both performance and efficiency. We introduce an improved ViT-Tiny backbone with a hybrid attention mechanism, CS-attention, that combines high- and low-frequency attention to better capture local and global features while minimizing computational overhead. Additionally, a pyramid feature network (FPN) is incorporated to enhance multi-scale feature extraction, allowing the model to accurately detect objects at varying scales. Experimental results demonstrate that the optimized model achieves high accuracy and real-time processing capabilities, making it suitable for deployment in industrial and edge computing applications. The proposed approach is validated through extensive experiments, providing a general solution for efficient object detection across various domains.},
  archive      = {J_IJPRAI},
  author       = {Lin Lei and Yun Huang},
  doi          = {10.1142/S0218001425590086},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2559008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimizing visual transformer and faster R-CNN integration for efficient object detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Patch feature transformation: An anomaly detection method with succinct feature filtering. <em>IJPRAI</em>, <em>39</em>(6), 2559006. (<a href='https://doi.org/10.1142/S0218001425590062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is often approached as an out-of-distribution (OOD) detection task, where a feature distribution from normal samples is constructed, and deviations are flagged as anomalies. This approach is dependent on manual labeling, as subtle visual anomalies can be easily overlooked, resulting in the potential for bias in labeling and subsequent unsatisfactory detection results. Based on the issue, we propose Anomaly Detection with Succinct Feature Filtering (ADSFF) for unlabeled samples. Our method avoids sample labeling bias and provides a solution to the coexistence of anomalous and normal features in the feature space of unlabeled samples. ADSFF includes a data preprocessing module and a feature filtering module, where the data preprocessing module improves the visibility of subtle anomalies, while the feature filtering module screens the local features of the samples. In feature filtering, we found that feedforward neural networks do not lose feature information during the feature transformation process. Consequently, we utilized feedforward neural networks for feature filtering and achieved expected results. Furthermore, we investigate the impact of sample imbalance on the task of anomaly detection using unlabeled samples. This paper assesses the performance of ADSFF using the MVTec AD and BeanTech Anomaly Detection (BTAD) datasets. The results demonstrate that ADSFF achieves an average area under the curve (AUC) of 0.978 on the MVTec AD and an average AUC of 0.942 on the BTAD. ADSFF outperformed other methods on seven test datasets in MVTec AD, achieving the highest average accuracy on MVTec AD.},
  archive      = {J_IJPRAI},
  author       = {Yaohua Guo and Guoai Xu and Jianping Yin and Siqi Wang},
  doi          = {10.1142/S0218001425590062},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2559006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Patch feature transformation: An anomaly detection method with succinct feature filtering},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced website fingerprinting attacks based on attention mechanism and spatial-temporal features. <em>IJPRAI</em>, <em>39</em>(6), 2559005. (<a href='https://doi.org/10.1142/S0218001425590050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Website fingerprinting (WF) attacks leverage deep learning to analyze encrypted traffic and identify the websites accessed by Tor users, posing a critical threat to online anonymity. However, existing detection models often suffer from low accuracy and weak robustness in open-world scenarios. To address these issues, we propose a novel spatiotemporal WF framework integrating a lightweight attention mechanism and parallel multi-size feature extraction with dilated convolution. This design significantly enhances detection performance while maintaining high efficiency. Experimental results show that our approach outperforms CNN and LSTM models by 3–5% in accuracy and surpasses the DF model by about 1%, while achieving a 50% increase in efficiency. Furthermore, it demonstrates robust performance as the number of website categories grows and remains effective against defenses such as WTF-PAD and Walkie-Talkie. Notably, our framework also mitigates the impact of concept drift, exhibiting minimal performance degradation when traffic distributions evolve over time. These findings not only underscore the unique potential of our model to advance WF attacks, but also highlight the urgent need for stronger privacy-preserving measures to protect Tor users in real-world environments.},
  archive      = {J_IJPRAI},
  author       = {Chunqian Guo and Gang Chen and Deliang Jin and Zhihan Lin},
  doi          = {10.1142/S0218001425590050},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2559005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An enhanced website fingerprinting attacks based on attention mechanism and spatial-temporal features},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A PMSM speed control strategy of LADRC based on neural network load torque estimation. <em>IJPRAI</em>, <em>39</em>(6), 2559003. (<a href='https://doi.org/10.1142/S0218001425590037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel speed control method for Permanent Magnet Synchronous Motors (PMSM) utilizing Linear Active Disturbance Rejection Control (LADRC). The initial step involves collecting data on the motor’s d -axis and q -axis currents, speed, and load torque during stable operation. A small-scale neural network, characterized by low computational demands, is then trained to provide a non-exact load torque estimation. Subsequently, this estimated value of the load torque is incorporated into the LADRC, resulting in a reduction of the pressure calculated by the Extended State Observer (ESO). The discrepancy between the actual and estimated load torque can be viewed as the total disturbance experienced by the system. Finally, a LADRC speed controller that utilizes an imprecise load torque estimation is constructed. To enhance the flexibility and adaptability of the method, a weight coefficient is added to the estimated load torque. The efficacy of this speed control strategy is confirmed through Matlab/Simulink simulation, demonstrating superior control performance when faced with sudden changes in load torque.},
  archive      = {J_IJPRAI},
  author       = {Lijie Yin and Chen Tang and Lijun Wei},
  doi          = {10.1142/S0218001425590037},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2559003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A PMSM speed control strategy of LADRC based on neural network load torque estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward generalized 3D lane representation with lane geometry supervision for autonomous driving. <em>IJPRAI</em>, <em>39</em>(6), 2555007. (<a href='https://doi.org/10.1142/S0218001425550079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lane detection is crucial for autonomous driving. Recent advancements have expanded traditional two-dimensional (2D) lane detection to three-dimensional (3D) by predicting lane positions in 3D space. These methods rely on fully supervised learning, requiring high-quality 3D labels, which are difficult to obtain. This challenge motivates a weakly supervised approach leveraging abundant and easily scalable 2D lane annotations. Specifically, we systematically analyze lane geometric structure priors and introduce Lane Geometry Supervision (LGS), which relies solely on 2D lane labels. Extensive experiments on both synthetic and real-world datasets demonstrate that our method achieves performance comparable to fully supervised approaches using direct 3D labels. Moreover, incorporating LGS as a regularization term further enhances the performance of existing fully supervised methods. Finally, we show that LGS enables a label-efficient training methodology for 3D monocular lane detection, effectively utilizing both scarce yet complete 3D lane labels and abundant but incomplete 2D lane labels.},
  archive      = {J_IJPRAI},
  author       = {Wenbo Ding and Wenlian Lu},
  doi          = {10.1142/S0218001425550079},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2555007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Toward generalized 3D lane representation with lane geometry supervision for autonomous driving},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quadrotor attitude control via three-loop ADRC and backstepping integral method: Dynamic modeling and validation. <em>IJPRAI</em>, <em>39</em>(6), 2555006. (<a href='https://doi.org/10.1142/S0218001425550067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the dynamic characteristics of four-rotor attitude control, including nonlinearity, internal underactuation and strong coupling, this study proposes a control strategy that integrates adaptive Active Disturbance Rejection Control (ADRC) with the inverse step integration method. This approach aims to enhance adaptability to uncertain parameters and external disturbances. First, a mathematical model for the flight attitude angle of the quadrotor is formulated. The dynamics of the quadrotor is partitioned into three subsystems corresponding to the pitch, roll and yaw axes, with ADRC parameters being individually calibrated for each. Subsequently, the Extended State Observer (ESO) component of ADRC is integrated into the design of each virtual control layer, enabling real-time estimation and compensation for dynamic disturbances within the subsystems. An adaptive parameter adjustment mechanism is incorporated during the backstepping process to enhance the precision and response speed of attitude angle control. Finally, the anti-interference performance and robustness of the tri-loop cascaded ADRC controller are validated using the fusion inverse integration method on the MATLAB simulation platform. Experimental results show that, compared to the single-loop attitude control ADRC, the three-loop cascaded ADRC integrated with the backstepping integral method significantly improves the response times for the pitch, roll and yaw axes by approximately 67.7%, 69.8% and 58.4%, respectively, under the same strong interference conditions. Additionally, the average fluctuation amplitude of the angles decreases to 0 . 2 3 8 ∘ , 0 . 1 1 5 ∘ and 0 . 2 1 2 ∘ for the pitch, roll and yaw axes, respectively. Therefore, the backstepping integral method integrated with the three-loop cascaded ADRC not only ensures a higher response speed across all three axes but also strengthens the robustness of the quadrotor, improving angle stability by nearly a factor of 10. It offers innovative theoretical insights and technical solutions for addressing the dynamic stability control challenges in strongly nonlinear and multi-source uncertain systems.},
  archive      = {J_IJPRAI},
  author       = {Guiyu Zhou and Zhengcong Du and Hong Wen and Lianghua Wen and Haibo Zhang},
  doi          = {10.1142/S0218001425550067},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2555006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Quadrotor attitude control via three-loop ADRC and backstepping integral method: Dynamic modeling and validation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STSODNet: Scale transformer small object detection network. <em>IJPRAI</em>, <em>39</em>(6), 2555004. (<a href='https://doi.org/10.1142/S0218001425550043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense small object detection in complex scenes is a valuable and challenging research field. While deep learning has driven significant advancements in computer vision, traditional object detection models still struggle to achieve high accuracy in detecting small objects, particularly in large-scale aerial images. Challenges such as scale variations, occlusions, and complex backgrounds continue to hinder the effective detection of dense small objects. In this paper, we present the Scale Transformer Small Object Detection Network (STSODNet), a novel architecture designed to address these challenges. First, we conceptualize the pronounced scale variation in drone images as an anomalous disturbance and propose a multiscale feature enhancement module (MSFEM), built upon the Spatial Transformer Network, to mitigate this effect. The multiscale feature enhancement module performs learnable, multi-point magnification on regions surrounding objects based on spatial saliency, enhancing the model’s scale invariance. Second, to generate a more accurate global saliency map and heighten the model’s focus on small target regions, we introduce a refined spatial attention mechanism, termed Spatial Region Attention. This mechanism combines coarse region attention with fine spatial attention to produce a more detailed saliency map and improve long-range dependency capture. Third, to achieve more accurate spatial regression of small objects, the traditional three-layer detection head is improved by expanding its output layer, resulting in a finer and larger output while maintaining the same number of parameters. Extensive experiments on the VisDrone and SeaPerson benchmark datasets validate that STSODNet achieves superior precision and robustness, outperforming current state-of-the-art object detection methods for small object detection.},
  archive      = {J_IJPRAI},
  author       = {Jincheng Li and Lina Yang and Patrick Shen-Pei Wang},
  doi          = {10.1142/S0218001425550043},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2555004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {STSODNet: Scale transformer small object detection network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-clues adaptive learning for cloth-changing person re-identification. <em>IJPRAI</em>, <em>39</em>(6), 2555001. (<a href='https://doi.org/10.1142/S0218001425550018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving long-term Cloth-Changing Person Re-identification (CC-ReID) requires extracting features insensitive to clothing such as face, silhouette, gait and pose estimation. Most current work focuses on modeling from a single feature, but we observe that CC-ReID problems in open environments are often difficult to solve solely based on a single feature, for instance, sometimes, contour features may be advantageous for recognition, while at other times gait features may be more valuable. In our paper, we suggest a novel multi-clues guided Adaptive Learning Transformer (ALT) which can adaptively select the most readily identifiable features based on different scenarios. The method comprises two parts: a Multi-clues Guiding Module (MGM) and a Feature Selection Module (FSM). We utilize clothes-irrelevant features from multi-modality information as clues, integrating multiple features to extract robust representations invariant to clothing changes for CC-ReID through cross-attention and Mixture of Experts (MoEs). We utilized contour sketch and gait as clues, conducting experiments on the CC-ReID dataset. The experimental results show that our recommended approach prevails over all other SOTA methods, particularly showing significant improvement compared to using contour sketch and gait alone.},
  archive      = {J_IJPRAI},
  author       = {Xiang Zhou and Junzhu Liu and Xinyang Jiang and Pengyu Li and Cairong Zhao},
  doi          = {10.1142/S0218001425550018},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2555001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-clues adaptive learning for cloth-changing person re-identification},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian uncertainty weighted optimization for offline reinforcement learning. <em>IJPRAI</em>, <em>39</em>(6), 2551001. (<a href='https://doi.org/10.1142/S0218001425510012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning (offline RL) endeavors to learn effective policies from a large batch of pre-collected datasets without any costly or dangerous online exploration. Nevertheless, offline RL always suffers from substantial algorithmic extrapolation errors and may fail when bootstrapping from out-of-distribution (OOD) actions or states. In this work, we introduce a practical and effective Bayesian uncertainty weighted optimization (BUWO) to leverage the Bayesian uncertainty to account for the epistemic uncertainty associated with each training sample and penalize the state-action pairs with high uncertainty. We compare BUWO with other prevailing offline RL algorithms on D4RL benchmarks. The experimental results demonstrate that the algorithm can enhance the average reward score by almost 15% without additional computational costs compared to the current state-of-the-art algorithm.},
  archive      = {J_IJPRAI},
  author       = {Tianyi Li and Genke Yang and Jian Chu},
  doi          = {10.1142/S0218001425510012},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2551001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Bayesian uncertainty weighted optimization for offline reinforcement learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale adaptive diffusion feature fusion with causal invariance learning for hyperspectral image classification. <em>IJPRAI</em>, <em>39</em>(6), 2550010. (<a href='https://doi.org/10.1142/S0218001425500107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image (HSI) classification is a significant research area in remote sensing with a wide range of application scenarios. Recently, numerous HSI classification methods based on convolutional neural networks (CNNs) and Transformers have demonstrated promising classification performance. However, these methods demonstrate insufficient capability in mining spectral–spatial relationships from limited HSI samples and fail to extract features pertinent to the target category. To address these challenges, we propose a multi-scale adaptive diffusion feature fusion and causal invariance learning (MSDF-CIL) framework based on diffusion models. Specifically, the framework establishes spectral–spatial distribution relationships through forward and backward diffusion processes. The forward process gradually introduces noise to the HSI input. In the backward diffusion process, our pre-trained hyperspectral denoising network extracts semantically rich multi-scale diffusion features from complex spectral–spatial relationships. A multi-scale adaptive diffusion feature fusion (MSADFF) module is designed to learn key information about each scale and fuse it to enhance the representation. In addition, a causal invariance learning (CIL) module is designed to focus on features causally related to the target class, enabling the model to eliminate spurious correlations among diffusion features. Experimental results on three public HSI datasets show that the proposed MSDF-CIL outperforms other state-of-the-art HSI classification methods, even with minimal samples. When the number of training samples in each class reaches 30, the MSDF-CIL achieves overall accuracy improvements of 4.0% on the Pavia University dataset, 2.3% on the Indian Pines dataset, and 2.3% on the Houston13 dataset, respectively.},
  archive      = {J_IJPRAI},
  author       = {Wanxing Zha and Lina Yang and Huafu Xu and Bingzhen Wang and Danyang Chen and Yuwen Lin and Yiqun Wang and Patrick Shen-Pei Wang},
  doi          = {10.1142/S0218001425500107},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2550010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-scale adaptive diffusion feature fusion with causal invariance learning for hyperspectral image classification},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence on power flow stability control of high-penetration Wind–Solar-ES (Energy storage) distribution grid network. <em>IJPRAI</em>, <em>39</em>(5), 2559004. (<a href='https://doi.org/10.1142/S0218001425590049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of new energy systems, the stability of the power system is challenged. By adding energy storage links access to the power system, the original source–grid–load structure has been transformed into source–grid–load-ES (energy storage) structure. In order to monitor the stability of the high-penetration wind–solar-ES distribution network, this paper starts from the flow stability of the renewable power system, establishes a stability monitoring matrix as artificial intelligence, and uses the fluctuation of current and power flow as the measurement index to establish reasonable monitoring points for each parameter to encounter the demand of the point with the highest fluctuation. By monitoring and comparing various fluctuation indicators of the power flow in the high-penetration wind–solar-ES distribution grid with wind–solar power access ratio of 10–50%, the stability data of the power flow in the high-penetration wind–solar-ES distribution grid is determined, providing reference for the stable operation of the rapidly developing new power system.},
  archive      = {J_IJPRAI},
  author       = {Zhilin Ding and Wenping Bu and Yao Xu and Hui Li},
  doi          = {10.1142/S0218001425590049},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2559004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Artificial intelligence on power flow stability control of high-penetration Wind–Solar-ES (Energy storage) distribution grid network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end classification network model based on hybrid supervision for industrial surface defect detection. <em>IJPRAI</em>, <em>39</em>(5), 2555005. (<a href='https://doi.org/10.1142/S0218001425550055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial part surface defect detection aims to precisely locate defects in images, which is crucial for quality control in manufacturing. The traditional method needs to be designed in advance, but it has shortcomings in terms of generalization ability. Deep neural network-based defect detection faces issues such as low resolution, data scarcity, labeling costs, and high computation. Therefore, an improved solution is necessary to enhance industrial product quality control efficiency and accuracy. A new method is proposed that utilizes end-to-end training of a two-stage neural network based on segmentation with an extended training process. The gradient flow from the classification to the segmentation network is adjusted to prevent unstable features from interfering with learning. To address the problem of image oversampling and undersampling during training, a frequency sampling scheme for negative samples is introduced. Additionally, positive pixels in the region-based segmentation mask are weighted using the distance transform algorithm so that regions with a high probability of defects can be detected without detailed annotation. Experiments are conducted across three distinct defect datasets by applying hybrid supervision encompassing diverse conditions. In the optimal case, the AP rate of the proposed model on the DAGM and KolektorSDD datasets reaches 100%, and the AP rate on the Severstal Steel dataset reaches 98.99%. The experiments’ results show that the detection accuracy has improved greatly, showing how well the proposed method works in the industry.},
  archive      = {J_IJPRAI},
  author       = {Runbing Qin and Ningjiang Chen and Shukun Gan},
  doi          = {10.1142/S0218001425550055},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2555005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An end-to-end classification network model based on hybrid supervision for industrial surface defect detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optic nerve segmentation model based on fully-convolutional-based masked autoencoders and direction field. <em>IJPRAI</em>, <em>39</em>(5), 2554005. (<a href='https://doi.org/10.1142/S0218001425540059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound measurement of optic nerve sheath diameter (ONSD) is considered a noninvasive method for estimating elevated intracranial pressure (ICP) in patients. Clinical trials have demonstrated a strong correlation between changes in ONSD and changes in ICP. Therefore, accurate segmentation of the ONSD is crucial for noninvasive ICP assessment. In this paper, we propose a two-stage self-supervised semantic segmentation method to enhance optic nerve segmentation. In the pre-training phase, we use a fully convolutional-based masked autoencoder (FCMAE) to reconstruct full images from partially masked inputs. The encoder of FCMAE aggregates contextual information to infer the masked image regions, and this pretrained encoder is then migrated to the segmentation task for parameter initialization. In the fine-tuning phase, we perform the optic nerve segmentation task. After obtaining the initial segmentation results through the UPerNet network, we use a direction field (DF) module to compute a vector of DFs pointing to the nearest edge of the optic nerve for each pixel. This DF information is then used to refine the initial segmentation results via the feature correction module. The model was trained on a dataset of optic nerve sheath images collected from hospital patients and achieved a Dice score of 98.03%. Our proposed method exhibits superior performance across all metrics compared to other segmentation models.},
  archive      = {J_IJPRAI},
  author       = {M. Jiang and Q. Huang and X. Huang and J. Zhang and C. Wu and T. Huang and L. Xia and T. Tan and Z. Wang and Y. Chu},
  doi          = {10.1142/S0218001425540059},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2554005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An optic nerve segmentation model based on fully-convolutional-based masked autoencoders and direction field},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hummingbird optimization with deep learning enabled feature reduction and classification approach for high dimensional data. <em>IJPRAI</em>, <em>39</em>(5), 2552004. (<a href='https://doi.org/10.1142/S0218001425520044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel technique for image classification tasks that handles high-dimensional data: Hummingbird Optimization Deep Learning-based Feature Reduction and Classification (HBODL-FRC). The proposed method incorporates several cutting-edge methodologies to improve the precision and effectiveness of the categorization process. To ensure the quality of the input data, bilateral filtering is first used to successfully remove noise. After that, key features are extracted by combining texture features and histograms, which form the basis of the feature reduction procedure that follows. One of the main innovations in this work is the deployment of the Hummingbird Optimization (HBO) algorithm, which is used to intentionally minimize the feature sets’ complexity. The final classification of the images is accomplished by feeding the optimized feature set into a “multi-head attention-based bidirectional long short-term memory” (MABi-LSTM) model. To further improve classification accuracy, the MABi-LSTM model makes use of the attention mechanism to concentrate on the most pertinent portions of the data. Using benchmark datasets, the HBODL-FRC model’s performance was thoroughly assessed and compared to the existing techniques. The HBODL-FRC model performs better than previous methods in terms of robustness and classification accuracy, according to extensive experimental results.},
  archive      = {J_IJPRAI},
  author       = {D. Mahalakshmi and S. Appavu Alias Balamurugan and M. Chinnadurai},
  doi          = {10.1142/S0218001425520044},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2552004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hummingbird optimization with deep learning enabled feature reduction and classification approach for high dimensional data},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The utilization of machine learning approaches in predicting the prominent physicochemical properties of polychlorinated biphenyl. <em>IJPRAI</em>, <em>39</em>(5), 2551007. (<a href='https://doi.org/10.1142/S0218001425510073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the difficulties in experimental measurement, machine learning offers a viable alternative method to reduce and minimize costs and time. Machine learning enhances the effectiveness and efficiency of environmental pollutant monitoring, supporting better management and protection of ecosystems and public health. Random forest is indeed a significant machine learning method, widely used for various applications due to its robustness and versatility. Polychlorinated biphenyls (PCBs), a vital class of persistent organic pollutants, have garnered significant attention from the scientific community due to their detrimental impacts. In this study, a computational prediction model for octanol–water partition coefficient (log P ) and bioconcentration factor (logBCF) of PCBs was developed by using random forest (RF), sparrow search algorithm random forest (SSA-RF), particle swarm optimization random forest (PSO-RF), and gray wolf optimization random forest (GWO-RF) methods. We performed a comprehensive validation, evaluation, and mechanistic explanation of the model for ensuring its reliability and applicability. Overall, the internal and external validation statistical parameters of the eight models have good robustness and predictive power. The Williams plots further show that all models are built in a wide range of application domains, and therefore they can be applied to unrecognized PCBs already in the environment to fill in the gaps in relevant experimental data. SSA-RF was superior to other methods, suggesting that it is more appropriate for computational studies of PCBs.},
  archive      = {J_IJPRAI},
  author       = {Hongqin Zhang and Ying Zhang and Lei Xu},
  doi          = {10.1142/S0218001425510073},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2551007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {The utilization of machine learning approaches in predicting the prominent physicochemical properties of polychlorinated biphenyl},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of job offers to measure gender barriers through natural language processing and soft computing techniques. <em>IJPRAI</em>, <em>39</em>(5), 2551005. (<a href='https://doi.org/10.1142/S021800142551005X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gender-biased language is still traced in job advertisements. Legal requirements to avoid direct gender-biased adjectives, and the usage of special software to detect and substitute gender-based words, scale up the issue more than solve it. The veil of discrimination on gender in job advertisements becomes more sophisticated with each succeeding level of its official and technical (including AI) prevention. This paper is mainly focused on the application of natural language processing (NLP) to detect gender-biased and discrimination of candidates by analyzing job offers posted online. NLP is an Artificial Intelligence tool that was applied in combination with Term Frequency-Inverse Document Frequency (TF-IDF) and Latent Dirichlet Allocation (LDA) to analyze the type of language used in job advertisements, detect the most relevant words used in the ads, and ultimately detect gender-bias. The main objective of this work is to provide equal access to employment opportunities from the very initial stage of the recruitment process. In addition, clustering techniques were applied to create groups based on the target public and the type of language used, providing evidence of gender-biased practices. The system was tested using a database of 2000 job ads in four different sectors: nursery, secretarial, managerial, and engineering.},
  archive      = {J_IJPRAI},
  author       = {Cristina Puente and Ivan Sanchez-Perez and Evhenia Kolomiyets-Ludwig and Clara Palacios-Castrillo and Patrick S. P. Wang and Rafael Palacios},
  doi          = {10.1142/S021800142551005X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2551005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Analysis of job offers to measure gender barriers through natural language processing and soft computing techniques},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State recognition method of power equipment in smart grid based on machine learning. <em>IJPRAI</em>, <em>39</em>(5), 2551004. (<a href='https://doi.org/10.1142/S0218001425510048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, machine learning is used to solve the problem of power equipment state recognition, aiming to improve the accuracy of equipment operation state recognition. With the ever-expanding size of the power system, an increasing number of devices are becoming more intricate, posing significant challenges to the security of the electricity network. Consequently, enhancing equipment operational reliability is imperative to ensure the reliability of power system operations. This study focuses on the identification of the operating status of power equipment, which integrates intelligent optimization algorithms and machine learning techniques, utilizing an ameliorative FOA to solve the parameter setting problem of support vector machine (SVM). Subsequently, the new diagnosis model is utilized to distinguish the fault types of the equipment. Through simulation and measured data verification, it shows that the new power equipment state recognition model by using machine learning has high diagnostic accuracy. The method effectively enhances equipment status identification capabilities and equipment fault diagnosis proficiency.},
  archive      = {J_IJPRAI},
  author       = {Zhihui Kang and Yunlong Li and Yang Chai and Min Zhao},
  doi          = {10.1142/S0218001425510048},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2551004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {State recognition method of power equipment in smart grid based on machine learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating the number of communities based on maximum a posteriori. <em>IJPRAI</em>, <em>39</em>(5), 2550007. (<a href='https://doi.org/10.1142/S0218001425500077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community structure is one of the important characteristics of complex networks. Community discovery or detection has important theoretical significance and practical value. At present, estimation of the number of communities (or clusters) is still an open question. By Bayesian inference, this research deduces the relationship between maximum possible partition and mutual information and information entropy, and proposes a framework algorithm Clustering Number Estimation (CNE) and a concrete implementation to estimate the number of clusters ( K ). Several typical algorithms for community number estimation are compared on several typical data sets, and primary experiments validate the effectiveness of this method.},
  archive      = {J_IJPRAI},
  author       = {Ningsi Li and Chuanpeng Wang and Dong Li},
  doi          = {10.1142/S0218001425500077},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2550007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Estimating the number of communities based on maximum a posteriori},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gait recognition by combining recurrent neural network and fully convolutional network. <em>IJPRAI</em>, <em>39</em>(5), 2550006. (<a href='https://doi.org/10.1142/S0218001425500065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition is one of the key technologies for exoskeleton robot control. The existing gait recognition methods cannot meet the needs of real-time control well in terms of recognition accuracy and robustness. In this paper, a gait recognition method based on the recurrent neural network and fully convolutional network (RNN-FCN) algorithm is proposed. In this paper, a human lower limb gait information acquisition device is developed, ten types of human lower limb gait data are collected, and a human gait recognition model is constructed using the RNN-FCN algorithm. The experimental results demonstrate that the RNN-FCN algorithm achieves an average recognition classification accuracy of 94.43% in the experiments, outperforming the other four algorithms.},
  archive      = {J_IJPRAI},
  author       = {Xinbin Zhang and Weixiang Xiong and Zhihao Yang and Qinghong Zhang and Jianjun Yan},
  doi          = {10.1142/S0218001425500065},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2550006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Gait recognition by combining recurrent neural network and fully convolutional network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-layer gated recurrent unit-based recurrent neural network for image captioning. <em>IJPRAI</em>, <em>39</em>(5), 2454018. (<a href='https://doi.org/10.1142/S0218001424540181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating natural language descriptions of an image, namely image captioning, has received much attention in computer vision and natural language processing. Recent image captioning models are mainly based on the encoder-decoder framework in which visual information is extracted by an encoder, e.g. using convolutional neural network (CNN), and captions are generated by a decoder, e.g. using recurrent neural network (RNN). Although this framework is promising for image captioning, there are still issues in the RNN decoder for exploiting the visual information to generate grammatically and semantically correct captions. More specifically, the RNN decoder has limited ability in dealing with long-term complex dependencies, leading to ineffective use of contextual information from the encoded data. To address this issue, in this paper, we introduce a multi-layer gated recurrent unit (ML-GRU) within the conventional RNN decoder, which enables the modulation of the relevant information flow inside the unit, and thus leads to the generation of semantically coherent captions. The proposed ML-GRU-based RNN decoder has been extensively evaluated on the MSCOCO dataset, and experimental results demonstrate the advantage of our proposed approach over the state-of-the-art approaches across multiple performance metrics.},
  archive      = {J_IJPRAI},
  author       = {Özkan Çaylı and Volkan Kılıç and Aytuğ Onan and Wenwu Wang},
  doi          = {10.1142/S0218001424540181},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2454018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-layer gated recurrent unit-based recurrent neural network for image captioning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting the fatigue crack life of train axles using a collaborative network of yolov5 and LSTM for acoustic emission signals. <em>IJPRAI</em>, <em>39</em>(03n04), 2559002. (<a href='https://doi.org/10.1142/S0218001425590025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of axles, life forecasting can be used to predict the lifespan of the axle and to determine more effective maintenance schedules. The life forecasting can have a significant positive impact on the safe operation of train axles, which can be used to predict the lifespan of the axle and to determine more effective maintenance schedules. Traditional methods for predicting the life of the shaft are based on experimental and statistical analysis, but these methods can be expensive and time-consuming. The LSTM-based Lifetime Forecasting method uses machine learning technology and historical data on the axles to more accurately predict remaining lifespan, thereby reducing costs and improving efficiency. This invention is innovative in that it introduces a semi-monitoring technique for estimating an axle RUL’s full life based on YOLOv5 and LSTM training. A large number of unmarked data are trained along with YOLOv5 and LSTM to determine interrupted data to RUL predictions. The use of a laboratory-collected sound crack on the 5 million, 7 million and 10 million signal data collection and RMSE MAE values, for verifying the performance of the model, respectively, for the full cycle of life of 5, 7 million, 10 million vehicles, is predicted with a strong difference between the predictable life of 5M and the remaining value of the forecast model.},
  archive      = {J_IJPRAI},
  author       = {Li Lin and Chunpeng Zhang and Liwen Ding and Lin Sun},
  doi          = {10.1142/S0218001425590025},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2559002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Predicting the fatigue crack life of train axles using a collaborative network of yolov5 and LSTM for acoustic emission signals},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Manifold matrices-based attention mechanisms on 3D skeletons for human action recognition. <em>IJPRAI</em>, <em>39</em>(03n04), 2557001. (<a href='https://doi.org/10.1142/S0218001425570010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, one of the most well-liked study fields in computer-vision is skeleton-based human action recognition. As the Lie group in Riemannian manifolds is able to precisely describe 3D geometric relationships among rigid bodies, it is widely used in skeleton-based action recognition approaches to construct action feature descriptors. Regrettably, the majority of these approaches overlook crucial body parts and skeletons in favor of focusing solely on spatio-temporal descriptors of an action as a whole. A manifold-based rigid body motion attention mechanism is proposed to assign varying degrees of importance to the relative geometries of different limb motions, and then a skeleton-based spatial attention module is constructed on the basis of limb motions for the more efficient extraction of spatial features from skeletons. Furthermore, a Lie group-based temporal attention mechanism is proposed on the basis of the first two phases to choose significant skeleton frames in an effort to raise the level of action recognition accuracy even higher. Results from experiments on four of the most influential action datasets demonstrate that the proposed approach performs better in terms of action recognition accuracy than many cutting-edge approaches based on skeletons.},
  archive      = {J_IJPRAI},
  author       = {Guang Li and Chongyang Ding and Jianjun Li},
  doi          = {10.1142/S0218001425570010},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2557001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Manifold matrices-based attention mechanisms on 3D skeletons for human action recognition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DGNet: A double-graph framework combined with occluded person re-identification for the prediction of pedestrian flow in scenic spots. <em>IJPRAI</em>, <em>39</em>(03n04), 2555003. (<a href='https://doi.org/10.1142/S0218001425550031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting pedestrian flow in scenic spots is a critical challenge for managing tourist areas. To address this, we propose the double-graph network (DGNet) framework, which combines occluded person re-identification and pedestrian flow prediction. Scenic spots are represented as nodes in a graph, with their pedestrian flow as node attributes, naturally forming a graph structure. DGNet consists of two key graphs: CNN-transformer graph (CTG) for occluded person re-identification and spatial-temporal graph (STG) for pedestrian flow prediction. CTG integrates global and local features using CNN, Transformer, and graph convolutional network (GCN) to handle occlusions effectively. STG employs spatial-temporal attention mechanisms to extract correlations across time and space for accurate pedestrian flow prediction. Based on comprehensive experiments, the proposed CTG obtains a comparable performance to the current mainstream occluded person re-identification algorithms. Comparative experiments with other models show that the STG achieves the best results on MAE, RMSE and MAPE metrics, outperforming other models by at least 0.29%, 0.51%, and 0.52%. These results highlight the framework’s robustness and accuracy. Moreover, the novelty of DGNet lies in its ability to bridge occluded person re-identification with flow prediction tasks, offering a scalable solution applicable to diverse scenic spots. This work provides practical insights into leveraging video surveillance for effective crowd management in tourist areas.},
  archive      = {J_IJPRAI},
  author       = {Jianrong Wang and Zhikang Meng and Fengping An},
  doi          = {10.1142/S0218001425550031},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2555003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DGNet: A double-graph framework combined with occluded person re-identification for the prediction of pedestrian flow in scenic spots},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel topic modeling framework for automated surveying of computer vision research in prostate cancer detection. <em>IJPRAI</em>, <em>39</em>(03n04), 2555002. (<a href='https://doi.org/10.1142/S021800142555002X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieving the relevant information or material makes a big difference in the medical field because it is necessary to acquire updates on recent findings and inferences so that the practitioners can understand the state-of-the-art topics. Thus, extracting relevant material automatically from the pool of large databases like Web of Science and IEE Explore on particular issues is important. This work focuses on extracting articles on different topics for prostate cancer detection. Due to a huge number of articles in large databases with many variations in the format, keywords, text in various forms, etc., extracting relevant articles is an open challenge. This observation motivated us to propose new Agnostic-topic modeling for retrieving articles across different categories, namely, Tasks (Image Classification, Image Segmentation, Gleason Grading, Object Detection, Image Enhancement, Motion Tracking, Image Registration, Image Synthesis, and Image Reconstruction), Models (CNN, UNet, GAN, Convolutional ML models, and Uncategorized) and Image Data Type (MRI, CT, Histological Images, Ultrasound Images, Nuclear Imaging, and Others). To address the above open challenge, the proposed work adapted ChatGPT and compared it with well-known models like LDA and BERT to show the robustness of ChatGPT. Furthermore, the extracted information is used to derive new inferences and findings. For example, the trend analysis according to the abovementioned tasks, models, and image types. To the best of our knowledge, this is the first work on retrieving articles automatically for prostate cancer detection.},
  archive      = {J_IJPRAI},
  author       = {Razieh Fadaeidehcheshmeh and Kaveh Kiani and Shivakumara Palaiahnakote and Taha Mansouri},
  doi          = {10.1142/S021800142555002X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2555002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel topic modeling framework for automated surveying of computer vision research in prostate cancer detection},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid-domain attention dense network for efficient image super-resolution. <em>IJPRAI</em>, <em>39</em>(03n04), 2554003. (<a href='https://doi.org/10.1142/S0218001425540035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient Image Super Resolution (EISR) techniques are critical to meeting the real-time demands of resource-constrained devices. Current approaches focus too much on parameter reduction, thus slightly sacrificing image quality. To alleviate this issue, we propose a novel Hybrid Attention Dense Network (HADN) in this paper. HADN fully explores how to balance model performance and image recovery quality better. It incorporates two key designs: (1) We apply Hybrid-domain Attention Dense Blocks (HADB) with different feature layers cumulatively connected to enhance the representation of shallow features. (2) We designed a novel Hybrid-domain Attention Block (HAB) to reinforce the correlation between image edges and receptive fields for effective information fusion to improve the perception of detailed image features. Extensive experimental analyses affirm the competitiveness of the proposed method, showcasing its ability to balance performance and recovery effectively, even with smaller training datasets. The code is available at https://github.com/Yuii666/HADN .},
  archive      = {J_IJPRAI},
  author       = {Yanyi He and Jinhong He and Minglong Xue and Senming Zhong and Mingliang Zhou},
  doi          = {10.1142/S0218001425540035},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2554003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hybrid-domain attention dense network for efficient image super-resolution},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stock market analysis and social media index based on deep learning. <em>IJPRAI</em>, <em>39</em>(03n04), 2552003. (<a href='https://doi.org/10.1142/S0218001425520032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a hybrid sentiment analysis model, FinBERT-BiLSTM-TextCNN, which integrates deep learning and machine learning techniques to accurately analyze the sentiment strength of comments in financial forums. We conduct a regression analysis of stock prices and apply economic analysis methods to evaluate the impact of social media sentiment on market dynamics. By processing user comments, we construct a comprehensive investor sentiment measurement indicator known as the Social Media Sentiment Index (SMI). This index innovatively combines two key metrics: sentiment strength and user engagement, offering a novel analytical tool for quantifying and characterizing investor sentiment. Our experimental results indicate two main findings: (1) Compared to current sentiment classification approaches, the hybrid FinBERT-BiLSTM-TextCNN sentiment analysis model achieves over a 3% improvement in sentiment classification accuracy on stock market forum datasets; (2) Based on real trading data from the Chinese stock market over two years and an analysis of 20 million comments from the East Money Forum, the proposed Social Media Sentiment Index more accurately reflects changes in individual stock characteristics and tracks market sentiment fluctuations more efficiently, with a correlation to stock price movements improving by more than 4% compared to traditional methods. This study demonstrates the significant role of integrating economic analysis with sentiment analysis in predicting stock market trends, highlighting the value of the Social Media Sentiment Index as a robust indicator of investor behavior and market sentiment.},
  archive      = {J_IJPRAI},
  author       = {Xiyao Xu},
  doi          = {10.1142/S0218001425520032},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2552003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Stock market analysis and social media index based on deep learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAT-UNet: Integrating CNN attention mechanism and TransUNet for lung mass segmentation. <em>IJPRAI</em>, <em>39</em>(03n04), 2552002. (<a href='https://doi.org/10.1142/S0218001425520020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest X-ray is one of the most common tests in radiology and plays a vital role in helping physicians spot different chest conditions. This paper proposes a new model called CAT-UNet to segment lung masses in chest X-ray images. The CAT-UNet uses TransUNet as the leading architecture and mixes CNN and transformer as an encoder. The CNN uses ResNet50 as the backbone, embedding the coordinate attention (CA) block and four skip connections of different scales to improve the accuracy of finding shallow features. Vision Transformer (ViT), which applied the transformer structure, was used in our method to enhance the feature representation ability of images, and Atrous Spatial Pyramid Pooling (ASPP) was used to adjust the filter’s field-of-view and control the resolution of features. In the decoder, the Convolutional Block Attention Modules (CBAM) are embedded for upsampling so that the segmentation details can be better optimized. To evaluate the performance and generalizability of the proposed method, we conducted a 3-fold cross-validation experiment using 1914 chest X-ray images labeled by radiologists collected from the Department of Radiology at Dalin Tzu Chi Hospital, Taiwan. Experimental results show that the proposed CAT-UNet achieves 89.06% on Dice, 91.62% on sensitivity, 98.64% on specificity, and 95.15% on accuracy, outperforming U-Net, TransUNet, and Swin-UNet encoders.},
  archive      = {J_IJPRAI},
  author       = {Ade Irma Suryani and Chuan-Wang Chang and Hsin-Tien Cheng and Tin-Kwang Lin and Chin-Wen Lin and Chuan-Yu Chang},
  doi          = {10.1142/S0218001425520020},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2552002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CAT-UNet: Integrating CNN attention mechanism and TransUNet for lung mass segmentation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven multi-modal interactive learning environment using deep learning and chain-of-thought reasoning. <em>IJPRAI</em>, <em>39</em>(03n04), 2552001. (<a href='https://doi.org/10.1142/S0218001425520019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of rapid advancements in educational technology, Active Interactive Learning Environments (ILEs) have emerged as key tools for enhancing instructional outcomes and student engagement. This paper presents an innovative active interactive learning system based on multi-modal chain-of-thought (CoT) reasoning, aiming to optimize personalized support in the learning process by integrating multi-modal data (including text, images, and videos) with CoT techniques. The system utilizes advanced deep learning technologies such as Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Retrieval-Augmented Generation (RAG) to achieve dynamic, real-time personalized content generation and feedback mechanisms. Experimental results indicate that this system significantly improves student performance and engagement in the “Computer Networks” course, demonstrating its effectiveness in practical teaching settings. This study provides a solid theoretical foundation and practical guidance for further research and application of intelligent educational systems, highlighting the potential for driving future educational innovation.},
  archive      = {J_IJPRAI},
  author       = {Tong Li},
  doi          = {10.1142/S0218001425520019},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2552001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {AI-driven multi-modal interactive learning environment using deep learning and chain-of-thought reasoning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing AutoTVM by parallel genetic algorithms. <em>IJPRAI</em>, <em>39</em>(03n04), 2551006. (<a href='https://doi.org/10.1142/S0218001425510061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To make deep neural networks automatically achieve the same or better performance compared with those in hand-optimized libraries, Tensor Virtual Machine (TVM) has combined a genetic algorithm (GA) with its AutoTVM auto-tuning process. The genetic algorithm of TVM has a primary and classic design, with restrictions in terms of searching scope, ability, and efficiency. Meanwhile, the current AutoTVM process is time-consuming. The whole process may last hours on GPUs. As such, we propose a new auto-tuning method that is based on a parallel GA and takes advantage of the strengths of the Roofline model-based cost models and machine learning classification models to widen the search scope and improve search efficiency. The new auto-tuning method achieves double optimization on both tuning results and tuning time. A series of experiments show that the new way improves the inference time of typical deep networks by about 8–14% and speeds up the time consumption of the auto-tuning process up to 1.2– 1 . 5 2 × on GPUs compared with the original GA process of AutoTVM.},
  archive      = {J_IJPRAI},
  author       = {Changhai Zhao and Jiamin Wen and Minqiang Shang and Yuchen Feng and Xiaohua Shi},
  doi          = {10.1142/S0218001425510061},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2551006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimizing AutoTVM by parallel genetic algorithms},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proton exchange membrane fuel cells lifetime estimation using GCN-GRU: Simulation and prospective tramway applications. <em>IJPRAI</em>, <em>39</em>(03n04), 2551003. (<a href='https://doi.org/10.1142/S0218001425510036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proton Exchange Membrane Fuel Cells (PEMFC) are a high-efficiency, clean energy source with significant potential for intelligent transportation systems, such as tramways. However, accurately predicting the lifespan of these fuel cells remains a significant challenge, critical for ensuring reliable and continuous tramway operation. This paper proposes an innovative hybrid neural network model combining Graph Convolutional Networks (GCN) and Gated Recurrent Units (GRU) for precise Remaining Useful Life (RUL) prediction of PEMFC. The model employs a graph learning layer to capture inter-node relationships from PEMFC data, constructing an asymmetric adjacency matrix that reflects the system’s internal directional dependencies. It then utilizes a mix-hop propagation layer to integrate time-series data, effectively capturing the dynamic behaviors and performance variations of PEMFC. Experimental results show that this model outperforms traditional GRU and CNN-GRU models in both short-term and long-term predictions, providing more accurate RUL estimations. The model utilizes high-fidelity test data from a France laboratory to improve the accuracy of fuel cell lifetime predictions, and the potential applications and experimental validation of the model in future intelligent transportation systems such as trams are discussed. This innovative approach provides a robust framework for predictive maintenance, and provides reliable data support and optimization schemes for practical applications in tramways, enhancing the reliability and efficiency of intelligent transportation systems.},
  archive      = {J_IJPRAI},
  author       = {Jinling Ma and Jiye Zhang and Jibin Yang},
  doi          = {10.1142/S0218001425510036},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2551003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Proton exchange membrane fuel cells lifetime estimation using GCN-GRU: Simulation and prospective tramway applications},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-validation-based multi-fault detection of gas turbine. <em>IJPRAI</em>, <em>39</em>(03n04), 2551002. (<a href='https://doi.org/10.1142/S0218001425510024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operating in harsh environments, gas turbines may encounter a variety of faults. Failure to promptly detect these faults can severely impact their safe and stable operation. During actual operations, accurately detecting the specific location of faults in gas turbines, such as sensors, actuators, or gas paths, to ensure prompt maintenance and safe, stable operation, is a crucial aspect of gas turbine maintenance. To address this issue, this study proposes a multi-fault detection method based on cross-validation. In situations with limited data, we have designed a classification method grounded in logical reasoning and constructed a cross-validation system. This system will be applied to layered analysis and discrimination of multiple faults, aiming to achieve effective detection of faults in gas turbine sensors, actuators, and air paths. Finally, simulation experiments have verified the effectiveness and feasibility of this method.},
  archive      = {J_IJPRAI},
  author       = {Ying Wang and Yunpeng Cao and Shuying Li and Linhai Zhu and Ke Han},
  doi          = {10.1142/S0218001425510024},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2551002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Cross-validation-based multi-fault detection of gas turbine},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining emerging patterns of data stream for improving classification performance. <em>IJPRAI</em>, <em>39</em>(03n04), 2550005. (<a href='https://doi.org/10.1142/S0218001425500053'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging patterns consider the support of patterns in the target class and opposite class datasets, which has a significant impact on improving the performance of data stream classification. The emerging pattern must first be a frequent pattern, and IncMine is a well-known data stream algorithm with frequent closed pattern mining. However, existing frequent pattern mining algorithms are oriented toward transactional data streams, and the itemset does not have class constraints, making it impossible to further mine emerging patterns for data stream classification. This paper proposes an emerging patterns based on IncMine (EPBIM) mining method, which improves the IncMine algorithm and uses Charm_Cla to mine frequent closed itemsets with class value constraints and obtain emerging patterns for Bayesian classification of data streams. The Charm_Cla runs on the WEKA platform, mining the emerging patterns of a batch and updating the semi-emerging patterns (semi-EPs) in the sliding window of data stream through the IncMine algorithm. Multiple real and simulated data streams were run on the data stream analysis platform massive online analysis (MOA), and the experimental results verified the effectiveness of the method.},
  archive      = {J_IJPRAI},
  author       = {Zhijie Li and Xuhong Liao and Sha Liao and Yuanxiang Li},
  doi          = {10.1142/S0218001425500053},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2550005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Mining emerging patterns of data stream for improving classification performance},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An invisible backdoor attack based on semantic feature. <em>IJPRAI</em>, <em>39</em>(03n04), 2550004. (<a href='https://doi.org/10.1142/S0218001425500041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backdoor attacks have severely threatened deep neural network (DNN) models in the past several years. Compared to adversarial attacks, backdoor attacks are always carried out during the training phase. The attacked model behaves normally on benign samples, it makes wrong predictions for samples containing triggers. This paper proposes a novel backdoor attack that makes imperceptible changes. Concretely, the attack first utilizes the pre-trained victim model to extract low-level and high-level semantic features from clean images and generates trigger patterns associated with high-level features based on channel attention. Then, the encoder model generates poisoned images based on the trigger and extracted low-level semantic features without causing noticeable feature loss. The attack is evaluated on two prominent image classification DNNs across three standard datasets. The results demonstrate that our attack achieves high attack success rates while maintaining robustness against backdoor defenses. Furthermore, extensive image similarity experiments emphasize the stealthiness of this attack strategy.},
  archive      = {J_IJPRAI},
  author       = {Yangming Chen and Xiaowei Xu and Xiaodong Wang and Zewen Li and Wenmin Chen},
  doi          = {10.1142/S0218001425500041},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2550004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An invisible backdoor attack based on semantic feature},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based texture feature extraction technique for face annotation. <em>IJPRAI</em>, <em>39</em>(03n04), 2532001. (<a href='https://doi.org/10.1142/S0218001425320015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face annotation plays a crucial role in the field of computer vision. Its purpose is to accurately label the faces that appear in an image. The effectiveness of face annotation relies heavily on the representation of facial features, such as color, texture, and shape. Deep texture features, in particular, play a significant role in face annotation systems. It is worth noting that different individuals can possess similar texture features, which can impact the performance of annotation. Therefore, this study addresses the enduring complexity of face similarity by introducing an innovative approach called the Deep Learning-based Texture Feature (DLTF) through the utilization of the efficient deep learning model known as the Residual Network (ResNet). Despite the variations in poses, lighting, expressions, and occlusions that can greatly alter faces, ResNet’s deep architecture and feature retention capabilities make it resilient to these changes, ensuring consistent and accurate annotations under diverse conditions. Experimental results obtained from the IMFDB, LFW, and Yahoo datasets demonstrate that the proposed DLTF is the most effective description of deep texture features, leading to improved face naming performance. Furthermore, the proposed DLTF enhances the efficiency of the face-naming task by effectively addressing real-life challenges.},
  archive      = {J_IJPRAI},
  author       = {A. Kasthuri and A. Suruliandi and E. Poongothai and S. P. Raja},
  doi          = {10.1142/S0218001425320015},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2532001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep learning-based texture feature extraction technique for face annotation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale GAN with NSCT prediction for seismic data denoising. <em>IJPRAI</em>, <em>39</em>(03n04), 2458006. (<a href='https://doi.org/10.1142/S0218001424580060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on denoising seismic signals effectively to obtain high-quality data, which is crucially important for oil-gas reservoir prediction and seismic interpretation tasks. The rapid progress of deep learning has brought new development opportunities to seismic oil and gas exploration technologies. However, current deep learning-based seismic denoising models have limited learning ability due to insufficient extraction features in strong noise backgrounds. For this reason, we develop a new multi-scale generative adversarial networks (GAN) with transform prediction for seismic signal denoising. First, we develop a deep multi-scale diversion fusion (MSDF) network in a GAN generator considering the advantages of combining GAN and convolutional neural networks. MSDF network primarily contains several MSDF blocks that mine abundant long-short path features in multiple receptive fields to restore seismic signals in a rough to detailed manner. Additionally, current deep learning-based seismic denoising models only exploit features in the spatial domain, not considering high-frequency characteristics, which results in insufficient high-frequency details when reconstructing seismic data. So, we propose to predict high-frequency components during learning by employing the superior non-subsampled contourlet transform (NSCT), which further preserves the better global topological structure and local texture characteristics of MSDF in GAN generator than the spatial domain, promoting the discrimination ability in GAN discriminator. The qualitative and quantitative results on our constructed synthetic dataset and actual seismic data demonstrate that the proposed method surpasses other deep learning-based approaches in realizing higher signal-to-noise ratio, as well as mining more effective high-frequency signals.},
  archive      = {J_IJPRAI},
  author       = {Cong Tang and Kang Chen and Bing Luo and Qi Ran and Majia Zheng and Han Xiao},
  doi          = {10.1142/S0218001424580060},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {03n04},
  pages        = {2458006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-scale GAN with NSCT prediction for seismic data denoising},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative artificial intelligence model for multi-granularity power data simulation. <em>IJPRAI</em>, <em>39</em>(2), 2559001. (<a href='https://doi.org/10.1142/S0218001425590013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric power resources are essential for the efficient and orderly development of society. Accurate power load forecasting is a key driver for the low-carbon upgrade of power systems. Traditional forecasting methods often struggle to capture long-term dependencies. Additionally, extracting complex nonlinear features from data remains a significant challenge, making it challenging to meet the accuracy demands of modern power systems. Besides, current deep learning-based forecasting methods cannot simulate multi-granularity power load data. To address these challenges, this paper presents a Generative Pre-trained Transformer model, GPT4PLTS, designed for power data simulation and fine-grained power load forecasting. The model leverages the Transformer architecture, incorporating the first six layers of the GPT decoder structure. It utilizes a multi-head attention mechanism to extract temporal features and includes a time alignment layer to maintain the sequence of time-series data, addressing both short-term and long-term dependencies. Extensive experiments are conducted on load observations from 2000 enterprises. The results demonstrate that GPT4PLTS achieves high accuracy in data simulation and forecasts across different time granularities, particularly excelling in short and medium-term predictions. Future research could focus on optimizing the model structure to enhance the model’s generalization ability.},
  archive      = {J_IJPRAI},
  author       = {Yiwen Jiang and Sheng Xiang and Yihan Dai and Dawei Cheng},
  doi          = {10.1142/S0218001425590013},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2559001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Generative artificial intelligence model for multi-granularity power data simulation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AMP: Multi-task transfer learning via leveraging attention mechanism on task embeddings. <em>IJPRAI</em>, <em>39</em>(2), 2557004. (<a href='https://doi.org/10.1142/S0218001425570046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The attention mechanism has been successfully used in a sequence consisted of a series of word embeddings to improve the representation of the sequence. Inspired by this, we leverage the attention mechanism on a set of tasks to implement a multi-task transfer learning method called AMP (Attentions between Multiple Prompts). First, we encode a task into a prompt as task representation called task embedding. Second, we learn an attention component on all task embeddings to generate a combined prompt for each task, which is an attention-weighted sum of task embeddings. Each combined prompt incorporates the knowledge of all tasks. The word embedding is a vector, but the task embedding is a 2D matrix. The attention mechanism can be exploited on a set of vectors rather than on a set of matrices. The prior methods employ pooling or flattened method to transform the matrix to the vector for computing the attentions between matrices. We propose a method called DAM (Direct Attention Mechanism) which can compute attentions between matrices directly without transforming. DAM method can more exactly compute the attentions between matrices. Wide experiments demonstrate that AMP outperforms prompt-tuning method and prior prompt transfer methods.},
  archive      = {J_IJPRAI},
  author       = {Yangyang Yu and Keru Wang},
  doi          = {10.1142/S0218001425570046},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2557004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {AMP: Multi-task transfer learning via leveraging attention mechanism on task embeddings},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lift-type power catwalk system based on dual closed-loop error-driven active disturbance rejection control. <em>IJPRAI</em>, <em>39</em>(2), 2557003. (<a href='https://doi.org/10.1142/S0218001425570034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To mitigate the flutter instability observed during lift-type power catwalk operations, a Dual-Loop Error-Driven Adaptive Disturbance Rejection Control (EDDL-ADRC) strategy is proposed. This approach enhances the tracking accuracy and robustness of the electro-hydraulic servo system under variable load and large inertia conditions, effectively alleviating flutter induced by fluctuations in driving speed. Under low-frequency small load conditions, the EDDL-ADRC overcomes the limitations of traditional Active Disturbance Rejection Control (ADRC), particularly those related to system order, and demonstrates superior control performance compared to conventional ADRC. The dual-loop error-driven controller consists of two identical second-order ADRC modules. The primary controller operates in a conventional driving mode, while the error-driven controller utilizes both the system’s output error and control input as driving signals. This error-driven controller effectively compensates for phase lag in the main controller and the limited observation accuracy of the Extended State Observer (ESO), thereby improving overall system performance. The proposed control strategy’s effectiveness is validated via a joint simulation platform that integrates both the electro-hydraulic and mechanical systems of the catwalk mechanism.},
  archive      = {J_IJPRAI},
  author       = {Jia Chen and Li Xiong and Simin Kang and Yi Yang and Zhongfeng Li},
  doi          = {10.1142/S0218001425570034},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2557003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lift-type power catwalk system based on dual closed-loop error-driven active disturbance rejection control},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An indoor WiFi fingerprint positioning based on RSS and CSI. <em>IJPRAI</em>, <em>39</em>(2), 2557002. (<a href='https://doi.org/10.1142/S0218001425570022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous people to determine the location by wireless fingerprint technology indoors at present. The premise of fingerprint positioning is to assume that the received signal strength distance is consistent with the positioning distance. However, due to the interference of obstacles such as walls, desks, chairs, pedestrians, the closest distance selected using the received signal strength distance may not be the closest to the target at its corresponding position, which may lead to large positioning errors. To improve accuracy, this paper analyzes the advantages of the respective features of RSS and CSI, use algorithms to extract them, and proposes a novel WiFi fingerprint positioning algorithm for fusion to estimate the target location. The experimental data show that this method has certain advantages in improving positioning accuracy.},
  archive      = {J_IJPRAI},
  author       = {Kun Zhang and Feixue Cheng and Haifeng Wang and Yu Zhou and Qiang Geng and Jinyang Zhou and Yukang Fan and Wenting Pan},
  doi          = {10.1142/S0218001425570022},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2557002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An indoor WiFi fingerprint positioning based on RSS and CSI},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rough intuitionistic fuzzy set based on inclusion degree. <em>IJPRAI</em>, <em>39</em>(2), 2554002. (<a href='https://doi.org/10.1142/S0218001425540023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper first proposes the notion of the intuitionistic fuzzy sets on inclusion degree, furthermore, a couple of dual operators’ lower approximations, and upper approximations of fuzzy inclusion approximate space are provided, thus, a probabilistic intuitionistic fuzzy set model that stemmed from inclusion degree was obtained. A rough intuitionistic fuzzy set and histogram equalization-based image enhancement algorithm is proposed to address the shortcomings of excessive enhancement and loss of image detail information in fuzzy enhancement that cannot improve image contrast and histogram equalization enhancement. The fusion of rough intuitionistic blur enhancement and histogram equalization focuses on rough intuitionistic blur enhancement while suppressing the shortcomings of histogram equalization, which not only enhances the detailed information of the image but also improves its contrast. Finally, its effectiveness is verified through typical image enhancement examples.},
  archive      = {J_IJPRAI},
  author       = {Qiuna Zhang and Chunhai Hu and Ling Zhang},
  doi          = {10.1142/S0218001425540023},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2554002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Rough intuitionistic fuzzy set based on inclusion degree},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image deblurring algorithm incorporating self-attention mechanism. <em>IJPRAI</em>, <em>39</em>(2), 2554001. (<a href='https://doi.org/10.1142/S0218001425540011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The acquisition of clear images is a critical aspect in various fields including computer vision, aerial detection, and medical imaging. The issue of image blur caused by object motion poses a challenge in obtaining clear images. To address this, an improved AT-DGAN network model is proposed in this paper. This model integrates the pyramid generator module of the DeblurGAN-v2 network with a self-attention mechanism. The feature pyramid is employed for image feature extraction and representation, while the self-attention mechanism dynamically adjusts the weight of important features in each pyramid layer and performs weighted fusion, thereby compensating for the information loss during feature extraction in the feature pyramid network. Additionally, a hinge loss function is designed for the proposed model to balance the discriminator and the generator, enhancing the stability and training efficiency of the generative adversarial network. The experimental results show that compared to other algorithms of the same type, this improved algorithm has increased the Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) of restored images by 0.58 dB and 1.5%, respectively.},
  archive      = {J_IJPRAI},
  author       = {Tingting Yu and Qiang Lv and Zhen Huang and Zhang Su and XiangLi Wang},
  doi          = {10.1142/S0218001425540011},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2554001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Image deblurring algorithm incorporating self-attention mechanism},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified model with multi-scale feature fusion and multi-decoupled-head for detecting traffic object. <em>IJPRAI</em>, <em>39</em>(2), 2550003. (<a href='https://doi.org/10.1142/S021800142550003X'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately and rapidly detecting traffic object has been attracted intensive attention due to its potential applications in the fields of autonomous driving, traffic flow monitoring, augmented reality (AR) and so on. However, there are many difficulties in the process of traffic object detection indeed, such as occlusion and aggregation between objects, insufficient feature extraction of objects, in particular the presence of a large number of small objects, which bring great challenges to these traffic objects detection. In this paper, an improved traffic object detection model based on You-Only-Look-Once version 5 small (YOLOv5s) is proposed to address the issues. By utilizing spatial pyramids to extract multi-scale spatial features and applying Squeeze-and-Excitation (SE) channel attention to capture more global and local semantic features, especially by designing a sub-network in the neck to fuse high-resolution information in shallow layers with more accurately semantic information in deep layers, the detection sensitivity of object features is enhanced. More importantly, by explanting decoupled-head into the network, outstanding performance of the model with high detection accuracy and rapid detection speed is realized. The experimental results on the Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) and Laboratory for Intelligent and Safe Automobiles (LISA) traffic signs datasets both show that the modified model significantly improves the detection accuracy. Meanwhile, the high real-time performance is still maintained. Undoubtedly, the modified model proposed in this paper can effectively address many difficulties in traffic object detection under various complex scenes, which would be greatly helpful for its potential applications in the future.},
  archive      = {J_IJPRAI},
  author       = {Yongfan Duan and Hongtao Gong and Haoyang Yu and Kuijie Shi and Bingbing Wang and Daoxun Jin and Wenqian Wan and Zihua Wang and Shuqin Liu and Gang Liu},
  doi          = {10.1142/S021800142550003X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2550003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A modified model with multi-scale feature fusion and multi-decoupled-head for detecting traffic object},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using hybrid transformer and convolutional neural network for malware detection in internet of things. <em>IJPRAI</em>, <em>39</em>(2), 2550002. (<a href='https://doi.org/10.1142/S0218001425500028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malicious firmware upgrading represents a critical security vulnerability in Internet of Things (IoT) devices. This study introduces HyCNNAt, a novel hybrid deep learning network for IoT malware detection that synergistically combines Convolutional Neural Networks (CNNs) with transformer attention mechanisms. HyCNNAt’s architecture vertically and horizontally stacks convolution and attention layers, enhancing the network’s generalization capabilities, capacity, and overall effectiveness. We evaluated HyCNNAt using a publicly available IoT firmware dataset, where it demonstrated superior performance with the highest accuracy ( 9 7 . 1 1 % ± 1 . 0 2 % ), F1-score ( 9 9 . 9 9 2 % ± 0 . 0 0 4 % ), and recall ( 9 7 . 4 8 % ± 2 . 6 5 5 6 % ), highlighting its robust classification capabilities, although its precision ( 9 1 . 2 7 % ± 4 5 . 0 8 % ) exhibited variability compared to state-of-the-art models such as CoAtNet, MobileViT, MobileNet, and MobileNet variants using transfer learning. These results underscore HyCNNAt’s potential as a robust solution for addressing the pressing challenge of IoT malware detection.},
  archive      = {J_IJPRAI},
  author       = {Yanhui Guo and Chunlai Du and Zelal Mustafaoglu and Abdulkadir Sengur and Harish Garg and Kemal Polat and Deepika Koundal},
  doi          = {10.1142/S0218001425500028},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2550002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Using hybrid transformer and convolutional neural network for malware detection in internet of things},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biased block term tensor decomposition for temporal pattern-aware QoS prediction. <em>IJPRAI</em>, <em>39</em>(2), 2550001. (<a href='https://doi.org/10.1142/S0218001425500016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of cloud services make users pay more attention to Quality of Service (QoS). Generally, the user cannot call all services simultaneously to obtain corresponding QoS data and can only choose a service from a few known data, thus it’s critical to predict unknown QoS values. A third-order tensor can model temporal patterns of QoS data, and studies indicate that the tensor latent factor analysis models based on Canonical Polyadic (CP) decomposition can effectively capture temporal patterns to predict unknown data in QoS. However, the existing CP decomposition-based models limit their learning ability since rank-one tensors contain less structure information, which results in low prediction accuracy. Therefore, this paper proposes a Biased Block Term Tensor Decomposition (BBTTD) model to achieve high accuracy for temporal pattern-aware QoS prediction. It mainly adopts the following three-fold ideas: (a) implementing a tensor learning model by adopting the block term decomposition in rank-( L r , L r , 1) terms; (b) proposing the bias block term tensors to enhance the model’s prediction accuracy; (c) designing a nonnegative multiplication update algorithm to learning model parameters. Extensive experiments on two public dynamic QoS datasets demonstrate that BBTTD has higher prediction accuracy compared with several QoS prediction models.},
  archive      = {J_IJPRAI},
  author       = {Qu Wang and Xin Liao and Hao Wu},
  doi          = {10.1142/S0218001425500016},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2550001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Biased block term tensor decomposition for temporal pattern-aware QoS prediction},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bayesian network-based scenario-response model for situation deduction in emergency management of rainstorm scenarios. <em>IJPRAI</em>, <em>39</em>(2), 2530001. (<a href='https://doi.org/10.1142/S0218001425300012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of safety hazards has intensified, underscoring the pressing need for effective responses to sudden disasters and enhanced emergency management. The traditional forecast-response paradigm is no longer adequately addressing the management and decision-making needs for contemporary emergency incidents. Existing emergency management frameworks often struggle with the systemic characteristics of unexpected events. This study proposes a Bayesian network-based scenario-response framework for situation deduction in Emergency Management, taking the torrential rain disaster in Henan Province as a point of reference. In this context, the fundamental units of disaster-forming environment (E), emergency measures (M), and scenario state (S) are employed to construct a coherent and dynamic scenario evolution chain, which effectively depicts the progression of the scenario linkage process. This approach facilitates a deeper understanding of the evolution of emergencies and enhances predictive capacity.},
  archive      = {J_IJPRAI},
  author       = {Liming Zhang and Jiangqinzhe Liu and Ruijie Zhao and Fenghua Zhang and Huiyou Chang},
  doi          = {10.1142/S0218001425300012},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2530001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A bayesian network-based scenario-response model for situation deduction in emergency management of rainstorm scenarios},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated human action recognition with improved graph convolutional network-based pose estimation. <em>IJPRAI</em>, <em>39</em>(2), 2457016. (<a href='https://doi.org/10.1142/S0218001424570167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of utilizing Artificial Intelligence (AI) to identify and label human behaviors from unprocessed activity data gathered from various sources is known as Human Activity Recognition (HAR). Because of its potential applications across multiple areas, computer vision faces a significant challenge in recognizing human actions and the accompanying interactions with objects and the environment. Investigating the temporal and geographical characteristics of the skeleton sequence is essential for this endeavor, according to recent studies. However, efficiently extracting discriminative temporal and spatial information remains a difficult task. This work proposes a novel Human Action Recognition Model exploiting improved Graph Convolutional Network (GCN)-based pose estimation with a Hybrid Classifier (IGCN-HC). The phases carried out in this model are pre-processing, pose estimation, feature extraction, and activity recognition. Initially, the input video will be pre-processed and a frame from the input video stream will be generated. Subsequently, human pose estimation exploiting improved GCN will be accomplished. Further, human skeletal joints’ coordinates in two- or three-dimensional spaces are determined via human pose estimation. Then, Shape Local Binary Texture (SLBT) and an improved hierarchy of skeleton features have been used to detect the variance in different activities. In the last phase, a hybrid classification model with the combination of Deep Maxout and customized CNN has been proposed for the recognition phase. The model utilizes two inputs pose estimation results (skeleton) and the extracted features for training purposes. Finally, the proposed trained model is evaluated for recognition on different test inputs and contrasted with the existing techniques.},
  archive      = {J_IJPRAI},
  author       = {Amit Baghel and Alok Kumar Singh Kushwaha and Roshan Singh},
  doi          = {10.1142/S0218001424570167},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2457016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automated human action recognition with improved graph convolutional network-based pose estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PDC bit design based on deep learning for gravel layer. <em>IJPRAI</em>, <em>39</em>(2), 2452023. (<a href='https://doi.org/10.1142/S0218001424520232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are lots of gravel layers gradually increasing from east to west of Kuqa Piedstone in Tarim Basin, especially the thickest gravel layer, high gravel content, large particle size, high compressive strength and poor drillability in Bozi block, which are the key factors that result in low drilling efficiency and complex drilling accidents. Therefore, this paper presents a design scheme based on lithology characteristics deep learning and artificial intelligence analysis of bit failure mode and characteristics of large section gravel layer in fore-salt. The design scheme of a PDC special-shaped tooth bit with strong impact resistance has been formed through the structural design of anti-impact aggressive PDC teeth, rock breaking efficiency study, combined with the optimization design of bit layout. The design scheme not only improves the anti-impact but also improves the anti-eddy performance of the PDC special-shaped tooth bit. It effectively expands both the application range of PDC special tooth bit in the gravel layer and prolongs the bit life. The artificial intelligence optimized PDC special-shaped tooth bit has obtained a great effect in deep gravel stratum, in the meantime, it successfully solved the problems of slow drilling rate and short footage of single bit in Kuqa formation and other formations.},
  archive      = {J_IJPRAI},
  author       = {Yongxing Sun},
  doi          = {10.1142/S0218001424520232},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2452023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {PDC bit design based on deep learning for gravel layer},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class incremental learning based on playback images generated by classification network. <em>IJPRAI</em>, <em>39</em>(2), 2451021. (<a href='https://doi.org/10.1142/S0218001424510212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification has surpassed human performance in numerous domains. However, in real-world scenarios, challenges such as storage constraints, privacy concerns, and commercial data protection necessitate the enhancement of existing models to accommodate new class classifications — a critical area of research known as class incremental learning. Data replay stands out as a pivotal technique within this domain. The DeepInversion algorithm ingeniously employs classification networks to generate training set images of notable quality. In this study, we improve the DeepInversion algorithm, leveraging a pre-trained model to yield superior quality playback images for class incremental learning. Within the context of class incremental learning, we introduce a cosine orthogonal classification loss function, formulated on the basis of linear layer analysis, to guide image generation and augment class incremental learning. This loss function is designed to ensure the mutual orthogonality of all class centers while minimizing intra-class distances. In the realm of knowledge distillation, we harness a combination of limited real images, a profusion of synthesized images, and Mix virtual images to facilitate feature cosine distance distillation. Sufficient comparative experiments and analyses with similar latest methods underscore the efficacy of our proposed approach, and obtain the SOTA results. The code for the paper can be found at http://github.com/YunXiaooooo/Class-incremental-learning-based-on-playback-images-generated-by-classification-network},
  archive      = {J_IJPRAI},
  author       = {Qiuyu Zhu and Yunxiao Zhang and Yunhang Zhuo and Junli Chen},
  doi          = {10.1142/S0218001424510212},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2451021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Class incremental learning based on playback images generated by classification network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diagnostic method for demagnetization fault of elevator synchronous traction machine based on informer. <em>IJPRAI</em>, <em>39</em>(2), 2451007. (<a href='https://doi.org/10.1142/S0218001424510078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a fault diagnosis method for synchronous traction machine demagnetization based on the Informer model. The method utilizes the Informer model to analyze and model the sensor data of the synchronous traction machine, adaptively learn the feature representation of time series data, and predict the future states in order to accurately identify and predict demagnetization faults. The specific steps include: (1) collecting sensor data of the synchronous traction machine, including parameters such as current, voltage, and rotational speed; (2) preprocessing the data, including denoising, normalization, and feature extraction; (3) constructing the Informer model and training and optimizing it using the preprocessed sensor data; and (4) using the trained model to predict and determine new sensor data, thereby achieving an accurate diagnosis of demagnetization faults. The advantages of this method are as follows: (1) automatic learning and extraction of important features of time series data without the need for manual feature design, improving diagnostic accuracy; (2) ability to handle long sequence data and strong modeling capability for time dependencies, better predicting future states and fault occurrences; and (3) adaptability to the characteristics and data features of different elevator systems and strong generalization capability.},
  archive      = {J_IJPRAI},
  author       = {Peng Shao and Bo Zheng and Xiaozhou Tang and Chao Chen and Xuefeng Hou},
  doi          = {10.1142/S0218001424510078},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2451007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Diagnostic method for demagnetization fault of elevator synchronous traction machine based on informer},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OTOT: An online training and offline testing system for 6D object pose estimation. <em>IJPRAI</em>, <em>39</em>(2), 2351015. (<a href='https://doi.org/10.1142/S0218001423510151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel system to assist 6D object pose estimation network training, which is only deployed in the training progress to optimize the network parameters, and does not work in the testing stage, called Online training and offline testing system (OTOT). OTOT consists of two modules: a feature fusion module and a supervision module. The feature fusion module fuses several feature maps from the pose estimation network in a specified order to obtain a fused feature. Then, the supervision module uses the encoder–decoder structure network to implicitly extract useful features from the fused feature and optimizes the pose estimation network online through the back-propagation mechanism. OTOT can be migrated to any network with encoder–decoder structure. The network trained with OTOT achieves 56.11% accuracy in terms of the VSD metric on the TLESS dataset using RGB inputs, compared to the 46.70% accuracy of the original network trained without OTOT. Experiments show that OTOT greatly improves the accuracy of the pose estimation network, and since OTOT is not deployed in the testing stage, it does not increase any parameters during testing and affect the original speed of the network.},
  archive      = {J_IJPRAI},
  author       = {Yilin Yuan and Qian Jiang and Quan Mu and Wenchao Jia and Boya Fu and Renzhi He and Jian Wen and Fei Liu and Qin Mao and Mingliang Zhou},
  doi          = {10.1142/S0218001423510151},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2351015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {OTOT: An online training and offline testing system for 6D object pose estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-target detection method of intelligent driving traffic scene based on faster R-CNN++. <em>IJPRAI</em>, <em>39</em>(1), 2459019. (<a href='https://doi.org/10.1142/S0218001424590195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current multi-objective detection methods are plagued by several issues, including insufficient detection efficiency, slow speeds, and difficulties in deciphering driving rules. To address these challenges, we introduce a traffic scene classification method that utilizes Improved Faster Regions with Convolutional Neural Network features (Faster R-CNN++). Initially, the shared convolutional layer and the Recurrent Criss-Cross Attention (RCCA) layer are employed to extract features from the input image. Subsequently, the derived feature map is fed into the Region Proposal Network (RPN) to generate detection boxes, and the Region of Interest Align (RoI Align) layer selects features corresponding to each Region of Interest (RoI) on the feature map, guided by the RPN’s output. Ultimately, we adopt an alternating training approach. Simulation experiments confirm the effectiveness of our method in multi-scene object detection. Our method has demonstrated significant improvements over existing algorithms and has delivered outstanding performance on the BDD-100 K, ApolloScape, and NuScenes datasets. The results indicate that our deep learning-based traffic scene classification method can accurately discern the behavioral characteristics of various traffic participants.},
  archive      = {J_IJPRAI},
  author       = {Qiangqiang Xu and Junhua Guo},
  doi          = {10.1142/S0218001424590195},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2459019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-target detection method of intelligent driving traffic scene based on faster R-CNN++},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance improvement in MIMO-OFDM VLC systems through combined adaptive modulation and coding with symbol decomposition. <em>IJPRAI</em>, <em>39</em>(1), 2458007. (<a href='https://doi.org/10.1142/S0218001424580072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the visible light communication (VLC) system, adaptive symbol decomposition technology is one of the methods to reduce peak-to-average power ratio (PAPR) and suppress LED nonlinear distortion. However, at high symbol variances, there still exists a high PAPR, leading to a higher number of decomposed symbols, which in turn reduces the information rate and increases the bit error rate (BER) performance. Therefore, a combined approach of adaptive modulation, adaptive symbol decomposition serial transmission (ASDST), and space–time block code and orthogonal cyclic matrix transform (STBC-OCT) coding is proposed. The characteristics of PAPR, symbol decomposition and BER under different approaches through Monte Carlo simulation were analyzed. The simulation results show that when using 4-Quadrate Amplitude Modulation (4QAM) modulation and CCDF= 2 × 1 0 − 4 , the STBC-OCT-ASDST scheme gains a 5 dB improvement compared to ASDST alone. At a BER of 3 × 1 0 − 2 , STBC-OCT-ASDST achieves a 10 dBm gain in symbol variance compared to ASDST. Moreover, when the symbol variance of STBC-OCT-ASDST is less than 34 dBm, the BER remains below the 7% threshold of forward error correction (FEC) error rate.},
  archive      = {J_IJPRAI},
  author       = {Na Zhang and JianQiang He and Jiao Liu and YuanYuan Wang},
  doi          = {10.1142/S0218001424580072},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2458007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Performance improvement in MIMO-OFDM VLC systems through combined adaptive modulation and coding with symbol decomposition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revolutionizing brain tumor diagnosis: A comprehensive model integrating VGG19 and LSTM for accurate MRI classification. <em>IJPRAI</em>, <em>39</em>(1), 2457015. (<a href='https://doi.org/10.1142/S0218001424570155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosing brain tumors is particularly difficult because they can grow in unpredictable ways and look very different on MRI scans. The current methods used to automatically identify these tumors often struggle because of the wide variety of tumor types and the complex structure of the brain. As a result, these methods don’t always classify tumors accurately, which can affect patient treatment and outcomes. The main problems with these methods are that they find it hard to distinguish between different types of tumors accurately and to deal with the various ways tumors can appear on MRI scans. To improve this situation, our study integrates the robust image classification capabilities of VGG19 with the sequential data processing strengths of LSTM. This synergistic approach enhances our model’s ability to accurately classify various types of brain tumors from MRI scans, addressing the inherent challenges associated with tumor heterogeneity in medical imaging. VGG19, a deep convolutional neural network, is employed to extract detailed features from MRI scans, facilitating precise tumor characterization based on visual patterns and LSTM complements VGG19 by capturing temporal dependencies in the sequential data of MRI scans, enabling the model to discern subtle variations in tumor appearances over time. By leveraging the combined power of VGG19 and LSTM architectures, our study achieves significant advancements in the accurate classification of brain tumors from MRI images. This approach not only enhances diagnostic precision but also lays the groundwork for future improvements in neuro-oncological imaging diagnostics. Our study includes 1000 patients evaluated with MRI for brain tumors. We achieved an overall accuracy of 98.32% demonstrating the efficacy of our VGG19-LSTM model in accurate tumor classification. By using both, our model aims to get better at understanding MRI scans and, as a result, be more accurate at identifying brain tumors. This combination is a new step forward in making brain tumor diagnosis more precise through a detailed and cooperative approach using neural networks.},
  archive      = {J_IJPRAI},
  author       = {Chandrasekar Venkatachalam and M. Umamaheswari and Priyanka Shah and Arastu Thakur},
  doi          = {10.1142/S0218001424570155},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2457015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Revolutionizing brain tumor diagnosis: A comprehensive model integrating VGG19 and LSTM for accurate MRI classification},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-frequency based EEG features for classification of human emotions. <em>IJPRAI</em>, <em>39</em>(1), 2457014. (<a href='https://doi.org/10.1142/S0218001424570143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human emotion classification without bias and unfairness is challenging because most existing image-based methods are directly or indirectly affected by subjectivity. Therefore, we propose an EEG (Electroencephalogram) based model for an accurate emotion classification without the effect of subjectivity. The captured EEG signals are converted into Delta, Theta, Alpha, Beta, and Gama frequency bands. As emotions change, the frequency bands change and provide unique patterns for each emotion irrespective of different persons. With this observation, the statical features, namely, mean, standard deviation, variance, and kurtosis, and frequency-based features, namely, Power Spectral Density (PSD) and Petrosian Fractal Dimension (PFD) are extracted. To integrate the strength of spatial and frequency-based features, the features are supplied to quadratic discriminative analysis for the final classification. The experiments on the benchmark datasets, DEAP and SEED-IV, achieve 99.40% and 91.97% accuracy, respectively. A comparison with state-of-the-art methods shows that the method performs very well on some datasets.},
  archive      = {J_IJPRAI},
  author       = {Shivanand S. Gornale and Shivakumara Palaiahnakote and Amruta Unki and Sunil Vadera},
  doi          = {10.1142/S0218001424570143},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2457014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Spatial-frequency based EEG features for classification of human emotions},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization-enabled shepard convolutional quantum neural network for brain tumor detection using MRI image. <em>IJPRAI</em>, <em>39</em>(1), 2457013. (<a href='https://doi.org/10.1142/S0218001424570131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors develop when abnormal cells grow within or near the brain. Determining the extent of the tumor is crucial for effective treatment. Magnetic Resonance Imaging (MRI) has emerged as a non-ionizing radiation tool for diagnosing brain tumors. Segmenting brain tumors manually is a tedious process so the performance depends on the experience of the operator. To overcome the above-mentioned problem, in this research project, brain tumor detection is classified by the proposed Shepard Convolutional Quantum Neural Network (ShCQNN) using MRI images. Initially, pre-processing of the input image is carried out with a Mean filter and the process of segmentation is executed by LinkNet. Here, the proposed Chicken Swarm Stock Exchange Trading Optimization (CSSETO) is used to train LinkNet. This CSSETO is formed from Stock Exchange Trading Optimization (SETO) and Chicken Swarm Optimization (CSO). Further, image augmentation includes rotation, random erasing, brightness or contrast adjustment, and shearing. Moreover, the extraction of features is done next to image augmentation, where some important features such as Local Ternary Pattern (LTP), Convolutional Neural Network (CNN), and Local Optimal Oriented Pattern (LOOP) are obtained. In the last stage, a brain tumor is detected using ShCQNN which is the amalgamation of Shepard Convolutional Neural Network (ShCNN) along with Quantum Neural Network (QNN). The two benchmark datasets, namely Multimodal Brain Tumor Segmentation Challenge 2018 (BraTS2018) database and the Figshare dataset are used to assess the performance of the proposed model using performance measures, such as specificity, accuracy, and sensitivity. Also, the performance of the proposed method has been compared with existing models, such as VGG Stacked Classifier Network (VGG-SCNet), Whale Harris Hawks Optimization (WHHO), CNN model, and EfficientNet-B0 and the results revealed that the proposed method provided superior performance than other existing methods. The proposed method obtains the accuracy of 0.925, sensitivity of 0.915, and specificity of 0.915. Regarding the accuracy, the performance improvement of the devised ShCQNN technique is 19.14%, 18.60%, 10.81%, and 2.70% higher than the existing methods VGG-SCNet, WHHO, CNN model, and EfficientNet-B0.},
  archive      = {J_IJPRAI},
  author       = {Swaminathan Balasubramanian and Veerraju Gampala and Alok Misra and Telu Venkata Madhusudhana Rao},
  doi          = {10.1142/S0218001424570131},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2457013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimization-enabled shepard convolutional quantum neural network for brain tumor detection using MRI image},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight and efficient wheat spike detection for small targets. <em>IJPRAI</em>, <em>39</em>(1), 2455014. (<a href='https://doi.org/10.1142/S0218001424550140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wheat spike detection is a crucial component of wheat yield prediction. In this study, n lightweight and efficient wheat spike detection model is proposed. The model employs a novel Wheat Spike Net Block (WSNB) within a lightweight network architecture, integrating Depth-Wise Convolution (DW-Conv) and Efficient Window Multi-Head Self-Attention (EW-MHSA) to rapidly process images and accurately identify wheat spikes, even under compact small target conditions. The model is equipped with four detection heads to effectively handle targets of varying scales and incorporates the innovative EMF-IOU loss function for refined bounding box estimation. Tested on a self-constructed Shangluo winter wheat dataset, the model achieves a detection speed of 96.1 FPS on NVIDIA Tesla V100 and mAP@0.5 of 95.3%, surpassing YOLOv5, EfficientV2, YOlOX,transformer, and MobileVIt3 in terms of accuracy and efficiency. The model’s performance across diverse hardware platforms highlights its potential for practical implementation in real-time wheat yield estimation and precision agriculture.},
  archive      = {J_IJPRAI},
  author       = {Bo Wang and Yawen Li and Jun Zhang and Liqiong Huang},
  doi          = {10.1142/S0218001424550140},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2455014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lightweight and efficient wheat spike detection for small targets},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel infogain and multi-axial wavelet-based transformer for personality trait question answering. <em>IJPRAI</em>, <em>39</em>(1), 2451023. (<a href='https://doi.org/10.1142/S0218001424510236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) is one of the attractive topics in the field of multimedia, affective, and empathic computing to garner user interest. Unlike existing models which aim at addressing challenges of VQA for the scene images, this work aims at developing a new model for Personality Trait Question Answering (PQA). It uses Twitter account information, which includes shared images, profile pictures, banners, text in the images, and descriptions of the images. Motivated by the accomplishments of the transformer, for encoding visual features of the images, a new InfoGain Multi-Axial Wavelet Vision Transformer (IgMaWaViT) is explored here. For encoding textual features in the images and descriptions, a new Information Gain BERT (InfoBert) method is introduced, which can handle the variable length encoding of text by choosing the optimal discriminator. Furthermore, the model fuses encodings of images and text according to the questions on different personality traits for question answering. The model is called InfoGain Multi-Axial Wavelet Vision Transformer for Personality Traits Question Answering (IgMaWaViT-PQA). To validate the efficacy of the proposed model, a dataset has been constructed, and it is used along with standard datasets for experimentation. Comprehensive experiments show that the proposed model is better than the state-of-the-art models. The code is available at the link: https://github.com/biswaskunal29/InfoGain_MultiAxial_PQA .},
  archive      = {J_IJPRAI},
  author       = {Kunal Biswas and Shivakumara Palaiahnakote and Saumik Bhattacharya and Umapada Pal and Ram Sarkar},
  doi          = {10.1142/S0218001424510236},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2451023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel infogain and multi-axial wavelet-based transformer for personality trait question answering},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of specialized deep-learning models for crop freshness assessment to mitigate post-harvest loss. <em>IJPRAI</em>, <em>39</em>(1), 2451022. (<a href='https://doi.org/10.1142/S0218001424510224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods for evaluating crop ripeness are critiqued for their inefficiency and potential harm to produce. The use of image-processing and deep-learning techniques can solve these issues as a trend in non-destructive methods. However, an overfitting problem arises when optimization and generalization are used to estimate the parameters of the next epoch. In this paper, we develop specialized models with a high volume of training images for a single type of crop to achieve the goal of 100% accuracy for both test and validation datasets. This development contributes insights into leveraging deep learning for crop assessment, emphasizing its potential application in diverse agricultural scenarios. Experimental results show that the proposed models are superior to several existing available methods.},
  archive      = {J_IJPRAI},
  author       = {Wellington Cunha and Arashdeep Kaur and Frank Y. Shih},
  doi          = {10.1142/S0218001424510224},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2451022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Development of specialized deep-learning models for crop freshness assessment to mitigate post-harvest loss},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). XAttentionHAR ensemble: Leveraging cross-modal attention for enhanced activity recognition. <em>IJPRAI</em>, <em>39</em>(1), 2450026. (<a href='https://doi.org/10.1142/S0218001424500265'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Activity Recognition (HAR) is pivotal in ubiquitous computing, offering benefits to human-centric services such as health monitoring, smart homes, and eldercare systems. HAR leverages smartphones, smartwatches, and other wearable devices to collect sensory data annotated with activity labels, which are then used to train machine learning or deep learning models for automatic activity recognition. Effective HAR systems must integrate information from multiple modalities to accurately assist users. This paper introduces the XAttentionHAR model, an innovative cross-modality attention-based ensemble model for HAR. Our approach utilizes a self-attention module to extract features within each modality and an inter-domain cross-attention module to capture and integrate long-term dependencies across domains. The cross-modality attention mechanism enhances the fusion of diverse modalities, enriching the semantic information. We conducted extensive experiments on the WISDM public dataset, which includes accelerometer and gyroscope data from smartwatches and smartphones. Our results demonstrate that XAttentionHAR outperforms other state-of-the-art methods in activity recognition, achieving 98.48% accuracy for smartphone-based HAR and 98.73% accuracy for smartwatch-based HAR, paving the way for improved human-centric services.},
  archive      = {J_IJPRAI},
  author       = {Sarita Sahni and Sweta Jain and Sri Khetwat Saritha},
  doi          = {10.1142/S0218001424500265},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2450026},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {XAttentionHAR ensemble: Leveraging cross-modal attention for enhanced activity recognition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A newly adopted YOLOv9 model for detecting mould regions inside of buildings. <em>IJPRAI</em>, <em>39</em>(1), 2450025. (<a href='https://doi.org/10.1142/S0218001424500253'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molds on wall and ceiling surfaces in damp indoor environments especially in houses with poor insulation and ventilation are common in the UK. Since it releases toxic chemicals as it grows, it is a serious health hazard for occupants who live in such houses. For example, eye irritation, sneezing, nose bleeds, respiratory infections, and skin irritations. Furthermore, there are chances of developing serious medical conditions like lung infections and respiratory diseases which may even lead to death. The main challenge here is that due to their irregular patterns, camouflaged with the background, it is not so easy to detect with our naked eyes in the early stage and often confused as stains. Therefore, inspired by the accomplishments of the Yolo architecture for object detection, the Yolov9 model is explored for mold detection by considering mold region as an object in this work. The overall result shows a promising 76% average classification rate. Since the mold does not have a shape, specific pattern, or color, adapting the Yolov9 for accurate mold detection is challenging. To the best of our knowledge, this is the first of its kind compared to existing methods. Since it is the first work, we constructed a dataset to perform experiments and evaluate the proposed method. To demonstrate the proposed method’s effectiveness, the results were also compared with the results of the Yolov8 and Yolov10 models.},
  archive      = {J_IJPRAI},
  author       = {Taha Mansouri and Md. Shadab Mashuk and Shivakumara Palaiahnakote and Aaron Chacko and Lawrence Sykes and Ali Alameer},
  doi          = {10.1142/S0218001424500253},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2450025},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A newly adopted YOLOv9 model for detecting mould regions inside of buildings},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight safety activity recognition algorithm for railway field personnel based on portable cards. <em>IJPRAI</em>, <em>39</em>(1), 2450024. (<a href='https://doi.org/10.1142/S0218001424500241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, railway construction has been plagued by frequent safety accidents, with workers’ safety during the construction process remaining a major concern. To mitigate this issue, intelligent monitoring of railway workers’ activity has been proposed as a means of improving the safety coefficient of construction. Human activity recognition (HAR) based on wearable devices holds significant application value in areas such as health monitoring, motion analysis, and intelligent assistance. Recently, convolutional neural networks (CNNs) have gained extensive adoption and demonstrated outstanding performance in HAR. However, current HAR research still faces some challenges, including problems with establishing spatial–temporal dependencies and addressing the demand for lightweight models. To address the above issues, we propose a lightweight dual-stream convolution model (LDSC) based on deformable convolution and hierarchical segmentation. The model adaptively captures significant variations in sensor readings over time from portable cards of railway personnel through a temporal stream and learns the interactive information among sensor channels over a spatial stream. LDSC consists of three lightweight convolutional modules that combine deep convolution and point convolution to reduce model parameters, thus meeting the demand for a lightweight model. Experiments and ablation studies are conducted on three available datasets (UCI-HAR, UniMiB-SHAR, and WISDM) to evaluate the proposed model. The experimental results indicate that our model outperforms existing state-of-the-art methods in terms of recognition accuracy, validating the effectiveness and feasibility of LDSC. In addition, theoretical analysis and ablation experiments demonstrate that the proposed LDSC embodies lightweight characteristics.},
  archive      = {J_IJPRAI},
  author       = {Hailu Zuo and Jiukai Deng and Zihan Liu and Guangjun Tian and Shuo Xiao},
  doi          = {10.1142/S0218001424500241},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2450024},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lightweight safety activity recognition algorithm for railway field personnel based on portable cards},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
